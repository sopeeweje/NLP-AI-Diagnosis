text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9768545,R01LM012918,"['Adult', 'Adverse drug event', 'Algorithms', 'Apache', 'Area', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'base', 'case finding', 'improved', 'learning strategy', 'malignant breast neoplasm', 'method development', 'natural language', 'neural network', 'new technology', 'news', 'novel', 'open source', 'point of care', 'side effect', 'social media', 'software systems', 'statistics', 'supervised learning', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2019,383874,0.031313564422697386
"Leveraging Unlabeled and Pseudo Data for Clinical Information Extraction Project Summary/Abstract Electronic Health Records (EHRs) contain significant information that can benefit many downstream uses. However, most of this information is in unstructured narrative form and is inaccessible to computerized methods that rely on structured representations for exploring, retrieving, and presenting the information. Natural language processing (NLP) and information extraction (IE) open this trove of information to studies that would otherwise be without. Over the past decades, many IE systems have been developed. These systems have typically focused on one task at a time. In addition, most have studied only specific types of records, e.g., discharge summaries, and addressed their task on data from a single institution. Performances achieved by the state-of-the-art IE systems developed under these conditions ranged from 44% F-measure to 99% F-measure. This observed variation can be attributed to the nature of the tasks: some target entities like dates tend to be better represented in the data and also more rigidly stick to known patterns of expression as opposed to reasons for medication administration which are relatively sparse in the data and can show wider linguistic diversity. However, this may not be the only reason: the data used can also explain the performance variation. Narratives of EHRs vary in their style, format, and content going from one department to another, from one hospital to another. Even the same record type in two different hospitals can be very different in narrative style and pose different challenges for IE. Understanding IE performance therefore requires studies of multiple tasks on multiple record types that come from multiple institutions. One major bottleneck for evaluation of IE systems on such a large scale is annotation. The same bottleneck also limits system development. This proposal aims to address this bottleneck for both evaluation and development. It first generates a multi-institution corpus consisting of multiple record types from five institutions. It studies four different IE tasks that broadly represent IE in clinical records and can inform the field of IE as a whole: de-identification, clinical concept extraction, medication extraction, and adverse drug event extraction. Within the context of these IE tasks, the proposal then puts forward methods that learn from unlabeled or pseudo data that can help alleviate reliance on annotated data for development. It evaluates these methods both for performance and generalizability on multiple types of records from multiple institutions. As a result of these activities, this proposal generates de-identified data, annotations, methods, software, and machine learning models which it then makes available to the research community. Project Narrative Information extraction (IE) systems, i.e., natural language processing (NLP) systems that enable creation of accurate semantic representations of narratives, rely heavily on the availability of gold standard annotated corpora and vary significantly in their performance from task to task, and from data set to data set. We propose methods that augment gold standard data with unlabeled data that are more easily available, and pseudo data which can be derived from gold standard data. We study IE within the context of four tasks and evaluate IE systems enhanced with unlabeled and pseudo data for generalizability on a heterogeneous data set consisting of multiple record types from five institutions.",Leveraging Unlabeled and Pseudo Data for Clinical Information Extraction,9813134,R15LM013209,"['Accident and Emergency department', 'Address', 'Adverse drug event', 'Affect', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Discipline of Nursing', 'Electronic Health Record', 'Engineering', 'Evaluation', 'Frequencies', 'Gold', 'Growth', 'Healthcare', 'Hospitals', 'Institution', 'Israel', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nature', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Plant Roots', 'Procedures', 'Psychiatry', 'Publications', 'Records', 'Reporting', 'Research', 'Resources', 'Route', 'Sampling', 'Semantics', 'Signs and Symptoms', 'Social Work', 'Structure', 'Supervision', 'System', 'Systems Development', 'Task Performances', 'Telephone', 'Test Result', 'Testing', 'Text', 'Thinness', 'Time', 'Training', 'Universities', 'Variant', 'Virginia', 'Washington', 'computerized', 'deep learning', 'dosage', 'field study', 'improved', 'learning strategy', 'medication administration', 'novel', 'open source', 'response', 'supervised learning', 'tool']",NLM,GEORGE MASON UNIVERSITY,R15,2019,414798,0.0038992432126095616
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this ﬁeld typically produce an “all-cause” risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest – at best – reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiﬁable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classiﬁcation models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signiﬁcantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identiﬁcation and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9681485,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Comorbidity', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'risk prediction model', 'skills', 'social', 'supportive environment', 'trend', 'trial design']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2019,195076,-0.004113318670624387
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9794757,R01LM012817,"['Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Comorbidity', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,337238,-0.0056828398690122895
"Improving Specialty Care Delivery in the Safety Net with Natural Language Processing Project Summary  Safety net providers treat a substantial share of socioeconomically vulnerable patients in their communities, but struggle to provide timely access to high quality specialty care for their patients. Delayed access to specialty care is associated with worse health outcomes and potentially contributes to health disparities across socioeconomic groups. Given their limited resources, safety net providers must seek creative approaches to improve specialty access. However, to choose what programs to implement, safety net providers need to understand the specialty care needs of their populations. Fortunately, the adoption of eConsult systems by safety net providers across the US provides a valuable opportunity to systematically measure patterns of specialty care referrals for minority, underserved populations.  In this project, we propose using state-of-the-art methods in machine learning and natural language processing (NLP) to help safety net providers extract actionable, population wide data from their electronic consultation systems. We will do this in partnership with three of the most prominent safety net health systems in the US in Los Angeles, San Francisco and New York City. Using specialty request databases from our collaborators, we will build NLP systems to automatically classify specialty requests along two dimensions: the “clinical issue” motivating the request (e.g., chest pain), and the “question type” (e.g., request for a procedure, help with medication management). This automated classification of electronic specialty requests can enable identification of promising targets for interventions to improve specialty access and quality of care.  After developing these NLP systems, we will analyze >1 million specialty requests to describe trends in how safety net patients are referred to specialists and examine variation in referral patterns by clinic and individual provider. The goal is to identify the most impactful opportunities to improve specialty access and quality. For example, a high rate of referrals for esophageal reflux, which most PCPs can treat on their own with specialist guidance, could lead to new treatment algorithms, potentially reducing the need for these requests and improving access for other patients.  This proposal is a “high-risk high-reward” project that creates new research tools to identify and evaluate data-driven interventions to improve specialty care delivery for underserved populations. Project Narrative Access to timely, high-quality specialty care is a fundamental component of a well-functioning health system, yet safety net health care providers face persistent challenges delivering such care. Quality improvement efforts to improve specialty access have been thwarted in part because safety net providers lack the data to understand a basic question – why patients are referred for specialty care. Taking advantage of the growing use of electronic specialty referral systems by safety net providers, we propose using natural language processing to conduct automated analysis and classification of specialty requests in safety net populations, which will enable the design of targeted interventions to improve specialty care access and delivery.",Improving Specialty Care Delivery in the Safety Net with Natural Language Processing,9789060,R21MD012693,"['Acute', 'Adopted', 'Adoption', 'Algorithms', 'Caring', 'Chest Pain', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Communities', 'Consultations', 'County', 'Data', 'Data Set', 'Databases', 'Education', 'Epidemiology', 'Face', 'Federally Qualified Health Center', 'Gastroesophageal reflux disease', 'Goals', 'Health', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Heart failure', 'Hospitals', 'Improve Access', 'Individual', 'Intervention', 'Lead', 'Los Angeles', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Education', 'Medical center', 'Medication Management', 'Methods', 'Minority', 'Morbidity - disease rate', 'Natural Language Processing', 'New York City', 'Online Systems', 'Ophthalmology', 'Outcome', 'Patients', 'Pattern', 'Play', 'Population', 'Primary Care Physician', 'Procedures', 'Provider', 'Public Hospitals', 'Quality of Care', 'Research', 'Resources', 'Retinal Diseases', 'Role', 'San Francisco', 'Specialist', 'System', 'Taxonomy', 'Telemedicine', 'Text', 'Time', 'Transplantation', 'Triage', 'Underserved Population', 'Variant', 'Visit', 'automated analysis', 'care delivery', 'design', 'diabetic', 'disease classification', 'ethnic minority population', 'follow-up', 'health disparity', 'high reward', 'high risk', 'improved', 'medical specialties', 'medically underserved', 'minority communities', 'mortality', 'performance tests', 'programs', 'racial and ethnic', 'safety net', 'screening', 'socioeconomic disadvantage', 'socioeconomics', 'tool', 'trend', 'two-dimensional']",NIMHD,BOSTON CHILDREN'S HOSPITAL,R21,2019,94263,0.019019594168846715
"Automated Knowledge Engineering Methods to Improve Consumers' Comprehension of their Health Records PROJECT SUMMARY  Today, more patients can access their health records online than ever before. However, clinical acronyms hinder patients' comprehension of their records and decrease the benefits of transparency. An automated system for expanding clinical acronyms should have major clinical significance and far-reaching consequences for improving patient-provider communication, shared decision-making, and health outcomes. Existing systems have limited power to expand clinical acronyms, primarily due to the lack of comprehensiveness (or generali- zability) of existing acronym sense inventories. Because developing comprehensive sense inventories is difficult, existing knowledge engineering methods have primarily focused on developing institution-specific sense inventories. Institution-specific sense inventories may not be generalizable to other geographical regions and medical specialties. Furthermore, developing an institution-specific sense inventory at every US healthcare organization is not feasible, especially without automated methods which currently do not exist.  I developed advanced knowledge engineering methods to overcome these limitations through the use of fully automated techniques to generalize existing sense inventories from different geographical regions and medical specialties. My methods leverage the extensive resources already devoted to developing institution- specific sense inventories in the U.S., and may help generalize existing sense inventories to institutions without the resources to develop them. Although promising, challenges remain with the optimization and evaluation of these methods. The objective of the proposed project is to use knowledge engineering to improve patients' comprehension of their health records, focusing specifically on clinical acronyms. In Aim 1, I will develop new knowledge engineering methods to facilitate the automated integration of sense inventories, using literature- based quality heuristics and a Siamese neural network to establish synonymy. I will evaluate these methods using multiple metrics to assess redundancy, quality, and coverage in two test corpora with over 17 million clinical notes. In Aim 2, I will evaluate whether the knowledge engineering methods improve comprehension of doctors' notes in 60 hospitalized patients with advanced heart failure. With success, I will create novel, automated knowledge engineering methods that can be directly applied to improve patient care. This research is in support of my mentored doctoral training at Columbia University Department of Biomedical Informatics (DBMI) under Drs. David Vawdrey, George Hripcsak, Carol Friedman, Suzanne Bakken, and Chunhua Weng, and will include coursework on deep learning, oral presentations at major annual conferences, and career development planning, among other activities. DBMI is frequently recognized as one of the oldest and best programs of its kind in the world, and provides an exception training environment for my development into an independent and productive academic investigator. PROJECT NARRATIVE Clinical acronyms make it difficult for patients to understand their medical records, decreasing the benefits of transparency. This project applies advanced knowledge engineering methods and machine learning to generate comprehensive acronym sense inventories used to aid consumers' comprehension of their health records. The project is in support of the applicant's mentored doctoral dissertation research.",Automated Knowledge Engineering Methods to Improve Consumers' Comprehension of their Health Records,9681711,F31LM013054,"['Abbreviations', 'Award', 'Clinical', 'Clinical Medicine', 'Comprehension', 'Controlled Vocabulary', 'Development', 'Development Plans', 'Engineering', 'Environment', 'Equipment and supply inventories', 'Evaluation', 'Future', 'Geographic Locations', 'Goals', 'Grant', 'Health', 'Healthcare', 'Heart failure', 'Hospitals', 'Informatics', 'Information Resources', 'Institution', 'Knowledge', 'Literature', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Mentors', 'Mentorship', 'Methods', 'Natural Language Processing', 'Oral', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Positioning Attribute', 'Publishing', 'Questionnaires', 'Records', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Safety', 'Source', 'Support System', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Unified Medical Language System', 'Universities', 'acronyms', 'base', 'biomedical informatics', 'career development', 'clinically significant', 'deep learning', 'doctoral student', 'federal policy', 'health care service organization', 'health record', 'heuristics', 'improved', 'information organization', 'medical specialties', 'method development', 'multidisciplinary', 'neural network', 'novel', 'patient portal', 'patient-clinician communication', 'programs', 'shared decision making', 'success', 'symposium', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,F31,2019,50016,0.00010049415444504074
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9774338,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2019,1521748,0.010548166935647536
"Studying pseudogout using naturallanguage processing and novelimaging approaches Candidate: Dr. Tedeschi is an Instructor in Medicine at Harvard Medical School (HMS) and Associate Physician in the Division of Rheumatology, Immunology and Allergy’s Section of Clinical Sciences (SCS) at Brigham and Women’s Hospital (BWH). She received an MPH from the Harvard T.H. Chan School of Public Health (HSPH). Her 10 first-author manuscripts, two BWH grants, and foundation award exemplify her productivity and commitment to research. She has assembled an experienced team of mentors and collaborators, led by Dr. Daniel Solomon (primary mentor) and Drs. Katherine Liao and Karen Costenbader (co-mentors), to guide her training in natural language processing and machine learning approaches for clinical research, analysis of linked electronic medical record (EMR) and Medicare claims data, and interpretation of advanced imaging modalities. Focused coursework at HSPH and HMS will complement the experience she gains through her proposed studies of pseudogout risk factors and long-term outcomes. Training in dual- energy CT and ultrasound interpretation for crystalline arthritis will be obtained via one-on-one sessions. Her long-term career goal is to become an independent patient-oriented investigator focused on pseudogout. Environment: Dr. Tedeschi has a commitment from her Division for >75% protected time for research and career development activities during the K23 award period. Support from the Division and her primary mentor’s research funds will supplement her salary and project-related expenses. The SCS, a collaborative clinical research group in the Division of Rheumatology, has extensive infrastructure including the VERITY Bioinformatics Core (NIH-P30-AR072577, PI: Solomon) that will provide resources and expertise for the proposed studies. In addition, the BWH Arthritis Center is one of the largest nationally, facilitating subject recruitment, and the BWH Division of Musculoskeletal Imaging has state-of-the-art equipment and expertise applying dual-energy CT in crystalline arthritis. Coursework at HSPH and HMS, adjacent to BWH, will provide training necessary for Dr. Tedeschi’s development into an independent investigator. Research: Dr. Tedeschi’s long-term objective is to prevent and reduce morbidity from pseudogout, an understudied, painful crystalline arthritis that affects 8-10 million Americans. She will use natural language processing and machine learning approaches to enhance an algorithm for identifying pseudogout in EMR data. She will study risk factors for and long-term outcomes in pseudogout, harnessing vast amounts of information contained in Partners HealthCare EMR data and Medicare claims data, and will gain experience working with linked datasets. Dr. Tedeschi will recruit subjects with pseudogout and other types of mono- and oligoarthritis to test and compare the performance of dual-energy CT scanning, musculoskeletal ultrasound, and x-ray for identifying pseudogout. Her proposed K23 projects will lead to manuscripts and data to be leveraged in an R01 application focused on pseudogout during the award period, leading to independence as a patient-oriented investigator. Project Narrative The proposed studies will contribute fundamental knowledge about pseudogout, a common, painful crystalline arthritis for which we have little prognostic information and no targeted treatments. Results from the proposed projects could lead to methods for non-invasive, accurate pseudogout diagnosis, development of preventive strategies for pseudogout, and interventions to reduce cardiovascular disease risk. Future work stemming from the proposed projects may include predictive models of pseudogout flares, identification of serum biomarkers for pseudogout, and development of outcomes measures to be used in prospectively recruited pseudogout cohort studies.",Studying pseudogout using naturallanguage processing and novelimaging approaches,9717330,K23AR075070,"['Acute', 'Affect', 'Age', 'Agreement', 'Algorithms', 'American', 'Arthritis', 'Award', 'Bioinformatics', 'Biological Markers', 'Calcium Pyrophosphate', 'Calcium pyrophosphate deposition disease', 'Cardiovascular Diseases', 'Case-Control Studies', 'Chronic', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Code', 'Cohort Studies', 'Complement', 'Computerized Medical Record', 'Conflict (Psychology)', 'Crystallization', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diuretics', 'Environment', 'Equipment', 'Event', 'Female', 'Flare', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Gout', 'Grant', 'Healthcare', 'Hospitals', 'Hypersensitivity', 'Image', 'Immunology', 'Inflammatory', 'Inflammatory Arthritis', 'Infrastructure', 'Institution', 'Insurance Claim Review', 'Interleukin-1 beta', 'Intervention', 'Ischemic Stroke', 'Joints', 'Knowledge', 'Lead', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Manuscripts', 'Medicare claim', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Oligonucleotides', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pain', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Polyarthritides', 'Population', 'Positioning Attribute', 'Predictive Value', 'Prevalence', 'Prevention strategy', 'Productivity', 'Proton Pump Inhibitors', 'Pseudogout', 'Public Health Schools', 'Publishing', 'Questionnaires', 'Research', 'Research Personnel', 'Resources', 'Rheumatoid Arthritis', 'Rheumatology', 'Risk', 'Risk Factors', 'Roentgen Rays', 'Sensitivity and Specificity', 'Serum', 'Structure', 'Synovial Fluid', 'Techniques', 'Testing', 'Time', 'Training', 'Ultrasonography', 'United States National Institutes of Health', 'Validation', 'Vascular calcification', 'Vascularization', 'Visit', 'Wages', 'Woman', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'bisphosphonate', 'calcium indicator', 'cardiovascular disorder risk', 'career', 'career development', 'cohort', 'crystallinity', 'epidemiology study', 'experience', 'genetic linkage analysis', 'high risk', 'human old age (65+)', 'imaging modality', 'instructor', 'longitudinal course', 'medical schools', 'modifiable risk', 'mortality', 'mortality risk', 'musculoskeletal imaging', 'musculoskeletal ultrasound', 'novel', 'patient oriented', 'predictive modeling', 'prevent', 'prognostic', 'prospective', 'ranpirnase', 'recruit', 'research and development', 'sex', 'side effect', 'stem', 'targeted treatment', 'unnecessary treatment']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,K23,2019,176541,0.02154545449914055
"Identifying Personalized Risk of Acute Kidney Injury with Machine Learning PROJECT SUMMARY/ABSTRACT Acute Kidney Injury (AKI) is a common and highly lethal health problem, affecting 10-15% of all hospitalized patients and >50% of patients in intensive care units (ICUs). It has been shown that a small increase in serum creatinine (SCr) of ≥0.5 mg/dl was associated with a 6.5-fold increase in the odds of death, a 3.5-day increase in length of stay, and nearly $7,500 in excess hospital costs. Unfortunately, no specific treatment exists to cure AKI once it has developed. The ability to predict AKI in hospitalized patients would provide clinicians the opportunity to modify care pathways and implement interventions, which could in turn prevent AKI and yield better outcomes. Although electronic medical record (EMR) based monitoring systems for AKI have led to expedited interventions and may increase the percentage of patients returning to baseline kidney function, most of these systems are reactive rather than proactive, with little or no contribution to AKI prevention. Moreover, our current knowledge of AKI risk factors is far from complete, especially in the ICU and general inpatient populations, characterized by numerous deficiencies and systematic failings that may be avoidable To transform the reactive AKI care to proactive and personalized care, early identification of high risk patients and better understanding of individual modifiable risk factors for AKI is the key. In Aim 1, to discover novel risk factors predictive of AKI, we propose to develop an ensemble multi-view feature selection framework to simultaneously consider the differences and interrelations between feature spaces and obtain robust knowledge by synthesizing findings from diverse patient populations across multiple institutions in nine US states. In Aim 2, to discover general modifiable causes of AKI to help physicians design more effective AKI prevention policies, we propose to develop a novel multi-cause inference method to identify causal relationships between modifiable factors and AKI for susceptible patient subgroups. In Aim 3, to explain what caused AKI in individual patients to support physicians in designing personalized AKI intervention, we propose to develop a new causal explanation method by integrating causal inference and case based reasoning to quantify patient-level causal significance of modifiable factors. The proposed study will have a significant clinical impact by not only expanding the capacity of clinicians to identify high risk patients for AKI early and advancing the general knowledge on causal and modifiable risk factors for AKI but also supporting personalized AKI intervention with suggestions on potential patient-specific actionable items. The work will not only advance AKI but also the machine learning and clinical research informatics community and the methodology developed is generalizable to other clinical domains. PROJECT NARRATIVE The proposed research is to identify clinical risk factors of acute kidney injury (AKI) in hospitalized patients from electronic medical records (EMRs) with machine learning. AKI risk factors discovered from EMR of diverse populations from multiple institutions across nine US states will be reliable and robust and can assist clinicians in providing proactive and personalized care to high-risk patients.",Identifying Personalized Risk of Acute Kidney Injury with Machine Learning,9819327,R01DK116986,"['Acute Renal Failure with Renal Papillary Necrosis', 'Affect', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Computerized Medical Record', 'Creatinine', 'Data', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Early identification', 'Elderly', 'Event', 'Exposure to', 'Geographic Locations', 'Geographic state', 'Health', 'Health system', 'Heterogeneity', 'Hospital Costs', 'Hospital Mortality', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Injury to Kidney', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Length of Stay', 'Life', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Monitor', 'Myocardial', 'Outcome', 'Outcomes Research', 'Pathway interactions', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Physiology', 'Policies', 'Population', 'Population Heterogeneity', 'Predictive Factor', 'Renal function', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Sepsis', 'Series', 'Serum', 'Suggestion', 'System', 'Time', 'Work', 'adjudication', 'base', 'case-based', 'clinical predictors', 'clinical risk', 'design', 'high dimensionality', 'high risk', 'improved', 'individual patient', 'inhibitor/antagonist', 'injury prevention', 'machine learning algorithm', 'modifiable risk', 'mortality risk', 'nephrotoxicity', 'novel', 'patient population', 'patient subsets', 'personalized care', 'prevent']",NIDDK,UNIVERSITY OF KANSAS MEDICAL CENTER,R01,2019,512304,0.012140186138396914
"Online Evidence of Withdrawal Self-Medication PROJECT SUMMARY/ABSTRACT Withdrawal symptoms from opioid use can be severe and are major contributing factors to relapse and continuing misuse. Many opioid users are actively experimenting with “remedies” that can alleviate withdrawal, and they are discussing their effectiveness in blogs and forums. In this pilot study we will use Natural Language Processing (NLP) and human expertise to examine over 50,000 recent posts in two Reddit forums OpiatesRecovery and Opiates to assess systematically which remedies are being used, how they are being used, and what are the reported consequences of such self-help experimentation. We will create a curated database of user-reported “remedies.” Information will be semiautomatically extracted from the online, self-reported use of alternative treatments (i.e., other prescription drugs, over the counter medications, food supplements, activities such as meditation and yoga). A team of a pharmacologist, physician, and ethnographer will evaluate database entries to uncover (1) potential harm associated with uncontrolled and unsupervised experimentation, (2) potentially effective available treatments (e.g., traditional medicine), (3) potentially promising compound leads, and (4) patients' needs and issues that are most important to them. Aim 1. To assemble an extensive database of opioid withdrawal and remedy-associated terminology from posts on OpiatesRecovery and Opiates Reddit communities. NLP will be used to build a language model that understands how words are used in context (word2vec). Aim 2. To develop a dataset of instances of self-reported remedy use from Reddit and conduct a bipartite network analysis of remedies and users. Using NLP tools and the word embedding model we will develop an exclusive dataset containing extracted information associated with remedies targeting withdrawal and craving. This aim will use elements of artificial intelligence and close human supervision to extract remedies, including variations of spelling, from the texts. The result of this aim will be a remedy database that includes spelling variations and slang references and a network analysis linking remedies and users. Aim 3. To organize, aggregate, and systematically assess information from mentions of remedy use. Potential compounds and other remedies will be classified to provide an initial assessment of their potential relevance to the opioid treatment process. This process will require the most human oversight and assessment. Network analysis tools will be used to assess and identify the relationships between the types of remedies and potential therapeutic effect and will create the benchmarks for similar future studies. PROJECT NARRATIVE Withdrawal symptoms from opioid use can be severe and are major contributing factors to relapse and continuing misuse. Many opioid users are actively experimenting with “remedies” that can alleviate withdrawal, and they are discussing their effectiveness in blogs and forums. In this pilot study we will use Natural Language Processing and human expertise to examine over 50,000 recent posts in two Reddit forums— OpiatesRecovery and Opiates—to assess systematically which remedies are being used, how they are being used, and what are the reported consequences of such self-help experimentation.",Online Evidence of Withdrawal Self-Medication,9786868,R21DA048739,"['Acupuncture Therapy', 'Adult', 'Artificial Intelligence', 'Automation', 'Belief', 'Benchmarking', 'Categories', 'Cluster Analysis', 'Collaborations', 'Communities', 'Data', 'Data Set', 'Databases', 'Drug Prescriptions', 'Effectiveness', 'Elements', 'Epidemiologist', 'Epidemiology', 'Food', 'Food Additives', 'Food Supplements', 'Future', 'Habits', 'Harm Reduction', 'Herb', 'Herbal Medicine', 'Human', 'Knowledge', 'Language', 'Life', 'Link', 'Marijuana', 'Medical', 'Meditation', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Prescription Drugs', 'Opioid', 'Opioid user', 'Pathway Analysis', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Pilot Projects', 'Process', 'Published Comment', 'Relapse', 'Reporting', 'Research', 'Resources', 'Self Medication', 'Supervision', 'Terminology', 'Text', 'Therapeutic Effect', 'Traditional Medicine', 'Twitter', 'United States Food and Drug Administration', 'Variant', 'Vitamins', 'Withdrawal', 'Withdrawal Symptom', 'Yoga', 'alternative treatment', 'cost', 'craving', 'dietary supplements', 'epidemiology study', 'experience', 'experimental study', 'interest', 'non-opioid analgesic', 'novel', 'off-label drug', 'off-label use', 'online community', 'opioid misuse', 'opioid use', 'opioid withdrawal', 'patient population', 'self help', 'social media', 'spelling', 'tool', 'trend']",NIDA,RESEARCH TRIANGLE INSTITUTE,R21,2019,228384,-0.00383024178513564
"Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings Project Summary (Abstract) With little change in incidence for over 50 years, pneumonia remains the top cause for morbid hospitalization1 in the USA, and is associated with healthcare costs exceeding $10 billion annually2. This study proposes to mine big data captured in an intergrated medical/dental record (iEHR) and enterprise data warehouse (EDW) of a large midwestern medical-dental integrated healthcare system and will test the hypothesis that poor oral health is an independent risk for subtypes of community-acquired and hospital-acquired pneumonia. Proposed specific aims include: 1) electronic identification and characterization of pneumonia types and 2) evaluation of the association of oral health status with risk of pneumonia. Tasks to achieve study aims are to: a) develop electronic, phenotype-based algorithm(s) to classify and characterize pneumonia by subtype and relative frequency of events; b) characterize impact of immediate and longitudinal oral health status on emergent pneumonia stratified by subtype; and c) evaluate relative risk contributed by medical and dental factors. Innovative application of natural language processing (NLP) to support evaluation of unstructured data and machine learning (ML) to identify as-yet unknown potential risk factors is proposed. These aims will be accomplished by established investigators including dentists and researchers with extensive research track records in oral and systemic health including pneumonia, clinical pulmonologist/intensivist to provide clinical expertise to inform data mining, biomedical informaticians with expertise in data mining, ML and NLP and data modeling, and experienced biostatisticians who will apply appropriate statistical approaches and traditional data modeling to big data. This team will collaboratively create and deliver a unique, well-defined, pneumonia- specific, oral health data registry resource and validated phenotype-based algorithm to classify pneumonia, stratified by subtypes, which will support future interrogation for additional permutations of medical and dental factors. Study outcomes are expected to leverage immediate translational value within the health system with high potential for relevance and portability to other settings. The project is expected to define risk factors which may represent actionable targets for reduction of pneumonia risk across various settings. Project Narrative- Relevance to public health: Pneumonia continues as a leading public health problem in hospitals, healthcare facilities and community settings. Pneumonia is the top disease-related cause for hospitalization. This study proposes to use data in electronic health records to classify pneumonia type and describe risk factors that may make individual susceptible to different types of pneumonia, including impact of diseases of the mouth, gums and teeth. The project expects to create models that can identify patients at risk for pneumonia based on information in their medical record so that those risks may be recognized and reduced.",Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings,9784789,R03DE027020,"['Address', 'Adoption', 'Adult', 'Affect', 'Age', 'Algorithms', 'Antibiotic Resistance', 'Aspiration Pneumonia', 'Big Data', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic', 'Classification', 'Climate', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Comorbidity', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Dental', 'Dental Care', 'Dental Hygiene', 'Dental Records', 'Dentists', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Electronic Health Record', 'Environmental Risk Factor', 'Evaluation', 'Event', 'Frequencies', 'Future', 'General Hospitals', 'Health', 'Health Care Costs', 'Health Status', 'Health care facility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Inpatients', 'Integrated Health Care Systems', 'Intervention Studies', 'Investigation', 'Knowledge', 'Laboratories', 'Link', 'Logic', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Care Costs', 'Medical Records', 'Modeling', 'Mouth Diseases', 'Natural Language Processing', 'Nosocomial pneumonia', 'Oral', 'Oral health', 'Outcome Study', 'Outpatients', 'Pathogenesis', 'Patients', 'Periodontitis', 'Pharmaceutical Preparations', 'Phenotype', 'Pneumococcal vaccine', 'Pneumonia', 'Population Study', 'Prevalence', 'Prevention', 'Public Health', 'Pulmonology', 'Recording of previous events', 'Records', 'Recurrence', 'Relative Risks', 'Research', 'Research Institute', 'Research Personnel', 'Resolution', 'Resources', 'Respiratory Signs and Symptoms', 'Retrospective cohort', 'Risk', 'Risk Factors', 'Role', 'Scoring Method', 'Site', 'Smoking', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tooth structure', 'Translational Research', 'Update', 'Ventilator', 'Visit', 'base', 'burden of illness', 'case finding', 'clinically relevant', 'community setting', 'cost', 'data mining', 'data modeling', 'data registry', 'data warehouse', 'demographics', 'experience', 'follow-up', 'health care delivery', 'health record', 'healthcare community', 'high risk', 'innovation', 'member', 'mortality risk', 'novel', 'outreach', 'patient population', 'patient screening', 'pneumonia model', 'portability', 'secondary analysis', 'systems research', 'ventilator-associated pneumonia']",NIDCR,MARSHFIELD CLINIC RESEARCH FOUNDATION,R03,2019,159914,-0.0011096786881689886
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that “big data” clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9782996,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'comparative effectiveness', 'cost', 'deep learning', 'diagnosis standard', 'effectiveness research', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'informatics\xa0tool', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2019,348107,0.0186095705833408
"Prediction of Clinical Deterioration Using a Bayesian Belief System Project Summary/Abstract Approximately 5-10% of hospitalized patients suffer significant clinical deterioration after admission, resulting in either transfer to the intensive care unit (ICU) or a ""code"" event (i.e., cardiac or pulmonary arrest). Delayed identification of these events result in increased morbidity and mortality. Unfortunately, existing prediction models result in multiple false alarms for every true positive alarm that they generate. In addition with every passing year, new monitoring systems are introduced that generate more false alarms, resulting in alarm fatigue which has been associated with patient deaths. The objective of this mentored career development proposal is to develop and assess novel computational algorithms that can predict the clinical deterioration of hospitalized patients earlier and more accurately than clinicians or conventional early warning systems, thereby allowing for timely intervention. Building upon our experience in the hematologic malignancy subpopulation of hospitalized patients, this new effort: 1) provides a foundation upon which to combine newer machine learning (ML) methods and clinical informatics to improve the capabilities of the model for an individual patient or specific subgroup; 2) assesses the impact and value of different variables from the electronic medical record (EMR) as part of the predictive model; and 3) broadens the evaluation of this approach to additional real-world patient populations, enabling insight into the translation of the models to clinical usage. The specific aims of this project are thus: Specific Aims Aim 1 To identify and extract model variables (features) from the EMR, evaluating different feature selection  methods to optimize different predictive criterion and their impact on ML algorithms. Aim 2 To develop an ML approach that handles multiple asynchronous data streams of longitudinal  information from the EMR, providing predictions on clinical deterioration in real-time. Aim 3 To explore clinician and rapid response team responses to early prediction of clinical deterioration. With successful completion of this proposal, the prediction model will be integrated into the EMR system. Future direction as part of a R01 proposal will involve external validation at other institutions and assessment of clinical impact on patient care. Relevance to Public Health Clinical deterioration in the hospital is often unexpected and is associated with increased mortality and morbidity, with the CDC reporting 17.2 million hospital admissions through the emergency department in 2010 suggesting that approximately 1 million people annually are at risk of clinical deterioration during their hospitalization. Existing early warning systems have not been able to accurately predict these events without creating an overwhelming amount of additional false positive alarms, resulting in alarm fatigue and potential harm. Our project, utilizing machine learning techniques with the large amount of available clinical data, will serve to develop a predictive model that can predict clinical deterioration earlier with a higher positive predictive value than current algorithms/models which, when implemented, will be able to provide hospitalized patients with an additional safety net.",Prediction of Clinical Deterioration Using a Bayesian Belief System,9768542,K01LM012873,"['Accident and Emergency department', 'Admission activity', 'Algorithms', 'Belief System', 'Cardiac', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical assessments', 'Code', 'Computational algorithm', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Set', 'Deterioration', 'Discipline of Nursing', 'Ensure', 'Evaluation', 'Event', 'Fatigue', 'Foundations', 'Future', 'Genes', 'Health Personnel', 'Heart Arrest', 'Hematologic Neoplasms', 'Hospitalization', 'Hospitals', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'Learning', 'Lung', 'Machine Learning', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Nature', 'Patient Care', 'Patients', 'Performance', 'Population', 'Predictive Value', 'Public Health', 'Reporting', 'Research', 'Risk', 'Science', 'Specificity', 'Stream', 'Subgroup', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translating', 'Translations', 'United Kingdom', 'United States', 'Validation', 'Work', 'Workload', 'base', 'biomedical informatics', 'burnout', 'career development', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinical predictors', 'clinical risk', 'cohort', 'computer science', 'experience', 'improved', 'individual patient', 'insight', 'learning strategy', 'machine learning algorithm', 'mental state', 'mortality', 'novel', 'patient population', 'predictive modeling', 'prevent', 'response', 'safety net', 'skills']",NLM,UNIVERSITY OF CALIFORNIA LOS ANGELES,K01,2019,205524,0.0012517661415633646
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9749151,K01ES026833,"['Acute', 'Affect', 'Blood', 'Blood flow', 'Brain', 'Brain Injuries', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Healthcare', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Ruptured Aneurysm', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision support', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'public health relevance', 'standard of care', 'support tools', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2019,216241,0.01175148854163092
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9607596,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Big Data Methods', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,762619,0.02441992669557586
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9670145,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'medication safety', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke therapy', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2019,163080,0.002689841670606051
"Epidemiology and clinical outcomes of diabetic macular edema Approximately 25% of the millions of veterans (est. 8.92 million FY 2013) enrolled for care in Veterans Health Administration (VHA) have diabetes mellitus, and diabetic macular edema (DME) is the leading cause of vision loss in the adult diabetic population world-wide. Although diabetic retinopathy has been well-studied, comparatively little is known about the burden of DME. In fact, only two national prevalence studies and no national study on the incidence of DME in persons with type 2 diabetes have been conducted. Similarly many risk factors have been characterized for DR, but no large studies have established predictors for DME.  Beyond the Medicare claims database, the VHA National Patient Care Database (NPCD) contains standardized administrative data for several aspects of patient care including diagnoses, procedures, medications, lab test results, vital signs, clinical text notes, and mortality. Because the VA uses teleretinal screening as routine clinical care for all patients with diabetes with these results included in the NPCD, the NPCD is an ideal source for studying the epidemiology of and risk factors for DME.  This study proposes to determine the burden of diabetic macular edema, establish risk factors, and examine treatment outcomes in a previously extracted dataset on 1.98 million veterans who have undergone diabetic retinopathy screening at least once since 2004. Currently invaluable ophthalmic data are encoded in unstructured clinical encounter notes in the Computerized Patient Record System (CPRS), and no validated automated extraction method exists to capture these data elements. An automated extraction method using natural language processing will be created and validated to unlock key ophthalmic variables. These text extraction methods will be applicable to extracting ophthalmology data from not only notes of patients with DME but also any ophthalmology clinical note. This will enable future large scale studies in ophthalmology using NPCD and be immediately valuable to the research community at large.  The candidate, Dr. Aaron Lee, MD MSCI, is an ophthalmologist with subspecialty training in retina surgery with a strong background in computer science and epidemiology. His career goal is to become an independent clinician scientist studying diabetic eye disease with large-scale electronic medical record extracted data. While he possesses the foundational skills, he seeks to gain training in advanced statistics and natural language processing to unlock the data captured in unstructured clinical encounter notes. He has assembled an outstanding mentorship team under the primary mentor, Dr. Edward Boyko, MD MPH. This mentorship team includes renowned experts in clinical epidemiology, health informatics, ophthalmology, and natural language processing. This K23 will provide Dr. Lee the structured coursework, mentorship, and applied learning needed to acquire new research skills. He will leverage key local resources to carry out the proposed research at the University of Washington and the VA Seattle Epidemiologic Research and Information Center. Despite the significant visual loss associated with diabetic macular edema, little is known about the frequency of its occurrence, its risk factors, and the real-world effectiveness of existing treatments. The purpose of this proposed research is to utilize the VA National Patient Care Database to extract relevant data elements to examine these three clinical questions: 1) what is the incidence and prevalence of diabetic macular edema, 2) what are the risk factors associated with its development, and 3) what is the comparative real-world effectiveness of its treatments, including intravitreal anti-VEGF therapy, intravitreal corticosteroid therapy and macular laser. The methods developed in this research proposal will not only further our understanding of DME but also generalize and enable future large-scale ophthalmic studies.",Epidemiology and clinical outcomes of diabetic macular edema,9756410,K23EY029246,"['Adopted', 'Adrenal Cortex Hormones', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anemia', 'Blindness', 'Cardiovascular Diseases', 'Caring', 'Cataract Extraction', 'Clinic', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Computerized Medical Record', 'Computerized Patient Records', 'Data', 'Data Element', 'Data Set', 'Databases', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Dyslipidemias', 'Effectiveness', 'Enrollment', 'Epidemiology', 'Ethnic Origin', 'Exclusion Criteria', 'Expressed Sequence Tags', 'Eye', 'Eye diseases', 'Foundational Skills', 'Frequencies', 'Future', 'Goals', 'Handedness', 'Hypertension', 'Incidence', 'Information Centers', 'Injections', 'Intervention', 'Lasers', 'Lead', 'Light Coagulation', 'Manuals', 'Masks', 'Measures', 'Medicare claim', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Operative Surgical Procedures', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Prediction of Response to Therapy', 'Prevalence', 'Prevalence Study', 'Procedures', 'Protocols documentation', 'Public Health Informatics', 'Randomized Controlled Trials', 'Regimen', 'Research', 'Research Proposals', 'Resources', 'Retina', 'Retinal', 'Risk Factors', 'Scientist', 'Severities', 'Sleep Apnea Syndromes', 'Smoking Status', 'Source', 'Standardization', 'Structure', 'System', 'Test Result', 'Text', 'Time', 'Training', 'Treatment Protocols', 'Treatment outcome', 'Universities', 'Use Effectiveness', 'Validation', 'Vascular Endothelial Growth Factors', 'Veterans', 'Visual', 'Visual Acuity', 'Washington', 'bevacizumab', 'career', 'clinical care', 'clinical epidemiology', 'cohort', 'comparative', 'computer science', 'diabetes management', 'diabetic', 'epidemiology study', 'hands-on learning', 'health administration', 'intravitreal injection', 'kidney dysfunction', 'laser photocoagulation', 'macula', 'macular edema', 'mortality', 'proliferative diabetic retinopathy', 'screening', 'skills', 'statistics', 'therapy outcome', 'traditional therapy', 'treatment optimization']",NEI,UNIVERSITY OF WASHINGTON,K23,2019,233078,0.020022855794244367
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9665255,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease Surveillance', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Infrastructure', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,461012,0.023106330451196283
"Collaborative Research: Statistical algorithms for anomaly  detection and patterns recognition in patient care and safety event reports     Medical errors have been shown to be the third leading cause of death in the United States. The Institute of Medicine and several state legislatures have recommended the use of patient safety event reporting systems (PSRS) to better understand and improve safety hazards. Numerous healthcare providers have adopted these systems, which provide a framework for healthcare provlder staff to report patient safety events. Public databases like MAUDE and VAERS have also been created to collect and trend safety events across healthcare systems. A patient safety event (PSE) report generally consists of both structured and unstructured data elements. Structured data are pre-defined, fixed fields that solicit specific information about the event. The unstructured data fields generally include a free text field where the reporter can enter a text description of the event. The text descriptions are often a rich data source in that the reporter ls not constrained to limited categories or selection options and is able to freely descrlbe the details of the event. The goal of this project is to develop novel statistical methods to analyze unstructured text like patient safety event reports arising in healthcare, which can lead to significant improvements to patient safety and enable timely intervention strategies. We address three problems: (a) Building realistic and meaningful baseline models for near misses, and detecting systematic deterioration of adverse outcomes relative to such baselines; (b) Understanding critical factors that lead to near misses & quantifying severity of outcomes; and (c) ldentifylng document groups of interest. We will use novel statistical approaches that combine Natural Language Processing with Statistical Process Monitoring, Statistical Networks Analysis, and Spatio-temporal Modeling to build a generalizable toolbox that can address these issues in healthcare. An important advantage of our research team is the involvement of healthcare domain experts and access to frontline staff, and we will leverage this strength to develop our algorithms. A key feature of our work is the generalizability of our methods, which will be applicable to biomedical documents arising across a remarkable variety of areas, such as patient safety and equipment malfunction reports, electronic health records, adverse drug or vaccine reports, etc. We will also release open source software via R packages & GitHub, which will enable healthcare staff and researchers to execute our methods on their datasets. Estimates of preventable adverse events in healthcare are staggering, despite the frequently cited Institute of Medicine (IOM) report that first brought attention to the problem over ten years ago. Identifying temporal trends and patterns in the data is particularly important to improving patient safety and patient care. Using our algorithms to effectively analyze documents from reporting systems has the potential to dramatically improve the safety and quality of care by exposing possible weaknesses in the care process.",Collaborative Research: Statistical algorithms for anomaly  detection and patterns recognition in patient care and safety event reports    ,9914443,R01LM013309,"['Address', 'Adopted', 'Adverse event', 'Algorithms', 'Area', 'Attention', 'Caring', 'Categories', 'Cause of Death', 'Computer software', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Deterioration', 'Electronic Health Record', 'Equipment Malfunction', 'Event', 'Goals', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Institute of Medicine (U.S.)', 'Instruction', 'Interest Group', 'Intervention', 'Lead', 'Medical Errors', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Process', 'Quality of Care', 'Report (document)', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Statistical Algorithm', 'Statistical Computing', 'Statistical Methods', 'Structure', 'System', 'Text', 'Time', 'Time trend', 'United States', 'Vaccines', 'Work', 'adverse outcome', 'hazard', 'improved', 'novel', 'open source', 'patient safety', 'spatiotemporal', 'trend']",NLM,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2019,279001,0.01142592337127292
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9615037,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Source', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'population based', 'prevent', 'sociodemographics', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2019,784820,0.02746559174005015
"Improving Adverse Event Reporting on Cooperative Oncology Group Trials PROJECT SUMMARY/ABSTRACT Background: The reports of side effects on clinical trials describe expected toxicities of chemotherapy. However, these side effects, also called adverse events, are globally under-reported on trials, which means that clinicians do not have an accurate sense of adverse event rates. In the current system, adverse events are identified through time-consuming, manual medical record review. This study aims to develop a system that uses electronic medical record data to capture complex adverse events of chemotherapy for pediatric cancer and to prove that this method is more accurate than the current adverse event reporting system. The specific aims of this application are to 1) develop algorithms to identify 10 complex adverse events using electronic medical record data from children treated for acute leukemia at two large children's hospitals, 2) compare the accuracy of this new method to that of the current system, and 3) demonstrate the utility of electronic adverse event capture in answering clinical questions by defining the incidence and risk factors of acute kidney injury. Methods: This study will use data from 1900 children with acute leukemia treated at the Children's Hospital of Philadelphia (CHOP) or the Texas Children's Hospital (TCH) from 2002 through 2017. Algorithms will be developed to identify adverse events by extracting electronic medical record data at CHOP. Once finalized, the algorithms will be tested at TCH. Using chart abstraction data as the gold standard, the accuracy of electronic ascertainment and of trial adverse event reports will determined, and the relative accuracy of each method will be compared. Lastly, algorithms will extract creatinine results from the electronic medical record and the incidence of acute kidney injury will be determined for each leukemia type and by chemotherapy regimen. Risk factors for acute kidney injury will be explored. Career Goals and Environment: With the support of this K07 award, the applicant, Tamara P. Miller, MD, MSCE, will learn how to use electronic medical record data for clinical research, obtain formal training in clinical informatics and implementation science, develop expertise in clinical trial design, and improve her knowledge of pediatric oncology and skills in scientific writing. To complete these training goals, Dr. Miller has assembled an experienced, complementary, and nurturing mentoring team led by her primary mentor, Richard Aplenc, MD, PhD. Her training plan includes formal coursework in informatics, tutorials, national conferences, and research progress and writing groups. She will benefit from the outstanding depth of resources and opportunities at CHOP and the University of Pennsylvania. Her long-term goal is to integrate the novel system of adverse event ascertainment she creates into pediatric oncology trials and to use the accurate datasets she develops to answer clinically important questions. With this award, Dr. Miller will be well-positioned to transition to her goal of an independent clinical research career focused on improving adverse event reporting and supportive care practices in pediatric oncology. PROJECT NARRATIVE Children with cancer experience significant side effects from their treatments, but these side effects are under- reported on clinical trials and no work has been done to improve the current system of side effect reporting. This study will create a new system of identifying and reporting side effects that is more accurate and efficient than the current system. The results of this research will provide clinicians, patients and their families with a true understanding of potential side effects of therapies used to treat childhood cancer.",Improving Adverse Event Reporting on Cooperative Oncology Group Trials,9762876,K07CA211956,"['Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute leukemia', 'Adverse event', 'Age', 'Algorithms', 'Award', 'Chemotherapy-Oncologic Procedure', 'Child', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Design', 'Common Terminology Criteria for Adverse Events', 'Complex', 'Computerized Medical Record', 'Consumption', 'Creatinine', 'Data', 'Data Set', 'Doctor of Philosophy', 'Enrollment', 'Environment', 'Ethnic Origin', 'Family', 'Foundations', 'Gender', 'Goals', 'Gold', 'Hospitals', 'Incidence', 'Informatics', 'Knowledge', 'Laboratories', 'Learning', 'Malignant Childhood Neoplasm', 'Manuals', 'Medical Records', 'Mentors', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Oncology Group', 'Patients', 'Pediatric Hospitals', 'Pediatric Oncology', 'Pediatric Oncology Group', 'Pennsylvania', 'Pharmaceutical Preparations', 'Philadelphia', 'Positioning Attribute', 'Predictive Value', 'Process', 'Publishing', 'Race', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Safety', 'Sensitivity and Specificity', 'Supportive care', 'System', 'Testing', 'Texas', 'Text', 'Time', 'Toxicity due to chemotherapy', 'Training', 'Treatment Side Effects', 'Universities', 'Work', 'Writing', 'base', 'cancer therapy', 'career', 'chemotherapy', 'clinical decision-making', 'clinical epidemiology', 'clinical implementation', 'cohort', 'data pipeline', 'epidemiology study', 'experience', 'implementation science', 'improved', 'leukemia', 'nephrotoxicity', 'novel', 'oncology trial', 'prospective', 'secondary analysis', 'side effect', 'skills', 'statistics', 'symposium']",NCI,EMORY UNIVERSITY,K07,2019,168764,0.025370477919629576
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions. PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.",Natural language processing for characterizing psychopathology,9445485,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Clinical stratification', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Risk stratification', 'Severities', 'Structure', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinical risk', 'clinically relevant', 'cohort', 'cost', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'patient subsets', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'readmission risk', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'translational scientist', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,376490,-0.009011882347124934
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9579181,R01LM012918,"['Adult', 'Adverse drug event', 'Adverse effects', 'Algorithms', 'Apache', 'Area', 'Biological Neural Networks', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'Supervision', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'base', 'case finding', 'improved', 'learning strategy', 'malignant breast neoplasm', 'method development', 'natural language', 'new technology', 'news', 'novel', 'open source', 'point of care', 'social media', 'software systems', 'statistics', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2018,416066,0.031313564422697386
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this ﬁeld typically produce an “all-cause” risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest – at best – reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiﬁable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classiﬁcation models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signiﬁcantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identiﬁcation and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9505570,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Comorbidity', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patient risk', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'collaborative environment', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'skills', 'social', 'trend', 'trial design']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2018,195205,-0.004113318670624387
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9670540,R01LM012817,"['AIDS education', 'Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Comorbidity', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,370291,-0.0056828398690122895
"Improving Specialty Care Delivery in the Safety Net with Natural Language Processing Project Summary  Safety net providers treat a substantial share of socioeconomically vulnerable patients in their communities, but struggle to provide timely access to high quality specialty care for their patients. Delayed access to specialty care is associated with worse health outcomes and potentially contributes to health disparities across socioeconomic groups. Given their limited resources, safety net providers must seek creative approaches to improve specialty access. However, to choose what programs to implement, safety net providers need to understand the specialty care needs of their populations. Fortunately, the adoption of eConsult systems by safety net providers across the US provides a valuable opportunity to systematically measure patterns of specialty care referrals for minority, underserved populations.  In this project, we propose using state-of-the-art methods in machine learning and natural language processing (NLP) to help safety net providers extract actionable, population wide data from their electronic consultation systems. We will do this in partnership with three of the most prominent safety net health systems in the US in Los Angeles, San Francisco and New York City. Using specialty request databases from our collaborators, we will build NLP systems to automatically classify specialty requests along two dimensions: the “clinical issue” motivating the request (e.g., chest pain), and the “question type” (e.g., request for a procedure, help with medication management). This automated classification of electronic specialty requests can enable identification of promising targets for interventions to improve specialty access and quality of care.  After developing these NLP systems, we will analyze >1 million specialty requests to describe trends in how safety net patients are referred to specialists and examine variation in referral patterns by clinic and individual provider. The goal is to identify the most impactful opportunities to improve specialty access and quality. For example, a high rate of referrals for esophageal reflux, which most PCPs can treat on their own with specialist guidance, could lead to new treatment algorithms, potentially reducing the need for these requests and improving access for other patients.  This proposal is a “high-risk high-reward” project that creates new research tools to identify and evaluate data-driven interventions to improve specialty care delivery for underserved populations. Project Narrative Access to timely, high-quality specialty care is a fundamental component of a well-functioning health system, yet safety net health care providers face persistent challenges delivering such care. Quality improvement efforts to improve specialty access have been thwarted in part because safety net providers lack the data to understand a basic question – why patients are referred for specialty care. Taking advantage of the growing use of electronic specialty referral systems by safety net providers, we propose using natural language processing to conduct automated analysis and classification of specialty requests in safety net populations, which will enable the design of targeted interventions to improve specialty care access and delivery.",Improving Specialty Care Delivery in the Safety Net with Natural Language Processing,9600732,R21MD012693,"['Acute', 'Adopted', 'Adoption', 'Algorithms', 'Caring', 'Chest Pain', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Communities', 'Consultations', 'County', 'Data', 'Data Set', 'Databases', 'Education', 'Epidemiology', 'Face', 'Federally Qualified Health Center', 'Gastroesophageal reflux disease', 'Goals', 'Health', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Heart failure', 'Hospitals', 'Improve Access', 'Individual', 'Intervention', 'Lead', 'Los Angeles', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Education', 'Medical center', 'Medication Management', 'Methods', 'Minority', 'Morbidity - disease rate', 'Natural Language Processing', 'New York City', 'Online Systems', 'Ophthalmology', 'Outcome', 'Patients', 'Pattern', 'Play', 'Population', 'Primary Care Physician', 'Procedures', 'Provider', 'Public Hospitals', 'Quality of Care', 'Research', 'Resources', 'Retinal Diseases', 'Role', 'San Francisco', 'Specialist', 'System', 'Taxonomy', 'Telemedicine', 'Text', 'Time', 'Transplantation', 'Triage', 'Underserved Population', 'Variant', 'Visit', 'care delivery', 'design', 'diabetic', 'disease classification', 'ethnic minority population', 'follow-up', 'health disparity', 'high reward', 'high risk', 'improved', 'medical specialties', 'medically underserved', 'minority communities', 'mortality', 'performance tests', 'programs', 'racial and ethnic', 'safety net', 'screening', 'socioeconomic disadvantage', 'socioeconomics', 'tool', 'trend', 'two-dimensional']",NIMHD,BOSTON CHILDREN'S HOSPITAL,R21,2018,278902,0.019019594168846715
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9547946,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2018,1542081,0.010548166935647536
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9534183,R01LM011934,"['Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'information model', 'novel', 'open source', 'profiles in patients', 'public health relevance', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2018,387966,0.04577050537011789
"Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance PROJECT SUMMARY The Center for Medicare and Medicaid Services Quality Payment Program is designed to motivate healthcare providers to adhere to best practices in clinical healthcare and patient safety. Unfortunately, extracting quality measures data from the clinical record is burdensome and as such, participation among clinical healthcare providers is suboptimal. Our aim is to develop a system to facilitate automatic extraction of quality data. This will reduce the burden of data collection and help remove the barrier to participation that keeps more providers from participating in the program. The proposed project, titled “Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance”, aims to develop novel natural language processing methods to recognize key elements from the clinical notes to enable proper documentation of meaningful use and compliance with quality payment. We envision this to be an effective research partnership that leverages the complementary assets of SaferMD, a small business unit, and the University of Michigan, a non-profit research institution, to develop and evaluate a prototype tool to extract clinical quality measures data, and increase participation in the Quality Payment Program. PROJECT NARRATIVE The proposed project, titled “Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance”, aims to develop novel natural language processing methods to recognize key elements from the clinical notes to enable proper documentation of meaningful use and compliance with quality payment. The project will develop algorithms to identify fields relevant for quality measures and develop tools to extract and analyze these data elements from large sets of radiology reports. Finally, the proposed work will initiate the extracted measures into existing quality service offerings by SaferMD. Successful completion of this project will advance the tools available for CMS clients to achieve higher adherence and compliance to the quality payment initiatives and help public health officials and policy developers advance the meaningful use of electronic health records.",Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance,9677579,R41LM013050,"['Address', 'Adherence', 'Algorithms', 'Benchmarking', 'Businesses', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Data', 'Data Collection', 'Data Element', 'Data Quality', 'Development', 'Disease', 'Documentation', 'Electronic Health Record', 'Elements', 'Experimental Models', 'Funding', 'Goals', 'Guidelines', 'Health Personnel', 'Healthcare', 'Human', 'Incentives', 'Institution', 'Label', 'Leadership', 'Manuals', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Neural Network Simulation', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Policies', 'Procedures', 'Process', 'Production', 'Provider', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Role', 'Running', 'Semantics', 'Services', 'System', 'Techniques', 'Technology', 'Telephone', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Work', 'analytical tool', 'base', 'clinical practice', 'clinically relevant', 'computerized data processing', 'dashboard', 'deep neural network', 'design', 'improved', 'interest', 'novel', 'novel strategies', 'patient safety', 'payment', 'programs', 'prototype', 'success', 'technological innovation', 'tool']",NLM,"SAFERMED, LLC",R41,2018,149953,0.0021008387166237662
"Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings Project Summary (Abstract) With little change in incidence for over 50 years, pneumonia remains the top cause for morbid hospitalization1 in the USA, and is associated with healthcare costs exceeding $10 billion annually2. This study proposes to mine big data captured in an intergrated medical/dental record (iEHR) and enterprise data warehouse (EDW) of a large midwestern medical-dental integrated healthcare system and will test the hypothesis that poor oral health is an independent risk for subtypes of community-acquired and hospital-acquired pneumonia. Proposed specific aims include: 1) electronic identification and characterization of pneumonia types and 2) evaluation of the association of oral health status with risk of pneumonia. Tasks to achieve study aims are to: a) develop electronic, phenotype-based algorithm(s) to classify and characterize pneumonia by subtype and relative frequency of events; b) characterize impact of immediate and longitudinal oral health status on emergent pneumonia stratified by subtype; and c) evaluate relative risk contributed by medical and dental factors. Innovative application of natural language processing (NLP) to support evaluation of unstructured data and machine learning (ML) to identify as-yet unknown potential risk factors is proposed. These aims will be accomplished by established investigators including dentists and researchers with extensive research track records in oral and systemic health including pneumonia, clinical pulmonologist/intensivist to provide clinical expertise to inform data mining, biomedical informaticians with expertise in data mining, ML and NLP and data modeling, and experienced biostatisticians who will apply appropriate statistical approaches and traditional data modeling to big data. This team will collaboratively create and deliver a unique, well-defined, pneumonia- specific, oral health data registry resource and validated phenotype-based algorithm to classify pneumonia, stratified by subtypes, which will support future interrogation for additional permutations of medical and dental factors. Study outcomes are expected to leverage immediate translational value within the health system with high potential for relevance and portability to other settings. The project is expected to define risk factors which may represent actionable targets for reduction of pneumonia risk across various settings. Project Narrative- Relevance to public health: Pneumonia continues as a leading public health problem in hospitals, healthcare facilities and community settings. Pneumonia is the top disease-related cause for hospitalization. This study proposes to use data in electronic health records to classify pneumonia type and describe risk factors that may make individual susceptible to different types of pneumonia, including impact of diseases of the mouth, gums and teeth. The project expects to create models that can identify patients at risk for pneumonia based on information in their medical record so that those risks may be recognized and reduced.",Secondary Analysis of EHR Data to Examine Relative Impact of Oral Health History on Incident Pneumonia by Settings,9599192,R03DE027020,"['Address', 'Adoption', 'Adult', 'Affect', 'Age', 'Algorithms', 'Antibiotic Resistance', 'Aspiration Pneumonia', 'Big Data', 'Caring', 'Cessation of life', 'Characteristics', 'Chronic', 'Classification', 'Climate', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Comorbidity', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Dental', 'Dental Care', 'Dental Hygiene', 'Dental Records', 'Dentists', 'Detection', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disease', 'Electronic Health Record', 'Environmental Risk Factor', 'Evaluation', 'Event', 'Frequencies', 'Future', 'General Hospitals', 'Health', 'Health Care Costs', 'Health Status', 'Health care facility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Inpatients', 'Integrated Health Care Systems', 'Intervention Studies', 'Investigation', 'Knowledge', 'Laboratories', 'Link', 'Logic', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Care Costs', 'Medical Records', 'Modeling', 'Mouth Diseases', 'Natural Language Processing', 'Nosocomial pneumonia', 'Oral', 'Oral health', 'Outcome Study', 'Outpatients', 'Pathogenesis', 'Patients', 'Periodontitis', 'Pharmaceutical Preparations', 'Phenotype', 'Pneumococcal vaccine', 'Pneumonia', 'Population Study', 'Prevalence', 'Prevention', 'Public Health', 'Pulmonology', 'Recording of previous events', 'Records', 'Recurrence', 'Relative Risks', 'Research', 'Research Institute', 'Research Personnel', 'Resolution', 'Resources', 'Respiratory Signs and Symptoms', 'Retrospective cohort', 'Risk', 'Risk Factors', 'Role', 'Scoring Method', 'Site', 'Smoking', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tooth structure', 'Translational Research', 'Update', 'Ventilator', 'Visit', 'base', 'burden of illness', 'case finding', 'clinically relevant', 'community setting', 'cost', 'data mining', 'data modeling', 'data registry', 'data warehouse', 'demographics', 'experience', 'follow-up', 'health care delivery', 'health record', 'healthcare community', 'high risk', 'innovation', 'member', 'mortality', 'novel', 'outreach', 'patient population', 'patient screening', 'pneumonia model', 'portability', 'secondary analysis', 'systems research', 'ventilator-associated pneumonia']",NIDCR,MARSHFIELD CLINIC RESEARCH FOUNDATION,R03,2018,174917,-0.0011096786881689886
"Identification of Patients with Low Life Expectancy ﻿    DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9481256,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2018,227899,0.04629143652052455
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that “big data” clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9640372,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'comparative effectiveness', 'cost', 'deep learning', 'diagnosis standard', 'effectiveness research', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2018,347584,0.0186095705833408
NIST Assistance with NTP SR Automation NIEHS seeks advice from NIST in the areas of human language technology and natural language processing component evaluations that support the measurement of systems that automatically extract toxicology information from publications to support the complex human task of systematic review of literature. NIST is positioned to assist NIEHS building upon existing test and evaluation infrastructure through its Text Analysis Conference (TAC) program. NIST is coordinating the 2019 Systematic Review Information Extraction evaluation (SRIE 2019) task for NIEHS as part of the Retrieval Group’s Text Analysis Conference (TAC) program. This coordination includes advising NIEHS on developing annotation guidelines; advising NIEHS on dataset construction and distribution; writing guidelines for the evaluation task; developing scoring methods and supporting software; including the evaluation task as part of the TAC program and call for participation; accepting participant submissions in the evaluation; evaluating those submissions; and reporting results of the evaluation. NIST and NIH will design an evaluation task in this domain. n/a,NIST Assistance with NTP SR Automation,9794240,ES18001002,"['Advertisements', 'Area', 'Automation', 'Complex', 'Computer software', 'Data Set', 'Development', 'Evaluation', 'Guidelines', 'Human', 'Language', 'Measurement', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Participant', 'Positioning Attribute', 'Preparation', 'Publications', 'Reporting', 'Research', 'Research Infrastructure', 'Retrieval', 'Review Literature', 'Scoring Method', 'System', 'Technology', 'Testing', 'Text', 'Toxicology', 'United States National Institutes of Health', 'Writing', 'biomedical informatics', 'design', 'programs', 'symposium', 'systematic review']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,Y01,2018,200000,-0.010382103679335392
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9538189,K01ES026833,"['Acute', 'Affect', 'Blood', 'Blood flow', 'Brain', 'Brain Injuries', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Healthcare', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Ruptured Aneurysm', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision support', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'public health relevance', 'standard of care', 'support tools', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2018,216241,0.01175148854163092
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9421556,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,793522,0.02441992669557586
"Prediction of Clinical Deterioration Using a Bayesian Belief System Project Summary/Abstract Approximately 5-10% of hospitalized patients suffer significant clinical deterioration after admission, resulting in either transfer to the intensive care unit (ICU) or a ""code"" event (i.e., cardiac or pulmonary arrest). Delayed identification of these events result in increased morbidity and mortality. Unfortunately, existing prediction models result in multiple false alarms for every true positive alarm that they generate. In addition with every passing year, new monitoring systems are introduced that generate more false alarms, resulting in alarm fatigue which has been associated with patient deaths. The objective of this mentored career development proposal is to develop and assess novel computational algorithms that can predict the clinical deterioration of hospitalized patients earlier and more accurately than clinicians or conventional early warning systems, thereby allowing for timely intervention. Building upon our experience in the hematologic malignancy subpopulation of hospitalized patients, this new effort: 1) provides a foundation upon which to combine newer machine learning (ML) methods and clinical informatics to improve the capabilities of the model for an individual patient or specific subgroup; 2) assesses the impact and value of different variables from the electronic medical record (EMR) as part of the predictive model; and 3) broadens the evaluation of this approach to additional real-world patient populations, enabling insight into the translation of the models to clinical usage. The specific aims of this project are thus: Specific Aims Aim 1 To identify and extract model variables (features) from the EMR, evaluating different feature selection  methods to optimize different predictive criterion and their impact on ML algorithms. Aim 2 To develop an ML approach that handles multiple asynchronous data streams of longitudinal  information from the EMR, providing predictions on clinical deterioration in real-time. Aim 3 To explore clinician and rapid response team responses to early prediction of clinical deterioration. With successful completion of this proposal, the prediction model will be integrated into the EMR system. Future direction as part of a R01 proposal will involve external validation at other institutions and assessment of clinical impact on patient care. Relevance to Public Health Clinical deterioration in the hospital is often unexpected and is associated with increased mortality and morbidity, with the CDC reporting 17.2 million hospital admissions through the emergency department in 2010 suggesting that approximately 1 million people annually are at risk of clinical deterioration during their hospitalization. Existing early warning systems have not been able to accurately predict these events without creating an overwhelming amount of additional false positive alarms, resulting in alarm fatigue and potential harm. Our project, utilizing machine learning techniques with the large amount of available clinical data, will serve to develop a predictive model that can predict clinical deterioration earlier with a higher positive predictive value than current algorithms/models which, when implemented, will be able to provide hospitalized patients with an additional safety net.",Prediction of Clinical Deterioration Using a Bayesian Belief System,9504995,K01LM012873,"['Accident and Emergency department', 'Admission activity', 'Algorithms', 'Belief System', 'Cardiac', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical assessments', 'Code', 'Computational algorithm', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Set', 'Deterioration', 'Discipline of Nursing', 'Ensure', 'Evaluation', 'Event', 'Fatigue', 'Foundations', 'Future', 'Genes', 'Health Personnel', 'Heart Arrest', 'Hematologic Neoplasms', 'Hospitalization', 'Hospitals', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'Learning', 'Lung', 'Machine Learning', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Nature', 'Patient Care', 'Patients', 'Performance', 'Population', 'Predictive Value', 'Public Health', 'Reporting', 'Research', 'Risk', 'Science', 'Specificity', 'Stream', 'Subgroup', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translating', 'Translations', 'United Kingdom', 'United States', 'Validation', 'Work', 'Workload', 'base', 'biomedical informatics', 'burnout', 'career development', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinical predictors', 'clinical risk', 'cohort', 'computer science', 'experience', 'improved', 'individual patient', 'insight', 'learning strategy', 'mental state', 'mortality', 'novel', 'patient population', 'predictive modeling', 'prevent', 'response', 'safety net', 'skills']",NLM,UNIVERSITY OF CALIFORNIA LOS ANGELES,K01,2018,205524,0.0012517661415633646
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9460286,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke treatment', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2018,163080,0.002689841670606051
"Epidemiology and clinical outcomes of diabetic macular edema Approximately 25% of the millions of veterans (est. 8.92 million FY 2013) enrolled for care in Veterans Health Administration (VHA) have diabetes mellitus, and diabetic macular edema (DME) is the leading cause of vision loss in the adult diabetic population world-wide. Although diabetic retinopathy has been well-studied, comparatively little is known about the burden of DME. In fact, only two national prevalence studies and no national study on the incidence of DME in persons with type 2 diabetes have been conducted. Similarly many risk factors have been characterized for DR, but no large studies have established predictors for DME.  Beyond the Medicare claims database, the VHA National Patient Care Database (NPCD) contains standardized administrative data for several aspects of patient care including diagnoses, procedures, medications, lab test results, vital signs, clinical text notes, and mortality. Because the VA uses teleretinal screening as routine clinical care for all patients with diabetes with these results included in the NPCD, the NPCD is an ideal source for studying the epidemiology of and risk factors for DME.  This study proposes to determine the burden of diabetic macular edema, establish risk factors, and examine treatment outcomes in a previously extracted dataset on 1.98 million veterans who have undergone diabetic retinopathy screening at least once since 2004. Currently invaluable ophthalmic data are encoded in unstructured clinical encounter notes in the Computerized Patient Record System (CPRS), and no validated automated extraction method exists to capture these data elements. An automated extraction method using natural language processing will be created and validated to unlock key ophthalmic variables. These text extraction methods will be applicable to extracting ophthalmology data from not only notes of patients with DME but also any ophthalmology clinical note. This will enable future large scale studies in ophthalmology using NPCD and be immediately valuable to the research community at large.  The candidate, Dr. Aaron Lee, MD MSCI, is an ophthalmologist with subspecialty training in retina surgery with a strong background in computer science and epidemiology. His career goal is to become an independent clinician scientist studying diabetic eye disease with large-scale electronic medical record extracted data. While he possesses the foundational skills, he seeks to gain training in advanced statistics and natural language processing to unlock the data captured in unstructured clinical encounter notes. He has assembled an outstanding mentorship team under the primary mentor, Dr. Edward Boyko, MD MPH. This mentorship team includes renowned experts in clinical epidemiology, health informatics, ophthalmology, and natural language processing. This K23 will provide Dr. Lee the structured coursework, mentorship, and applied learning needed to acquire new research skills. He will leverage key local resources to carry out the proposed research at the University of Washington and the VA Seattle Epidemiologic Research and Information Center. Despite the significant visual loss associated with diabetic macular edema, little is known about the frequency of its occurrence, its risk factors, and the real-world effectiveness of existing treatments. The purpose of this proposed research is to utilize the VA National Patient Care Database to extract relevant data elements to examine these three clinical questions: 1) what is the incidence and prevalence of diabetic macular edema, 2) what are the risk factors associated with its development, and 3) what is the comparative real-world effectiveness of its treatments, including intravitreal anti-VEGF therapy, intravitreal corticosteroid therapy and macular laser. The methods developed in this research proposal will not only further our understanding of DME but also generalize and enable future large-scale ophthalmic studies.",Epidemiology and clinical outcomes of diabetic macular edema,9574973,K23EY029246,"['Adopted', 'Adrenal Cortex Hormones', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anemia', 'Blindness', 'Cardiovascular Diseases', 'Caring', 'Cataract Extraction', 'Clinic', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Computerized Medical Record', 'Computerized Patient Records', 'Data', 'Data Element', 'Data Set', 'Databases', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Dyslipidemias', 'Effectiveness', 'Enrollment', 'Epidemiology', 'Ethnic Origin', 'Exclusion Criteria', 'Expressed Sequence Tags', 'Eye', 'Eye diseases', 'Foundational Skills', 'Frequencies', 'Functional disorder', 'Future', 'Goals', 'Handedness', 'Hypertension', 'Incidence', 'Information Centers', 'Injections', 'Intervention', 'Kidney', 'Lasers', 'Lead', 'Light Coagulation', 'Manuals', 'Masks', 'Measures', 'Medicare claim', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Operative Surgical Procedures', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Prediction of Response to Therapy', 'Prevalence', 'Prevalence Study', 'Procedures', 'Protocols documentation', 'Public Health Informatics', 'Randomized Controlled Trials', 'Regimen', 'Research', 'Research Proposals', 'Resources', 'Retina', 'Retinal', 'Risk Factors', 'Scientist', 'Severities', 'Sleep Apnea Syndromes', 'Smoking Status', 'Source', 'Standardization', 'Structure', 'System', 'Test Result', 'Text', 'Time', 'Training', 'Treatment Protocols', 'Treatment outcome', 'Universities', 'Use Effectiveness', 'Validation', 'Vascular Endothelial Growth Factors', 'Veterans', 'Visual', 'Visual Acuity', 'Washington', 'bevacizumab', 'career', 'clinical care', 'clinical epidemiology', 'cohort', 'comparative', 'computer science', 'diabetes management', 'diabetic', 'epidemiology study', 'hands-on learning', 'health administration', 'intravitreal injection', 'laser photocoagulation', 'macula', 'macular edema', 'mortality', 'proliferative diabetic retinopathy', 'screening', 'skills', 'statistics', 'therapy outcome', 'traditional therapy', 'treatment optimization']",NEI,UNIVERSITY OF WASHINGTON,K23,2018,237398,0.020022855794244367
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9454246,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease Surveillance', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,461012,0.023106330451196283
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9476980,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'base', 'clinical decision support', 'clinical implementation', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2018,300000,0.05271203904444639
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9395941,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Data Sources', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'population based', 'prevent', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2018,803425,0.02746559174005015
"How Does Automated Record Linkage Affect Inferences about Population Health? ABSTRACT  Our broad research objective is to create the Longitudinal Intergenerational Family Electronic Micro-dataset (LIFE-M) spanning the late 19th and 20th century United States. Using automated record linkage technology, the LIFE-M project combines millions of vital records to reconstruct how and why individuals' health has changed across time. This multi-generational, longitudinal micro-database aims to transform research on health and longevity, on childbearing and family structure, and on the long-run health effects of early-life circumstances and exposures.  In creating LIFE-M, however, we have encountered serious deficits in knowledge about the performance of automated record linkage technology. The proposed project seeks to evaluate the performance of the most popular and cutting-edge automated linking techniques for the purposes of creating longitudinal health data. Our specific aims are to (1) produce systematic evidence regarding the performance of automated record linking algorithms in terms of match rates, representativeness of the linked sample, erroneous matches (type I errors), and systematic measurement error; (2) examine how phonetic name-cleaning methods affect quality metrics; and (3) examine how record quality metrics vary for different underrepresented subgroups (including women, racial/ethnic minorities, and immigrants) and to determine how linking methods affect representativeness and inferences. To achieve these aims, we have developed new partnerships with record linking experts allowing us to incorporate the most cutting-edge methods in record linking. We will also rely on new “ground truth” generated by LIFE-M project's independent, double-blind human review process.  This project will contribute significantly to existing knowledge about the use of automated linking methods for creating longitudinal and intergenerational health data. It will also increase knowledge about potential sources of bias in health studies. Both contributions should greatly enhance the quality of descriptive and causal inferences about population health and aging and disparities in these outcomes. PROJECT NARRATIVE  This project contributes to public health knowledge by advancing record linking methodology for creating longitudinal and intergenerational health datasets. It will also increase knowledge about potential sources of bias in public health and aging studies using linked records. Both contributions should significantly improve the quality of inferences about public and population health and health disparities.",How Does Automated Record Linkage Affect Inferences about Population Health?,9565480,R21AG056912,"['Affect', 'Aging', 'Algorithms', 'American', 'Benchmarking', 'Big Data', 'Birth', 'Birth Certificates', 'Birth Records', 'Censuses', 'Child', 'Computers', 'Data', 'Data Linkages', 'Data Set', 'Databases', 'Double-Blind Method', 'Economics', 'Family', 'Foundations', 'Four-dimensional', 'Funding', 'Genealogy', 'Generations', 'Genetic Transcription', 'Goals', 'Graph', 'Hand', 'Health', 'Heterogeneity', 'Human', 'Immigrant', 'Incidence', 'Individual', 'Infant', 'Joints', 'Knowledge', 'Life', 'Link', 'Longevity', 'Machine Learning', 'Maiden Name', 'Marriage', 'Measurement', 'Measures', 'Medicare', 'Methodology', 'Methods', 'Minnesota', 'Minor', 'Names', 'Outcome', 'Performance', 'Pilot Projects', 'Politics', 'Population', 'Process', 'Public Health', 'Records', 'Research', 'Research Infrastructure', 'Running', 'Sample Size', 'Sampling', 'Science', 'Scientist', 'Source', 'Speed', 'Subgroup', 'Techniques', 'Technology', 'Time', 'United States', 'United States National Institutes of Health', 'Universities', 'Variant', 'Veterans', 'Woman', 'aging population', 'child bearing', 'cost effective', 'ethnic minority population', 'family structure', 'health data', 'health disparity', 'health knowledge', 'improved', 'innovation', 'intergenerational', 'longitudinal database', 'population health', 'racial and ethnic', 'repository', 'social', 'vector']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2018,194895,0.0027594684685012
"Development and Evaluation of a Learning Electronic Medical Record System ﻿    DESCRIPTION (provided by applicant):  The goal of this project to develop and evaluate a learning electronic medical records (L-EMR) system that draws a physician's attention to the right data, at the right time. It learns how to do so by analyzing patterns of patient data access f many physicians in many past cases in the EMR, and learning which EMR data to highlight that are relevant for making clinical decisions in a given patient.      The hypothesis underlying this research is that the L-EMR system will have sufficiently high precision and recall in highlighting relevant data, decrease the average time to assess an intensive care unit (ICU) patient case, and be judged by critical care medicine (CCM) physicians to be clinically useful.    The first aim of this project is develop a highly-usable L-EMR user interface. The L-EMR user interface will include zoomable time-series displays of lab-results, med-orders, and vital signs. Usability studies of the L-EMR user interface will guide revisions and enhancements.      The second aim of the project is to train statistical models that can be applied to a patient case to predict relevant lab-results, med-orders, and vital signs. We will enlist CCM physicians to review a set of retrospective ICU patient cases on a focused set of clinical conditions. Participants will review these cases as if they were active patients, identifying relevant lab- results, med-orders, and vital signs. We will train and evaluate statistical models to predict relevant data, and identify the best performing algorithm to include in the L-EMR system.      The third aim of the project is to evaluate the L-EMR system. We will recruit CCM physicians to evaluate an L-EMR system based on user interfaces from Aim 1 and statistical models trained using the best performing algorithm in Aim 2 to highlight relevant data items. We will measure the precision and recall of the data-highlighting functionality for assessing patient cases and making clinical decisions (e.g., lab and medication orders), the time required to assess cases with and without the highlighting, and physicians' assessments of the strengths and weaknesses of the L-EMR system.    If the results of these experiments are positive, as anticipated, this project will introduce a computational method that has significant potential to improve future EMR systems and enhance patient care. Narrative The purpose of this research is to develop and evaluate a learning electronic medical records (EMR) system that draws a physician's attention to the right data, at the right time. The system works by analyzing patterns of EMR usage of physicians, and learning which EMR data to highlight that are relevant in a given patient. The main idea underlying the approach is that patterns of past EMR usage patterns can be exploited to selectively highlight clinically useful patient data.",Development and Evaluation of a Learning Electronic Medical Record System,9521586,R01LM012095,"['Address', 'Adult', 'Algorithms', 'American', 'Attention', 'Bayesian Modeling', 'Blood', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical assessments', 'Computerized Medical Record', 'Computing Methodologies', 'Critical Care', 'Critical Illness', 'Data', 'Data Display', 'Data Set', 'Development', 'E-learning', 'Educational workshop', 'Evaluation', 'Face', 'Future', 'Gastrointestinal Hemorrhage', 'Goals', 'Healthcare Systems', 'Heart Rate', 'Hemoglobin', 'Individual', 'Information Systems', 'Institute of Medicine (U.S.)', 'Intensive Care Units', 'Intravenous', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Participant', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Physiological', 'Provider', 'Reporting', 'Research', 'Research Personnel', 'Series', 'Statistical Models', 'System', 'Test Result', 'Time', 'Training', 'Work', 'base', 'clinical decision-making', 'computer human interaction', 'data access', 'design', 'experimental study', 'follow-up', 'improved', 'prospective', 'prototype', 'recruit', 'research clinical testing', 'stem', 'trend', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2018,452158,0.05036895570030398
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,9534365,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2018,449751,-0.0010793700081888563
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9567932,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,249135,0.04081266129569819
"Improving Adverse Event Reporting on Cooperative Oncology Group Trials PROJECT SUMMARY/ABSTRACT Background: The reports of side effects on clinical trials describe expected toxicities of chemotherapy. However, these side effects, also called adverse events, are globally under-reported on trials, which means that clinicians do not have an accurate sense of adverse event rates. In the current system, adverse events are identified through time-consuming, manual medical record review. This study aims to develop a system that uses electronic medical record data to capture complex adverse events of chemotherapy for pediatric cancer and to prove that this method is more accurate than the current adverse event reporting system. The specific aims of this application are to 1) develop algorithms to identify 10 complex adverse events using electronic medical record data from children treated for acute leukemia at two large children's hospitals, 2) compare the accuracy of this new method to that of the current system, and 3) demonstrate the utility of electronic adverse event capture in answering clinical questions by defining the incidence and risk factors of acute kidney injury. Methods: This study will use data from 1900 children with acute leukemia treated at the Children's Hospital of Philadelphia (CHOP) or the Texas Children's Hospital (TCH) from 2002 through 2017. Algorithms will be developed to identify adverse events by extracting electronic medical record data at CHOP. Once finalized, the algorithms will be tested at TCH. Using chart abstraction data as the gold standard, the accuracy of electronic ascertainment and of trial adverse event reports will determined, and the relative accuracy of each method will be compared. Lastly, algorithms will extract creatinine results from the electronic medical record and the incidence of acute kidney injury will be determined for each leukemia type and by chemotherapy regimen. Risk factors for acute kidney injury will be explored. Career Goals and Environment: With the support of this K07 award, the applicant, Tamara P. Miller, MD, MSCE, will learn how to use electronic medical record data for clinical research, obtain formal training in clinical informatics and implementation science, develop expertise in clinical trial design, and improve her knowledge of pediatric oncology and skills in scientific writing. To complete these training goals, Dr. Miller has assembled an experienced, complementary, and nurturing mentoring team led by her primary mentor, Richard Aplenc, MD, PhD. Her training plan includes formal coursework in informatics, tutorials, national conferences, and research progress and writing groups. She will benefit from the outstanding depth of resources and opportunities at CHOP and the University of Pennsylvania. Her long-term goal is to integrate the novel system of adverse event ascertainment she creates into pediatric oncology trials and to use the accurate datasets she develops to answer clinically important questions. With this award, Dr. Miller will be well-positioned to transition to her goal of an independent clinical research career focused on improving adverse event reporting and supportive care practices in pediatric oncology. PROJECT NARRATIVE Children with cancer experience significant side effects from their treatments, but these side effects are under- reported on clinical trials and no work has been done to improve the current system of side effect reporting. This study will create a new system of identifying and reporting side effects that is more accurate and efficient than the current system. The results of this research will provide clinicians, patients and their families with a true understanding of potential side effects of therapies used to treat childhood cancer.",Improving Adverse Event Reporting on Cooperative Oncology Group Trials,9568724,K07CA211956,"['Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute leukemia', 'Adverse effects', 'Adverse event', 'Age', 'Algorithms', 'Award', 'Chemotherapy-Oncologic Procedure', 'Child', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Design', 'Common Terminology Criteria for Adverse Events', 'Complex', 'Computerized Medical Record', 'Creatinine', 'Data', 'Data Set', 'Doctor of Philosophy', 'Enrollment', 'Environment', 'Ethnic Origin', 'Family', 'Foundations', 'Gender', 'Goals', 'Gold', 'Hospitals', 'Incidence', 'Informatics', 'Knowledge', 'Laboratories', 'Learning', 'Malignant Childhood Neoplasm', 'Manuals', 'Medical Records', 'Mentors', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Oncology Group', 'Patients', 'Pediatric Hospitals', 'Pediatric Oncology', 'Pediatric Oncology Group', 'Pennsylvania', 'Pharmaceutical Preparations', 'Philadelphia', 'Positioning Attribute', 'Predictive Value', 'Process', 'Publishing', 'Race', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Safety', 'Sensitivity and Specificity', 'Supportive care', 'System', 'Testing', 'Texas', 'Text', 'Time', 'Toxicity due to chemotherapy', 'Training', 'Universities', 'Work', 'Writing', 'base', 'cancer therapy', 'career', 'chemotherapy', 'clinical decision-making', 'clinical epidemiology', 'clinical implementation', 'cohort', 'epidemiology study', 'experience', 'implementation science', 'improved', 'leukemia', 'nephrotoxicity', 'novel', 'oncology trial', 'prospective', 'secondary analysis', 'skills', 'statistics', 'symposium']",NCI,EMORY UNIVERSITY,K07,2018,169028,0.025370477919629576
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,9337267,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face Processing', 'Goals', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Supervision', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'learning strategy', 'model development', 'novel', 'open source', 'real world application', 'statistics', 'success', 'tool', 'usability', 'word learning']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,463061,0.02689385490793908
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions. PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.",Natural language processing for characterizing psychopathology,9254614,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Clinical stratification', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Risk stratification', 'Severities', 'Structure', 'Subgroup', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinically relevant', 'cohort', 'cost', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'translational scientist', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,377260,-0.009011882347124934
"IGF::OT::IGF  Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP n/a","IGF::OT::IGF  Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP",9581371,61201400011I,"['Natural Language Processing', 'meetings']",NCI,"SCIENTIFIC CONSULTING GROUP, INC.",N01,2017,9923,-0.016516460845659723
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9385056,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Biological Preservation', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2017,1589604,0.010548166935647536
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9325065,R01LM011934,"['Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'information model', 'novel', 'open source', 'profiles in patients', 'public health relevance', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2017,387966,0.04577050537011789
"From genomics to natural language processing: A protected environment for research computing in the health science NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Health sciences researchers are often required to manage, mine, and analyze restricted patient data (Protected Health Information, PHI) to facilitate and advance their research aims. They are often required to do this without access to central information technology expertise or resources to facilitate their research aims. These researchers are often left to their own devices to “solve” their research compute and data needs and are challenged due to lack of available resources, barriers from central IT, and/or lack of knowledge of available resources. A further challenge is that “small” data sets— data that researchers could formerly handle on office resources—have morphed and grown into the big data domain through the explosion of technical advances and significant expansion in various research directions. Examples include: genomics research, image analysis, simulation, natural language processing, and mining of EMRs. Therefore, the need exists to develop a framework for managing and processing this data securely and reliably. This S10 equipment proposal is to replace the “protected environment” (PE) prototype the University of Utah’s Center for High Performance Computing (CHPC) and Department of Biomedical Informatics built six years ago and has operated since. The PE consists of both high performance computing and virtual machine (VM) components and associated storage sufficient to manage, protect and analyze HIPAA protected health information. This environment has been very successful and has grown significantly in scope. CHPC isolated this protected environment in the secured University of Utah Downtown Data Center and setup a network protected logical partition that provided research groups specific access to individual data sets. As the environment and technology developed, CHPC added additional security features such as two-factor authentication for entry and audit/monitoring. Unfortunately, the prototype has reached the point where demand is surpassing capability and all the hardware is aged and off-warranty. To give an idea of users of the virtual machine farm component, the Biomedical Informatics Core (BMIC) REDCap (Research Electronic Data Capture) environment for data collection has over 2,500 users in 1,500 projects supporting over $25M in NIH funding at the University of Utah, including support for more than 25 active NIH R-01 grants. Moreover, the HIPAA compliant protected environment was a key factor that aided passing the recent University of Utah HIPAA audit. The “protected environment” also helped the University of Utah Health Sciences Center and the BMIC justify the NCATS Center Clinical and Translational Science award (1ULTR001067). NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Project Narrative: The proposed “Protected Environment” instrument will provide research computing and data management capabilities for health sciences researchers to properly manage, secure, and analyze HIPAA regulated protected health information. The technology will not only support a large number of clinical trials, but also enable research in Human Genetics and Natural Language Processing of electronic health records.",From genomics to natural language processing: A protected environment for research computing in the health science,9274445,S10OD021644,"['Award', 'Big Data', 'Clinical Sciences', 'Data', 'Data Collection', 'Data Set', 'Devices', 'Environment', 'Equipment', 'Explosion', 'Farming environment', 'Funding', 'Genomics', 'Grant', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'High Performance Computing', 'Image Analysis', 'Individual', 'Information Technology', 'Knowledge', 'Left', 'Mining', 'Monitor', 'Natural Language Processing', 'Patients', 'Research', 'Research Personnel', 'Resources', 'Secure', 'Security', 'Technology', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Utah', 'aged', 'biomedical informatics', 'computerized data processing', 'electronic data', 'prototype', 'simulation', 'virtual']",OD,UNIVERSITY OF UTAH,S10,2017,493595,-0.013373152113391946
"Crowd Sourcing Labels From Electronic Medical Records to Enable Biomedical Research ﻿    DESCRIPTION (provided by applicant): Supervised machine learning is a popular method that uses labeled training examples to predict future outcomes.  Unfortunately, supervised machine learning for biomedical research is often limited by a lack of labeled data.  Current methods to produce labeled data involve manual chart reviews that are laborious and do not scale with data creation rates.  This project aims to develop a framework to crowd source labeled data sets from electronic medical records by forming a crowd of clinical personnel labelers.  The construction of these labeled data sets will allow for new biomedical research studies that were previously infeasible to conduct.  There are numerous practical and theoretical challenges of developing a crowd sourcing platform for clinical data.  First, popular, public crowd sourcing platforms such as Amazon's Mechanical Turk are not suitable for medical record labeling as HIPAA makes clinical data sharing risky.  Second, the types of clinical questions that are amenable for crowd sourcing are not well understood.  Third, it is unclear if the clinical crowd can produce labels quickly and accurately.  Each of these challenges will be addressed in a separate Aim. As the first Aim of this project, the team will evaluate different clinical crowd sourcing architectures.  The architecture must leverage the scale of the crowd, while minimizing patient information exposure.  De-identification tools will be considered to scrub clinical notes t reduce information leakage.  Using this design, the team will extend a popular open source crowd sourcing tool, Pybossa, and release it to the public.  As the second Aim, the team will study the type, structure, topic and specificity of clinical prediction questions, and how these characteristics impact labeler quality.  Lastly, the team will evaluate the quality and accuracy of collected clinical crowd sourced data on two existing chart review problems to determine the platform's utility. PUBLIC HEALTH RELEVANCE: Traditionally, clinical prediction models rely on supervised machine learning algorithms to probabilistically predict clinical events using labeled medical records.  When data sets are small, manual chart reviews performed by clinical staff are sufficient to label each outcome; however, as data sets have scaled up and researchers aim to study larger cohorts, current manual approaches become intractable.  The goal of this proposal is to develop a framework to crowd source labeled data sets from electronic medical records to support prediction model development.",Crowd Sourcing Labels From Electronic Medical Records to Enable Biomedical Research,9270528,UH2CA203708,"['Accident and Emergency department', 'Address', 'Algorithms', 'Architecture', 'Area', 'Asthma', 'Biomedical Research', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Data', 'Collection', 'Computerized Medical Record', 'Crowding', 'Data', 'Data Set', 'Data Sources', 'Development', 'Disclosure', 'Ensure', 'Evaluation', 'Event', 'Extravasation', 'Future', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Human Resources', 'Incentives', 'Interview', 'Label', 'Machine Learning', 'Management Audit', 'Manuals', 'Measures', 'Mechanics', 'Medical Records', 'Medical Research', 'Medical Students', 'Medical center', 'Methods', 'Modeling', 'Nurses', 'Outcome', 'Patients', 'Privacy', 'Productivity', 'Receiver Operating Characteristics', 'Relapse', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Security', 'Specificity', 'Structure', 'Supervision', 'System', 'Time', 'Training', 'clinical predictors', 'cohort', 'computer science', 'crowdsourcing', 'data sharing', 'design', 'member', 'model development', 'open source', 'public health relevance', 'research study', 'response', 'scale up', 'tool']",NCI,VANDERBILT UNIVERSITY MEDICAL CENTER,UH2,2017,316000,0.03263952837251487
"Real-time detection of deviations in clinical care in ICU data streams DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our previous studies provide support that such deviations indicate clinically important events at false alert rates belo 50%, which is very promising. We propose to further improve the new methodology, and build a real-time monitoring and alerting system integrated with production electronic medical records. We propose an evaluation of the system using physicians' assessment of alerts raised by our real-time system for intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories. PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in the intensive care unit (ICU). This project develops and evaluates a new clinical monitoring and alerting framework that uses electronic medical records and machine-learning methods to send alerts concerning clinical decisions in the ICU that are unexpected given the clinical context and may represent medical errors.",Real-time detection of deviations in clinical care in ICU data streams,9278178,R01GM088224,"['Algorithms', 'Archives', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complication', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Detection', 'Development', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Funding', 'Health Personnel', 'Healthcare', 'Hospitals', 'Immunosuppressive Agents', 'Inpatients', 'Intensive Care Units', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Errors', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Oral', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Play', 'Practice Management', 'Production', 'Real-Time Systems', 'Records', 'Research', 'Research Personnel', 'Signal Transduction', 'Stream', 'System', 'Tacrolimus', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical data warehouse', 'clinical practice', 'computer science', 'cost', 'data archive', 'design', 'improved', 'individual patient', 'knowledge base', 'learning strategy', 'liver transplantation', 'multidisciplinary', 'prototype', 'public health relevance']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2017,543819,0.045942678741332725
"Identification of Patients with Low Life Expectancy ﻿    DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9275946,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2017,227900,0.04629143652052455
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9320962,K01ES026833,"['Acute', 'Affect', 'Blood', 'Blood flow', 'Brain', 'Brain Injuries', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Healthcare', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Ruptured Aneurysm', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'public health relevance', 'standard of care', 'support tools', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2017,216241,0.01175148854163092
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9199581,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Injectable', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2017,798827,0.02441992669557586
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9294543,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke treatment', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2017,163080,0.002689841670606051
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9249484,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2017,461012,0.023106330451196283
"Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients Project Summary Epilepsy is one of the leading neurological disorders in the United States, affecting more than 479,000 children and over 2 million adults. Approximately 30% of epileptic patients have poor seizure control despite antiepileptic medications and are potential candidates for neurosurgical intervention. Early identification and referral of children who are potential surgical candidates is complex and while relevant guidelines exist, there is no standard process to efficiently identify those patients meeting criteria for neurosurgical intervention. Given the large corpus of note-based data available in the electronic health record (EHR), it is challenging for providers to efficiently retain and process all the pertinent patient information. Natural Language Processing (NLP) and machine learning techniques have been successfully used to evaluate clinical notes and make recommendations in the research setting. However, NLP techniques are rarely integrated into practice to provide real-time clinical decision support. We developed and retrospectively evaluated a NLP system to help identify those patients who meet neurosurgical criteria and therefore enable surgical consults and evaluations to occur sooner. Knowing clinical decision support can improve outcomes of care, our proposed research will implement NLP into clinical practice and develop a decision support mechanism to improve the time to surgery for eligible patients. The objective of this project is to implement NLP directly into clinical care and determine the most effective decision support mechanism for provider adherence to epilepsy surgical consult recommendations. The long- term goal of this project is to reduce the time to initial surgery evaluation for patients with intractable epilepsy by integrating NLP-classification criteria into clinical practice. This project is one of the first in the field to study the integration of NLP recommendations into clinical care. We will use a human factors engineering framework to design and to analyze two different alerting methodologies for the best-fit for clinical workflow to produce the optimum provider adherence while reducing alert fatigue. Epilepsy progress notes can be classified across hospitals, and if successful, the system will be implemented in additional pediatric institutions around the United States. Project Narrative Epilepsy affects more than 479,000 children; 30% of those are not controlled with medication and may require surgery. We developed a novel Natural Language Processing (NLP) algorithm that can be integrated into neurology practice to detect patients who may be eligible for epilepsy surgical consults. Once implemented, this research can help to drive successful implementations of NLP and identify and use ideal alerting mechanisms in neurological care.",Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients,9355161,R21HS024977,[' '],AHRQ,CINCINNATI CHILDRENS HOSP MED CTR,R21,2017,159334,-0.04498197155870883
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9251814,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2017,300000,0.05271203904444639
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9215012,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Data Sources', 'Development', 'Diagnostic', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'outcome forecast', 'population based', 'prevent', 'socioeconomics', 'surveillance data', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2017,836858,0.02746559174005015
"How Does Automated Record Linkage Affect Inferences about Population Health? ABSTRACT  Our broad research objective is to create the Longitudinal Intergenerational Family Electronic Micro-dataset (LIFE-M) spanning the late 19th and 20th century United States. Using automated record linkage technology, the LIFE-M project combines millions of vital records to reconstruct how and why individuals' health has changed across time. This multi-generational, longitudinal micro-database aims to transform research on health and longevity, on childbearing and family structure, and on the long-run health effects of early-life circumstances and exposures.  In creating LIFE-M, however, we have encountered serious deficits in knowledge about the performance of automated record linkage technology. The proposed project seeks to evaluate the performance of the most popular and cutting-edge automated linking techniques for the purposes of creating longitudinal health data. Our specific aims are to (1) produce systematic evidence regarding the performance of automated record linking algorithms in terms of match rates, representativeness of the linked sample, erroneous matches (type I errors), and systematic measurement error; (2) examine how phonetic name-cleaning methods affect quality metrics; and (3) examine how record quality metrics vary for different underrepresented subgroups (including women, racial/ethnic minorities, and immigrants) and to determine how linking methods affect representativeness and inferences. To achieve these aims, we have developed new partnerships with record linking experts allowing us to incorporate the most cutting-edge methods in record linking. We will also rely on new “ground truth” generated by LIFE-M project's independent, double-blind human review process.  This project will contribute significantly to existing knowledge about the use of automated linking methods for creating longitudinal and intergenerational health data. It will also increase knowledge about potential sources of bias in health studies. Both contributions should greatly enhance the quality of descriptive and causal inferences about population health and aging and disparities in these outcomes. PROJECT NARRATIVE  This project contributes to public health knowledge by advancing record linking methodology for creating longitudinal and intergenerational health datasets. It will also increase knowledge about potential sources of bias in public health and aging studies using linked records. Both contributions should significantly improve the quality of inferences about public and population health and health disparities.",How Does Automated Record Linkage Affect Inferences about Population Health?,9372797,R21AG056912,"['Affect', 'Aging', 'Algorithms', 'American', 'Benchmarking', 'Big Data', 'Birth', 'Birth Certificates', 'Birth Records', 'Censuses', 'Child', 'Computers', 'Data', 'Data Linkages', 'Data Set', 'Databases', 'Double-Blind Method', 'Economics', 'Family', 'Foundations', 'Four-dimensional', 'Funding', 'Genealogy', 'Generations', 'Genetic Transcription', 'Goals', 'Graph', 'Hand', 'Health', 'Heterogeneity', 'Human', 'Immigrant', 'Incidence', 'Individual', 'Infant', 'Joints', 'Knowledge', 'Life', 'Link', 'Longevity', 'Machine Learning', 'Maiden Name', 'Marriage', 'Measurement', 'Measures', 'Medicare', 'Methodology', 'Methods', 'Minnesota', 'Minor', 'Names', 'Outcome', 'Performance', 'Pilot Projects', 'Politics', 'Population', 'Process', 'Public Health', 'Records', 'Research', 'Research Infrastructure', 'Running', 'Sample Size', 'Sampling', 'Science', 'Scientist', 'Source', 'Speed', 'Subgroup', 'Techniques', 'Technology', 'Time', 'United States', 'United States National Institutes of Health', 'Universities', 'Variant', 'Veterans', 'Woman', 'aging population', 'child bearing', 'cost effective', 'ethnic minority population', 'family structure', 'health data', 'health disparity', 'health knowledge', 'improved', 'innovation', 'intergenerational', 'longitudinal database', 'population health', 'racial and ethnic', 'repository', 'social', 'vector']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2017,232500,0.0027594684685012
"Development and Evaluation of a Learning Electronic Medical Record System ﻿    DESCRIPTION (provided by applicant):  The goal of this project to develop and evaluate a learning electronic medical records (L-EMR) system that draws a physician's attention to the right data, at the right time. It learns how to do so by analyzing patterns of patient data access f many physicians in many past cases in the EMR, and learning which EMR data to highlight that are relevant for making clinical decisions in a given patient.      The hypothesis underlying this research is that the L-EMR system will have sufficiently high precision and recall in highlighting relevant data, decrease the average time to assess an intensive care unit (ICU) patient case, and be judged by critical care medicine (CCM) physicians to be clinically useful.    The first aim of this project is develop a highly-usable L-EMR user interface. The L-EMR user interface will include zoomable time-series displays of lab-results, med-orders, and vital signs. Usability studies of the L-EMR user interface will guide revisions and enhancements.      The second aim of the project is to train statistical models that can be applied to a patient case to predict relevant lab-results, med-orders, and vital signs. We will enlist CCM physicians to review a set of retrospective ICU patient cases on a focused set of clinical conditions. Participants will review these cases as if they were active patients, identifying relevant lab- results, med-orders, and vital signs. We will train and evaluate statistical models to predict relevant data, and identify the best performing algorithm to include in the L-EMR system.      The third aim of the project is to evaluate the L-EMR system. We will recruit CCM physicians to evaluate an L-EMR system based on user interfaces from Aim 1 and statistical models trained using the best performing algorithm in Aim 2 to highlight relevant data items. We will measure the precision and recall of the data-highlighting functionality for assessing patient cases and making clinical decisions (e.g., lab and medication orders), the time required to assess cases with and without the highlighting, and physicians' assessments of the strengths and weaknesses of the L-EMR system.    If the results of these experiments are positive, as anticipated, this project will introduce a computational method that has significant potential to improve future EMR systems and enhance patient care. Narrative The purpose of this research is to develop and evaluate a learning electronic medical records (EMR) system that draws a physician's attention to the right data, at the right time. The system works by analyzing patterns of EMR usage of physicians, and learning which EMR data to highlight that are relevant in a given patient. The main idea underlying the approach is that patterns of past EMR usage patterns can be exploited to selectively highlight clinically useful patient data.",Development and Evaluation of a Learning Electronic Medical Record System,9297355,R01LM012095,"['Address', 'Adult', 'Algorithms', 'American', 'Attention', 'Bayesian Modeling', 'Blood', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical assessments', 'Computerized Medical Record', 'Computing Methodologies', 'Critical Care', 'Critical Illness', 'Data', 'Data Display', 'Data Set', 'Development', 'E-learning', 'Educational workshop', 'Evaluation', 'Face', 'Future', 'Gastrointestinal Hemorrhage', 'Goals', 'Healthcare Systems', 'Heart Rate', 'Hemoglobin', 'Individual', 'Information Systems', 'Institute of Medicine (U.S.)', 'Intensive Care Units', 'Intravenous', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Participant', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Physiological', 'Provider', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Series', 'Statistical Models', 'System', 'Test Result', 'Time', 'Training', 'Work', 'base', 'clinical decision-making', 'computer human interaction', 'data access', 'design', 'experimental study', 'follow-up', 'improved', 'prospective', 'prototype', 'research clinical testing', 'stem', 'trend', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2017,444581,0.05036895570030398
"NLP to Improve Accuracy and Quality of Dictated Medical Documents ﻿    DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005). PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9352296,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2017,249995,0.03797305076177993
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,9319536,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2017,449993,-0.0010793700081888563
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9352770,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,249135,0.04081266129569819
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,9307936,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Databases', 'Disease', 'Drug Exposure', 'Drug Modelings', 'Drug toxicity', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'cost', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'genomic data', 'improved', 'longitudinal dataset', 'novel', 'open source', 'personalized medicine', 'phenotypic data', 'public health relevance', 'rapid growth', 'rare variant', 'response', 'study population', 'success', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,600474,0.01833216900285443
"Improving Adverse Event Reporting on Cooperative Oncology Group Trials PROJECT SUMMARY/ABSTRACT Background: The reports of side effects on clinical trials describe expected toxicities of chemotherapy. However, these side effects, also called adverse events, are globally under-reported on trials, which means that clinicians do not have an accurate sense of adverse event rates. In the current system, adverse events are identified through time-consuming, manual medical record review. This study aims to develop a system that uses electronic medical record data to capture complex adverse events of chemotherapy for pediatric cancer and to prove that this method is more accurate than the current adverse event reporting system. The specific aims of this application are to 1) develop algorithms to identify 10 complex adverse events using electronic medical record data from children treated for acute leukemia at two large children's hospitals, 2) compare the accuracy of this new method to that of the current system, and 3) demonstrate the utility of electronic adverse event capture in answering clinical questions by defining the incidence and risk factors of acute kidney injury. Methods: This study will use data from 1900 children with acute leukemia treated at the Children's Hospital of Philadelphia (CHOP) or the Texas Children's Hospital (TCH) from 2002 through 2017. Algorithms will be developed to identify adverse events by extracting electronic medical record data at CHOP. Once finalized, the algorithms will be tested at TCH. Using chart abstraction data as the gold standard, the accuracy of electronic ascertainment and of trial adverse event reports will determined, and the relative accuracy of each method will be compared. Lastly, algorithms will extract creatinine results from the electronic medical record and the incidence of acute kidney injury will be determined for each leukemia type and by chemotherapy regimen. Risk factors for acute kidney injury will be explored. Career Goals and Environment: With the support of this K07 award, the applicant, Tamara P. Miller, MD, MSCE, will learn how to use electronic medical record data for clinical research, obtain formal training in clinical informatics and implementation science, develop expertise in clinical trial design, and improve her knowledge of pediatric oncology and skills in scientific writing. To complete these training goals, Dr. Miller has assembled an experienced, complementary, and nurturing mentoring team led by her primary mentor, Richard Aplenc, MD, PhD. Her training plan includes formal coursework in informatics, tutorials, national conferences, and research progress and writing groups. She will benefit from the outstanding depth of resources and opportunities at CHOP and the University of Pennsylvania. Her long-term goal is to integrate the novel system of adverse event ascertainment she creates into pediatric oncology trials and to use the accurate datasets she develops to answer clinically important questions. With this award, Dr. Miller will be well-positioned to transition to her goal of an independent clinical research career focused on improving adverse event reporting and supportive care practices in pediatric oncology. PROJECT NARRATIVE Children with cancer experience significant side effects from their treatments, but these side effects are under- reported on clinical trials and no work has been done to improve the current system of side effect reporting. This study will create a new system of identifying and reporting side effects that is more accurate and efficient than the current system. The results of this research will provide clinicians, patients and their families with a true understanding of potential side effects of therapies used to treat childhood cancer.",Improving Adverse Event Reporting on Cooperative Oncology Group Trials,9452250,K07CA211956,"['Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute leukemia', 'Adverse effects', 'Adverse event', 'Age', 'Algorithms', 'Award', 'Chemotherapy-Oncologic Procedure', 'Child', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Design', 'Common Terminology Criteria for Adverse Events', 'Complex', 'Computerized Medical Record', 'Creatinine', 'Data', 'Data Set', 'Doctor of Philosophy', 'Enrollment', 'Environment', 'Ethnic Origin', 'Family', 'Foundations', 'Gender', 'Goals', 'Gold', 'Hospitals', 'Incidence', 'Informatics', 'Knowledge', 'Laboratories', 'Learning', 'Malignant Childhood Neoplasm', 'Manuals', 'Medical Records', 'Mentors', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Nephrotoxic', 'Oncology Group', 'Patients', 'Pediatric Hospitals', 'Pediatric Oncology', 'Pediatric Oncology Group', 'Pennsylvania', 'Pharmaceutical Preparations', 'Philadelphia', 'Positioning Attribute', 'Predictive Value', 'Process', 'Publishing', 'Race', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Safety', 'Sensitivity and Specificity', 'Supportive care', 'System', 'Testing', 'Texas', 'Text', 'Time', 'Toxicity due to chemotherapy', 'Training', 'Universities', 'Work', 'Writing', 'base', 'cancer therapy', 'career', 'chemotherapy', 'clinical decision-making', 'clinical epidemiology', 'cohort', 'epidemiology study', 'experience', 'implementation science', 'improved', 'leukemia', 'nephrotoxicity', 'novel', 'prospective', 'secondary analysis', 'skills', 'statistics', 'symposium']",NCI,EMORY UNIVERSITY,K07,2017,169044,0.025370477919629576
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,9132834,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'learning strategy', 'model building', 'model development', 'novel', 'open source', 'real world application', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,463405,0.02689385490793908
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions.         PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.            ",Natural language processing for characterizing psychopathology,9105846,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electronics', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Process', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Severities', 'Stratification', 'Structure', 'Subgroup', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinical risk', 'cohort', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2016,413500,-0.009011882347124934
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9115996,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'profiles in patients', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2016,387966,0.04577050537011789
"Measuring and Improving Colonoscopy Quality Using Natural Language Processing DESCRIPTION (provided by applicant):  Colonoscopy is the predominant method for screening for colorectal cancer in the US. Yet, its effectiveness in screening is limited by variation in performance. For example, the rate at which physicians detect cancer precursors called adenomas during a colonoscopy has been shown to vary three-fold from one physician to another. A patient whose colonoscopy is performed by a physician with a low adenoma detection rate has a higher risk of subsequent colorectal cancer.  Our proposal centers on measuring, understanding, and improving colonoscopy quality. The major innovation of this work is to use natural language processing (NLP) to measure the quality of colonoscopy. NLP is a field of computer science in which a computer is trained to ""read"" text to identify relevant data We developed and validated the first NLP-based computer software application (C-QUAL) that analyzes colonoscopy and associated pathology reports. Our primary quality measure is adenoma detection rate because it is a common, validated measure that is linked to colorectal cancer incidence. However, we also use a number of secondary quality measures. We applied C-QUAL to almost 25,000 colonoscopy reports in one health system and found large variation in physician's performance on the quality measures. Building on this prior work, our goal is to use C-QUAL to measure colonoscopy quality across a spectrum of US practice environments, to understand what drives variation in colonoscopy quality, and to improve colonoscopy quality. In Aim 1, we propose to use the C-QUAL tool to measure performance in 4 diverse health care systems. This will be one of the largest assessments of the variation in adenoma detection rates and will span different geographic regions, payment systems, and practice settings. In Aim 2, we seek to understand why there is variation in quality. We will survey providers at the 4 health care systems about factors that might affect quality. We will link those survey results to the adenoma detection rates assessed in Aim 1 and look for key associations. It is assumed, but not proven, that providing feedback to physicians on colonoscopy quality will improve care. In Aim 3, we assess whether feedback to physicians does drive quality improvement and, building on Aim 2, explore which types of physicians may respond to feedback. Our proposal is the first to use this innovative method to measure colonoscopy quality and to use the quality scores to decrease the variation in colonoscopy performance. Together the results of the 3 aims are consistent with the NCI's focus on improving the quality of colorectal cancer screening. PUBLIC HEALTH RELEVANCE: Prior research has shown that the quality of colonoscopy varies from physician to physician. It is important to address low quality because patients who see physicians with lower quality colonoscopies have a higher risk of developing colorectal cancer in the future. To help address poor quality of colonoscopy, we propose to use a computer software program to measure colonoscopy quality, survey physicians to understand why there is variation in quality, and provide physician feedback to stimulate quality improvement.",Measuring and Improving Colonoscopy Quality Using Natural Language Processing,9025565,R01CA168959,"['Address', 'Affect', 'Cancer Etiology', 'Caring', 'Cecum', 'Cessation of life', 'Colon', 'Colonoscopy', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Detection', 'Effectiveness', 'Environment', 'Feedback', 'Future', 'Gastroenterology', 'Geographic Locations', 'Goals', 'Health', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidence', 'Knowledge', 'Link', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Natural Language Processing', 'Pathology Report', 'Patients', 'Performance', 'Physicians', 'Provider', 'Reading', 'Recommendation', 'Records', 'Reporting', 'Research', 'Risk', 'Science', 'Site', 'Societies', 'Sum', 'Surveys', 'System', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Variant', 'Work', 'adenoma', 'base', 'colorectal cancer screening', 'computer science', 'cost effective', 'high risk', 'improved', 'innovation', 'medical specialties', 'novel', 'payment', 'programs', 'screening', 'symposium', 'tool', 'trend']",NCI,HARVARD MEDICAL SCHOOL,R01,2016,409330,0.00908091989995884
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,9033918,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2016,562809,0.06520643376319431
"Crowd Sourcing Labels From Electronic Medical Records to Enable Biomedical Research ﻿    DESCRIPTION (provided by applicant): Supervised machine learning is a popular method that uses labeled training examples to predict future outcomes.  Unfortunately, supervised machine learning for biomedical research is often limited by a lack of labeled data.  Current methods to produce labeled data involve manual chart reviews that are laborious and do not scale with data creation rates.  This project aims to develop a framework to crowd source labeled data sets from electronic medical records by forming a crowd of clinical personnel labelers.  The construction of these labeled data sets will allow for new biomedical research studies that were previously infeasible to conduct.  There are numerous practical and theoretical challenges of developing a crowd sourcing platform for clinical data.  First, popular, public crowd sourcing platforms such as Amazon's Mechanical Turk are not suitable for medical record labeling as HIPAA makes clinical data sharing risky.  Second, the types of clinical questions that are amenable for crowd sourcing are not well understood.  Third, it is unclear if the clinical crowd can produce labels quickly and accurately.  Each of these challenges will be addressed in a separate Aim. As the first Aim of this project, the team will evaluate different clinical crowd sourcing architectures.  The architecture must leverage the scale of the crowd, while minimizing patient information exposure.  De-identification tools will be considered to scrub clinical notes t reduce information leakage.  Using this design, the team will extend a popular open source crowd sourcing tool, Pybossa, and release it to the public.  As the second Aim, the team will study the type, structure, topic and specificity of clinical prediction questions, and how these characteristics impact labeler quality.  Lastly, the team will evaluate the quality and accuracy of collected clinical crowd sourced data on two existing chart review problems to determine the platform's utility.         PUBLIC HEALTH RELEVANCE: Traditionally, clinical prediction models rely on supervised machine learning algorithms to probabilistically predict clinical events using labeled medical records.  When data sets are small, manual chart reviews performed by clinical staff are sufficient to label each outcome; however, as data sets have scaled up and researchers aim to study larger cohorts, current manual approaches become intractable.  The goal of this proposal is to develop a framework to crowd source labeled data sets from electronic medical records to support prediction model development.        ",Crowd Sourcing Labels From Electronic Medical Records to Enable Biomedical Research,9076555,UH2CA203708,"['Accident and Emergency department', 'Address', 'Algorithms', 'Architecture', 'Area', 'Asthma', 'Biomedical Research', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Data', 'Collection', 'Computerized Medical Record', 'Crowding', 'Data', 'Data Set', 'Development', 'Disclosure', 'Ensure', 'Evaluation', 'Event', 'Extravasation', 'Future', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Human Resources', 'Incentives', 'Interview', 'Label', 'Machine Learning', 'Management Audit', 'Manuals', 'Measures', 'Mechanics', 'Medical Records', 'Medical Research', 'Medical Students', 'Medical center', 'Methods', 'Modeling', 'Nurses', 'Outcome', 'Patients', 'Privacy', 'Productivity', 'Receiver Operating Characteristics', 'Relapse', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Security', 'Specificity', 'Structure', 'System', 'Time', 'Training', 'cohort', 'computer science', 'crowdsourcing', 'design', 'member', 'model development', 'open source', 'public health relevance', 'research study', 'response', 'scale up', 'tool']",NCI,VANDERBILT UNIVERSITY MEDICAL CENTER,UH2,2016,316000,0.03263952837251487
"Real-time detection of deviations in clinical care in ICU data streams DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our previous studies provide support that such deviations indicate clinically important events at false alert rates belo 50%, which is very promising. We propose to further improve the new methodology, and build a real-time monitoring and alerting system integrated with production electronic medical records. We propose an evaluation of the system using physicians' assessment of alerts raised by our real-time system for intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories. PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in the intensive care unit (ICU). This project develops and evaluates a new clinical monitoring and alerting framework that uses electronic medical records and machine-learning methods to send alerts concerning clinical decisions in the ICU that are unexpected given the clinical context and may represent medical errors.",Real-time detection of deviations in clinical care in ICU data streams,9095389,R01GM088224,"['Algorithms', 'Archives', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complication', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Decision Making', 'Detection', 'Development', 'Electronics', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Funding', 'Health', 'Health Personnel', 'Healthcare', 'Hospitals', 'Immunosuppressive Agents', 'Information Systems', 'Inpatients', 'Intensive Care Units', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Errors', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Oral', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Play', 'Practice Management', 'Production', 'Real-Time Systems', 'Records', 'Research', 'Research Personnel', 'Signal Transduction', 'Stream', 'System', 'Tacrolimus', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'data archive', 'design', 'improved', 'individual patient', 'knowledge base', 'learning strategy', 'liver transplantation', 'multidisciplinary', 'prototype']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2016,548500,0.045942678741332725
"Identification of Patients with Low Life Expectancy ﻿    DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9115065,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,227891,0.04629143652052455
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9147611,K01ES026833,"['Affect', 'Blood', 'Blood flow', 'Brain', 'Brain Injuries', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrovascular system', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health', 'Healthcare', 'Hemorrhage', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Rupture', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'standard of care', 'support tools', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2016,216241,0.01175148854163092
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9029656,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Phenotype', 'Philosophy', 'Process', 'Public Health', 'Research', 'Semantics', 'Solid', 'Stream', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2016,844963,0.02441992669557586
"BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO) DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's. n/a",BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO),9066173,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Assessment tool', 'Beds', 'Benchmarking', 'Big Data', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Names', 'National Institute of Child Health and Human Development', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'data visualization', 'design', 'emergency service responder', 'experience', 'genetic variant', 'genome analysis', 'genome sequencing', 'genomic data', 'improved', 'indexing', 'interoperability', 'learning strategy', 'medical information system', 'novel', 'open source', 'outcome prediction', 'parallel processing', 'performance tests', 'personalized care', 'predict clinical outcome', 'processing speed', 'reference genome', 'repository', 'research study', 'response', 'search engine', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual', 'whole genome']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R01,2016,507805,0.023453272066740274
"Leveraging advanced clinical phenotyping to enhance problem lists and support value-based healthcare Project Summary As United States healthcare seeks to address inconsistent quality and overwhelming cost, data and technology have become central to all suggested approaches. With newly available electronic health data and massive growth in processing power, the hardest challenges in using clinical data are becoming clear. Big data holds the potential to enable personalized patient care, population health management, and value-based payment models. However, it also creates challenges in discriminating accurate data from inaccurate or incomplete information. One of the greatest areas of data inaccuracy is the patient phenotype, or clinical description of the patient. Every clinical decision support tool, population health management system, and payment reform product relies on accurate electronic patient descriptions as its source data. But, the descriptions are not accurate, most notably in terms of completeness and granularity. Recall often falls below 50% in describing a patient’s medical conditions, such as heart failure and cancer. Detailed descriptions such as low ejection fraction heart failure or stage III breast cancer, needed for downstream analytics, are lacking in the discrete record. Poor data puts care delivery, payment reform, and population health efforts in peril. The time is right for technology to proactively define the clinical phenotype from source data, without reliance on current manual approaches. This will necessitate overcoming challenges in harmonizing discrepant narrative and discrete data, inferring when a characteristic such as cough is a primary condition versus symptom of another condition, and screening noise from signal in robust narrative text. This Small Business Innovation Research (SBIR) Phase I project will include the following specific aims: 1. Create the components required to define an accurate and comprehensive clinical phenotype,  including: (i) extract problem, medication, procedure, and lab features from clinical data using  natural language processing (NLP) and ontologic mapping, (ii) build a large knowledge database  of associated clinical conditions, and (iii) assess extracted features against the knowledge  database to accurately distinguish symptoms from diseases and surface relevant active diseases  in a candidate problem list. 2. Validate the clinical phenotyping components using de-identified longitudinal clinical data for  10,000 patients The goal, dependent on Phase I success, is to create an automated, accurate, and robust clinical phenotyping engine to enable personalized patient care, population health management, and value- based payment models. Project Narrative Individual and global care improvement demands accurate phenotypes. This type of clinical phenotyping is extremely challenging, requiring full clinical data and advanced semantic technologies to develop a longitudinal patient map. The approach, if successful, offers an opportunity to empower national efforts to improve outcomes and reduce costs.",Leveraging advanced clinical phenotyping to enhance problem lists and support value-based healthcare,9199039,R43LM012357,"['Address', 'Area', 'Back', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Congresses', 'Coughing', 'Data', 'Data Sources', 'Databases', 'Disease', 'EFRAC', 'Electronics', 'Funding', 'Goals', 'Government', 'Growth', 'Health system', 'Healthcare', 'Heart failure', 'Individual', 'Industry', 'Investments', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Medical', 'Medical Technology', 'Modeling', 'Natural Language Processing', 'Noise', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Principal Investigator', 'Procedures', 'Process', 'Review Literature', 'Semantics', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Staging', 'Surface', 'Symptoms', 'System', 'Technology', 'Text', 'Time', 'United States', 'Work', 'base', 'care delivery', 'clinical phenotype', 'clinical practice', 'cost', 'discrete data', 'empowered', 'experience', 'falls', 'health data', 'high risk', 'improved', 'improved outcome', 'malignant breast neoplasm', 'payment', 'personalized care', 'population health', 'screening', 'success', 'support tools']",NLM,"VMT, INC.",R43,2016,222977,-0.0076459101033951255
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk.         PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.                ",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9065021,R01AI117011,"['Accounting', 'Animals', 'Applied Research', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Taxon', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'improved', 'information model', 'interest', 'journal article', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2016,479735,0.023106330451196283
"Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients Project Summary Epilepsy is one of the leading neurological disorders in the United States, affecting more than 479,000 children and over 2 million adults. Approximately 30% of epileptic patients have poor seizure control despite antiepileptic medications and are potential candidates for neurosurgical intervention. Early identification and referral of children who are potential surgical candidates is complex and while relevant guidelines exist, there is no standard process to efficiently identify those patients meeting criteria for neurosurgical intervention. Given the large corpus of note-based data available in the electronic health record (EHR), it is challenging for providers to efficiently retain and process all the pertinent patient information. Natural Language Processing (NLP) and machine learning techniques have been successfully used to evaluate clinical notes and make recommendations in the research setting. However, NLP techniques are rarely integrated into practice to provide real-time clinical decision support. We developed and retrospectively evaluated a NLP system to help identify those patients who meet neurosurgical criteria and therefore enable surgical consults and evaluations to occur sooner. Knowing clinical decision support can improve outcomes of care, our proposed research will implement NLP into clinical practice and develop a decision support mechanism to improve the time to surgery for eligible patients. The objective of this project is to implement NLP directly into clinical care and determine the most effective decision support mechanism for provider adherence to epilepsy surgical consult recommendations. The long- term goal of this project is to reduce the time to initial surgery evaluation for patients with intractable epilepsy by integrating NLP-classification criteria into clinical practice. This project is one of the first in the field to study the integration of NLP recommendations into clinical care. We will use a human factors engineering framework to design and to analyze two different alerting methodologies for the best-fit for clinical workflow to produce the optimum provider adherence while reducing alert fatigue. Epilepsy progress notes can be classified across hospitals, and if successful, the system will be implemented in additional pediatric institutions around the United States. Project Narrative Epilepsy affects more than 479,000 children; 30% of those are not controlled with medication and may require surgery. We developed a novel Natural Language Processing (NLP) algorithm that can be integrated into neurology practice to detect patients who may be eligible for epilepsy surgical consults. Once implemented, this research can help to drive successful implementations of NLP and identify and use ideal alerting mechanisms in neurological care.",Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients,9222109,R21HS024977,[' '],AHRQ,CINCINNATI CHILDRENS HOSP MED CTR,R21,2016,137233,-0.04498197155870883
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9050675,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'abstracting', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'meetings', 'patient safety', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2016,300000,0.05271203904444639
"Semi-supervised learning with electronic medical records Project Summary/Abstract The implementation of electronic medical record (EMR) systems in routine healthcare has resulted in a rich and inexpensive source of data for translational research. When linked with specimen biobanks, these extensive databases offer a unique opportunity to accelerate the goals of disease genomics as they contain large amounts of detailed clinical and genetic data collected for the purposes of medical care [4; 6; 7; 8; 9]. However, the statistical methods to analyze EMR data are limited and thus the focus of this proposal.  In particular, extracting accurate disease phenotype information is a major challenge impeding EMR-based research [10]. Currently, ICD9 codes are used to conﬁrm presence or absence of a disease in cohorts derived from EMRs. These codes are extremely variable and therefore have a signiﬁcant impact on the statistical power of genetic studies [11; 12]. An alternative approach is to develop a highly accurate algorithm to classify disease status. But due to the laborious medical record review required to obtain validated phenotype information for classiﬁer estimation, phenotypes are only available for a small training set nested in a large cohort. In contrast, predictors of phenotype are available for all observations. To improve accuracy and efﬁciency in model estimation and evaluation, it is therefore of interest to develop semi-supervised learning (SSL) methods that utilize the so- called unlabeled data or observations without conﬁrmed phenotype status in addition to the labeled training set.  Although a great body of literature on SSL exists, nearly all methods concern estimation of classiﬁers or prediction rules when the labeled training set is a simple random sample from the large unlabeled data set [13; 14; 15; 16; 17; 18; 19; 20; 21]. Despite the practical importance of evaluating the prediction performance of an estimated model, no SSL procedures currently exist to improve the estimation of model performance parame- ters. Additionally, the simple random sampling assumption is restrictive and the development of semi-supervised (SS) methods that accommodate more ﬂexible sampling schemes in the context of both model estimation and evaluation is needed.  In this proposal, these limitations are addressed through formulation of an efﬁcient method to estimate various prediction performance measures including the ROC curve within the traditional SS framework of simple random sampling. The stratiﬁed random sampling design in the SS setting is also considered and methods to estimate a classiﬁer and its accuracy are developed. These procedures will be applied to EMR-based studies of bipolar disorder and depression. The success of this work will thus improve efﬁciency in analyzing EMR data and expedite the use of EMRs in clinical and genetic research in neuropsychiatry. Project Narrative  The use of electronic medical records (EMRs) in routine healthcare has generated a rich source of data for in-depth study of disease risk factors. However, EMR data typically consists of a very small number of expensive observations with information on disease status and a large amount of automatically extracted data concerning risk factors such as laboratory results and previous health history. Statistical methods that accommodate this data structure are limited and thus the focus of this proposal.",Semi-supervised learning with electronic medical records,9192096,F31GM119263,"['Address', 'Algorithms', 'Bipolar Depression', 'Bipolar Disorder', 'Caring', 'Clinical', 'Clinical Research', 'Code', 'Computerized Medical Record', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Disease', 'Evaluation', 'Formulation', 'Genes', 'Genetic Research', 'Genetic study', 'Genomics', 'Goals', 'Health', 'Healthcare', 'International', 'Label', 'Laboratories', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Genetics', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'ROC Curve', 'Recording of previous events', 'Research', 'Rest', 'Risk Factors', 'Sampling', 'Sampling Biases', 'Scheme', 'Specimen', 'Statistical Methods', 'System', 'Time', 'Training', 'Translational Research', 'Work', 'abstracting', 'base', 'biobank', 'clinical care', 'clinical practice', 'clinically relevant', 'cohort', 'cost effective', 'data structure', 'design', 'disease phenotype', 'disorder risk', 'experience', 'improved', 'interest', 'learning strategy', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'patient population', 'phenome', 'repository', 'success']",NIGMS,HARVARD SCHOOL OF PUBLIC HEALTH,F31,2016,34098,0.030836338113710886
"Challenges in Natural Language Processing in Clinical Text No abstract available Challenges in Natural Language Processing for Clinical Narratives Narrative: This project aims to organize a series of shared task challenges that open electronic health records to the research community for advancing the state of the art in natural language processing in clinical records. The proposed shared tasks are complemented by workshops, conference proceedings, and journal special issues that aim to disseminate the knowledge generated by the challenges.",Challenges in Natural Language Processing in Clinical Text,9597333,R13LM011411,[' '],NLM,GEORGE MASON UNIVERSITY,R13,2016,20000,-0.02223535586578122
"Development and Evaluation of a Learning Electronic Medical Record System ﻿    DESCRIPTION (provided by applicant):  The goal of this project to develop and evaluate a learning electronic medical records (L-EMR) system that draws a physician's attention to the right data, at the right time. It learns how to do so by analyzing patterns of patient data access f many physicians in many past cases in the EMR, and learning which EMR data to highlight that are relevant for making clinical decisions in a given patient.      The hypothesis underlying this research is that the L-EMR system will have sufficiently high precision and recall in highlighting relevant data, decrease the average time to assess an intensive care unit (ICU) patient case, and be judged by critical care medicine (CCM) physicians to be clinically useful.    The first aim of this project is develop a highly-usable L-EMR user interface. The L-EMR user interface will include zoomable time-series displays of lab-results, med-orders, and vital signs. Usability studies of the L-EMR user interface will guide revisions and enhancements.      The second aim of the project is to train statistical models that can be applied to a patient case to predict relevant lab-results, med-orders, and vital signs. We will enlist CCM physicians to review a set of retrospective ICU patient cases on a focused set of clinical conditions. Participants will review these cases as if they were active patients, identifying relevant lab- results, med-orders, and vital signs. We will train and evaluate statistical models to predict relevant data, and identify the best performing algorithm to include in the L-EMR system.      The third aim of the project is to evaluate the L-EMR system. We will recruit CCM physicians to evaluate an L-EMR system based on user interfaces from Aim 1 and statistical models trained using the best performing algorithm in Aim 2 to highlight relevant data items. We will measure the precision and recall of the data-highlighting functionality for assessing patient cases and making clinical decisions (e.g., lab and medication orders), the time required to assess cases with and without the highlighting, and physicians' assessments of the strengths and weaknesses of the L-EMR system.    If the results of these experiments are positive, as anticipated, this project will introduce a computational method that has significant potential to improve future EMR systems and enhance patient care. Narrative The purpose of this research is to develop and evaluate a learning electronic medical records (EMR) system that draws a physician's attention to the right data, at the right time. The system works by analyzing patterns of EMR usage of physicians, and learning which EMR data to highlight that are relevant in a given patient. The main idea underlying the approach is that patterns of past EMR usage patterns can be exploited to selectively highlight clinically useful patient data.",Development and Evaluation of a Learning Electronic Medical Record System,9144440,R01LM012095,"['Address', 'Adult', 'Algorithms', 'American', 'Attention', 'Bayesian Modeling', 'Blood', 'Caring', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Computerized Medical Record', 'Computing Methodologies', 'Critical Care', 'Critical Illness', 'Data', 'Data Display', 'Data Set', 'Development', 'Educational workshop', 'Evaluation', 'Face', 'Future', 'Gastrointestinal Hemorrhage', 'Goals', 'Healthcare Systems', 'Heart Rate', 'Hemoglobin', 'Individual', 'Information Systems', 'Institute of Medicine (U.S.)', 'Intensive Care Units', 'Intravenous', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Participant', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Physiological', 'Provider', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Series', 'Statistical Models', 'System', 'Test Result', 'Time', 'Training', 'Work', 'base', 'clinical decision-making', 'computer human interaction', 'data access', 'design', 'follow-up', 'improved', 'prototype', 'research clinical testing', 'research study', 'stem', 'trend', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2016,424376,0.05036895570030398
"NLP to Improve Accuracy and Quality of Dictated Medical Documents ﻿    DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005). PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9146893,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,249994,0.03797305076177993
"Scalable EEG interpretation using Deep Learning and Schema Descriptors ﻿    DESCRIPTION (provided by applicant): Electronic medical records (EMRs) collected at every hospital in the country collectively contain a staggering wealth of biomedical knowledge. EMRs can include unstructured text, temporally constrained measurements (e.g., vital signs), multichannel signal data (e.g., EEGs), and image data (e.g., MRIs). This information could be transformative if properly harnessed. Information about patient medical problems, treatments, and clinical course is essential for conducting comparative effectiveness research. Uncovering clinical knowledge that enables comparative research is the primary goal of this proposal. We will focus on the automatic interpretation of clinical EEGs collected over 12 years at Temple University Hospital (over 25,000 sessions and 15,000 patients). Clinicians will be able to retrieve relevant EEG signals and EEG reports using standard queries (e.g. ""Young patients with focal cerebral dysfunction who were treated with Topamax""). In Aim 1 we will automatically annotate EEG events that contribute to a diagnosis. We will develop automated techniques to discover and time-align the underlying EEG events using semi-supervised learning. In Aim 2 we will process the text from the EEG reports using state-of-the-art clinical language processing techniques. Clinical concepts, their type, polarity and modality shall be discovered automatically, as well as spatial and temporal information. In addition, we shall extract the medical concepts describing the clinical picture of patients from the EEG reports. In Aim 3, we will develop a patient cohort retrieval system that will operate on the clinical knowledge extracted in Aims 1 and 2. In addition we shall organize this knowledge in a unified representation: the Qualified Medical Knowledge Graph (QMKG), which will be built using BigData solutions through MapReduce. The QMKG will be able to be searched by biomedical researchers as well as practicing clinicians. The QMKG will also provide a characterization of the way in which events in an EEG are narrated by physicians and the validation of these across a BigData resource. The EMKG represents an important contribution to basic science. In Aim 4 we will validate the usefulness of the patient cohort identification system by collecting feedback from clinicians and medical students who will participate in a rigorous evaluation protocol. Inclusion and exclusion criteria for the queries shall be designed and experts will provide relevance judgments for the results. For each query, medical experts shall examine the top-ranked cohorts for common precision errors (false positives) and the bottom five ranked common recall errors (false negatives). User validation testing will be performed using live clinical data and the feedback wil enhance the quality of the cohort identification system. The existence of an annotated BigData archive of EEGs will greatly increase accessibility for non- experts in neuroscience, bioengineering and medical informatics who would like to study EEG data. The creation of this resource through the development of efficient automated data wrangling techniques will demonstrate that a much wider range of BigData bioengineering applications are now tractable. PUBLIC HEALTH RELEVANCE: The primary goal of this proposal is to enable comparative research by automatically uncovering clinical knowledge from a vast BigData archive of clinical EEG signals and EEG reports collected over the past 12 years at Temple University Hospital. In the proposed project, we will develop a proof-of-concept based on the discovery of patient cohorts and provide an annotated BigData archive as well as the software that enabled the annotations and the generation of the patient cohort retrieval system. This resource will be accompanied by a novel medical knowledge representation generated with MapReduce, greatly increasing accessibility for non- experts in neuroscience, bioengineering and medical informatics, and demonstrating the transformative potential of mining the staggering wealth of biomedical knowledge available in hospital medical records.",Scalable EEG interpretation using Deep Learning and Schema Descriptors,9243724,U01HG008468,"['Accident and Emergency department', 'Archives', 'Area', 'Basic Science', 'Big Data', 'Bilateral', 'Biomedical Engineering', 'Blinking', 'Cerebrum', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Treatment', 'Code', 'Comparative Study', 'Computer software', 'Computerized Medical Record', 'Country', 'Data', 'Descriptor', 'Development', 'Diagnosis', 'Diffuse', 'Discharge from eye', 'Electroencephalography', 'Epilepsy', 'Evaluation', 'Event', 'Exclusion Criteria', 'Feedback', 'Frequencies', 'Functional disorder', 'Generations', 'Goals', 'Graph', 'Health', 'Hospitals', 'Image', 'Judgment', 'Knowledge', 'Language', 'Learning', 'Life', 'Link', 'Measurement', 'Medical', 'Medical Informatics', 'Medical Records', 'Medical Students', 'Mining', 'Modality', 'Modeling', 'Morphologic artifacts', 'Multimedia', 'Nature', 'Neurosciences', 'Outcome', 'Patients', 'Pattern', 'Physicians', 'Process', 'Protocols documentation', 'Qualifying', 'Reporting', 'Research', 'Research Personnel', 'Research Support', 'Resources', 'Retrieval', 'Role', 'Signal Transduction', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'University Hospitals', 'Validation', 'base', 'career', 'cohort', 'comparative', 'comparative effectiveness', 'data archive', 'data wrangling', 'design', 'effectiveness research', 'inclusion criteria', 'information organization', 'language processing', 'novel', 'repository']",NHGRI,TEMPLE UNIV OF THE COMMONWEALTH,U01,2016,374745,0.014294517775012883
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,9120230,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2016,425000,-0.0010793700081888563
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9144757,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,249135,0.04081266129569819
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,9068953,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Health', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'genomic data', 'improved', 'large-scale database', 'novel', 'open source', 'personalized medicine', 'rapid growth', 'rare variant', 'response', 'study population', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2016,536892,0.01833216900285443
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,8936515,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Solutions', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'model building', 'model development', 'novel', 'open source', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,448348,0.02689385490793908
"Identification of patients with diabetes at high risk for treatment failure ﻿    DESCRIPTION (provided by applicant):  The overall goal of this project is to improve quality of care of patients with diabetes by identifying patients who may have particular difficulty reaching treatment targets and who could therefore potentially benefit from additional resources. Investigators propose to achieve this goal by developing a technology to accurately identify patients at high risk for not reaching blood glucose target to enable cost-effective implementation of resource-intensive interventions that improve glycemic control in high-risk individuals.  Improving blood glucose control in patients with diabetes could both improve their quality of life by reducing diabetes complications and decrease costs. Some patients that face particularly high barriers to glucose control may benefit from additional resources that are too expensive to apply to broad patient populations. However, it is not currently possible to identify patients at high risk not being able to reach blood glucose targets with sufficient accuracy to make these interventions cost-effective.  One reason for this is that a large fraction of critical information about the patients' functional status, social circumstances and other important factors that may present barriers to glucose control is only found in narrative documents, from which it is difficult to extract. Furthermore, the amount of information about any single patient i the medical record is enormous, and is impossible to process efficiently using standard analytical algorithms such as regression analysis.  In the proposed project investigators will combine two novel technologies - natural language processing of electronic provider notes and artificial intelligence technology Dynamic Logic - to help circumvent these challenges to build a high-accuracy model of risk of not being able to reach blood glucose targets in patients with diabetes. Natural language processing will identify key concepts documented in the provider notes and will help translate their text into a compendium of facts about the patient. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will therefore allow to greatly increasing the number of factors / variables that can be considered for the models for prediction of failure to reach glucose control, and ultimately improve their accuracy. Consequently this translational multidisciplinary project will both advance our understanding of the risk factors for not being able to reach glucose control for patients with diabetes and assist in real-life implementation of interventions that can help lower their blood glucose, decrease the rate of diabetes complications, improve the patients' quality of life and help control the rising costs of healthcare.         PUBLIC HEALTH RELEVANCE:  Lowering blood glucose of patients with diabetes could both improve their quality of life and reduce healthcare costs, but may be more difficult for some patients than others. Patients who have particularly high barriers to blood glucose control could benefit from extra resources, but it can be challenging to identify them in advance. In this projec the investigators will combine advanced computational technologies including artificial intelligence and natural language processing to identify patients with diabetes at high risk for difficulty lowering blood glucose to help make commitment of additional resources cost-effective.                ",Identification of patients with diabetes at high risk for treatment failure,8902473,R41DK105612,"['Adult', 'Algorithms', 'Artificial Intelligence', 'Blood Glucose', 'Cardiovascular Diseases', 'Caring', 'Complications of Diabetes Mellitus', 'Computerized Medical Record', 'Counseling', 'Data', 'Data Analyses', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Electronics', 'Epidemic', 'Face', 'Failure', 'Fee-for-Service Plans', 'Glucose', 'Glycosylated hemoglobin A', 'Goals', 'Growth', 'Guidelines', 'Health', 'Health Care Costs', 'Health Personnel', 'Healthcare', 'Incentives', 'Individual', 'Intervention', 'Kidney Failure', 'Language', 'Life', 'Life Style', 'Logic', 'Logistic Regressions', 'Medical', 'Medical Records', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Neuropathy', 'Outcome', 'Patient Care', 'Patients', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Prevalence', 'Process', 'Provider', 'Quality of Care', 'Quality of life', 'Regression Analysis', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Translating', 'Transportation', 'Treatment Failure', 'analytical method', 'base', 'blood glucose regulation', 'combinatorial', 'commercial application', 'cost', 'cost effective', 'functional status', 'glycemic control', 'high risk', 'improved', 'mortality', 'multidisciplinary', 'new technology', 'patient population', 'public health relevance', 'social']",NIDDK,LP INFORMATION TECHNOLOGY,R41,2015,223336,0.013574848757537773
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,8928647,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2015,376327,0.04577050537011789
"Measuring and Improving Colonoscopy Quality Using Natural Language Processing DESCRIPTION (provided by applicant):  Colonoscopy is the predominant method for screening for colorectal cancer in the US. Yet, its effectiveness in screening is limited by variation in performance. For example, the rate at which physicians detect cancer precursors called adenomas during a colonoscopy has been shown to vary three-fold from one physician to another. A patient whose colonoscopy is performed by a physician with a low adenoma detection rate has a higher risk of subsequent colorectal cancer.  Our proposal centers on measuring, understanding, and improving colonoscopy quality. The major innovation of this work is to use natural language processing (NLP) to measure the quality of colonoscopy. NLP is a field of computer science in which a computer is trained to ""read"" text to identify relevant data We developed and validated the first NLP-based computer software application (C-QUAL) that analyzes colonoscopy and associated pathology reports. Our primary quality measure is adenoma detection rate because it is a common, validated measure that is linked to colorectal cancer incidence. However, we also use a number of secondary quality measures. We applied C-QUAL to almost 25,000 colonoscopy reports in one health system and found large variation in physician's performance on the quality measures. Building on this prior work, our goal is to use C-QUAL to measure colonoscopy quality across a spectrum of US practice environments, to understand what drives variation in colonoscopy quality, and to improve colonoscopy quality. In Aim 1, we propose to use the C-QUAL tool to measure performance in 4 diverse health care systems. This will be one of the largest assessments of the variation in adenoma detection rates and will span different geographic regions, payment systems, and practice settings. In Aim 2, we seek to understand why there is variation in quality. We will survey providers at the 4 health care systems about factors that might affect quality. We will link those survey results to the adenoma detection rates assessed in Aim 1 and look for key associations. It is assumed, but not proven, that providing feedback to physicians on colonoscopy quality will improve care. In Aim 3, we assess whether feedback to physicians does drive quality improvement and, building on Aim 2, explore which types of physicians may respond to feedback. Our proposal is the first to use this innovative method to measure colonoscopy quality and to use the quality scores to decrease the variation in colonoscopy performance. Together the results of the 3 aims are consistent with the NCI's focus on improving the quality of colorectal cancer screening. PUBLIC HEALTH RELEVANCE: Prior research has shown that the quality of colonoscopy varies from physician to physician. It is important to address low quality because patients who see physicians with lower quality colonoscopies have a higher risk of developing colorectal cancer in the future. To help address poor quality of colonoscopy, we propose to use a computer software program to measure colonoscopy quality, survey physicians to understand why there is variation in quality, and provide physician feedback to stimulate quality improvement.",Measuring and Improving Colonoscopy Quality Using Natural Language Processing,8830936,R01CA168959,"['Address', 'Affect', 'Cancer Etiology', 'Caring', 'Cecum', 'Cessation of life', 'Colon', 'Colonoscopy', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Detection', 'Effectiveness', 'Environment', 'Feedback', 'Future', 'Gastroenterology', 'Geographic Locations', 'Goals', 'Health', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidence', 'Knowledge', 'Link', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Natural Language Processing', 'Pathology Report', 'Patients', 'Performance', 'Physicians', 'Provider', 'Reading', 'Recommendation', 'Records', 'Reporting', 'Research', 'Risk', 'Science', 'Site', 'Societies', 'Sum', 'Surveys', 'System', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Variant', 'Work', 'adenoma', 'base', 'colorectal cancer screening', 'computer science', 'cost effective', 'high risk', 'improved', 'innovation', 'medical specialties', 'novel', 'payment', 'programs', 'screening', 'symposium', 'tool', 'trend']",NCI,HARVARD MEDICAL SCHOOL,R01,2015,494533,0.00908091989995884
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,8826771,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2015,571551,0.06520643376319431
"IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC) This study seeks to leverage electronic pathology (ePath) reports through NLP and machine learning methods to automate the annotation of NSCLC lung cases with results from EGFR and ALK gene mutation testing.  Objectives:  1)	Develop and implement machine-learned predictive NLP models to automatically process ePath reports to ascertain the use of and reported results of EGFR and ALK testing in stage IV non-squamous NSCLC cases.   2)	Conduct a multiphase validation study of the NLP algorithms initially involving cases included in the Kentucky SEER registry, and posteriorly validating the algorithms for cases in the Seattle_Puget Sound SEER registry. 3)	Develop and evaluate an open source, distributable software implementation of the NLP algorithms, an accompanying application programming interface (API), and documentation that can be integrated into SEER*DMS and other registry software applications. n/a",IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC),9161889,61201300013I,"['ALK gene', 'Algorithms', 'Automated Annotation', 'Computer software', 'Documentation', 'EGFR gene', 'Electronics', 'Epidermal Growth Factor Receptor', 'Gene Mutation', 'Kentucky', 'Lung', 'Machine Learning', 'Methods', 'Modeling', 'Molecular Profiling', 'Non-Small-Cell Lung Carcinoma', 'Pathology Report', 'Process', 'Registries', 'Reporting', 'Staging', 'Testing', 'c-erbB-1 Proto-Oncogenes', 'open source', 'programs', 'sound', 'validation studies']",NCI,UNIVERSITY OF KENTUCKY,N01,2015,87813,-0.03945415648974119
"IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC). The overarching goal of this research proposal is to develop and validate Natural Language Processing (NLP) algorithms for ascertainment of use, results, and techniques employed for EGFR and ALK testing, respectively, from SEER electronic pathology reports of stage IV non-squamous NSCLC cases.  Successful achievement of this goal will occur through the accomplishment of the study objectives outlined below.  Objectives: 1)	 Develop Natural Language Processing (NLP) algorithms to ascertain use, results, and techniques employed for EGFR and ALK testing, respectively, from SEER electronic pathology reports of stage IV non-squamous NSCLC registry cases diagnosed between 09/01/2011 and 12/31/2013. 2)	Conduct a multiphase validation study of NLP algorithms for ascertainment of EGFR and ALK testing initially involving cases included in the Seattle Puget-Sound SEER registry, and posteriorly validating the NLP algorithms in the Kentucky SEER registry. n/a",IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC).,9161888,61201300012I,"['Achievement', 'Algorithms', 'Cells', 'Diagnosis', 'Electronics', 'Epidermal Growth Factor Receptor', 'Goals', 'Kentucky', 'Lung', 'Molecular Profiling', 'Natural Language Processing', 'Non-Small-Cell Lung Carcinoma', 'Pathology Report', 'Registries', 'Research Proposals', 'Staging', 'Techniques', 'Testing', 'neoplasm registry', 'sound', 'validation studies']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,N01,2015,156435,0.020560938057464583
"Real-time detection of deviations in clinical care in ICU data streams DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our previous studies provide support that such deviations indicate clinically important events at false alert rates belo 50%, which is very promising. We propose to further improve the new methodology, and build a real-time monitoring and alerting system integrated with production electronic medical records. We propose an evaluation of the system using physicians' assessment of alerts raised by our real-time system for intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories. PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in the intensive care unit (ICU). This project develops and evaluates a new clinical monitoring and alerting framework that uses electronic medical records and machine-learning methods to send alerts concerning clinical decisions in the ICU that are unexpected given the clinical context and may represent medical errors.",Real-time detection of deviations in clinical care in ICU data streams,8912480,R01GM088224,"['Algorithms', 'Archives', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complication', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Decision Making', 'Detection', 'Development', 'Electronics', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Funding', 'Health', 'Health Personnel', 'Healthcare', 'Hospitals', 'Immunosuppressive Agents', 'Individual', 'Information Systems', 'Inpatients', 'Intensive Care Units', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Errors', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Oral', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Play', 'Practice Management', 'Production', 'Real-Time Systems', 'Records', 'Relative (related person)', 'Research', 'Research Personnel', 'Signal Transduction', 'Solutions', 'Stream', 'System', 'Tacrolimus', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'design', 'improved', 'knowledge base', 'liver transplantation', 'multidisciplinary', 'prototype']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2015,583203,0.045942678741332725
"Identification of Patients with Low Life Expectancy ﻿    DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death.         PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.            ",Identification of Patients with Low Life Expectancy,8942806,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,232521,0.04629143652052455
"Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage ﻿    DESCRIPTION (provided by applicant)    Subarachnoid Hemorrhage (SAH) affects an estimated 14.5 per 100,000 persons in the United States, and is a substantial burden on health care resources, because it can cause long-term functional and cognitive disability. Much of this is due to delayed cerebral ischemia (DCI) from vasospasm (VSP). VSP refers to the reactive narrowing of cerebral blood vessels due the unusual presence of blood surrounding the vessel. In its extreme, severe VSP precludes blood flow to brain tissue, resulting in stroke.  SAH is one of the most common disease entities treated in the Neurointensive Care Unit (NICU). Currently, resource planning is scripted around the Modified Fisher Scale, which predicts the odds ratio of developing DCI based on the volume and pattern of blood on initial brain computed tomography (CT). It does not, however, allow for further individualized risk assessments. The first 14 days are occupied by efforts to detect preclinical or early VSP and arrange timely interventions to prevent permanent injury. The only noninvasive tool supported by guidelines to potentially identify preclinical VSP is the transcrania Doppler (TCD), which has an unreliable range of sensitivity and negative predictive values, and is at the mercy of technician availability. If not identified preclinically, VSP must be detected once it is symptomatic and is then dependent on quality and availability of expertise in the complex and diurnal environment of the ICU.  Promisingly, electronic medical record (EMR) data and continuous physiology monitors offer abundant opportunities to risk stratify for future events as well as reveal events in real-time in the acutely brain injured patient. A methodical approach to feature engineering will be performed over a large set of potentially discriminatory data-driven and knowledge-based features. Meta-features representing variations and trends in time series variables will be extracted using a variety of quantitative and symbolic abstraction techniques. Predictive modeling will be performed using Naïve Bayes, Logistic Regression, and Support Vector Machine.  This project will result in a prediction tool that improves timeliness and precision in VSP classification. It will fill an important gap in the understanding of the potentia of underutilized EMR and physiological data to predict neurological decline. Generating accurate and timely prediction rules from already collected clinical data would be cost effective and have implications not only for SAH patients, but also for almost any monitored patient in any ICU. PUBLIC HEALTH RELEVANCE    This project will explore the optimal methods for creating a prediction tool that improves timeliness and precision of diagnosis. It will fill an important gap in the understanding of the underutilized potential of electronic medical record and high frequency device monitor data. Generating timely and accurate prediction rules from already collected clinical data would be cost effective and have implications for almost any monitored patient in any ICU.",Multiparametric Prediction of Vasospasm after Subarachnoid Hemorrhage,9044336,K01ES026833,"['Affect', 'Blood', 'Blood Vessels', 'Blood flow', 'Brain', 'Caring', 'Cerebral Aneurysm', 'Cerebral Ischemia', 'Cerebrum', 'Classification', 'Clinical', 'Clinical Data', 'Coagulation Process', 'Coma', 'Complex', 'Computerized Medical Record', 'Cost Savings', 'Data', 'Detection', 'Development Plans', 'Diagnosis', 'Disease', 'Engineering', 'Environment', 'Event', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Guidelines', 'Health', 'Healthcare', 'Hemorrhage', 'Injury', 'Intervention', 'Ischemic Penumbra', 'Knowledge', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Mentorship', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Neurologic', 'Odds Ratio', 'Outcome', 'Patient Care', 'Patient Discharge', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Persons', 'Physicians', 'Physiological', 'Physiology', 'Predictive Value', 'Process', 'Resources', 'Risk', 'Risk Assessment', 'Rupture', 'Series', 'Stroke', 'Subarachnoid Hemorrhage', 'Symptoms', 'Techniques', 'Time', 'Time Series Analysis', 'Training', 'United States', 'Variant', 'Vasospasm', 'X-Ray Computed Tomography', 'base', 'brain tissue', 'career development', 'clinical decision-making', 'cognitive disability', 'cohort', 'cost effective', 'data mining', 'functional disability', 'high risk', 'improved', 'injured', 'instrument', 'knowledge base', 'monitoring device', 'multidisciplinary', 'pre-clinical', 'predictive modeling', 'prevent', 'standard of care', 'tool', 'trend']",NIEHS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2015,216241,0.01175148854163092
"BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO)     DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's.              n/a",BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO),8840825,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Beds', 'Benchmarking', 'Big Data', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Child health care', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Development', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Names', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'data visualization', 'design', 'emergency service responder', 'experience', 'genetic variant', 'genome analysis', 'genome sequencing', 'improved', 'indexing', 'interoperability', 'medical information system', 'novel', 'open source', 'parallel processing', 'performance tests', 'processing speed', 'repository', 'research study', 'response', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R01,2015,529458,0.023453272066740274
"Using NLP to Extract Clinically Important Recommendations from Radiology Reports  Abstract Communication of clinically important follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology follow-up recommendations is an important barrier to ensuring timely follow-up of patients, especially for non-acute but potentially life threatening and unexpected findings. The primary goal of this proposal is to develop a Natural Language Processing (NLP) system to extract clinically important recommendation information from free-text radiology reports. Each radiology report will be preprocessed at the structural, syntactic, and semantic level to generate features that will be used to extract the boundaries of sentences that include recommendation information as well as the details of reason for recommendation, requested imaging test, and recommendation time frame. We will use a large corpus of free-text radiology reports represented by a mixture of modalities (e.g., radiography, computed tomography, ultrasound, and magnetic resonance imaging (MRI)) from three different institutions. Using this dataset we will perform the following specific aims: Aim 1. Create a multi- institutional radiology report corpus annotated for clinically important recommendation information; Aim 2. Develop a novel NLP system to extract clinically important recommendations in radiology reports. The proposed research is innovative because it will generate a new text processing approach that can be used to flag reports visually and electronically so that separate workflow processes can be initiated to reduce the chance that necessary investigations or interventions suggested in the report are missed by clinicians. The proposed set of tools will be disseminated to the biomedical informatics community as open source tools. PUBLIC HEALTH RELEVANCE: Communication of recommendations for necessary investigations and interventions when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. We propose to build natural language processing tools to automatically extract clinically important recommendation information from radiology reports.                ",Using NLP to Extract Clinically Important Recommendations from Radiology Reports,8804856,R21EB016872,"['Academic Medical Centers', 'Address', 'Adopted', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computerized Medical Record', 'Data Set', 'Dependency', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Funding', 'Future', 'Goals', 'Gold', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Imaging technology', 'Incidental Findings', 'Institution', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Lung nodule', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medical center', 'Methods', 'Modality', 'Natural Language Processing', 'Outcome', 'Output', 'Patient Care', 'Patients', 'Persons', 'Process', 'Provider', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Risk', 'Safety', 'Semantics', 'Shapes', 'Societies', 'Specific qualifier value', 'Speech', 'System', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Ultrasonography', 'Unified Medical Language System', 'Washington', 'Writing', 'X-Ray Computed Tomography', 'biomedical informatics', 'cancer care', 'care delivery', 'design', 'falls', 'follow-up', 'health care delivery', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'phrases', 'public health relevance', 'radiologist', 'screening', 'syntax', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R21,2015,217500,0.025341166075928526
"Secondary use of EMRs for surgical complication surveillance     DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.                ",Secondary use of EMRs for surgical complication surveillance,8798027,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'abstracting', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'meetings', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2015,299888,0.05271203904444639
"Worcester Heart Attack Study DESCRIPTION (provided by applicant): This population-based study proposes to continue the examination of changing long-term trends in the descriptive epidemiology of acute myocardial infarction (AMI) and out-of hospital deaths due to coronary heart disease (CHD) in residents of the Worcester, MA, metropolitan area. The specific objectives of this population- based study are to examine contemporary (2013 and 2015), as compared with prior (1975-2011), trends in the annual incidence and attack rates of AMI, hospital and post-discharge survival rates, management practices, and out-of-hospital deaths attributed to CHD. To accomplish these and several additional secondary study objectives, this investigation will be carried out in the 11 acute care general hospitals providing care for residents of central Massachusetts. All new (incident) and recurrent episodes of definite AMI occurring in greater Worcester residents during 2013 and 2015 will be identified from discharge diagnostic printouts obtained from all metropolitan Worcester hospitals of patients with a primary or secondary discharge diagnosis of AMI and related CHD rubrics. The medical records of these patients will be individually reviewed for validation purposes according to pre-established criteria for AMI. Abstraction of the medical records of patients satisfying the study diagnostic and geographic eligibility criteria will be carried out by trained physicians with the recording of demographic, clinical, treatment, and outcomes related data. A review of records for additional hospitalizations and a search of death certificates will be carried out to examine the long-term survival status of discharged hospital patients from each of the proposed 2 study years, as well as those identified previously, through 2017. Death certificates will be reviewed to identify cases of out-of-hospital deaths attributed to CHD occurring during 2013 and 2015. In addition, we will assess the feasibility of carrying out an innovative approach for ""real time"" surveillance of acute coronary disease in this central MA population through the development of natural language processing systems that will automatically extract clinical information from electronic medical records in our most recently hospitalized patient cohort in 2015. Monitoring contemporary trends in our principal study outcomes remains timely given the ongoing publication and dissemination of treatment guidelines and recommendations by national agencies and emphasis on improving quality in processes of care. Given the ""real world"" setting of this investigation, important contemporary insights would be provided into current gaps between ideal and achieved patient care in the broader community setting, to assist in the development of novel educational approaches and incentives to provide more optimal patient care. The results of this investigation will provide important insights from a 40 year (1975-2015) vantage point about the magnitude of, mortality from, and treatment approaches used in the management of the nation's leading cause of death as it affects residents of a large New England metropolitan area. PUBLIC HEALTH RELEVANCE: The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Worcester Heart Attack Study,9130442,R56HL035434,"['Accident and Emergency department', 'Acute', 'Acute myocardial infarction', 'Affect', 'Aftercare', 'Age', 'Area', 'Behavior', 'Cardiac', 'Caring', 'Case Fatality Rates', 'Cause of Death', 'Cessation of life', 'Clinical', 'Clinical Treatment', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Death Certificates', 'Descriptive Epidemiology', 'Development', 'Diagnosis', 'Diagnostic', 'Eligibility Determination', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'General Hospitals', 'Guidelines', 'Health', 'Hospital Administration', 'Hospitalization', 'Hospitals', 'Incentives', 'Incidence', 'Investigation', 'Massachusetts', 'Medical', 'Medical Records', 'Medical center', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'Natural Language Processing', 'New England', 'Outcome', 'Outcome Study', 'Patient Care', 'Patient Discharge', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Population', 'Practice Management', 'Process', 'Public Health', 'Publications', 'Recommendation', 'Records', 'Recurrence', 'Risk', 'Source', 'Survival Rate', 'Symptoms', 'System', 'Therapeutic', 'Time', 'Training', 'Treatment outcome', 'Update', 'Validation', 'Work', 'base', 'care seeking', 'cohort', 'community setting', 'experience', 'follow-up', 'health care service utilization', 'improved', 'innovation', 'insight', 'metropolitan', 'mortality', 'novel', 'outcome forecast', 'population based', 'prospective', 'secondary outcome', 'sex', 'treatment strategy', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R56,2015,724600,-0.0011161414433039697
"Development and Evaluation of a Learning Electronic Medical Record System ﻿    DESCRIPTION (provided by applicant):  The goal of this project to develop and evaluate a learning electronic medical records (L-EMR) system that draws a physician's attention to the right data, at the right time. It learns how to do so by analyzing patterns of patient data access f many physicians in many past cases in the EMR, and learning which EMR data to highlight that are relevant for making clinical decisions in a given patient.      The hypothesis underlying this research is that the L-EMR system will have sufficiently high precision and recall in highlighting relevant data, decrease the average time to assess an intensive care unit (ICU) patient case, and be judged by critical care medicine (CCM) physicians to be clinically useful.    The first aim of this project is develop a highly-usable L-EMR user interface. The L-EMR user interface will include zoomable time-series displays of lab-results, med-orders, and vital signs. Usability studies of the L-EMR user interface will guide revisions and enhancements.      The second aim of the project is to train statistical models that can be applied to a patient case to predict relevant lab-results, med-orders, and vital signs. We will enlist CCM physicians to review a set of retrospective ICU patient cases on a focused set of clinical conditions. Participants will review these cases as if they were active patients, identifying relevant lab- results, med-orders, and vital signs. We will train and evaluate statistical models to predict relevant data, and identify the best performing algorithm to include in the L-EMR system.      The third aim of the project is to evaluate the L-EMR system. We will recruit CCM physicians to evaluate an L-EMR system based on user interfaces from Aim 1 and statistical models trained using the best performing algorithm in Aim 2 to highlight relevant data items. We will measure the precision and recall of the data-highlighting functionality for assessing patient cases and making clinical decisions (e.g., lab and medication orders), the time required to assess cases with and without the highlighting, and physicians' assessments of the strengths and weaknesses of the L-EMR system.    If the results of these experiments are positive, as anticipated, this project will introduce a computational method that has significant potential to improve future EMR systems and enhance patient care.             Narrative The purpose of this research is to develop and evaluate a learning electronic medical records (EMR) system that draws a physician's attention to the right data, at the right time. The system works by analyzing patterns of EMR usage of physicians, and learning which EMR data to highlight that are relevant in a given patient. The main idea underlying the approach is that patterns of past EMR usage patterns can be exploited to selectively highlight clinically useful patient data.",Development and Evaluation of a Learning Electronic Medical Record System,9030245,R01LM012095,"['Address', 'Adult', 'Algorithms', 'American', 'Attention', 'Bayesian Modeling', 'Blood', 'Caring', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Computerized Medical Record', 'Computing Methodologies', 'Critical Care', 'Critical Illness', 'Data', 'Data Display', 'Data Set', 'Development', 'Educational workshop', 'Evaluation', 'Face', 'Future', 'Goals', 'Healthcare Systems', 'Heart Rate', 'Hemoglobin', 'Hemorrhage', 'Individual', 'Information Systems', 'Institute of Medicine (U.S.)', 'Intensive Care Units', 'Intravenous', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Participant', 'Patient Care', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Physiological', 'Provider', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Series', 'Statistical Models', 'System', 'Test Result', 'Time', 'Training', 'Work', 'base', 'clinical decision-making', 'computer human interaction', 'design', 'follow-up', 'gastrointestinal', 'improved', 'prototype', 'research clinical testing', 'research study', 'stem', 'trend', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2015,447973,0.05036895570030398
"NLP to Improve Accuracy and Quality of Dictated Medical Documents ﻿    DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005).         PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.            ",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9004939,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,250000,0.03797305076177993
"Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD) DESCRIPTION (provided by applicant): Dr. Khaled Abdel-Kader has completed prior training in nephrology and a master's in medical education with formal training in adult learning, medical errors, and cognitive theory as well as introductory coursework in clinical research and biostatistics. His primary research interest is characterizing and addressing chronic kidney disease (CKD) care deficiencies in the primary care setting. He has received individual post-doctoral funding to support his work in this area. His career goal is to become an expert in CKD epidemiology and an independent clinical investigator studying electronic medical record (EMR)-based interventions to improve CKD care and outcomes. In this career development award (CDA), he focuses on improving primary care physician (PCP) screening for CKD. This award provides him with mentorship, formal coursework, and hands-on experience in epidemiology, research design, medical informatics, decision analysis, health services research, and biostatistics. He has assembled a group of highly skilled mentors who will guide him and help him develop into an independent clinical investigator. A supportive research environment that has already cultivated the development of numerous successful independent clinical investigators complements these individual mentors. In addition, unique institutional resources including a well-developed EMR, EMR research infrastructure, and large patient base make the local environment an ideal setting for the candidate and his research. Dr. Abdel- Kader will use these research experiences, coursework, mentorship, and institutional resources and commitment to continue his progression to becoming an independently funded clinical researcher. An important element of the application is the candidate's research proposal. He will conduct his research project in 2 phases. In the first phase, he will leverage the local, well-developed EMR database and the University of Pittsburgh's large ambulatory patient base (>450,000 unique patients in the prior 2 years) to develop a decision tree predictive model to identify patients at high risk for CKD without the use of serum chemistries. He will compare the performance of the decision tree model to a prominent, recently developed logistic regression model of CKD risk. After identifying the model with the best performance, the candidate will conduct a randomized controlled trial of PCPs examining the effect of implementing the CKD predictive model in the EMR as a clinical alert versus usual care. The clinical alert will remind PCPs to screen high-risk patients for CKD if they have not already done so. This novel approach pairs machine modeling of CKD risk factors with an EMR clinical decision support system (CDSS) to provide real-time guidance to PCPs to improve the care delivered to patients with occult CKD. This project will provide the applicant with valuable experience in data mining, medical informatics, decision analysis, health services research, and clinical trial design and implementation. These experiences will be integral to his development into an independent clinical researcher. In addition to these direct experiences, the applicant will also benefit from the teaching and guidance provided by his team of proficient mentors and consultants. Dr. Mark Unruh, primary mentor for the proposal, is a well-funded, independent clinical investigator who brings expertise in epidemiology, clinical trials, and CKD. Dr. Mark Roberts, Chair of Health Policy and Management at the University of Pittsburgh's Graduate School of Public Health, brings a strong record of independent funding and well-established research interests in predictive modeling, decision tree analysis, and CKD. Dr. Shyam Visweswaran, an investigator in biomedical informatics, brings expertise in biomedical data mining, predictive modeling, and CDSS. Dr. Charity Moore is a highly skilled health services statistician with extensive experience in clinical trials. She will bring her expertise in research design, implementation, analysis, and interpretation to the project. Dr. Gary Fischer, director of the general internal medicine ambulatory clinic, has substantial experience in the integration of the EMR and CDSS with physician workflow. Dr. Douglas Landsittel, a statistician with an interest in the classification of disease outcomes using decision trees, has extensive experience in building and validating predictive models. This interdisciplinary team combines uniquely qualified investigators with the diversity of experience and expertise necessary for the successful completion of the proposed research and the candidate's training. To complement these hands-on experiences and mentorship activities, the candidate will undertake formal coursework through the University of Pittsburgh's Graduate School of Public Health, Department of Biomedical Informatics, and the Institute for Clinical Research Education (part of the university's Clinical and Translational Science Institute). These courses will include formal training in research design and clinical trial implementation, applied medical informatics and decision analysis, and methods in health services research and biostatistics. In addition, the medical center has numerous seminars, workshops, and leadership courses that the candidate will participate in to form collaborative relationships and enhance his skills. In summary, the candidate's research interest in improving the quality of CKD care delivery coupled with a sound background in medical education and early training in clinical research make him an ideal candidate to use this CDA to investigate EMR interventions that can broadly improve CKD screening by PCPs. The applicant's experienced, multidisciplinary mentorship team, strong institutional resources and support, and the formal training he will complete under this award will ensure that he continues to develop into a successful independent clinical investigator studying methods to improve PCP care delivery to CKD patients. Chronic kidney disease is a growing public health problem with over 10% of adults affected by the disorder. Evidence indicates that late recognition and suboptimal care of chronic kidney disease contributes to poor health in these patients. This study will develop a model that can predict the presence of chronic kidney disease without the use of blood work. This model will be implemented to alert doctors in real-time to screen high-risk patients who may have unrecognized chronic kidney disease with the potential to substantially improve the care of these patients.","Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD)",8897359,K23DK090304,"['Academy', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Area', 'Award', 'Behavior', 'Biometry', 'Blood', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Characteristics', 'Charities', 'Chemistry', 'Cholesterol', 'Chronic', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cognitive', 'Comorbidity', 'Complement', 'Computerized Medical Record', 'Coupled', 'Creatinine', 'Data', 'Databases', 'Decision Analysis', 'Decision Trees', 'Development', 'Diagnosis', 'Disease', 'Disease Outcome', 'Disease model', 'Education', 'Educational Intervention', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Evaluation', 'Event', 'Foundations', 'Funding', 'Goals', 'Guidelines', 'Health', 'Health Policy', 'Health Services', 'Health Services Research', 'Hemoglobin', 'Hospitalization', 'Individual', 'Institutes', 'Internal Medicine', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Leadership', 'Learning', 'Logistic Regressions', 'Medical Education', 'Medical Errors', 'Medical Informatics', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Nephrology', 'Outcome', 'Outpatients', 'Patient Care', 'Patient risk', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Population', 'Postdoctoral Fellow', 'Prevalence', 'Primary Care Physician', 'Process', 'Provider', 'Public Health', 'Public Health Schools', 'Qualifying', 'Randomized', 'Randomized Controlled Trials', 'Recommendation', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Sensitivity and Specificity', 'Serum', 'Staging', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'Universities', 'Urine', 'Validation', 'Work', 'advanced disease', 'age related', 'base', 'biomedical informatics', 'care delivery', 'career', 'computer program', 'cost effective', 'data mining', 'demographics', 'disease diagnosis', 'disorder risk', 'experience', 'high risk', 'improved', 'interest', 'multidisciplinary', 'novel', 'novel strategies', 'predictive modeling', 'primary care setting', 'screening', 'skills', 'sound', 'theories', 'treatment as usual', 'trend']",NIDDK,VANDERBILT UNIVERSITY,K23,2015,37402,0.016503406676452535
"Improving Accuracy of Electronic Notes Using A Faster, Simpler Approach DESCRIPTION (provided by applicant): Physician progress notes contain information essential to patient care, including findings from history and physical exam, interpretation of tests, assessment and treatment plans. However in the transition from paper to electronic physician notes, many physicians spend more time creating them, which has led to the use of time-saving measures such as copy/paste and templates that have degraded note accuracy and quality. This threatens the usefulness of notes not only for their most important use-patient care-but also for research, quality improvement, and in supporting reimbursement. To address these problems, we propose a project with the following specific aims: 1. To refine and implement a new voice-generated enhanced electronic note system (VGEENS) integrating voice recognition with natural language processing and links to the electronic medical record (EMR) to improve note accuracy and timeliness. 2. To evaluate VGEENS using a randomized trial with 30 internal medicine physicians in each arm to assess electronic note accuracy, quality, timeliness, and user satisfaction. Intervention physicians will use VGEENS, while the control physicians will continue with note creation as they normally would. This novel approach has the potential to improve note accuracy while reducing delays in making progress notes in EMRs available to other clinicians. It leverages rapidly improving voice recognition and NLP technologies to permit physicians to use a natural, fast method-human voice-to convey their observation and thoughts into the EMR record. PUBLIC HEALTH RELEVANCE: Physician documentation of a patient visit contains information that is used in that patient's care. This information includes findings from a patient' history and physical exam, interpretation of necessary tests, the problem assessment and treatment plan. However, in the transition from paper to electronic physician notes, many physicians are spending more time creating these notes. This has led to use of time-saving measures that have degraded the accuracy and ease of use of patient notes. By the end of this project, we expect to have developed, used and evaluated a new method for creating electronic physician notes that both improve accuracy and timely availability of inpatient progress notes.","Improving Accuracy of Electronic Notes Using A Faster, Simpler Approach",8928601,R21HS023631,[' '],AHRQ,UNIVERSITY OF WASHINGTON,R21,2015,139245,0.027628947687283373
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,8915498,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2015,419993,-0.0010793700081888563
"Outpatient Adverse Drug Effect Alerting System Using Admission H&P Notes ﻿    DESCRIPTION (provided by applicant): This project will create, test, implement, and evaluate a real-time Adverse Drug Effect (ADE) alerting system at Vanderbilt University Hospital (VUH). Utilizing information extracted from admission history and physical examination notes (H&Ps) stored in the electronic medical record (EMR), our system will detect adult inpatients' previously unrecognized symptomatic ADEs and alert appropriate care providers. The project will create an ADE knowledge base, mined from multiple publically available sources including MEDLINE, RxNorm, and the product labels for human prescription drugs. Next, we will apply natural language processing (NLP) to EMR-based H&P texts to identify mentions of patients' current medications and dosages. We will similarly detect EMR-based H&P documentation of patients' clinical manifestations (CMs - diseases, symptoms, findings, etc.), and then represent them using the Unified Medical Language System's (UMLS) Concept Unique Identifiers (CUIs). The system will then compare each patient's recognized medications and CMs against the aforementioned ADE knowledgebase, generating appropriate patient-specific alerts for potential adverse effects related to the patient's current medications. Each alert will identify the offendin medication, the suspected nature of the ADE, and evidence supporting the assertion. We will independently evaluate the accuracy of the ADE knowledgebase using expert manual review and comparison to multiple other sources. Before implementing the real-time ADE monitoring system, we will conduct a pilot implementation using retrospective EMR data from the Vanderbilt Synthetic Derivative (SD), a de-identified version of the Vanderbilt EMR. After successful testing and any necessary iterative improvements, we will implement the real-time detection system at VUH, initially monitoring newly admitted inpatients presenting to the Internal Medicine service. Using the methods described above, the system will detect potential ADEs each time a new inpatient H&P is generated, and alert appropriate clinicians via additions to an existing dashboard that the clinicians already utilize. We will survey clinicians immediately upon receipt of an ADE alert to determine if the alerting condition was already known or not, whether the alert seems plausible, and whether it requires intervention. Then we will compare discharge medications to admission medications to determine what actions occurred post-alert, independent of physician survey results. We will thus evaluate both the effectiveness of the system in improving ADE recognition and its perceived usefulness according to the physician-subjects. We hypothesize that our system will improve clinicians' awareness of ADEs in a manner applicable to any facility that stores admission H&Ps electronically. Addressing previously unrecognized ADEs has the potential to reduce costs and improve patient care.         PUBLIC HEALTH RELEVANCE: Unrecognized adverse drug effects (ADEs), a serious clinical problem, cause preventable hospitalizations, increase healthcare costs, and worsen health outcomes. To potentially improve quality of care, my dissertation project will develop and evaluate a novel system to detect adult inpatients' previously unrecognized symptomatic ADEs and alert appropriate care providers. Using automated natural language processing of clinician-generated electronic admission history and physical exam (H&P) notes and a locally-developed ADE knowledgebase derived from publically available sources, the system, once validated, could improve both recognition and treatment of ADEs in a generalizable manner - applicable in hospital environments using electronic medical records.            ",Outpatient Adverse Drug Effect Alerting System Using Admission H&P Notes,8796404,R36HS023485,[' '],AHRQ,VANDERBILT UNIVERSITY,R36,2015,41626,0.042489723890208136
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,8928596,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,249655,0.04081266129569819
"NLP-enabled decision support for cervical cancer screening and surveillance DESCRIPTION (provided by applicant): Although cervical cancer is preventable, it still continues to be a leading cause of death. Following the evidence- based guidelines for cervical cancer prevention is challenging for healthcare providers, due to which many patients do not receive the optimal preventive care. Clinical decision support (CDS) systems can potentially improve the care delivery. However, the current CDS systems only identify patients overdue for screening, and do not suggest the optimal screening interval. Moreover they do not help with surveillance of patients with abnormal screening results. This is because the existing systems lack the capability to process free- text clinical reports that contain information needed for applying the guidelines. Hence there is a critical need for natural language processing (NLP)-enabled CDS systems that can utilize discrete as well as free-text patient information for enhancing the decision support. Our long-term goal is to improve healthcare delivery of cervical cancer prevention with guideline based reminders. The central hypothesis is that NLP- enabled CDS system will significantly improve the quality of care delivery for cervical cancer prevention. The rationale is that use of NLP will improve granularity of the guideline implementation, which will in-turn enhance care delivery. As preliminary work we have developed an NLP-enabled CDS system that automatically interprets the patient information from the electronic health record and applies the national guidelines to compute the optimal recommendation for screening and surveillance. We have performed validation of the system in a non-clinical setting.1 In this application we will proceed towards deployment of the system in the clinical setting, and will carry out studies for measuring the impact on the quality of care delivery. In ai one, we will validate the system in the clinical setting and will optimize its usability and workflw integration. In aim two, we will test the hypothesis that reminders from the NLP-enabled CDS system to primary care providers will improve the quality of care delivery, by performing a one year intervention control study across four sites of a primary care practice. In aim three, we will test the hypothesis that reminders to non-adherent high-risk patients will improve their surveillance rates, by performing a randomized intervention study for three months. In this study, care coordinators will utilize the CDS system for sending reminders to patients that are non-adherent and at high risk due to abnormal screenings. The main contribution of this project will be knowledge about the effectiveness of NLP in enhancing the impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This project is innovative because the CDS system will utilize NLP to generate screening reminders for normal patients and surveillance reminders for patients with abnormal findings. This is a major advancement over existing systems that can only identify patients for screening. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because it will yield knowledge about the effectiveness of natural language processing (NLP) to enhance impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This research will foster implementation of similar CDS systems across the nation for cervical cancer prevention and for other decision problems, which will improve the quality of healthcare delivery. Thus, the proposed research is relevant to AHRQ's mission to improve the quality, safety, efficiency, and effectiveness of health care for all Americans.",NLP-enabled decision support for cervical cancer screening and surveillance,8934087,R21HS022911,[' '],AHRQ,MAYO CLINIC ROCHESTER,R21,2015,145229,-0.0029626845366826715
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,8929257,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Health', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Population Study', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'improved', 'large-scale database', 'novel', 'open source', 'personalized medicine', 'rapid growth', 'rare variant', 'response', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY,R01,2015,598996,0.01833216900285443
"Interactive machine learning methods for clinical natural language processing     DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3.             Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,8818096,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Solutions', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'model development', 'novel', 'open source', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,558372,0.02689385490793908
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification     DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts.         PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.                ",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,8811565,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'public health relevance', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2014,460688,0.04577050537011789
"Measuring and Improving Colonoscopy Quality Using Natural Language Processing     DESCRIPTION (provided by applicant):  Colonoscopy is the predominant method for screening for colorectal cancer in the US. Yet, its effectiveness in screening is limited by variation in performance. For example, the rate at which physicians detect cancer precursors called adenomas during a colonoscopy has been shown to vary three-fold from one physician to another. A patient whose colonoscopy is performed by a physician with a low adenoma detection rate has a higher risk of subsequent colorectal cancer.  Our proposal centers on measuring, understanding, and improving colonoscopy quality. The major innovation of this work is to use natural language processing (NLP) to measure the quality of colonoscopy. NLP is a field of computer science in which a computer is trained to ""read"" text to identify relevant data We developed and validated the first NLP-based computer software application (C-QUAL) that analyzes colonoscopy and associated pathology reports. Our primary quality measure is adenoma detection rate because it is a common, validated measure that is linked to colorectal cancer incidence. However, we also use a number of secondary quality measures. We applied C-QUAL to almost 25,000 colonoscopy reports in one health system and found large variation in physician's performance on the quality measures. Building on this prior work, our goal is to use C-QUAL to measure colonoscopy quality across a spectrum of US practice environments, to understand what drives variation in colonoscopy quality, and to improve colonoscopy quality. In Aim 1, we propose to use the C-QUAL tool to measure performance in 4 diverse health care systems. This will be one of the largest assessments of the variation in adenoma detection rates and will span different geographic regions, payment systems, and practice settings. In Aim 2, we seek to understand why there is variation in quality. We will survey providers at the 4 health care systems about factors that might affect quality. We will link those survey results to the adenoma detection rates assessed in Aim 1 and look for key associations. It is assumed, but not proven, that providing feedback to physicians on colonoscopy quality will improve care. In Aim 3, we assess whether feedback to physicians does drive quality improvement and, building on Aim 2, explore which types of physicians may respond to feedback. Our proposal is the first to use this innovative method to measure colonoscopy quality and to use the quality scores to decrease the variation in colonoscopy performance. Together the results of the 3 aims are consistent with the NCI's focus on improving the quality of colorectal cancer screening.           PUBLIC HEALTH RELEVANCE: Prior research has shown that the quality of colonoscopy varies from physician to physician. It is important to address low quality because patients who see physicians with lower quality colonoscopies have a higher risk of developing colorectal cancer in the future. To help address poor quality of colonoscopy, we propose to use a computer software program to measure colonoscopy quality, survey physicians to understand why there is variation in quality, and provide physician feedback to stimulate quality improvement.                  ",Measuring and Improving Colonoscopy Quality Using Natural Language Processing,8641674,R01CA168959,"['Address', 'Affect', 'Cancer Etiology', 'Caring', 'Cecum', 'Cessation of life', 'Colon', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Detection', 'Effectiveness', 'Environment', 'Feedback', 'Future', 'Gastroenterology', 'Geographic Locations', 'Goals', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidence', 'Knowledge', 'Link', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Metric', 'Monitor', 'Natural Language Processing', 'Pathology Report', 'Patients', 'Performance', 'Physicians', 'Provider', 'Reading', 'Recommendation', 'Records', 'Reporting', 'Research', 'Risk', 'Science', 'Site', 'Societies', 'Sum', 'Surveys', 'System', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Variant', 'Work', 'adenoma', 'base', 'colorectal cancer screening', 'computer science', 'cost effective', 'high risk', 'improved', 'innovation', 'medical specialties', 'novel', 'payment', 'public health relevance', 'screening', 'symposium', 'tool', 'trend']",NCI,HARVARD MEDICAL SCHOOL,R01,2014,547410,0.00908091989995884
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,8920720,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2014,160000,0.06520643376319431
"Natural language processing for clinical and translational research     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.                ",Natural language processing for clinical and translational research,8640959,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'public health relevance', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2014,580082,0.06520643376319431
"Real-time detection of deviations in clinical care in ICU data streams  PROJECT SUMMARY / ABSTRACT Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our previous studies provide support that such deviations indicate clinically important events at false alert rates below 50%, which is very promising. We propose to further improve the new methodology, and build a real-time monitoring and alerting system integrated with production electronic medical records. We propose an evaluation of the system using physicians' assessment of alerts raised by our real-time system for intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories. PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in the intensive care unit (ICU). This project develops and evaluates a new clinical monitoring and alerting framework that uses electronic medical records and machine-learning methods to send alerts concerning clinical decisions in the ICU that are unexpected given the clinical context and may represent medical errors.                ",Real-time detection of deviations in clinical care in ICU data streams,8641014,R01GM088224,"['Algorithms', 'Archives', 'Area', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complication', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Decision Making', 'Detection', 'Development', 'Electronics', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Funding', 'Health Personnel', 'Healthcare', 'Hospitals', 'Immunosuppressive Agents', 'Individual', 'Information Systems', 'Inpatients', 'Intensive Care Units', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Errors', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Oral', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Play', 'Practice Management', 'Production', 'Real-Time Systems', 'Records', 'Relative (related person)', 'Research', 'Research Personnel', 'Signal Transduction', 'Solutions', 'Stream', 'System', 'Tacrolimus', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'design', 'improved', 'knowledge base', 'liver transplantation', 'multidisciplinary', 'prototype', 'public health relevance']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2014,580180,0.04525150354079238
"Secure Sharing of Clinical History & Genetic Data: Empowering Predictive Pers. Me    DESCRIPTION (provided by applicant):       Computer-assisted medicine is at a crossroads: medical care requires accurate data, but making such data widely available can create unacceptable risks to the privacy of individual patients. This tension between utility and privacy is especially acute in predictive personalized medicine (PPM). PPM holds the promise of making treatment decisions tailored to the individual based on her or his particular genetics and clinical history. Making PPM a reality requires running statistical, data mining and machine learning algorithms on combined genetic, clinical and demographic data to construct predictive models. Access to such data directly competes with the need for healthcare providers to protect the privacy of each patient's data, thus creating a tradeoff between model efficacy and privacy. Thus we find ourselves in an unfortunate standoff: significant medical advances that would result from more powerful mining of the data by a wider variety of researchers are hindered by significant privacy concerns on behalf of the patients represented in the data set. In this proposed work, we seek to develop and evaluate technology to resolve this standoff, enabling health practitioners and researchers to compute on privacy-sensitive medical records in order to make treatment decisions or create accurate models, while protecting patient privacy. We will evaluate our approach on a de-identified actual electronic medical record, with an average of 29 years of clinical history on each patient, and with detailed genetic data (650K SNPs) available for a subset of 5000 of the patients. This data set is available to us now through the Wisconsin Genomics Initiative, but only on a computer at the Marshfield Clinic. If successful our approach will make possible the sharing of this cutting-edge data set, and others like it that are now in development, including our ability to analyze this data at UW-Madison where we have thousands of processors available in our Condor pool. Our privacy approach integrates secure data access environments, including those appropriate to the use of laptops and cloud computing, with novel anonymization algorithms providing differential privacy guarantees for data and/or published results of data analysis. To this end, our specific aims are as follows:       AIM 1: Develop and deploy a secure local environment that, in combination with secure network functionality, will ensure end-to-end security and privacy for electronic medical records and biomedical datasets shared between clinical institutions and researchers.       AIM 2: Develop and deploy a secure virtual environment to allow large-scale, privacy-preserving data analysis ""in the cloud.""       AIM 3: Develop and evaluate privacy-preserving data mining algorithms for use with original (not anonymized) data sets consisting of electronic medical records and genetic data.       AIM 4: Develop and evaluate anonymizing data publishing algorithms and privacy guarantees that are appropriate to the complex structure present in electronic medical records with genetic data.            Project Narrative This project will develop an integrated approach to secure sharing of clinical and genetic data that based on algorithms for anonymization of data to achieve differential privacy guarantees, for privacy-preserving publication of data analysis results, and secure environments for data sharing that include addressing the increasing use of laptops and of cloud computing. The end goal of this project is to meet the competing demands of providing patients with both privacy and accurate predictive models based on clinical history and genetics. This project includes the first concrete evaluation of privacy- preserving data mining algorithms on actual combined EMR and genetic data, using with the Wisconsin Genomics Initiative data set.",Secure Sharing of Clinical History & Genetic Data: Empowering Predictive Pers. Me,8729006,R01LM011028,"['Acute', 'Address', 'Algorithms', 'Caring', 'Clinic', 'Clinical', 'Cloud Computing', 'Complex', 'Computer Assisted', 'Computer Security', 'Computer software', 'Computerized Medical Record', 'Computers', 'Confidentiality', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Dose', 'Ensure', 'Environment', 'Evaluation', 'Genetic', 'Genetic Databases', 'Genomics', 'Goals', 'Health', 'Health Personnel', 'Individual', 'Institution', 'Lead', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Medicine', 'Mining', 'Modeling', 'Operating System', 'Output', 'Patients', 'Privacy', 'Publications', 'Publishing', 'Recording of previous events', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Structure', 'System', 'Technology', 'Warfarin', 'Wisconsin', 'Work', 'base', 'data management', 'data mining', 'data sharing', 'design', 'empowered', 'experience', 'laptop', 'meetings', 'novel', 'patient privacy', 'predictive modeling', 'prototype', 'virtual']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,554661,0.028956379693266806
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8714052,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,UNIVERSITY OF UTAH,R01,2014,579144,0.01570451187244843
"Using NLP to Extract Clinically Important Recommendations from Radiology Reports  Abstract Communication of clinically important follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology follow-up recommendations is an important barrier to ensuring timely follow-up of patients, especially for non-acute but potentially life threatening and unexpected findings. The primary goal of this proposal is to develop a Natural Language Processing (NLP) system to extract clinically important recommendation information from free-text radiology reports. Each radiology report will be preprocessed at the structural, syntactic, and semantic level to generate features that will be used to extract the boundaries of sentences that include recommendation information as well as the details of reason for recommendation, requested imaging test, and recommendation time frame. We will use a large corpus of free-text radiology reports represented by a mixture of modalities (e.g., radiography, computed tomography, ultrasound, and magnetic resonance imaging (MRI)) from three different institutions. Using this dataset we will perform the following specific aims: Aim 1. Create a multi- institutional radiology report corpus annotated for clinically important recommendation information; Aim 2. Develop a novel NLP system to extract clinically important recommendations in radiology reports. The proposed research is innovative because it will generate a new text processing approach that can be used to flag reports visually and electronically so that separate workflow processes can be initiated to reduce the chance that necessary investigations or interventions suggested in the report are missed by clinicians. The proposed set of tools will be disseminated to the biomedical informatics community as open source tools. PUBLIC HEALTH RELEVANCE: Communication of recommendations for necessary investigations and interventions when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. We propose to build natural language processing tools to automatically extract clinically important recommendation information from radiology reports.                ",Using NLP to Extract Clinically Important Recommendations from Radiology Reports,8635902,R21EB016872,"['Academic Medical Centers', 'Address', 'Adopted', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computerized Medical Record', 'Data Set', 'Dependency', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Funding', 'Future', 'Goals', 'Gold', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Imaging technology', 'Incidental Findings', 'Institution', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Lung nodule', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medical center', 'Methods', 'Modality', 'Natural Language Processing', 'Outcome', 'Output', 'Patient Care', 'Patients', 'Persons', 'Process', 'Provider', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Risk', 'Safety', 'Semantics', 'Shapes', 'Societies', 'Specific qualifier value', 'Speech', 'System', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Ultrasonography', 'Unified Medical Language System', 'Washington', 'Writing', 'X-Ray Computed Tomography', 'biomedical informatics', 'cancer care', 'care delivery', 'design', 'falls', 'follow-up', 'health care delivery', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'phrases', 'public health relevance', 'radiologist', 'screening', 'syntax', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R21,2014,257300,0.025341166075928526
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8721471,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2014,191107,0.029461759346084804
"Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD) DESCRIPTION (provided by applicant): Dr. Khaled Abdel-Kader has completed prior training in nephrology and a master's in medical education with formal training in adult learning, medical errors, and cognitive theory as well as introductory coursework in clinical research and biostatistics. His primary research interest is characterizing and addressing chronic kidney disease (CKD) care deficiencies in the primary care setting. He has received individual post-doctoral funding to support his work in this area. His career goal is to become an expert in CKD epidemiology and an independent clinical investigator studying electronic medical record (EMR)-based interventions to improve CKD care and outcomes. In this career development award (CDA), he focuses on improving primary care physician (PCP) screening for CKD. This award provides him with mentorship, formal coursework, and hands-on experience in epidemiology, research design, medical informatics, decision analysis, health services research, and biostatistics. He has assembled a group of highly skilled mentors who will guide him and help him develop into an independent clinical investigator. A supportive research environment that has already cultivated the development of numerous successful independent clinical investigators complements these individual mentors. In addition, unique institutional resources including a well-developed EMR, EMR research infrastructure, and large patient base make the local environment an ideal setting for the candidate and his research. Dr. Abdel- Kader will use these research experiences, coursework, mentorship, and institutional resources and commitment to continue his progression to becoming an independently funded clinical researcher. An important element of the application is the candidate's research proposal. He will conduct his research project in 2 phases. In the first phase, he will leverage the local, well-developed EMR database and the University of Pittsburgh's large ambulatory patient base (>450,000 unique patients in the prior 2 years) to develop a decision tree predictive model to identify patients at high risk for CKD without the use of serum chemistries. He will compare the performance of the decision tree model to a prominent, recently developed logistic regression model of CKD risk. After identifying the model with the best performance, the candidate will conduct a randomized controlled trial of PCPs examining the effect of implementing the CKD predictive model in the EMR as a clinical alert versus usual care. The clinical alert will remind PCPs to screen high-risk patients for CKD if they have not already done so. This novel approach pairs machine modeling of CKD risk factors with an EMR clinical decision support system (CDSS) to provide real-time guidance to PCPs to improve the care delivered to patients with occult CKD. This project will provide the applicant with valuable experience in data mining, medical informatics, decision analysis, health services research, and clinical trial design and implementation. These experiences will be integral to his development into an independent clinical researcher. In addition to these direct experiences, the applicant will also benefit from the teaching and guidance provided by his team of proficient mentors and consultants. Dr. Mark Unruh, primary mentor for the proposal, is a well-funded, independent clinical investigator who brings expertise in epidemiology, clinical trials, and CKD. Dr. Mark Roberts, Chair of Health Policy and Management at the University of Pittsburgh's Graduate School of Public Health, brings a strong record of independent funding and well-established research interests in predictive modeling, decision tree analysis, and CKD. Dr. Shyam Visweswaran, an investigator in biomedical informatics, brings expertise in biomedical data mining, predictive modeling, and CDSS. Dr. Charity Moore is a highly skilled health services statistician with extensive experience in clinical trials. She will bring her expertise in research design, implementation, analysis, and interpretation to the project. Dr. Gary Fischer, director of the general internal medicine ambulatory clinic, has substantial experience in the integration of the EMR and CDSS with physician workflow. Dr. Douglas Landsittel, a statistician with an interest in the classification of disease outcomes using decision trees, has extensive experience in building and validating predictive models. This interdisciplinary team combines uniquely qualified investigators with the diversity of experience and expertise necessary for the successful completion of the proposed research and the candidate's training. To complement these hands-on experiences and mentorship activities, the candidate will undertake formal coursework through the University of Pittsburgh's Graduate School of Public Health, Department of Biomedical Informatics, and the Institute for Clinical Research Education (part of the university's Clinical and Translational Science Institute). These courses will include formal training in research design and clinical trial implementation, applied medical informatics and decision analysis, and methods in health services research and biostatistics. In addition, the medical center has numerous seminars, workshops, and leadership courses that the candidate will participate in to form collaborative relationships and enhance his skills. In summary, the candidate's research interest in improving the quality of CKD care delivery coupled with a sound background in medical education and early training in clinical research make him an ideal candidate to use this CDA to investigate EMR interventions that can broadly improve CKD screening by PCPs. The applicant's experienced, multidisciplinary mentorship team, strong institutional resources and support, and the formal training he will complete under this award will ensure that he continues to develop into a successful independent clinical investigator studying methods to improve PCP care delivery to CKD patients. Chronic kidney disease is a growing public health problem with over 10% of adults affected by the disorder. Evidence indicates that late recognition and suboptimal care of chronic kidney disease contributes to poor health in these patients. This study will develop a model that can predict the presence of chronic kidney disease without the use of blood work. This model will be implemented to alert doctors in real-time to screen high-risk patients who may have unrecognized chronic kidney disease with the potential to substantially improve the care of these patients.","Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD)",8730137,K23DK090304,"['Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Area', 'Award', 'Behavior', 'Biometry', 'Blood', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Characteristics', 'Charities', 'Chemistry', 'Cholesterol', 'Chronic', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cognitive', 'Comorbidity', 'Complement', 'Computerized Medical Record', 'Coupled', 'Creatinine', 'Data', 'Databases', 'Decision Analysis', 'Decision Trees', 'Development', 'Diagnosis', 'Disease', 'Disease Outcome', 'Disease model', 'Education', 'Educational Intervention', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Evaluation', 'Foundations', 'Funding', 'Goals', 'Guidelines', 'Health', 'Health Policy', 'Health Services', 'Health Services Research', 'Hemoglobin', 'Hospitalization', 'Individual', 'Institutes', 'Internal Medicine', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Leadership', 'Learning', 'Logistic Regressions', 'Medical Education', 'Medical Errors', 'Medical Informatics', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Nephrology', 'Outcome', 'Outpatients', 'Patient Care', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Population', 'Postdoctoral Fellow', 'Prevalence', 'Primary Care Physician', 'Process', 'Provider', 'Public Health', 'Public Health Schools', 'Qualifying', 'Randomized', 'Randomized Controlled Trials', 'Recommendation', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Sensitivity and Specificity', 'Serum', 'Staging', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'Universities', 'Urine', 'Validation', 'Work', 'advanced disease', 'age related', 'base', 'biomedical informatics', 'care delivery', 'career', 'computer program', 'cost', 'data mining', 'demographics', 'disease diagnosis', 'disorder risk', 'experience', 'high risk', 'improved', 'interest', 'multidisciplinary', 'novel', 'novel strategies', 'predictive modeling', 'primary care setting', 'screening', 'skills', 'sound', 'theories', 'treatment as usual', 'trend']",NIDDK,VANDERBILT UNIVERSITY,K23,2014,172287,0.016503406676452535
"Improving Accuracy of Electronic Notes Using A Faster, Simpler Approach     DESCRIPTION (provided by applicant): Physician progress notes contain information essential to patient care, including findings from history and physical exam, interpretation of tests, assessment and treatment plans. However in the transition from paper to electronic physician notes, many physicians spend more time creating them, which has led to the use of time-saving measures such as copy/paste and templates that have degraded note accuracy and quality. This threatens the usefulness of notes not only for their most important use-patient care-but also for research, quality improvement, and in supporting reimbursement. To address these problems, we propose a project with the following specific aims: 1. To refine and implement a new voice-generated enhanced electronic note system (VGEENS) integrating voice recognition with natural language processing and links to the electronic medical record (EMR) to improve note accuracy and timeliness. 2. To evaluate VGEENS using a randomized trial with 30 internal medicine physicians in each arm to assess electronic note accuracy, quality, timeliness, and user satisfaction. Intervention physicians will use VGEENS, while the control physicians will continue with note creation as they normally would. This novel approach has the potential to improve note accuracy while reducing delays in making progress notes in EMRs available to other clinicians. It leverages rapidly improving voice recognition and NLP technologies to permit physicians to use a natural, fast method-human voice-to convey their observation and thoughts into the EMR record.         PUBLIC HEALTH RELEVANCE: Physician documentation of a patient visit contains information that is used in that patient's care. This information includes findings from a patient' history and physical exam, interpretation of necessary tests, the problem assessment and treatment plan. However, in the transition from paper to electronic physician notes, many physicians are spending more time creating these notes. This has led to use of time-saving measures that have degraded the accuracy and ease of use of patient notes. By the end of this project, we expect to have developed, used and evaluated a new method for creating electronic physician notes that both improve accuracy and timely availability of inpatient progress notes.            ","Improving Accuracy of Electronic Notes Using A Faster, Simpler Approach",8805997,R21HS023631,[' '],AHRQ,UNIVERSITY OF WASHINGTON,R21,2014,154347,0.027628947687283373
"Comp B-Western Intermountain Regional NMD STARnet     DESCRIPTION (provided by applicant): The Muscular dystrophies and Spinal Muscular Atrophy are neuromuscular disorders that account for an increasing burden of medical disability and healthcare costs. All of these disorders have some evidence to suggest that early detection and aggressive preventative care management may improve the morbidity and mortality. To that end, each disorder has an existing or nearly complete standard of care guideline. The implementation of such care requires early detection of affected individuals or those at-risk. In many disorders, such as Duchenne Muscular Dystrophy or Myotonic Dystrophy, there is a documented delay in diagnosis that impairs qualified individuals from delivering such care. This is underscored by promising new treatments being developed for Duchenne Muscular Dystrophy, Myotonic Dystrophy, or Spinal Muscular Atrophy. It is very likely that treatment effectiveness may hinge on early delivery. This application proposes to develop a surveillance network in the states of Utah and Nevada to detect all cases of muscular dystrophy and spinal muscular atrophy. These states include a diverse population of around 6 million persons. The surveillance program proposes uses an innovative tool, natural language processing, to more efficiently and reliably detect such cases from the states' electronic medical records. Secondly, this surveillance program utilizes a unique resource, The Utah Population Database, to better understand the between family variation and to confirm those cases identified from electronic health records. Finally, this proposal seeks to identify care disparities in underserved communities, particularly through guideline adherence, and address these disparities. Once complete, this proposal will achieve a better understanding of the prevalence, morbidity, and mortality in those individuals with muscular dystrophy or spinal muscular atrophy. This information is critical for future disease- modifying therapeutic trials, and for the detection and care of those individuals who may not currently have access to the standard of care.         PUBLIC HEALTH RELEVANCE: The Muscular Dystrophies and Spinal Muscular Atrophy are major health problems, leading to significant reduced quality of life and mortality. This proposal seeks to identify the incidence and prevalence of these disorders, and prospectively assess how application of care guidelines improves mortality and quality of life. In addition, through surveillance of the state populations of Utah and Nevada, we hope to better engage minority and other under-served populations.            ",Comp B-Western Intermountain Regional NMD STARnet,8821956,U01DD001108,[' '],NCBDDD,UNIVERSITY OF UTAH,U01,2014,449993,-0.0010793700081888563
"Learning from patient safety events: A case base tool kit     DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture.         PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.            ",Learning from patient safety events: A case base tool kit,8818528,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,249655,0.04081266129569819
"NLP-enabled decision support for cervical cancer screening and surveillance     DESCRIPTION (provided by applicant): Although cervical cancer is preventable, it still continues to be a leading cause of death. Following the evidence- based guidelines for cervical cancer prevention is challenging for healthcare providers, due to which many patients do not receive the optimal preventive care. Clinical decision support (CDS) systems can potentially improve the care delivery. However, the current CDS systems only identify patients overdue for screening, and do not suggest the optimal screening interval. Moreover they do not help with surveillance of patients with abnormal screening results. This is because the existing systems lack the capability to process free- text clinical reports that contain information needed for applying the guidelines. Hence there is a critical need for natural language processing (NLP)-enabled CDS systems that can utilize discrete as well as free-text patient information for enhancing the decision support. Our long-term goal is to improve healthcare delivery of cervical cancer prevention with guideline based reminders. The central hypothesis is that NLP- enabled CDS system will significantly improve the quality of care delivery for cervical cancer prevention. The rationale is that use of NLP will improve granularity of the guideline implementation, which will in-turn enhance care delivery. As preliminary work we have developed an NLP-enabled CDS system that automatically interprets the patient information from the electronic health record and applies the national guidelines to compute the optimal recommendation for screening and surveillance. We have performed validation of the system in a non-clinical setting.1 In this application we will proceed towards deployment of the system in the clinical setting, and will carry out studies for measuring the impact on the quality of care delivery. In ai one, we will validate the system in the clinical setting and will optimize its usability and workflw integration. In aim two, we will test the hypothesis that reminders from the NLP-enabled CDS system to primary care providers will improve the quality of care delivery, by performing a one year intervention control study across four sites of a primary care practice. In aim three, we will test the hypothesis that reminders to non-adherent high-risk patients will improve their surveillance rates, by performing a randomized intervention study for three months. In this study, care coordinators will utilize the CDS system for sending reminders to patients that are non-adherent and at high risk due to abnormal screenings. The main contribution of this project will be knowledge about the effectiveness of NLP in enhancing the impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This project is innovative because the CDS system will utilize NLP to generate screening reminders for normal patients and surveillance reminders for patients with abnormal findings. This is a major advancement over existing systems that can only identify patients for screening.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because it will yield knowledge about the effectiveness of natural language processing (NLP) to enhance impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This research will foster implementation of similar CDS systems across the nation for cervical cancer prevention and for other decision problems, which will improve the quality of healthcare delivery. Thus, the proposed research is relevant to AHRQ's mission to improve the quality, safety, efficiency, and effectiveness of health care for all Americans.            ",NLP-enabled decision support for cervical cancer screening and surveillance,8678798,R21HS022911,[' '],AHRQ,MAYO CLINIC ROCHESTER,R21,2014,145229,-0.0029626845366826715
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers.         PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.            ",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,8629996,R01GM103859,"['Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Medicine', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Population Study', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'improved', 'large-scale database', 'novel', 'open source', 'public health relevance', 'rapid growth', 'rare variant', 'response', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY,R01,2014,648591,0.01833216900285443
"Natural language processing for clinical and translational research     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.                ",Natural language processing for clinical and translational research,8505753,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'public health relevance', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2013,630706,0.06520643376319431
"Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictio DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to  explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index  patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's. n/a",Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictio,8599828,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Beds', 'Benchmarking', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Child health care', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Development', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Mutation', 'Names', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'design', 'emergency service responder', 'experience', 'genome analysis', 'genome sequencing', 'improved', 'indexing', 'interoperability', 'medical information system', 'novel', 'open source', 'parallel processing', 'performance tests', 'processing speed', 'repository', 'research study', 'response', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual']",NIGMS,UNIVERSITY OF UTAH,R01,2013,568249,0.024021945225097624
"Secure Sharing of Clinical History & Genetic Data: Empowering Predictive Pers. Me    DESCRIPTION (provided by applicant):       Computer-assisted medicine is at a crossroads: medical care requires accurate data, but making such data widely available can create unacceptable risks to the privacy of individual patients. This tension between utility and privacy is especially acute in predictive personalized medicine (PPM). PPM holds the promise of making treatment decisions tailored to the individual based on her or his particular genetics and clinical history. Making PPM a reality requires running statistical, data mining and machine learning algorithms on combined genetic, clinical and demographic data to construct predictive models. Access to such data directly competes with the need for healthcare providers to protect the privacy of each patient's data, thus creating a tradeoff between model efficacy and privacy. Thus we find ourselves in an unfortunate standoff: significant medical advances that would result from more powerful mining of the data by a wider variety of researchers are hindered by significant privacy concerns on behalf of the patients represented in the data set. In this proposed work, we seek to develop and evaluate technology to resolve this standoff, enabling health practitioners and researchers to compute on privacy-sensitive medical records in order to make treatment decisions or create accurate models, while protecting patient privacy. We will evaluate our approach on a de-identified actual electronic medical record, with an average of 29 years of clinical history on each patient, and with detailed genetic data (650K SNPs) available for a subset of 5000 of the patients. This data set is available to us now through the Wisconsin Genomics Initiative, but only on a computer at the Marshfield Clinic. If successful our approach will make possible the sharing of this cutting-edge data set, and others like it that are now in development, including our ability to analyze this data at UW-Madison where we have thousands of processors available in our Condor pool. Our privacy approach integrates secure data access environments, including those appropriate to the use of laptops and cloud computing, with novel anonymization algorithms providing differential privacy guarantees for data and/or published results of data analysis. To this end, our specific aims are as follows:       AIM 1: Develop and deploy a secure local environment that, in combination with secure network functionality, will ensure end-to-end security and privacy for electronic medical records and biomedical datasets shared between clinical institutions and researchers.       AIM 2: Develop and deploy a secure virtual environment to allow large-scale, privacy-preserving data analysis ""in the cloud.""       AIM 3: Develop and evaluate privacy-preserving data mining algorithms for use with original (not anonymized) data sets consisting of electronic medical records and genetic data.       AIM 4: Develop and evaluate anonymizing data publishing algorithms and privacy guarantees that are appropriate to the complex structure present in electronic medical records with genetic data.            Project Narrative This project will develop an integrated approach to secure sharing of clinical and genetic data that based on algorithms for anonymization of data to achieve differential privacy guarantees, for privacy-preserving publication of data analysis results, and secure environments for data sharing that include addressing the increasing use of laptops and of cloud computing. The end goal of this project is to meet the competing demands of providing patients with both privacy and accurate predictive models based on clinical history and genetics. This project includes the first concrete evaluation of privacy- preserving data mining algorithms on actual combined EMR and genetic data, using with the Wisconsin Genomics Initiative data set.",Secure Sharing of Clinical History & Genetic Data: Empowering Predictive Pers. Me,8531347,R01LM011028,"['Acute', 'Address', 'Algorithms', 'Caring', 'Clinic', 'Clinical', 'Complex', 'Computer Assisted', 'Computer Security', 'Computer software', 'Computerized Medical Record', 'Computers', 'Confidentiality', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Dose', 'Ensure', 'Environment', 'Evaluation', 'Genetic', 'Genetic Databases', 'Genomics', 'Goals', 'Health', 'Health Personnel', 'Individual', 'Institution', 'Lead', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Medicine', 'Mining', 'Modeling', 'Operating System', 'Output', 'Patients', 'Privacy', 'Publications', 'Publishing', 'Recording of previous events', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Structure', 'System', 'Technology', 'Warfarin', 'Wisconsin', 'Work', 'base', 'data management', 'data mining', 'data sharing', 'design', 'empowered', 'experience', 'laptop', 'meetings', 'novel', 'patient privacy', 'predictive modeling', 'prototype', 'virtual']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2013,512888,0.028956379693266806
"Measuring and Improving Colonoscopy Quality Using Natural Language Processing No abstract available  Prior research has shown that the quality of colonoscopy varies from physician to physician. It is important to address low quality because patients who see physicians with lower quality colonoscopies have a higher risk of developing colorectal cancer in the future. To help address poor quality of colonoscopy, we propose to use a computer software program to measure colonoscopy quality, survey physicians to understand why there is variation in quality, and test methods of physician feedback to stimulate quality improvement.                 ",Measuring and Improving Colonoscopy Quality Using Natural Language Processing,8752179,R01CA168959,"['Address', 'Affect', 'Cancer Etiology', 'Cecum', 'Cessation of life', 'Colon', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Detection', 'Effectiveness', 'Environment', 'Feedback', 'Future', 'Gastroenterology', 'Geographic Locations', 'Goals', 'Gold', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Incidence', 'Institution', 'Knowledge', 'Link', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Metric', 'Monitor', 'Names', 'Natural Language Processing', 'Pathology Report', 'Patients', 'Performance', 'Physicians', 'Provider', 'Randomized', 'Reading', 'Recommendation', 'Records', 'Reporting', 'Research', 'Risk', 'Science', 'Societies', 'Sum', 'Surveys', 'System', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Variant', 'Work', 'adenoma', 'base', 'colorectal cancer screening', 'computer science', 'cost effective', 'high risk', 'improved', 'innovation', 'medical specialties', 'novel', 'payment', 'peer', 'screening', 'symposium', 'tool']",NCI,HARVARD MEDICAL SCHOOL,R01,2013,634795,0.016083350396862376
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.       PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.         ","Annotation, development and evaluation for clinical information extraction",8501543,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,370221,0.06559052334651118
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8536940,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2013,292186,0.011956292040670244
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8728454,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2013,197687,0.029461759346084804
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8517791,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2013,935039,0.029461759346084804
"Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD) DESCRIPTION (provided by applicant): Dr. Khaled Abdel-Kader has completed prior training in nephrology and a master's in medical education with formal training in adult learning, medical errors, and cognitive theory as well as introductory coursework in clinical research and biostatistics. His primary research interest is characterizing and addressing chronic kidney disease (CKD) care deficiencies in the primary care setting. He has received individual post-doctoral funding to support his work in this area. His career goal is to become an expert in CKD epidemiology and an independent clinical investigator studying electronic medical record (EMR)-based interventions to improve CKD care and outcomes. In this career development award (CDA), he focuses on improving primary care physician (PCP) screening for CKD. This award provides him with mentorship, formal coursework, and hands-on experience in epidemiology, research design, medical informatics, decision analysis, health services research, and biostatistics. He has assembled a group of highly skilled mentors who will guide him and help him develop into an independent clinical investigator. A supportive research environment that has already cultivated the development of numerous successful independent clinical investigators complements these individual mentors. In addition, unique institutional resources including a well-developed EMR, EMR research infrastructure, and large patient base make the local environment an ideal setting for the candidate and his research. Dr. Abdel- Kader will use these research experiences, coursework, mentorship, and institutional resources and commitment to continue his progression to becoming an independently funded clinical researcher. An important element of the application is the candidate's research proposal. He will conduct his research project in 2 phases. In the first phase, he will leverage the local, well-developed EMR database and the University of Pittsburgh's large ambulatory patient base (>450,000 unique patients in the prior 2 years) to develop a decision tree predictive model to identify patients at high risk for CKD without the use of serum chemistries. He will compare the performance of the decision tree model to a prominent, recently developed logistic regression model of CKD risk. After identifying the model with the best performance, the candidate will conduct a randomized controlled trial of PCPs examining the effect of implementing the CKD predictive model in the EMR as a clinical alert versus usual care. The clinical alert will remind PCPs to screen high-risk patients for CKD if they have not already done so. This novel approach pairs machine modeling of CKD risk factors with an EMR clinical decision support system (CDSS) to provide real-time guidance to PCPs to improve the care delivered to patients with occult CKD. This project will provide the applicant with valuable experience in data mining, medical informatics, decision analysis, health services research, and clinical trial design and implementation. These experiences will be integral to his development into an independent clinical researcher. In addition to these direct experiences, the applicant will also benefit from the teaching and guidance provided by his team of proficient mentors and consultants. Dr. Mark Unruh, primary mentor for the proposal, is a well-funded, independent clinical investigator who brings expertise in epidemiology, clinical trials, and CKD. Dr. Mark Roberts, Chair of Health Policy and Management at the University of Pittsburgh's Graduate School of Public Health, brings a strong record of independent funding and well-established research interests in predictive modeling, decision tree analysis, and CKD. Dr. Shyam Visweswaran, an investigator in biomedical informatics, brings expertise in biomedical data mining, predictive modeling, and CDSS. Dr. Charity Moore is a highly skilled health services statistician with extensive experience in clinical trials. She will bring her expertise in research design, implementation, analysis, and interpretation to the project. Dr. Gary Fischer, director of the general internal medicine ambulatory clinic, has substantial experience in the integration of the EMR and CDSS with physician workflow. Dr. Douglas Landsittel, a statistician with an interest in the classification of disease outcomes using decision trees, has extensive experience in building and validating predictive models. This interdisciplinary team combines uniquely qualified investigators with the diversity of experience and expertise necessary for the successful completion of the proposed research and the candidate's training. To complement these hands-on experiences and mentorship activities, the candidate will undertake formal coursework through the University of Pittsburgh's Graduate School of Public Health, Department of Biomedical Informatics, and the Institute for Clinical Research Education (part of the university's Clinical and Translational Science Institute). These courses will include formal training in research design and clinical trial implementation, applied medical informatics and decision analysis, and methods in health services research and biostatistics. In addition, the medical center has numerous seminars, workshops, and leadership courses that the candidate will participate in to form collaborative relationships and enhance his skills. In summary, the candidate's research interest in improving the quality of CKD care delivery coupled with a sound background in medical education and early training in clinical research make him an ideal candidate to use this CDA to investigate EMR interventions that can broadly improve CKD screening by PCPs. The applicant's experienced, multidisciplinary mentorship team, strong institutional resources and support, and the formal training he will complete under this award will ensure that he continues to develop into a successful independent clinical investigator studying methods to improve PCP care delivery to CKD patients. Chronic kidney disease is a growing public health problem with over 10% of adults affected by the disorder. Evidence indicates that late recognition and suboptimal care of chronic kidney disease contributes to poor health in these patients. This study will develop a model that can predict the presence of chronic kidney disease without the use of blood work. This model will be implemented to alert doctors in real-time to screen high-risk patients who may have unrecognized chronic kidney disease with the potential to substantially improve the care of these patients.","Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD)",8521270,K23DK090304,"['Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Area', 'Award', 'Behavior', 'Biometry', 'Blood', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Characteristics', 'Charities', 'Chemistry', 'Cholesterol', 'Chronic', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cognitive', 'Comorbidity', 'Complement', 'Computerized Medical Record', 'Coupled', 'Creatinine', 'Data', 'Databases', 'Decision Analysis', 'Decision Trees', 'Development', 'Diagnosis', 'Disease', 'Disease Outcome', 'Disease model', 'Education', 'Educational Intervention', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Evaluation', 'Foundations', 'Funding', 'Goals', 'Guidelines', 'Health', 'Health Policy', 'Health Services', 'Health Services Research', 'Hemoglobin', 'Hospitalization', 'Individual', 'Institutes', 'Internal Medicine', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Leadership', 'Learning', 'Logistic Regressions', 'Medical Education', 'Medical Errors', 'Medical Informatics', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Nephrology', 'Outcome', 'Outpatients', 'Patient Care', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Population', 'Postdoctoral Fellow', 'Prevalence', 'Primary Care Physician', 'Process', 'Provider', 'Public Health', 'Public Health Schools', 'Qualifying', 'Randomized', 'Randomized Controlled Trials', 'Recommendation', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Sensitivity and Specificity', 'Serum', 'Staging', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'Universities', 'Urine', 'Validation', 'Work', 'advanced disease', 'age related', 'base', 'biomedical informatics', 'care delivery', 'career', 'computer program', 'cost', 'data mining', 'demographics', 'disease diagnosis', 'disorder risk', 'experience', 'high risk', 'improved', 'interest', 'multidisciplinary', 'novel', 'novel strategies', 'predictive modeling', 'primary care setting', 'screening', 'skills', 'sound', 'theories', 'treatment as usual', 'trend']",NIDDK,VANDERBILT UNIVERSITY,K23,2013,172287,0.016503406676452535
"Annotation, development and evaluation for clinical information extraction (transfer) Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible. In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction (transfer)",8868500,R01GM090187,[' '],NIGMS,BOSTON CHILDREN'S HOSPITAL,R01,2013,297936,0.06559052334651118
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8305149,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2012,129035,0.03823049582899747
"Secure Sharing of Clinical History & Genetic Data: Empowering Predictive Pers. Me    DESCRIPTION (provided by applicant):       Computer-assisted medicine is at a crossroads: medical care requires accurate data, but making such data widely available can create unacceptable risks to the privacy of individual patients. This tension between utility and privacy is especially acute in predictive personalized medicine (PPM). PPM holds the promise of making treatment decisions tailored to the individual based on her or his particular genetics and clinical history. Making PPM a reality requires running statistical, data mining and machine learning algorithms on combined genetic, clinical and demographic data to construct predictive models. Access to such data directly competes with the need for healthcare providers to protect the privacy of each patient's data, thus creating a tradeoff between model efficacy and privacy. Thus we find ourselves in an unfortunate standoff: significant medical advances that would result from more powerful mining of the data by a wider variety of researchers are hindered by significant privacy concerns on behalf of the patients represented in the data set. In this proposed work, we seek to develop and evaluate technology to resolve this standoff, enabling health practitioners and researchers to compute on privacy-sensitive medical records in order to make treatment decisions or create accurate models, while protecting patient privacy. We will evaluate our approach on a de-identified actual electronic medical record, with an average of 29 years of clinical history on each patient, and with detailed genetic data (650K SNPs) available for a subset of 5000 of the patients. This data set is available to us now through the Wisconsin Genomics Initiative, but only on a computer at the Marshfield Clinic. If successful our approach will make possible the sharing of this cutting-edge data set, and others like it that are now in development, including our ability to analyze this data at UW-Madison where we have thousands of processors available in our Condor pool. Our privacy approach integrates secure data access environments, including those appropriate to the use of laptops and cloud computing, with novel anonymization algorithms providing differential privacy guarantees for data and/or published results of data analysis. To this end, our specific aims are as follows:       AIM 1: Develop and deploy a secure local environment that, in combination with secure network functionality, will ensure end-to-end security and privacy for electronic medical records and biomedical datasets shared between clinical institutions and researchers.       AIM 2: Develop and deploy a secure virtual environment to allow large-scale, privacy-preserving data analysis ""in the cloud.""       AIM 3: Develop and evaluate privacy-preserving data mining algorithms for use with original (not anonymized) data sets consisting of electronic medical records and genetic data.       AIM 4: Develop and evaluate anonymizing data publishing algorithms and privacy guarantees that are appropriate to the complex structure present in electronic medical records with genetic data.            Project Narrative This project will develop an integrated approach to secure sharing of clinical and genetic data that based on algorithms for anonymization of data to achieve differential privacy guarantees, for privacy-preserving publication of data analysis results, and secure environments for data sharing that include addressing the increasing use of laptops and of cloud computing. The end goal of this project is to meet the competing demands of providing patients with both privacy and accurate predictive models based on clinical history and genetics. This project includes the first concrete evaluation of privacy- preserving data mining algorithms on actual combined EMR and genetic data, using with the Wisconsin Genomics Initiative data set.",Secure Sharing of Clinical History & Genetic Data: Empowering Predictive Pers. Me,8333324,R01LM011028,"['Acute', 'Address', 'Algorithms', 'Caring', 'Clinic', 'Clinical', 'Complex', 'Computer Assisted', 'Computer Security', 'Computer software', 'Computerized Medical Record', 'Computers', 'Confidentiality', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Dose', 'Ensure', 'Environment', 'Evaluation', 'Genetic', 'Genetic Databases', 'Genomics', 'Goals', 'Health', 'Health Personnel', 'Individual', 'Institution', 'Lead', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Medicine', 'Mining', 'Modeling', 'Operating System', 'Output', 'Patients', 'Privacy', 'Publications', 'Publishing', 'Recording of previous events', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Structure', 'System', 'Technology', 'Warfarin', 'Wisconsin', 'Work', 'base', 'data management', 'data mining', 'data sharing', 'design', 'empowered', 'experience', 'laptop', 'meetings', 'novel', 'patient privacy', 'predictive modeling', 'prototype', 'virtual']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2012,545129,0.028956379693266806
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8333306,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,592423,0.01570451187244843
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8288078,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,663130,0.06282482954901003
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),8318247,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Caring', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Systematized Nomenclature of Medicine', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2012,366912,0.04919448394561618
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8326648,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2012,318393,0.011956292040670244
"An in-silico method for epidemiological studies using Electronic Medical Records Observational epidemiological studies are effective methods for identifying  factors affecting the health and illness of populations, as well as for determining optimal  treatments for diseases, such as cancers. However, conventional epidemiological  research usually involves personnel-intensive effort (such as manual chart and public  records review) and can be very time consuming before conclusive results are obtained.  Recently, a large amount of detailed longitudinal clinical data has been accumulated at  hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data  source for epidemiological studies. However, there are two obstacles that prevent the  wide usage of EMR data in epidemiological studies. First, most of the detailed clinical  information in EMRs is embedded in narrative text and it is very costly to extract that  information manually. Second, EMRs usually have data quality problems such as  selection bias and missing data, which require adaptation of conventional statistical  methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for  observational epidemiological studies using EMR data. We hypothesize that existing  EMR data can be used for certain types of epidemiological studies in a very efficient  manner with the help of informatics methods. The informatics-based approach will  contain two major components. One is an NLP (Natural Language Processing) based  information extraction system that can automatically extract detailed clinical information  from EMR and another is a set of statistical and informatics methods that can be used to  analyze EMR-derived data. If the feasibility of this approach is proven, it will change the  standard paradigm of observational epidemiological research, because it has the  capability to answer an epidemiological question in a very short time at a very low cost.   The specific aim of this study is to develop an automated informatics approach to  extract both fine-grained cancer findings and general clinical information from EMRs and  use them to conduct cancer related epidemiological studies. We will perform both case-  control and cohort studies related to prevention and treatment of breast and colon  cancers using EMR data. The informatics approach will be validated on EMRs from two  major hospitals to demonstrate its generalizability. Epidemiological findings from our  study will be compared to reported findings for validation. Project Narrative  According to the American Cancer Society, about 7.6 million people died from various  types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,8298614,R01CA141307,"['Address', 'Affect', 'American Cancer Society', 'Breast Cancer Treatment', 'Case-Control Studies', 'Cereals', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Collection', 'Data Quality', 'Data Sources', 'Databases', 'Discipline of Nursing', 'Disease', 'Documentation', 'Effectiveness', 'Epidemiologic Studies', 'Epidemiology', 'Ethics', 'Gold', 'Health', 'Healthcare Industry', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Language', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Education', 'Methods', 'Natural Language Processing', 'Nature', 'New York', 'Observational Study', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Play', 'Population', 'Presbyterian Church', 'Prevention', 'Process', 'Quality of Care', 'Radiology Specialty', 'Randomized Clinical Trials', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Selection Bias', 'Statistical Methods', 'Structure', 'Syndrome', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic Agents', 'Therapeutic procedure', 'Time', 'Translational Research', 'Universities', 'University Hospitals', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'clinical application', 'clinical practice', 'cost', 'efficacy testing', 'improved', 'malignant breast neoplasm', 'novel', 'prevent', 'prognostic indicator', 'public health research', 'statistics', 'treatment effect']",NCI,VANDERBILT UNIVERSITY,R01,2012,56569,0.0043673975117178325
"Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach  Abstract The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The study design is prospective observational study. Scope is limited to cancer patients. There are three specific aims for this project. The first aim is to identify concepts that overlap between the electronic medical record's (EMR) clinical notes and the free text of clinical trial announcements. The PI will use the concepts to develop mapping frames that connect concepts in the text of trial announcements to those found in clinical notes in the medical record. When he has the mapping frames he will build the NLP module for the application. In the software development work he will utilize as many publicly available software components as possible. He will experiment with UIMA, GATE, MetaMap, Stanford Parser, NegEx algorithm and others. The PI will develop the tool around the National Library of Medicine's Unified Medical Language System knowledgebase. He will use Java for programming. The second aim is to create an algorithm that automatically generates questions to request information directly from the patient if the information is not available or accessible in the records. The third aim is to evaluate the in-vitro, laboratory performance of the application. For performance evaluation purposes the PI will recruit cancer care specialists to generate the gold standard lists of eligible clinical trials for study patients. He will publicly release the developed code at the end of the grant period. This K99/R00 project will serve the foundation for future R01 grant applications. The PI is fully committed to become faculty in the Clinical Research Informatics domain with a specialization in biomedical NLP. The support of the K99/R00 grant will enable him to acquire substantial formal training in Computational Linguistics while contributing to the body of knowledge of the Clinical Research Informatics field. The five-year grant support will ensure success in his endeavor. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, EMR based clinical trial recommendations directly to the patients. The results of this research will empower the patients and elevate their role in the decision making process.  Relevance The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, electronic medical record based clinical trial recommendations directly to the patients. The results of this research will empower patients and elevate their role in the decision making process.",Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach,8331381,R00LM010227,"['Adult', 'Age', 'Algorithms', 'Applications Grants', 'Biomedical Research', 'Cancer Patient', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Code', 'Commit', 'Complement', 'Computer software', 'Computerized Medical Record', 'Decision Making', 'Development', 'Elderly', 'Elements', 'Eligibility Determination', 'Enrollment', 'Ensure', 'Equation', 'Evaluation', 'Faculty', 'Foundations', 'Future', 'Goals', 'Gold', 'Grant', 'In Vitro', 'Informatics', 'Java', 'Knowledge', 'Laboratories', 'Linguistics', 'Malignant Neoplasms', 'Maps', 'Medical Records', 'Medicine', 'Methods', 'Minority', 'Modification', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Role', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Surgeon', 'Text', 'Training', 'Unified Medical Language System', 'United States National Library of Medicine', 'Work', 'abstracting', 'base', 'cancer care', 'empowered', 'ethnic minority population', 'information organization', 'knowledge base', 'novel', 'older patient', 'patient oriented', 'programs', 'prospective', 'research study', 'software development', 'success', 'tool']",NLM,CINCINNATI CHILDRENS HOSP MED CTR,R00,2012,238944,0.04310945341693634
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8493901,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2012,1154966,0.029461759346084804
"Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD) DESCRIPTION (provided by applicant): Dr. Khaled Abdel-Kader has completed prior training in nephrology and a master's in medical education with formal training in adult learning, medical errors, and cognitive theory as well as introductory coursework in clinical research and biostatistics. His primary research interest is characterizing and addressing chronic kidney disease (CKD) care deficiencies in the primary care setting. He has received individual post-doctoral funding to support his work in this area. His career goal is to become an expert in CKD epidemiology and an independent clinical investigator studying electronic medical record (EMR)-based interventions to improve CKD care and outcomes. In this career development award (CDA), he focuses on improving primary care physician (PCP) screening for CKD. This award provides him with mentorship, formal coursework, and hands-on experience in epidemiology, research design, medical informatics, decision analysis, health services research, and biostatistics. He has assembled a group of highly skilled mentors who will guide him and help him develop into an independent clinical investigator. A supportive research environment that has already cultivated the development of numerous successful independent clinical investigators complements these individual mentors. In addition, unique institutional resources including a well-developed EMR, EMR research infrastructure, and large patient base make the local environment an ideal setting for the candidate and his research. Dr. Abdel- Kader will use these research experiences, coursework, mentorship, and institutional resources and commitment to continue his progression to becoming an independently funded clinical researcher. An important element of the application is the candidate's research proposal. He will conduct his research project in 2 phases. In the first phase, he will leverage the local, well-developed EMR database and the University of Pittsburgh's large ambulatory patient base (>450,000 unique patients in the prior 2 years) to develop a decision tree predictive model to identify patients at high risk for CKD without the use of serum chemistries. He will compare the performance of the decision tree model to a prominent, recently developed logistic regression model of CKD risk. After identifying the model with the best performance, the candidate will conduct a randomized controlled trial of PCPs examining the effect of implementing the CKD predictive model in the EMR as a clinical alert versus usual care. The clinical alert will remind PCPs to screen high-risk patients for CKD if they have not already done so. This novel approach pairs machine modeling of CKD risk factors with an EMR clinical decision support system (CDSS) to provide real-time guidance to PCPs to improve the care delivered to patients with occult CKD. This project will provide the applicant with valuable experience in data mining, medical informatics, decision analysis, health services research, and clinical trial design and implementation. These experiences will be integral to his development into an independent clinical researcher. In addition to these direct experiences, the applicant will also benefit from the teaching and guidance provided by his team of proficient mentors and consultants. Dr. Mark Unruh, primary mentor for the proposal, is a well-funded, independent clinical investigator who brings expertise in epidemiology, clinical trials, and CKD. Dr. Mark Roberts, Chair of Health Policy and Management at the University of Pittsburgh's Graduate School of Public Health, brings a strong record of independent funding and well-established research interests in predictive modeling, decision tree analysis, and CKD. Dr. Shyam Visweswaran, an investigator in biomedical informatics, brings expertise in biomedical data mining, predictive modeling, and CDSS. Dr. Charity Moore is a highly skilled health services statistician with extensive experience in clinical trials. She will bring her expertise in research design, implementation, analysis, and interpretation to the project. Dr. Gary Fischer, director of the general internal medicine ambulatory clinic, has substantial experience in the integration of the EMR and CDSS with physician workflow. Dr. Douglas Landsittel, a statistician with an interest in the classification of disease outcomes using decision trees, has extensive experience in building and validating predictive models. This interdisciplinary team combines uniquely qualified investigators with the diversity of experience and expertise necessary for the successful completion of the proposed research and the candidate's training. To complement these hands-on experiences and mentorship activities, the candidate will undertake formal coursework through the University of Pittsburgh's Graduate School of Public Health, Department of Biomedical Informatics, and the Institute for Clinical Research Education (part of the university's Clinical and Translational Science Institute). These courses will include formal training in research design and clinical trial implementation, applied medical informatics and decision analysis, and methods in health services research and biostatistics. In addition, the medical center has numerous seminars, workshops, and leadership courses that the candidate will participate in to form collaborative relationships and enhance his skills. In summary, the candidate's research interest in improving the quality of CKD care delivery coupled with a sound background in medical education and early training in clinical research make him an ideal candidate to use this CDA to investigate EMR interventions that can broadly improve CKD screening by PCPs. The applicant's experienced, multidisciplinary mentorship team, strong institutional resources and support, and the formal training he will complete under this award will ensure that he continues to develop into a successful independent clinical investigator studying methods to improve PCP care delivery to CKD patients. Chronic kidney disease is a growing public health problem with over 10% of adults affected by the disorder. Evidence indicates that late recognition and suboptimal care of chronic kidney disease contributes to poor health in these patients. This study will develop a model that can predict the presence of chronic kidney disease without the use of blood work. This model will be implemented to alert doctors in real-time to screen high-risk patients who may have unrecognized chronic kidney disease with the potential to substantially improve the care of these patients.","Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD)",8301548,K23DK090304,"['Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Area', 'Award', 'Behavior', 'Biometry', 'Blood', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Characteristics', 'Charities', 'Chemistry', 'Cholesterol', 'Chronic', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cognitive', 'Comorbidity', 'Complement', 'Computerized Medical Record', 'Coupled', 'Creatinine', 'Data', 'Databases', 'Decision Analysis', 'Decision Trees', 'Development', 'Diagnosis', 'Disease', 'Disease Outcome', 'Disease model', 'Education', 'Educational Intervention', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Evaluation', 'Foundations', 'Funding', 'Goals', 'Guidelines', 'Health', 'Health Policy', 'Health Services', 'Health Services Research', 'Hemoglobin', 'Hospitalization', 'Individual', 'Institutes', 'Internal Medicine', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Leadership', 'Learning', 'Logistic Regressions', 'Medical Education', 'Medical Errors', 'Medical Informatics', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Nephrology', 'Outcome', 'Outpatients', 'Patient Care', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Population', 'Postdoctoral Fellow', 'Prevalence', 'Primary Care Physician', 'Process', 'Provider', 'Public Health', 'Public Health Schools', 'Qualifying', 'Randomized', 'Randomized Controlled Trials', 'Recommendation', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Serum', 'Staging', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'Universities', 'Urine', 'Validation', 'Work', 'advanced disease', 'age related', 'base', 'biomedical informatics', 'care delivery', 'career', 'computer program', 'cost', 'data mining', 'demographics', 'disease diagnosis', 'disorder risk', 'experience', 'high risk', 'improved', 'interest', 'multidisciplinary', 'novel', 'novel strategies', 'predictive modeling', 'primary care setting', 'skills', 'sound', 'theories', 'treatment as usual', 'trend']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K23,2012,172287,0.016503406676452535
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8589822,R01LM010681,[' '],NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2012,237877,0.03823049582899747
"An insilico method for epidemiological studies using Electonic Medical Records Observational epidemiological studies are effective methods for identifying  factors affecting the health and illness of populations, as well as for determining optimal  treatments for diseases, such as cancers. However, conventional epidemiological  research usually involves personnel-intensive effort (such as manual chart and public  records review) and can be very time consuming before conclusive results are obtained.  Recently, a large amount of detailed longitudinal clinical data has been accumulated at  hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data  source for epidemiological studies. However, there are two obstacles that prevent the  wide usage of EMR data in epidemiological studies. First, most of the detailed clinical  information in EMRs is embedded in narrative text and it is very costly to extract that  information manually. Second, EMRs usually have data quality problems such as  selection bias and missing data, which require adaptation of conventional statistical  methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for  observational epidemiological studies using EMR data. We hypothesize that existing  EMR data can be used for certain types of epidemiological studies in a very efficient  manner with the help of informatics methods. The informatics-based approach will  contain two major components. One is an NLP (Natural Language Processing) based  information extraction system that can automatically extract detailed clinical information  from EMR and another is a set of statistical and informatics methods that can be used to  analyze EMR-derived data. If the feasibility of this approach is proven, it will change the  standard paradigm of observational epidemiological research, because it has the  capability to answer an epidemiological question in a very short time at a very low cost.   The specific aim of this study is to develop an automated informatics approach to  extract both fine-grained cancer findings and general clinical information from EMRs and  use them to conduct cancer related epidemiological studies. We will perform both case-  control and cohort studies related to prevention and treatment of breast and colon  cancers using EMR data. The informatics approach will be validated on EMRs from two  major hospitals to demonstrate its generalizability. Epidemiological findings from our  study will be compared to reported findings for validation. Project Narrative  According to the American Cancer Society, about 7.6 million people died from various  types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An insilico method for epidemiological studies using Electonic Medical Records,8589201,R01CA141307,[' '],NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2012,195838,0.001313486217775576
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8077875,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2011,374000,0.03823049582899747
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,8144459,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2011,147161,0.026753251280373536
"Detecting deviations in clinical care in ICU data streams    DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient [1]. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our preliminary studies provide support that such deviations often indicate clinically important events for which it is worthwhile to raise an alert. We propose an evaluation based on physician assessment of alerts that are generated from a retrospective set of intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories.    PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.           PROJECT NARRATIVE There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.",Detecting deviations in clinical care in ICU data streams,8098786,R01GM088224,"['Algorithms', 'Anticoagulants', 'Belief', 'Cardiac', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Detection', 'Development', 'Disadvantaged', 'Drops', 'Electronics', 'Evaluation', 'Event', 'Future', 'Healthcare', 'Heparin', 'Individual', 'Industry', 'Information Systems', 'Intensive Care Units', 'Knowledge', 'Lead', 'Left', 'Machine Learning', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Patient Care', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Platelet Count measurement', 'Play', 'Practice Management', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Services', 'Signal Transduction', 'Solutions', 'Statistical Models', 'Stream', 'System', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Time', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'cost', 'experience', 'follow-up', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'public health relevance', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2011,498467,0.026563200597767192
"Using medical records repositories to improve the alert system design    DESCRIPTION (provided by applicant):       Rapid and accurate alerting of concerning patient events and conditions remains an important problem in clinical practice. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into the monitoring and alerting systems. However, it is often time-consuming and costly to extract and codify such knowledge; hence such systems are typically built to cover only very specific conditions. In addition, it is difficult for an expert to foresee the performance of the deployed systems and their potential drawbacks, especially their false alarm rates. It is not uncommon that computer alerting systems are discarded or must undergo multiple costly modification cycles before they reach clinically acceptable levels of performance.    Electronic health record (EHR) repositories today provide an opportunity to test various theories and develop new computational solutions to various clinical problems. The objective of this project is to investigate methods for using the data in such repositories to assist in the development of alerting systems. The project goals include the building of an evidence-driven framework for the evaluation and optimization of alerting systems with the help of past data. The framework will be able to provide early feedback and future performance estimates of an alerting system before it is deployed, which is anticipated to decrease the expert effort required to design such a system and lead to a shorter alerting system design cycle. The evidence-driven framework will be tested and evaluated on multiple clinical conditions and compared to the performance of alerting rules currently deployed at the University of Pittsburgh Medical Center (UPMC). The project investigators consist of a multidisciplinary team with expertise in rule-based alerting in the hospital setting, clinical pharmacy, laboratory medicine, biomedical informatics, statistical machine learning, and knowledge based systems.           Project Narrative: There remain numerous opportunities to reduce medical errors by sending computer-based reminders and alerts to clinicians. This project investigates a novel combination of past patient data stored in electronic form and statistical machine-learning methods to help develop and refine computer-based alerts, which are expected to improve healthcare quality and reduce costs.",Using medical records repositories to improve the alert system design,8139263,R01LM010019,"['Amiodarone', 'Archives', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Data', 'Databases', 'Detection', 'Development', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Event', 'Expert Opinion', 'Feedback', 'Future', 'Goals', 'Gold', 'Heparin', 'Hospitals', 'Human', 'Information Systems', 'Knowledge', 'Knowledge acquisition', 'Label', 'Laboratories', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Medical Errors', 'Medical Informatics', 'Medical Records', 'Medical center', 'Medicine', 'Methods', 'Metric', 'Modeling', 'Modification', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Pharmacy facility', 'Physicians', 'Research', 'Research Personnel', 'Solutions', 'Source', 'Statistical Methods', 'Stream', 'System', 'Techniques', 'Testing', 'Thrombocytopenia', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Universities', 'base', 'biomedical informatics', 'clinical practice', 'cost', 'design', 'evaluation/testing', 'flexibility', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'novel', 'predictive modeling', 'repository', 'response', 'statistics', 'success', 'theories', 'treatment response']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2011,366808,0.0026312869825095724
"Secure Sharing of Clinical History & Genetic Data: Empowering Predictive Pers. Me    DESCRIPTION (provided by applicant):       Computer-assisted medicine is at a crossroads: medical care requires accurate data, but making such data widely available can create unacceptable risks to the privacy of individual patients. This tension between utility and privacy is especially acute in predictive personalized medicine (PPM). PPM holds the promise of making treatment decisions tailored to the individual based on her or his particular genetics and clinical history. Making PPM a reality requires running statistical, data mining and machine learning algorithms on combined genetic, clinical and demographic data to construct predictive models. Access to such data directly competes with the need for healthcare providers to protect the privacy of each patient's data, thus creating a tradeoff between model efficacy and privacy. Thus we find ourselves in an unfortunate standoff: significant medical advances that would result from more powerful mining of the data by a wider variety of researchers are hindered by significant privacy concerns on behalf of the patients represented in the data set. In this proposed work, we seek to develop and evaluate technology to resolve this standoff, enabling health practitioners and researchers to compute on privacy-sensitive medical records in order to make treatment decisions or create accurate models, while protecting patient privacy. We will evaluate our approach on a de-identified actual electronic medical record, with an average of 29 years of clinical history on each patient, and with detailed genetic data (650K SNPs) available for a subset of 5000 of the patients. This data set is available to us now through the Wisconsin Genomics Initiative, but only on a computer at the Marshfield Clinic. If successful our approach will make possible the sharing of this cutting-edge data set, and others like it that are now in development, including our ability to analyze this data at UW-Madison where we have thousands of processors available in our Condor pool. Our privacy approach integrates secure data access environments, including those appropriate to the use of laptops and cloud computing, with novel anonymization algorithms providing differential privacy guarantees for data and/or published results of data analysis. To this end, our specific aims are as follows:       AIM 1: Develop and deploy a secure local environment that, in combination with secure network functionality, will ensure end-to-end security and privacy for electronic medical records and biomedical datasets shared between clinical institutions and researchers.       AIM 2: Develop and deploy a secure virtual environment to allow large-scale, privacy-preserving data analysis ""in the cloud.""       AIM 3: Develop and evaluate privacy-preserving data mining algorithms for use with original (not anonymized) data sets consisting of electronic medical records and genetic data.       AIM 4: Develop and evaluate anonymizing data publishing algorithms and privacy guarantees that are appropriate to the complex structure present in electronic medical records with genetic data.            Project Narrative This project will develop an integrated approach to secure sharing of clinical and genetic data that based on algorithms for anonymization of data to achieve differential privacy guarantees, for privacy-preserving publication of data analysis results, and secure environments for data sharing that include addressing the increasing use of laptops and of cloud computing. The end goal of this project is to meet the competing demands of providing patients with both privacy and accurate predictive models based on clinical history and genetics. This project includes the first concrete evaluation of privacy- preserving data mining algorithms on actual combined EMR and genetic data, using with the Wisconsin Genomics Initiative data set.",Secure Sharing of Clinical History & Genetic Data: Empowering Predictive Pers. Me,8085051,R01LM011028,"['Acute', 'Address', 'Algorithms', 'Caring', 'Clinic', 'Clinical', 'Complex', 'Computer Assisted', 'Computer Security', 'Computer software', 'Computerized Medical Record', 'Computers', 'Confidentiality', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Dose', 'Ensure', 'Environment', 'Evaluation', 'Genetic', 'Genetic Databases', 'Genomics', 'Goals', 'Health', 'Health Personnel', 'Individual', 'Institution', 'Lead', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medical Records', 'Medicine', 'Mining', 'Modeling', 'Operating System', 'Output', 'Patients', 'Privacy', 'Publications', 'Publishing', 'Recording of previous events', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Structure', 'System', 'Technology', 'Warfarin', 'Wisconsin', 'Work', 'base', 'data management', 'data mining', 'data sharing', 'design', 'empowered', 'experience', 'laptop', 'meetings', 'novel', 'patient privacy', 'predictive modeling', 'prototype', 'virtual']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2011,588817,0.028956379693266806
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8133360,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,664617,0.06282482954901003
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8022026,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,591195,0.01570451187244843
"An in-silico method for epidemiological studies using Electronic Medical Records DESCRIPTION: Observational epidemiological studies are effective methods for identifying factors affecting the health and illness of populations, as well as for determining optimal treatments for diseases, such as cancers. However, conventional epidemiological research usually involves personnel-intensive effort (such as manual chart and public records review) and can be very time consuming before conclusive results are obtained. Recently, a large amount of detailed longitudinal clinical data has been accumulated at hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data source for epidemiological studies. However, there are two obstacles that prevent the wide usage of EMR data in epidemiological studies. First, most of the detailed clinical information in EMRs is embedded in narrative text and it is very costly to extract that information manually. Second, EMRs usually have data quality problems such as selection bias and missing data, which require adaptation of conventional statistical methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for observational epidemiological studies using EMR data. We hypothesize that existing EMR data can be used for certain types of epidemiological studies in a very efficient manner with the help of informatics methods. The informatics-based approach will contain two major components. One is an NLP (Natural Language Processing) based information extraction system that can automatically extract detailed clinical information from EMR and another is a set of statistical and informatics methods that can be used to analyze EMR-derived data. If the feasibility of this approach is proven, it will change the standard paradigm of observational epidemiological research, because it has the capability to answer an epidemiological question in a very short time at a very low cost. The specific aim of this study is to develop an automated informatics approach to extract both fine-grained cancer findings and general clinical information from EMRs and use them to conduct cancer related epidemiological studies. We will perform both casecontrol and cohort studies related to prevention and treatment of breast and colon cancers using EMR data. The informatics approach will be validated on EMRs from two major hospitals to demonstrate its generalizability. Epidemiological findings from our study will be compared to reported findings for validation.  Project Narrative According to the American Cancer Society, about 7.6 million people died from various types of cancer in the world during 2007. It is very important to identify risk factors of cancers and to determine optimal treatments of cancers, and epidemiological study is one of the methods to achieve it. This proposed study will use natural language processing technologies to automatically extract fine-grained cancer information from existing patient electronic medical records and use it to conduct cancer related epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,8110041,R01CA141307,"['Affect', 'American Cancer Society', 'Breast Cancer Treatment', 'Cereals', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Quality', 'Data Sources', 'Disease', 'Epidemiologic Studies', 'Epidemiology', 'Health', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Natural Language Processing', 'Patients', 'Population', 'Prevention', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Risk Factors', 'Selection Bias', 'Statistical Methods', 'System', 'Technology', 'Text', 'Time', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'cost', 'prevent']",NCI,VANDERBILT UNIVERSITY,R01,2011,252298,0.0043673975117178325
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),8145183,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Caring', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Systematized Nomenclature of Medicine', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2011,374400,0.04919448394561618
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,8306467,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Institutional Review Boards', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2011,13000,0.046127103997035485
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8182025,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2011,325163,0.011956292040670244
"Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership    DESCRIPTION (provided by applicant): The Seattle eMERGE project aims to bring personal genomics to practice settings by taking advantage of the extensive electronic medical record (EMR) and biorepository of Group Health Cooperative (GH), including a 33-year pharmacy database and longitudinal data on an aging population. Algorithms developed in eMERGE I will be used to combine genome-wide association studies with phenotypes mined from EMRs to discover new polymorphism-phenotype relationships. Target phenotypes are infectious disease susceptibility, specifically to Clostridium difficile diarrhea, shingles from varicella zoster virus, and fungal nail infection, responses to antihypertensive drugs, serotonin-specific reuptake inhibitors, and statins, including adverse events. A new algorithm will follow longitudinal glycemia and hematocrit trajectories, and a novel automated method will detect karyotype abnormalities for assessing correlation to myelodysplasia and leukemia. Data will also support phenotypes investigated at other eMERGE sites. To create a model for introducing genomics into clinical practice, successful needs assessment methods from eMERGE I will engage stakeholders in guiding development of prototype EMR user interfaces in a clinical decision support format. The test case will be human leukocyte antigen-typing for an adverse drug reaction and the setting will be the patient-centered medical home care model developed at GH. This proposal provides the eMERGE network and its collaborators with the Seattle team's unique expertise in using natural language processing (NLP) to extract information from EMRs, and assisting in adoption of NLP methods. To disseminate eMERGE results and foster collaborations, it takes advantage of leadership positions of the investigators, including partners within eMERGE, other consortia and the HMO Research network, especially the potential for developments supported by the NIH Director's Common Fund in biobanking and megaepidemiology. Completion of the aims will reveal new, medically useful markers, improve the linking of high-throughput genomic methods to EMR data, and develop policies and practices for bringing individualized evidence-based medicine to communities.       RELEVANCE (See instrucfions): To advance personalized medicine-treatment and preventive care based on individual traits; this project matches small differences in DNA to infectious disease susceptibility and response to statins, serotonin- specific reuptake inhibitors (SSRIs) and blood pressure medications. Methods to use these results in clinical care will be guided by focus groups of patients and caregivers in the patient-centered Group Health system.              n/a",Genetic Discovery and  Application in a Clinical Setting Continuing a Partnership,8192387,U01HG006375,"['Address', 'Adoption', 'Adverse event', 'Algorithms', 'Anemia', 'Antihypertensive Agents', 'Bioethics', 'Blood Pressure', 'Bone Marrow Diseases', 'Caregivers', 'Caring', 'Chromosome abnormality', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computerized Medical Record', 'Consent', 'DNA', 'Data', 'Development', 'Diabetes Mellitus', 'Diarrhea', 'Disease', 'Disease susceptibility', 'Dysmyelopoietic Syndromes', 'Ensure', 'Epidemiology', 'Evidence Based Medicine', 'Excision', 'Focus Groups', 'Fostering', 'Funding', 'Genetic', 'Genetic Polymorphism', 'Genomics', 'Goals', 'HLA Antigens', 'Health', 'Health system', 'Healthcare', 'Hematocrit procedure', 'Herpes zoster disease', 'Herpesvirus Type 3', 'Incidental Findings', 'Individual', 'Infection', 'Karyotype', 'Knowledge', 'Leadership', 'Libraries', 'Link', 'Low-Density Lipoproteins', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mental Depression', 'Methods', 'Mining', 'Modeling', 'Nail plate', 'Natural Language Processing', 'Needs Assessment', 'Other Genetics', 'Outcome', 'Oxidoreductase', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Phenotype', 'Policies', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Qualifying', 'Reaction', 'Research', 'Research Personnel', 'Resources', 'Serotonin', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Systems Biology', 'Technology', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Variant', 'aging population', 'base', 'biobank', 'clinical application', 'clinical care', 'clinical practice', 'clinical research site', 'clinically relevant', 'comparative effectiveness', 'design', 'effectiveness research', 'ethical legal social implication', 'evidence base', 'experience', 'genetic technology', 'genome wide association study', 'improved', 'inhibitor/antagonist', 'leukemia', 'leukocyte antigen typing', 'longitudinal database', 'member', 'novel', 'patient home care', 'patient oriented', 'patient population', 'prototype', 'response', 'reuptake', 'skills', 'standard care', 'trait']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2011,818798,0.029461759346084804
"Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD)    DESCRIPTION (provided by applicant): Dr. Khaled Abdel-Kader has completed prior training in nephrology and a master's in medical education  with formal training in adult learning, medical errors, and cognitive theory as well as introductory coursework in  clinical research and biostatistics. His primary research interest is characterizing and addressing chronic  kidney disease (CKD) care deficiencies in the primary care setting. He has received individual post-doctoral  funding to support his work in this area. His career goal is to become an expert in CKD epidemiology and an  independent clinical investigator studying electronic medical record (EMR)-based interventions to improve CKD  care and outcomes. In this career development award (CDA), he focuses on improving primary care physician  (PCP) screening for CKD. This award provides him with mentorship, formal coursework, and hands-on  experience in epidemiology, research design, medical informatics, decision analysis, health services research,  and biostatistics. He has assembled a group of highly skilled mentors who will guide him and help him develop  into an independent clinical investigator. A supportive research environment that has already cultivated the  development of numerous successful independent clinical investigators complements these individual mentors.  In addition, unique institutional resources including a well-developed EMR, EMR research infrastructure, and  large patient base make the local environment an ideal setting for the candidate and his research. Dr. Abdel-  Kader will use these research experiences, coursework, mentorship, and institutional resources and  commitment to continue his progression to becoming an independently funded clinical researcher.   An important element of the application is the candidate's research proposal. He will conduct his  research project in 2 phases. In the first phase, he will leverage the local, well-developed EMR database and  the University of Pittsburgh's large ambulatory patient base (>450,000 unique patients in the prior 2 years) to  develop a decision tree predictive model to identify patients at high risk for CKD without the use of serum  chemistries. He will compare the performance of the decision tree model to a prominent, recently developed  logistic regression model of CKD risk. After identifying the model with the best performance, the candidate will  conduct a randomized controlled trial of PCPs examining the effect of implementing the CKD predictive model  in the EMR as a clinical alert versus usual care. The clinical alert will remind PCPs to screen high-risk patients  for CKD if they have not already done so. This novel approach pairs machine modeling of CKD risk factors with  an EMR clinical decision support system (CDSS) to provide real-time guidance to PCPs to improve the care  delivered to patients with occult CKD. This project will provide the applicant with valuable experience in data  mining, medical informatics, decision analysis, health services research, and clinical trial design and  implementation. These experiences will be integral to his development into an independent clinical researcher.   In addition to these direct experiences, the applicant will also benefit from the teaching and guidance  provided by his team of proficient mentors and consultants. Dr. Mark Unruh, primary mentor for the proposal, is  a well-funded, independent clinical investigator who brings expertise in epidemiology, clinical trials, and CKD.  Dr. Mark Roberts, Chair of Health Policy and Management at the University of Pittsburgh's Graduate School of  Public Health, brings a strong record of independent funding and well-established research interests in  predictive modeling, decision tree analysis, and CKD. Dr. Shyam Visweswaran, an investigator in biomedical  informatics, brings expertise in biomedical data mining, predictive modeling, and CDSS. Dr. Charity Moore is a  highly skilled health services statistician with extensive experience in clinical trials. She will bring her expertise  in research design, implementation, analysis, and interpretation to the project. Dr. Gary Fischer, director of the  general internal medicine ambulatory clinic, has substantial experience in the integration of the EMR and  CDSS with physician workflow. Dr. Douglas Landsittel, a statistician with an interest in the classification of  disease outcomes using decision trees, has extensive experience in building and validating predictive models.  This interdisciplinary team combines uniquely qualified investigators with the diversity of experience and  expertise necessary for the successful completion of the proposed research and the candidate's training.   To complement these hands-on experiences and mentorship activities, the candidate will undertake formal  coursework through the University of Pittsburgh's Graduate School of Public Health, Department of Biomedical  Informatics, and the Institute for Clinical Research Education (part of the university's Clinical and Translational  Science Institute). These courses will include formal training in research design and clinical trial  implementation, applied medical informatics and decision analysis, and methods in health services research  and biostatistics. In addition, the medical center has numerous seminars, workshops, and leadership courses  that the candidate will participate in to form collaborative relationships and enhance his skills.   In summary, the candidate's research interest in improving the quality of CKD care delivery coupled with a  sound background in medical education and early training in clinical research make him an ideal candidate to  use this CDA to investigate EMR interventions that can broadly improve CKD screening by PCPs. The  applicant's experienced, multidisciplinary mentorship team, strong institutional resources and support, and the  formal training he will complete under this award will ensure that he continues to develop into a successful  independent clinical investigator studying methods to improve PCP care delivery to CKD patients.   PUBLIC HEALTH RELEVANCE: Chronic kidney disease is a growing public health problem with over 10% of adults affected by the disorder.  Evidence indicates that late recognition and suboptimal care of chronic kidney disease contributes to poor  health in these patients. This study will develop a model that can predict the presence of chronic kidney  disease without the use of blood work. This model will be implemented to alert doctors in real-time to screen  high-risk patients who may have unrecognized chronic kidney disease with the potential to substantially  improve the care of these patients.        Chronic kidney disease is a growing public health problem with over 10% of adults affected by the disorder.  Evidence indicates that late recognition and suboptimal care of chronic kidney disease contributes to poor  health in these patients. This study will develop a model that can predict the presence of chronic kidney  disease without the use of blood work. This model will be implemented to alert doctors in real-time to screen  high-risk patients who may have unrecognized chronic kidney disease with the potential to substantially  improve the care of these patients.      ","Developing, Validating, and Implementing a CKD Predictive Model (DELVECKD)",8189595,K23DK090304,"['Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Area', 'Award', 'Behavior', 'Biometry', 'Blood', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Characteristics', 'Charities', 'Chemistry', 'Cholesterol', 'Chronic', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cognitive', 'Comorbidity', 'Complement', 'Computerized Medical Record', 'Coupled', 'Creatinine', 'Data', 'Databases', 'Decision Analysis', 'Decision Trees', 'Development', 'Diagnosis', 'Disease', 'Disease Outcome', 'Disease model', 'Education', 'Educational Intervention', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Evaluation', 'Foundations', 'Funding', 'Goals', 'Guidelines', 'Health', 'Health Policy', 'Health Services', 'Health Services Research', 'Hemoglobin', 'Hospitalization', 'Individual', 'Institutes', 'Internal Medicine', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Leadership', 'Learning', 'Logistic Regressions', 'Medical Education', 'Medical Errors', 'Medical Informatics', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Nephrology', 'Outcome', 'Outpatients', 'Patient Care', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Population', 'Postdoctoral Fellow', 'Prevalence', 'Primary Care Physician', 'Process', 'Provider', 'Public Health', 'Public Health Schools', 'Qualifying', 'Randomized', 'Randomized Controlled Trials', 'Recommendation', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Serum', 'Staging', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'Universities', 'Urine', 'Validation', 'Work', 'advanced disease', 'age related', 'base', 'biomedical informatics', 'care delivery', 'career', 'computer program', 'cost', 'data mining', 'demographics', 'disease diagnosis', 'disorder risk', 'experience', 'high risk', 'improved', 'interest', 'multidisciplinary', 'novel', 'novel strategies', 'predictive modeling', 'primary care setting', 'skills', 'sound', 'theories', 'treatment as usual', 'trend']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K23,2011,172287,0.015900930909731794
"Automating assessment of obesity care quality    DESCRIPTION (provided by applicant): Current trends suggest that obesity prevalence will continue to rise and that costs of treating obesity-related disease will dramatically increase as the population ages. Despite NHLBI guidelines for preventing, diagnosing, and treating obesity among adults, most health care systems have been slow to respond to this looming public health problem. This slow response is partly due to the inability to assess adherence to obesity diagnosis and treatment guidelines. In particular, the lack of appropriate Health IT for integrating diverse clinical data on obesity, even within state-of-the-art electronic medical record systems (EMRs), makes it difficult to evaluate the quality of care, measure the effectiveness of new intervention programs, and make rational decisions at system, organization, and individual patient levels. EMRs offer the potential to efficiently assess large populations, however much of the data necessary for obesity care assessment are unavailable to automated methods because they reside in the text clinical notes of the EMR. Previous studies have shown that although some data of interest are recorded in easily retrievable fields (e.g., body weights recorded as a vital sign; standard diagnosis codes), much of the treatment information is found only in free-text clinical notes. This research aims to develop, validate, apply, and evaluate a scalable method for routine and comprehensive measurement of outpatient obesity care quality. To accomplish this, we will extend MediClass (a ""Medical Classifier""), which is a proven technology for extracting care quality data from both coded data and free-text clinical notes in the EMR. This research will perform retrospective analysis of adult primary care from the EMR data of two distinct health systems: a   mid-sized HMO (Kaiser Permanente Northwest, KPNW) and a consortium of public health clinics (OCHIN) including a diverse sample of patients, providers, and health care practices of the West Coast states (primarily Oregon, but also Washington and California). We propose to use Health IT to integrate diverse data and knowledge that advance quality improvement for both insured and the indigent, uninsured, and underinsured populations of this region. We will first develop obesity care quality (OCQ) measures using up to-date NHLBI guidelines for diagnosis and treatment of obesity. Next, we will develop and validate an automated method for applying these measures to comprehensive EMR data. At each study site, the Medi Class system will extract coded data and use natural language processing (NLP) on free-text clinical notes to identify OCQ-relevant clinical events in the EMR. Then we will apply the OCQ measures to assess current levels of obesity care quality in the two health systems. Finally, we will evaluate the associations between OCQ measures of recommended obesity care and provider characteristics as well as clinical outcomes for patients, including change in weight.           PROJECT NARRATIVE This study will improve care for obese and overweight patients by improving the technology we use for measuring the quality of care for these populations. This study will use specialized computer programs to analyze the electronic medical records of obese and overweight patients. The results of this work will help us determine if patients from two different health care systems are receiving recommended care, and how to better monitor the delivery of care for obese and overweight patients.",Automating assessment of obesity care quality,8136907,R18HS018157,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R18,2011,247887,0.03453516620617526
"Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach No abstract available  Relevance The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, electronic medical record based clinical trial recommendations directly to the patients. The results of this research will empower patients and elevate their role in the decision making process.",Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach,8215715,R00LM010227,"['Adult', 'Age', 'Algorithms', 'Applications Grants', 'Biomedical Research', 'Cancer Patient', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Code', 'Commit', 'Complement', 'Computer software', 'Computerized Medical Record', 'Decision Making', 'Development', 'Elderly', 'Elements', 'Eligibility Determination', 'Enrollment', 'Ensure', 'Equation', 'Evaluation', 'Faculty', 'Foundations', 'Future', 'Goals', 'Gold', 'Grant', 'In Vitro', 'Informatics', 'Java', 'Knowledge', 'Laboratories', 'Linguistics', 'Malignant Neoplasms', 'Maps', 'Medical Records', 'Medicine', 'Methods', 'Minority', 'Modification', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Role', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Surgeon', 'Text', 'Training', 'Unified Medical Language System', 'United States National Library of Medicine', 'Work', 'abstracting', 'base', 'cancer care', 'empowered', 'ethnic minority population', 'information organization', 'knowledge base', 'novel', 'older patient', 'patient oriented', 'programs', 'prospective', 'research study', 'software development', 'success', 'tool']",NLM,CINCINNATI CHILDRENS HOSP MED CTR,R00,2011,239040,0.02893512376016524
"A Hybrid General Natural Language Processing Architecture    DESCRIPTION (provided by applicant): Electronic medical records and exchanges offer new opportunities for the analysis of population health data; however, new methods in natural language processing (NLP) must first be developed to structure and codify these records, since most medical data is in the form of free text which cannot be stored and manipulated by computers. Once this is accomplished, population health data can be analyzed which will lead to better treatment guidelines, targeted drug therapy, and more cost effective care. Logical Semantics, Inc. (LSI) proposes to develop new statistical NLP methods for analyzing large scale medical domains. These methods will leverage LSI's semantic annotation technology, which has created the largest semantically annotated clinical corpus in the world. LSI's goal is to semantically index large medical record repositories accurately against propositions arranged in knowledge ontologies and make these indices available for text mining applications. The phase one research is focused on three specific aims that will lead to breakthroughs in the science of NLP: (1) Develop new statistical NLP algorithms employing a large semantically annotated medical corpus, (2) Semi-automate knowledge ontology generation, and (3) Develop and combine rule based with statistical NLP algorithms to create a superior hybrid NLP system. The achievement of these aims will result in computer systems that can extract the meaning from free text medical records so researchers, policy makers, and clinicians can use health analytics to improve healthcare.      PUBLIC HEALTH RELEVANCE: Natural language processing (NLP) has been successful in extracting specific findings and diagnoses from free text medical records. However, for NLP to be useful in health analytics, methods must be devised to capture most of the findings in a medical record. Logical Semantics, Inc. (LSI) proposes to build new statistical algorithms that can scale against the numerous complex findings in medical reports. LSI will leverage its advanced semantic annotation technology which employs corpus linguistics and sentential logic to build these new algorithms. The goal is to abstract over 80% of a free text records into computer readable form so that researchers can develop new treatment guidelines, improve decision support, and deliver more cost effective care.           Project Narrative Natural language processing (NLP) has been successful in extracting specific findings and diagnoses from free text medical records. However, for NLP to be useful in health analytics, methods must be devised to capture most of the findings in a medical record. Logical Semantics, Inc. (LSI) proposes to build new statistical algorithms that can scale against the numerous complex findings in medical reports. LSI will leverage its advanced semantic annotation technology which employs corpus linguistics and sentential logic to build these new algorithms. The goal is to abstract over 80% of a free text records into computer readable form so that researchers can develop new treatment guidelines, improve decision support, and deliver more cost effective care.",A Hybrid General Natural Language Processing Architecture,7996937,R43LM010846,"['Achievement', 'Address', 'Algorithms', 'Architecture', 'Businesses', 'Caring', 'Clinical', 'Communities', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Computers', 'Data', 'Diagnosis', 'Discipline', 'Generations', 'Goals', 'Guidelines', 'Health', 'Healthcare', 'Hybrids', 'Knowledge', 'Lead', 'Legal patent', 'Linguistics', 'Logic', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Metric', 'Mining', 'Natural Language Processing', 'Ontology', 'Pattern', 'Pharmacotherapy', 'Phase', 'Policy Maker', 'Process', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Work', 'abstracting', 'base', 'cost effective', 'improved', 'indexing', 'knowledge base', 'operation', 'phrases', 'population health', 'public health relevance', 'repository', 'stem', 'success', 'text searching', 'tool']",NLM,"LOGICAL SEMANTICS, INC.",R43,2010,148180,0.06675716091936713
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,7866149,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2010,387500,0.03823049582899747
"Natural Language Processing to Study Epidemiology of Statin Side Effects    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (10) Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-101: Informatics for post-marketing surveillance. The overall goal of this study is to develop a generalizable framework for studying medication side effects recorded in narrative medical documents. We will implement and test this system on the example of epidemiologic characterization of side effects of HMG-CoA reductase inhibitors (a.k.a. statins). Statins are the most commonly used class of medications for treatment of hypercholesterolemia in the U.S. In randomized clinical trials statins are associated only with a slight increase in adverse reactions and no increase in discontinuation of treatment compared to placebo. However, in clinical practice the rates of side effects and discontinuation appear significantly higher and represent a major barrier to a critical, potentially lifesaving therapy. For example, myalgias are reported to be relatively rare in clinical trials but are thought to be more common in clinical practice. Additionally, a number of other statin-associated complaints reported anecdotally but not well elucidated in clinical trials include depression, irritability, and memory loss among others. Most of these have been poorly epidemiologically characterized and their prevalence and risk factors remain unknown. Structured electronic medical record (EMR) and administrative data have been used to study medication side effects. However, structured data have important limitations. They may not contain temporal or causative information necessary to link particular problems to medications and may not be sufficiently granular to identify specific adverse reactions. Narrative EMR data, such as provider notes, can provide documentation of causative links between medication and adverse events at high levels of granularity. Natural language processing (NLP) is an emerging technology that enables computational abstraction of information from narrative medical documents. In prior work we have successfully applied natural language processing to abstract medication information from narrative provider notes, including medication intensification, medication non-adherence and medication discontinuation. We will leverage these tools and the extensive EMR infrastructure at Partners HealthCare to develop and test a natural language processing system to study medication side effects. We will validate this system on the example of studying epidemiology of adverse reactions to statins. The findings of this project will lay the foundation for an open-source system that can be used for post-marketing surveillance of medication side effects using narrative EMR data.       PUBLIC HEALTH RELEVANCE (provided by applicant): Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.                 Natural Language Processing to Study Epidemiology of Statin Side Effects  Project Narrative  Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.",Natural Language Processing to Study Epidemiology of Statin Side Effects,7936999,RC1LM010460,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Area', 'Cholesterol', 'Clinical Trials', 'Computerized Medical Record', 'Data', 'Documentation', 'Emerging Technologies', 'Epidemiology', 'Foundations', 'Frequencies', 'Goals', 'Healthcare', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Hypersensitivity', 'Incidence', 'Informatics', 'Information Technology', 'Link', 'Medical', 'Memory Loss', 'Mental Depression', 'Myalgia', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Placebos', 'Prevalence', 'Process', 'Provider', 'Randomized Clinical Trials', 'Reaction', 'Records', 'Reporting', 'Research Infrastructure', 'Risk Factors', 'Semantics', 'Side', 'Structure', 'System', 'Systems Analysis', 'Testing', 'Text', 'Work', 'abstracting', 'clinical practice', 'design', 'epidemiology study', 'hypercholesterolemia', 'medication compliance', 'open source', 'post-market', 'public health relevance', 'repository', 'research study', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,RC1,2010,499697,0.047184503759763685
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,7921455,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2010,148350,0.026753251280373536
"Natural Language Processing for Cancer Research Network Surveillance Studies    DESCRIPTION (provided by applicant): This application addresses Broad Challenge Area: (10) Information Technology for Processing Health Care Data and specific Challenge Topic: 10-CA-107 Expand Spectrum of Cancer Surveillance through Informatics Approaches. The proposed project launches a collaborative effort to advance adoption within the HMO Cancer Research Network (CRN) of ""industrial-strength"" natural language processing (NLP) systems useful for mining valuable, research-grade information from unstructured clinical text. Such text is available for processing, now in the electronic medical record (EMR) systems of affiliated CRN health plans. The proposed NLP methods   will create ongoing capacity to tap what has recently been described as ""a treasure trove of historical   unstructured data that provides essential information for the study of disease progression, treatment   effectiveness and long-term outcomes"" (5). The vision of advancing widespread NLP capacity across the CRN, as well as the approach we present here for implementing it, grew out of an in-depth strategic planning effort we completed in December 2008. That effort involved participants from six CRN sites guided by a blue-ribbon panel of NLP experts from three of the nation's leading centers of clinical NLP research: University of Pittsburgh Medical Center, Vanderbilt University, and Mayo Clinic. The vision is to deploy a powerful NLP system locally, manage it with newly hired and trained local NLP technical staff, and conduct NLP-based research projects initiated by local investigators, in consultation with higher-level external NLP experts. Our planning efforts suggest this collaborative model is feasible; we will test the model in the context of the proposed project. An important development in April 2009 yielded what we believe is a potentially transformative opportunity to accelerate adoption of NLP capacity in applied research settings: release of the open-source Clinical Text Analysis and Knowledge Extraction System (cTAKES) software. This software was the result of a collaborative effort between IBM and Mayo Clinic. Built on the same framework Mayo Clinic currently uses to process its repository of over 40 million clinical documents, cTAKES dramatically lowers the cost of adopting a comprehensive and flexible NLP system. Deployment and use of such systems was previously only feasible in institutions with large, academically-oriented biomedical informatics research programs.   Still, other deployment challenges and the need to acquire NLP training for local staff present residual   barriers to adopting comprehensive NLP systems such as cTAKES. In collaboration with five other CRN sites the proposed project mitigates these challenges in two ways: 1) it develops configurable open-source software modules needed to streamline and therefore reduce the cost of deploying cTAKES, and 2) it presents and tests a model for training local staff through hands-on NLP projects overseen by outside NLP expert consultants. The potential impact of this project is evident most clearly in the vast untapped opportunities for text mining represented in CRN-affiliated health plans, where EMR systems have been in place since at least 2005, and whose patients represent 4% of the U.S. population. Clinical text mining offers the potential to provide new or improved data elements for cancer surveillance and other types of research requiring information about patient functional status, medication side-effects, details of therapeutic approaches, and differential information about clinical findings. Another significant impact of this project is its plan to integrate into the cTAKES system   an open-source de-identification tool based on state of the art, best of breed NLP approaches developed by the MITRE Corporation. De-identification of clinical text will make it easier for researchers to get access to clinical text, and will also facilitate multi-site collaborations while protecting patient privacy. Finally, if successful, the NLP algorithm we propose as a proof-of-principle project at Group Health-which will classify sets of patient charts as either containing or not containing a diagnosis of recurrent breast cancer-could dramatically reduce the cost of research in this area; currently all recurrent breast cancer endpoints must be established through costly manual chart abstraction.   Novel aspects of the proposed project include its talented and transdisciplinary research team,   including national experts in NLP, and its resourceful strategy for building the technical resources and ""human capital"" needed to support an ongoing program of applied NLP research. Natural language processing is itself a highly innovative technology; when successfully established in multiple CRN in the future it will represent a watershed moment in the CRN's already impressive history of exploiting data systems to support innovative research. Newly hired staff positions total approximately 2.0 FTE in each project year, most of which we anticipate will be supported by ongoing new research programs after the proposed project concludes. Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.           Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.",Natural Language Processing for Cancer Research Network Surveillance Studies,7944035,RC1CA146917,"['Address', 'Adopted', 'Adoption', 'Adverse effects', 'Algorithms', 'Applied Research', 'Area', 'Arts', 'Bioinformatics', 'Breeding', 'Cancer Research Network', 'Charge', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Complex', 'Comprehensive Health Care', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Data', 'Data Element', 'Data Quality', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Environment', 'Epidemiology', 'Exercise', 'Future', 'Generic Drugs', 'Hand', 'Health', 'Health Planning', 'Health system plans', 'Healthcare', 'Human Resources', 'Individual', 'Informatics', 'Information Systems', 'Information Technology', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Licensing', 'Life', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Mining', 'Modeling', 'NCI Center for Cancer Research', 'Natural Language Processing', 'Operating System', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Process', 'Public Health', 'Recording of previous events', 'Recurrence', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Resources', 'Risk', 'Site', 'Solutions', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Training', 'Treatment Effectiveness', 'Universities', 'Vision', 'Woman', 'base', 'biomedical informatics', 'breast cancer diagnosis', 'cost', 'design', 'experience', 'feeding', 'firewall', 'flexibility', 'functional status', 'human capital', 'improved', 'innovation', 'innovative technologies', 'malignant breast neoplasm', 'novel', 'open source', 'patient privacy', 'programs', 'repository', 'skills', 'software systems', 'surveillance study', 'text searching', 'tool']",NCI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,RC1,2010,494477,0.0018983787748149386
"Detecting deviations in clinical care in ICU data streams    DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient [1]. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our preliminary studies provide support that such deviations often indicate clinically important events for which it is worthwhile to raise an alert. We propose an evaluation based on physician assessment of alerts that are generated from a retrospective set of intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories.    PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.           PROJECT NARRATIVE There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.",Detecting deviations in clinical care in ICU data streams,7918929,R01GM088224,"['Algorithms', 'Anticoagulants', 'Belief', 'Cardiac', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Detection', 'Development', 'Disadvantaged', 'Drops', 'Electronics', 'Evaluation', 'Event', 'Future', 'Healthcare', 'Heparin', 'Individual', 'Industry', 'Information Systems', 'Intensive Care Units', 'Knowledge', 'Lead', 'Left', 'Machine Learning', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Patient Care', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Platelet Count measurement', 'Play', 'Practice Management', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Role', 'Services', 'Signal Transduction', 'Solutions', 'Statistical Models', 'Stream', 'System', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Time', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'cost', 'experience', 'follow-up', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'public health relevance', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,493140,0.026563200597767192
"Using medical records repositories to improve the alert system design    DESCRIPTION (provided by applicant):       Rapid and accurate alerting of concerning patient events and conditions remains an important problem in clinical practice. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into the monitoring and alerting systems. However, it is often time-consuming and costly to extract and codify such knowledge; hence such systems are typically built to cover only very specific conditions. In addition, it is difficult for an expert to foresee the performance of the deployed systems and their potential drawbacks, especially their false alarm rates. It is not uncommon that computer alerting systems are discarded or must undergo multiple costly modification cycles before they reach clinically acceptable levels of performance.    Electronic health record (EHR) repositories today provide an opportunity to test various theories and develop new computational solutions to various clinical problems. The objective of this project is to investigate methods for using the data in such repositories to assist in the development of alerting systems. The project goals include the building of an evidence-driven framework for the evaluation and optimization of alerting systems with the help of past data. The framework will be able to provide early feedback and future performance estimates of an alerting system before it is deployed, which is anticipated to decrease the expert effort required to design such a system and lead to a shorter alerting system design cycle. The evidence-driven framework will be tested and evaluated on multiple clinical conditions and compared to the performance of alerting rules currently deployed at the University of Pittsburgh Medical Center (UPMC). The project investigators consist of a multidisciplinary team with expertise in rule-based alerting in the hospital setting, clinical pharmacy, laboratory medicine, biomedical informatics, statistical machine learning, and knowledge based systems.           Project Narrative: There remain numerous opportunities to reduce medical errors by sending computer-based reminders and alerts to clinicians. This project investigates a novel combination of past patient data stored in electronic form and statistical machine-learning methods to help develop and refine computer-based alerts, which are expected to improve healthcare quality and reduce costs.",Using medical records repositories to improve the alert system design,7935413,R01LM010019,"['Amiodarone', 'Archives', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Data', 'Databases', 'Detection', 'Development', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Event', 'Expert Opinion', 'Feedback', 'Future', 'Goals', 'Gold', 'Heparin', 'Hospitals', 'Human', 'Information Systems', 'Knowledge', 'Knowledge acquisition', 'Label', 'Laboratories', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Medical Errors', 'Medical Informatics', 'Medical Records', 'Medical center', 'Medicine', 'Methods', 'Metric', 'Modeling', 'Modification', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Pharmacy facility', 'Physicians', 'Research', 'Research Personnel', 'Solutions', 'Source', 'Statistical Methods', 'Stream', 'System', 'Techniques', 'Testing', 'Thrombocytopenia', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Universities', 'base', 'biomedical informatics', 'clinical practice', 'cost', 'design', 'evaluation/testing', 'flexibility', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'novel', 'predictive modeling', 'repository', 'response', 'statistics', 'success', 'theories', 'treatment response']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,377274,0.0026312869825095724
"An NLP Approach to Generating Patient Record Summaries :  The long-term goal of this proposal is to enhance the manner in which physicians access, process and marshal medical information by providing them with an automatically generated, comprehensive, and up-to date summary of the information appearing in a patient record. At the point of patient care, physicians must often rapidly process a potentially overwhelming quantity of information pertaining to a patient. Failure to do so effectively may lead to provision of suboptimal care. Some electronic health record systems provide an automatically produced “cover sheet” geared to help physicians with a broad overview of a given patient, but the information is derived from the structured data fields in the patient record, ignoring the valuable narrative text entered by clinicians over time. We are building upon our prior work in summarization and natural language processing and leveraging our expertise in cognitive research studying information needs and decision making of clinicians to build a patient record summarizer that gathers information narrative (unstructured) as well as structured parts in the record. We focus on producing a summary for patients with kidney disease, as they often have a complex medical history with numerous conditions, procedures and medications. Providing a holistic, up-to-date summary of their chart would prove valuable to physicians in general and nephrologists in particular. The following three aims will be carried out: (1) conduct a formative study to determine how physicians prioritize and mentally represent relevant information when reviewing a patient chart; (2) create a set of automated methods to select salient pieces of information in the patient record and organize them into a coherent summary; and (3) evaluate the efficacy, efficiency and physician-user satisfaction associated with the use of the summarizer. A primary strength of this proposal is that we are addressing the problem of information overload, a bottleneck in the use of electronic health records, and evaluate the impact of our solution on clinicians’ actions and patients’ health outcomes. Furthermore, we propose to use novel natural language processing, knowledge-based and data mining methods to extract and organize salient information. Finally, we contribute to informatics research by extending the electronic health record functionalities to go beyond a simple documentation-entry system towards a useful reference and decision-making tool for physicians  Project Narrative We propose to design an automatically generated, comprehensive, and up-to-date summary of the information appearing in a patient record. Such a summary would enhance the manner in which both patients and their physicians access, process and marshal medical information.",An NLP Approach to Generating Patient Record Summaries,7925659,R01LM010027,"['Address', 'Allergic', 'Caring', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Data', 'Data Analyses', 'Decision Making', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation Studies', 'Face', 'Failure', 'Feasibility Studies', 'Goals', 'Hand', 'Health', 'Health Status', 'Informatics', 'Information Resources', 'Interview', 'Kidney Diseases', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Marshal', 'Medical', 'Medical History', 'MedlinePlus', 'Methods', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Personal Health Records', 'Pharmaceutical Preparations', 'Physicians', 'Procedures', 'Process', 'Records', 'Research', 'Resources', 'Solutions', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Visit', 'Work', 'data mining', 'design', 'health literacy', 'information gathering', 'knowledge base', 'literate', 'medical schools', 'meetings', 'novel', 'research study', 'satisfaction', 'stem', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,456856,0.011046618961052504
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7942766,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2010,320155,0.03182642961458544
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",7985218,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Caring', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,1,0.06282482954901003
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),7950411,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patient Care', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2010,388125,0.04919448394561618
"An in-silico method for epidemiological studies using Electronic Medical Records DESCRIPTION: Observational epidemiological studies are effective methods for identifying factors affecting the health and illness of populations, as well as for determining optimal treatments for diseases, such as cancers. However, conventional epidemiological research usually involves personnel-intensive effort (such as manual chart and public records review) and can be very time consuming before conclusive results are obtained. Recently, a large amount of detailed longitudinal clinical data has been accumulated at hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data source for epidemiological studies. However, there are two obstacles that prevent the wide usage of EMR data in epidemiological studies. First, most of the detailed clinical information in EMRs is embedded in narrative text and it is very costly to extract that information manually. Second, EMRs usually have data quality problems such as selection bias and missing data, which require adaptation of conventional statistical methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for observational epidemiological studies using EMR data. We hypothesize that existing EMR data can be used for certain types of epidemiological studies in a very efficient manner with the help of informatics methods. The informatics-based approach will contain two major components. One is an NLP (Natural Language Processing) based information extraction system that can automatically extract detailed clinical information from EMR and another is a set of statistical and informatics methods that can be used to analyze EMR-derived data. If the feasibility of this approach is proven, it will change the standard paradigm of observational epidemiological research, because it has the capability to answer an epidemiological question in a very short time at a very low cost. The specific aim of this study is to develop an automated informatics approach to extract both fine-grained cancer findings and general clinical information from EMRs and use them to conduct cancer related epidemiological studies. We will perform both casecontrol and cohort studies related to prevention and treatment of breast and colon cancers using EMR data. The informatics approach will be validated on EMRs from two major hospitals to demonstrate its generalizability. Epidemiological findings from our study will be compared to reported findings for validation. Narrative: According to the American Cancer Society, about 7.6 million people died from various types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,7925776,R01CA141307,"['Affect', 'American Cancer Society', 'Breast', 'Cereals', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Quality', 'Data Sources', 'Disease', 'Epidemiologic Studies', 'Epidemiology', 'Health', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Natural Language Processing', 'Patients', 'Population', 'Prevention', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Risk Factors', 'Selection Bias', 'Statistical Methods', 'System', 'Technology', 'Text', 'Time', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'cost', 'prevent']",NCI,VANDERBILT UNIVERSITY,R01,2010,259993,0.0043673975117178325
"Online Social Networking as an Alternative Information Source for Clinical Resear    DESCRIPTION (provided by applicant): Clinical trials and patient records have been the main information sources for clinical research. While well- designed clinical trials can produce high quality data, they are generally very expensive and time consuming. Prior studies have also shown that patients enrolled in clinical trials are not necessarily representative of the general patient population. Chart reviews, which rely on the patient records, avoid some of the drawbacks of the clinical trials approach. Although chart review studies are more labor intensive, new developments in structured data entry and natural language processing (NLP) are helping to automate the process. However, studies which use chart reviews are limited by the accuracy and completeness of the data in the records.       In the past decade, online social networks have grown exponentially. Some health-focused social network sites have attracted large numbers of users and begun accumulating large quantities of detailed clinical information. The PatientsLikeMe site, for instance, has about 3,200 amyotrophic lateral sclerosis (ALS) patients worldwide, and includes about 5% of the ALS population in the US. Information gathered by online social networks is primarily intended for patients to share with each other. Such information has also begun to attract the attention of medical researchers.[3, 4]       Because using information from online social networks for medical research is a fairly new phenomenon, the value and limitation of this type of information source have not been systematically examined. To do so, we propose to conduct a comparison study of patient-contributed information from PatientsLikeMe and records from a large medical record data repository - the Research Patient Data Registry (RPDR) of the Partners Healthcare Systems. The proposed study will focus on ALS, multiple sclerosis (MS), and Parkinson's disease (PD). The general goal is to explore how the medical record and online networking data differ, and if and how online networking data could complement the medical record data. The specific aims are:    1) Extract symptom and treatment information from the two different data sources.    2) Compare the prevalence of symptoms and treatments from the two information sources and analyze the difference.    3) Extract treatment response of prescription medications from PatientsLikeMe and analyze the confounding effect of the misunderstanding of medication indication.      PUBLIC HEALTH RELEVANCE: The proposed project will investigate an emerging data source for clinical research: online social network. This data source may complement and supplement the data from clinical trials and medical records, with a unique emphasis on patients' experience and perspectives.           The proposed project will investigate an emerging data source for clinical research: online social network. This data source may complement and supplement the data from clinical trials and medical records, with a unique emphasis on patients' experience and perspectives.",Online Social Networking as an Alternative Information Source for Clinical Resear,7941839,R21NS067463,"['Amyotrophic Lateral Sclerosis', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Communities', 'Comparative Study', 'Complement', 'Data', 'Data Quality', 'Data Sources', 'Databases', 'Development', 'Enrollment', 'Frequencies', 'Goals', 'Healthcare Systems', 'Medical Records', 'Medical Research', 'Multiple Sclerosis', 'Natural Language Processing', 'Nature', 'Parkinson Disease', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Prevalence', 'Process', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Site', 'Source', 'Structure', 'Symptoms', 'System', 'Text', 'Time', 'Update', 'experience', 'information gathering', 'medical attention', 'patient population', 'public health relevance', 'social networking website', 'statistics', 'treatment response', 'web-based social networking']",NINDS,UNIVERSITY OF UTAH,R21,2010,233374,0.03009412114630868
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7893787,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2010,1512082,0.046127103997035485
"Development and Use of Network Infrastructure for High-Throughput GWA Studies    DESCRIPTION (provided by applicant):  Linking biorepositories of patients in healthcare delivery systems with electronic medical records (EMRs) is an efficient strategy for high-throughput genome wide association (GWA) studies, as phenotype, covariable and exposure data of public health importance can be economically abstracted and pooled across delivery systems to facilitate the large numbers of subjects needed for GWA studies of each phenotype. Key obstacles to the success of this strategy remain. In this project, which will use population-based genomic and phenotype data from a well characterized population served by a delivery system which captures virtually all health care encounters in its data bases. Researchers from Group Health Cooperative's Center for Health Studies, the University of Washington, and the Fred Hutchinson Cancer Research Center will address these obstacles by pursuing the following specific aims:       1. Informed by results from targeted focus groups, implement a consensus process with key stakeholders to develop recommendations concerning consent, data sharing, and return of research results to subjects.    2. Work together with other network sites to develop a virtual data warehouse (VDW) analogous to that used in the Cancer Research Network, and extend natural language processing (NLP) to pathology, radiology, and clinical chart notes.   3. Develop and test strategies to determine whether each candidate EMR-based phenotype is sufficiently valid to pursue analyses of GWA data, and develop statistical methods that explicitly account for heterogeneous phenotype validity within and between sites.    4. Perform a series of GWA analyses in the GHC biorepository and linked biorepositories. 4a: Alzheimer's disease (AD). 4b: Carotid artery atherosclerotic disease (CAAD). 4c: Complications of statin use, including elevations of CPK and muscle pain.       Through cooperation with other investigators and the NHGRI, this work will facilitate development of policies and procedures to realize the incredible potential of EMR-linked biorepositories for GWA studies to improve understanding, prevention and treatment of chronic diseases and illnesses. Specific GWA research will allow us to explore both etiologic research (AD and CAAD progression) and pharmacogenetics (statin therapy). The implications of this portfolio of research extend far beyond the specific phenotypes we have chosen to emphasize; we expect this work represents the beginning of a large and productive enterprise.              n/a",Development and Use of Network Infrastructure for High-Throughput GWA Studies,7902293,U01HG004610,"['Abbreviations', 'Accounting', 'Address', 'Adult', 'Adverse event', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease patient registry', 'Blood Pressure', 'Cancer Research Network', 'Carotid Arteries', 'Carotid Artery Diseases', 'Cholesterol', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Data', 'Cognition', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consent', 'Creatinine', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Electronics', 'Enrollment', 'Environmental Exposure', 'Exposure to', 'Focus Groups', 'Foundations', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Genotype', 'Gold', 'Health', 'Healthcare', 'Healthcare Systems', 'High Density Lipoproteins', 'Individual', 'Inpatients', 'Knowledge', 'Laboratories', 'Leadership', 'Life', 'Link', 'Malignant Neoplasms', 'Maps', 'Medical', 'Meta-Analysis', 'Methods', 'Myalgia', 'National Cancer Institute', 'National Human Genome Research Institute', 'National Institute on Aging', 'Natural Language Processing', 'Neurofibrillary Tangles', 'Outcome', 'Outpatients', 'Participant', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Pharmacy facility', 'Phenotype', 'Population', 'Prevention', 'Procedures', 'Process', 'Public Domains', 'Public Health', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Recruitment Activity', 'Research', 'Research Ethics Committees', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sampling', 'Senile Plaques', 'Series', 'Single Nucleotide Polymorphism', 'Site', 'Statistical Methods', 'System', 'Testing', 'Text', 'Time', 'Universities', 'Ursidae Family', 'Washington', 'Work', 'abstracting', 'base', 'biobank', 'case control', 'cohort', 'cost', 'data sharing', 'development policy', 'economic cost', 'gene environment interaction', 'genome wide association study', 'genome-wide', 'health care delivery', 'human disease', 'improved', 'interest', 'member', 'population based', 'prospective', 'success', 'trait', 'virtual']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2010,889184,-0.01590681437000699
"Enhancing Clinical Effectiveness Research with Natural Language Processing of EMR    DESCRIPTION (provided by applicant): To successfully use large linked clinical databases for comparative effectiveness research (CER) requires addressing some key informatics challenges associated with distributed, heterogeneous clinical data. Electronic networks of researchers are part of the solution because they can bridge the physical and organizational divides created by distinct health systems' individual electronic medical records (EMRs). In addition, informatics research has demonstrated the feasibility of automatically coding clinical text, enhancing the capacity to integrate both unstructured and non-standardized clinical data from EMRs. With this study, we propose to develop CER infrastructure, make broadly available the proven MediClass technology for automated classification of EMRs containing both coded data and text clinical notes, and demonstrate the potential of this infrastructure for addressing CER questions within the asthma and tobacco-using patient populations of 6 diverse health systems. Asthma and smoking each impose huge and modifiable burdens on the healthcare system, and multiple morbidities related to asthma and smoking have been targeted by the IOM and AHRQ as priority areas in efforts to improve the healthcare system through comparative effectiveness research. We propose to develop, deploy, operate and evaluate the CER HUB, an Internet-based platform for conducting CER, and to demonstrate its utility in studying clinical interventions in asthma and smoking. Researchers who register to use the HUB, beginning with the research team from the 6 participating study sites, will be able to use a secure website to configure and download MediClass applications addressing CER questions within their respective healthcare organizations, to contribute these IRB-approved, processed datasets back to a centralized data coordinating center to be pooled with data similarly processed from other healthcare organizations, and to use the pooled database to answer diverse comparative effectiveness questions of large, real-world populations. A central function of the CER HUB will be facilitating (through online, interactive tools) development of a shared library of MediClass knowledge modules that afford uniform, standardized coding of EMR data. This shared library of knowledge modules could permit researchers to assess effectiveness in multiple areas of healthcare and gain access to data otherwise locked away in text clinical notes. A goal of the CER HUB is to accelerate creation of standardized knowledge used to normalize heterogeneous EMR data as representations of clinical events for CER. During the project period we will conduct 2 studies using this infrastructure to address the effectiveness of interventions for asthmatics and tobacco users across the 6 participating health systems. As an ongoing resource, the HUB will provide a collaborative development platform for enhancing comparative effectiveness research in potentially any health care domain.      CER researchers can build software applications that will process their EMRs, creating standardized datasets permitting CER using a secure website to configure and download MediClass applications addressing CER questions within their respective healthcare organizations, to contribute these IRB-approved, processed datasets back to a centralized data coordinating center to be pooled with data similarly processed from other healthcare organizations, and to use the pooled database to answer diverse comparative effectiveness questions of large, real-world populations      PUBLIC HEALTH RELEVANCE: Comparative effectiveness research (CER) requires that clinical data be in standard forms allowing multiple, large databases to be efficiently combined, and requires that all of the data be coded so that automated summarization of the data is possible. However, much of the clinical data necessary for CER is in the text clinical notes written by clinicians when caring for patients. We will build a centralized website where CER researchers can build software applications that will process their electronic medical records, including both the text and coded data, creating standardized datasets permitting comparative effectiveness research. We will demonstrate the utility of this infrastructure by conducting CER studies investigating the effectiveness of interventions in asthma and smoking, across the 6 participating health systems.           PROJECT NARRATIVE Comparative effectiveness research (CER) requires that clinical data be in standard forms allowing multiple, large databases to be efficiently combined, and requires that all of the data be coded so that automated summarization of the data is possible. However, much of the clinical data necessary for CER is in the text clinical notes written by clinicians when caring for patients. We will build a centralized website where CER researchers can build software applications that will process their electronic medical records, including both the text and coded data, creating standardized datasets permitting comparative effectiveness research. We will demonstrate the utility of this infrastructure by conducting CER studies investigating the effectiveness of interventions in asthma and smoking, across the 6 participating health systems.",Enhancing Clinical Effectiveness Research with Natural Language Processing of EMR,8032928,R01HS019828,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2010,8696942,-0.0071543148303139
"Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts    DESCRIPTION (provided by applicant):  Accurate and complete medication lists are critical inputs to effective medication reconciliation to prevent medication prescribing and administration errors. Previous research aggregated structured medication data form multiple sources to generate and maintain a reconciled medication list. Medications documented in clinical texts also need to be reconciled. However, most reconciliation methods currently have limited capability to process textual data and temporal information (e.g., dates, duration and status). Our goal is to pilot and test methodologies and applications in the fields of natural language processing (NLP) and temporal reasoning to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. Clinic notes and free-text ""comments"" fields in medication lists in an ambulatory electronic medical record system will be considered in the study. An NLP system and a temporal reasoning system will be adapted to automatically extract medication and associated temporal information from clinical texts and encode the medications using a controlled terminology. Multiple knowledge bases will be used to develop a mechanism to represent the timing of medication use, detect the changes (e.g., active or inactive), and then to organize medications into appropriate groups (e.g., by ingredient or by status). The feasibility and efficiency of the proposed methods and tools in improving the process of medication   reconciliation will be assessed. Domain experts will serve as judges to assess the success of capturing, coding, and organizing the medications and temporal information and also to evaluate whether our methods are complementary to those currently used for medication management.           Accurate and complete medication information at the point of care is crucial for delivery of high-quality care and prevention of adverse events. Most previous studies aggregated structured medication data from EMR and CPOE (Computerized Physician Order Entry) systems to generate and maintain a reconciled medication list. However, medications in non-structured narrative sources (such as clinic notes and free-text comments) must also be reconciled. Structured data presented in a standard, predictable form can be easily processed by a computer. By contrast, narrative data does not have a well-defined structure, so processing such data is very challenging. Our goal is to pilot and test methodologies and applications in the fields of natural language processing (any system that manipulates text) and temporal reasoning (e.g., identifying the timing of medication use) to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. The feasibility and efficiency of the proposed methods and tools in improving the process of medication reconciliation will be assessed.",Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts,7935475,R03HS018288,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R03,2010,50100,0.02095441885557976
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8231171,R01GM090187,[' '],NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,642650,0.06282482954901003
"Data Structuring and Visualization System for Neuro-oncology    DESCRIPTION (provided by applicant):       The medical record for a neuro-oncology patient is complex, consisting of typically a large number of both text and imaging data. It includes descriptions of prior observations, interpretations, and interventions which need to be integrated into decisions regarding current patient care. An appropriate review of a patient's medical record often requires that a physician review multiple clinical documents while mentally noting issues related to what the findings were, the chronology of events, spatial/temporal patterns of disease progression, the effects of interventions, and the possible causal lines of explanation of observed findings. Additionally, imaging data and imaging- derived conclusions are poorly integrated into patient care and management decisions. The physician also needs to filter out those pieces of information not related to the current clinical context of care. Given the time constraints, data complexity and data volume associated with chronic patient cases, an appropriate review of a patient's chart is in reality rarely performed. Additionally, the lack of tools for formalizing the representation of the accounts of current and prior cases impedes the development of clinical databases that can be ultimately used to learn patterns of disease.       This proposal addresses the development of a system for facilitating the review of clinical patient data intended to promote an orderly process of medical problem understanding and care. The specific aims of the proposal are summarized as follows: 1) Development of a backend tool to facilitate the structured representation of observations, events, and inferences stated within medical reports. 2) Development of an application interface for visualizing, navigating, and editing structured patient data. 3) Evaluation of the effectiveness of the application in the domain of neuro-oncology.       Relation to public health. If the goals of this proposal can be realized, neuro-oncologist should be able to more easily seek desired patient data and detect patterns of evidence as compared to the current mode of operation (HIS, RIS, PACS). The structuring tools should lead to improvements in the quality of clinical research databases.           Narrative Medical records for neuro-oncology patients are difficult to review due to volume and complexity of information. A novel system for partitioning data along the information axes of space, time, existence, and causality is proposed to improve navigation and assimilation of data within the medical record.",Data Structuring and Visualization System for Neuro-oncology,7877057,R01LM009961,"['Abnormal coordination', 'Accounting', 'Address', 'Anatomy', 'Appearance', 'Assimilations', 'Caregivers', 'Caring', 'Chronic', 'Chronology', 'Clinic', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Complex', 'Computer software', 'Data', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Disease model', 'Effectiveness', 'Etiology', 'Evaluation', 'Event', 'Goals', 'Image', 'Imagery', 'Intervention', 'Lead', 'Learning', 'Medical', 'Medical Records', 'Metric', 'Natural Language Processing', 'Oncologist', 'Patient Care', 'Patient Care Management', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Process', 'Property', 'Public Health', 'Recording of previous events', 'Reporting', 'Research Personnel', 'Structure', 'System', 'Technology', 'Text', 'Time', 'Training', 'abstracting', 'follow-up', 'improved', 'innovation', 'intervention effect', 'neuro-oncology', 'novel', 'open source', 'operation', 'physical state', 'satisfaction', 'tool']",NLM,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2010,771496,0.04065268113243179
"Automating assessment of obesity care quality    DESCRIPTION (provided by applicant): Current trends suggest that obesity prevalence will continue to rise and that costs of treating obesity-related disease will dramatically increase as the population ages. Despite NHLBI guidelines for preventing, diagnosing, and treating obesity among adults, most health care systems have been slow to respond to this looming public health problem. This slow response is partly due to the inability to assess adherence to obesity diagnosis and treatment guidelines. In particular, the lack of appropriate Health IT for integrating diverse clinical data on obesity, even within state-of-the-art electronic medical record systems (EMRs), makes it difficult to evaluate the quality of care, measure the effectiveness of new intervention programs, and make rational decisions at system, organization, and individual patient levels. EMRs offer the potential to efficiently assess large populations, however much of the data necessary for obesity care assessment are unavailable to automated methods because they reside in the text clinical notes of the EMR. Previous studies have shown that although some data of interest are recorded in easily retrievable fields (e.g., body weights recorded as a vital sign; standard diagnosis codes), much of the treatment information is found only in free-text clinical notes. This research aims to develop, validate, apply, and evaluate a scalable method for routine and comprehensive measurement of outpatient obesity care quality. To accomplish this, we will extend MediClass (a ""Medical Classifier""), which is a proven technology for extracting care quality data from both coded data and free-text clinical notes in the EMR. This research will perform retrospective analysis of adult primary care from the EMR data of two distinct health systems: a   mid-sized HMO (Kaiser Permanente Northwest, KPNW) and a consortium of public health clinics (OCHIN) including a diverse sample of patients, providers, and health care practices of the West Coast states (primarily Oregon, but also Washington and California). We propose to use Health IT to integrate diverse data and knowledge that advance quality improvement for both insured and the indigent, uninsured, and underinsured populations of this region. We will first develop obesity care quality (OCQ) measures using up to-date NHLBI guidelines for diagnosis and treatment of obesity. Next, we will develop and validate an automated method for applying these measures to comprehensive EMR data. At each study site, the Medi Class system will extract coded data and use natural language processing (NLP) on free-text clinical notes to identify OCQ-relevant clinical events in the EMR. Then we will apply the OCQ measures to assess current levels of obesity care quality in the two health systems. Finally, we will evaluate the associations between OCQ measures of recommended obesity care and provider characteristics as well as clinical outcomes for patients, including change in weight.           PROJECT NARRATIVE This study will improve care for obese and overweight patients by improving the technology we use for measuring the quality of care for these populations. This study will use specialized computer programs to analyze the electronic medical records of obese and overweight patients. The results of this work will help us determine if patients from two different health care systems are receiving recommended care, and how to better monitor the delivery of care for obese and overweight patients.",Automating assessment of obesity care quality,7941068,R18HS018157,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R18,2010,496075,0.03453516620617526
"Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach No abstract available  Relevance The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, electronic medical record based clinical trial recommendations directly to the patients. The results of this research will empower patients and elevate their role in the decision making process.",Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach,8145098,R00LM010227,"['Adult', 'Age', 'Algorithms', 'Applications Grants', 'Arts', 'Biomedical Research', 'Cancer Patient', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Code', 'Commit', 'Complement', 'Computer software', 'Computerized Medical Record', 'Decision Making', 'Development', 'Elderly', 'Elements', 'Eligibility Determination', 'Enrollment', 'Ensure', 'Equation', 'Evaluation', 'Faculty', 'Foundations', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'In Vitro', 'Informatics', 'Java', 'Knowledge', 'Laboratories', 'Linguistics', 'Malignant Neoplasms', 'Maps', 'Medical Records', 'Medicine', 'Methods', 'Minority', 'Modification', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Role', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Surgeon', 'Text', 'Training', 'Unified Medical Language System', 'United States National Library of Medicine', 'Work', 'abstracting', 'base', 'cancer care', 'empowered', 'ethnic minority population', 'information organization', 'knowledge base', 'novel', 'older patient', 'patient oriented', 'programs', 'prospective', 'research study', 'software development', 'success', 'tool']",NLM,CINCINNATI CHILDRENS HOSP MED CTR,R00,2010,249000,0.02893512376016524
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7933293,R01LM006910,"['Address', 'Area', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Machine Learning', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'clinical care', 'data mining', 'improved', 'knowledge base', 'natural language', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,152617,0.04350625600107967
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7918614,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'clinical practice', 'forgetting', 'innovation', 'natural language', 'preference', 'speech processing', 'symposium']",NLM,UNIVERSITY OF CHICAGO,R01,2009,185745,0.01297295608885409
"Extracting Semantic Knowledge from Clinical Reports    DESCRIPTION (provided by applicant): Analyzing and processing free-text medical reports for data mining and clinical data interchange is one of the most challenging problems in medical informatics, yet it is crucial for continued research advances and improvements in clinical care. Natural language processing (NLP) is an important enabling technology, but has been held back because it is difficult to understand human language, since it requires extensive domain knowledge. In Phase I, we developed new statistical and machine learning methods that apply domain specific knowledge to the semantic analysis of free-text radiology reports. The methods enabled the creation of two new prototype applications - a SNOMED CT (Systematized Nomenclature of Medicine--Clinical Terms) coding service called SnomedCoder, and a text mining tool for analyzing a large corpus of medical reports, called DataMiner. In Phase II, we will accomplish the following specific aims: 1) Improve the semantic extraction methods developed in Phase I, 2) Expand the semantic knowledge base and classify at least two million new unique sentences from multiple medical institutions, 3) Provide a SNOMED CT auto coding service (alpha service) to participating Indiana Health Information Exchange hospitals, and 4) Build a commercial version of the DataMiner software, and test its functionality using researchers at the Regenstrief Institute.       These scientific innovations will revolutionize the ability of health care researchers to analyze vast repositories of clinical information currently locked up in electronic medical records, and correlate this data with new biomedical discoveries in proteonomics and genomics. The ability to codify text rapidly will extend the potential for clinical decision support beyond its narrow base of numeric and structured medical data, and enable SNOMED CT to become a useful coding standard. Phase III will offer coding and data mining services to healthcare payers (both private and government), pharmaceuticals, and academic researchers. A key advantage of our approach over other NLP systems is that we attempt to codify all the information in the report and not just a limited subset, and insist on expert validation which provides a high degree of confidence in the accuracy of the coded data.Project Narrative           n/a",Extracting Semantic Knowledge from Clinical Reports,7554153,R44RR024929,"['Address', 'Algorithms', 'Back', 'Bioinformatics', 'Body of uterus', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Code', 'Collection', 'Computer software', 'Computerized Medical Record', 'Data', 'Decision Making', 'Effectiveness', 'Genomics', 'Goals', 'Government', 'Health', 'Healthcare', 'Hospitals', 'Human', 'Indiana', 'Institutes', 'Institution', 'Journals', 'Knowledge', 'Language', 'Longitudinal Studies', 'Machine Learning', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Natural Language Processing', 'Paper', 'Pharmacologic Substance', 'Phase', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Speed', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Testing', 'Text', 'Trees', 'Trust', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Validation', 'base', 'clinical care', 'computerized', 'data mining', 'health care quality', 'improved', 'indexing', 'innovation', 'knowledge base', 'novel strategies', 'patient safety', 'prototype', 'repository', 'research and development', 'success', 'text searching', 'tool']",NCRR,"LOGICAL SEMANTICS, INC.",R44,2009,422728,0.029129766221864823
"Natural Language Processing to Study Epidemiology of Statin Side Effects    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (10) Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-101: Informatics for post-marketing surveillance. The overall goal of this study is to develop a generalizable framework for studying medication side effects recorded in narrative medical documents. We will implement and test this system on the example of epidemiologic characterization of side effects of HMG-CoA reductase inhibitors (a.k.a. statins). Statins are the most commonly used class of medications for treatment of hypercholesterolemia in the U.S. In randomized clinical trials statins are associated only with a slight increase in adverse reactions and no increase in discontinuation of treatment compared to placebo. However, in clinical practice the rates of side effects and discontinuation appear significantly higher and represent a major barrier to a critical, potentially lifesaving therapy. For example, myalgias are reported to be relatively rare in clinical trials but are thought to be more common in clinical practice. Additionally, a number of other statin-associated complaints reported anecdotally but not well elucidated in clinical trials include depression, irritability, and memory loss among others. Most of these have been poorly epidemiologically characterized and their prevalence and risk factors remain unknown. Structured electronic medical record (EMR) and administrative data have been used to study medication side effects. However, structured data have important limitations. They may not contain temporal or causative information necessary to link particular problems to medications and may not be sufficiently granular to identify specific adverse reactions. Narrative EMR data, such as provider notes, can provide documentation of causative links between medication and adverse events at high levels of granularity. Natural language processing (NLP) is an emerging technology that enables computational abstraction of information from narrative medical documents. In prior work we have successfully applied natural language processing to abstract medication information from narrative provider notes, including medication intensification, medication non-adherence and medication discontinuation. We will leverage these tools and the extensive EMR infrastructure at Partners HealthCare to develop and test a natural language processing system to study medication side effects. We will validate this system on the example of studying epidemiology of adverse reactions to statins. The findings of this project will lay the foundation for an open-source system that can be used for post-marketing surveillance of medication side effects using narrative EMR data.       PUBLIC HEALTH RELEVANCE (provided by applicant): Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.                 Natural Language Processing to Study Epidemiology of Statin Side Effects  Project Narrative  Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.",Natural Language Processing to Study Epidemiology of Statin Side Effects,7834605,RC1LM010460,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Area', 'Cholesterol', 'Clinical Trials', 'Computerized Medical Record', 'Data', 'Documentation', 'Emerging Technologies', 'Foundations', 'Frequencies', 'Goals', 'Healthcare', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Hypersensitivity', 'Incidence', 'Informatics', 'Information Technology', 'Link', 'Medical', 'Memory Loss', 'Myalgia', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Placebos', 'Prevalence', 'Process', 'Provider', 'Randomized Clinical Trials', 'Reaction', 'Records', 'Reporting', 'Research Infrastructure', 'Risk Factors', 'Semantics', 'Side', 'Structure', 'System', 'Systems Analysis', 'Testing', 'Text', 'Work', 'abstracting', 'clinical practice', 'depression', 'design', 'epidemiology study', 'hypercholesterolemia', 'medication compliance', 'open source', 'post-market', 'public health relevance', 'repository', 'research study', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,RC1,2009,499818,0.047184503759763685
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,7693117,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2009,145926,0.026753251280373536
"Natural Language Processing for Cancer Research Network Surveillance Studies    DESCRIPTION (provided by applicant): This application addresses Broad Challenge Area: (10) Information Technology for Processing Health Care Data and specific Challenge Topic: 10-CA-107 Expand Spectrum of Cancer Surveillance through Informatics Approaches. The proposed project launches a collaborative effort to advance adoption within the HMO Cancer Research Network (CRN) of ""industrial-strength"" natural language processing (NLP) systems useful for mining valuable, research-grade information from unstructured clinical text. Such text is available for processing, now in the electronic medical record (EMR) systems of affiliated CRN health plans. The proposed NLP methods   will create ongoing capacity to tap what has recently been described as ""a treasure trove of historical   unstructured data that provides essential information for the study of disease progression, treatment   effectiveness and long-term outcomes"" (5). The vision of advancing widespread NLP capacity across the CRN, as well as the approach we present here for implementing it, grew out of an in-depth strategic planning effort we completed in December 2008. That effort involved participants from six CRN sites guided by a blue-ribbon panel of NLP experts from three of the nation's leading centers of clinical NLP research: University of Pittsburgh Medical Center, Vanderbilt University, and Mayo Clinic. The vision is to deploy a powerful NLP system locally, manage it with newly hired and trained local NLP technical staff, and conduct NLP-based research projects initiated by local investigators, in consultation with higher-level external NLP experts. Our planning efforts suggest this collaborative model is feasible; we will test the model in the context of the proposed project. An important development in April 2009 yielded what we believe is a potentially transformative opportunity to accelerate adoption of NLP capacity in applied research settings: release of the open-source Clinical Text Analysis and Knowledge Extraction System (cTAKES) software. This software was the result of a collaborative effort between IBM and Mayo Clinic. Built on the same framework Mayo Clinic currently uses to process its repository of over 40 million clinical documents, cTAKES dramatically lowers the cost of adopting a comprehensive and flexible NLP system. Deployment and use of such systems was previously only feasible in institutions with large, academically-oriented biomedical informatics research programs.   Still, other deployment challenges and the need to acquire NLP training for local staff present residual   barriers to adopting comprehensive NLP systems such as cTAKES. In collaboration with five other CRN sites the proposed project mitigates these challenges in two ways: 1) it develops configurable open-source software modules needed to streamline and therefore reduce the cost of deploying cTAKES, and 2) it presents and tests a model for training local staff through hands-on NLP projects overseen by outside NLP expert consultants. The potential impact of this project is evident most clearly in the vast untapped opportunities for text mining represented in CRN-affiliated health plans, where EMR systems have been in place since at least 2005, and whose patients represent 4% of the U.S. population. Clinical text mining offers the potential to provide new or improved data elements for cancer surveillance and other types of research requiring information about patient functional status, medication side-effects, details of therapeutic approaches, and differential information about clinical findings. Another significant impact of this project is its plan to integrate into the cTAKES system   an open-source de-identification tool based on state of the art, best of breed NLP approaches developed by the MITRE Corporation. De-identification of clinical text will make it easier for researchers to get access to clinical text, and will also facilitate multi-site collaborations while protecting patient privacy. Finally, if successful, the NLP algorithm we propose as a proof-of-principle project at Group Health-which will classify sets of patient charts as either containing or not containing a diagnosis of recurrent breast cancer-could dramatically reduce the cost of research in this area; currently all recurrent breast cancer endpoints must be established through costly manual chart abstraction.   Novel aspects of the proposed project include its talented and transdisciplinary research team,   including national experts in NLP, and its resourceful strategy for building the technical resources and ""human capital"" needed to support an ongoing program of applied NLP research. Natural language processing is itself a highly innovative technology; when successfully established in multiple CRN in the future it will represent a watershed moment in the CRN's already impressive history of exploiting data systems to support innovative research. Newly hired staff positions total approximately 2.0 FTE in each project year, most of which we anticipate will be supported by ongoing new research programs after the proposed project concludes. Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.           Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.",Natural Language Processing for Cancer Research Network Surveillance Studies,7839706,RC1CA146917,"['Address', 'Adopted', 'Adoption', 'Adverse effects', 'Algorithms', 'Applied Research', 'Area', 'Arts', 'Bioinformatics', 'Breeding', 'Cancer Research Network', 'Charge', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Complex', 'Comprehensive Health Care', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Data', 'Data Element', 'Data Quality', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Environment', 'Exercise', 'Future', 'Generic Drugs', 'Hand', 'Health', 'Health Planning', 'Health system plans', 'Healthcare', 'Human Resources', 'Individual', 'Informatics', 'Information Systems', 'Information Technology', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Licensing', 'Life', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Mining', 'Modeling', 'NCI Center for Cancer Research', 'Natural Language Processing', 'Operating System', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Process', 'Public Health', 'Recording of previous events', 'Recurrence', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Resources', 'Risk', 'Site', 'Solutions', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Training', 'Treatment Effectiveness', 'Universities', 'Vision', 'Woman', 'base', 'biomedical informatics', 'breast cancer diagnosis', 'cost', 'design', 'experience', 'feeding', 'firewall', 'flexibility', 'functional status', 'human capital', 'improved', 'innovation', 'innovative technologies', 'malignant breast neoplasm', 'novel', 'open source', 'patient privacy', 'programs', 'repository', 'skills', 'software systems', 'surveillance study', 'text searching', 'tool']",NCI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,RC1,2009,497857,0.0018983787748149386
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7691692,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development', 'web site']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2009,177750,0.07479107134051369
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7850343,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development', 'web site']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2009,99971,0.07479107134051369
"Detecting deviations in clinical care in ICU data streams    DESCRIPTION (provided by applicant): Timely detection of severe patient conditions or concerning events and their mitigation remains an important problem in clinical practice. This is especially true in the critically ill patient [1]. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into monitoring and alerting systems. However, it is often time-consuming, costly, and difficult to extract and implement such knowledge in existing monitoring systems. The research work in this proposal offers computational, rather than expert-based, solutions that build alert systems from data stored in patient data repositories, such as electronic medical records. Briefly, our approach uses advanced machine learning algorithms to identify unusual clinical management patterns in individual patients, relative to patterns associated with comparable patients, and raises an alert signaling this discrepancy. Our preliminary studies provide support that such deviations often indicate clinically important events for which it is worthwhile to raise an alert. We propose an evaluation based on physician assessment of alerts that are generated from a retrospective set of intensive-care unit (ICU) patient cases. The project investigators comprise a multidisciplinary team with expertise in critical care medicine, computer science, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories.    PUBLIC HEALTH RELEVANCE: There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.           PROJECT NARRATIVE There remain numerous opportunities to reduce medical errors in critical care by sending computer-based reminders and alerts to clinicians. This project uses past patient data, which is stored in electronic form, and machine-learning methods to help develop and refine computer-based alerts to improve healthcare quality and reduce costs.",Detecting deviations in clinical care in ICU data streams,7698505,R01GM088224,"['Algorithms', 'Anticoagulants', 'Belief', 'Cardiac', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computerized Medical Record', 'Computers', 'Critical Care', 'Critical Illness', 'Data', 'Databases', 'Detection', 'Development', 'Disadvantaged', 'Drops', 'Electronics', 'Evaluation', 'Event', 'Future', 'Healthcare', 'Heparin', 'Individual', 'Industry', 'Information Systems', 'Intensive Care Units', 'Knowledge', 'Lead', 'Left', 'Machine Learning', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Patient Care', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Platelet Count measurement', 'Play', 'Practice Management', 'Quality of Care', 'Relative (related person)', 'Research', 'Research Personnel', 'Role', 'Services', 'Signal Transduction', 'Solutions', 'Statistical Models', 'Stream', 'System', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Time', 'Work', 'base', 'biomedical informatics', 'clinical care', 'clinical practice', 'computer science', 'cost', 'experience', 'follow-up', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'public health relevance', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,499603,0.026563200597767192
"Using medical records repositories to improve the alert system design    DESCRIPTION (provided by applicant):       Rapid and accurate alerting of concerning patient events and conditions remains an important problem in clinical practice. Typical computer-based detection methods developed for this purpose rely on the use of clinical knowledge, such as expert-derived rules, that are incorporated into the monitoring and alerting systems. However, it is often time-consuming and costly to extract and codify such knowledge; hence such systems are typically built to cover only very specific conditions. In addition, it is difficult for an expert to foresee the performance of the deployed systems and their potential drawbacks, especially their false alarm rates. It is not uncommon that computer alerting systems are discarded or must undergo multiple costly modification cycles before they reach clinically acceptable levels of performance.    Electronic health record (EHR) repositories today provide an opportunity to test various theories and develop new computational solutions to various clinical problems. The objective of this project is to investigate methods for using the data in such repositories to assist in the development of alerting systems. The project goals include the building of an evidence-driven framework for the evaluation and optimization of alerting systems with the help of past data. The framework will be able to provide early feedback and future performance estimates of an alerting system before it is deployed, which is anticipated to decrease the expert effort required to design such a system and lead to a shorter alerting system design cycle. The evidence-driven framework will be tested and evaluated on multiple clinical conditions and compared to the performance of alerting rules currently deployed at the University of Pittsburgh Medical Center (UPMC). The project investigators consist of a multidisciplinary team with expertise in rule-based alerting in the hospital setting, clinical pharmacy, laboratory medicine, biomedical informatics, statistical machine learning, and knowledge based systems.           Project Narrative: There remain numerous opportunities to reduce medical errors by sending computer-based reminders and alerts to clinicians. This project investigates a novel combination of past patient data stored in electronic form and statistical machine-learning methods to help develop and refine computer-based alerts, which are expected to improve healthcare quality and reduce costs.",Using medical records repositories to improve the alert system design,7784403,R01LM010019,"['Amiodarone', 'Archives', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Data', 'Databases', 'Detection', 'Development', 'Electronic Health Record', 'Electronics', 'Evaluation', 'Event', 'Expert Opinion', 'Feedback', 'Future', 'Goals', 'Gold', 'Heparin', 'Hospitals', 'Human', 'Information Systems', 'Knowledge', 'Knowledge acquisition', 'Label', 'Laboratories', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Medical Errors', 'Medical Informatics', 'Medical Records', 'Medical center', 'Medicine', 'Methods', 'Metric', 'Modeling', 'Modification', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Pharmacy facility', 'Physicians', 'Research', 'Research Personnel', 'Solutions', 'Source', 'Statistical Methods', 'Stream', 'System', 'Techniques', 'Testing', 'Thrombocytopenia', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Universities', 'base', 'biomedical informatics', 'clinical practice', 'cost', 'design', 'evaluation/testing', 'flexibility', 'health care quality', 'improved', 'knowledge base', 'multidisciplinary', 'novel', 'predictive modeling', 'repository', 'response', 'statistics', 'success', 'theories', 'treatment response']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,370642,0.0026312869825095724
"An NLP Approach to Generating Patient Record Summaries :  The long-term goal of this proposal is to enhance the manner in which physicians access, process and marshal medical information by providing them with an automatically generated, comprehensive, and up-to date summary of the information appearing in a patient record. At the point of patient care, physicians must often rapidly process a potentially overwhelming quantity of information pertaining to a patient. Failure to do so effectively may lead to provision of suboptimal care. Some electronic health record systems provide an automatically produced “cover sheet” geared to help physicians with a broad overview of a given patient, but the information is derived from the structured data fields in the patient record, ignoring the valuable narrative text entered by clinicians over time. We are building upon our prior work in summarization and natural language processing and leveraging our expertise in cognitive research studying information needs and decision making of clinicians to build a patient record summarizer that gathers information narrative (unstructured) as well as structured parts in the record. We focus on producing a summary for patients with kidney disease, as they often have a complex medical history with numerous conditions, procedures and medications. Providing a holistic, up-to-date summary of their chart would prove valuable to physicians in general and nephrologists in particular. The following three aims will be carried out: (1) conduct a formative study to determine how physicians prioritize and mentally represent relevant information when reviewing a patient chart; (2) create a set of automated methods to select salient pieces of information in the patient record and organize them into a coherent summary; and (3) evaluate the efficacy, efficiency and physician-user satisfaction associated with the use of the summarizer. A primary strength of this proposal is that we are addressing the problem of information overload, a bottleneck in the use of electronic health records, and evaluate the impact of our solution on clinicians’ actions and patients’ health outcomes. Furthermore, we propose to use novel natural language processing, knowledge-based and data mining methods to extract and organize salient information. Finally, we contribute to informatics research by extending the electronic health record functionalities to go beyond a simple documentation-entry system towards a useful reference and decision-making tool for physicians  Project Narrative We propose to design an automatically generated, comprehensive, and up-to-date summary of the information appearing in a patient record. Such a summary would enhance the manner in which both patients and their physicians access, process and marshal medical information.",An NLP Approach to Generating Patient Record Summaries,7635002,R01LM010027,"['Address', 'Allergic', 'Caring', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Data', 'Data Analyses', 'Decision Making', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation Studies', 'Failure', 'Goals', 'Harvest', 'Health', 'Informatics', 'Information Resources', 'Interview', 'Kidney Diseases', 'Kidney Function Tests', 'Knowledge', 'Laboratories', 'Lead', 'Marshal', 'Medical', 'Medical History', 'Methods', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Procedures', 'Process', 'Research', 'Solutions', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Text', 'Time', 'Visit', 'Work', 'data mining', 'design', 'information gathering', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research study', 'satisfaction', 'stem', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,455605,0.011046618961052504
"HERMES - Help physicians to Extract and aRticulate Multimedia information from li    DESCRIPTION (provided by applicant): Physicians have many questions when seeing patients. Primary care physicians are reported to generate between 0.7 and 18.5 questions for every 10 patient visits. The published medical literature is an important resource helping physicians to access up-to-date clinical information and thereby to enhance the quality of patient care. For example, the case study in the above example (i.e., diagnostic procedures and treatment for cellulites) was published in a ""Clinical Practice"" article in the New England Journal of Medicine (NEJM). Although PubMed is frequently used by physicians in large hospitals, it does not return answers to specific questions. Frequently, PubMed returns a large number of articles in response to a specific user query. Physicians have limited time for browsing the articles retrieved; it has been found that physicians spend on average two minutes or less seeking an answer to a question, and that if a search takes longer it is likely to be abandoned. An evaluation study has shown that it takes an average of more than 30 minutes for a healthcare provider to search for answer from PubMed, which makes ""information seeking ... practical only `after hours' and not in the clinical setting."" It has been concluded that a lack of time is the most common obstacle resulting in many unanswered medical questions.       The importance of answering physicians' questions at the point of patient care has been widely recognized by the medical community. Many medical databases (e.g., UpToDate and Thomson MICROMEDEX) provide summaries to answer important medical questions related to patient care. However, most of the summaries are written by medical experts who manually review the literature information. The databases are limited in their scope and timeliness.       We hypothesize that we can develop medical language processing (MLP) approaches to build a fully automated system HERMES - Help physicians to Extract and aRticulate Multimedia information from literature to answer their ad-hoc medical quEstionS. HERMES will automatically retrieve, extract, analyze, and integrate text, image, and video from the literature and formulate them as answers to ad-hoc medical questions posed by physicians. Our preliminary results show that even a limited HERMES working system outperformed other information retrieval systems and can generate answers within a timeframe necessary to meet the demands of physicians. HERMES promise to assist physicians for practicing evidence-based medicine (EBM), the medical practice that involves the explicit use of current best evidence, i.e., high-quality patient-centered clinical research reported in the primary medical literature.       Our specific aims are:       1) Identify information needs from ad-hoc medical questions. We will incorporate rich semantic, statistical, and machine learning approaches to map ad-hoc medical questions to their component question types automatically. A component question type is a generic, simple question type that requires an answer strategy that is different from other component question types.       2) Develop new information retrieval models that integrate domain-specific knowledge for retrieving relevant documents in response to an ad-hoc medical question.       3) Extract relevant text, images, and videos from the retrieved documents in response to an ad-hoc medical question.       4) Integrate text, images, and videos, fusing information to generate a short and coherent multimedia summary.       5) Design a usability study to measure efficacy, accuracy and perceived ease of use of HERMES and to compare HERMES with other information systems.          n/a",HERMES - Help physicians to Extract and aRticulate Multimedia information from li,7690941,R01LM009836,"['Area', 'Back', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Research', 'Communities', 'Databases', 'Diagnostic Procedure', 'Edema', 'Erythema', 'Evaluation Studies', 'Evidence Based Medicine', 'Generic Drugs', 'Health Personnel', 'Hospitals', 'Hour', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Journals', 'Knowledge', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medicine', 'Modeling', 'Multimedia', 'New England', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Primary Care Physician', 'PubMed', 'Publishing', 'Redness', 'Reporting', 'Resources', 'Review Literature', 'Semantics', 'System', 'Text', 'Time', 'Toes', 'Ultrasonography', 'Visit', 'Work', 'Writing', 'clinical practice', 'design', 'foot', 'journal article', 'language processing', 'meetings', 'older men', 'patient oriented', 'response', 'usability']",NLM,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2009,351549,0.02836861393919664
"HERMES - Help physicians to Extract and aRticulate Multimedia information from li    DESCRIPTION (provided by applicant): Physicians have many questions when seeing patients. Primary care physicians are reported to generate between 0.7 and 18.5 questions for every 10 patient visits. The published medical literature is an important resource helping physicians to access up-to-date clinical information and thereby to enhance the quality of patient care. For example, the case study in the above example (i.e., diagnostic procedures and treatment for cellulites) was published in a ""Clinical Practice"" article in the New England Journal of Medicine (NEJM). Although PubMed is frequently used by physicians in large hospitals, it does not return answers to specific questions. Frequently, PubMed returns a large number of articles in response to a specific user query. Physicians have limited time for browsing the articles retrieved; it has been found that physicians spend on average two minutes or less seeking an answer to a question, and that if a search takes longer it is likely to be abandoned. An evaluation study has shown that it takes an average of more than 30 minutes for a healthcare provider to search for answer from PubMed, which makes ""information seeking ... practical only `after hours' and not in the clinical setting."" It has been concluded that a lack of time is the most common obstacle resulting in many unanswered medical questions.       The importance of answering physicians' questions at the point of patient care has been widely recognized by the medical community. Many medical databases (e.g., UpToDate and Thomson MICROMEDEX) provide summaries to answer important medical questions related to patient care. However, most of the summaries are written by medical experts who manually review the literature information. The databases are limited in their scope and timeliness.       We hypothesize that we can develop medical language processing (MLP) approaches to build a fully automated system HERMES - Help physicians to Extract and aRticulate Multimedia information from literature to answer their ad-hoc medical quEstionS. HERMES will automatically retrieve, extract, analyze, and integrate text, image, and video from the literature and formulate them as answers to ad-hoc medical questions posed by physicians. Our preliminary results show that even a limited HERMES working system outperformed other information retrieval systems and can generate answers within a timeframe necessary to meet the demands of physicians. HERMES promise to assist physicians for practicing evidence-based medicine (EBM), the medical practice that involves the explicit use of current best evidence, i.e., high-quality patient-centered clinical research reported in the primary medical literature.       Our specific aims are:       1) Identify information needs from ad-hoc medical questions. We will incorporate rich semantic, statistical, and machine learning approaches to map ad-hoc medical questions to their component question types automatically. A component question type is a generic, simple question type that requires an answer strategy that is different from other component question types.       2) Develop new information retrieval models that integrate domain-specific knowledge for retrieving relevant documents in response to an ad-hoc medical question.       3) Extract relevant text, images, and videos from the retrieved documents in response to an ad-hoc medical question.       4) Integrate text, images, and videos, fusing information to generate a short and coherent multimedia summary.       5) Design a usability study to measure efficacy, accuracy and perceived ease of use of HERMES and to compare HERMES with other information systems.          n/a",HERMES - Help physicians to Extract and aRticulate Multimedia information from li,7908952,R01LM009836,"['Area', 'Back', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Research', 'Communities', 'Databases', 'Diagnostic Procedure', 'Edema', 'Erythema', 'Evaluation Studies', 'Evidence Based Medicine', 'Generic Drugs', 'Health Personnel', 'Hospitals', 'Hour', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Journals', 'Knowledge', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medicine', 'Modeling', 'Multimedia', 'New England', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Primary Care Physician', 'PubMed', 'Publishing', 'Redness', 'Reporting', 'Resources', 'Review Literature', 'Semantics', 'System', 'Text', 'Time', 'Toes', 'Ultrasonography', 'Visit', 'Work', 'Writing', 'clinical practice', 'design', 'foot', 'journal article', 'language processing', 'meetings', 'older men', 'patient oriented', 'response', 'usability']",NLM,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2009,170662,0.02836861393919664
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7691699,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2009,311821,0.03182642961458544
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7908950,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2009,17240,0.03182642961458544
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7638001,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Non-Prescription Drugs', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'clinical practice', 'evidence base', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'patient population', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY,R01,2009,374185,0.018007997871518373
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7908946,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'meetings', 'natural language', 'population based', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2009,71200,0.0076566232735139576
"Online Social Networking as an Alternative Information Source for Clinical Resear    DESCRIPTION (provided by applicant): Clinical trials and patient records have been the main information sources for clinical research. While well- designed clinical trials can produce high quality data, they are generally very expensive and time consuming. Prior studies have also shown that patients enrolled in clinical trials are not necessarily representative of the general patient population. Chart reviews, which rely on the patient records, avoid some of the drawbacks of the clinical trials approach. Although chart review studies are more labor intensive, new developments in structured data entry and natural language processing (NLP) are helping to automate the process. However, studies which use chart reviews are limited by the accuracy and completeness of the data in the records.       In the past decade, online social networks have grown exponentially. Some health-focused social network sites have attracted large numbers of users and begun accumulating large quantities of detailed clinical information. The PatientsLikeMe site, for instance, has about 3,200 amyotrophic lateral sclerosis (ALS) patients worldwide, and includes about 5% of the ALS population in the US. Information gathered by online social networks is primarily intended for patients to share with each other. Such information has also begun to attract the attention of medical researchers.[3, 4]       Because using information from online social networks for medical research is a fairly new phenomenon, the value and limitation of this type of information source have not been systematically examined. To do so, we propose to conduct a comparison study of patient-contributed information from PatientsLikeMe and records from a large medical record data repository - the Research Patient Data Registry (RPDR) of the Partners Healthcare Systems. The proposed study will focus on ALS, multiple sclerosis (MS), and Parkinson's disease (PD). The general goal is to explore how the medical record and online networking data differ, and if and how online networking data could complement the medical record data. The specific aims are:    1) Extract symptom and treatment information from the two different data sources.    2) Compare the prevalence of symptoms and treatments from the two information sources and analyze the difference.    3) Extract treatment response of prescription medications from PatientsLikeMe and analyze the confounding effect of the misunderstanding of medication indication.      PUBLIC HEALTH RELEVANCE: The proposed project will investigate an emerging data source for clinical research: online social network. This data source may complement and supplement the data from clinical trials and medical records, with a unique emphasis on patients' experience and perspectives.           The proposed project will investigate an emerging data source for clinical research: online social network. This data source may complement and supplement the data from clinical trials and medical records, with a unique emphasis on patients' experience and perspectives.",Online Social Networking as an Alternative Information Source for Clinical Resear,7777633,R21NS067463,"['Amyotrophic Lateral Sclerosis', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Communities', 'Comparative Study', 'Complement', 'Data', 'Data Quality', 'Data Sources', 'Databases', 'Development', 'Enrollment', 'Frequencies', 'Goals', 'Healthcare Systems', 'Medical Records', 'Medical Research', 'Multiple Sclerosis', 'Natural Language Processing', 'Nature', 'Parkinson Disease', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Prevalence', 'Process', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Site', 'Source', 'Structure', 'Symptoms', 'System', 'Text', 'Time', 'Update', 'experience', 'information gathering', 'medical attention', 'patient population', 'public health relevance', 'social networking website', 'statistics', 'treatment response', 'web-based social networking']",NINDS,UNIVERSITY OF UTAH,R21,2009,219896,0.03009412114630868
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7671509,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2009,1455866,0.046127103997035485
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7922465,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2009,415228,0.046127103997035485
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7911405,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2009,229436,0.046127103997035485
"Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach    DESCRIPTION (provided by applicant):       The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The study design is prospective observational study. Scope is limited to cancer patients. There are three specific aims for this project. The first aim is to identify concepts that overlap between the electronic medical record's (EMR) clinical notes and the free text of clinical trial announcements. The PI will use the concepts to develop mapping frames that connect concepts in the text of trial announcements to those found in clinical notes in the medical record. When he has the mapping frames he will build the NLP module for the application. In the software development work he will utilize as many publicly available software components as possible. He will experiment with UIMA, GATE, MetaMap, Stanford Parser, NegEx algorithm and others. The PI will develop the tool around the National Library of Medicine's Unified Medical Language System knowledgebase. He will use Java for programming. The second aim is to create an algorithm that automatically generates questions to request information directly from the patient if the information is not available or accessible in the records. The third aim is to evaluate the in-vitro, laboratory performance of the application. For performance evaluation purposes the PI will recruit cancer care specialists to generate the gold standard lists of eligible clinical trials for study patients. He will publicly release the developed code at the end of the grant period. This K99/R00 project will serve the foundation for future R01 grant applications. The PI is fully committed to become faculty in the Clinical Research Informatics domain with a specialization in biomedical NLP. The support of the K99/R00 grant will enable him to acquire substantial formal training in Computational Linguistics while contributing to the body of knowledge of the Clinical Research Informatics field. The five-year grant support will ensure success in his endeavor. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, EMR based clinical trial recommendations directly to the patients. The results of this research will empower the patients and elevate their role in the decision making process.           Relevance The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, electronic medical record based clinical trial recommendations directly to the patients. The results of this research will empower patients and elevate their role in the decision making process.",Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach,7770648,K99LM010227,"['Adult', 'Age', 'Algorithms', 'Applications Grants', 'Arts', 'Biomedical Research', 'Cancer Patient', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Code', 'Commit', 'Complement', 'Computer software', 'Computerized Medical Record', 'Decision Making', 'Development', 'Elderly', 'Elements', 'Eligibility Determination', 'Enrollment', 'Ensure', 'Equation', 'Evaluation', 'Faculty', 'Foundations', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'In Vitro', 'Informatics', 'Java', 'Knowledge', 'Laboratories', 'Linguistics', 'Malignant Neoplasms', 'Maps', 'Medical Records', 'Medicine', 'Methods', 'Minority', 'Modification', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Role', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Surgeon', 'Text', 'Training', 'Unified Medical Language System', 'United States National Library of Medicine', 'Work', 'base', 'cancer care', 'empowered', 'ethnic minority population', 'information organization', 'novel', 'older patient', 'patient oriented', 'programs', 'prospective', 'research study', 'software development', 'success', 'tool']",NLM,UNIVERSITY OF WASHINGTON,K99,2009,84306,0.04316327027356663
"Early Warning Method and Technologies for Improving Cancer Care and Targeted Inte    DESCRIPTION (provided by applicant): Substantial evidence gathered over the last 50 years shows that adherence poses a crucial barrier to effective treatment and survival for cancer and other chronic diseases. At least one in five cancer patients do not adhere to treatment regimen, with much higher disease-specific rates. This non-adherence, or deviation from the recommended and expected clinical path, can dramatically increase costs of care, hospitalizations, adverse outcomes and the chance of preventable death. What causes non-adherence to treatment regimens is currently not rigorously understood. Current adherence research methods largely rely on survey instruments that have limited scale and scope, provide lagging information that inhibits timely intervention, and offer little actionable information to help patients to adhere to their care regimens. Further, the nature and timing of intervention to improve adherence have not been researched in depth. With continuous changes in cancer treatment, newer proactive approaches and methods for surveillance of patient adherence and targeted interventions are needed. In this project, we examine the feasibility and validity of a novel approach that uses a computational model to glean fine-grained attributes of cancer patients from standard electronic medical records. Our preliminary work has shown that electronic records to contain free-form text describing patient sentiment, vitals, medical condition, side effects, social history and family status written by physicians, nurses, medical assistants, and other staff during every visit encounter. With the steady adoption of electronic medical records by clinicians across the US (currently 29% and rising at 12% per year), clinical notes found in electronic records offer a tantalizing source of insight into patient adherence and behavior. Current adherence research has not tapped this rich source of data, even though many disciplines including biomedical informatics have employed natural language processing and text-mining techniques to glean patterns in semi- structured biomedical data. We aim to employ similar but novel, scalable computational models to glean a rich set of risk factors for patient non-adherence from 1 million patient encounter records, corresponding to 24,050 patients that span a 10 year time-horizon. Our objectives are to estimate the risk of a patient's ability to adhere to a prescribed regimen and enable targeted and timely interventions by using computational analysis of unstructured and structured fields in standard clinical documentation.  PUBLIC HEALTH RELEVANCE: We aim to show the feasibility of an early warning system that detects and estimates a cancer patient's risk of non-adherence to treatment regimens by analyzing unstructured text in standard medical records. This technology has tremendous relevance for improved quality of care, proactive management of chronic diseases and patient safety.                        Project Narrative We aim to show the feasibility of an early warning system that detects and estimates a cancer patient's risk of non-adherence to treatment regimens by analyzing unstructured text in standard medical records. This technology has tremendous relevance for improved quality of care, proactive management of chronic diseases and patient safety.  ",Early Warning Method and Technologies for Improving Cancer Care and Targeted Inte,7746912,R43CA141899,"['Adherence', 'Adoption', 'Adverse effects', 'Behavior', 'Behavioral', 'Cancer Patient', 'Caring', 'Cereals', 'Cessation of life', 'Chronic Disease', 'Clinical', 'Clinical Paths', 'Clinical Trials', 'Community Clinical Oncology Program', 'Computer Analysis', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Set', 'Data Sources', 'Discipline', 'Disease', 'Documentation', 'Electronics', 'Emotional', 'Employment', 'Family history of', 'Glean', 'Hospitalization', 'Individual', 'Intervention', 'Malignant Neoplasms', 'Medical', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Nurses', 'Nutritionist', 'Outcome', 'Patient Noncompliance', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Psychologist', 'Quality of Care', 'Records', 'Research', 'Research Methodology', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Scientific Advances and Accomplishments', 'Semantics', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Social Workers', 'Source', 'Structure', 'Surveillance Methods', 'Surveys', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Treatment Protocols', 'Visit', 'Weight', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer care', 'cancer therapy', 'clinical practice', 'compliance behavior', 'cost', 'effective therapy', 'follow-up', 'improved', 'innovation', 'insight', 'mathematical algorithm', 'novel', 'novel strategies', 'patient safety', 'psychologic', 'public health relevance', 'social', 'text searching']",NCI,"360FRESH, INC.",R43,2009,100000,0.018314149945293654
"Development and Use of Network Infrastructure for High-Throughput GWA Studies    DESCRIPTION (provided by applicant):  Linking biorepositories of patients in healthcare delivery systems with electronic medical records (EMRs) is an efficient strategy for high-throughput genome wide association (GWA) studies, as phenotype, covariable and exposure data of public health importance can be economically abstracted and pooled across delivery systems to facilitate the large numbers of subjects needed for GWA studies of each phenotype. Key obstacles to the success of this strategy remain. In this project, which will use population-based genomic and phenotype data from a well characterized population served by a delivery system which captures virtually all health care encounters in its data bases. Researchers from Group Health Cooperative's Center for Health Studies, the University of Washington, and the Fred Hutchinson Cancer Research Center will address these obstacles by pursuing the following specific aims:       1. Informed by results from targeted focus groups, implement a consensus process with key stakeholders to develop recommendations concerning consent, data sharing, and return of research results to subjects.    2. Work together with other network sites to develop a virtual data warehouse (VDW) analogous to that used in the Cancer Research Network, and extend natural language processing (NLP) to pathology, radiology, and clinical chart notes.   3. Develop and test strategies to determine whether each candidate EMR-based phenotype is sufficiently valid to pursue analyses of GWA data, and develop statistical methods that explicitly account for heterogeneous phenotype validity within and between sites.    4. Perform a series of GWA analyses in the GHC biorepository and linked biorepositories. 4a: Alzheimer's disease (AD). 4b: Carotid artery atherosclerotic disease (CAAD). 4c: Complications of statin use, including elevations of CPK and muscle pain.       Through cooperation with other investigators and the NHGRI, this work will facilitate development of policies and procedures to realize the incredible potential of EMR-linked biorepositories for GWA studies to improve understanding, prevention and treatment of chronic diseases and illnesses. Specific GWA research will allow us to explore both etiologic research (AD and CAAD progression) and pharmacogenetics (statin therapy). The implications of this portfolio of research extend far beyond the specific phenotypes we have chosen to emphasize; we expect this work represents the beginning of a large and productive enterprise.              n/a",Development and Use of Network Infrastructure for High-Throughput GWA Studies,7684273,U01HG004610,"['Abbreviations', 'Accounting', 'Address', 'Adult', 'Adverse event', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease patient registry', 'Blood Pressure', 'Cancer Research Network', 'Carotid Arteries', 'Carotid Artery Diseases', 'Cholesterol', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Data', 'Cognition', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consent', 'Creatinine', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Electronics', 'Enrollment', 'Environmental Exposure', 'Exposure to', 'Focus Groups', 'Foundations', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Genotype', 'Gold', 'Health', 'Healthcare', 'Healthcare Systems', 'High Density Lipoproteins', 'Individual', 'Inpatients', 'Knowledge', 'Laboratories', 'Leadership', 'Life', 'Link', 'Malignant Neoplasms', 'Maps', 'Medical', 'Meta-Analysis', 'Methods', 'Myalgia', 'National Cancer Institute', 'National Human Genome Research Institute', 'National Institute on Aging', 'Natural Language Processing', 'Neurofibrillary Tangles', 'Outcome', 'Outpatients', 'Participant', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Pharmacy facility', 'Phenotype', 'Population', 'Prevention', 'Procedures', 'Process', 'Public Domains', 'Public Health', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Recruitment Activity', 'Research', 'Research Ethics Committees', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sampling', 'Senile Plaques', 'Series', 'Single Nucleotide Polymorphism', 'Site', 'Statistical Methods', 'System', 'Testing', 'Text', 'Time', 'Universities', 'Ursidae Family', 'Washington', 'Work', 'abstracting', 'base', 'biobank', 'case control', 'cohort', 'cost', 'data sharing', 'development policy', 'economic cost', 'gene environment interaction', 'genome wide association study', 'genome-wide', 'health care delivery', 'human disease', 'improved', 'interest', 'member', 'population based', 'prospective', 'success', 'trait', 'virtual']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2009,1039667,-0.01590681437000699
"Development and Use of Network Infrastructure for High-Throughput GWA Studies    DESCRIPTION (provided by applicant):  Linking biorepositories of patients in healthcare delivery systems with electronic medical records (EMRs) is an efficient strategy for high-throughput genome wide association (GWA) studies, as phenotype, covariable and exposure data of public health importance can be economically abstracted and pooled across delivery systems to facilitate the large numbers of subjects needed for GWA studies of each phenotype. Key obstacles to the success of this strategy remain. In this project, which will use population-based genomic and phenotype data from a well characterized population served by a delivery system which captures virtually all health care encounters in its data bases. Researchers from Group Health Cooperative's Center for Health Studies, the University of Washington, and the Fred Hutchinson Cancer Research Center will address these obstacles by pursuing the following specific aims:       1. Informed by results from targeted focus groups, implement a consensus process with key stakeholders to develop recommendations concerning consent, data sharing, and return of research results to subjects.    2. Work together with other network sites to develop a virtual data warehouse (VDW) analogous to that used in the Cancer Research Network, and extend natural language processing (NLP) to pathology, radiology, and clinical chart notes.   3. Develop and test strategies to determine whether each candidate EMR-based phenotype is sufficiently valid to pursue analyses of GWA data, and develop statistical methods that explicitly account for heterogeneous phenotype validity within and between sites.    4. Perform a series of GWA analyses in the GHC biorepository and linked biorepositories. 4a: Alzheimer's disease (AD). 4b: Carotid artery atherosclerotic disease (CAAD). 4c: Complications of statin use, including elevations of CPK and muscle pain.       Through cooperation with other investigators and the NHGRI, this work will facilitate development of policies and procedures to realize the incredible potential of EMR-linked biorepositories for GWA studies to improve understanding, prevention and treatment of chronic diseases and illnesses. Specific GWA research will allow us to explore both etiologic research (AD and CAAD progression) and pharmacogenetics (statin therapy). The implications of this portfolio of research extend far beyond the specific phenotypes we have chosen to emphasize; we expect this work represents the beginning of a large and productive enterprise.              n/a",Development and Use of Network Infrastructure for High-Throughput GWA Studies,7921317,U01HG004610,"['Abbreviations', 'Accounting', 'Address', 'Adult', 'Adverse event', 'Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's Disease patient registry', 'Blood Pressure', 'Cancer Research Network', 'Carotid Arteries', 'Carotid Artery Diseases', 'Cholesterol', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Data', 'Cognition', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consent', 'Creatinine', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Electronics', 'Enrollment', 'Environmental Exposure', 'Exposure to', 'Focus Groups', 'Foundations', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Genotype', 'Gold', 'Health', 'Healthcare', 'Healthcare Systems', 'High Density Lipoproteins', 'Individual', 'Inpatients', 'Knowledge', 'Laboratories', 'Leadership', 'Life', 'Link', 'Malignant Neoplasms', 'Maps', 'Medical', 'Meta-Analysis', 'Methods', 'Myalgia', 'National Cancer Institute', 'National Human Genome Research Institute', 'National Institute on Aging', 'Natural Language Processing', 'Neurofibrillary Tangles', 'Outcome', 'Outpatients', 'Participant', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Pharmacy facility', 'Phenotype', 'Population', 'Prevention', 'Procedures', 'Process', 'Public Domains', 'Public Health', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Recruitment Activity', 'Research', 'Research Ethics Committees', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sampling', 'Senile Plaques', 'Series', 'Single Nucleotide Polymorphism', 'Site', 'Statistical Methods', 'System', 'Testing', 'Text', 'Time', 'Universities', 'Ursidae Family', 'Washington', 'Work', 'abstracting', 'base', 'biobank', 'case control', 'cohort', 'cost', 'data sharing', 'development policy', 'economic cost', 'gene environment interaction', 'genome wide association study', 'genome-wide', 'health care delivery', 'human disease', 'improved', 'interest', 'member', 'population based', 'prospective', 'success', 'trait', 'virtual']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2009,118469,-0.01590681437000699
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7908086,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Constitutional', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,130902,0.04152823991386371
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7660312,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Constitutional', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,362514,0.04152823991386371
"Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts    DESCRIPTION (provided by applicant):  Accurate and complete medication lists are critical inputs to effective medication reconciliation to prevent medication prescribing and administration errors. Previous research aggregated structured medication data form multiple sources to generate and maintain a reconciled medication list. Medications documented in clinical texts also need to be reconciled. However, most reconciliation methods currently have limited capability to process textual data and temporal information (e.g., dates, duration and status). Our goal is to pilot and test methodologies and applications in the fields of natural language processing (NLP) and temporal reasoning to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. Clinic notes and free-text ""comments"" fields in medication lists in an ambulatory electronic medical record system will be considered in the study. An NLP system and a temporal reasoning system will be adapted to automatically extract medication and associated temporal information from clinical texts and encode the medications using a controlled terminology. Multiple knowledge bases will be used to develop a mechanism to represent the timing of medication use, detect the changes (e.g., active or inactive), and then to organize medications into appropriate groups (e.g., by ingredient or by status). The feasibility and efficiency of the proposed methods and tools in improving the process of medication   reconciliation will be assessed. Domain experts will serve as judges to assess the success of capturing, coding, and organizing the medications and temporal information and also to evaluate whether our methods are complementary to those currently used for medication management.           Accurate and complete medication information at the point of care is crucial for delivery of high-quality care and prevention of adverse events. Most previous studies aggregated structured medication data from EMR and CPOE (Computerized Physician Order Entry) systems to generate and maintain a reconciled medication list. However, medications in non-structured narrative sources (such as clinic notes and free-text comments) must also be reconciled. Structured data presented in a standard, predictable form can be easily processed by a computer. By contrast, narrative data does not have a well-defined structure, so processing such data is very challenging. Our goal is to pilot and test methodologies and applications in the fields of natural language processing (any system that manipulates text) and temporal reasoning (e.g., identifying the timing of medication use) to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. The feasibility and efficiency of the proposed methods and tools in improving the process of medication reconciliation will be assessed.",Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts,7774682,R03HS018288,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R03,2009,48782,0.02095441885557976
"Data Structuring and Visualization System for Neuro-oncology    DESCRIPTION (provided by applicant):       The medical record for a neuro-oncology patient is complex, consisting of typically a large number of both text and imaging data. It includes descriptions of prior observations, interpretations, and interventions which need to be integrated into decisions regarding current patient care. An appropriate review of a patient's medical record often requires that a physician review multiple clinical documents while mentally noting issues related to what the findings were, the chronology of events, spatial/temporal patterns of disease progression, the effects of interventions, and the possible causal lines of explanation of observed findings. Additionally, imaging data and imaging- derived conclusions are poorly integrated into patient care and management decisions. The physician also needs to filter out those pieces of information not related to the current clinical context of care. Given the time constraints, data complexity and data volume associated with chronic patient cases, an appropriate review of a patient's chart is in reality rarely performed. Additionally, the lack of tools for formalizing the representation of the accounts of current and prior cases impedes the development of clinical databases that can be ultimately used to learn patterns of disease.       This proposal addresses the development of a system for facilitating the review of clinical patient data intended to promote an orderly process of medical problem understanding and care. The specific aims of the proposal are summarized as follows: 1) Development of a backend tool to facilitate the structured representation of observations, events, and inferences stated within medical reports. 2) Development of an application interface for visualizing, navigating, and editing structured patient data. 3) Evaluation of the effectiveness of the application in the domain of neuro-oncology.       Relation to public health. If the goals of this proposal can be realized, neuro-oncologist should be able to more easily seek desired patient data and detect patterns of evidence as compared to the current mode of operation (HIS, RIS, PACS). The structuring tools should lead to improvements in the quality of clinical research databases.           Narrative Medical records for neuro-oncology patients are difficult to review due to volume and complexity of information. A novel system for partitioning data along the information axes of space, time, existence, and causality is proposed to improve navigation and assimilation of data within the medical record.",Data Structuring and Visualization System for Neuro-oncology,7567140,R01LM009961,"['Abnormal coordination', 'Accounting', 'Address', 'Anatomy', 'Appearance', 'Assimilations', 'Caregivers', 'Caring', 'Chronic', 'Chronology', 'Clinic', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Complex', 'Computer software', 'Data', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Disease model', 'Effectiveness', 'Etiology', 'Evaluation', 'Event', 'Goals', 'Image', 'Imagery', 'Intervention', 'Lead', 'Learning', 'Medical', 'Medical Records', 'Metric', 'Natural Language Processing', 'Oncologist', 'Operative Surgical Procedures', 'Patient Care', 'Patient Care Management', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Process', 'Property', 'Public Health', 'Recording of previous events', 'Reporting', 'Research Personnel', 'Structure', 'System', 'Technology', 'Text', 'Time', 'Training', 'abstracting', 'follow-up', 'improved', 'innovation', 'intervention effect', 'neuro-oncology', 'novel', 'open source', 'physical state', 'satisfaction', 'tool']",NLM,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2009,953185,0.04065268113243179
"Automating assessment of obesity care quality    DESCRIPTION (provided by applicant): Current trends suggest that obesity prevalence will continue to rise and that costs of treating obesity-related disease will dramatically increase as the population ages. Despite NHLBI guidelines for preventing, diagnosing, and treating obesity among adults, most health care systems have been slow to respond to this looming public health problem. This slow response is partly due to the inability to assess adherence to obesity diagnosis and treatment guidelines. In particular, the lack of appropriate Health IT for integrating diverse clinical data on obesity, even within state-of-the-art electronic medical record systems (EMRs), makes it difficult to evaluate the quality of care, measure the effectiveness of new intervention programs, and make rational decisions at system, organization, and individual patient levels. EMRs offer the potential to efficiently assess large populations, however much of the data necessary for obesity care assessment are unavailable to automated methods because they reside in the text clinical notes of the EMR. Previous studies have shown that although some data of interest are recorded in easily retrievable fields (e.g., body weights recorded as a vital sign; standard diagnosis codes), much of the treatment information is found only in free-text clinical notes. This research aims to develop, validate, apply, and evaluate a scalable method for routine and comprehensive measurement of outpatient obesity care quality. To accomplish this, we will extend MediClass (a ""Medical Classifier""), which is a proven technology for extracting care quality data from both coded data and free-text clinical notes in the EMR. This research will perform retrospective analysis of adult primary care from the EMR data of two distinct health systems: a   mid-sized HMO (Kaiser Permanente Northwest, KPNW) and a consortium of public health clinics (OCHIN) including a diverse sample of patients, providers, and health care practices of the West Coast states (primarily Oregon, but also Washington and California). We propose to use Health IT to integrate diverse data and knowledge that advance quality improvement for both insured and the indigent, uninsured, and underinsured populations of this region. We will first develop obesity care quality (OCQ) measures using up to-date NHLBI guidelines for diagnosis and treatment of obesity. Next, we will develop and validate an automated method for applying these measures to comprehensive EMR data. At each study site, the Medi Class system will extract coded data and use natural language processing (NLP) on free-text clinical notes to identify OCQ-relevant clinical events in the EMR. Then we will apply the OCQ measures to assess current levels of obesity care quality in the two health systems. Finally, we will evaluate the associations between OCQ measures of recommended obesity care and provider characteristics as well as clinical outcomes for patients, including change in weight.           PROJECT NARRATIVE This study will improve care for obese and overweight patients by improving the technology we use for measuring the quality of care for these populations. This study will use specialized computer programs to analyze the electronic medical records of obese and overweight patients. The results of this work will help us determine if patients from two different health care systems are receiving recommended care, and how to better monitor the delivery of care for obese and overweight patients.",Automating assessment of obesity care quality,7761795,R18HS018157,[' '],AHRQ,KAISER FOUNDATION RESEARCH INSTITUTE,R18,2009,447671,0.03453516620617526
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7495030,R01LM006910,"['Address', 'Area', 'Caring', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Language', 'Machine Learning', 'Medical Surveillance', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'data mining', 'improved', 'knowledge base', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2008,338600,0.04350625600107967
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7675157,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Language', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'day', 'forgetting', 'innovation', 'preference', 'speech processing', 'symposium']",NLM,UNIVERSITY OF CHICAGO,R01,2008,354823,0.01297295608885409
"Extracting Semantic Knowledge from Clinical Reports    DESCRIPTION (provided by applicant): Analyzing and processing free-text medical reports for data mining and clinical data interchange is one of the most challenging problems in medical informatics, yet it is crucial for continued research advances and improvements in clinical care. Natural language processing (NLP) is an important enabling technology, but has been held back because it is difficult to understand human language, since it requires extensive domain knowledge. In Phase I, we developed new statistical and machine learning methods that apply domain specific knowledge to the semantic analysis of free-text radiology reports. The methods enabled the creation of two new prototype applications - a SNOMED CT (Systematized Nomenclature of Medicine--Clinical Terms) coding service called SnomedCoder, and a text mining tool for analyzing a large corpus of medical reports, called DataMiner. In Phase II, we will accomplish the following specific aims: 1) Improve the semantic extraction methods developed in Phase I, 2) Expand the semantic knowledge base and classify at least two million new unique sentences from multiple medical institutions, 3) Provide a SNOMED CT auto coding service (alpha service) to participating Indiana Health Information Exchange hospitals, and 4) Build a commercial version of the DataMiner software, and test its functionality using researchers at the Regenstrief Institute.       These scientific innovations will revolutionize the ability of health care researchers to analyze vast repositories of clinical information currently locked up in electronic medical records, and correlate this data with new biomedical discoveries in proteonomics and genomics. The ability to codify text rapidly will extend the potential for clinical decision support beyond its narrow base of numeric and structured medical data, and enable SNOMED CT to become a useful coding standard. Phase III will offer coding and data mining services to healthcare payers (both private and government), pharmaceuticals, and academic researchers. A key advantage of our approach over other NLP systems is that we attempt to codify all the information in the report and not just a limited subset, and insist on expert validation which provides a high degree of confidence in the accuracy of the coded data.Project Narrative           n/a",Extracting Semantic Knowledge from Clinical Reports,7394699,R44RR024929,"['Address', 'Algorithms', 'Back', 'Bioinformatics', 'Body of uterus', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Code', 'Collection', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Reporting', 'Decision Making', 'Effectiveness', 'Genomics', 'Goals', 'Government', 'Health', 'Healthcare', 'Hospitals', 'Human', 'Indiana', 'Institutes', 'Institution', 'Journals', 'Knowledge', 'Language', 'Longitudinal Studies', 'Machine Learning', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Natural Language Processing', 'Paper', 'Pharmacologic Substance', 'Phase', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Testing', 'Text', 'Thinking', 'Trees', 'Trust', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Validation', 'base', 'computerized', 'data mining', 'health care quality', 'improved', 'indexing', 'innovation', 'knowledge base', 'novel strategies', 'patient safety', 'prototype', 'repository', 'research and development', 'success', 'text searching', 'tool']",NCRR,"LOGICAL SEMANTICS, INC.",R44,2008,429955,0.029129766221864823
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7478824,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2008,177729,-0.0081242207653767
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7529967,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Numbers', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Purpose', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Standards of Weights and Measures', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'concept', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2008,213300,0.07479107134051369
"Using Natural Language Processing to Monitor Product Claims Compliance for FDA    DESCRIPTION (provided by applicant): Linguastat, Inc. proposes to develop a means to automate the process of monitoring and identifying companies engaged in false advertising and deceptive practices in the marketing of drugs, dietary supplements, and/or food products. By leveraging state of the art approaches in computational linguistics such as Information Extraction and Natural Language Processing, it should be feasible, with some adaptation, to use this technology to: 1) automatically and continuously monitor the websites, TV transcripts, press releases and other electronic marketing text communications of tens of thousands of companies for various claims and product information 2) automatically ""red-flag"" instances in which claims have a high likelihood of potential harm to consumers, according to FDA priorities 3) automatically identify and extract the companies, products and claims embedded in electronic product information and electronic promotional materials to create a database easily searchable by the FDA and 4) automatically capture web-based or other electronic content for human review and store it as ""evidence."" Such automated technology would enable the FDA to significantly stretch its limited human resource to more effectively and comprehensively identify noncompliant product information, detect deceptive ads and other illegal practices, successfully prosecute offenders, and prevent harm to American consumers. For this Phase I SBIR project we propose to assess the feasibility of automated claims monitoring in three steps: In the first step, we will train information extraction and natural language processing algorithms to extract product marketing claims from text. In the second, step we will apply data mining and rules-based algorithms to assess which claims are likely to be non-compliant and merit further attention by FDA staff. In the third step, we will design and build a database of product claims that allows analysts to search, organize, and prioritize product claims based on the type of claim (e.g. what ailments does the product claim to treat), the type of product, and the likelihood of non- compliance. This technology will enable regulators and consumers to better monitor and detect cases of false, misleading, or deceptive advertising and product information. By enabling more effective enforcement of FDA regulations and giving consumers tools to make better buying decisions, the public health can be better protected by minimizing the impact of products that cause harm, give false hope, or entice consumers to forgo conventional remedies.          n/a",Using Natural Language Processing to Monitor Product Claims Compliance for FDA,7677599,R43FD003406,[' '],FDA,"LINGUASTAT, INC.",R43,2008,20000,0.007975937219575756
"HERMES - Help physicians to Extract and aRticulate Multimedia information from li    DESCRIPTION (provided by applicant): Physicians have many questions when seeing patients. Primary care physicians are reported to generate between 0.7 and 18.5 questions for every 10 patient visits. The published medical literature is an important resource helping physicians to access up-to-date clinical information and thereby to enhance the quality of patient care. For example, the case study in the above example (i.e., diagnostic procedures and treatment for cellulites) was published in a ""Clinical Practice"" article in the New England Journal of Medicine (NEJM). Although PubMed is frequently used by physicians in large hospitals, it does not return answers to specific questions. Frequently, PubMed returns a large number of articles in response to a specific user query. Physicians have limited time for browsing the articles retrieved; it has been found that physicians spend on average two minutes or less seeking an answer to a question, and that if a search takes longer it is likely to be abandoned. An evaluation study has shown that it takes an average of more than 30 minutes for a healthcare provider to search for answer from PubMed, which makes ""information seeking ... practical only `after hours' and not in the clinical setting."" It has been concluded that a lack of time is the most common obstacle resulting in many unanswered medical questions.       The importance of answering physicians' questions at the point of patient care has been widely recognized by the medical community. Many medical databases (e.g., UpToDate and Thomson MICROMEDEX) provide summaries to answer important medical questions related to patient care. However, most of the summaries are written by medical experts who manually review the literature information. The databases are limited in their scope and timeliness.       We hypothesize that we can develop medical language processing (MLP) approaches to build a fully automated system HERMES - Help physicians to Extract and aRticulate Multimedia information from literature to answer their ad-hoc medical quEstionS. HERMES will automatically retrieve, extract, analyze, and integrate text, image, and video from the literature and formulate them as answers to ad-hoc medical questions posed by physicians. Our preliminary results show that even a limited HERMES working system outperformed other information retrieval systems and can generate answers within a timeframe necessary to meet the demands of physicians. HERMES promise to assist physicians for practicing evidence-based medicine (EBM), the medical practice that involves the explicit use of current best evidence, i.e., high-quality patient-centered clinical research reported in the primary medical literature.       Our specific aims are:       1) Identify information needs from ad-hoc medical questions. We will incorporate rich semantic, statistical, and machine learning approaches to map ad-hoc medical questions to their component question types automatically. A component question type is a generic, simple question type that requires an answer strategy that is different from other component question types.       2) Develop new information retrieval models that integrate domain-specific knowledge for retrieving relevant documents in response to an ad-hoc medical question.       3) Extract relevant text, images, and videos from the retrieved documents in response to an ad-hoc medical question.       4) Integrate text, images, and videos, fusing information to generate a short and coherent multimedia summary.       5) Design a usability study to measure efficacy, accuracy and perceived ease of use of HERMES and to compare HERMES with other information systems.          n/a",HERMES - Help physicians to Extract and aRticulate Multimedia information from li,7502749,R01LM009836,"['Area', 'Back', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Research', 'Communities', 'Databases', 'Diagnostic Procedure', 'Edema', 'Erythema', 'Evaluation Studies', 'Evidence Based Medicine', 'Generic Drugs', 'Health Personnel', 'Hospitals', 'Hour', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Journals', 'Knowledge', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medicine', 'Modeling', 'Multimedia', 'New England', 'Numbers', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Primary Care Physician', 'PubMed', 'Publishing', 'Redness', 'Reporting', 'Resources', 'Review Literature', 'Semantics', 'System', 'Text', 'Time', 'Toes', 'Ultrasonography', 'Visit', 'Work', 'Writing', 'design', 'foot', 'journal article', 'language processing', 'mecarzole', 'older men', 'patient oriented', 'response', 'usability']",NLM,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2008,352226,0.02836861393919664
"Evidence based anomaly detection in clinical databases.    DESCRIPTION (provided by applicant):       Medical errors and their timely identification remain an important problem in clinical practice. Electronic medical record repositories and electronic data processing offer an opportunity to identify such errors in time to prevent them or at least attenuate their harm.  Typical computer-based error detection methods rely on the use of clinical knowledge, such as expert-derived rules, that is incorporated into the monitoring and alerting systems. Alerting that is based on knowledge is generally reliable; however, it is time-consuming and costly to extract and codify such knowledge, and as a consequence such systems are relatively narrow in their scope.  We propose to develop and evaluate a data-based approach for detecting clinical outliers (anomalies) that is complementary to knowledge-based approaches. This new approach is based on comparing clinical actions, such as medications given and labs ordered, taken for the current patient to those actions taken for similar patients in the recent past, as recorded in a clinical database. If a clinical action for the current patient is highly unusual, then a cautionary alert is raised along with an explanation for why the action appears to be unusual. Key advantages of the new technique are that it works with minimal prior knowledge, and it may detect anomalies for which no rules have yet been written. Thus, this data-driven approach to clinical anomaly detection is expected to complement knowledge-based alerting methods. We propose to implement a data-driven anomaly detection method, and then evaluate it in a laboratory setting using retrospective data for the cohort of surgical cardiac patients.  The project investigators comprise a multidisciplinary team with expertise in rule-based alerting in a hospital setting, clinical pharmacy, laboratory medicine, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories.          n/a",Evidence based anomaly detection in clinical databases.,7385073,R21LM009102,"['Anticoagulants', 'Arts', 'Attenuated', 'Automatic Data Processing', 'Blood Platelets', 'Cardiac', 'Catheters', 'Cessation of life', 'Clinical', 'Complement', 'Computerized Medical Record', 'Computers', 'Condition', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Disadvantaged', 'Dose', 'Drops', 'Evaluation', 'Event', 'Flushing', 'General Population', 'Healthcare', 'Heparin', 'Hospitals', 'Imagery', 'Information Resources Management', 'Invasive', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Lead', 'Left', 'Life', 'Low-Molecular-Weight Heparin', 'Machine Learning', 'Manuals', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Monitor', 'Numbers', 'Operative Surgical Procedures', 'Outcome', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Physicians', 'Platelet Count measurement', 'Platelet Transfusion', 'Practice Management', 'Procedures', 'Range', 'Records', 'Research', 'Research Personnel', 'Risk', 'Signal Transduction', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'System', 'Techniques', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Time', 'Validation', 'Warfarin', 'Work', 'Writing', 'base', 'biomedical informatics', 'cohort', 'computer based statistical methods', 'cost', 'design', 'improved', 'interest', 'knowledge base', 'medical specialties', 'multidisciplinary', 'novel', 'novel strategies', 'prevent', 'prophylactic', 'repository', 'response', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2008,193536,0.022381268513104405
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7579478,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computational Technique', 'Computerized Medical Record', 'Count', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Medical Surveillance', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'Numbers', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Pliability', 'Population', 'Positioning Attribute', 'Practice based research', 'Primary Health Care', 'Procedures', 'Process', 'Purpose', 'Range', 'Reaction', 'Records', 'Reference Standards', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Role', 'Safety', 'Score', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'concept', 'data mining', 'design', 'experience', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2008,299619,0.03182642961458544
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7448662,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY,R01,2008,383338,0.018007997871518373
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7414601,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Language', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Population', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Today', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2008,142400,0.0076566232735139576
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7502672,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Population', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'concept', 'data modeling', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2008,1432331,0.046127103997035485
"Development and Use of Network Infrastructure for High-Throughput GWA Studies    DESCRIPTION (provided by applicant):  Linking biorepositories of patients in healthcare delivery systems with electronic medical records (EMRs) is an efficient strategy for high-throughput genome wide association (GWA) studies, as phenotype, covariable and exposure data of public health importance can be economically abstracted and pooled across delivery systems to facilitate the large numbers of subjects needed for GWA studies of each phenotype. Key obstacles to the success of this strategy remain. In this project, which will use population-based genomic and phenotype data from a well characterized population served by a delivery system which captures virtually all health care encounters in its data bases. Researchers from Group Health Cooperative's Center for Health Studies, the University of Washington, and the Fred Hutchinson Cancer Research Center will address these obstacles by pursuing the following specific aims:       1. Informed by results from targeted focus groups, implement a consensus process with key stakeholders to develop recommendations concerning consent, data sharing, and return of research results to subjects.    2. Work together with other network sites to develop a virtual data warehouse (VDW) analogous to that used in the Cancer Research Network, and extend natural language processing (NLP) to pathology, radiology, and clinical chart notes.   3. Develop and test strategies to determine whether each candidate EMR-based phenotype is sufficiently valid to pursue analyses of GWA data, and develop statistical methods that explicitly account for heterogeneous phenotype validity within and between sites.    4. Perform a series of GWA analyses in the GHC biorepository and linked biorepositories. 4a: Alzheimer's disease (AD). 4b: Carotid artery atherosclerotic disease (CAAD). 4c: Complications of statin use, including elevations of CPK and muscle pain.       Through cooperation with other investigators and the NHGRI, this work will facilitate development of policies and procedures to realize the incredible potential of EMR-linked biorepositories for GWA studies to improve understanding, prevention and treatment of chronic diseases and illnesses. Specific GWA research will allow us to explore both etiologic research (AD and CAAD progression) and pharmacogenetics (statin therapy). The implications of this portfolio of research extend far beyond the specific phenotypes we have chosen to emphasize; we expect this work represents the beginning of a large and productive enterprise.              n/a",Development and Use of Network Infrastructure for High-Throughput GWA Studies,7688756,U01HG004610,"['Abbreviations', 'Accounting', 'Address', 'Adult', 'Adverse event', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Blood Pressure', 'Cancer Research Network', 'Carotid Arteries', 'Carotid Artery Diseases', 'Cholesterol', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Data', 'Cognition', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consent', 'Creatinine', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Electronics', 'Elevation', 'Enrollment', 'Environmental Exposure', 'Exposure to', 'Focus Groups', 'Foundations', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genome', 'Genomics', 'Genotype', 'Gold', 'Health', 'Healthcare', 'Healthcare Systems', 'High Density Lipoproteins', 'Individual', 'Inpatients', 'Institutes', 'Knowledge', 'Laboratories', 'Leadership', 'Life', 'Link', 'Malignant Neoplasms', 'Maps', 'Medical', 'Meta-Analysis', 'Methods', 'Myalgia', 'National Cancer Institute', 'Natural Language Processing', 'Neurofibrillary Tangles', 'Numbers', 'Outcome', 'Outpatients', 'Participant', 'Pathology', 'Patients', 'Performance', 'Personal Satisfaction', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Pharmacy facility', 'Phenotype', 'Policy Developments', 'Population', 'Prevention', 'Procedures', 'Process', 'Public Domains', 'Public Health', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Recruitment Activity', 'Research', 'Research Ethics Committees', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sampling', 'Senile Plaques', 'Series', 'Single Nucleotide Polymorphism', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'System', 'Testing', 'Text', 'Thinking', 'Time', 'Universities', 'Ursidae Family', 'Washington', 'Work', 'abstracting', 'base', 'case control', 'cohort', 'cost', 'development policy', 'gene environment interaction', 'genome wide association study', 'health care delivery', 'human disease', 'improved', 'interest', 'member', 'patient registry', 'prescription document', 'prescription procedure', 'prospective', 'success', 'trait', 'virtual']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2008,219307,-0.01590681437000699
"Development and Use of Network Infrastructure for High-Throughput GWA Studies    DESCRIPTION (provided by applicant):  Linking biorepositories of patients in healthcare delivery systems with electronic medical records (EMRs) is an efficient strategy for high-throughput genome wide association (GWA) studies, as phenotype, covariable and exposure data of public health importance can be economically abstracted and pooled across delivery systems to facilitate the large numbers of subjects needed for GWA studies of each phenotype. Key obstacles to the success of this strategy remain. In this project, which will use population-based genomic and phenotype data from a well characterized population served by a delivery system which captures virtually all health care encounters in its data bases. Researchers from Group Health Cooperative's Center for Health Studies, the University of Washington, and the Fred Hutchinson Cancer Research Center will address these obstacles by pursuing the following specific aims:       1. Informed by results from targeted focus groups, implement a consensus process with key stakeholders to develop recommendations concerning consent, data sharing, and return of research results to subjects.    2. Work together with other network sites to develop a virtual data warehouse (VDW) analogous to that used in the Cancer Research Network, and extend natural language processing (NLP) to pathology, radiology, and clinical chart notes.   3. Develop and test strategies to determine whether each candidate EMR-based phenotype is sufficiently valid to pursue analyses of GWA data, and develop statistical methods that explicitly account for heterogeneous phenotype validity within and between sites.    4. Perform a series of GWA analyses in the GHC biorepository and linked biorepositories. 4a: Alzheimer's disease (AD). 4b: Carotid artery atherosclerotic disease (CAAD). 4c: Complications of statin use, including elevations of CPK and muscle pain.       Through cooperation with other investigators and the NHGRI, this work will facilitate development of policies and procedures to realize the incredible potential of EMR-linked biorepositories for GWA studies to improve understanding, prevention and treatment of chronic diseases and illnesses. Specific GWA research will allow us to explore both etiologic research (AD and CAAD progression) and pharmacogenetics (statin therapy). The implications of this portfolio of research extend far beyond the specific phenotypes we have chosen to emphasize; we expect this work represents the beginning of a large and productive enterprise.              n/a",Development and Use of Network Infrastructure for High-Throughput GWA Studies,7502172,U01HG004610,"['Abbreviations', 'Accounting', 'Address', 'Adult', 'Adverse event', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Blood Pressure', 'Cancer Research Network', 'Carotid Arteries', 'Carotid Artery Diseases', 'Cholesterol', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Data', 'Cognition', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consent', 'Creatinine', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Electronics', 'Elevation', 'Enrollment', 'Environmental Exposure', 'Exposure to', 'Focus Groups', 'Foundations', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genome', 'Genomics', 'Genotype', 'Gold', 'Health', 'Healthcare', 'Healthcare Systems', 'High Density Lipoproteins', 'Individual', 'Inpatients', 'Institutes', 'Knowledge', 'Laboratories', 'Leadership', 'Life', 'Link', 'Malignant Neoplasms', 'Maps', 'Medical', 'Meta-Analysis', 'Methods', 'Myalgia', 'National Cancer Institute', 'Natural Language Processing', 'Neurofibrillary Tangles', 'Numbers', 'Outcome', 'Outpatients', 'Participant', 'Pathology', 'Patients', 'Performance', 'Personal Satisfaction', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Pharmacy facility', 'Phenotype', 'Policy Developments', 'Population', 'Prevention', 'Procedures', 'Process', 'Public Domains', 'Public Health', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Recruitment Activity', 'Research', 'Research Ethics Committees', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sampling', 'Senile Plaques', 'Series', 'Single Nucleotide Polymorphism', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'System', 'Testing', 'Text', 'Thinking', 'Time', 'Universities', 'Ursidae Family', 'Washington', 'Work', 'abstracting', 'base', 'case control', 'cohort', 'cost', 'development policy', 'gene environment interaction', 'genome wide association study', 'health care delivery', 'human disease', 'improved', 'interest', 'member', 'patient registry', 'prescription document', 'prescription procedure', 'prospective', 'success', 'trait', 'virtual']",NHGRI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,U01,2008,987473,-0.01590681437000699
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7469551,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Condition', 'Constitutional', 'Depth', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Medical Surveillance', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'concept', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2008,392337,0.04152823991386371
"Statistical NLP Analysis of Cross-discipline Clinical Text emerging trend in computational linguistics is melding natural language processing (NLP) and machine learning (ML) to help computers make sense of human-generated free text. The blending of these disciplines is relatively rare in biomedical inforrnatics. Past medical NLP/ML research work is biased heavily towards linguistic methods that attempt to reason about grammar and syntax aided by a domain-focal knowledge base (e.g., one for radiology or one for clinical pathology). The aim of the work proposed here takes a different tack: exploring the utility of a statistical approach to clinical NLP, one augmented by machine learning and concentrating on general progress notes from across multiple clinical domains. The specific clinical goal will be to identify adverse drug events described implicitly or explicitly in inpatient progress notes. Rather than relying on a narrow domain focus to provide enough context restriction to make text interpretation tractable, this approach will use statistical patterns in note author information (e.g., profession, note type, treating ward) and patient information (e.g., admit diagnosis, procedures performed, temporal note relationships) for context restriction. The research component of this proposal is divided into two categories: three small-scale projects designed to rapidly hone new skills developed under the training component, and a large-scale project that assesses the feasibility of cross-discipline clinical text analysis. n/a",Statistical NLP Analysis of Cross-discipline Clinical Text,6944955,F38LM008478,"['Categories', 'Clinical', 'Clinical Pathology', 'Computers', 'Coupled', 'Diagnosis', 'Discipline', 'Event', 'Fellowship', 'Goals', 'Human', 'Inpatients', 'Linguistics', 'Machine Learning', 'Medical', 'Methods', 'Natural Language Processing', 'Patients', 'Pattern', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Procedures', 'Radiology Specialty', 'Research', 'Statistical Study', 'Text', 'Training', 'Work', 'Writing', 'design', 'experience', 'knowledge base', 'skills', 'syntax', 'theories', 'tool', 'trend', 'ward']",NLM,UNIVERSITY OF UTAH,F38,2007,38768,0.01771153974917548
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7288319,R01LM006910,"['Address', 'Area', 'Caring', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Language', 'Machine Learning', 'Medical Surveillance', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'data mining', 'improved', 'knowledge base', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,345833,0.04350625600107967
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7217497,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Language', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'day', 'forgetting', 'innovation', 'preference', 'speech processing', 'symposium']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,361696,0.01297295608885409
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7305430,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2007,229030,-0.0081242207653767
"Using Natural Language Processing to Monitor Product Claims Compliance for FDA    DESCRIPTION (provided by applicant): Linguastat, Inc. proposes to develop a means to automate the process of monitoring and identifying companies engaged in false advertising and deceptive practices in the marketing of drugs, dietary supplements, and/or food products. By leveraging state of the art approaches in computational linguistics such as Information Extraction and Natural Language Processing, it should be feasible, with some adaptation, to use this technology to: 1) automatically and continuously monitor the websites, TV transcripts, press releases and other electronic marketing text communications of tens of thousands of companies for various claims and product information 2) automatically ""red-flag"" instances in which claims have a high likelihood of potential harm to consumers, according to FDA priorities 3) automatically identify and extract the companies, products and claims embedded in electronic product information and electronic promotional materials to create a database easily searchable by the FDA and 4) automatically capture web-based or other electronic content for human review and store it as ""evidence."" Such automated technology would enable the FDA to significantly stretch its limited human resource to more effectively and comprehensively identify noncompliant product information, detect deceptive ads and other illegal practices, successfully prosecute offenders, and prevent harm to American consumers. For this Phase I SBIR project we propose to assess the feasibility of automated claims monitoring in three steps: In the first step, we will train information extraction and natural language processing algorithms to extract product marketing claims from text. In the second, step we will apply data mining and rules-based algorithms to assess which claims are likely to be non-compliant and merit further attention by FDA staff. In the third step, we will design and build a database of product claims that allows analysts to search, organize, and prioritize product claims based on the type of claim (e.g. what ailments does the product claim to treat), the type of product, and the likelihood of non- compliance. This technology will enable regulators and consumers to better monitor and detect cases of false, misleading, or deceptive advertising and product information. By enabling more effective enforcement of FDA regulations and giving consumers tools to make better buying decisions, the public health can be better protected by minimizing the impact of products that cause harm, give false hope, or entice consumers to forgo conventional remedies.          n/a",Using Natural Language Processing to Monitor Product Claims Compliance for FDA,7326883,R43FD003406,[' '],FDA,"LINGUASTAT, INC.",R43,2007,99773,0.007975937219575756
"HERMES - Help physicians to Extract and aRticulate Multimedia information from li    DESCRIPTION (provided by applicant): Physicians have many questions when seeing patients. Primary care physicians are reported to generate between 0.7 and 18.5 questions for every 10 patient visits. The published medical literature is an important resource helping physicians to access up-to-date clinical information and thereby to enhance the quality of patient care. For example, the case study in the above example (i.e., diagnostic procedures and treatment for cellulites) was published in a ""Clinical Practice"" article in the New England Journal of Medicine (NEJM). Although PubMed is frequently used by physicians in large hospitals, it does not return answers to specific questions. Frequently, PubMed returns a large number of articles in response to a specific user query. Physicians have limited time for browsing the articles retrieved; it has been found that physicians spend on average two minutes or less seeking an answer to a question, and that if a search takes longer it is likely to be abandoned. An evaluation study has shown that it takes an average of more than 30 minutes for a healthcare provider to search for answer from PubMed, which makes ""information seeking ... practical only `after hours' and not in the clinical setting."" It has been concluded that a lack of time is the most common obstacle resulting in many unanswered medical questions.       The importance of answering physicians' questions at the point of patient care has been widely recognized by the medical community. Many medical databases (e.g., UpToDate and Thomson MICROMEDEX) provide summaries to answer important medical questions related to patient care. However, most of the summaries are written by medical experts who manually review the literature information. The databases are limited in their scope and timeliness.       We hypothesize that we can develop medical language processing (MLP) approaches to build a fully automated system HERMES - Help physicians to Extract and aRticulate Multimedia information from literature to answer their ad-hoc medical quEstionS. HERMES will automatically retrieve, extract, analyze, and integrate text, image, and video from the literature and formulate them as answers to ad-hoc medical questions posed by physicians. Our preliminary results show that even a limited HERMES working system outperformed other information retrieval systems and can generate answers within a timeframe necessary to meet the demands of physicians. HERMES promise to assist physicians for practicing evidence-based medicine (EBM), the medical practice that involves the explicit use of current best evidence, i.e., high-quality patient-centered clinical research reported in the primary medical literature.       Our specific aims are:       1) Identify information needs from ad-hoc medical questions. We will incorporate rich semantic, statistical, and machine learning approaches to map ad-hoc medical questions to their component question types automatically. A component question type is a generic, simple question type that requires an answer strategy that is different from other component question types.       2) Develop new information retrieval models that integrate domain-specific knowledge for retrieving relevant documents in response to an ad-hoc medical question.       3) Extract relevant text, images, and videos from the retrieved documents in response to an ad-hoc medical question.       4) Integrate text, images, and videos, fusing information to generate a short and coherent multimedia summary.       5) Design a usability study to measure efficacy, accuracy and perceived ease of use of HERMES and to compare HERMES with other information systems.          n/a",HERMES - Help physicians to Extract and aRticulate Multimedia information from li,7380099,R01LM009836,"['Area', 'Back', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Research', 'Communities', 'Databases', 'Diagnostic Procedure', 'Edema', 'Erythema', 'Evaluation Studies', 'Evidence Based Medicine', 'Generic Drugs', 'Health Personnel', 'Hospitals', 'Hour', 'Image', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Journals', 'Knowledge', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medicine', 'Modeling', 'Multimedia', 'New England', 'Numbers', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Primary Care Physician', 'PubMed', 'Publishing', 'Redness', 'Reporting', 'Resources', 'Review Literature', 'Semantics', 'System', 'Text', 'Time', 'Toes', 'Ultrasonography', 'Visit', 'Work', 'Writing', 'design', 'foot', 'journal article', 'language processing', 'mecarzole', 'older men', 'patient oriented', 'response', 'usability']",NLM,UNIVERSITY OF WISCONSIN MILWAUKEE,R01,2007,383550,0.02836861393919664
"Evidence based anomaly detection in clinical databases.    DESCRIPTION (provided by applicant):       Medical errors and their timely identification remain an important problem in clinical practice. Electronic medical record repositories and electronic data processing offer an opportunity to identify such errors in time to prevent them or at least attenuate their harm.  Typical computer-based error detection methods rely on the use of clinical knowledge, such as expert-derived rules, that is incorporated into the monitoring and alerting systems. Alerting that is based on knowledge is generally reliable; however, it is time-consuming and costly to extract and codify such knowledge, and as a consequence such systems are relatively narrow in their scope.  We propose to develop and evaluate a data-based approach for detecting clinical outliers (anomalies) that is complementary to knowledge-based approaches. This new approach is based on comparing clinical actions, such as medications given and labs ordered, taken for the current patient to those actions taken for similar patients in the recent past, as recorded in a clinical database. If a clinical action for the current patient is highly unusual, then a cautionary alert is raised along with an explanation for why the action appears to be unusual. Key advantages of the new technique are that it works with minimal prior knowledge, and it may detect anomalies for which no rules have yet been written. Thus, this data-driven approach to clinical anomaly detection is expected to complement knowledge-based alerting methods. We propose to implement a data-driven anomaly detection method, and then evaluate it in a laboratory setting using retrospective data for the cohort of surgical cardiac patients.  The project investigators comprise a multidisciplinary team with expertise in rule-based alerting in a hospital setting, clinical pharmacy, laboratory medicine, biomedical informatics, statistical machine learning, knowledge based systems, and clinical data repositories.          n/a",Evidence based anomaly detection in clinical databases.,7197167,R21LM009102,"['Anticoagulants', 'Arts', 'Attenuated', 'Automatic Data Processing', 'Blood Platelets', 'Cardiac', 'Catheters', 'Cessation of life', 'Clinical', 'Complement', 'Computerized Medical Record', 'Computers', 'Condition', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Disadvantaged', 'Dose', 'Drops', 'Evaluation', 'Event', 'Flushing', 'General Population', 'Healthcare', 'Heparin', 'Hospitals', 'Imagery', 'Information Resources Management', 'Invasive', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Lead', 'Left', 'Life', 'Low-Molecular-Weight Heparin', 'Machine Learning', 'Manuals', 'Measures', 'Medical Errors', 'Medicine', 'Methods', 'Monitor', 'Numbers', 'Operative Surgical Procedures', 'Outcome', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Physicians', 'Platelet Count measurement', 'Platelet Transfusion', 'Practice Management', 'Procedures', 'Range', 'Records', 'Research', 'Research Personnel', 'Risk', 'Signal Transduction', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'System', 'Techniques', 'Testing', 'Thrombocytopenia', 'Thrombosis', 'Time', 'Validation', 'Warfarin', 'Work', 'Writing', 'base', 'biomedical informatics', 'cohort', 'computer based statistical methods', 'cost', 'design', 'improved', 'interest', 'knowledge base', 'medical specialties', 'multidisciplinary', 'novel', 'novel strategies', 'prevent', 'prophylactic', 'repository', 'response', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2007,161562,0.022381268513104405
"Automated Detection of Medical Errors DESCRIPTION:    The long-term goal of this proposal is to use the electronic medical record, including narrative text, to understand and encode the process of care for individual patients in order to improve patient safety.   Achieving this goal has the potential to help detect adverse events, and to differentiate medical errors from appropriately tailored care. The specific aims for this proposal are as follows: 1) To understand and encode the process of care for individual patients using data in the electronic medical record, including narrative text.   2) To use a more detailed understanding of patients' processes of care to improve automated adverse event detection. 3) To match processes of care for individual patients against accepted care pathways in order to identify discrepancies. We will capitalize on three core technologies that are in active use by clinicians and researchers in our busy clinical setting: 1) a Web-based clinical information system and its associated clinical data repository (WebCIS), 2) a full medical language parser (MedLEE), and 3) a semi-structured, electronic physician documentation system built by the applicant specifically to support this project (eNote).   Methods will include evaluating the performance (sensitivity, specificity and positive predictive value) of our system, DETER+MINE (DETecting ERrors Mining Narrative Electronically), to model the care process and detect adverse events and pathway deviations. We will utilize explicit process criteria and manual, retrospective chart review as a gold standard.   This research is intended to provide proof of concept that combining natural language processing of clinical narrative with traditional sources of coded data is required for effective screening with automated defection systems. This approach has the potential to impact significantly on our ability to detect and investigate medical errors, adverse medical events, and pathway deviations by reducing reliance on costly and slow manual chart reviews. n/a",Automated Detection of Medical Errors,7282343,K22LM008805,"['Address', 'Adverse event', 'Applications Grants', 'Caring', 'Causations', 'Cause of Death', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Pathways', 'Code', 'Computerized Medical Record', 'Critical Care', 'Data', 'Databases', 'Decision Support Systems', 'Detection', 'Documentation', 'Effectiveness', 'Electronics', 'Event', 'Goals', 'Gold', 'Guidelines', 'Hospitals', 'Human', 'Individual', 'Information Systems', 'Institute of Medicine (U.S.)', 'Language', 'Manuals', 'Medical', 'Medical Errors', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Negligence', 'Online Systems', 'Pathway interactions', 'Patients', 'Performance', 'Physicians', 'Predictive Value', 'Prevention', 'Process', 'Range', 'Recommendation', 'Reliance', 'Reporting', 'Research', 'Research Personnel', 'Screening procedure', 'Sensitivity and Specificity', 'Source Code', 'Standards of Weights and Measures', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'United States', 'base', 'computerized', 'concept', 'experience', 'improved', 'patient safety', 'programs', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,K22,2007,135000,0.047828496088746
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7262635,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY MED CTR,R01,2007,304785,0.018007997871518373
"TIME:(Tools for Inpatient Monitoring using Evidence)for Safe & AppropriateTesting The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care. Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence- based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients. Public Statement The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury. n/a",TIME:(Tools for Inpatient Monitoring using Evidence)for Safe & AppropriateTesting,7347232,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY MED CTR,R01,2007,55295,0.018795883935495184
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7195053,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Language', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Population', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Today', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2007,145510,0.0076566232735139576
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,7249382,R01EB000362,"['Address', 'Architecture', 'Caring', 'Chronic', 'Clinical', 'Clinical Medicine', 'Complex', 'Computer Architectures', 'Condition', 'Data', 'Data Collection', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Documentation', 'Early Diagnosis', 'Effectiveness', 'Engineering', 'Environment', 'Evaluation', 'Evidence Based Medicine', 'Extensible Markup Language', 'Geographic Locations', 'Healthcare', 'Image', 'Imagery', 'Individual', 'Information Management', 'Laboratories', 'Language', 'Link', 'Management Information Systems', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Methodology', 'Metric', 'Multimedia', 'Natural Language Processing', 'Numbers', 'Online Systems', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Problem Solving', 'Procedures', 'Process', 'Provider', 'Radiology Specialty', 'Records', 'Reporting', 'Research', 'Research Design', 'Series', 'Services', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'TimeLine', 'United States', 'Urology', 'Visit', 'base', 'concept', 'cost', 'data acquisition', 'data management', 'data modeling', 'improved', 'information gathering', 'innovation', 'innovative technologies', 'insight', 'peer', 'point of care', 'portability', 'research clinical testing', 'urologic', 'usability']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2007,517331,0.07342343995885153
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,7272822,R01EB002247,"['Address', 'Algorithms', 'Anatomy', 'Area', 'Atlases', 'Body of uterus', 'Cancer Patient', 'Caregivers', 'Chronic', 'Chronic Disease', 'Clinical', 'Communication', 'Communities', 'Condition', 'Consultations', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Documentation', 'Eating', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Health Personnel', 'Healthcare', 'Image', 'Label', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Records', 'Methods', 'Metric', 'Modeling', 'Musculoskeletal', 'Musculoskeletal Pain', 'Natural Language Processing', 'Neurologic', 'Oncologist', 'Optics', 'Patients', 'Performance', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Process', 'Quality of Care', 'Reference Standards', 'Reporting', 'Research', 'Research Design', 'Research Infrastructure', 'Slice', 'Specialist', 'Structure', 'Surgeon', 'System', 'Techniques', 'Technology', 'Teleconsultations', 'Telemedicine', 'Testing', 'Time', 'Upper arm', 'Work', 'base', 'chemotherapy', 'data mining', 'diagnostic accuracy', 'health care quality', 'image registration', 'improved', 'interest', 'knowledge base', 'medical specialties', 'novel', 'research clinical testing', 'size', 'telehealth']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2007,394864,0.05131919882389047
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7427367,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Population', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'concept', 'data modeling', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY MED CTR,U01,2007,1463449,0.046127103997035485
"Development and Use of Network Infrastructure for High-Throughput GWA Studies    DESCRIPTION (provided by applicant):  Linking biorepositories of patients in healthcare delivery systems with electronic medical records (EMRs) is an efficient strategy for high-throughput genome wide association (GWA) studies, as phenotype, covariable and exposure data of public health importance can be economically abstracted and pooled across delivery systems to facilitate the large numbers of subjects needed for GWA studies of each phenotype. Key obstacles to the success of this strategy remain. In this project, which will use population-based genomic and phenotype data from a well characterized population served by a delivery system which captures virtually all health care encounters in its data bases. Researchers from Group Health Cooperative's Center for Health Studies, the University of Washington, and the Fred Hutchinson Cancer Research Center will address these obstacles by pursuing the following specific aims:       1. Informed by results from targeted focus groups, implement a consensus process with key stakeholders to develop recommendations concerning consent, data sharing, and return of research results to subjects.    2. Work together with other network sites to develop a virtual data warehouse (VDW) analogous to that used in the Cancer Research Network, and extend natural language processing (NLP) to pathology, radiology, and clinical chart notes.   3. Develop and test strategies to determine whether each candidate EMR-based phenotype is sufficiently valid to pursue analyses of GWA data, and develop statistical methods that explicitly account for heterogeneous phenotype validity within and between sites.    4. Perform a series of GWA analyses in the GHC biorepository and linked biorepositories. 4a: Alzheimer's disease (AD). 4b: Carotid artery atherosclerotic disease (CAAD). 4c: Complications of statin use, including elevations of CPK and muscle pain.       Through cooperation with other investigators and the NHGRI, this work will facilitate development of policies and procedures to realize the incredible potential of EMR-linked biorepositories for GWA studies to improve understanding, prevention and treatment of chronic diseases and illnesses. Specific GWA research will allow us to explore both etiologic research (AD and CAAD progression) and pharmacogenetics (statin therapy). The implications of this portfolio of research extend far beyond the specific phenotypes we have chosen to emphasize; we expect this work represents the beginning of a large and productive enterprise.              n/a",Development and Use of Network Infrastructure for High-Throughput GWA Studies,7427364,U01HG004610,"['Abbreviations', 'Accounting', 'Address', 'Adult', 'Adverse event', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Blood Pressure', 'Cancer Research Network', 'Carotid Arteries', 'Carotid Artery Diseases', 'Cholesterol', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Data', 'Cognition', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consent', 'Creatinine', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Electronics', 'Elevation', 'Enrollment', 'Environmental Exposure', 'Exposure to', 'Focus Groups', 'Foundations', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genome', 'Genomics', 'Genotype', 'Gold', 'Health', 'Healthcare', 'Healthcare Systems', 'High Density Lipoproteins', 'Individual', 'Inpatients', 'Institutes', 'Knowledge', 'Laboratories', 'Leadership', 'Life', 'Link', 'Malignant Neoplasms', 'Maps', 'Medical', 'Meta-Analysis', 'Methods', 'Myalgia', 'National Cancer Institute', 'Natural Language Processing', 'Neurofibrillary Tangles', 'Numbers', 'Outcome', 'Outpatients', 'Participant', 'Pathology', 'Patients', 'Performance', 'Personal Satisfaction', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Pharmacy facility', 'Phenotype', 'Policy Developments', 'Population', 'Prevention', 'Procedures', 'Process', 'Public Domains', 'Public Health', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Recruitment Activity', 'Research', 'Research Ethics Committees', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sampling', 'Senile Plaques', 'Series', 'Single Nucleotide Polymorphism', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'System', 'Testing', 'Text', 'Thinking', 'Time', 'Universities', 'Ursidae Family', 'Washington', 'Work', 'abstracting', 'base', 'case control', 'cohort', 'cost', 'development policy', 'gene environment interaction', 'genome wide association study', 'health care delivery', 'human disease', 'improved', 'interest', 'member', 'patient registry', 'prescription document', 'prescription procedure', 'prospective', 'success', 'trait', 'virtual']",NHGRI,GROUP HEALTH COOPERATIVE,U01,2007,970601,-0.01590681437000699
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,7076099,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2006,162000,0.011708611822349241
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7147611,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,372106,0.04350625600107967
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7101997,R01LM008799,"['clinical research', 'human', 'language', 'memory disorders', 'model', 'physicians', 'training', 'voice']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,372499,0.01297295608885409
"Automated Detection of Medical Errors DESCRIPTION:    The long-term goal of this proposal is to use the electronic medical record, including narrative text, to understand and encode the process of care for individual patients in order to improve patient safety.   Achieving this goal has the potential to help detect adverse events, and to differentiate medical errors from appropriately tailored care. The specific aims for this proposal are as follows: 1) To understand and encode the process of care for individual patients using data in the electronic medical record, including narrative text.   2) To use a more detailed understanding of patients' processes of care to improve automated adverse event detection. 3) To match processes of care for individual patients against accepted care pathways in order to identify discrepancies. We will capitalize on three core technologies that are in active use by clinicians and researchers in our busy clinical setting: 1) a Web-based clinical information system and its associated clinical data repository (WebCIS), 2) a full medical language parser (MedLEE), and 3) a semi-structured, electronic physician documentation system built by the applicant specifically to support this project (eNote).   Methods will include evaluating the performance (sensitivity, specificity and positive predictive value) of our system, DETER+MINE (DETecting ERrors Mining Narrative Electronically), to model the care process and detect adverse events and pathway deviations. We will utilize explicit process criteria and manual, retrospective chart review as a gold standard.   This research is intended to provide proof of concept that combining natural language processing of clinical narrative with traditional sources of coded data is required for effective screening with automated defection systems. This approach has the potential to impact significantly on our ability to detect and investigate medical errors, adverse medical events, and pathway deviations by reducing reliance on costly and slow manual chart reviews. n/a",Automated Detection of Medical Errors,7124706,K22LM008805,"['automated medical record system', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'health care quality', 'health services research tag', 'human data', 'information retrieval', 'medical records', 'method development', 'patient care management', 'patient safety /medical error']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,K22,2006,135000,0.047828496088746
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,7115855,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,396341,0.05131919882389047
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7019753,G08LM008983,"['clinical research', 'public health']",NLM,SYRACUSE UNIVERSITY,G08,2006,149472,0.0076566232735139576
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,7110256,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,478733,0.06292826181924688
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,7083613,R01EB000362,"['automated medical record system', 'clinical research', 'computer assisted medical decision making', 'data collection methodology /evaluation', 'human data', 'informatics', 'information display', 'information system analysis', 'mathematical model', 'medical records', 'outcomes research', 'patient care management', 'performance']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,535569,0.07342343995885153
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,6898458,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2005,162000,0.011708611822349241
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6892934,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,384538,0.030097867524280453
"Extracting Semantic Knowledge from Clinical Data Sources DESCRIPTION (provided by applicant):    Electronic medical record systems (EMR) contain a wealth of clinical data that is invaluable for biomedical research, but because there are no satisfactory methods to build coherent specialized knowledge bases, which represent the information in free text medical records, data mining and clinical discovery are held back. Medical Reporting Solutions, Inc. has developed advanced technology, which we propose to extend, refine, and test for constructing specialized semantic knowledge bases. These knowledge bases will encode the clinical information in medical reports, and enable automated natural language processing systems for extracting clinical knowledge.      Our research and development uses methods in corpus linguistics and sentential logic to represent the knowledge in free-text medical reports in an efficient, codeable manner. We have created tools to map sentences in a medical domain to unique codeable propositions. Our method for creating knowledge ontologies makes it easy for biomedical researchers to get semantic information at the appropriate level of detail. The knowledge base and mapping tables allow us to analyze medical reports in near real-time. One knowledge base, under development, is derived from hundreds of thousands of reports in the radiology domain, and we intend to analyze other medical domains using the methods we have pioneered.      Our phase one project plan includes further improving our knowledge editing tools, substantially enlarging our semantic knowledge base to cover over 60-70% of the radiology domain, and extensively test our knowledge representation schema against actual radiology reports. We plan to make the knowledge base freely accessible to the biomedical research community, while providing commercial services to codify free text reports found in EMRs. n/a",Extracting Semantic Knowledge from Clinical Data Sources,6988908,R43LM008974,"['automated medical record system', 'clinical research', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'human data', 'informatics', 'information retrieval']",NLM,"LOGICAL SEMANTICS, INC.",R43,2005,100000,0.004961734264580837
"Automated Detection of Medical Errors DESCRIPTION:    The long-term goal of this proposal is to use the electronic medical record, including narrative text, to understand and encode the process of care for individual patients in order to improve patient safety.   Achieving this goal has the potential to help detect adverse events, and to differentiate medical errors from appropriately tailored care. The specific aims for this proposal are as follows: 1) To understand and encode the process of care for individual patients using data in the electronic medical record, including narrative text.   2) To use a more detailed understanding of patients' processes of care to improve automated adverse event detection. 3) To match processes of care for individual patients against accepted care pathways in order to identify discrepancies. We will capitalize on three core technologies that are in active use by clinicians and researchers in our busy clinical setting: 1) a Web-based clinical information system and its associated clinical data repository (WebCIS), 2) a full medical language parser (MedLEE), and 3) a semi-structured, electronic physician documentation system built by the applicant specifically to support this project (eNote).   Methods will include evaluating the performance (sensitivity, specificity and positive predictive value) of our system, DETER+MINE (DETecting ERrors Mining Narrative Electronically), to model the care process and detect adverse events and pathway deviations. We will utilize explicit process criteria and manual, retrospective chart review as a gold standard.   This research is intended to provide proof of concept that combining natural language processing of clinical narrative with traditional sources of coded data is required for effective screening with automated defection systems. This approach has the potential to impact significantly on our ability to detect and investigate medical errors, adverse medical events, and pathway deviations by reducing reliance on costly and slow manual chart reviews. n/a",Automated Detection of Medical Errors,6958394,K22LM008805,"['automated medical record system', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'health care quality', 'health services research tag', 'human data', 'information retrieval', 'medical records', 'method development', 'patient care management', 'patient safety /medical error']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,K22,2005,134800,0.047828496088746
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6948251,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2005,399327,0.05131919882389047
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6912634,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,478937,0.06292826181924688
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,6917854,R01EB000362,"['automated medical record system', 'clinical research', 'computer assisted medical decision making', 'data collection methodology /evaluation', 'human data', 'informatics', 'information display', 'information system analysis', 'mathematical model', 'medical records', 'outcomes research', 'patient care management', 'performance']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2005,593264,0.07342343995885153
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,6768325,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2004,135000,0.011708611822349241
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6754395,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,380979,0.030097867524280453
"Statistical NLP Analysis of Cross-discipline Clinical Text DESCRIPTION (provided by applicant):     An emerging trend in computational linguistics is melding natural language processing (NLP) and machine learning (ML) to help computers make sense of human-generated free text. The blending of these disciplines is relatively rare in biomedical informatics. Past medical NLP/ML research work is biased heavily towards linguistic methods that attempt to reason about grammar and syntax aided by a domain-focal knowledge base (e.g., one for radiology or one for clinical pathology). The aim of the work proposed here takes a different tack: exploring the utility of a statistical approach to clinical NLP, one augmented by machine learning and concentrating on general progress notes from across multiple clinical domains. The specific clinical goal will be to identify adverse drug events described implicitly or explicitly in inpatient progress notes. Rather than relying on a narrow domain focus to provide enough context restriction to make text interpretation tractable, this approach will use statistical patterns in note author information (e.g., profession, note type, treating ward) and patient information (e.g., admit diagnosis, procedures performed, temporal note relationships) for context restriction. The research component of this proposal is divided into two categories: three small-scale projects designed to rapidly hone new skills developed under the training component, and a large-scale project that assesses the feasibility of cross-discipline clinical text analysis. n/a",Statistical NLP Analysis of Cross-discipline Clinical Text,6836781,F38LM008478,"['bioinformatics', 'clinical research', 'computational biology', 'human data', 'library', 'mathematical model', 'public health', 'statistics /biometry']",NLM,UNIVERSITY OF UTAH,F38,2004,94545,0.01777796305484754
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6802269,R01EB002247,"['anatomy', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer assisted patient care', 'computer data analysis', 'computer graphics /printing', 'computer system design /evaluation', 'diagnosis quality /standard', 'health care quality', 'health care referral /consultation', 'human data', 'image enhancement', 'image processing', 'magnetic resonance imaging', 'musculoskeletal disorder', 'nervous system disorder', 'statistics /biometry', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,387825,0.05131919882389047
"Using Narrative Data to Enrich the Online Medical Record  DESCRIPTION (provided by applicant):    Narrative information is vital to health care, because it enables physicians to synthesize the raw facts and provide a context and interpretation for them.  Electronic medical record systems contain a wealth of clinical data, but typically lack the clinical narrative found in paper records, e.g., the patient history and progress notes.  Numerous barriers prevent the timely acquisition of narrative data, and most computer systems are unable to use such information productively.  Current approaches offer a tradeoff, capture of rich clinical data that lacks structure (using transcription services or speech technology), versus entry of structured data that lacks flexibility and expressiveness (using template systems).  Natural language processing can integrate these approaches by allowing physicians full freedom of expression while producing structured documents that preserve the richness and enable further computer processing.   This proposal seeks to capture and structure narrative in the online medical record in order to improve entry time, completeness, information content and consistency of clinical documentation.  The specific aims of this proposal are:  1) Maintain the continuity of the medical record; a lengthy medical record requires significant time to review and digest.  Many facts from past narratives remain true in the present or persist with minor changes.  By automatically bringing these facts forward into the current narrative, the system can reduce the time to enter the document, and improve the completeness of documentation by maintaining continuity of what is known about a patient; 2) Integrate the medical record:  Electronic medical records contain a vast amount of data.  However, most of these data are raw facts.  By helping the physician to connect, interpret and summarize these facts, the system can improve the usefulness of the information in the record, and reduce the time to enter documents by performing some syntheses automatically; and 3) Harmonize the medical record; the multidisciplinary nature of health care creates the potential for the differing perspectives and interpretations in the medical record, and even contradictions.  By bringing possible discrepancies to the attention of the physician, the system can help resolve the inconsistencies.     n/a",Using Narrative Data to Enrich the Online Medical Record,6802698,R01LM007268,"['automated medical record system', 'clinical research', 'computer data analysis', 'data collection methodology /evaluation', 'human data', 'information systems', 'medical records', 'online computer', 'primary care physician', 'vocabulary']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,437194,0.05963512850461216
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6781785,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,468590,0.06292826181924688
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,6749459,R01EB000362,"['automated medical record system', 'clinical research', 'computer assisted medical decision making', 'data collection methodology /evaluation', 'human data', 'informatics', 'information display', 'information system analysis', 'mathematical model', 'medical records', 'outcomes research', 'patient care management', 'performance']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,594553,0.07342343995885153
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6717704,P01EB000216,"['automated medical record system', 'health care facility information system', 'radiology', 'telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2004,1723576,0.05340515574947115
"UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE   DESCRIPTION (adapted from the Abstract):                                             With the explosion of medical information accessible via the Internet, there         is a growing need for development of better access to the online medical             literature databases through user-friendly systems and interface.  The               proliferation of online information and the diversity of interfaces to data          collections has led to a medical information gap between medical researchers         and the accessibility of medical literature databases.  Users who need access        to such information must visit a variety of sources, which can be both               excessively time consuming and potentially dangerous if the information is           needed for treatment decisions.  In addition, information generated by using         existing search engines is often too general or inaccurate.  Particularly            frustrating is that simple queries can result in an excessive number of              documents retrieved - too many to search through to determine which are and          which are not relevant.                                                                                                                                                   The goal of this research is to extend a bridge across the medical information       gap by creating easy-to-use interfaces to medical literature databases based         on UMLS-enhanced Semantic Parsing and Personalized Medical Agent (PMA):                                                                                                   (1)  UMLS-enhanced Semantic Parsing: Our first goal will be to combine noun          phrasing and co-occurrence analysis techniques recently developed by The             University of Arizona Artificial Intelligence Lab (AI Lab) for the NSF-funded        Illinois Digital Library Initiative (DLI) project with existing components           found in the Unified Medical Language System (UMLS) developed by NLM.                                                                                                     (2)  Personalized Medical Agent: The second goal will be to develop a dynamic,       intelligent medical agent interface to assist searchers in effortlessly              locating documents and summarizing topics in the documents.  The interface is        particularly suited for busy physicians.                                                                                                                                  n/a",UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE,6637557,R01LM006919,"['abstracting', ' artificial intelligence', ' cancer information system', ' computer system design /evaluation', ' human data', ' information retrieval', ' information system analysis', ' literature citation', ' semantics', ' vocabulary development for information system']",NLM,UNIVERSITY OF ARIZONA,R01,2003,148818,0.02294140317213784
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6630735,R01LM006910,"['artificial intelligence', ' classification', ' clinical research', ' computer assisted medical decision making', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' health care facility information system', ' human data', ' information system analysis', ' method development', ' vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,377617,0.030097867524280453
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6657426,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2003,369494,0.04529202862880494
"Using Narrative Data to Enrich the Online Medical Record  DESCRIPTION (provided by applicant):    Narrative information is vital to health care, because it enables physicians to synthesize the raw facts and provide a context and interpretation for them.  Electronic medical record systems contain a wealth of clinical data, but typically lack the clinical narrative found in paper records, e.g., the patient history and progress notes.  Numerous barriers prevent the timely acquisition of narrative data, and most computer systems are unable to use such information productively.  Current approaches offer a tradeoff, capture of rich clinical data that lacks structure (using transcription services or speech technology), versus entry of structured data that lacks flexibility and expressiveness (using template systems).  Natural language processing can integrate these approaches by allowing physicians full freedom of expression while producing structured documents that preserve the richness and enable further computer processing.   This proposal seeks to capture and structure narrative in the online medical record in order to improve entry time, completeness, information content and consistency of clinical documentation.  The specific aims of this proposal are:  1) Maintain the continuity of the medical record; a lengthy medical record requires significant time to review and digest.  Many facts from past narratives remain true in the present or persist with minor changes.  By automatically bringing these facts forward into the current narrative, the system can reduce the time to enter the document, and improve the completeness of documentation by maintaining continuity of what is known about a patient; 2) Integrate the medical record:  Electronic medical records contain a vast amount of data.  However, most of these data are raw facts.  By helping the physician to connect, interpret and summarize these facts, the system can improve the usefulness of the information in the record, and reduce the time to enter documents by performing some syntheses automatically; and 3) Harmonize the medical record; the multidisciplinary nature of health care creates the potential for the differing perspectives and interpretations in the medical record, and even contradictions.  By bringing possible discrepancies to the attention of the physician, the system can help resolve the inconsistencies.     n/a",Using Narrative Data to Enrich the Online Medical Record,6665504,R01LM007268,"['automated medical record system', ' clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' human data', ' information systems', ' medical records', ' online computer', ' primary care physician', ' vocabulary']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,424735,0.05963512850461216
"A Context-Sensitive Teleconsultation Infrastructure DESCRIPTION (provided by applicant):  Consultation with appropriate specialists improves the quality of healthcare, particularly in patients with complicated cases or chronic illnesses. And for the majority of such patients, specialists use imaging studies (e.g., MR, CT) to objectively document the disease process (e.g., a cancer patient on chemotherapy). However, specialists are generally not available in all communities, tending to be concentrated in academic/specialty centers. Thus, to facilitate the routine use of teleconsultations for patients when specialists are not locally present: 1) the images captured to document the patient's condition must be incorporated into the medical record to enable proper review; and 2) the remote consultant should only receive pertinent parts of the medical record to streamline the consultation process. This proposal is focused on developing and testing a ""context-sensitive"" telehealth infrastructure based on: 1) automated incorporation of clinical context (patient presentation and referring physician hypothesis) to focus the consultation process; 2) a knowledge-base derived from data mining of natural language processing (NLP) results, mapping patient presentation to select an appropriate imaging study based on anatomical region and imaging parameters; and 3) automated selection of key anatomical structures in the acquired imaging study through the use of a contrast-customizable atlas and rigid body/deformable registration algorithms. Collectively, these technologies will allow context-sensitive, automated summarization of medical records for telehealth in a real-world environment. The proposed technologies will be implemented for neurological and musculoskeletal domains, two areas that are MR imaging intensive.      Technical evaluation will be performed with experts serving as the reference standard and will focus on measuring: 1) the accuracy of the corpus based, NLP-guided knowledge-base in selecting relevant anatomical structures; and 2) the accuracy of anatomical structure delineation using the customizable atlas registration methods. Clinical evaluation will be conducted in a real-world teleconsultation environment in a before/after study design using two performance metrics: 1) the time required for consultations; and 2) the effect on the quality of the consultations. n/a",A Context-Sensitive Teleconsultation Infrastructure,6725819,R01EB002247,"['anatomy', ' clinical research', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer assisted patient care', ' computer data analysis', ' computer graphics /printing', ' computer system design /evaluation', ' diagnosis quality /standard', ' health care quality', ' health care referral /consultation', ' human data', ' image enhancement', ' image processing', ' magnetic resonance imaging', ' musculoskeletal disorder', ' nervous system disorder', ' statistics /biometry', ' telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,383268,0.05131919882389047
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6558664,R01LM007659,"['cancer information system', ' clinical research', ' data collection', ' health science research', ' human data', ' informatics', ' library', ' medical records', ' molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,464049,0.06292826181924688
"Engineering Approach to Individually Tailored Medicine DESCRIPTION (provided by applicant):    Technological advances in medicine, particularly imaging, have resulted in early detection, objective documentation, and overall better insight into medical conditions. These advances, however, have also led to an increasingly complex medical record. Physicians now spend a significant portion of their time retrieving, structuring, organizing, and analyzing patient data, inaccurately and inefficiently: current information management systems in clinical medicine do not adequately support these functions, critical to the real-world practice of evidence-based medicine. Objective evidence, tailored to an individual patient, must be readily available to physicians as part of routine practice if true evidence-based medical practice is to become a reality. This proposal details the development and evaluation of several innovative technologies, providing solutions for the information management problems faced by physicians: 1) a distributed XML-based peer-to-peer medical record architecture, to enable portability and accessibility of patient information, regardless of geographical location; 2) a natural language processing (NLP) system for free-text medical reports, to automatically structure and characterize the contents of medical documents; 3) a phenomenon-centric data model, which supports the problem-solving tasks of the physician through explicit linking of objective findings (e.g., images, lab values) to medical problems; and 4) a time-based, problem-centric, context-sensitive visualization of the medical record, supporting a ""gestalt"" view of the patient, with access to detailed patient data when needed. Together, these technologies will form a comprehensive system facilitating evidence-based medicine in a real-world environment. System evaluation will proceed in two parts. Technical evaluation focuses on each of the proposed technologies individually, gauging classical performance metrics: scalability of the distributed medical record; NLP precision/recall; expressibility/comprehensibility of the data model; and the usability of the new medical record user interface. Clinical evaluation will follow a time series study design (""off-on-off""), with implementation of the entire system in a real-world clinical environment, the UCLA Clark Urological Center. Clinical evaluation will measure the effectiveness of the system as a whole on intermediate outcomes (process of care) including the number of visits, number of procedures performed, and time to final diagnosis (disposition), as well as the impact on physician efficiency (time required to gather information and review charts). n/a",Engineering Approach to Individually Tailored Medicine,6678913,R01EB000362,"['automated medical record system', ' clinical research', ' computer assisted medical decision making', ' data collection methodology /evaluation', ' human data', ' informatics', ' information display', ' information system analysis', ' mathematical model', ' medical records', ' outcomes research', ' patient care management', ' performance']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,572597,0.07342343995885153
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6682850,P01EB000216,"['automated medical record system', ' health care facility information system', ' radiology', ' telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2003,1645392,0.05340515574947115
"UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE   DESCRIPTION (adapted from the Abstract):                                             With the explosion of medical information accessible via the Internet, there         is a growing need for development of better access to the online medical             literature databases through user-friendly systems and interface.  The               proliferation of online information and the diversity of interfaces to data          collections has led to a medical information gap between medical researchers         and the accessibility of medical literature databases.  Users who need access        to such information must visit a variety of sources, which can be both               excessively time consuming and potentially dangerous if the information is           needed for treatment decisions.  In addition, information generated by using         existing search engines is often too general or inaccurate.  Particularly            frustrating is that simple queries can result in an excessive number of              documents retrieved - too many to search through to determine which are and          which are not relevant.                                                                                                                                                   The goal of this research is to extend a bridge across the medical information       gap by creating easy-to-use interfaces to medical literature databases based         on UMLS-enhanced Semantic Parsing and Personalized Medical Agent (PMA):                                                                                                   (1)  UMLS-enhanced Semantic Parsing: Our first goal will be to combine noun          phrasing and co-occurrence analysis techniques recently developed by The             University of Arizona Artificial Intelligence Lab (AI Lab) for the NSF-funded        Illinois Digital Library Initiative (DLI) project with existing components           found in the Unified Medical Language System (UMLS) developed by NLM.                                                                                                     (2)  Personalized Medical Agent: The second goal will be to develop a dynamic,       intelligent medical agent interface to assist searchers in effortlessly              locating documents and summarizing topics in the documents.  The interface is        particularly suited for busy physicians.                                                                                                                                  n/a",UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE,6530779,R01LM006919,"['abstracting', ' artificial intelligence', ' cancer information system', ' computer system design /evaluation', ' human data', ' information retrieval', ' information system analysis', ' literature citation', ' semantics', ' vocabulary development for information system']",NLM,UNIVERSITY OF ARIZONA,R01,2002,144484,0.02294140317213784
"INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING DESCRIPTION (Taken from application abstract):  This proposed study will         replicate and extend methodology used in earlier studies and will use            extensive clinical data repositories, informatics tools, and expert              practitioners for perinatal medical knowledge building.                                                                                                           Clinical Data Repository:  Duke University's Medical Center (DUMC) TMR (The      Medical Record) data repository will be used for this study, and contains        45,922 electronic medical records for both low and high-risk pregnant women      (and their infants) who have received prenatal care at DUMC, and its             affiliated regional clinics, between 1/1/86 and 12/3l/95.  Each patient's        electronic data is used for clinical patient care and contains a potential       4000 variables per record.  This volume of data requires new approaches for      data analysis and medical decision support, since human information              processing limitations become quickly overloaded by both an individual           patient s data and the aggregate information collected for the perinatal         patient population.                                                                                                                                               lnformatics Tools:  Informatics techniques for knowledge acquisition and         data mining will use machine learning programs, statistical analysis, and        domain expert input to articulate relationships between the data and             perinatal patent outcomes.  The goal is to provide decision support for          perinatal care providers to accurately identify patients at risk and assist      them with modifiable preterm birth ask factors.  An expert system will use       data-generated and verified knowledge bases to test its predictive validity      when new patient cases are induced to the expert system.  Earlier studies        found 53-90% predictive accuracies for an expert system prototype, as            compared to 17-38% accuracies, reported in the literature, using current         manual techniques.  Mapping the expert system's knowledge base terms to          medical library resources will be explored for additional decision support.                                                                                       Expert Practitioner:  The perinatal expert panel will consist of the             Principal Investigator, a Board Certified OB-Gyn Physician, and a certified      Perinatal RN.  Each of the panel members has more than 20 years of perinatal     experience.  Participating informatics experts are known, both nationally        and internationally for their expertise in the field of Medical Informatics.      n/a",INFORMATICS TOOLS & MEDICAL PERINATAL KNOWLEDGE BUILDING,6577458,R01LM006488,"['artificial intelligence', ' computer system design /evaluation', ' human data', ' information systems', ' prenatal care']",NLM,DUKE UNIVERSITY,R01,2002,382114,0.024435778981172922
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6528316,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2002,360015,0.04529202862880494
"Using Narrative Data to Enrich the Online Medical Record  DESCRIPTION (provided by applicant):    Narrative information is vital to health care, because it enables physicians to synthesize the raw facts and provide a context and interpretation for them.  Electronic medical record systems contain a wealth of clinical data, but typically lack the clinical narrative found in paper records, e.g., the patient history and progress notes.  Numerous barriers prevent the timely acquisition of narrative data, and most computer systems are unable to use such information productively.  Current approaches offer a tradeoff, capture of rich clinical data that lacks structure (using transcription services or speech technology), versus entry of structured data that lacks flexibility and expressiveness (using template systems).  Natural language processing can integrate these approaches by allowing physicians full freedom of expression while producing structured documents that preserve the richness and enable further computer processing.   This proposal seeks to capture and structure narrative in the online medical record in order to improve entry time, completeness, information content and consistency of clinical documentation.  The specific aims of this proposal are:  1) Maintain the continuity of the medical record; a lengthy medical record requires significant time to review and digest.  Many facts from past narratives remain true in the present or persist with minor changes.  By automatically bringing these facts forward into the current narrative, the system can reduce the time to enter the document, and improve the completeness of documentation by maintaining continuity of what is known about a patient; 2) Integrate the medical record:  Electronic medical records contain a vast amount of data.  However, most of these data are raw facts.  By helping the physician to connect, interpret and summarize these facts, the system can improve the usefulness of the information in the record, and reduce the time to enter documents by performing some syntheses automatically; and 3) Harmonize the medical record; the multidisciplinary nature of health care creates the potential for the differing perspectives and interpretations in the medical record, and even contradictions.  By bringing possible discrepancies to the attention of the physician, the system can help resolve the inconsistencies.     n/a",Using Narrative Data to Enrich the Online Medical Record,6535939,R01LM007268,"['automated medical record system', ' clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' human data', ' information systems', ' medical records', ' online computer', ' primary care physician', ' vocabulary']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2002,395391,0.05963512850461216
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6528412,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2002,325555,-0.016142631763827034
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING   DESCRIPTION (adapted from the Abstract):                                              The long-term aim of this project is to use natural language processing (NLP)        to help realize the full potential of the Electronic Medical Record (EMR).           Our research involves advanced NLP techniques to: 1) extract and encode              information in textual reports; 2) map terms to an authoritative vocabulary;         3) obtain comprehensive domain coverage based on the processing of domain            corpora; and 4) facilitate vocabulary development by providing visualization         tools using the Extensible Markup Language (XML).  It has already been               demonstrated that MedLEE, the NLP system we developed, accurately extracts and       codifies information in the EMR.  This current project builds upon our               experience with MedLEE and uses it to accomplish the latter three goals              concerning vocabulary development and standardization.                                                                                                                    More specifically, MedLEE will be used to map source terms to UMLS concepts.         MedLEE will process and structure the source terms and candidate UMLS                concepts.  Suitable matches will be found based on structural similarity             between components of the source term and candidate concepts.  This should           enhance current methods because knowledge of the type of modifiers that match        should improve the quality of the matches.  We will also use MedLEE to process       a large corpus and generate structured output in XML format.  Statistics based       on the structured output will be computed, and then clinically relevant              composite terms will be detected based on frequencies of the structures              containing the more elementary terms.  Our method differs from other discovery       methods because we use NLP techniques that identify semantic modifiers and           complex relations even if the terms are distant from each other, whereas other       methods use statistical co-occurrence data based on adjacency.  The individual       XML structures and statistics will be combined and mapped into a single XML          tree.  It will be possible to visualize the tree and frequencies using an XML        tree viewer, to navigate the tree, to manipulate the tree, and to reorganize         the tree according to different axes (i.e., procedure, body location,                finding).                                                                                                                                                                 The use of a sophisticated NLP system, such as MedLEE, is ideal as a                 foundation for our proposed work in vocabulary development and                       standardization; medical terminology is an integral part of medical language         and a state of the art NLP system is especially equipped to handle the               inherent complexities of language. n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,6490773,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,2002,288252,0.04138871297966476
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6512665,P01EB000216,"['automated medical record system', ' health care facility information system', ' radiology', ' telemedicine']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2002,2120168,0.05340515574947115
"UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE   DESCRIPTION (adapted from the Abstract):                                             With the explosion of medical information accessible via the Internet, there         is a growing need for development of better access to the online medical             literature databases through user-friendly systems and interface.  The               proliferation of online information and the diversity of interfaces to data          collections has led to a medical information gap between medical researchers         and the accessibility of medical literature databases.  Users who need access        to such information must visit a variety of sources, which can be both               excessively time consuming and potentially dangerous if the information is           needed for treatment decisions.  In addition, information generated by using         existing search engines is often too general or inaccurate.  Particularly            frustrating is that simple queries can result in an excessive number of              documents retrieved - too many to search through to determine which are and          which are not relevant.                                                                                                                                                   The goal of this research is to extend a bridge across the medical information       gap by creating easy-to-use interfaces to medical literature databases based         on UMLS-enhanced Semantic Parsing and Personalized Medical Agent (PMA):                                                                                                   (1)  UMLS-enhanced Semantic Parsing: Our first goal will be to combine noun          phrasing and co-occurrence analysis techniques recently developed by The             University of Arizona Artificial Intelligence Lab (AI Lab) for the NSF-funded        Illinois Digital Library Initiative (DLI) project with existing components           found in the Unified Medical Language System (UMLS) developed by NLM.                                                                                                     (2)  Personalized Medical Agent: The second goal will be to develop a dynamic,       intelligent medical agent interface to assist searchers in effortlessly              locating documents and summarizing topics in the documents.  The interface is        particularly suited for busy physicians.                                                                                                                                  n/a",UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE,6258188,R01LM006919,"['abstracting', ' artificial intelligence', ' cancer information system', ' computer system design /evaluation', ' human data', ' information retrieval', ' information system analysis', ' literature citation', ' semantics', ' vocabulary development for information system']",NLM,UNIVERSITY OF ARIZONA,R01,2001,140274,0.02294140317213784
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6448720,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2001,356099,0.04529202862880494
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6404288,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2001,673495,-0.016142631763827034
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING   DESCRIPTION (adapted from the Abstract):                                              The long-term aim of this project is to use natural language processing (NLP)        to help realize the full potential of the Electronic Medical Record (EMR).           Our research involves advanced NLP techniques to: 1) extract and encode              information in textual reports; 2) map terms to an authoritative vocabulary;         3) obtain comprehensive domain coverage based on the processing of domain            corpora; and 4) facilitate vocabulary development by providing visualization         tools using the Extensible Markup Language (XML).  It has already been               demonstrated that MedLEE, the NLP system we developed, accurately extracts and       codifies information in the EMR.  This current project builds upon our               experience with MedLEE and uses it to accomplish the latter three goals              concerning vocabulary development and standardization.                                                                                                                    More specifically, MedLEE will be used to map source terms to UMLS concepts.         MedLEE will process and structure the source terms and candidate UMLS                concepts.  Suitable matches will be found based on structural similarity             between components of the source term and candidate concepts.  This should           enhance current methods because knowledge of the type of modifiers that match        should improve the quality of the matches.  We will also use MedLEE to process       a large corpus and generate structured output in XML format.  Statistics based       on the structured output will be computed, and then clinically relevant              composite terms will be detected based on frequencies of the structures              containing the more elementary terms.  Our method differs from other discovery       methods because we use NLP techniques that identify semantic modifiers and           complex relations even if the terms are distant from each other, whereas other       methods use statistical co-occurrence data based on adjacency.  The individual       XML structures and statistics will be combined and mapped into a single XML          tree.  It will be possible to visualize the tree and frequencies using an XML        tree viewer, to navigate the tree, to manipulate the tree, and to reorganize         the tree according to different axes (i.e., procedure, body location,                finding).                                                                                                                                                                 The use of a sophisticated NLP system, such as MedLEE, is ideal as a                 foundation for our proposed work in vocabulary development and                       standardization; medical terminology is an integral part of medical language         and a state of the art NLP system is especially equipped to handle the               inherent complexities of language. n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,6095940,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,2001,303860,0.04138871297966476
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6375859,P01CA051198,"['automated medical record system', ' health care facility information system', ' radiology', ' telemedicine']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2001,2071652,0.05340515574947115
"IMIA WG6 CONFERENCE The basic science of representing patient events, findings, interventions, and outcomes in a semantically consistent and logically reproducible way is medical concept representation.  It embodies principles of linguistics, logic, computer science, cognition, biology and clinical medicine to undertake this highly multidisciplinary activity. Much of this work is undertaken in experimental settings, which hypothesize practical extensions to existing models, and test their utility against standardized retrieval sets or clinical usability environments. The proposed conference intends to continue the tradition of the International Medical Informatics Association (IMIA), Working Group 6 on Medical Concept Representation, to provide a forum for the academic discussion of problems, issues, theories, and applications of natural language processing, knowledge representation, terminology development, and concept coordination to biomedicine and healthcare.  the proposed tracks at this time are: 1. Natural Language Processing  2. Clinical Classifications 3. Cognitive Evaluations  4. Terminology Models  5. Maintenance and Uptake Strategies.  n/a",IMIA WG6 CONFERENCE,6027283,R13LM006899,"['informatics', ' international health /scientific organization', ' meeting /conference /symposium', ' travel']",NLM,MAYO CLINIC ROCHESTER,R13,2000,20000,-0.0014109810837565932
"PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE The broad, tong-term objective of this Program Project Grant is to develop an effective imaging-based information and health care delivery system to support clinical practice, research, and education. The specific aims of the grant are to: (1) evolve PACS into an effective infrastructure that promotes the objectification of subjective patient clinical symptoms, (2) develop methods for improving the characterization of medical data through structured data collection, natural language processing of medical reports (NLP) and parametric summarization for medical images, (3) provide flexible, patient -specific presentation methods of medical images, timelines, and structured medical data. The objectification, intelligent access, and flexible presentation of medical data provide better information, which will facilitate the evidence-based practice of medicine and enhance research and evaluation. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently selected imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NP for text of parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Five integrated projects employ novel techniques to address specific elements of the system. Intelligently secreted imaging protocols are used to objectify patient symptoms. Well-defined information units capture and structure diverse forms of data, whether directly or indirectly through NLP for text or parametric summarization for images. Patient medical records are correlated with medical literature by content. Timelines organize the data into a format that allow medical events, their dependencies, and conditional trends to be easily visualized (Project 3). Scenario-based proxies provide up-to-date access to relevant medical information. Relaxation broadens queries to medical information when exact matches are not found. Software toolkits and user models enable user-, and domain-, and task-specific customizations. The hardware independent architecture will facilitate access to the system across different platforms and software subsystems. Together, they form a unique infrastructure that provides broad and intelligently customized access to well-defined structured data and up-to-date literature. This, in addition to patient-specific relevant data, expert opinion, and similar cases with known outcome, will promote the evidence-based practice of medicine. Evaluation of the impact of the proposed system will focus on technical measures; process of care; and patient and physician satisfaction. The evaluation will also explore the relationship between process changes and specific outcomes, particularly short-term health related quality of life. Although a formal cost-effectiveness study is not proposed, the foundation is laid for these measurements when these PACs technologies mature. These measurements will be facilitated by recording resource utilization, determining of imaging-based episodes of care, and counter- specific information related to a chief complaint.  n/a",PACS INFRASTRUCTURE TO SUPPORT-BASED MEDICAL PRACTICE,6094628,P01CA051198,"['automated medical record system', ' health care facility information system', ' radiology', ' telemedicine']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,P01,2000,1926078,0.05340515574947115
"A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications PROJECT SUMMARY/ABSTRACT  In radiology practices, timely and accurate formulation of reports is closely linked to patient satisfaction, physician productivity, and reimbursement. While the American College of Radiology and the Radiological Soci- ety of North America have recommended implementation of structured reporting to facilitate clear and consistent communication between radiologists and referring clinicians, cumbersome nature of current structured reporting systems made them unpopular amongst their users. Recently, the emerging techniques of deep learning have been widely and successfully applied in many different natural language processing tasks (NLP). However, when adopted in a certain speciﬁc domain, such as radiology, these techniques should be combined with extensive domain knowledge to improve efﬁciency and accuracy. There is, therefore, a critical need to take advantage of clinical NLP and deep learning to fundamentally change the radiology reporting. The long-term goal in this appli- cation is to improve the form, content, and quality of radiology reports and to facilitate rapid generation of radiol- ogy reports with consistent organization and standardized texts. The overall objective is to use radiology-speciﬁc ontology, NLP and computer vision techniques, and deep learning to construct a radiology-speciﬁc knowledge graph, which will then be used to build a reporting system that can assist radiologists to quickly generate struc- tured and standardized text reports. The rationale for this project is that through integration of new clinical NLP technologies, radiology-speciﬁc knowledge graphs, and development of new reporting system, we can build au- tomatous systems with a higher-level understanding of the radiological world. The speciﬁc aims of this project are to: (1) recognize and normalize named entities in radiology reports; (2) construct a radiology-speciﬁc knowledge graph from free-text and images; and (3) build a reporting system that can dynamically adjust templates based on radiologists' prior entries. The research proposed in this application is innovative, in the applicant's opinion, because it combines deep learning, NLP techniques, and domain knowledge in a single framework to construct comprehensive and accurate knowledge graphs that will enhance the workﬂow of the current reporting systems. The proposed research is signiﬁcant because a novel reporting system can expedite radiologists' workﬂow and acquire well-annotated datasets that facilitate machine learning and data science. To develop such a method, the candidate, Dr. Yifan Peng, requires additional training and mentoring in clinical NLP and radiology. During the K99 phase, Dr. Peng will conduct this research as a research fellow at the National Center for Biotechnology Information. He will be mentored by Dr. Zhiyong Lu, a leading text mining and deep learning researcher, and co- mentored by Dr. Ronald M. Summers, a leading radiologist and clinical informatics researcher. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Peng to achieve the career goals of becoming an independent investigator and leader in the study of clinical NLP. PROJECT NARRATIVE The proposed research is relevant to public health because it entails a new strategy to construct a radiology- speciﬁc knowledge graph to facilitate the development of a new reporting system that enables rapid generation of structured radiology reports. The proposed knowledge graph and reporting system will contribute to advancement in understanding of the radiological world, and promise to enhance clinical communication and patient-centric care. Thus, the proposed research is relevant to the part of the NLM's mission that pertains to applying deep knowledge of clinical terminology and natural language processing to improve clinical data science and health services.",A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications,10197509,R00LM013001,"['Address', 'Adopted', 'American College of Radiology', 'Award', 'Biotechnology', 'Caring', 'Client satisfaction', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Communication', 'Complex', 'Computer Vision Systems', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Formulation', 'Generations', 'Goals', 'Health Services', 'Hospitals', 'Hybrids', 'Image', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Mission', 'Modeling', 'Mus', 'Names', 'Natural Language Processing', 'Nature', 'Nomenclature', 'North America', 'Ontology', 'Outcome', 'Pathway interactions', 'Patients', 'Phase', 'Physicians', 'Picture Archiving and Communication System', 'Process', 'Productivity', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resort', 'Societies', 'Standardization', 'Structure', 'System', 'Systems Development', 'Techniques', 'Technology', 'Terminology', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Voice', 'Writing', 'base', 'career', 'career development', 'convolutional neural network', 'deep learning', 'deep neural network', 'impression', 'improved', 'innovation', 'knowledge graph', 'lexical', 'long short term memory', 'neural network', 'neural network architecture', 'novel', 'radiologist', 'repository', 'response', 'syntax', 'text searching']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,R00,2020,236549,0.026872890951766266
"CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare Project Summary Wide adoption of electronic health records (EHRs) has led to huge clinical databases, which enable the rapid growth of healthcare analytics market. One particular challenge for analyzing EHRs data is that much detailed patient information is embedded in clinical documents and not directly available for downstream analysis. Therefore, clinical natural language processing (NLP) technologies, which can unlock information embedded in clinical narratives, have received great attention, with an estimated global market of $2.65 billion by 2021 . In our previous work, we have developed CLAMP (Clinical Language Annotation, Modeling, and Processing), a clinical NLP tool with demonstrated superior performance through multiple international NLP challenges and a large user community (over 1,500 downloads by users from over 700 organizations). Commercialization of CLAMP by Melax Technologies Inc. has been successful (i.e., with a dozen licensed customers now); but it also reveals its limitations as a desktop application in the Cloud era. Therefore, we propose to extend CLAMP to a new Cloud- based, Service-oriented platform (called CLAMP-CS), which will address the identified challenges by: 1) improving clinical NLP performance and reducing annotation cost by leveraging the state-of-the-art algorithms such as deep learning, active learning and transfer learning and making them accessible to less experienced users; 2) following new service-oriented architectures to make CLAMP-CS available via SaaS and PaaS, ready for Cloud-based development and deployment; and 3) improving CLAMP-CS interoperability with downstream applications following two widely used standard representations: HL7 FHIR (Fast Healthcare Interoperability Resources) and OMOP CMD (Common Data Model), to support the use cases in clinical operations and research respectively. With these advanced features, we believe CLAMP-CS will be a leading clinical NLP system in the market and it will accelerate the adoption of NLP technology for diverse healthcare applications and clinical/translational research. Project Narrative In this study, we plan to develop a new clinical natural language processing (NLP) tool based on the existing widely used CLAMP (Clinical Language Annotation, Modeling, and Processing) system, to support enterprise development and deployment of NLP solutions in healthcare. We believe that the new generation of Cloud- based, service-oriented NLP tool will accelerate the adoption of NLP technology for diverse healthcare applications and clinical and translational research.","CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare",10011177,R44TR003254,"['Active Learning', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Architecture', 'Attention', 'Belief', 'Clinical', 'Clinical Research', 'Closure by clamp', 'Cloud Computing', 'Communities', 'Custom', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Generations', 'Grant', 'Growth', 'Health Sciences', 'Healthcare', 'Hospital Administration', 'International', 'Language', 'Licensing', 'Machine Learning', 'Medical', 'Modeling', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Operations Research', 'Output', 'Patients', 'Performance', 'Psychological Transfer', 'Records', 'Research', 'Services', 'System', 'Technology', 'Texas', 'Time', 'Translational Research', 'Universities', 'Work', 'active method', 'base', 'clinical application', 'clinical database', 'cloud based', 'commercialization', 'cost', 'data modeling', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'insight', 'interoperability', 'language training', 'learning algorithm', 'model building', 'next generation', 'novel', 'prevent', 'rapid growth', 'tool', 'user-friendly', 'web app']",NCATS,"MELAX TECHNOLOGIES, INC.",R44,2020,503546,0.03182177113131415
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9986899,R01LM012918,"['Adult', 'Adverse drug event', 'Algorithms', 'Apache', 'Area', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Information Retrieval', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'adaptation algorithm', 'base', 'case finding', 'improved', 'machine learning method', 'malignant breast neoplasm', 'method development', 'natural language', 'neural network', 'new technology', 'news', 'novel', 'open source', 'point of care', 'side effect', 'social media', 'software systems', 'statistics', 'structured data', 'supervised learning', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2020,383874,0.031313564422697386
"Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment Project Summary The purpose of this proposal is to develop two strategies, natural language processing (NLP) and automated speech analysis (ASA), to enable automated identification of patients with cognitive impairment (CI), from mild cognitive impairment (MCI) to Alzheimer’s Disease Related Dementias (ADRD) in clinical settings. The number of older adults in the United States with MCI and ADRD is increasing and yet the ability of clinicians and researchers to identify them at scale has advanced little over recent decades and screening with clinical assessments is done inconsistently. Alternative strategies using available data, like analysis of diagnostic codes in the clinical record or insurance claims, have very low sensitivity. NLP and ASA used with machine learning are technologies that could greatly increase ability to detect MCI and ADRD in clinical contexts. NLP automatically converts text in the electronic health record (EHR) into structured concepts suitable for analysis. Thus, clinicians’ documentation of signs and symptoms or orders of tests and services that reflect or address cognitive limitations can be efficiently captured, possibly long before the clinician uses an ADRD-related diagnostic code. ASA directly measures cognition by recognizing different features of cognition captured in speech. Extracting features through both NLP and ASA could thus provide a unique measure of cognition and its impact on the individual and their caregivers. Early detection of MCI and ADRD can help researchers identify appropriate patients for research and help clinicians and health systems target patients for preventive care and care coordination. For these reasons, more efficient, highly scalable strategies are needed to identify people with MCI and ADRD. The Specific Aims of this proposal are to (1) Develop and validate a ML algorithm using features extracted from the EHR with NLP to identify patients with CI, (2) Develop and validate a ML algorithm using features extracted from ASA of audio recordings of patient-provider encounters during routine primary care visits to identify patients with CI, (3) Develop and validate a ML algorithm using both NLP and ASA extracted features to create an integrated CI diagnostic algorithm. We will develop machine learning algorithms using NLP and ASA extracted features trained against neurocognitive assessment data on 800 primary care patients in New York City and validate them in an independent sample of 200 patients in Chicago. In secondary analyses we will train ML algorithms to identify MCI and its subtypes. This project will be the most rigorous development of NLP, ASA, and ML algorithms for CI yet performed, the first to test ASA in primary care settings, and the first to test NLP and ASA feature extraction strategies in combination. The multi-disciplinary team of clinicians, health services researchers, and neurocognitive and data scientists will apply machine learning to develop these highly scalable, automated technologies for identification of MCI and ADRD. 1 Project Narrative The ability of clinicians, health systems and researchers to identify patients with mild cognitive impairment (MCI) and Alzheimer’s Disease Related Dementias (ADRD) is limited. This project will apply machine learning to natural language processing (NLP) of electronic health record data and automated speech analysis (ASA) of patient-doctor conversations during primary care visits to identify patients with MCI and ADRD using automated and scalable procedures. The analytic algorithms will be developed with neurocognitive assessment data on 800 primary care patients in New York City and validated in an independent sample of 200 patients in Chicago. 1",Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment,9998610,R01AG066471,"['Acoustics', 'Acute', 'Address', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'Caregivers', 'Chicago', 'Clinical', 'Clinical assessments', 'Code', 'Cognition', 'Cognitive', 'Data', 'Data Analyses', 'Data Element', 'Data Scientist', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Documentation', 'Early Diagnosis', 'Elderly', 'Electronic Health Record', 'Health Services', 'Health system', 'Impaired cognition', 'Individual', 'Insurance Carriers', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Natural Language Processing', 'Neurocognitive', 'New York City', 'Parkinson Disease', 'Patient Care', 'Patients', 'Persons', 'Physicians', 'Population', 'Positioning Attribute', 'Preventive care', 'Primary Health Care', 'Procedures', 'Provider', 'Psychiatric Diagnosis', 'Reference Standards', 'Research', 'Research Personnel', 'Resource Allocation', 'Risk Factors', 'Sampling', 'Semantics', 'Sensitivity and Specificity', 'Services', 'Signs and Symptoms', 'Speech', 'Structure', 'Study Subject', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Validation', 'Visit', 'adverse event risk', 'aging population', 'automated speech recognition', 'base', 'care coordination', 'clinical encounter', 'cognitive function', 'cognitive testing', 'deep learning', 'demographics', 'electronic data', 'electronic structure', 'falls', 'feature extraction', 'financial incentive', 'health care settings', 'improved', 'insurance claims', 'learning classifier', 'machine learning algorithm', 'mental state', 'mild cognitive impairment', 'multidisciplinary', 'prevent', 'primary care setting', 'recruit', 'risk mitigation', 'screening', 'secondary analysis', 'structured data', 'success', 'testing services', 'tool', 'treatment choice', 'unstructured data']",NIA,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2020,855710,0.005716645025351514
"Addressing variability in peripheral arterial disease outcomes using machine learning techniques Project Summary/Abstract: Peripheral arterial disease (PAD) is a major cause of morbidity and mortality in the United States, affecting over eight million Americans, of whom 100,000 a year suffer major amputation. Current guidelines dictate medical treatment and aggressive risk factor modification for all PAD patients, whether symptomatic or not, with revascularization attempts for patients with chronic limb threatening ischemia (CLTI) or lifestyle-limiting claudication. Despite strongly-worded standards of care, variability in PAD outcomes persists. Prior research has demonstrated that some demographic factors such as gender, race, and socioeconomic status are associated with worse PAD care and outcomes even when controlling for comorbidities. It is unknown what specific patient, provider, and healthcare system factors lead to these disparities. Efforts to understand which patients will suffer worse outcomes and disease progression have been hampered by contemporary outcomes research techniques. The majority of PAD outcomes research relies on administrative claims databases, procedural registries, or single center retrospective reviews. While each of these methods has some advantages, none offer the combination of patient- and disease-specific data, information about care provision on a provider and health-system level, and outcomes across a range of possible locations. Furthermore, use of any of these methods at the scale necessary to draw powerful conclusions is prohibitively time- and resource-intensive. The overall objective of this research is to use a novel natural language processing model to build a combined EHR/CMS database and to use that database to predict which PAD patients are at highest risk of poor outcomes with improved power and precision. This proposal contains plans for collaboration with Duke Forge, who bring expertise in natural language processing and machine learning in order to efficiently identify PAD patients within our EHR and efficiently abstract information about them. Once identified, these patients can be linked to their CMS outcomes, allowing for assessment of how patient-, physician-, and healthcare-specific factors affect PAD outcomes. Our central hypothesis is that natural language processing powered by machine learning will permit efficient identification of patients with PAD, thereby facilitating higher-powered and higher-quality investigation into disparities in PAD outcomes. This research will pave the way for future interventions targeting sources of outcome inequality, possibly including access to care, physician adherence to national guidelines, and patient preferences or health literacy. Project Narrative: Peripheral arterial disease affects more than eight million Americans, with over one hundred thousand amputations performed yearly. Despite the prevalence and morbidity of this disease, there is a lack of knowledge about which patients will require amputation, multiple surgeries or hospitalizations, or suffer cardiovascular- related death. This proposal uses natural language processing to improve on current research methodology in order to account for patient-specific, physician-specific, and system-specific factors in peripheral arterial disease care and outcomes.",Addressing variability in peripheral arterial disease outcomes using machine learning techniques,10066805,F32HL151181,"['Address', 'Adherence', 'Affect', 'American', 'Amputation', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Chronic', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Country', 'Data', 'Data Set', 'Databases', 'Demographic Factors', 'Disease', 'Disease Outcome', 'Disease Progression', 'Documentation', 'Elements', 'Failure', 'Female', 'Future', 'Gender', 'Goals', 'Guidelines', 'Health Services Accessibility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Inequality', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Intervention', 'Investigation', 'Ischemia', 'Knowledge', 'Lead', 'Life Style', 'Light', 'Limb structure', 'Link', 'Location', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Patient Care', 'Patient Preferences', 'Patients', 'Peripheral arterial disease', 'Physicians', 'Prevalence', 'Process', 'Provider', 'Race', 'Registries', 'Research', 'Research Methodology', 'Research Technics', 'Resources', 'Risk', 'Risk Factors', 'Socioeconomic Status', 'Source', 'Stroke', 'System', 'Techniques', 'Text', 'Time', 'Training', 'United States', 'Work', 'adjudicate', 'base', 'care outcomes', 'claudication', 'cohort', 'comorbidity', 'cost', 'demographics', 'design', 'effective intervention', 'health literacy', 'high risk', 'improved', 'low socioeconomic status', 'mortality', 'novel', 'patient subsets', 'tool', 'treatment effect']",NHLBI,DUKE UNIVERSITY,F32,2020,82476,-0.01525261361322833
"Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases Project Summary Patients living with chronic lung diseases (CLDs) are frequently admitted to the hospital for potentially preventable causes. Such admissions may be discordant with patient preferences and/or represent a low-value allocation of health system resources. To anticipate such admissions, existing clinical prediction models in this ﬁeld typically produce an “all-cause” risk estimate which, even if accurate, overlooks the actionable mechanisms behind admis- sion risk and therefore fails to identify a prescribed response. This limitation may explain the only modest – at best – reductions in hospital admissions and readmissions seen in most intervention bundles that have been tested in this population. An opportunity exists, therefore, to predict hospitalization risk while simultaneously identifying patient phenotypes (i.e. some constellation of social, demographic, clinical, and other characteristics) for which known preventive interventions exist. The proposed study seeks to overcome these limitations and capitalize on this opportunity by (1) conducting semi-structured interviews with hospitalized patients with CLDs, and their caregivers and clinicians, to directly identify modiﬁable risks and their associated phenotypes driving hospital ad- missions; (2) using natural language processing techniques (NLP) to build classiﬁcation models that will leverage nuanced narrative, social, and clinical information in the unstructured text of clinical encounter notes to identify patients with these phenotypes; and (3) building risk prediction model focused on actionable phenotypes with a wide-array of traditional regression and machine learning approaches while also incorporating large numbers of predictor variables from text data and accounting for time-varying trends. The candidate's preliminary work using basic NLP techniques to signiﬁcantly improve the discrimination of clinical prediction models in an inpatient population has motivated this methodologic approach. The rising burden and costs of hospitalizations associated with CLDs, and the increasing attention from federal payers, highlights the critical nature of this work. Completion of this research will build upon the candidate's past training, which includes a Masters of Science in Health Policy Research obtained with NHLBI T32 support, and will provide the experience, education, and mentorship to allow the candidate to become a fully independent investigator. Based on the candidate's tailored training plan, he will acquire advanced skills in mixed-methods research, NLP, and trial design all through coursework, close men- toring and supervision, and direct practice. The skills will position him ideally to submit successful R01s testing the deployment of the proposed clinical prediction models in real-world settings. The candidate's primary mentor, collaborators, and advisors will ensure adherence to the proposed timeline and goals and provide a support- ive environment for him to develop an independent research career testing the real-world deployment of clinical prediction models to reduce low-value and preference-discordant care for patients with CLDs. Project Narrative Every year many people living with chronic lung diseases are admitted to the hospital despite the fact that some of these admissions may have been prevented with early identiﬁcation and intervention prior to the hospitalization. Previous attempts at preventing such hospitalizations have been limited by their ability to both accurately identify those at risk, and because most risk models do not provide a reason for the likely admission. The proposed work draws directly on the experiences of patients with chronic lung diseases who are admitted to a hospital, and then uses cutting edge statistical and computer science techniques to use information in the electronic health record to accurately predict the risk and the likely reason for future hospital admissions.",Using natural language processing and machine learning to identify potentially preventable hospital admissions among outpatients with chronic lung diseases,9906933,K23HL141639,"['Accounting', 'Acute', 'Address', 'Adherence', 'Admission activity', 'Adult', 'Ambulatory Care', 'Attention', 'Automobile Driving', 'Bioinformatics', 'Caregivers', 'Caring', 'Characteristics', 'Chronic Obstructive Airway Disease', 'Chronic lung disease', 'Classification', 'Clinical', 'Communities', 'Data', 'Data Set', 'Data Sources', 'Diagnosis', 'Discrimination', 'Early Intervention', 'Early identification', 'Education', 'Electronic Health Record', 'Ensure', 'Future', 'Goals', 'Health Policy', 'Health system', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Hospitals', 'Inpatients', 'Interstitial Lung Diseases', 'Intervention', 'Interview', 'K-Series Research Career Programs', 'Machine Learning', 'Master of Science', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Nature', 'Nurses', 'Outpatients', 'Palliative Care', 'Patient Care', 'Patient Preferences', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Physicians', 'Policy Research', 'Population', 'Positioning Attribute', 'Preventive Intervention', 'Primary Health Care', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Risk', 'Risk Estimate', 'Social support', 'Structure', 'Supervision', 'Symptoms', 'Techniques', 'Testing', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Universities', 'Validation', 'Work', 'administrative database', 'base', 'career', 'career development', 'clinical center', 'clinical encounter', 'comorbidity', 'computer science', 'cost', 'design', 'discrete data', 'end of life', 'experience', 'hospital readmission', 'improved', 'innovation', 'instrument', 'interest', 'model development', 'modifiable risk', 'novel', 'predictive modeling', 'preference', 'prevent', 'randomized trial', 'response', 'risk prediction model', 'skills', 'social', 'statistical learning', 'structured data', 'supportive environment', 'trend', 'trial design', 'unstructured data']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K23,2020,194806,-0.004113318670624387
"Use of Machine Learning on Integrated Electronic Medical Record, Genetic and Waveform Data to Predict Perioperative Cardiorespiratory Instability Project Summary/Abstract  The objective of this K01 application is to give Dr. Hofer the necessary training and research experience to establish himself as an independent investigator focused on using machine learning (ML) on a variety of healthcare data to predict outcomes during the perioperative period. The career development activities consist of escalating coursework on machine learning beginning with an online course of ML fundamentals and ending with a UCLA course on ML applications in healthcare. Augmenting these courses are tutorials on the application of these techniques to healthcare data and a research program is designed to use ML on healthcare data to predict perioperative cardio-respiratory instability (CRI) – specifically hypotension and arrhythmia.  To achieve these goals, Dr. Hofer has established an outstanding team of leaders in machine learning, perioperative medicine, and clinical informatics. Dr. Maxime Cannesson, his primary mentor, is an expert in perioperative medicine and the use of ML on physiologic signals. Dr. Eran Halperin, the co-mentor for this pro- posal, is an expert in ML and its application to genomic and other healthcare data. Dr. Hofer has ongoing collab- orations with Drs. Cannesson and Halperin on joint projects. Both Drs. Cannesson and Halperin have a strong track record of mentoring individuals who have progressed to independent and productive academic careers. Dr. Hofer will be aided by an advisory committee consisting of Dr. Douglas Bell (who will provide guidance on integrating data from multiple sources), Dr. Mohammed Mahbouba (providing support regarding data security and creating enterprise level analytic solutions) and Dr. Jeanine Wiener-Kronish (providing guidance on the most relevant questions in perioperative outcome prediction).  Challenges managing CRI have been implicated in the more than 15 million annual postoperative com- plications, costing more than $165 billion, however no scores exist to predict CRI. This study will leverage unique infrastructure at UCLA where whole EMR data has been combined with physiologic waveforms and genomic data on more than 30,000 patients. This proposal will use a variety of ML techniques on these data to create predictive models for CRI.  In summary, this proposal will provide Dr. Hofer with both technical training in ML and hands on experi- ence in using ML to predict perioperative outcomes. This study has the potential to create models that will help clinicians predict, and thus avoid, perioperative instability, thereby improving patient outcomes. Additionally, this program will provide Dr. Hofer with the tools he needs to successfully compete for a R01 focusing on using ML models on a variety of healthcare data to predict the downstream effects of CRI – perioperative complications. Project Narrative During the perioperative period hemodynamic instability is the norm rather than the exception; the ability of clinicians to manage this instability has been associated with postoperative complications affecting more than 15 million Americans and costing more than $165 billion each year. There are no current risk scores that predict instability in real time, however the recent widespread adoption of electronic medical records and creation of genomic biobanks creates unique opportunities to develop scores that are both accurate and precise. We will use machine learning techniques to create risk scores for perioperative cardiorespiratory instability – specifically hypotension and arrhythmia – using combined electronic medical record, genomic and physiologic waveform data.","Use of Machine Learning on Integrated Electronic Medical Record, Genetic and Waveform Data to Predict Perioperative Cardiorespiratory Instability",10055690,K01HL150318,"['Acute', 'Adoption', 'Advisory Committees', 'Affect', 'African American', 'Algorithms', 'American', 'Arrhythmia', 'Atlases', 'California', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computerized Medical Record', 'Data', 'Data Security', 'Databases', 'Disease', 'Ensure', 'Event', 'Functional disorder', 'Genetic', 'Genetic Databases', 'Genetic Risk', 'Genomics', 'Goals', 'Health', 'Healthcare', 'Hypotension', 'Individual', 'Infrastructure', 'Inpatients', 'Joints', 'Latino', 'Logistic Regressions', 'Los Angeles', 'Machine Learning', 'Manuals', 'Medical Genetics', 'Medical History', 'Medicine', 'Mentors', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Operative Surgical Procedures', 'Outcome', 'Outpatients', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perioperative', 'Perioperative complication', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Physiology', 'Population Analysis', 'Population Heterogeneity', 'Postoperative Complications', 'Prevalence', 'Process', 'Provider', 'Recurrence', 'Research', 'Research Personnel', 'Risk', 'Signal Transduction', 'Subgroup', 'Techniques', 'Time', 'Training', 'Universities', 'Work', 'acute stress', 'automated algorithm', 'base', 'biobank', 'biological adaptation to stress', 'career', 'career development', 'cost', 'deep neural network', 'design', 'diverse data', 'electronic data', 'ethnic minority population', 'experience', 'feeding', 'genetic information', 'genetic profiling', 'genomic data', 'hemodynamics', 'improved', 'long short term memory', 'multiple data sources', 'online course', 'outcome prediction', 'phenotyping algorithm', 'prediction algorithm', 'predictive modeling', 'pressure', 'prevent', 'programs', 'random forest', 'structured data', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,K01,2020,175284,0.008586232542189827
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9925807,R01LM012817,"['Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'comorbidity', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2020,335875,-0.0056828398690122895
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,10005506,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Pooling', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data infrastructure', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phenotyping algorithm', 'phrases', 'portability', 'preservation', 'privacy preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2020,1500847,0.010548166935647536
"Prediction of therapist cultural competency using Natural Language Processing (NLP) models PROJECT SUMMARY  Racial-ethnic minorities (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) individuals experience high levels of psychological distress. Psychological treatments can be effective in addressing mental health concerns, but disparities in quality of care still exist. Although systemic and institutional factors contribute to disparities in care, mental health providers are also critical to examine. A primary focus of efforts to understand and reduce provider contributions to mental health care disparities has been to examine cultural competency (CC), which involves a provider’s ability to navigate the cultural aspects of clinical interactions. Patient ratings of CC are generally associated with treatment outcomes and therapeutic processes. While patient perceptions of provider CC are important, a reliance on retrospective patient ratings limits what we know about how cultural identities are discussed, and the language that constitutes culturally sensitive care. Many studies of provider CC also require observers or patients to make complex judgments based on internal provider characteristics that are not reliably observable (e.g. rate provider awareness of their own cultural values). More studies are needed that examine patient-provider interactions in treatment in order to assess the impact of specific provider behaviors, and how they relate to perceptions of provider CC. Recently, Natural Language Processing (NLP) models have been applied to psychotherapy conversations to automatically capture the use of evidence based treatments, topics of conversation, empathy, and emotional expression. Prior research demonstrating the feasibility of automatically identifying topics of conversation in psychotherapy suggest that NLP models could be trained to automatically identify specific moments in sessions where patients and providers are talking about cultural issues. NLP models could allow researchers to not only examine how specific patterns of provider-patient interactions drive CC, but might also provide rapid feedback to providers, and in turn help address disparities in care. The purpose of the current study is to do the foundational work to develop and evaluate NLP tools that capture the cultural content of provider-patient interactions among REM and LGBTQ patients. First, utilizing 32,436 labeled talk turns from 200 psychotherapy sessions we will evaluate the accuracy of NLP models in recognizing the discussion of cultural topics in psychotherapy. Second, we will use NLP models to explore differences in the content of 1,235 psychotherapy sessions that were rated as highly positive or negative on a measure of cultural competence. PROJECT NARRATIVE Although disparities in the quality of mental health treatment for racial-ethnic minority (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) patients are well known, to date there are no tools that can identify specific patterns of provider-patient interactions that drive disparities in care. This project will evaluate the ability of Natural Language Processing (NLP) models to recognize discussion of cultural topics in psychotherapy among REM and LGBTQ patients, and explore differences in patient-provider interactions with low and high patient ratings of provider cultural competency.",Prediction of therapist cultural competency using Natural Language Processing (NLP) models,9906653,F31MD014941,"['Address', 'Alcohol or Other Drugs use', 'Anxiety', 'Awareness', 'Behavior', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Discrimination', 'Empathy', 'Evidence based treatment', 'Face', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Grant', 'Health Personnel', 'Healthcare', 'Individual', 'Judgment', 'Label', 'Language', 'Lesbian Gay Bisexual Transgender Queer', 'Machine Learning', 'Measures', 'Mental Depression', 'Mental Health', 'Methods', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Outcome', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Provider', 'Psychotherapy', 'Quality of Care', 'Reporting', 'Research', 'Research Personnel', 'Suicide', 'Technology', 'Text', 'Therapeutic', 'Training', 'Treatment outcome', 'Work', 'base', 'commercial application', 'community setting', 'cultural competence', 'cultural values', 'disparity reduction', 'effective intervention', 'ethnic minority population', 'experience', 'health care disparity', 'improved', 'psychologic', 'psychological distress', 'racial and ethnic', 'sexual identity', 'showing emotion', 'substance abuse treatment', 'symptomatic improvement', 'tool', 'treatment disparity', 'university student', 'willingness']",NIMHD,UNIVERSITY OF UTAH,F31,2020,45016,-0.00639679190808116
"Optimizing the Utility of Large Electronic Health Records Data in Data-Driven Health Research Optimizing the Utility of Electronic Medical Records Data in  Data-driven Health Research ABSTRACT Medical centers continue to archive patient follow-up data in Electronic Medical Records (EMR), which have tremendous value in discovering new knowledge and insights. The large volume of EMR data can play an important role in improving the accuracy and generalizability of predictive models in healthcare, especially when misdiagnosis is known to be the third leading cause of death in the United States. Despite these merits, EMR data are invariably corrupted by factors like missing values, outliers, and unrealistic measurements, which prevent researchers from fully utilizing such abundant data in many important studies. Many studies simply discard a large number of samples to get rid of missingness and eventually bias their data-driven analytical models. Existing techniques for missing data imputation use simplified linear models and are mostly suitable for imputing cross-sectional data missingness that ignore longitudinal missingness in patient follow-up data. This proposal aims to investigate novel artificial intelligence (AI) based models to improve the quality and utility of EMR data in preparation for data-driven retrospective studies. Toward this preparation, the goal of the project is 1) to investigate more accurate and robust data imputation models compared to existing ones and 2) adapt state-of-the-art deep learning techniques in preparing optimal representation of large EMR data. The proposed research will 1) maximize the quality and utility of EMR data to support a multitude of retrospective studies, 2) enable visualization of complex patient data, 3) identify more important and predictive clinical parameters, 4) yield a compact and optimal representation of large EMR datasets. We hypothesize that optimally processed EMR data with state-of-the-art AI models can most accurately model patient risk when compared to existing statistical and clinical risk models. This project will combine the complementary expertise of the collaborators, Dr. Manar Samad, PhD (Computer Science), Dr. Owen Johnson, DPH (Biostatistics and Public Health), and Dr. Edilberto Raynes, MD, PhD (Medicine) along with the participating undergraduate students at Tennessee State University (TSU). The proposal entails several research and development components that will allow undergraduate students to gain valuable research and analytical skills in data science, programming, and health informatics. The project activities will expose health science students to AI-based computing solutions to broaden their scope of future health research and career. This project will help TSU prepare a strong workforce of minority students who will gain competitive skill sets in data science and health informatics that are currently high in demand almost everywhere. Overall, the project will develop a data-capable workforce to strengthen an interdisciplinary research capacity and collaboration between the Departments of Computer and Health science at TSU. Project Narrative Electronic Medical Record (EMR) data are invariably corrupted by data missingness and data redundancy that limit their application in many valuable data-driven research studies aiming to achieve the goals of precision medicine. This project aims to develop a number of innovative computational frameworks that will optimally prepare and utilize EMR data to facilitate research studies with relevance to patient risk modeling, discovery of new health markers, and patient-specific prognosis and therapeutic strategy. The project will leverage recent advances in machine learning and data science by involving an interdisciplinary team of researchers consisting of three faculty members, two graduate students, and four undergraduate students, which will establish a data-centric research collaboration between the Departments of Computer and Health Science.",Optimizing the Utility of Large Electronic Health Records Data in Data-Driven Health Research,10111205,R15LM013569,"['Affect', 'Algorithms', 'Anatomy', 'Archives', 'Artificial Intelligence', 'Biometry', 'Cause of Death', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Collaborations', 'Complex', 'Computer Models', 'Computerized Medical Record', 'Consumption', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Diagnostic', 'Dimensions', 'Disease', 'Doctor of Philosophy', 'Electronic Health Record', 'Ensure', 'Faculty', 'Future', 'Goals', 'Health', 'Health Sciences', 'Healthcare', 'High Performance Computing', 'Hybrids', 'Image', 'Interdisciplinary Study', 'International Classification of Diseases', 'Knowledge', 'Laboratories', 'Linear Models', 'Literature', 'Machine Learning', 'Measurement', 'Medical center', 'Medicine', 'Modeling', 'Network-based', 'Outcome', 'Outcomes Research', 'Patient risk', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physiological', 'Play', 'Preparation', 'Process', 'Public Health', 'Public Health Informatics', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Retrospective Studies', 'Risk stratification', 'Role', 'Sample Size', 'Sampling', 'Statistical Models', 'Structure', 'Students', 'Techniques', 'Tennessee', 'Testing', 'Therapeutic', 'Time', 'United States', 'Universities', 'Validation', 'Variant', 'Visit', 'Visualization', 'base', 'career', 'clinical decision-making', 'clinical predictors', 'clinical risk', 'complex data ', 'computational platform', 'computer framework', 'computer science', 'computing resources', 'data quality', 'data structure', 'data visualization', 'deep learning', 'deep neural network', 'digital', 'follow-up', 'graduate student', 'health science research', 'high dimensionality', 'improved', 'individual patient', 'innovation', 'insight', 'member', 'minority student', 'neural network', 'non-linear transformation', 'novel', 'outcome forecast', 'precision medicine', 'predictive modeling', 'prevent', 'prognostic', 'recurrent neural network', 'research and development', 'research study', 'skills', 'structured data', 'survival prediction', 'undergraduate student']",NLM,TENNESSEE STATE UNIVERSITY,R15,2020,421700,-0.003897027310978776
"Online Evidence of Withdrawal Self-Medication PROJECT SUMMARY/ABSTRACT Withdrawal symptoms from opioid use can be severe and are major contributing factors to relapse and continuing misuse. Many opioid users are actively experimenting with “remedies” that can alleviate withdrawal, and they are discussing their effectiveness in blogs and forums. In this pilot study we will use Natural Language Processing (NLP) and human expertise to examine over 50,000 recent posts in two Reddit forums OpiatesRecovery and Opiates to assess systematically which remedies are being used, how they are being used, and what are the reported consequences of such self-help experimentation. We will create a curated database of user-reported “remedies.” Information will be semiautomatically extracted from the online, self-reported use of alternative treatments (i.e., other prescription drugs, over the counter medications, food supplements, activities such as meditation and yoga). A team of a pharmacologist, physician, and ethnographer will evaluate database entries to uncover (1) potential harm associated with uncontrolled and unsupervised experimentation, (2) potentially effective available treatments (e.g., traditional medicine), (3) potentially promising compound leads, and (4) patients' needs and issues that are most important to them. Aim 1. To assemble an extensive database of opioid withdrawal and remedy-associated terminology from posts on OpiatesRecovery and Opiates Reddit communities. NLP will be used to build a language model that understands how words are used in context (word2vec). Aim 2. To develop a dataset of instances of self-reported remedy use from Reddit and conduct a bipartite network analysis of remedies and users. Using NLP tools and the word embedding model we will develop an exclusive dataset containing extracted information associated with remedies targeting withdrawal and craving. This aim will use elements of artificial intelligence and close human supervision to extract remedies, including variations of spelling, from the texts. The result of this aim will be a remedy database that includes spelling variations and slang references and a network analysis linking remedies and users. Aim 3. To organize, aggregate, and systematically assess information from mentions of remedy use. Potential compounds and other remedies will be classified to provide an initial assessment of their potential relevance to the opioid treatment process. This process will require the most human oversight and assessment. Network analysis tools will be used to assess and identify the relationships between the types of remedies and potential therapeutic effect and will create the benchmarks for similar future studies. PROJECT NARRATIVE Withdrawal symptoms from opioid use can be severe and are major contributing factors to relapse and continuing misuse. Many opioid users are actively experimenting with “remedies” that can alleviate withdrawal, and they are discussing their effectiveness in blogs and forums. In this pilot study we will use Natural Language Processing and human expertise to examine over 50,000 recent posts in two Reddit forums— OpiatesRecovery and Opiates—to assess systematically which remedies are being used, how they are being used, and what are the reported consequences of such self-help experimentation.",Online Evidence of Withdrawal Self-Medication,9979829,R21DA048739,"['Acupuncture Therapy', 'Adult', 'Artificial Intelligence', 'Automation', 'Belief', 'Benchmarking', 'Categories', 'Cluster Analysis', 'Collaborations', 'Communities', 'Data', 'Data Set', 'Databases', 'Drug Prescriptions', 'Effectiveness', 'Elements', 'Epidemiologist', 'Epidemiology', 'Food', 'Food Additives', 'Food Supplements', 'Future', 'Habits', 'Harm Reduction', 'Herb', 'Herbal Medicine', 'Human', 'Information Retrieval', 'Knowledge', 'Language', 'Life', 'Link', 'Marijuana', 'Medical', 'Meditation', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Prescription Drugs', 'Opioid', 'Pathway Analysis', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Pilot Projects', 'Process', 'Published Comment', 'Relapse', 'Reporting', 'Research', 'Resources', 'Self Medication', 'Supervision', 'Terminology', 'Therapeutic Effect', 'Traditional Medicine', 'Twitter', 'United States Food and Drug Administration', 'Variant', 'Vitamins', 'Withdrawal', 'Withdrawal Symptom', 'Yoga', 'alternative treatment', 'cost', 'craving', 'dietary supplements', 'epidemiology study', 'experience', 'experimental study', 'interest', 'non-opioid analgesic', 'novel', 'off-label drug', 'off-label use', 'online community', 'opioid misuse', 'opioid use', 'opioid user', 'opioid withdrawal', 'patient population', 'self help', 'social media', 'spelling', 'tool', 'trend']",NIDA,RESEARCH TRIANGLE INSTITUTE,R21,2020,268226,-0.00383024178513564
"An Interoperable HL7 FHIR-based Medical Device Data System (MDDS) For Accessing And Integrating Live Point-Of-Care Data From High-Acuity Bedside Patient Monitoring Equipment Abstract The overall goal of this proposal is to combine expertise and approaches from biomedical engineering and critical care medicine to design a universal system to acquire, record and transmit physiological signals from bedside monitored patients. Patient monitors generate over a million datapoints of information per hour, however, only a tiny fraction of those data are transmitted or recorded. In order to improve data exchange in healthcare, the Fast Healthcare Interoperability Resources (FHIR) standard was published in 2014. However, it has yet to make a significant impact on Medical Device Integration (MDI), which is the process of automating the flow of clinical data from bedside medical devices, such as patient monitors, to external systems such as Electronic Medical Records (EMR). Also, MDI is a complex task because data from these devices are high-frequency and high- volume and because most devices use proprietary protocols and outdated interfaces such as serial cables. Hospitals and researchers have therefore been left with few options except to use expensive and vendor-specific MDI solutions to access these data or to use manual data entry into the patient EMR, which leads to data entry errors, late entry of data, and lost time for clinical care. Manual data entry only captures a tiny fraction of the available data, and with increased research interest in Artificial Intelligence (AI) and Machine Learning, there is a growing need for a standardized way to access the vast amounts of data from bedside devices. This project will develop a vendor-neutral software-based Medical Device Data System (MDDS) that acquires and records data from bedside devices across a hospital network and makes live data available to 3rd party systems using a FHIR application programming interface (API). The proposed proof-of-concept will consist of three elements: [i] a transmitter which encrypts and transmits patient signals across the network, [ii] an aggregator which receives, translates and records the signals to a central location, and [iii] a FHIR Server with API for allowing external systems to access live data as FHIR resources. This proposal seeks to create a novel design that will overcome a critical barrier in healthcare, medicine and research. The proposed MDDS will be valuable to hospitals, clinicians, researchers and app developers because it makes data accessible which were previously only available to clinicians at the bedside in real-time. Narrative MediCollector’s proposed vendor-neutral medical device data system (MDDS) will be a valuable research tool to access, acquire and record high-frequency bedside patient monitor data for facilitating clinical research in hospitals. In addition, it will make live patient monitor data accessible to external systems through an HL7 FHIR application programming interface (API), thereby improving interoperability in hospitals and opening the doors to the integration of live data into external systems, such as smartphone apps and artificial intelligence algorithms, which can improve clinical workflow and healthcare in general.",An Interoperable HL7 FHIR-based Medical Device Data System (MDDS) For Accessing And Integrating Live Point-Of-Care Data From High-Acuity Bedside Patient Monitoring Equipment,10140938,R43EB030890,"['Artificial Intelligence', 'Beds', 'Biomedical Engineering', 'Boston', 'Client', 'Clinical', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'Computerized Medical Record', 'Critical Care', 'Data', 'Data Display', 'Devices', 'Documentation', 'Elements', 'Engineering', 'Environment', 'Equipment', 'Fast Healthcare Interoperability Resources', 'Frequencies', 'Goals', 'Healthcare', 'Hospitals', 'Hour', 'Information Systems', 'Instruction', 'Knowledge', 'Left', 'Location', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Medical', 'Medical Device', 'Medicine', 'Monitor', 'Patient Monitoring', 'Patients', 'Patients&apos', ' Rooms', 'Pediatric Hospitals', 'Physiological', 'Positioning Attribute', 'Problem Solving', 'Process', 'Protocols documentation', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Resources', 'Safety', 'Secure', 'Services', 'Signal Transduction', 'Standardization', 'Sum', 'System', 'Test Result', 'Testing', 'Time', 'Translating', 'Vendor', 'Ventilator', 'application programming interface', 'base', 'clinical care', 'clinically relevant', 'data access', 'data exchange', 'design', 'encryption', 'experience', 'graphical user interface', 'improved', 'intelligent algorithm', 'interest', 'interoperability', 'novel', 'point of care', 'sensor', 'smartphone Application', 'software systems', 'tool']",NIBIB,"MEDICOLLECTOR, LLC",R43,2020,210642,0.018899032897556185
"Studying pseudogout using naturallanguage processing and novelimaging approaches Candidate: Dr. Tedeschi is an Instructor in Medicine at Harvard Medical School (HMS) and Associate Physician in the Division of Rheumatology, Immunology and Allergy’s Section of Clinical Sciences (SCS) at Brigham and Women’s Hospital (BWH). She received an MPH from the Harvard T.H. Chan School of Public Health (HSPH). Her 10 first-author manuscripts, two BWH grants, and foundation award exemplify her productivity and commitment to research. She has assembled an experienced team of mentors and collaborators, led by Dr. Daniel Solomon (primary mentor) and Drs. Katherine Liao and Karen Costenbader (co-mentors), to guide her training in natural language processing and machine learning approaches for clinical research, analysis of linked electronic medical record (EMR) and Medicare claims data, and interpretation of advanced imaging modalities. Focused coursework at HSPH and HMS will complement the experience she gains through her proposed studies of pseudogout risk factors and long-term outcomes. Training in dual- energy CT and ultrasound interpretation for crystalline arthritis will be obtained via one-on-one sessions. Her long-term career goal is to become an independent patient-oriented investigator focused on pseudogout. Environment: Dr. Tedeschi has a commitment from her Division for >75% protected time for research and career development activities during the K23 award period. Support from the Division and her primary mentor’s research funds will supplement her salary and project-related expenses. The SCS, a collaborative clinical research group in the Division of Rheumatology, has extensive infrastructure including the VERITY Bioinformatics Core (NIH-P30-AR072577, PI: Solomon) that will provide resources and expertise for the proposed studies. In addition, the BWH Arthritis Center is one of the largest nationally, facilitating subject recruitment, and the BWH Division of Musculoskeletal Imaging has state-of-the-art equipment and expertise applying dual-energy CT in crystalline arthritis. Coursework at HSPH and HMS, adjacent to BWH, will provide training necessary for Dr. Tedeschi’s development into an independent investigator. Research: Dr. Tedeschi’s long-term objective is to prevent and reduce morbidity from pseudogout, an understudied, painful crystalline arthritis that affects 8-10 million Americans. She will use natural language processing and machine learning approaches to enhance an algorithm for identifying pseudogout in EMR data. She will study risk factors for and long-term outcomes in pseudogout, harnessing vast amounts of information contained in Partners HealthCare EMR data and Medicare claims data, and will gain experience working with linked datasets. Dr. Tedeschi will recruit subjects with pseudogout and other types of mono- and oligoarthritis to test and compare the performance of dual-energy CT scanning, musculoskeletal ultrasound, and x-ray for identifying pseudogout. Her proposed K23 projects will lead to manuscripts and data to be leveraged in an R01 application focused on pseudogout during the award period, leading to independence as a patient-oriented investigator. Project Narrative The proposed studies will contribute fundamental knowledge about pseudogout, a common, painful crystalline arthritis for which we have little prognostic information and no targeted treatments. Results from the proposed projects could lead to methods for non-invasive, accurate pseudogout diagnosis, development of preventive strategies for pseudogout, and interventions to reduce cardiovascular disease risk. Future work stemming from the proposed projects may include predictive models of pseudogout flares, identification of serum biomarkers for pseudogout, and development of outcomes measures to be used in prospectively recruited pseudogout cohort studies.",Studying pseudogout using naturallanguage processing and novelimaging approaches,9882206,K23AR075070,"['Acute', 'Affect', 'Age', 'Agreement', 'Algorithms', 'American', 'Arthritis', 'Award', 'Bioinformatics', 'Biological Markers', 'Calcium Pyrophosphate', 'Calcium pyrophosphate deposition disease', 'Cardiovascular Diseases', 'Case-Control Studies', 'Chronic', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Code', 'Cohort Studies', 'Complement', 'Computerized Medical Record', 'Conflict (Psychology)', 'Crystallization', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diuretics', 'Environment', 'Equipment', 'Event', 'Female', 'Flare', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Gout', 'Grant', 'Healthcare', 'Hospitals', 'Hypersensitivity', 'Image', 'Immunology', 'Inflammatory', 'Inflammatory Arthritis', 'Infrastructure', 'Institution', 'Insurance Claim Review', 'Interleukin-1 beta', 'Intervention', 'Ischemic Stroke', 'Joints', 'Knowledge', 'Lead', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Manuscripts', 'Medicare claim', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Oligonucleotides', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pain', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Polyarthritides', 'Population', 'Positioning Attribute', 'Predictive Value', 'Prevalence', 'Prevention strategy', 'Productivity', 'Proton Pump Inhibitors', 'Pseudogout', 'Public Health Schools', 'Publishing', 'Questionnaires', 'Research', 'Research Personnel', 'Resources', 'Rheumatoid Arthritis', 'Rheumatology', 'Risk', 'Risk Factors', 'Roentgen Rays', 'Sensitivity and Specificity', 'Serum', 'Synovial Fluid', 'Techniques', 'Testing', 'Time', 'Training', 'Ultrasonography', 'United States National Institutes of Health', 'Validation', 'Vascular calcification', 'Vascularization', 'Visit', 'Wages', 'Woman', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'bisphosphonate', 'calcium indicator', 'cardiovascular disorder risk', 'career', 'career development', 'cohort', 'crystallinity', 'epidemiology study', 'experience', 'genetic linkage analysis', 'high risk', 'human old age (65+)', 'imaging modality', 'instructor', 'longitudinal course', 'medical schools', 'modifiable risk', 'mortality', 'mortality risk', 'musculoskeletal imaging', 'musculoskeletal ultrasound', 'novel', 'patient health information', 'patient oriented', 'predictive modeling', 'prevent', 'prognostic', 'prospective', 'ranpirnase', 'recruit', 'research and development', 'sex', 'side effect', 'stem', 'structured data', 'targeted treatment', 'unnecessary treatment']",NIAMS,BRIGHAM AND WOMEN'S HOSPITAL,K23,2020,176541,0.02154545449914055
"Machine Learning Clinical Order Recommendations for Specialty Consultation Care Summary: Machine Learning Clinical Order Recommendations for Specialty Consultation Care  A future vision of clinical decision support must transcend constraints in scalability, maintainability, and adaptability. The shortage of 100,000 physicians by 2030 reflects unmet (and unlimited) demand for the scarcest healthcare resource, clinical expertise. Over 25 million in the US alone have deficient access to medical specialty care, with delays contributing to 20% higher mortality. There is no quality without access.  Our goal is to develop a radically different paradigm for outpatient specialty consultations by inductively learning clinical workups embedded in clinical data. We focus on predicting the concrete clinical orders for medications and diagnostic tests that result from specialty consultations. This can power a tier of fully automated guides that will enable clinicians to initiate care that would otherwise await in-person specialty visits, opening access for more patients.  The major scientific barriers are advances in data science and decision support methods for collating clinical knowledge, with continuous improvement through clinical experience, crowdsourcing, and machine learning. Our innovative approach is inspired by collaborative filtering algorithms that power “Customers like you also bought this...” recommender systems with the scalability to answer unlimited queries, maintainability through statistical learning, and adaptability to respond to evolving clinical practices.  Our team uniquely combines expertise in clinical medicine, electronic medical records, clinical decision support, statistics and machine learning to enhance medical specialty consultations through aims that seek to: (1) Develop methods to generate clinical decision support by predicting the clinical orders that will result from Endocrinology and Hematology specialty consultations; (2) Evaluate and iteratively design clinical collaborative filtering prototypes based on clinical user input on usability and acceptability; and (3) Determine which consult clinical order patterns are associated with better results through reinforcement learning and causal inference frameworks. Completion of these aims will yield a sustained, powerful impact on clinical information retrieval and knowledge discovery for synthesizing clinical practices from real-world data. By addressing grand challenges in clinical decision support, adoption of these methods will fulfill a vision that empowers clinicians to practice to the top of their license, making healthcare more scalable in reach, responsiveness, and reproducibility Project Narrative There can be no quality without access, and over 25 million in the US alone have deficient access to the scarcest healthcare resource: Human medical expertise. Building on methods analogous to commercial product recommender systems, the proposed research will automatically learn practice patterns from electronic medical records. Distributing predictable practices of medical specialty consultations can then enable healthcare systems to achieve broader patient access to timely and consistent care.",Machine Learning Clinical Order Recommendations for Specialty Consultation Care,10265158,R56LM013365,"['Active Learning', 'Acute', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complex', 'Computerized Medical Record', 'Consult', 'Consultations', 'Data', 'Data Reporting', 'Data Science', 'Diagnosis', 'Diagnostic tests', 'Electronic Mail', 'Endocrinology', 'Environment', 'Evaluation', 'Event', 'Feedback', 'Foundations', 'Future', 'Goals', 'Graph', 'Healthcare', 'Healthcare Systems', 'Hematology', 'Human', 'Human Resources', 'Hyperthyroidism', 'Individual', 'Industry', 'Information Retrieval', 'Inpatients', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Licensing', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Modeling', 'Modern Medicine', 'Monitor', 'Outcome', 'Outpatients', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Primary Health Care', 'Psychological reinforcement', 'Recommendation', 'Records', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Running', 'Specialist', 'Suggestion', 'System', 'Test Result', 'Testing', 'Thrombocytopenia', 'Time', 'Training', 'Transcend', 'Vision', 'Visit', 'Work', 'base', 'clinical care', 'clinical decision support', 'clinical practice', 'clinical predictors', 'convolutional neural network', 'crowdsourcing', 'data streams', 'design', 'experience', 'individual patient', 'innovation', 'iterative design', 'medical specialties', 'mortality', 'novel', 'open source', 'outcome forecast', 'personalized decision', 'personalized predictions', 'predictive modeling', 'prototype', 'statistical learning', 'statistics', 'tool', 'usability']",NLM,STANFORD UNIVERSITY,R56,2020,394250,0.012285084925636725
"Automated Knowledge Engineering Methods to Improve Consumers' Comprehension of their Health Records PROJECT SUMMARY  Today, more patients can access their health records online than ever before. However, clinical acronyms hinder patients' comprehension of their records and decrease the benefits of transparency. An automated system for expanding clinical acronyms should have major clinical significance and far-reaching consequences for improving patient-provider communication, shared decision-making, and health outcomes. Existing systems have limited power to expand clinical acronyms, primarily due to the lack of comprehensiveness (or generali- zability) of existing acronym sense inventories. Because developing comprehensive sense inventories is difficult, existing knowledge engineering methods have primarily focused on developing institution-specific sense inventories. Institution-specific sense inventories may not be generalizable to other geographical regions and medical specialties. Furthermore, developing an institution-specific sense inventory at every US healthcare organization is not feasible, especially without automated methods which currently do not exist.  I developed advanced knowledge engineering methods to overcome these limitations through the use of fully automated techniques to generalize existing sense inventories from different geographical regions and medical specialties. My methods leverage the extensive resources already devoted to developing institution- specific sense inventories in the U.S., and may help generalize existing sense inventories to institutions without the resources to develop them. Although promising, challenges remain with the optimization and evaluation of these methods. The objective of the proposed project is to use knowledge engineering to improve patients' comprehension of their health records, focusing specifically on clinical acronyms. In Aim 1, I will develop new knowledge engineering methods to facilitate the automated integration of sense inventories, using literature- based quality heuristics and a Siamese neural network to establish synonymy. I will evaluate these methods using multiple metrics to assess redundancy, quality, and coverage in two test corpora with over 17 million clinical notes. In Aim 2, I will evaluate whether the knowledge engineering methods improve comprehension of doctors' notes in 60 hospitalized patients with advanced heart failure. With success, I will create novel, automated knowledge engineering methods that can be directly applied to improve patient care. This research is in support of my mentored doctoral training at Columbia University Department of Biomedical Informatics (DBMI) under Drs. David Vawdrey, George Hripcsak, Carol Friedman, Suzanne Bakken, and Chunhua Weng, and will include coursework on deep learning, oral presentations at major annual conferences, and career development planning, among other activities. DBMI is frequently recognized as one of the oldest and best programs of its kind in the world, and provides an exception training environment for my development into an independent and productive academic investigator. PROJECT NARRATIVE Clinical acronyms make it difficult for patients to understand their medical records, decreasing the benefits of transparency. This project applies advanced knowledge engineering methods and machine learning to generate comprehensive acronym sense inventories used to aid consumers' comprehension of their health records. The project is in support of the applicant's mentored doctoral dissertation research.",Automated Knowledge Engineering Methods to Improve Consumers' Comprehension of their Health Records,9895430,F31LM013054,"['Abbreviations', 'Award', 'Clinical', 'Clinical Medicine', 'Comprehension', 'Controlled Vocabulary', 'Development', 'Development Plans', 'Engineering', 'Environment', 'Equipment and supply inventories', 'Evaluation', 'Future', 'Geographic Locations', 'Goals', 'Grant', 'Health', 'Healthcare', 'Heart failure', 'Hospitals', 'Informatics', 'Information Resources', 'Institution', 'Knowledge', 'Literature', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Mentors', 'Mentorship', 'Methods', 'Natural Language Processing', 'Oral', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Positioning Attribute', 'Publishing', 'Questionnaires', 'Records', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Safety', 'Source', 'Support System', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Unified Medical Language System', 'Universities', 'acronyms', 'base', 'biomedical informatics', 'career development', 'clinically significant', 'deep learning', 'doctoral student', 'federal policy', 'health care service organization', 'health record', 'heuristics', 'improved', 'information organization', 'medical specialties', 'method development', 'multidisciplinary', 'neural network', 'novel', 'patient portal', 'patient-clinician communication', 'programs', 'shared decision making', 'success', 'symposium', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,F31,2020,47355,0.00010049415444504074
"Identifying Personalized Risk of Acute Kidney Injury with Machine Learning PROJECT SUMMARY/ABSTRACT Acute Kidney Injury (AKI) is a common and highly lethal health problem, affecting 10-15% of all hospitalized patients and >50% of patients in intensive care units (ICUs). It has been shown that a small increase in serum creatinine (SCr) of ≥0.5 mg/dl was associated with a 6.5-fold increase in the odds of death, a 3.5-day increase in length of stay, and nearly $7,500 in excess hospital costs. Unfortunately, no specific treatment exists to cure AKI once it has developed. The ability to predict AKI in hospitalized patients would provide clinicians the opportunity to modify care pathways and implement interventions, which could in turn prevent AKI and yield better outcomes. Although electronic medical record (EMR) based monitoring systems for AKI have led to expedited interventions and may increase the percentage of patients returning to baseline kidney function, most of these systems are reactive rather than proactive, with little or no contribution to AKI prevention. Moreover, our current knowledge of AKI risk factors is far from complete, especially in the ICU and general inpatient populations, characterized by numerous deficiencies and systematic failings that may be avoidable To transform the reactive AKI care to proactive and personalized care, early identification of high risk patients and better understanding of individual modifiable risk factors for AKI is the key. In Aim 1, to discover novel risk factors predictive of AKI, we propose to develop an ensemble multi-view feature selection framework to simultaneously consider the differences and interrelations between feature spaces and obtain robust knowledge by synthesizing findings from diverse patient populations across multiple institutions in nine US states. In Aim 2, to discover general modifiable causes of AKI to help physicians design more effective AKI prevention policies, we propose to develop a novel multi-cause inference method to identify causal relationships between modifiable factors and AKI for susceptible patient subgroups. In Aim 3, to explain what caused AKI in individual patients to support physicians in designing personalized AKI intervention, we propose to develop a new causal explanation method by integrating causal inference and case based reasoning to quantify patient-level causal significance of modifiable factors. The proposed study will have a significant clinical impact by not only expanding the capacity of clinicians to identify high risk patients for AKI early and advancing the general knowledge on causal and modifiable risk factors for AKI but also supporting personalized AKI intervention with suggestions on potential patient-specific actionable items. The work will not only advance AKI but also the machine learning and clinical research informatics community and the methodology developed is generalizable to other clinical domains. PROJECT NARRATIVE The proposed research is to identify clinical risk factors of acute kidney injury (AKI) in hospitalized patients from electronic medical records (EMRs) with machine learning. AKI risk factors discovered from EMR of diverse populations from multiple institutions across nine US states will be reliable and robust and can assist clinicians in providing proactive and personalized care to high-risk patients.",Identifying Personalized Risk of Acute Kidney Injury with Machine Learning,10003227,R01DK116986,"['Acute Renal Failure with Renal Papillary Necrosis', 'Affect', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Computerized Medical Record', 'Creatinine', 'Data', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Early identification', 'Elderly', 'Event', 'Exposure to', 'Geographic Locations', 'Geographic state', 'Health', 'Health system', 'Hospital Costs', 'Hospital Mortality', 'Hospitals', 'Incidence', 'Individual', 'Informatics', 'Injury to Kidney', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Length of Stay', 'Life', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Monitor', 'Myocardial', 'Outcome', 'Outcomes Research', 'Pathway interactions', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Physicians', 'Physiology', 'Policies', 'Population', 'Population Heterogeneity', 'Predictive Factor', 'Renal function', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Role', 'Sepsis', 'Series', 'Serum', 'Suggestion', 'System', 'Time', 'Work', 'adjudication', 'base', 'case-based', 'clinical predictors', 'clinical risk', 'design', 'feature selection', 'heterogenous data', 'high dimensionality', 'high risk', 'improved', 'individual patient', 'inhibitor/antagonist', 'injury prevention', 'machine learning algorithm', 'modifiable risk', 'mortality risk', 'nephrotoxicity', 'novel', 'patient population', 'patient subsets', 'personalized care', 'prevent']",NIDDK,UNIVERSITY OF KANSAS MEDICAL CENTER,R01,2020,506170,0.012140186138396914
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9899862,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Comparative Effectiveness Research', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'advanced analytics', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'improved', 'interdisciplinary approach', 'medication compliance', 'medication safety', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke therapy', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2020,163080,0.002689841670606051
"Epidemiology and clinical outcomes of diabetic macular edema Approximately 25% of the millions of veterans (est. 8.92 million FY 2013) enrolled for care in Veterans Health Administration (VHA) have diabetes mellitus, and diabetic macular edema (DME) is the leading cause of vision loss in the adult diabetic population world-wide. Although diabetic retinopathy has been well-studied, comparatively little is known about the burden of DME. In fact, only two national prevalence studies and no national study on the incidence of DME in persons with type 2 diabetes have been conducted. Similarly many risk factors have been characterized for DR, but no large studies have established predictors for DME.  Beyond the Medicare claims database, the VHA National Patient Care Database (NPCD) contains standardized administrative data for several aspects of patient care including diagnoses, procedures, medications, lab test results, vital signs, clinical text notes, and mortality. Because the VA uses teleretinal screening as routine clinical care for all patients with diabetes with these results included in the NPCD, the NPCD is an ideal source for studying the epidemiology of and risk factors for DME.  This study proposes to determine the burden of diabetic macular edema, establish risk factors, and examine treatment outcomes in a previously extracted dataset on 1.98 million veterans who have undergone diabetic retinopathy screening at least once since 2004. Currently invaluable ophthalmic data are encoded in unstructured clinical encounter notes in the Computerized Patient Record System (CPRS), and no validated automated extraction method exists to capture these data elements. An automated extraction method using natural language processing will be created and validated to unlock key ophthalmic variables. These text extraction methods will be applicable to extracting ophthalmology data from not only notes of patients with DME but also any ophthalmology clinical note. This will enable future large scale studies in ophthalmology using NPCD and be immediately valuable to the research community at large.  The candidate, Dr. Aaron Lee, MD MSCI, is an ophthalmologist with subspecialty training in retina surgery with a strong background in computer science and epidemiology. His career goal is to become an independent clinician scientist studying diabetic eye disease with large-scale electronic medical record extracted data. While he possesses the foundational skills, he seeks to gain training in advanced statistics and natural language processing to unlock the data captured in unstructured clinical encounter notes. He has assembled an outstanding mentorship team under the primary mentor, Dr. Edward Boyko, MD MPH. This mentorship team includes renowned experts in clinical epidemiology, health informatics, ophthalmology, and natural language processing. This K23 will provide Dr. Lee the structured coursework, mentorship, and applied learning needed to acquire new research skills. He will leverage key local resources to carry out the proposed research at the University of Washington and the VA Seattle Epidemiologic Research and Information Center. Despite the significant visual loss associated with diabetic macular edema, little is known about the frequency of its occurrence, its risk factors, and the real-world effectiveness of existing treatments. The purpose of this proposed research is to utilize the VA National Patient Care Database to extract relevant data elements to examine these three clinical questions: 1) what is the incidence and prevalence of diabetic macular edema, 2) what are the risk factors associated with its development, and 3) what is the comparative real-world effectiveness of its treatments, including intravitreal anti-VEGF therapy, intravitreal corticosteroid therapy and macular laser. The methods developed in this research proposal will not only further our understanding of DME but also generalize and enable future large-scale ophthalmic studies.",Epidemiology and clinical outcomes of diabetic macular edema,9995499,K23EY029246,"['Adopted', 'Adrenal Cortex Hormones', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anemia', 'Blindness', 'Cardiovascular Diseases', 'Caring', 'Cataract Extraction', 'Clinic', 'Clinical', 'Clinical Data', 'Code', 'Communities', 'Computerized Medical Record', 'Computerized Patient Records', 'Data', 'Data Element', 'Data Set', 'Databases', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Dyslipidemias', 'Effectiveness', 'Enrollment', 'Epidemiology', 'Ethnic Origin', 'Exclusion Criteria', 'Eye', 'Eye diseases', 'Foundational Skills', 'Frequencies', 'Future', 'Goals', 'Handedness', 'Hypertension', 'Incidence', 'Information Centers', 'Injections', 'Intervention', 'Lasers', 'Lead', 'Light Coagulation', 'Manuals', 'Masks', 'Measures', 'Medicare claim', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Operative Surgical Procedures', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Prediction of Response to Therapy', 'Prevalence', 'Prevalence Study', 'Procedures', 'Protocols documentation', 'Public Health Informatics', 'Randomized Controlled Trials', 'Regimen', 'Research', 'Research Proposals', 'Resources', 'Retina', 'Risk Factors', 'Scientist', 'Severities', 'Sleep Apnea Syndromes', 'Smoking Status', 'Source', 'Standardization', 'Structure', 'System', 'Test Result', 'Text', 'Time', 'Training', 'Treatment Protocols', 'Treatment outcome', 'Universities', 'Use Effectiveness', 'Validation', 'Vascular Endothelial Growth Factors', 'Veterans', 'Visual', 'Visual Acuity', 'Washington', 'automated algorithm', 'bevacizumab', 'career', 'clinical care', 'clinical encounter', 'clinical epidemiology', 'cohort', 'comparative', 'computer science', 'diabetes management', 'diabetic', 'epidemiology study', 'hands-on learning', 'health administration', 'intravitreal injection', 'kidney dysfunction', 'laser photocoagulation', 'macula', 'macular edema', 'mortality', 'proliferative diabetic retinopathy', 'screening', 'skills', 'statistics', 'therapy outcome', 'traditional therapy', 'treatment optimization', 'unstructured data']",NEI,UNIVERSITY OF WASHINGTON,K23,2020,238049,0.020022855794244367
"Multicenter Study of the Emergency Department Trigger Tool Existing methods for surveillance of patient harm in the ED setting are inadequate, without any meaningful change in decades. Trigger tools, popularized by the Institute for Healthcare Improvement’s Global Trigger Tool, have been developed for multiple clinical areas and are used across the world, outperform traditional approaches for surveillance of adverse events. These tools use a two-tiered review process where a nurse screens records for triggers (predefined findings that make the presence of an AE more likely) and reviews records with triggers for AEs, discarding those without triggers. We developed a consensus-based ED trigger tool (EDTT) using a multicenter, transdisciplinary modified Delphi approach, subsequently pilot testing this in a multicenter fashion with encouraging results. This was followed by a recently completed, AHRQ-funded single center study to automate, refine and validate this tool. This study demonstrated that the EDTT is a high-yield and efficient instrument for identifying adverse events in the ED. The present study will evaluate the refined, automated EDTT), in a multicenter study. We will evaluate the EDTT’s generalizability and robustness at three sites with large emergency departments, with a planned in-depth review of 9,000 ED admissions. We will use natural language processing of electronic medical record narratives and machine learning to improve the EDTT efficiency in trigger detection and AE discovery. We will establish the basis for a wider use and prepare for scalability and usability of the tool, creating standardized, streamlined and free online training materials, and by evaluating the tool in a real-world manner consistent with intended use. Project Narrative Commonly used approaches in Emergency Departments to detect adverse events are low yield and have not changed in decades, providing inadequate surveillance for patient harm. The need for improved methodology is critical, given the evolving role of the emergency department in the health care system. Trigger tools, developed for use in many healthcare settings across the world, detect all-cause harm, helping direct resources by identifying areas of risk and allowing an assessment of the effectiveness of quality improvement efforts over time. Trigger tools involve screening of records by a nurse for triggers (findings that make an adverse event more likely) and a review of only records with triggers searching for adverse events. Any events identified undergo confirmatory physician review. We developed a trigger tool for the ED, applying rigorous methods to identify predictive triggers, to computerize the screen for triggers eliminating manual review and improving record selection to enhance yield and efficiency. This tool demonstrates superior performance for detecting adverse events. We will now test this tool in a multicenter project to evaluate its broad application, confirming its utility and to continue to improve its yield and efficiency in adverse event detection by applying natural language processing and machine learning techniques.",Multicenter Study of the Emergency Department Trigger Tool,10098792,R01HS027811,[' '],AHRQ,WASHINGTON UNIVERSITY,R01,2020,398528,0.015996190074859203
"Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration Project Summary Diagnostic imaging costs $100 billion annually. These healthcare costs are expected to increase in the coming decade as the national population ages and the pool of insured patients increases. The size and growth of these costs concern policy makers, payers, and society alike. The use of advanced imaging for PE has increased 27 fold in recent years, and this sharp escalation has the potential to expose patients to unnecessary procedures, tests, and risks due to incidental findings. Although radiologists do not order most radiology exams, these physicians are the target of criticism about the rising costs and possible overuse of radiology services. The healthcare industry has called upon radiologists to manage the potential overuse of advanced imaging and to take the lead on investigating best practices for the optimal use of advanced imaging. The ideal sources of information for imaging utilization guidelines are randomized, controlled imaging clinical trials. However, these trials are cost and time intensive, exceedingly difficult to conduct, and typically use narrow patient-inclusion criteria, making it challenging to generalize the results to broader clinical situations. Alternative sources of reliable evidence, such as observational or retrospective studies, have been lacking. The widespread adoption of electronic medical records (EMRs) and the increasing availability of computational methods to process vast amounts of unstructured information now make it possible to learn directly from practice-based evidence. We propose that “big data” clinical repositories, including radiology reports, can lend themselves to a treasure trove of point-of-care, relevant, actionable data that can be used in an innovative and cost-sensitive approach to evaluate the appropriate use of medical imaging. We aim to create a predictive model that leverages real-time EMR clinical data from top national medical centers to arrive at a patient-specific imaging outcome prediction. We recognize that clinicians have to make on-the-spot medical imaging-ordering decisions and they generally do not comply with existing clinical decision support rules. Our study aims to provide clinicians with a tool that can leverage aggregate patient data for medical imaging decision making at the point of care. The overarching approach of this study is to utilize scalable methodology that can be widely applied to leverage EMR data to predict the outcome of a several other high-cost, low-yield imaging tests. This proposal has the potential to better inform advanced imaging in the learning healthcare system of the future and reduce unnecessary imaging examinations and healthcare costs. Project Narrative Imaging costs make up a significant proportion of health care expenditures and cause concern among policy makers, insurers, and patients alike; the inappropriate use of imaging technology is in part a result of imperfect risk models for imaging clinical decision support tools. Current risk models are often irrelevant to patients and as such, clinicians do not always heed to these recommendations, which in turn leads to unnecessary treatments and increased costs. We propose to create a precision health predictive model that leverages real-time electronic medical record data to arrive at a patient-specific imaging prediction in order to enhance imaging decision making at the point of care and optimize advanced image utilization.",Deep Learning for Pulmonary Embolism Imaging Decision Support: A Multi-institutional Collaboration,9926311,R01LM012966,"['Academic Medical Centers', 'Acute', 'Adoption', 'Affect', 'Age', 'Big Data', 'Biometry', 'Caring', 'Cigarette', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Trials', 'Collaborations', 'Communities', 'Comparative Effectiveness Research', 'Computerized Medical Record', 'Computing Methodologies', 'Data', 'Databases', 'Decision Making', 'Decision Support Model', 'Diagnostic Imaging', 'Engineering', 'Environment', 'Epidemiology', 'Evidence based practice', 'Exposure to', 'Future', 'Generations', 'Gold', 'Growth', 'Guidelines', 'Health Care Costs', 'Health Expenditures', 'Healthcare Industry', 'Healthcare Systems', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Imaging technology', 'Immune System Diseases', 'Incidental Findings', 'Informatics', 'Institution', 'Insurance Carriers', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical center', 'Medicare', 'Mentors', 'Methodology', 'Modeling', 'Obesity', 'Observational Study', 'Outcome', 'Patients', 'Phenotype', 'Physicians', 'Policy Maker', 'Population', 'Precision Health', 'Pregnancy', 'Principal Investigator', 'Process', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Randomized', 'Recommendation', 'Reporting', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Scanning', 'Services', 'Societies', 'Source', 'Spottings', 'Testing', 'Time', 'Unnecessary Procedures', 'Work', 'X-Ray Computed Tomography', 'aged', 'base', 'biomedical informatics', 'chemotherapy', 'clinical data warehouse', 'clinical decision support', 'clinical imaging', 'cohort', 'cost', 'deep learning', 'diagnosis standard', 'flexibility', 'imaging study', 'improved', 'inclusion criteria', 'informatics tool', 'innovation', 'insight', 'learning strategy', 'lung imaging', 'model building', 'mortality', 'new technology', 'outcome prediction', 'patient oriented', 'payment', 'personalized risk prediction', 'point of care', 'precision medicine', 'predictive modeling', 'pressure', 'radiologist', 'support tools', 'tool', 'unnecessary treatment']",NLM,STANFORD UNIVERSITY,R01,2020,348620,0.0186095705833408
"Collaborative Research: Statistical algorithms for anomaly detection and patterns recognition in patient care and safety event reports Medical errors have been shown to be the third leading cause of death in the United States. The Institute of Medicine and several state legislatures have recommended the use of patient safety event reporting systems (PSRS) to better understand and improve safety hazards. Numerous healthcare providers have adopted these systems, which provide a framework for healthcare provlder staff to report patient safety events. Public databases like MAUDE and VAERS have also been created to collect and trend safety events across healthcare systems. A patient safety event (PSE) report generally consists of both structured and unstructured data elements. Structured data are pre-defined, fixed fields that solicit specific information about the event. The unstructured data fields generally include a free text field where the reporter can enter a text description of the event. The text descriptions are often a rich data source in that the reporter ls not constrained to limited categories or selection options and is able to freely descrlbe the details of the event. The goal of this project is to develop novel statistical methods to analyze unstructured text like patient safety event reports arising in healthcare, which can lead to significant improvements to patient safety and enable timely intervention strategies. We address three problems: (a) Building realistic and meaningful baseline models for near misses, and detecting systematic deterioration of adverse outcomes relative to such baselines; (b) Understanding critical factors that lead to near misses & quantifying severity of outcomes; and (c) ldentifylng document groups of interest. We will use novel statistical approaches that combine Natural Language Processing with Statistical Process Monitoring, Statistical Networks Analysis, and Spatio-temporal Modeling to build a generalizable toolbox that can address these issues in healthcare. An important advantage of our research team is the involvement of healthcare domain experts and access to frontline staff, and we will leverage this strength to develop our algorithms. A key feature of our work is the generalizability of our methods, which will be applicable to biomedical documents arising across a remarkable variety of areas, such as patient safety and equipment malfunction reports, electronic health records, adverse drug or vaccine reports, etc. We will also release open source software via R packages & GitHub, which will enable healthcare staff and researchers to execute our methods on their datasets. Estimates of preventable adverse events in healthcare are staggering, despite the frequently cited Institute of Medicine (IOM) report that first brought attention to the problem over ten years ago. Identifying temporal trends and patterns in the data is particularly important to improving patient safety and patient care. Using our algorithms to effectively analyze documents from reporting systems has the potential to dramatically improve the safety and quality of care by exposing possible weaknesses in the care process.",Collaborative Research: Statistical algorithms for anomaly detection and patterns recognition in patient care and safety event reports,10211805,R01LM013309,"['Address', 'Adopted', 'Adverse event', 'Algorithms', 'Area', 'Attention', 'Caring', 'Categories', 'Cause of Death', 'Computer software', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Deterioration', 'Electronic Health Record', 'Equipment Malfunction', 'Event', 'Goals', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Institute of Medicine (U.S.)', 'Interest Group', 'Intervention', 'Lead', 'Medical Errors', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Process', 'Quality of Care', 'Report (document)', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Statistical Algorithm', 'Statistical Computing', 'Statistical Methods', 'System', 'Text', 'Time', 'Time trend', 'United States', 'Vaccines', 'Work', 'adverse outcome', 'hazard', 'improved', 'novel', 'open source', 'patient safety', 'spatiotemporal', 'structured data', 'trend', 'unstructured data']",NLM,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2020,278731,0.01142592337127292
"Automated Data Collection on Antimicrobial Use in Dogs and Cats in a Tertiary Hospital and Private Practices Judicious antimicrobial use in veterinary medicine is important because improper antimicrobial use can contribute to the evolution of antimicrobial resistance in bacterial pathogens, which makes subsequent use of these drugs less effective in both human and veterinary medicine. There is very little on-the-ground information about veterinary clinicians’ antimicrobial use (AMU) practices in companion animal practice in the US. veterinary medicine. To improve our understanding of antimicrobial use in dogs and cats, we propose to create a nationwide digital surveillance system to collect critical AMU data using existing electronic practice information management systems (PIMS) in collaboration with veterinary industry partners. The system will automatically harvest AMU and patient data from digital PIMS. The proposed system will harvest data collected in routine veterinary examinations from existing PIMS systems and therefore will not require any additional effort from practitioners to participate in the program. Natural language processing, a machine learning method used to classify unstructured text, will be used to review electronic medical records to determine patients’ diagnosis. We aim to prototype the system in our native digital PIMS at North Carolina State University’s College of Veterinary Medicine Teaching hospital. We will then enroll additional private veterinary practices, including general practice, specialty hospitals, and emergency clinics, as sentinels and collect the same detailed PIMS data from a more representative set of clinics. Working closely with the sentinel clinics will provide a deep understanding of how our system operates in private clinics, and in the final stage we aim to expand the fully automated system to PIMS nationwide. The combination of sentinel clinics with the nationwide survey of clinics will create a powerful broad and deep surveillance system for antimicrobial use in veterinary clinics. A broad suite of AMU parameters will be estimated from this data, and the results reported to the FDA in an annual report. Additionally, we will share the data with other researchers through an web-based portal and GitHub repositories. This system will provide the critical data and analysis to understand veterinary AMU in the US. NARRATIVE Veterinarians play a central role in protecting animal and human health by preserving the efficacy of the antibiotics that their use for their patients. We have created a partnership among a public university, private veterinary hospitals, and a leading industry partner to collect information on how antibiotics are being used in cat and dog practices across the country with no disruption to the participating hospitals. The data will support FDA’s commitment to promoting antimicrobial stewardship.",Automated Data Collection on Antimicrobial Use in Dogs and Cats in a Tertiary Hospital and Private Practices,10166402,U01FD007057,[' '],FDA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,U01,2020,199999,-0.0005708482879042372
"Prediction of Clinical Deterioration Using a Bayesian Belief System Project Summary/Abstract Approximately 5-10% of hospitalized patients suffer significant clinical deterioration after admission, resulting in either transfer to the intensive care unit (ICU) or a ""code"" event (i.e., cardiac or pulmonary arrest). Delayed identification of these events result in increased morbidity and mortality. Unfortunately, existing prediction models result in multiple false alarms for every true positive alarm that they generate. In addition with every passing year, new monitoring systems are introduced that generate more false alarms, resulting in alarm fatigue which has been associated with patient deaths. The objective of this mentored career development proposal is to develop and assess novel computational algorithms that can predict the clinical deterioration of hospitalized patients earlier and more accurately than clinicians or conventional early warning systems, thereby allowing for timely intervention. Building upon our experience in the hematologic malignancy subpopulation of hospitalized patients, this new effort: 1) provides a foundation upon which to combine newer machine learning (ML) methods and clinical informatics to improve the capabilities of the model for an individual patient or specific subgroup; 2) assesses the impact and value of different variables from the electronic medical record (EMR) as part of the predictive model; and 3) broadens the evaluation of this approach to additional real-world patient populations, enabling insight into the translation of the models to clinical usage. The specific aims of this project are thus: Specific Aims Aim 1 To identify and extract model variables (features) from the EMR, evaluating different feature selection  methods to optimize different predictive criterion and their impact on ML algorithms. Aim 2 To develop an ML approach that handles multiple asynchronous data streams of longitudinal  information from the EMR, providing predictions on clinical deterioration in real-time. Aim 3 To explore clinician and rapid response team responses to early prediction of clinical deterioration. With successful completion of this proposal, the prediction model will be integrated into the EMR system. Future direction as part of a R01 proposal will involve external validation at other institutions and assessment of clinical impact on patient care. Relevance to Public Health Clinical deterioration in the hospital is often unexpected and is associated with increased mortality and morbidity, with the CDC reporting 17.2 million hospital admissions through the emergency department in 2010 suggesting that approximately 1 million people annually are at risk of clinical deterioration during their hospitalization. Existing early warning systems have not been able to accurately predict these events without creating an overwhelming amount of additional false positive alarms, resulting in alarm fatigue and potential harm. Our project, utilizing machine learning techniques with the large amount of available clinical data, will serve to develop a predictive model that can predict clinical deterioration earlier with a higher positive predictive value than current algorithms/models which, when implemented, will be able to provide hospitalized patients with an additional safety net.",Prediction of Clinical Deterioration Using a Bayesian Belief System,9999034,K01LM012873,"['Accident and Emergency department', 'Admission activity', 'Algorithms', 'Belief System', 'Cardiac', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical assessments', 'Code', 'Computational algorithm', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Set', 'Deterioration', 'Discipline of Nursing', 'Ensure', 'Evaluation', 'Event', 'Fatigue', 'Foundations', 'Future', 'Genes', 'Health Personnel', 'Heart Arrest', 'Hematologic Neoplasms', 'Hospitalization', 'Hospitals', 'Inpatients', 'Institution', 'Intensive Care Units', 'Intervention', 'Learning', 'Lung', 'Machine Learning', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Nature', 'Patient Care', 'Patients', 'Performance', 'Population', 'Predictive Value', 'Public Health', 'Reporting', 'Research', 'Risk', 'Science', 'Specificity', 'Subgroup', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translating', 'Translations', 'United Kingdom', 'United States', 'Validation', 'Work', 'Workload', 'base', 'biomedical informatics', 'burnout', 'career development', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinical predictors', 'clinical risk', 'cohort', 'computer science', 'data streams', 'experience', 'feature selection', 'improved', 'individual patient', 'insight', 'machine learning algorithm', 'machine learning method', 'mental state', 'mortality', 'novel', 'patient population', 'predictive modeling', 'prevent', 'response', 'safety net', 'skills']",NLM,UNIVERSITY OF CALIFORNIA LOS ANGELES,K01,2020,205524,0.0012517661415633646
"Clinical Biomechanics of Hip Fracture Over 300,000 hip fractures occur each year in the U.S. and up to 25% of hip-fracture patients die within a year of their injury. Despite the importance of this clinical problem, the diagnostic screening rate for osteoporosis is only 5% of the eligible population, and the sensitivity of measuring bone mineral density (BMD) by DXA, the clinical standard test for diagnosis, is only 50%. Therefore, most patients are not being screened diagnostically for osteoporosis, and for those who are, about half who will experience a hip fracture are missed. Given that the current empirical approach is inadequate, we propose to pursue a more mechanistic approach, combining state-of-the-art biomechanics and machine learning approaches. Biomechanically, the three etiological elements of hip fracture are fall risk, femoral strength, and femoral impact force. In this project, our overall goal is to provide a deeper understanding of how all three biomechanical etiological elements interact in the event of a hip fracture and from that, directly improve clinical fracture risk assessment through the use of a single predictive “Integral Biomechanical Risk (IBR)” parameter. In addition, we will also address the problem of low DXA screening rates by further developing our Biomechanical Computed Tomography (BCT) technology. This test estimates the breaking strength of the femur using finite element analysis of routine clinical CT scans previously acquired for any medical reason, and represents an improvement compared to the use of BMD alone. Since millions of patients are scanned with CT each year, this approach could double screening rates if offered as an alternative to DXA. The proposed study will investigate this biomechanical approach in a large incident hip fracture, case-cohort study (3,000 patients with hip fracture, 6,000 without). This retrospective study will include patients seen at Kaiser Permanente who had an abdominal CT scan as part of medical care prior to any hip fracture; and have standard geriatric measurements in their electronic medical records, which we will use to estimate fall risk. Specifically, our aims are to: 1) utilize electronic medical record data and CT scans to obtain patient-specific measurements related to fall risk, femoral strength, and fall severity, and 2) combine the different elements of hip fracture etiology into the IBR parameter to test the hypothesis that this metric predicts hip fracture independent of age, sex, BMI, race/ethnicity, and history of prior fracture and improves hip fracture prediction compared to the clinical standard (BMD with FRAX). Scientifically, a major novelty of this work is its use of contemporary machine learning algorithms to inform construction of a mechanistic model of the three etiological elements of hip fracture, which should better capture any interactions between these elements compared to a purely statistical-regression approach. In addition, the study cohort will be the largest and most diverse CT-based hip fracture cohort ever assembled. Importantly, positive results from this project would provide a compelling “second front” to DXA that could be quickly translated to widespread clinical practice, profoundly impacting osteoporosis care. STATEMENT OF RELEVANCE More than half of individuals who experience hip fracture do not have osteoporosis as assessed by DXA. This project draws together the latest technological advances in CT-based finite element modeling and combines it into a probabilistic model of fracture risk that uses as inputs, data typically available in medical records. By going beyond BMD, the fracture risk prediction tool developed by this work aims to significantly improve clinical fracture risk assessment and substantially impact the preventative care and treatment of osteoporosis.",Clinical Biomechanics of Hip Fracture,9886227,R01AR074958,"['Accounting', 'Address', 'Age', 'Algorithms', 'Archives', 'Biomechanics', 'Blinded', 'Bone Density', 'Calibration', 'Caring', 'Clinical', 'Clinical Data', 'Clinical assessments', 'Cohort Studies', 'Complex', 'Computerized Medical Record', 'Data', 'Diagnosis', 'Discrimination', 'Dual-Energy X-Ray Absorptiometry', 'Economics', 'Elderly', 'Elements', 'Ensure', 'Equilibrium', 'Ethnic Origin', 'Etiology', 'Evaluation', 'Event', 'Fatty acid glycerol esters', 'Femur', 'Finite Element Analysis', 'Fracture', 'Goals', 'Health', 'Hip Fractures', 'Individual', 'Injury', 'Intramuscular', 'Investigation', 'Logistics', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Modeling', 'Muscle', 'Osteoporosis', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Preventive care', 'Preventive treatment', 'Probability', 'Race', 'Recording of previous events', 'Regression Analysis', 'Retrospective Studies', 'Risk', 'Risk Assessment', 'Risk Factors', 'Scanning', 'Severities', 'Shapes', 'Spatial Distribution', 'Statistical Models', 'Technology', 'Testing', 'Thick', 'Tissues', 'Training', 'Translating', 'Validation', 'Weight', 'Work', 'X-Ray Computed Tomography', 'abdominal CT', 'base', 'biomechanical model', 'bone', 'bone strength', 'clinical practice', 'clinical risk', 'clinical translation', 'cohort', 'diagnostic screening', 'ductile', 'electronic data', 'experience', 'fall risk', 'falls', 'fracture risk', 'high risk', 'hip bone', 'improved', 'indexing', 'insight', 'kinematics', 'machine learning algorithm', 'neuromuscular', 'older patient', 'patient health information', 'screening', 'sex', 'soft tissue', 'standing height', 'theories', 'tool']",NIAMS,"O. N. DIAGNOSTICS, LLC",R01,2020,647058,0.017090585017014014
"Collaborative Research: Statistical Algorithms for Anomaly Detection and Patterns Recognition in Patient Care and Safety Event Reports Project Summary Medical errors have been shown to be the third leading cause of death in the United States. The Institute of Medicine and several state legislatures have recommended the use of patient safety event reporting systems (PSRS) to better understand and improve safety hazards. A patient safety event (PSE) report generally consists of both structured and unstructured data elements. Structured data are pre-defined, fixed fields that solicit specific information about the event. The unstructured data fields generally include a free text field where the reporter can enter a text description of the event. The text descriptions are often a rich data source in that the reporter is not constrained to limited categories or selection options and is able to freely describe the details of the event. The goal of this project is to develop novel statistical methods to analyze unstructured text like patient safety event reports arising in healthcare, which can lead to significant improvements to patient safety and enable timely intervention strategies. We address three problems: (a) Building realistic and meaningful baseline models for near misses, and detecting systematic deterioration of adverse outcomes relative to such baselines; (b) Understanding critical factors that lead to near misses & quantifying severity of outcomes; and (c) Identifying document groups of interest. We will use novel statistical approaches that combine Natural Language Processing with Statistical Process Monitoring, Statistical Networks Analysis, and Spatio-temporal Modeling to build a generalizable toolbox that can address these issues in healthcare. We will also release open source software via R packages & GitHub, which will enable healthcare staff and researchers to execute our methods on their datasets. The COVID-19 pandemic has resulted in increased patient volumes and increased patient acuity, leading to an excessive burden on many healthcare facilities across the United States. This greatly increases the risk of patient safety consequences arising from malfunctioning medical equipment or adverse reaction to medication. To ensure patient safety and the highest quality of healthcare during this crisis, we need a rapid response system to model and analyze COVID-specific safety issues at scale, and quickly disseminate the results to healthcare facilities, so that these risks can be mitigated at the point of care. In this supplement, we propose to do this by (a) mining public databases and EHRs to identify devices/medication being used for treating COVID and (b) applying our methods (based on NLP, SPC, and SPM) to understand risks associated with these items. This information will be disseminated nationally to all healthcare facilities so that it can be integrated into the EHR at the point of care to alert clinicians. Project Narrative Estimates of preventable adverse events in healthcare are staggering, and the risk is particularly high for COVID patients due to the rapidly increasing burden on healthcare facilities. Using our algorithms to identify temporal trends and analyze free text narratives from reporting systems can ensure the safety and quality of care for COVID patients by exposing and mitigating possible weaknesses in the care process.",Collaborative Research: Statistical Algorithms for Anomaly Detection and Patterns Recognition in Patient Care and Safety Event Reports,10254593,R01LM013309,"['Address', 'Adverse event', 'Adverse reactions', 'Algorithms', 'Architecture', 'Behavior', 'COVID-19 pandemic', 'Caring', 'Categories', 'Cause of Death', 'Computer software', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Detection', 'Deterioration', 'Devices', 'Disease Outbreaks', 'English Language', 'Ensure', 'Equipment', 'Equipment Malfunction', 'Event', 'Goals', 'Health', 'Health care facility', 'Healthcare', 'Institute of Medicine (U.S.)', 'Interest Group', 'Intervention', 'Investigation', 'Lead', 'Length', 'Measures', 'Medical', 'Medical Errors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Natural Language Processing', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Prevalence', 'Process', 'Property', 'Quality of Care', 'Records', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Severities', 'Side', 'Site', 'Statistical Algorithm', 'Statistical Computing', 'Statistical Methods', 'Statistical Models', 'Supervision', 'System', 'Techniques', 'Text', 'Time', 'Time trend', 'United States', 'Variant', 'Vocabulary', 'adverse outcome', 'base', 'checkup examination', 'cluster computing', 'coronavirus disease', 'dosage', 'hazard', 'health care quality', 'health care service', 'health care service organization', 'improved', 'insight', 'interest', 'mathematical model', 'novel', 'open source', 'patient safety', 'point of care', 'response', 'service delivery', 'spatiotemporal', 'structured data', 'trend', 'unstructured data']",NLM,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2020,74963,0.007502513235279676
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9838247,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Source', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'patient health information', 'population based', 'prevent', 'sociodemographics', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2020,768763,0.02746559174005015
"Accelerating research to advance care for adults with congenital heart disease through development of validated scalable computational phenotypes PROJECT SUMMARY The advent of surgery to treat congenital heart disease (CHD) in the second half of the 20th century shifted the care paradigm from palliation of disease fatal in infancy to management of lifelong chronic disease through adulthood. There are now more than 1.5 million adults with CHD living in the United States. These patients have a substantial burden of cardiovascular and other medical comorbidities, as well as markedly increased risk for adverse outcomes such as arrhythmia, heart failure, cerebrovascular accident, and premature death. The emergence of this population requires new clinical care models as well as the development of novel research tools and infrastructures to address these patients' unique characteristics and healthcare needs. Adult CHD is characterized by substantial complexity, era-dependent heterogeneity in treatment strategies, and time-varying implications of lifelong disease. This burgeoning population is understudied, and the pathophysiology of the component diseases remains incompletely understood. Billing and other administrative codes available in the electronic medical record are neither sensitive nor specific for CHD diagnosis and do not adequately describe many other salient clinical features. As a result, structured data in large administrative databases are not well suited to studying adults with CHD, even when the goal is simply to identify a cohort of patients with a given diagnosis. This constitutes a major impediment to research efforts and is the primary barrier underlying the limited population-based research performed to date. Adult CHD investigation would benefit immensely from methods to establish harmonized, large-scale, multi-center datasets. While billing codes are inadequate, the information needed to accurately classify adults with CHD is already available in the electronic medical record in the form of clinical notes, comprised mainly of unstructured (“free”) text. Manual data extraction is laborious, resource intensive, and, therefore, not scalable. We propose to apply cutting-edge natural language processing approaches to unstructured text in the electronic medical record to develop computable classifiers for variables fundamental to the study of adults with CHD. We will use two unique institutional data resources at Boston Children's Hospital and Brigham and Women's Hospital that are already populated with expert-adjudicated labels to train classifiers for key phenotypes that are poorly defined by administrative codes. These classifiers will be validated in an independent patient cohort at Vanderbilt University Medical Center and tested in new disease-specific risk prediction models. This work promises to accelerate CHD research by massively increasing the scale of the patient cohorts that can be studied and by establishing a foundation for improved evidence-based decision support for this underserved population. PROJECT NARRATIVE Administrative billing codes are inadequate to support research for adults with congenital heart disease, a growing but understudied population with a high burden of medical comorbidities. To advance high quality research towards much-needed innovations in clinical care for these patients, we plan to develop novel methods for the creation of harmonized, large-scale, multi-center datasets that will expand and enhance collaborative research efforts.",Accelerating research to advance care for adults with congenital heart disease through development of validated scalable computational phenotypes,9946462,R01HL151604,"['Academic Medical Centers', 'Address', 'Adult', 'Algorithms', 'Architecture', 'Arrhythmia', 'Atrial Heart Septal Defects', 'Boston', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caring', 'Cessation of life', 'Characteristics', 'Child', 'Chronic', 'Chronic Disease', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Diagnostic Specificity', 'Disease', 'Eisenmenger Complex', 'Foundations', 'Functional disorder', 'Goals', 'Health', 'Healthcare', 'Heart', 'Heart failure', 'Heterogeneity', 'Hospitals', 'ICD-9', 'Incidence', 'Infrastructure', 'Intervention', 'Investigation', 'Label', 'Life', 'Lung', 'Manuals', 'Medical', 'Medical Informatics', 'Medical center', 'Methods', 'Modeling', 'Natural Language Processing', 'New York', 'Nomenclature', 'Operative Surgical Procedures', 'Outcome', 'Patient Care', 'Patient Monitoring', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phenotype', 'Play', 'Population', 'Population Research', 'Positioning Attribute', 'Public Health', 'Publishing', 'Regimen', 'Research', 'Research Support', 'Resources', 'Risk', 'Role', 'Stroke', 'Testing', 'Text', 'Thromboembolism', 'Time', 'Training', 'Transposition of Great Vessels', 'Underserved Population', 'United States', 'Validation', 'Vascular Diseases', 'Visit', 'Woman', 'Work', 'adjudicate', 'administrative database', 'adverse outcome', 'base', 'biobank', 'clinical care', 'clinical data warehouse', 'clinical database', 'clinical decision support', 'clinical phenotype', 'clinically actionable', 'cohort', 'comorbidity', 'computable phenotypes', 'congenital heart disorder', 'data resource', 'design', 'disease diagnosis', 'evidence base', 'experience', 'high risk', 'improved', 'infancy', 'innovation', 'large scale data', 'large-scale database', 'mortality', 'multitask', 'neural network', 'neural network classifier', 'novel', 'outcome forecast', 'palliation', 'patient population', 'population based', 'predict clinical outcome', 'predictive modeling', 'premature', 'prospective', 'repaired', 'risk prediction model', 'structured data', 'tool', 'treatment strategy']",NHLBI,CINCINNATI CHILDRENS HOSP MED CTR,R01,2020,784220,0.016524412338722417
"Maternal Morbidity and Mortality: Risk Factors, Early Detection and Personalized Intervention PROJECT ABSTRACT  In the U.S., from 2011 to 2014, 7,208 maternal fatalities, with the trend worsening year-on-year (CDC, 2016). In addition to the 700+ fatalities, at least 50,000 woman experienced life-threatening complications, annually. According to CDC (2019) for every fatality, 70 more women suffer avoidable, traumatic complications as a result of pregnancy.  Medstar Health Research Institute and Invaryant, Inc, propose the evaluation of a cardiac risk assessment tool for pregnant and postpartum women; this tool updates automatically directly from patient medical records; wearable devices; and patient surveys. Success implies disruptive improvement in women's health. Proposed research involves three key elements: technology, data, and social determinants of health (SDOH) using geospatial mapping of patient locations. Technology: Study technology shall be based on the Invaryant Health Platform (IHP), a technology that automatically ingests data, from medical records, wearable devices, and other sources using proprietary AI based interoperability technology called Mesh-Complex Method Exchange (Mesh-CMX). We propose using the IHP in conjunction with novel prototype-level technology, namely Healthy Outcomes for all Pregnancy Experiences-Cardiovascular-risk Assessment Technology (HOPE-CAT) and the Invaryant machine learning technologies to monitor the patient, based on signals, out-of-range “trip-wires”, and trends in the mother's health data that merit medical intervention. By extending the proof of concept into an early commercial version of the software, and integrating it to the IHP which will automatically update changes in the patient's medical record, we will provide an “early warning” system for mothers and their providers. Data: The study will be tested on patients' medical records using the MedStar's Analytics Platform (MAP), a registry of over 5 Million unique patients. The tool will subsequently have the potential to be leveraged to over 90 million medical records for the MedStar and Cerner hospital systems, distilled down to meet specific eligibility criteria including, gender, age, race, pregnancy and medical outcomes. A second phase of this project would take the findings from the retrospective study (this grant request) and use the technology within the Medstar hospital system, to validate the efficacy of the findings in a “real-world setting”. Using our proprietary AI technology, we will compare each mother's progress against a cohort of retrospective data to enhance diagnostics and provide real-time feedback to caregivers and patients. Geospatial mapping: Mapping the patient medical record and the health information to their social setting is vital for understanding the underlying social constructs that affect the health of mothers in different regions. PROJECT NARRATIVE Medstar Health Research Institute and Invaryant, Inc. propose the evaluation of a cardiovascular risk assessment tool (HOPE-CAT) for pregnant and postpartum women utilizing technology, data, and social determinants of health (SDoH) with geospatial mapping. HOPE- CAT, in conjunction with Invaryant's health platform and machine learning technologies, will monitor the patient based on signals, out-of-range ""trip-wires"", and trends in health data. HOPE-CAT will be validated on patient medical records using MedStar's Analytics Platform (MAP), a registry of over 5 million unique patients.","Maternal Morbidity and Mortality: Risk Factors, Early Detection and Personalized Intervention",10200448,UL1TR001409,"['Affect', 'Age', 'Assessment tool', 'Behavioral', 'California', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Centers for Disease Control and Prevention (U.S.)', 'Complex', 'Computer software', 'Data', 'Database Management Systems', 'Diagnostic', 'Discipline of obstetrics', 'Early Diagnosis', 'Eclampsia', 'Elements', 'Eligibility Determination', 'Epidemiology', 'Evaluation', 'Feedback', 'Gender', 'Grant', 'Health', 'Healthcare Systems', 'Hemorrhage', 'Hospitals', 'Individual', 'Intervention', 'Life Experience', 'Location', 'Machine Learning', 'Maternal Mortality', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Mothers', 'Outcome', 'Patient Monitoring', 'Patients', 'Phase', 'Postpartum Women', 'Pre-Eclampsia', 'Pregnancy', 'Pregnant Women', 'Provider', 'Race', 'Registries', 'Research', 'Research Institute', 'Retrospective Studies', 'Retrospective cohort', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sepsis', 'Signal Transduction', 'Socioeconomic Status', 'Source', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Update', 'Urban Population', 'Woman', 'Women&apos', 's Health', 'advanced analytics', 'base', 'cardiovascular disorder risk', 'cardiovascular risk factor', 'data ingestion', 'ethnic diversity', 'experience', 'health data', 'health of the mother', 'high risk', 'indexing', 'interoperability', 'maternal morbidity', 'maternal risk', 'mortality', 'mortality risk', 'novel', 'patient health information', 'personalized intervention', 'prototype', 'screening', 'social', 'social health determinants', 'sociodemographics', 'socioeconomics', 'success', 'tool', 'trend', 'venous thromboembolism', 'wearable device']",NCATS,GEORGETOWN UNIVERSITY,UL1,2020,146537,0.03263484587983436
"Improving Adverse Event Reporting on Cooperative Oncology Group Trials PROJECT SUMMARY/ABSTRACT Background: The reports of side effects on clinical trials describe expected toxicities of chemotherapy. However, these side effects, also called adverse events, are globally under-reported on trials, which means that clinicians do not have an accurate sense of adverse event rates. In the current system, adverse events are identified through time-consuming, manual medical record review. This study aims to develop a system that uses electronic medical record data to capture complex adverse events of chemotherapy for pediatric cancer and to prove that this method is more accurate than the current adverse event reporting system. The specific aims of this application are to 1) develop algorithms to identify 10 complex adverse events using electronic medical record data from children treated for acute leukemia at two large children's hospitals, 2) compare the accuracy of this new method to that of the current system, and 3) demonstrate the utility of electronic adverse event capture in answering clinical questions by defining the incidence and risk factors of acute kidney injury. Methods: This study will use data from 1900 children with acute leukemia treated at the Children's Hospital of Philadelphia (CHOP) or the Texas Children's Hospital (TCH) from 2002 through 2017. Algorithms will be developed to identify adverse events by extracting electronic medical record data at CHOP. Once finalized, the algorithms will be tested at TCH. Using chart abstraction data as the gold standard, the accuracy of electronic ascertainment and of trial adverse event reports will determined, and the relative accuracy of each method will be compared. Lastly, algorithms will extract creatinine results from the electronic medical record and the incidence of acute kidney injury will be determined for each leukemia type and by chemotherapy regimen. Risk factors for acute kidney injury will be explored. Career Goals and Environment: With the support of this K07 award, the applicant, Tamara P. Miller, MD, MSCE, will learn how to use electronic medical record data for clinical research, obtain formal training in clinical informatics and implementation science, develop expertise in clinical trial design, and improve her knowledge of pediatric oncology and skills in scientific writing. To complete these training goals, Dr. Miller has assembled an experienced, complementary, and nurturing mentoring team led by her primary mentor, Richard Aplenc, MD, PhD. Her training plan includes formal coursework in informatics, tutorials, national conferences, and research progress and writing groups. She will benefit from the outstanding depth of resources and opportunities at CHOP and the University of Pennsylvania. Her long-term goal is to integrate the novel system of adverse event ascertainment she creates into pediatric oncology trials and to use the accurate datasets she develops to answer clinically important questions. With this award, Dr. Miller will be well-positioned to transition to her goal of an independent clinical research career focused on improving adverse event reporting and supportive care practices in pediatric oncology. PROJECT NARRATIVE Children with cancer experience significant side effects from their treatments, but these side effects are under- reported on clinical trials and no work has been done to improve the current system of side effect reporting. This study will create a new system of identifying and reporting side effects that is more accurate and efficient than the current system. The results of this research will provide clinicians, patients and their families with a true understanding of potential side effects of therapies used to treat childhood cancer.",Improving Adverse Event Reporting on Cooperative Oncology Group Trials,9994848,K07CA211956,"['Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute leukemia', 'Adverse event', 'Age', 'Algorithms', 'Award', 'Chemotherapy-Oncologic Procedure', 'Child', 'Childhood Acute Myeloid Leukemia', 'Childhood Leukemia', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Design', 'Common Terminology Criteria for Adverse Events', 'Complex', 'Computerized Medical Record', 'Consumption', 'Creatinine', 'Data', 'Data Set', 'Doctor of Philosophy', 'Enrollment', 'Environment', 'Ethnic Origin', 'Family', 'Foundations', 'Gender', 'Goals', 'Gold', 'Hospitals', 'Incidence', 'Informatics', 'Knowledge', 'Laboratories', 'Learning', 'Malignant Childhood Neoplasm', 'Manuals', 'Medical Records', 'Mentors', 'Methods', 'National Cancer Institute', 'Natural Language Processing', 'Oncology Group', 'Patients', 'Pediatric Hospitals', 'Pediatric Oncology', 'Pediatric Oncology Group', 'Pennsylvania', 'Pharmaceutical Preparations', 'Philadelphia', 'Positioning Attribute', 'Predictive Value', 'Process', 'Publishing', 'Race', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Safety', 'Sensitivity and Specificity', 'Supportive care', 'System', 'Testing', 'Texas', 'Text', 'Time', 'Toxicity due to chemotherapy', 'Training', 'Treatment Side Effects', 'Universities', 'Work', 'Writing', 'base', 'cancer clinical trial', 'cancer therapy', 'career', 'chemotherapy', 'clinical decision-making', 'clinical epidemiology', 'clinical implementation', 'cohort', 'data pipeline', 'epidemiology study', 'experience', 'implementation science', 'improved', 'leukemia', 'nephrotoxicity', 'novel', 'oncology trial', 'prospective', 'secondary analysis', 'side effect', 'skills', 'statistics', 'symposium']",NCI,EMORY UNIVERSITY,K07,2020,169884,0.025370477919629576
