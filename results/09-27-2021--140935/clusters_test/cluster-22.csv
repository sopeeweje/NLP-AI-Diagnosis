text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"A Network Science Approach to Conflicts of Interest: Metrics, Policies, and Communication Design A Network Science Approach to Conflicts of Interest: Metrics, Policies, and  Communication Design Project Description 1. Overview Research on the effects of conflicts of interest (COI) in biomedical science have long- established, significant causes for concern. For example, industry-funded trials are significantly more likely to return results that support patient use of tested drugs. As early as 2003, a JAMA study of 370 randomized controlled trials found that industry-sponsored studies were 5.3 times more likely to return results favorable to industry.[1] Subsequent research has corroborated these sponsorship effects.[2] Furthermore, funding relationships come in the form of advisory board positions, speaking fees, consulting fees, free lunches, prescription pads, and ink pens, and these smaller, financial relationships also have significant, undesirable effects on biomedical research, including an 8.4 factor increase in the likelihood of results favorable to industry.[3] The primary purpose of this project is to develop new metrics and mechanisms for the evaluation and communication of COI risks in the biomedical research enterprise. The research will use a network science approach to understand the circulation and accumulation of COI in biomedical decision systems. Network science offers an ideal framework for assessing influence within the biomedical research enterprise. The approach also moves beyond understandings of COI as about individual researchers or funders to encompass systemic risk and network-level effects. To advance the science of COI mitigation, this research will improve and enhance a machine-learning-based system that identifies and classifies COI across published disclosure statements. We will apply this system to COI disclosure statements representing the current state of biomedical research for 240 of the most commonly used prescription drug products and distill COI networks for each drug. The team will test candidate COI and COI-network metrics against drug safety data drawn from the Food and Drug Administration's Adverse Events Reporting System. The results will inform the development of new recommendations for COI policies in biomedical research and recommendations for evidence-based disclosure practices. 2. Intellectual Merit 2.1 Significance Given the growing recognition of the problems of COI, many federal agencies, universities, professional medical associations, and biomedical journals have adopted policies to mitigate the potentially harmful effects of these relationships. However, despite the consensus that policy interventions are a necessary and appropriate response, policies are inconsistent.[4] In some cases, institutions have outright bans on any financial relationships with industry. In other cases, institutions have complex requirements for vetting each individual COI. The FDA, for example, assesses each potential advisory committee member COI for “directness” and “predictability.” So, if a potential advisory committee member owns stock in a company that is seeking a new drug approval, regulators can identify a direct and predictable COI (stock values may rise based on the regulatory decision). The most common COI intervention across institutions is some form 12 n/a","A Network Science Approach to Conflicts of Interest: Metrics, Policies, and Communication Design",10202242,R01GM141476,"['Adopted', 'Adverse event', 'Advisory Committees', 'Biomedical Research', 'Blood Circulation', 'Committee Members', 'Communication', 'Complex', 'Conflict of Interest', 'Consensus', 'Consult', 'Data', 'Development', 'Disclosure', 'Drug Prescriptions', 'Evaluation', 'Fees', 'Funding', 'Individual', 'Industry', 'Ink', 'Institution', 'Intervention', 'Journals', 'Machine Learning', 'Medical', 'New Drug Approvals', 'PF4 Gene', 'Patients', 'Pharmaceutical Preparations', 'Policies', 'Positioning Attribute', 'Publishing', 'Randomized Controlled Trials', 'Recommendation', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Science', 'System', 'Testing', 'Time', 'United States Food and Drug Administration', 'Universities', 'base', 'design', 'drug testing', 'evidence based guidelines', 'financial relationship', 'improved', 'medication safety', 'response']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2021,215960
"High Performance Text Mining for Translator We propose to build a knowledge provider that will seek out, integrate and provide AI-ready, BioLink-compatible models via high-performance text-mining of the biomedical literature. Problems with Translator’s current mining of the biomedical literature that we intend to solve include: (1) weaknesses in framework extensibility and benchmarking that make integrating and validating new text-mining approaches difficult; (2) problematic licensing of software, terminologies and other resources that do not adequately support FAIR (and TLC) best practices; (3) processing only PubMed titles and abstracts, not full text publications; (4) Translator’s use of older NLP technology with relatively poor performance; (5) lack of a mechanism for community feedback regarding errors and other problems; (6) lack of continuous updates to add knowledge from new publications; (7) output knowledge representation that is simplistic and vague, failing to reflect the richness of what is expressed in scientific documents. Plan for implementation: Our team has a long history of productive NLP research, successful open source software projects, effective benchmarking and broad community engagement. We will build on the results of NLM-funded work in information extraction, our gold-standard Colorado Richly Annotated Full Text (CRAFT) corpus, a recent BioNLP Open Shared Task (BioNLP-OST) that we organized, and recent advances in state-of-the-art NLP. For Segment 1, we will: (1) Demonstrate BioStacks, an extensible, cloud-based text-mining framework that produces knowledge graphs grounded in the Open Biomedical Ontologies (OBOs). This BioStacks demo will include a state-of-the-art OBO concept recognizer for multiple ontologies, a state-of-the-art semantic relationship prediction tool, and a state-of-the-art structural analysis tool. All generated assertions will have provenance metadata linking the assertion to a particular text span in a document specified by PMCID. (2) Demonstrate CRAFTST, a cloud-based text-mining evaluation system that evaluates the performance of text-mining systems against the CRAFT gold standard. (3) Demonstrate an adaptive machine learning process illustrating how to efficiently create tools to extract BioLink association types. For Segment 2, we propose to extend the text-mining and evaluation frameworks to align with BioLink and the Translator community, improve text-mining quality and expand the collection of source documents mined. Specifically, we propose to target 10 long term milestones: (1) Align CRAFT to BioLink. (2) Develop new tools for extracting associations from text. (3) Develop and manage a community engagement process on text-mining for Translator. (4) Extend benchmarking. (5) Improve recall. (6) Improve precision. (7) Improve computational efficiency. (8) Expand BioStacks to include all available full text biomedical journal articles. (9) Expand document collections to include Patents & Regulatory filings. (10) Develop a scientist-based movement to improve document access for text-mining from non-open publishers. The types of questions the resulting knowledge graph can be used to address are extremely broad, as it is generated by mining a large part of the biomedical literature. Questions that can be answered include those about specific assertions (e.g. is this drug an agonist-activator of this protein?), general relations (are these two proteins often mentioned together?), and documents (which publications mention this gene, mutation and drug?). Integration: We are long-time contributors to the open-science community and have longstanding collaborations with existing awardees; we were participants in the NIH Data Commons Pilot. We propose to align the output of text-mining tools to the BioLink model via OBO terms. We propose to implement our frameworks in NIH Cloud Computing environments. We propose to adopt the CD2H Contributor Attribution Model to foreground community contributions. We plan to coordinate with the NLM’s nascent benchmarking activities and the SmartAPI effort to build Translator standard interfaces. Challenges and gaps: High-performance mining of rich, contextualized knowledge from the literature remains a difficult task, and is unlikely to be solved in the next five years. Many important publications remain inaccessible to text-mining due to restrictive licensing. n/a",High Performance Text Mining for Translator,10334356,OT2TR003422,"['Address', 'Adopted', 'Agonist', 'Benchmarking', 'Cloud Computing', 'Collaborations', 'Collection', 'Colorado', 'Communities', 'Computer software', 'Data Commons', 'Environment', 'Evaluation', 'Feedback', 'Funding', 'Gene Mutation', 'Gold', 'Information Retrieval', 'Knowledge', 'Legal patent', 'Licensing', 'Link', 'Literature', 'Machine Learning', 'Metadata', 'Mining', 'Modeling', 'Movement', 'Ontology', 'Output', 'Participant', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Proteins', 'Provider', 'PubMed', 'Publications', 'Recording of previous events', 'Research', 'Resources', 'Scientist', 'Semantics', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Terminology', 'Text', 'Time', 'United States National Institutes of Health', 'Update', 'Work', 'base', 'biomedical ontology', 'cloud based', 'improved', 'information organization', 'journal article', 'knowledge graph', 'knowledge of results', 'open data', 'open source', 'text searching', 'tool']",NCATS,UNIVERSITY OF COLORADO DENVER,OT2,2021,471239
"The Metadata Powerwash - Integrated tools to make biomedical data FAIR Project Summary  The metadata that describe scientific data are fundamental resources to enable (1) the discovery and reuse of the data and (2) the reproducibility of the experiments that generated the data in the first place. Metadata are essential for scientists to understand the associated data and to reuse them, as well as for information technology to index the data, to make the data available, and to provide filters for scientists to search for the corresponding datasets. Currently, the scientific metadata hosted in public repositories suffer from multiple quality issues that limit scientists’ ability to find and reuse the experimental datasets to which they refer. It can take many weeks of a scientist’s time to identify a collection of datasets that fulfill specific criteria when the data are so poorly described—and the majority of the process is necessarily manual.  We propose to develop an end-to-end solution to standardize biomedical metadata with the help of ontologies—data structures that define the terms in an application domain and the relationships among them. There are hundreds of ontologies that provide standard terms for use in biomedicine, and they are essential resources to make biomedical metadata interoperable and reusable. Our approach also will build on the technology created by the Center for Expanded Data Annotation and Retrieval (CEDAR), which offers a library of building blocks and common data elements for defining computer-based metadata templates based on community standards.  Our plan involves three specific aims. First, we will develop a method and tool to standardize the multiple, ad hoc metadata field names that may appear in metadata to represent the same type of information by replacing those field names with the field names used in standard metadata templates or, if no appropriate template match is available, with terms from a relevant ontology. Second, we will develop methods and tools to standardize different types of metadata field values, for example, categorical values such as drugs or diseases, and numerical values such as age, or sample collection date. Third, we will evaluate the speed, precision, and recall of our metadata transformation pipeline—built out of the methods and tools to standardize field names and values—on a large corpus of metadata that we will manually curate based on existing public metadata. We will also carry out experiments to test the effect of the standardized metadata when biomedical scientists perform dataset search in the context of their work. Project Narrative Data that offer precise descriptions of data—metadata—are critical scientific resources that facilitate the discovery, reuse, and reproducibility of the data to which they refer. Our goal is to create methods and tools that improve the quality of scientific metadata hosted in public repositories, and thus enhance the discoverability and re-use of public biomedical datasets. Making data more accessible through scientifically rigorous metadata will accelerate the ability to make transformative data-driven biomedical discoveries using public data archives.",The Metadata Powerwash - Integrated tools to make biomedical data FAIR,10093841,R01LM013498,"['Age', 'Biological Specimen Banks', 'Categories', 'Collection', 'Common Data Element', 'Communities', 'Computers', 'Data', 'Data Science', 'Data Set', 'Disease', 'FAIR principles', 'Funding Agency', 'Goals', 'Gold', 'Information Technology', 'Knowledge', 'Libraries', 'Link', 'Manuals', 'Metadata', 'Methods', 'Names', 'Natural Language Processing', 'Numerical value', 'Ontology', 'Pharmaceutical Preparations', 'Problem Solving', 'Process', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Sampling', 'Science', 'Scientist', 'Specific qualifier value', 'Speed', 'Standardization', 'Structure', 'Technology', 'Testing', 'Time', 'Variant', 'Work', 'base', 'biomedical scientist', 'data archive', 'data repository', 'data reuse', 'experimental study', 'improved', 'indexing', 'information organization', 'interoperability', 'metadata standards', 'public repository', 'repository', 'sample collection', 'search engine', 'secondary analysis', 'tool']",NLM,STANFORD UNIVERSITY,R01,2021,334847
"Temporal relation discovery for clinical text Project Summary / Abstract The current proposal continues the investigation on the topic of temporal relation extraction from the Electronic Medical Records (EMR) clinical narrative funded by the NLM since 2010 (Temporal Histories of Your Medical Events, or THYME; thyme.healthnlp.org). Through our efforts so far, we have defined the topic as an active area of research attracting attention across the world. Since its inception, the project has pushed the boundaries of this highly challenging task by investigating new computational methods within the context of the latest developments in the fields of natural language processing (NLP), machine learning (ML), artificial intelligence (AI) and biomedical informatics (BMI) resulting in 60+ publications/presentations. We have made our best performing methods available to the community open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (cTAKES; ctakes.apache.org). In 2015, 2016, 2017 and 2018, we organized an international shared task (Clinical TempEval) on the topic under the umbrella of the highly prestigious SemEval, thus inviting the international community to work with our THYME data and improve on our results. Clinical TempEval has been highly successful with many participants each year, resulting in new discoveries and many publications. We have made all our data along with our gold standard annotations available to the community through the hNLP Center (center.healthnlp.org).  The underlying theme of this renewal is novel methods for combining explicit domain knowledge (linguistic, semantic, biomedical ontological, clinical), readily available unlabeled data (health-related social media, EMRs), and modern machine learning techniques (e.g. neural networks) for temporal relation extraction from the EMR clinical narrative. Therefore, our renewal proposes a novel and much needed exploration of this line of research:  Specific Aim 1: Develop computational models for novel rich semantic representations such as the Abstract Meaning Representations to encapsulate a single, coherent, full-document graphical representation of meaning for temporal relation extraction  Specific Aim 2: Develop computational methods to infuse domain knowledge (linguistic, semantic, biomedical ontological, clinical) into modern machine learning techniques such as NNs for temporal relation extraction – through input representations, pre-trained vectors, or architectures  Specific Aim 3: Develop novel methods for combining labeled and unlabeled data from various sources (EMR, health-related social media, newswire) for temporal relation extraction from the clinical narrative  Specific Aim 4: Apply the best performing methods for temporal relation extraction developed in SA1-3 to temporally sensitive phenotypes for direct translational sciences studies. Dissemination efforts through publications and open source releases into Apache cTAKES. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EMR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,10176589,R01LM010090,"['Address', 'Apache', 'Architecture', 'Area', 'Artificial Intelligence', 'Attention', 'Clinical', 'Cognitive', 'Communities', 'Complex', 'Computer Models', 'Computerized Medical Record', 'Computing Methodologies', 'Coupled', 'Data', 'Development', 'Disease', 'Encapsulated', 'Engineering', 'Event', 'Fostering', 'Foundations', 'Funding', 'Goals', 'Gold', 'Health', 'Image', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Label', 'Linguistics', 'Link', 'Machine Learning', 'Medical', 'Methods', 'Modernization', 'Natural Language Processing', 'Nature', 'Participant', 'Patient Care', 'Patients', 'Phenotype', 'Publications', 'Recording of previous events', 'Research', 'Semantics', 'Signs and Symptoms', 'Solid', 'Source', 'Speed', 'Structure', 'System', 'Techniques', 'Text', 'Thyme', 'Time', 'TimeLine', 'Training', 'Translational Research', 'Vision', 'Work', 'advanced disease', 'base', 'biomedical informatics', 'biomedical ontology', 'clinically relevant', 'cohesion', 'electronic data', 'electronic structure', 'epidemiology study', 'improved', 'individualized medicine', 'learning community', 'neural network', 'next generation', 'novel', 'open source', 'programs', 'relating to nervous system', 'social media', 'support vector machine', 'symptom treatment', 'vector']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,531398
"Semi-Automating Data Extraction for Systematic Reviews Summary ​Semi-Automating Data Extraction for Systematic Reviews (​Renewal) Evidence-based Medicine (EBM) aims to inform patient care using all available evidence. Realizing this aim in practice would require access to concise, comprehensive, and up-to-date structured summaries of the evidence relevant to a particular clinical question. Systematic reviews of biomedical literature aim to provide such summaries, and are a critical component of the EBM arsenal and modern medicine more generally. However, such reviews are extremely laborious to conduct. Furthermore, owing to the rapid expansion of the biomedical literature base, they tend to go out of date quickly as new evidence emerges. These factors hinder the practice of evidence-based care. In this renewal proposal, we seek to continue our ground-breaking efforts on developing, evaluating, and deploying novel machine learning (ML) and natural language processing (NLP) methods to automate or semi-automate the evidence synthesis process. This will extend our innovative and successful efforts developing RobotReviewer and related technologies under the current grant. Concretely, for this renewal we propose to move from extraction of clinically salient data elements from individual trials to synthesis of these elements across trials. Our first aim is to extend our ML and NLP models to produce (as one deliverable) a publicly available, continuously and automatically updated semi-structured evidence database, comprising extracted data for all evidence, both published and unpublished. Unpublished trials will be identified via trial registries. Taking this up-to-date evidence repository as a starting point, we then propose cutting-edge ML and NLP models that will generate first drafts of evidence syntheses, automatically. More specifically we propose novel neural cross-document summarization models that will capitalize on the semi-structured information automatically extracted by our existing models, in addition to article texts. These models will be deployed in a new version of RobotReviewer, called RobotReviewerLive, intended to be a prototype for “living” systematic reviews. To rigorously evaluate the practical utility of the proposed methodological innovations, we will pilot their use to support real, ongoing, exemplar living reviews. Semi-Automating Data Extraction for Systematic Reviews (​Renewal) Narrative We propose novel machine learning and natural language processing methods that will aid biomedical literature summarization and synthesis, and thereby support the conduct of evidence-based medicine (EBM). The proposed models and technologies will motivate core methodological innovations and support real-time, up-to-date, semi-automated biomedical evidence syntheses (“systematic reviews”). Such approaches are necessary if we are to have any hope of practicing evidence-based care in our era of information overload.",Semi-Automating Data Extraction for Systematic Reviews,10199049,R01LM012086,"['American', 'Automation', 'Caring', 'Clinical', 'Collection', 'Consumption', 'Data', 'Data Element', 'Databases', 'Development', 'Elements', 'Evaluation', 'Evidence Based Medicine', 'Evidence based practice', 'Feedback', 'Grant', 'Hybrids', 'Individual', 'Informatics', 'Internet', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical Informatics', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Modern Medicine', 'Natural Language Processing', 'Outcome', 'Output', 'Paper', 'Patient Care', 'Population Intervention', 'Process', 'PubMed', 'Publications', 'Publishing', 'Registries', 'Reporting', 'Research', 'Resources', 'Risk', 'Stroke', 'Structure', 'Surveillance Methods', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Vision', 'Work', 'base', 'cardiovascular health', 'database structure', 'design', 'evidence base', 'improved', 'indexing', 'innovation', 'machine learning method', 'natural language', 'neural network', 'novel', 'open source', 'programs', 'prospective', 'prototype', 'recruit', 'relating to nervous system', 'repository', 'search engine', 'structured data', 'study characteristics', 'study population', 'success', 'systematic review', 'tool', 'usability', 'working group']",NLM,NORTHEASTERN UNIVERSITY,R01,2021,292031
"Advanced End-to-End Relation Extraction with Deep Neural Networks ABSTRACT Relations linking various biomedical entities constitute a crucial resource that enables biomedical data science applications and knowledge discovery. Relational information spans the translational science spectrum going from biology (e.g., protein–protein interactions) to translational bioinformatics (e.g., gene–disease associations), and eventually to clinical care (e.g., drug–drug interactions). Scientists report newly discovered relations in nat- ural language through peer-reviewed literature and physicians may communicate them in clinical notes. More recently, patients are also reporting side-effects and adverse events on social media. With exponential growth in textual data, advances in biomedical natural language processing (BioNLP) methods are gaining prominence for biomedical relation extraction (BRE) from text. Most current efforts in BRE follow a pipeline approach containing named entity recognition (NER), entity normalization (EN), and relation classiﬁcation (RC) as subtasks. They typically suffer from error snowballing — errors in a component of the pipeline leading to more downstream errors — resulting in lower performance of the overall BRE system. This situation has lead to evaluation of different BRE substaks conducted in isolation. In this proposal we make a strong case for strictly end-to-end evaluations where relations are to be produced from raw text. We propose novel deep neural network architectures that model BRE in an end-to-end fashion and directly identify relations and corresponding entity spans in a single pass. We also extend our architectures to n-ary and cross-sentence settings where more than two entities may need to be linked even as the relation is expressed across multiple sentences. We also propose to create two new gold standard BRE datasets, one for drug–disease treatment relations and another ﬁrst of a kind dataset for combination drug therapies. Our main hypothesis is that our end-to-end extraction models will yield supe- rior performance when compared with traditional pipelines. We test this through (1). intrinsic evaluations based on standard performance measures with several gold standard datasets and (2). extrinsic application oriented assessments of relations extracted with use-cases in information retrieval, question answering, and knowledge base completion. All software and data developed as part of this project will be made available for public use and we hope this will foster rigorous end-to-end benchmarking of BRE systems. NARRATIVE Relations connecting biomedical entities are at the heart of biomedical research given they encapsulate mech- anisms of disease etiology, progression, and treatment. As most such relations are ﬁrst disclosed in textual narratives (scientiﬁc literature or clinical notes), methods to extract and represent them in a structured format are essential to facilitate applications such as hypotheses generation, question answering, and information retrieval. The high level objective of this project is to develop and evaluate novel end-to-end supervised machine learning methods for biomedical relation extraction using latest advances in deep neural networks.",Advanced End-to-End Relation Extraction with Deep Neural Networks,10200889,R01LM013240,"['Adverse event', 'Architecture', 'Area', 'Benchmarking', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Combination Drug Therapy', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Disease', 'Distant', 'Drug Interactions', 'Encapsulated', 'Etiology', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Generations', 'Genes', 'Gold', 'Growth', 'Hand', 'Heart', 'Information Retrieval', 'Information Sciences', 'Intramural Research', 'Joints', 'Knowledge Discovery', 'Label', 'Language', 'Lead', 'Link', 'Literature', 'Manuals', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Patients', 'Peer Review', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'Scientist', 'Semantics', 'Software Tools', 'Source', 'Standardization', 'Structure', 'Supervision', 'System', 'Terminology', 'Testing', 'Text', 'Training', 'Translational Research', 'Trees', 'base', 'biomedical data science', 'clinical care', 'deep neural network', 'improved', 'insight', 'interest', 'knowledge base', 'machine learning method', 'natural language', 'neural network', 'neural network architecture', 'new therapeutic target', 'novel', 'off-label use', 'protein protein interaction', 'relating to nervous system', 'side effect', 'social media', 'supervised learning', 'syntax']",NLM,UNIVERSITY OF KENTUCKY,R01,2021,332681
"xARA: ARA through Explainable AI In response to the NIH FOA OTA-19009 “Biomedical Translator: Development” we propose to build an Autonomous Relay Agent (ARA) that can characterize and rate the quality of information returned from multiple multiscale heterogeneous knowledge providers (KPs). Biomedical researchers develop a trust relationship with a knowledge provider (KP) through frequent and continued use. Over time a familiarity develops that drives their understanding and insight on 1) how to structure and invoke more effective queries, 2) the quality of the results they may expect in response to different query parameters and feature values, and 3) how to assess the relevancy of a specific query’s results. Although this information retrieval paradigm has served the research community moderately well in the past it is not scalable and the number, scope and complexity of KPs is increasing at a dramatic pace (1,613 molecular biology databases reported as of Jan. 2019). Within this ever changing information landscape, a biomedical researcher now has two choices -- either continue using the few KPs they have learned to trust but remain limited in the actionable information they will receive, or invest the time and accept the risk of using a range of new information resources with little or no familiarity and thus uncertain effectiveness. If researchers are to benefit from the vast array of NIH and industry sponsored information assets now available and expanding new information retrieval and quality assessment technologies will be required. We propose to build an Explanatory Autonomous Relay Agent (xARA) that can characterize query results by rating the quality of information returned from multi-scale heterogeneous KPs. The xARA will utilize multiple information retrieval and explainable Artificial Intelligence (xAI) strategies to perform queries across multiple heterogeneous KPs and rank their results by quality and relevancy while also identifying and explaining any inconsistencies among databases for the same query response. To deliver on this promise, we will utilize case-based reasoning and language models trained with biomedical data (i.e., BioBERT and custom annotation embeddings through Reactome and UniProt) permitting a new level of query profiling and assessment. Our strategies will permit 1) information gaps to be filled by testing alternative query patterns that produce different surface syntax yet possess semantically related and actionable concepts, 2) inconsistencies to be identified for a given query feature value, and 3) the identification and elimination or merging of semantically redundant query results via similarity metrics enriched by case-based reasoning strategies employed in the explainable AI (xAI) community to identify machine learning model behavior and performance. The xARA capabilities proposed herein will be based on strategies developed in Dr. Weber’s lab for information retrieval where the desire for greater transparency when reasoning over experimental data is our primary aim. Our multi-institutional team is comprised of senior researchers and software engineers formally trained and experienced in the computer and data sciences, cheminformatics, bioinformatics, molecular biology, and biochemistry. Inherent risks in querying heterogeneous KPs include the presence of inconsistent labeling of the same biomedical concept within unique KP data structures. Manual engineering may be necessary to overcome such hurdles, but will not be a significant challenge for the initial prototype, since only two well documented KPs are being evaluated. Another noteworthy risk is that the quality of word embeddings generated from UniProt and Reactome may not be sufficient, requiring further textual analysis of biomedical text like PubMed, which is feasible within the timeframe of our project plan. n/a",xARA: ARA through Explainable AI,10330631,OT2TR003448,"['Artificial Intelligence', 'Behavior', 'Biochemistry', 'Bioinformatics', 'Communities', 'Custom', 'Data', 'Data Science', 'Databases', 'Development', 'Effectiveness', 'Engineering', 'Familiarity', 'Industry', 'Information Resources', 'Information Retrieval', 'Knowledge', 'Label', 'Language', 'Machine Learning', 'Manuals', 'Modeling', 'Molecular Biology', 'Pattern', 'Performance', 'Provider', 'PubMed', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Software Engineering', 'Structure', 'Surface', 'Technology Assessment', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'United States National Institutes of Health', 'base', 'case-based', 'cheminformatics', 'computer science', 'experience', 'insight', 'prototype', 'response', 'syntax']",NCATS,TUFTS MEDICAL CENTER,OT2,2021,736476
"Knowledge-Based Biomedical Data Science Knowledge-based biomedical data science  In the previous funding period, we designed and constructed breakthrough methods for creating a semantically coherent and logically consistent knowledge-base by automatically transforming and integrating many biomedical databases, and by directly extracting information from the literature. Building on decades of work in biomedical ontology development, and exploiting the architectures supporting the Semantic Web, we have demonstrated methods that allow effective querying spanning any combination of data sources in purely biological terms, without the queries having to reflect anything about the structure or distribution of information among any of the sources. These methods are also capable of representing apparently conflicting information in a logically consistent manner, and tracking the provenance of all assertions in the knowledge-base. Perhaps the most important feature of these methods is that they scale to potentially include nearly all knowledge of molecular biology.  We now hypothesize that using these technologies we can build knowledge-bases with broad enough coverage to overcome the “brittleness” problems that stymied previous approaches to symbolic artificial intelligence, and then create novel computational methods which leverage that knowledge to provide critical new tools for the interpretation and analysis of biomedical data. To test this hypothesis, we propose to address the following specific aims:  1. Identify representative and significant analytical needs in knowledge-based data science, and  refine and extend our knowledge-base to address those needs in three distinct domains: clinical  pharmacology, cardiovascular disease and rare genetic disease.  2. Develop novel and implement existing symbolic, statistical, network-based, machine learning  and hybrid approaches to goal-driven inference from very large knowledge-bases. Create a goal-  directed framework for selecting and combining these inference methods to address particular  analytical problems.  3. Overcome barriers to broad external adoption of developed methods by analyzing their  computational complexity, optimizing performance of knowledge-based querying and inference,  developing simplified, biology-focused query languages, lightweight packaging of knowledge  resources and systems, and addressing issues of licensing and data redistribution. Knowledge-based biomedical data science  In the previous funding period, we designed and constructed breakthrough methods for creating a semantically coherent and logically consistent knowledge-base by automatically transforming and integrating many biomedical databases, and by directly extracting information from the literature. We now hypothesize that using these technologies we can build knowledge-bases with broad enough coverage to overcome the “brittleness” problems that stymied previous approaches to symbolic artificial intelligence, and then create novel computational methods which leverage that knowledge to provide critical new tools for the interpretation and analysis of biomedical data.",Knowledge-Based Biomedical Data Science,10197219,R01LM008111,"['Address', 'Adoption', 'Architecture', 'Area', 'Artificial Intelligence', 'Biological', 'Biology', 'Biomedical Research', 'Cardiovascular Diseases', 'Clinical Data', 'Clinical Pharmacology', 'Collaborations', 'Communities', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Duchenne muscular dystrophy', 'Fruit', 'Funding', 'Genomics', 'Goals', 'Heart failure', 'Hybrids', 'Information Distribution', 'Information Resources', 'Knowledge', 'Language', 'Licensing', 'Literature', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Network-based', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Proteins', 'Proteomics', 'Publishing', 'Role', 'Semantics', 'Serum', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Work', 'biomedical data science', 'biomedical ontology', 'cohort', 'computer based Semantic Analysis', 'design and construction', 'health data', 'innovation', 'knowledge base', 'large scale data', 'light weight', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'online resource', 'ontology development', 'rare genetic disorder', 'tool', 'transcriptomics']",NLM,UNIVERSITY OF COLORADO DENVER,R01,2021,506502
"National Resource for Network Biology (NRNB) OVERALL - PROJECT SUMMARY The mission of the National Resource for Network Biology (NRNB) is to advance the science of biological networks by creating leading-edge bioinformatic methods, software tools and infrastructure, and by engaging the scientific community in a portfolio of collaboration and training opportunities. Much of biomedical research is dependent on knowledge of biological networks of multiple types and scales, including molecular interactions among genes, proteins, metabolites and drugs; cell communication systems; relationships among genotypes and biological and clinical phenotypes; and patient and social networks. NRNB-supported platforms like Cytoscape are among the most widely used software tools in biology, with tens of thousands of active users, enabling researchers to apply network concepts and data to understand biological systems and how they are reprogrammed in disease.  NRNB’s three Technology Research and Development projects introduce innovative concepts with the potential to transform network biology, transitioning it from a static to a dynamic science (TR&D 1); from flat network diagrams to multi-scale hierarchies of biological structure and function (TR&D 2); and from descriptive interaction maps to predictive and interpretable machine learning models (TR&D 3). In previous funding periods our technology projects have produced novel and highly cited approaches, including network-based biomarkers for stratification of disease, data-driven gene ontologies assembled completely from network data, and deep learning models of cell structure and function built using biological networks as a scaffold.  During the next period of support, we introduce dynamic regulatory networks formulated from single-cell transcriptomics and advanced proteomics data (TR&D 1); substantially improved methodology for the study of hierarchical structure and pleiotropy in biological networks (TR&D 2); and procedures for using networks to seed machine learning models of drug response that are both mechanistically interpretable and transferable across biomedical contexts (TR&D 3). These efforts are developed and applied in close collaboration with outside investigators from 19 Driving Biomedical Projects who specialize in experimental generation of network data, disease biology (cancer, neuropsychiatric disorders, diabetes), single-cell developmental biology, and clinical trials. TR&Ds are also bolstered by 7 Technology Partnerships in which NRNB scientists coordinate technology development with leading resource-development groups in gene function prediction, mathematics and algorithm development, and biomedical databases. Beyond these driving collaborations, we continually support a broader portfolio of transient (non-driving) research collaborations; organize and lead international meetings including the popular Network Biology track of the Intelligent Systems for Molecular Biology conference; and deliver a rich set of training opportunities and network analysis protocols. OVERALL - PROJECT NARRATIVE We are all familiar with some of the components of biological systems – DNA, proteins, cells, organs, individuals – but understanding biological systems involves more than just cataloging its component parts. It is critical to understand the many interactions of these parts within systems, and how these systems give rise to biological functions and responses and determine states of health and disease. The National Resource for Network Biology provides the scientific community with a broad platform of computational tools for the study of biological networks and for incorporating network knowledge in biomedical research.",National Resource for Network Biology (NRNB),10145009,P41GM103504,"['Area', 'Automobile Driving', 'Beds', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Biomedical Technology', 'Cataloging', 'Cell Communication', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Conceptions', 'DNA', 'Data', 'Data Set', 'Databases', 'Developmental Cell Biology', 'Diabetes Mellitus', 'Disease', 'Disease stratification', 'Drug Modelings', 'Ecosystem', 'Educational workshop', 'Event', 'Expert Systems', 'Feedback', 'Funding', 'Gene Proteins', 'Generations', 'Genes', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Health', 'Individual', 'Infrastructure', 'International', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mentors', 'Methodological Studies', 'Methods', 'Mission', 'Modeling', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Network-based', 'Ontology', 'Organ', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Phase Transition', 'Phenotype', 'Positioning Attribute', 'Procedures', 'Proteins', 'Proteomics', 'Protocols documentation', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Running', 'Science', 'Scientist', 'Seeds', 'Services', 'Social Network', 'Software Tools', 'Structure', 'Students', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Visual', 'Visualization', 'Work', 'algorithm development', 'biological systems', 'clinical phenotype', 'cloud storage', 'computational platform', 'computerized tools', 'deep learning', 'gene function', 'genomics cloud', 'improved', 'innovation', 'interoperability', 'lens', 'mathematical algorithm', 'meetings', 'method development', 'multi-scale modeling', 'neuropsychiatric disorder', 'next generation', 'novel', 'pleiotropism', 'prediction algorithm', 'programs', 'protein metabolite', 'response', 'scaffold', 'single cell analysis', 'software infrastructure', 'symposium', 'technology development', 'technology research and development', 'tool', 'training opportunity', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P41,2021,1210147
"Image-guided Biocuration of Disease Pathways From Scientific Literature Realization of precision medicine ideas requires an unprecedented rapid pace of translation of biomedical discoveries into clinical practice. However, while many non-canonical disease pathways and uncommon drug actions, which are of vital importance for understanding individual patient-specific disease pathways, are accumulated in the literature, most are not organized in databases. Currently, such knowledge is curated manually or semi-automatically in a very limited scope. Meanwhile, the volume of biomedical information in PubMed (currently 28 million publications) keeps growing by more than a million articles per year, which demands more efficient and effective biocuration approaches.  To address this challenge, a novel biocuration method for automatic extraction of disease pathways from figures and text of biomedical articles will be developed.  Specific Aim 1: To develop focused benchmark sets of articles to assess the performance of the biocuration pipeline.  Specific Aim 2: To develop a method for extraction of components of disease pathways from articles’ figures based on deep-learning techniques.  Specific Aim 3: To develop a method for reconstruction of disease-specific pathways through enrichment and through graph neural network (GNN) approaches.  Specific Aim 4: To conduct a comprehensive evaluation of the pipeline.  The overarching goal of this project is to develop a computer-based automatic biocuration ecosystem for rapid transformation of free-text biomedical literature into a machine-processable format for medical applications.  The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. It will especially benefit cancer patients for which up-to-date knowledge of newly discovered molecular mechanisms and drug actions is critical. The overall impact of the proposed project will be to significantly improve health outcomes in individualized patient cases by efficiently bringing the latest biomedical discoveries into a precision medicine setting. In this project, a novel biocuration method for an automatic extraction of disease mechanisms from figures and text in scientific literature will be developed. These mechanisms will be stored in a database for further querying to assist in medical diagnosis and treatment.",Image-guided Biocuration of Disease Pathways From Scientific Literature,10149399,R01LM013392,"['Address', 'Architecture', 'Benchmarking', 'Biological', 'Cancer Patient', 'Communities', 'Computers', 'Databases', 'Deposition', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Pathway', 'Ecosystem', 'Elements', 'Evaluation', 'Feedback', 'Genes', 'Goals', 'Graph', 'Health', 'Image', 'Informatics', 'Knowledge', 'Label', 'Language', 'Link', 'Literature', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measures', 'Medical', 'Methods', 'Molecular', 'Molecular Analysis', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'PubMed', 'Publications', 'Regulation', 'Reporting', 'Research', 'Retrieval', 'Selection Criteria', 'Signal Pathway', 'Source', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'Translations', 'Visual', 'Work', 'base', 'clinical practice', 'deep learning', 'design', 'detector', 'drug action', 'image guided', 'improved', 'individual patient', 'knowledge base', 'knowledge curation', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'precision medicine', 'reconstruction', 'success', 'text searching', 'tool', 'usability']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,313018
"Breakthrough Molecular Dynamics Research via an Anton2 Supercomputer Project Summary In 2010, Pittsburgh Supercomputing Center (PSC) and D.E. Shaw Research (DESRES) partnered to make the Anton special-purpose molecular dynamics (MD) supercomputer available to the national biomedical research community for the first time. Anton enabled researchers to simulate biomolecular systems two orders of magnitude faster than any conventional supercomputer, allowing researchers access to critical multi- microsecond and longer timescales on which most biologically-significant molecular processes take place. In 2016, with operational support from NIH, DESRES made available a next generation Anton 2 system at PSC at no cost. This multimillion-dollar gift from DESRES, with NIH support, provided a unique opportunity for researchers to tackle even more groundbreaking biological questions by simulating systems as large as 700,000 atoms at a rate of multiple microseconds per day. The goal of this renewal project is to provide the national biomedical research community with continued access to this unique and powerful Anton 2 resource and to maximize the benefit of this resource to the community. Since 2010, PSC has supported 589 research projects conducted by 202 unique PIs on the Anton systems hosted at PSC. So far, these projects have resulted in 292 publications, many of which have had significant impact on their fields of research. These fields cover the entire spectrum of biomolecular processes that form the fundamental underpinnings of biology, including protein folding, ion channel selectivity and gating, membrane dynamics and organization, protein- ligand binding, and many others. Demand for Anton 2 is quite high, with 2-3x higher demand than can be met each year. Given this, our goals are focused not only on providing continued access but also on maximizing the value of this limited resource to the community—recognizing that the creativity of the broad, diverse Anton 2 research community is one of our most powerful resources for innovation. Anton 2 will be integrated as an XSEDE service provider, and the accessibility and impact of Anton 2 will significantly increase by engaging in their extensive broadening participation, outreach, and training programs. Through these outreach efforts, researchers at many more institutions will have the opportunity to use Anton 2, especially researchers from traditionally underrepresented groups in biomedical research. The hundreds of long-timescale MD trajectories researchers generate on Anton 2 constitute a unique and valuable dataset that can be used to gain additional biomedical knowledge and advance the application of machine learning protocols to augment molecular dynamics simulations. This important dataset will be available to researchers and educators worldwide through a web portal and co-located on the PSC's Bridges-2 system for classroom instruction and research, including reanalysis, machine learning, and data mining. Project Narrative The Anton 2 supercomputer made available at Pittsburgh Supercomputing Center through this award will enable researchers to simulate biomolecular systems orders of magnitude faster than any conventional supercomputer. This powerful resource will enable biomedical researchers to better understand the fundamental biomolecular processes of biology, leading to better ways to treat disease and improve quality of life.",Breakthrough Molecular Dynamics Research via an Anton2 Supercomputer,10211715,R01GM116961,"['Academy', 'Area', 'Award', 'Awareness', 'Binding Proteins', 'Biological', 'Biology', 'Biomedical Research', 'Collaborations', 'Communities', 'Community Health Education', 'Creativeness', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Disease', 'Evaluation Reports', 'FAIR principles', 'Funding', 'Gifts', 'Goals', 'Grant', 'Institution', 'Instruction', 'Ion Channel', 'Knowledge', 'Letters', 'Machine Learning', 'Membrane', 'Molecular', 'National Research Council', 'Process', 'Protocols documentation', 'Publications', 'Quality of life', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Running', 'Science', 'Secure', 'Supercomputing', 'System', 'Time', 'Training Programs', 'Underrepresented Populations', 'United States National Academy of Sciences', 'United States National Institutes of Health', 'Work', 'anxious', 'archive data', 'archived data', 'base', 'broadening participation research', 'computing resources', 'cost', 'data management', 'data mining', 'data sharing', 'improved', 'innovation', 'molecular dynamics', 'next generation', 'outreach', 'outreach program', 'price lists', 'protein folding', 'service providers', 'supercomputer', 'uptake', 'web portal']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2021,408856
