text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients ABSTRACT The prevalence of obesity in the United States has risen to record levels over the past 40 years, putting strain on the healthcare system and creating difficult challenges for medical imaging. We propose to overcome the challenges that obesity poses to ultrasound imaging by (1) developing novel image-quality improvement techniques, and (2) implementing them on pulse-echo ultrasound imaging systems to yield high-quality images of the liver. Ultrasound imaging is uniquely affected by the presence of additional connective tissue and thick subcutaneous fat layers in overweight and obese patients; these additional subcutaneous layers greatly exacerbate reverberation and phase-aberration of the acoustic wave, leading to high levels of clutter, degraded resolution, and overall poor-quality ultrasound images. Our proposed methods will determine the local speed-of-sound in abdominal tissue layers and use this information to accomplish distributed phase-aberration correction. We also apply machine learning techniques to model and suppress the effects of reverberation clutter and speckle noise. The combination of these techniques is expected to achieve significant improvements in liver image quality. These image-quality improvement methods will be implemented on a real-time ultrasound scanner and will be evaluated in clinical imaging tasks of overweight and obese patients undergoing ultrasound surveillance of hepatocellular carcinoma. Successful development of the proposed technology will not only enable high-quality ultrasound imaging of the liver in otherwise difficult-to-image overweight and obese patients, but also facilitate improved image quality across nearly all ultrasound imaging applications, for all populations. NARRATIVE This proposal aims to develop and test several new techniques to overcome the current limitations of ultrasound to make high-quality images in overweight and obese individuals. These novel ultrasound techniques will be initially applied to improve liver imaging in overweight and obese patients in a pilot study, though the benefits of this new high-quality imaging technology will extend to all other areas of clinical ultrasound imaging.",Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients,10236260,R01EB027100,"['Abdomen', 'Acoustics', 'Affect', 'American', 'Architecture', 'Area', 'Attenuated', 'Cardiac', 'Cirrhosis', 'Clinical', 'Computer software', 'Connective Tissue', 'Data', 'Development', 'Diffuse', 'Disease', 'Fatty acid glycerol esters', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Image', 'Imaging technology', 'Lesion', 'Liver', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Noise', 'Obesity', 'Output', 'Overweight', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Resolution', 'Risk Factors', 'Signal Transduction', 'Source', 'Speed', 'Subcutaneous Tissue', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Weight', 'clinical imaging', 'elastography', 'epidemiology study', 'fetal', 'high body mass index', 'imaging system', 'improved', 'in vivo', 'liver imaging', 'neural network', 'novel', 'obese patients', 'obese person', 'patient population', 'prototype', 'radio frequency', 'simulation', 'sound', 'subcutaneous']",NIBIB,STANFORD UNIVERSITY,R01,2021,585234
"Computational Diffusion MRI for Studying Early Human Brain Development Computational Diffusion MRI for Studying Early Human Brain Development Abstract In the ﬁrst years of life, the human brain develops dynamically in both structure and function. Many neurodevel- opmental disorders are associated with aberrations from normative growth during this critical period of early brain development. The increasing availability of longitudinal baby MRI data, such as those acquired through the Baby Connectome Project (BCP), affords unprecedented opportunity for precise charting of early brain developmental trajectories in order to understand normative and aberrant growth. Dedicated computational tools are needed for accurate processing and analysis of baby MR images, which typically exhibit dynamic heterogeneous changes across time. The goal of this project is to equip brain researchers with computational tools effective for studying the early developing human brain in terms of tissue microstructure and white matter pathways using diffusion MRI. We propose three aims. In Aim 1, we will develop computational tools for effective estimation of white matter pathways in the baby brain via diffusion tractography. We will tackle the challenge of tracking through regions with low diffusion anisotropy owing to ongoing myelination in the developing brain. Our tools will allow proper characterization of complex white matter pathway patterns such as fanning and bending. This will allow solving the gyral bias problem ubiquitous in existing tractography algorithms with ﬁber streamlines terminating predomi- nantly at gyral crowns but not sulcal banks. Our tools will allow tracing of cortico-cortical and cortico-subcortical pathways with more uniform coverage of the cortex. In Aim 2, we will develop microstructural analysis meth- ods that are unconfounded by complex ﬁber conﬁgurations, such as crossing, bending, branching, kissing, and fanning, allowing more accurate and speciﬁc characterization of changes in tissue microarchitecture during early brain development. In Aim 3, we will develop techniques that will allow diffusion MRI data collected at multiple sites, which are very common in the era of big data, to be harmonized to mitigate the negative effects of inter-site variability. Unlike existing methods that harmonize derived quantities such as fractional anisotropy, our method can be applied directly to the diffusion-weighted images, allowing measurements based on microstructure and connectivity to be subsequently computed for consistent analysis. We will also develop deep learning tools for multi-shell data prediction so that diffusion MRI data collected with different numbers of shells can be harmonized. Successful completion of this project will empower the neuroscience community with computational tools to better chart the normative early development of the human brain using diffusion MRI. The developed tools will also enable quantitative brain examinations of children who are affected by neurological developmental disorders. Project Narrative This project will empower neuroscience researchers with robust computational tools needed to study the early developing human brain in terms of tissue microstructure and white matter connection pathways using diffusion MRI. We will develop tools to tackle challenges speciﬁc to analyzing infant diffusion MRI data, including (i) com- plex microstructure arising from the interweaving of differentially oriented neurites (axons and dendrites) in the context of the extracellular matrix; and (ii) complex white matter ﬁber geometries, such as crossing, bending, and fanning. We will also create tools to cater to the big-data era need of dealing with data from multiple imaging sites with potential discrepancies in acquisition protocols and scanner behaviors, allowing intra- and inter-site variability to be reduced via data harmonization for consistent analysis with signiﬁcantly boosted statistical power.",Computational Diffusion MRI for Studying Early Human Brain Development,10317389,R01MH125479,"['Address', 'Adult', 'Affect', 'Algorithms', 'Anatomy', 'Anisotropy', 'Award', 'Axon', 'Behavior', 'Big Data', 'Brain', 'Child', 'Communities', 'Complex', 'Data', 'Dendrites', 'Dental crowns', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Environment', 'Exhibits', 'Extracellular Matrix', 'Felis catus', 'Fiber', 'Geometry', 'Goals', 'Growth', 'Human', 'Image', 'Infant', 'Life', 'Magnetic Resonance Imaging', 'Measurement', 'Methods', 'Minnesota', 'Myelin', 'Nature', 'Neurites', 'Neurodevelopmental Disorder', 'Neurologic', 'Neurosciences', 'North Carolina', 'Pathway interactions', 'Pattern', 'Process', 'Property', 'Protocols documentation', 'Research', 'Research Personnel', 'Signal Transduction', 'Site', 'Structure', 'Techniques', 'Time', 'Tissues', 'Universities', 'base', 'brain tissue', 'computerized tools', 'connectome', 'critical period', 'data harmonization', 'deep learning', 'design', 'developmental disease', 'diffusion anisotropy', 'imaging modality', 'improved', 'myelination', 'tool', 'tractography', 'white matter']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,456443
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,10061631,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2021,1261742
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,10187567,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2021,310796
"Reading workstation for clinical contrast echocardiography Proposal Summary There is increasing appreciation of a syndrome in which patients female patients, present with chest pain due to myocardial ischemia and have a normal or near normal coronary angiogram. Termed coronary microvascular dysfunction (MVD) this disorder is not benign with cardiovascular event rates similar to those with established coronary artery disease. Clinical tools are therefore needed to both identify MVD patients and better understand the mechanisms causing myocardial ischemia. There is evidence that myocardial contrast echocardiography (MCE) provides incremental information in the evaluation of patients with coronary artery disease, myocardial viability, or diseases of the microvasculature. Despite data demonstrating the diagnostic and prognostic benefit of MCE in evaluating patients with MVD, its clinical use has been limited to only a handful of experts in the field, because there are currently no widely available clinical tools to support MCE quantitative analysis and interpretation. The overall aim of this Phase I proposal is to provide clinicians with a new tool to evaluate the myocardial flow-function relationship that is critical to identifying patients with MVD by using echocardiography. We will develop clinical software that can rapidly process MCE data into a standardized, quantitative and easy- to- interpret format. In Aim 1, the power of image averaging and computer aided assessment of radial wall thickening will be used to enhance the current standard of care which relies solely on readers' visual estimation of segmental function. An algorithm will be developed to rearrange the order of images so that images representing the same phase of the cardiac cycle are grouped together. Functional analysis will then be developed using computer-aided tracings of epicardial and endocardial borders. In Aim 2, a software module for quantitative analysis of real-time MCE perfusion will be developed that will incorporate statistical confidence, derived from the performance of image processing algorithms to inform the interpreter about the data strength. Machine learning will be utilized to train and deploy a neural network for the pixel-by-pixel assessment of myocardial perfusion. In Aim 3, we will combine myocardial perfusion and function modules into a novel, perfusion-function mode of imaging (PF-mode). This new mode will be applied to an archival sample of clinically diagnosed MVD cases to demonstrate the feasibility to detect abnormalities in the myocardial flow-function relationship. The composite PF-mode will include a cine-loop rendered for one cardiac cycle where parametric images (perfusion) are superimposed over averaged ultrasound images with an overlay of graphic representation of wall thickness (function). This novel mode of imaging provides the means to diagnose MVD in a single clinical study. Project Narrative Project Title: Reading workstation for clinical contrast echocardiography Despite a wealth of evidence that myocardial contrast echocardiography imaging of myocardial perfusion provides incremental information in the evaluation of patients with diseases of the myocardial microvasculature (MVD), its clinical use has been limited to only a handful of experts in the field. In this proposal, we have created a multidisciplinary partnership between physicians-scientists and engineers with the overall aim to address this clinical gap that exists between a proven echocardiographic technique and the technology necessary to enable widespread adoption of MCE clinically. We will develop a software program enabling a new method for evaluating the myocardial flow-function relationship using echocardiography that will enable the identification of MVD using MCE studies at the level of expert readers.",Reading workstation for clinical contrast echocardiography,10155647,R43HL152939,"['Address', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Apical', 'Benign', 'Blood', 'Blood Flow Velocity', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Chest Pain', 'Classification', 'Clinical', 'Clinical Research', 'Clip', 'Code', 'Color', 'Computer Assisted', 'Computer software', 'Computers', 'Contrast Echocardiography', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Echocardiography', 'Engineering', 'Evaluation', 'Event', 'Eye', 'Female', 'Guidelines', 'Image', 'Imaging Techniques', 'Machine Learning', 'Mechanics', 'Medical', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Myocardial', 'Myocardial Ischemia', 'Myocardial perfusion', 'Names', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Physicians', 'Process', 'Radial', 'Reader', 'Reading', 'Recommendation', 'Rest', 'Scientist', 'Side', 'Societies', 'Software Engineering', 'Standardization', 'Stress', 'Syndrome', 'Techniques', 'Technology', 'Thick', 'Time', 'Training', 'Ultrasonography', 'Vendor', 'Visual', 'arteriole', 'base', 'clinical Diagnosis', 'endothelial dysfunction', 'image processing', 'imaging software', 'indexing', 'multidisciplinary', 'neural network', 'novel', 'parametric imaging', 'perfusion imaging', 'prognostic', 'programs', 'sample archive', 'single photon emission computed tomography', 'standard of care', 'tool', 'user-friendly']",NHLBI,"NARNAR, LLC",R43,2021,252399
"Multi-Task MR Simulation for Abdominal Radiation Treatment Planning The accuracy of radiation treatment planning (RTP) heavily influences the effectiveness of external beam radiotherapy (EBRT). Individualized RTP begins with a “simulation”, in which the patient in a treatment position is commonly scanned using computed tomography (CT) to define the treatment target and organs at risk (OARs). When soft-tissue contrast is inadequate to support accurate target and OAR delineation in CT based RTP, conservatively large treatment margins are used to avoid a geometric miss. The crude treatment prevents delivering sufficient radiation dose to the tumor without exceeding the tolerance of surrounding normal tissues. Magnetic resonance (MR) can be used as a simulation platform complementary to CT for improved soft-tissue conspicuity. Yet, such a complicated, costly and tedious multi-modal RTP workflow along with unavoidable systematic MR-CT co-registration errors has limited its applications in EBRT, especially at the abdominal site whereby anatomies are highly mobile. Over the past few years, there is a keen interest in the integration of MR alone into RTP and even the therapy workflow (i.e. MR-guided radiotherapy, MRgRT). The abdomen poses critical challenges to MR simulation. Current MR imaging sequences are suboptimal to produce motion-free images and resolve respiratory motion. MR data processing for abdominal RTP is underdeveloped. Contouring of target and OARs typically relies on manual, tedious procedures that are time-consuming and variation-prone. In this proposal, we will substantially improve the MR acquisition and automated multi-organ segmentation, so the potential of MR as a simulation modality can be fully unleashed for abdominal EBRT. Three specific aims will be completed. In Aim 1, we will develop and validate a standalone multi-task MR (MT-MR) sequence dedicated to abdominal MR simulation. In Aim 2, we will develop an MT-MR simulation based multi-organ auto- segmentation tool. In Aim 3, we will optimize a deep learning-based dose prediction model and assess the effectiveness of the MT-MR based RTP workflow in adaptive stereotactic body radiotherapy planning of pancreatic cancer patients. Successful completion of the project will significantly promote the clinical adoption of MR simulation for abdominal RTP, which will improve treatment precision and outcomes. Moreover, the developed techniques will open the door to future studies aiming at optimizations in both cancer diagnosis and radiotherapy. Imaging is essential for precise radiation treatment planning. MR based planning is challenging in the abdomen whereby anatomies are highly mobile. We will substantially improve the MR acquisition and automated multi- organ segmentation, so the potential of MR as an imaging-based planning modality can be fully unleashed for abdominal radiation treatment.",Multi-Task MR Simulation for Abdominal Radiation Treatment Planning,10331615,R01EB029088,"['3-Dimensional', 'Abdomen', 'Address', 'Adoption', 'Anatomy', 'Breathing', 'Clinical', 'Consumption', 'Data', 'Data Collection', 'Detection', 'Development', 'Dose', 'Effectiveness', 'Fatty acid glycerol esters', 'Future', 'Geometry', 'Goals', 'Image', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Modality', 'Motion', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pancreas', 'Patients', 'Phase', 'Positioning Attribute', 'Precision therapeutics', 'Procedures', 'Protocols documentation', 'Protons', 'Radiation Dose Unit', 'Radiation therapy', 'Research', 'Risk', 'Scanning', 'Site', 'Solid', 'Spatial Distribution', 'Study Subject', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Tissues', 'Variant', 'Water', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'cancer diagnosis', 'cancer radiation therapy', 'computerized data processing', 'contrast imaging', 'cost', 'deep learning', 'density', 'effectiveness evaluation', 'experience', 'image processing', 'image reconstruction', 'improved', 'interest', 'learning strategy', 'multimodality', 'multitask', 'novel', 'pancreatic cancer patients', 'predictive modeling', 'prevent', 'respiratory', 'simulation', 'soft tissue', 'standard of care', 'success', 'tool', 'treatment planning', 'tumor']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,507076
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10173765,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'efficacy evaluation', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2021,256578
"Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis Project Summary Osteoarthritis (OA) is the leading cause of disability worldwide. The inability of non-invasive techniques to quantify disease progression has limited understanding of the pathogenesis of OA. While numerous magnetic resonance imaging (MRI) methods have been proposed for imaging OA, sensitivity to bone metabolism has been limited. We propose to develop advanced three-dimensional PET-MRI methods for bone and soft tissue metabolism to study the response of the tissues in the joint to changes in knee load. This work will lead to a new understanding of OA pathogenesis by revealing relationships between changes in cartilage and bone metabolism over time. This project aims to develop PET-MRI methods to sensitively track changes of OA in response to biomechanical loading. Our specific aims are to (1) Develop accurate, reproducible and dose-optimized kinetic models of dynamic 18F-NaF PET-MRI for quantitative bilateral whole joint imaging using deep learning and advanced MR coil technology, (2) Study the relationship between resting state bone metabolism and biomechanics using PET- MRI and (3) Perform a longitudinal study to assess the response of our new imaging methods to changes in joint biomechanics from gait retraining. The innovation of this work lies in the development of novel imaging techniques that simultaneously offer quantitative measures of tissue physiology in cartilage and bone using PET-MRI. The significance of this work is that we will be able to sensitively and quantitatively track changes in bone metabolism and soft tissue microstructure due to changes in biomechanical loading in the knee joint over time. This will provide new and more sensitive imaging tools to assess the responses of the joint to biomechanical interventions to treat OA such as gait retraining, bracing, or high tibial osteotomy. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for assessment of disease-modifying treatments such as bracing or gait modification. This work aims to develop novel 3D imaging approaches using positron-emission tomography (PET) and magnetic resonance imaging (MRI), to quantitatively assess joint health during mechanical treatment of osteoarthritis. !",Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis,10202485,R01AR074492,"['3-Dimensional', 'Affect', 'Anatomy', 'Architecture', 'Arthralgia', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Matrix', 'Bone Spur', 'Bone Tissue', 'Bone remodeling', 'Canes', 'Cartilage', 'Clinical', 'Data', 'Degenerative polyarthritis', 'Deposition', 'Development', 'Diagnostic Imaging', 'Disease', 'Disease Progression', 'Dose', 'Environment', 'Extracellular Matrix', 'Fluoride Ion', 'Future', 'Gait', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Medial', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Multimodal Imaging', 'Needs Assessment', 'Orthopedics', 'Osteotomy', 'Pain', 'Pathogenesis', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Protocols documentation', 'Quality of life', 'Reporting', 'Reproducibility', 'Research', 'Rest', 'Risk Factors', 'Roentgen Rays', 'Sclerosis', 'Severities', 'Shapes', 'Societies', 'Sodium Fluoride', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Treatment Efficacy', 'Work', 'analysis pipeline', 'attenuation', 'base', 'bone', 'bone metabolism', 'cartilage metabolism', 'clinical translation', 'cost', 'deep learning', 'disability', 'efficacy evaluation', 'flexibility', 'gait examination', 'gait rehabilitation', 'imaging approach', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'innovation', 'joint loading', 'kinetic model', 'mechanical force', 'mechanical properties', 'mineralization', 'molecular marker', 'non-invasive imaging', 'novel', 'novel imaging technique', 'pharmacokinetic model', 'quantitative imaging', 'radiotracer', 'response', 'soft tissue', 'subchondral bone', 'tool', 'treatment strategy', 'uptake']",NIAMS,STANFORD UNIVERSITY,R01,2021,425647
"Novel Algorithms for Reducing Radiation Dose of CT Perfusion Project Summary/Abstract X-ray computed tomography (CT) has been increasingly used in medical diagnosis, currently reaching more than 100 million CT scans every year in the US. The increasing use of CT has sparked concern over the effects of radiation dose on patients. It is estimated that every 2000 CT scans will cause one future cancer, i.e., 50,000 cases of future cancers from 100 million CT scans every year. CT brain perfusion (CTP) is a widely used imaging technique for the evaluation of hemodynamic changes in stroke and cerebrovascular disorders. However, CTP involves high radiation dose for patients as the CTP scan is repeated on the order of 40 times at the same anatomical location, in order to capture the full passage of the contrast bolus. Several techniques have been applied for radiation dose reduction in CTP scans, including reduction of tube current and tube voltage, as well as the use of noise reduction techniques such as iterative reconstruction (IR). However, the resultant radiation dose of existing CTP scans is still significantly higher than that of a standard head CT scan. The application of IR techniques in CTP is very limited due to the high complexity and computational burden for processing multiple CTP images that impairs clinical workflow. During the Phase 1 STTR project, we introduced a novel low dose CTP imaging method based on the k-space weighted image contrast (KWIC) reconstruction algorithm. We performed thorough evaluation in both a CTP phantom and clinical CTP datasets, and demonstrated that the KWIC algorithm is able to reduce the radiation dose of existing CTP techniques by 75% without affecting the image quality and accuracy of quantification (i.e., Milestone of Phase 1 STTR). However, the original KWIC algorithm requires rapid-switching pulsed X-ray at pre-specified rotation angles – a hardware capability yet to be implemented by commercial CT vendors. In order to address this limitation, we recently introduced a variant of the KWIC algorithm termed k-space weighted image average (KWIA) that preserves high spatial and temporal resolutions as well as image quality of low dose CTP data (~75% dose reduction) to be comparable to those of standard CTP scans. Most importantly, KWIA does not require modification of existing CT hardware and is computationally simple and fast, therefore has a low barrier for market penetration. The purpose of the Phase 2 STTR project is to further optimize and validate the KWIA algorithm for reducing radiation dose of CTP scans by ~75% while preserving the image quality and quantification accuracy in CTP phantom, clinical CTP data and animal studies. We will further develop innovative deep-learning (DL) based algorithms to address potential motion and other artifacts in KWIA, and commercialize the developed algorithms by collaborating with CT vendors. Relevance to Public Health More than 100 million CT scans are performed every year in the US, estimated to cause 50,000 cases of future cancers. This project will develop, evaluate and commercialize novel CT imaging technologies that reduce the radiation dose of existing CT perfusion techniques by ~75% without compromising imaging speed or quality.",Novel Algorithms for Reducing Radiation Dose of CT Perfusion,10220967,R44EB024438,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American Heart Association', 'Anatomy', 'Angiography', 'Animals', 'Bolus Infusion', 'Brain', 'Brain Neoplasms', 'Cerebrovascular Disorders', 'Clinical', 'Collaborations', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Dose', 'Evaluation', 'Future', 'Goals', 'Guidelines', 'Head', 'Heart', 'Image', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Infarction', 'Location', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical', 'Methods', 'Modification', 'Monitor', 'Morphologic artifacts', 'Motion', 'Noise', 'Organ', 'Patients', 'Pattern', 'Penetration', 'Perfusion', 'Phase', 'Physiologic pulse', 'Public Health', 'Radiation Dose Unit', 'Reperfusion Therapy', 'Roentgen Rays', 'Rotation', 'Scanning', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specific qualifier value', 'Speed', 'Stroke', 'Techniques', 'Technology', 'Time', 'Traumatic Brain Injury', 'Tube', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'acute stroke', 'base', 'brain tissue', 'contrast imaging', 'deep learning', 'denoising', 'hemodynamics', 'imaging modality', 'innovation', 'low dose computed tomography', 'novel', 'perfusion imaging', 'preservation', 'radiation effect', 'reconstruction', 'temporal measurement', 'voltage']",NIBIB,"HURA IMAGING, INC",R44,2021,821583
"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,10127641,R01EB028752,"['Address', 'Adoption', 'Affordable Care Act', 'Aging', 'Algorithmic Software', 'Algorithms', 'Benign', 'Biopsy', 'Caliber', 'Cancer Center', 'Categories', 'Cellular Morphology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Current Procedural Terminology', 'Dermatologist', 'Dermatology', 'Dermis', 'Dermoscopy', 'Devices', 'Diagnosis', 'Diagnostic', 'Drops', 'Effectiveness', 'Endoscopes', 'Engineering', 'Epidermis', 'Grant', 'Head and neck structure', 'Image', 'Imaging Techniques', 'Lesion', 'Lesion by Morphology', 'Letters', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medicaid services', 'Medicare/Medicaid', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopic', 'Montana', 'Morphology', 'Optics', 'Oral', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sensitivity and Specificity', 'Site', 'Skin', 'Skin Cancer', 'Specificity', 'Surface', 'Technology', 'Testing', 'Time', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Visual', 'base', 'blind', 'cancer diagnosis', 'clinical examination', 'clinical practice', 'cost', 'design', 'design and construction', 'diagnostic accuracy', 'gastrointestinal', 'image guided', 'image processing', 'image registration', 'improved', 'in vivo', 'innovation', 'instrument', 'instrumentation', 'interest', 'lens', 'medical specialties', 'microscopic imaging', 'miniaturize', 'novel', 'novel diagnostics', 'optical imaging', 'prospective test', 'reflectance confocal microscopy', 'response', 'routine practice', 'skin lesion', 'volunteer']",NIBIB,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2021,589357
"Enabling Kinematic Joint Profiling Using MRI Project Summary We propose a technical feasibility study seeking to develop methods for quantitative kinematic proﬁling of moving joints using magnetic resonance imaging (MRI). In the context of this study, a kinematic proﬁle is deﬁned as a collection of joint characteristics computed and tracked during the course of movement. This project is motivated by the hypothesis that such proﬁling of moving joints can highlight dysfunction, treatment progress, and point towards favorable (or unfavorable) surgical interventions. At a high level, it is envisioned that the proposed kinematic proﬁles could ﬁt into clinical management workﬂows much in the same way as blood biomarker panels.  While kinematic imaging of joints can be performed using plain-ﬁlm (PF) X-ray, computed tomography (CT), and ultrasound (US) methods, MRI is the gold-standard for advanced orthopedic assessment and is an appealing option for accessory kinematic analysis. A set of relatively fast kinematic proﬁling acquisitions could feasibly be added to routine orthopedic MRI exams, thereby providing optimal diagnostic imaging in both static and kinematic contexts within a single visit.  Though several preliminary studies have hinted at the potential diagnostic value of kinematic imaging data, such data is difﬁcult to interpret and cannot easily be quantiﬁed or captured in clinical records. In this study, we seek to establish fundamental methods that can provide simple and easily digestible kinematic imaging reports with data acquired in a short scan interval using conventional clinical MRI equipment.  As a preliminary feasibility investigation of these methods, kinematic imaging of the wrist will be studied. Dysfunction of the scaphoid and lunate bones in the wrist is a well-studied kinematic problem of diagnostic signiﬁcance. Novel 4D zero-echo-time MRI of the wrist will be used to capture the kinematic imaging using for proﬁling of the scaphoid-lunate mechanics during two established wrist movement patterns.  The goal of this project is to establish and demonstrate methodological components required for MRI kinematic proﬁling. Data collection on a modest-sized cohort of 100 healthy control subjects is proposed for this purpose. Novel MRI pulse-sequence and post-processing development components are introduced and tasked for analysis of this normative data. Using the acquired MRI data, kinematic parameters for each dynamic dataset will be extracted and curated into a multi-parametric proﬁle for each subject.  Aim 2 of the study proposes the use of external sensor motion capture methods to validate the MRI-based kinematic parameter measurements on 50% of the study cohort.  Finally, Aim 3 of the study seeks to use machine-learning clustering approaches to develop a kinematic proﬁle normalization procedure using the acquired control dataset. Such normalization is a crucial milestone in the translation of kinematic proﬁling to the clinic and will establish a baseline for future translational studies of symptomatic cohorts. Project Narrative We seek to develop and demonstrate fundamental methods in quantitative kinematic proﬁling using clinical diagnostic imaging equipment. This technical development project is constructed under the hypothesis that such proﬁling of moving joints can highlight dysfunction, treatment progress, and point towards favorable (or unfavorable) surgical interventions. Using currently available advanced magnetic resonance imaging technology, data collected from a controlled subject cohort will be used to develop and test the proposed kinematic proﬁling technology on the moving wrist.",Enabling Kinematic Joint Profiling Using MRI,10107769,R21AR075327,"['3-Dimensional', 'Age', 'Algorithms', 'Anatomy', 'Biological Process', 'Biomechanics', 'Blood', 'Blood flow', 'Cardiovascular system', 'Cartilage', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Data', 'Data Collection', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Equipment', 'Feasibility Studies', 'Film', 'Functional Imaging', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Gold', 'Hand', 'Image', 'Imaging technology', 'Investigation', 'Joints', 'Ligaments', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Orthopedics', 'Patient risk', 'Patients', 'Pattern', 'Physiologic pulse', 'Physiological', 'Population Control', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Protocols documentation', 'Records', 'Reporting', 'Resolution', 'Rest', 'Rewards', 'Roentgen Rays', 'Scanning', 'Scaphoid bone', 'Semilunar Bone', 'Series', 'Structure', 'Surgeon', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Ultrasonography', 'Upper Extremity', 'Visit', 'Work', 'Wrist', 'Wrist joint', 'X-Ray Computed Tomography', 'base', 'biomarker panel', 'blood perfusion', 'bone', 'clinical diagnostics', 'clinical practice', 'cohort', 'heart function', 'high resolution imaging', 'human subject', 'image registration', 'imaging Segmentation', 'imaging modality', 'interest', 'joint mobilization', 'kinematics', 'motion sensor', 'novel', 'radiologist', 'soft tissue', 'task analysis', 'tool', 'translational study', 'volunteer', 'water diffusion']",NIAMS,MEDICAL COLLEGE OF WISCONSIN,R21,2021,163890
"Ultrasonic Imaging of Bone Graft Healing in Extraction Sockets for Precise and Personalized Implant Therapy Abstract Socket augmentation after tooth extraction by placing either allograft or xenograft bone particulates in the socket is frequently applied to reduce jawbone volume shrinkage for subsequent implant placement. Socket healing after the augmentation varies largely, ranging from uneventful healing to infection, failure of bone graft integration and severe bone loss due to bacterial infection and/or local/systemic conditions. The healing duration, which dictates the timing of implant placement, is widely different as well. Currently, an arbitrary waiting time of 6 months after socket augmentation is adopted, when a 2-dimensional (2D) or 3D radiograph, along with a visual examination is performed to assess hard- and soft-tissue healing to determine the readiness and strategy for the subsequent implant surgery. However, 3D radiographs are not recommended for longitudinal use to monitor socket healing due to radiation concerns. They have lower image resolution (250-500 µm), which limits their ability to evaluate bone surface healing, and inferior soft tissue contrast. A non-radiation and point-of-care method that can evaluate both hard- and soft-tissue longitudinally is much needed for a definitive, accurate, and timely diagnosis of socket healing pathologies. A high-frequency and miniature-sized intraoral ultrasound probe that can operate on an off-the-shelf scanner has been manufactured in collaboration with industry (see support letter) by our research team. Research conducted by our group demonstrated accuracy of this probe in measuring various oral and dental structures. The central hypothesis is to develop ultrasound-based imaging to characterize and grade socket healing lesions in determining the extent and severity of disease. To test this hypothesis, two aims are proposed: Aim 1. Evaluate the diagnostic value of ultrasonic images for bone grafting procedures of dental extraction sockets in a longitudinal clinical study (from -2 months to +6 months of graft placement). We will compare other imaging and clinical diagnostic tools for assessing hard- and soft tissue, anatomical and physiological status throughout the longitudinal study time-course. Aim 2. Develop an extended-view scan-mode for acquiring large field- of-view jawbone images and determine buccal (facial) to lingual tissue morphology. We will engage the manufacturer (see support letter) to modify the existing scanner for this dental specific application. Design goals will include the creation of an extended, large angle, field-of-view to visualize the buccal to lingual jaw bone surface and to create machine learning based measurement tools, including soft- and hard-tissue thickness and surface analysis. Successful execution of the proposed aims will result in an imaging-based tool for longitudinal socket augmentation evaluation that is based on soft- and hard-tissue features and will allow the care provider to choose deviation from current clinical procedures where indicated. This would be investigated subsequently in a specifically designed clinical trial. Narrative The goals of this investigation are to follow dental patients that require bone grafts before their dental implant is placed and to demonstrate the diagnostic opportunities that ultrasound adds to the current standard of clinical dental care. 3",Ultrasonic Imaging of Bone Graft Healing in Extraction Sockets for Precise and Personalized Implant Therapy,10427073,R56DE030872,"['3-Dimensional', 'Adopted', 'Allografting', 'Anatomy', 'Atrophic', 'Bacterial Infections', 'Blood', 'Blood flow', 'Bone Surface', 'Bone Transplantation', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials Design', 'Collaborations', 'Dental', 'Dental Care', 'Dental Implants', 'Dental caries', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Face', 'Failure', 'Frequencies', 'Goals', 'Gold', 'Image', 'Implant', 'Implantation procedure', 'Industry', 'Infection', 'Inferior', 'Inflammation', 'Investigation', 'Ionizing radiation', 'Jaw', 'Lateral', 'Lesion', 'Letters', 'Longitudinal Studies', 'Machine Learning', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Miniaturization', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Oral', 'Oral cavity', 'Organ Transplantation', 'Outcome', 'Particulate', 'Pathology', 'Patients', 'Perfusion', 'Physiological', 'Procedures', 'Process', 'Quality of life', 'Radiation', 'Readiness', 'Research', 'Resolution', 'Roentgen Rays', 'Scanning', 'Severities', 'Severity of illness', 'Site', 'Structure', 'Surface', 'Testing', 'Thick', 'Time', 'Time Study', 'Tissues', 'Tooth Extraction', 'Ultrasonography', 'United States', 'Visual', 'Wait Time', 'base', 'bone', 'bone healing', 'bone loss', 'bone xenograft', 'care providers', 'clinical diagnostics', 'cone-beam computed tomography', 'dental structure', 'design', 'experience', 'graft failure', 'graft healing', 'healing', 'improved', 'oral care', 'point of care', 'soft tissue', 'targeted treatment', 'tool', 'two-dimensional']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R56,2021,642438
"FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring Project Abstract/Summary Ultra-low dose CT, defined as sub-millisievert (sub-mSv) imaging of the entire chest, abdomen or pelvis, is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, photon starvation and electronic noise make imaging at such dose levels challenging. Photon starvation refers to the number of transmitted photons. When no photons are transmitted, the measurement is essentially useless. If few photons are transmitted, the measurement carries information, but its interpretation and value are confounded by electronic noise. Solutions with encouraging results have been offered for sub-mSv chest imaging, but these are not widely available and not easily generalizable across anatomical sites, vendors and scanner models. We propose a novel, robust solution for ultra-low dose CT that will overcome these issues. We refer to our solution as FAIR-CT, which stands for Finite-Angle Integrated-Ray CT. FAIR-CT operates under the principle that photon starvation and the confounding effect of electronic noise are best handled by avoiding them, which is made possible by increasing the data integration time during the source-detector rotation. FAIR-CT data strongly deviate from the classical CT data model and share the streak artifact problem of sparse view sampling. FAIR-CT data acquisition also affects azimuthal resolution. We anticipate that these issues can be suitably handled using advanced image reconstruction techniques. Once available, FAIR-CT will allow improvements in longitudinal monitoring of patients with chronic diseases such as COPD, urolithiasis and diabetes, thereby reducing mortality and co-morbidities. FAIR-CT will also allow advancing cancer therapy treatments by enabling adjustments in radiation therapy plans between dose fractions without increasing CT radiation exposure, and by facilitating early detection of inflammations in drug-based therapies. To bring FAIR-CT towards fruition, we will work on two specific aims: (1) Creation of a comprehensive collection of FAIR-CT data sets enabling rigorous development, validation and evaluation of image reconstruction algorithms; (2) Development, validation and evaluation of advanced image reconstruction algorithms. The FAIR-CT data sets will involve the utilization of state-of-the-art scanners and include real patient data synthesized from high dose scans acquired for standard of care. Two complementary image reconstruction approaches will be investigated. Namely, model-based iterative reconstruction with non-linear forward model and dedicated compressed sensing regularization; and deep learning-based refinement of FBP reconstructions using target images with task-adapted image quality. Image quality evaluation will account for critical biological variables and involve objective metrics such as structure similarity and contrast-to-noise ratio for clinically-proven lesions, as well as task-based performance metrics involving human readers. Ultra-low dose X-ray computed tomography is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, physics-related challenges and impractical solutions make this concept unavailable for everyday clinical use. We will develop a novel solution that is practical and can quickly be brought to clinical practice.",FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring,10158473,R21EB029179,"['Abdomen', 'Academia', 'Advanced Malignant Neoplasm', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Body mass index', 'Chest', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Clinical', 'Collection', 'Computers', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Early Diagnosis', 'Epidemic', 'Evaluation', 'Fruit', 'Goals', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Industry', 'Inflammation', 'Inflammatory Bowel Diseases', 'Lesion', 'Malignant Neoplasms', 'Measurement', 'Metabolic Diseases', 'Modeling', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Noise', 'Obesity', 'Patient Monitoring', 'Patients', 'Pelvis', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physics', 'Polycystic Kidney Diseases', 'Process', 'Pulmonary Inflammation', 'Radiation exposure', 'Radiation therapy', 'Radiology Specialty', 'Reader', 'Research', 'Resolution', 'Rotation', 'Sampling', 'Scanning', 'Source', 'Starvation', 'Structure', 'Techniques', 'Technology', 'Time', 'Validation', 'Vendor', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer risk', 'cancer therapy', 'clinical practice', 'clinical translation', 'clinically translatable', 'comorbidity', 'data acquisition', 'data integration', 'data modeling', 'data sharing', 'deep learning', 'detector', 'expectation', 'image reconstruction', 'improved', 'low dose computed tomography', 'mortality', 'novel', 'reconstruction', 'sex', 'side effect', 'standard of care', 'targeted imaging', 'urolithiasis']",NIBIB,UNIVERSITY OF UTAH,R21,2021,227282
"Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance PROGRAM SUMMARY Radiological imaging is often the first step of the diagnostic pathway for many devastating diseases; thus, an erroneous assessment of “normal” can lead to death. Whereas a grayscale object in an image can be described by its first-order image statistics—such as contrast, spatial frequency, position, entropy, and orientation—none of these dimensions, by itself, indicates abnormal vs normal radiological findings. We are a highly diverse team proposing an empirical approach to determine the mixtures of the first-order statistics—the “visual textures”— that radiology experts explicitly and implicitly use to identify the locations of potential abnormalities in medical images. Our innovative approach does not rely on assumptions about which textures may or may not be im- portant to abnormality detection. Instead, we will track the oculomotor behavior of expert radiologists to deter- mine their conscious and unconscious targeting choices, and thus ascertain which textures are empirically in- formative. The ability of expert radiologists to rapidly find abnormalities suggests that they may be able to first identify them in their retinal periphery. Peripheral visual analysis skills are therefore potentially critical to radio- logic performance, despite being understudied. We will measure these skills and leverage the results to develop perceptual learning heuristics to improve peripheral abnormality texture detection. By comparing novices to ex- perts we will determine whether the first are inexpert due to a lack of sensitivity to diagnostically relevant textures (texture informativeness), or to a lack of knowledge about which textures are abnormal, or to a combined lack of both sensitivity and knowledge. Radiology also requires the acquisition of oculomotor skills through practice and optimization. Radiologic expertise thus changes the oculomotor system in predictable and detectable ways, in much the same way that an athlete’s body and brain change as a function of expertise acquisition in their sport. We will therefore analyze both the consistency between experts’ fixation choices in medical images, and the eye movement performance characteristics of experts vs novice radiologists, to create an objective oculomotor bi- omarker of radiological expertise. The differences between novices and experts will train a deep learning (DL) system, which will have human visual and oculomotor performance characteristics. Training the DL with the abnormalities identified by a panel of expert radiologists will allow it to pinpoint the possible solutions in the manner of a simulated human radiologist performing at peak accuracy, precision, and speed. The resulting rank- ordered list of possible optimal and suboptimal image-reading strategies will serve as a benchmarking tool to quantify the performance of actual clinicians and residents who read the same images, rested vs fatigued. Meas- uring the effects of both training and fatigue on radiology expertise will be a major interdisciplinary cross-cutting advance in performance assessment. Our proposal to quantify fatigue in terms of erosion of expertise represents a transformational advance towards objective fitness-for-duty and expertise measures in medicine and beyond. PROJECT NARRATIVE There are 25-32 million perceptual errors in radiological case studies worldwide each year, contributing to med- ical error, the third most common cause of death in the US. We seek to reduce detection errors in radiology with four innovations: (1) we will empirically and objectively determine the visual textures used by expert radiologists to identify abnormalities within medical images; (2) we will determine the ways in which expert radiologists use their eyes, and especially their peripheral vision, to scan images and target informative regions; (3) we will de- velop a perceptual learning paradigm to optimally train residents in both texture perception and oculomotor per- formance domains; and (4) we will construct a deep learning model bestowed with simulated human visual and oculomotor capabilities, to create a normative model of human radiological expertise. The combined results from these studies will quantify peak expert performance and be employed to track and enhance individual expertise acquisition during radiology training; thus, the proposed research will help reduce medical error and moreover provide objective fitness-for-duty measurement tools—based on quantified biomarkers—to evaluate and ame- liorate the effects of fatigue on radiologic performance.",Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance,10220201,R01CA258021,"['Assessment tool', 'Benchmarking', 'Biological Markers', 'Brain', 'COVID-19', 'Cancer Detection', 'Case Study', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical/Radiologic', 'Collection', 'Conscious', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Diagnostic', 'Dimensions', 'Disease', 'Elements', 'Ensure', 'Entropy', 'Exposure to', 'Eye', 'Eye Movements', 'Fatigue', 'Film', 'Foundations', 'Frequencies', 'Human', 'Image', 'Incentives', 'Individual', 'Instruction', 'Knowledge', 'Lead', 'Learning', 'Location', 'Measurement', 'Measures', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Modeling', 'Nature', 'North America', 'Outcome', 'Participant', 'Pathway interactions', 'Perception', 'Perceptual learning', 'Performance', 'Peripheral', 'Positioning Attribute', 'Radiologic Finding', 'Radiology Specialty', 'Reading', 'Research', 'Residencies', 'Resolution', 'Rest', 'Retina', 'Scanning', 'Societies', 'Speed', 'Sports', 'Stress', 'System', 'Testing', 'Texture', 'Thoracic Radiography', 'Time', 'Training', 'Unconscious State', 'Vision', 'Visual', 'Workload', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cancer imaging', 'cohort', 'deep learning', 'design', 'experience', 'fitness', 'heuristics', 'human error', 'human model', 'improved', 'innovation', 'learning network', 'lung imaging', 'meetings', 'novel', 'oculomotor', 'oculomotor behavior', 'pandemic disease', 'patient safety', 'programs', 'radiological imaging', 'radiologist', 'sample fixation', 'shift work', 'skills', 'statistics', 'tool', 'tool development']",NCI,SUNY DOWNSTATE MEDICAL CENTER,R01,2021,646124
"Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients Esophageal adenocarcinoma (EAC) is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. Barrett’s esophagus (BE) confers elevated risk for progression to EAC. Patients diagnosed with BE undergo periodic surveillance endoscopy with biopsies to detect dysplasia which can be treated by endoscopic eradication with radiofrequency ablation before it progresses to EAC. However, the majority of diagnosed EAC patients have not had prior screening endoscopy and present with advanced lesions that limit treatment options and result in poorer survival. The development of a rapid, low cost, well tolerated, non-endoscopic BE screening technique that can be performed in unsedated patients at points of care outside the endoscopy suite would improve BE detection and reduce EAC morbidity and mortality. Our program is a multidisciplinary collaboration among investigators at the Massachusetts Institute Technology and Veteran Affairs Boston Healthcare System / Harvard Medical School that integrates novel optical imaging and software design, preclinical studies in swine, clinical studies in patients, and advanced image processing / machine learning. Aim 1 will develop an omniview tethered capsule technology that generates a map of the esophageal mucosa over a multi-centimeter length of esophagus and a series of wide angle forward views to aid navigation as the capsule is swallowed or retracted. The images will resemble endoscopic white light or narrow band imaging, but will not suffer from perspective distortion present in standard endoscopic or video capsule images. This will facilitate development of automated BE detection algorithms as well as enhance their sensitivity and specificity. This aim will also perform imaging studies in swine as a translational step toward clinical studies. Aim 2 will determine reader sensitivity and specificity for BE detection versus standard endoscopy / biopsy and prepare data for developing automated BE detection. Patients undergoing screening as well as with history of BE undergoing surveillance will be recruited and unsedated capsule imaging will be performed on the same day prior to their endoscopy. Sensitivity and specificity for detecting BE will be assessed using multiple blinded readers and data sets suitable for developing automated BE detection algorithms will be developed. Aim 3 will develop image analysis methods for automated BE detection by investigating classifiers that operate on handcrafted features (colors and textures) and modern deep convolutional neural network methods for direct classification. If successful, this program will develop a rapid, low cost and scalable method for BE screening that would not require patient sedation, endoscopy, or tissue acquisition, and which could be performed in community primary care clinics. The procedure would be much faster and many times lower cost than endoscopy. Automated BE detection would enable immediate results for patient consultation and referral to gastroenterology if indicated. Larger patient populations with expanded risk criteria could be cost effectively screened and access to screening dramatically improved, reducing EAC mortality. Esophageal adenocarcinoma is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. The program proposes to develop an omniview tethered capsule technology, examination protocol, and automated analysis methods for low cost, rapid, well tolerated, and scalable screening in order to facilitate monitoring and timely treatment. Larger patient populations could be cost effectively screened and access to screening dramatically improved, reducing mortality.","Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients",10210371,R01CA252216,"['Algorithmic Software', 'Algorithms', 'Back', 'Barrett Esophagus', 'Biopsy', 'Blinded', 'Blood Vessels', 'Boston', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Color', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Set', 'Deglutition', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dysplasia', 'Endoscopic Biopsy', 'Endoscopy', 'Esophageal Adenocarcinoma', 'Esophageal mucous membrane', 'Esophagus', 'Family suidae', 'Gastroenterologist', 'Gastroenterology', 'Gastroesophageal reflux disease', 'Healthcare Systems', 'Histology', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Institutes', 'Interdisciplinary Study', 'Label', 'Length', 'Lesion', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Massachusetts', 'Measures', 'Methods', 'Modernization', 'Monitor', 'Morbidity - disease rate', 'Mucous Membrane', 'Nurse Practitioners', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Population', 'Primary Care Physician', 'Primary Health Care', 'Procedures', 'Protocols documentation', 'Radiofrequency Interstitial Ablation', 'Reader', 'Reading', 'Recording of previous events', 'Referral and Consultation', 'Research Personnel', 'Resolution', 'Risk', 'Screening Result', 'Sedation procedure', 'Sensitivity and Specificity', 'Series', 'Side', 'Software Design', 'Stomach', 'Surface', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'United States Department of Veterans Affairs', 'Validation', 'advanced disease', 'automated analysis', 'automated image analysis', 'base', 'capsule', 'clinical imaging', 'convolutional neural network', 'cost', 'design', 'graphical user interface', 'image processing', 'imaging software', 'imaging study', 'improved', 'medical schools', 'mortality', 'navigation aid', 'novel', 'optical imaging', 'patient population', 'point of care', 'preclinical study', 'programs', 'recruit', 'screening']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,345509
"Rapid Motion-Robust and Easy-to-Use Dynamic Contrast-Enhanced MRI for Liver Perfusion Quantification Project Summary The broad objective of this application is to develop a rapid motion-robust and easy-to-use dynamic contrast- enhanced magnetic resonance imaging (DCE-MRI) framework for liver perfusion quantification and to evaluate its performance in quantitative assessment of hepatocellular carcinoma (HCC), the most prevalent primary malignancy in the liver. Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) using gadolinium-based contrast agents is currently a cornerstone for identifying and characterizing hepatic lesions, including HCC. However, the current clinical use of liver DCE-MRI is limited to visual assessment of the pattern of perfusion in 3-4 multiphasic images (arterial, venous and delayed phases), and these images are routinely acquired during multiple breath holds. DCE-MRI also has the potential for quantitative assessment of perfusion kinetics, which can provide a deeper insight into the tumor microenvironment for non-invasive characterization of different histological features of the tumor, such as tumor angiogenesis and aggressiveness. This is particularly relevant for HCC, which is typically diagnosed based on imaging without pathological confirmation from invasive biopsy. Unfortunately, conventional liver perfusion MRI techniques suffer from a number of important limitations that restrict its clinical implementation, including (1) slow imaging speed, (2) limited spatiotemporal resolution, (3) sensitivity to motion artifacts, and (4) time-consuming quantitative perfusion analysis. Meanwhile, the need for pre-contrast T1 mapping to convert MR signal to gadolinium concentration further complicates the already-cumbersome imaging workflow. These challenges and underlying complexity have all led to non-reproducible performance of liver perfusion MRI and have significantly diminished its ultimate clinical utility. In this project, we propose to develop new rapid MRI techniques combining novel motion-robust sampling strategies and advanced reconstruction models to address these challenges. The new imaging techniques will enable motion-robust 3D T1 mapping with whole-liver coverage for efficient estimation of contrast concentration and free-breathing DCE-MRI of the liver with high spatiotemporal resolution. We will also incorporate state-of-the-art methods in deep learning to further improve imaging performance, to reduce reconstruction time, and to substantially simplify perfusion quantification. These new technical developments will be integrated into a new liver perfusion MRI framework, which will be translated into the clinical setting for assessment of HCC in an exploratory clinical study. The overall hypothesis is that with the new imaging framework developed in the project, robust high spatiotemporal resolution perfusion MRI of the liver can be achieved under free breathing, and absolute quantification of liver perfusion can be performed without user- interaction. Given the rapidly rising incidence and substantial burden of HCC in the United States, successful completion of this project would enable significant progress towards improved characterization and management of HCC and other liver diseases with high clinical impact. Project Narrative The objective of this application is to develop and evaluate a rapid motion-robust and easy-to-use dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) framework for liver perfusion quantification. This new imaging framework is expected to promote the utilization, efficacy and clinical translation of liver perfusion MRI for improved management of hepatocellular carcinoma (HCC) and other diseases of high clinical impact.",Rapid Motion-Robust and Easy-to-Use Dynamic Contrast-Enhanced MRI for Liver Perfusion Quantification,10297597,R01EB030549,"['3-Dimensional', 'Address', 'Aftercare', 'Biopsy', 'Breathing', 'Cancer Etiology', 'Clinical', 'Clinical Research', 'Consumption', 'Contrast Media', 'Development', 'Diagnosis', 'Disease', 'Gadolinium', 'Hepatic', 'Histologic', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Kinetics', 'Lead', 'Learning', 'Lesion', 'Liver', 'Liver Dysfunction', 'Liver diseases', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Operative Surgical Procedures', 'Pathologic', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Perfusion', 'Phase', 'Prediction of Response to Therapy', 'Primary carcinoma of the liver cells', 'Radial', 'Recovery', 'Resolution', 'Sampling', 'Signal Transduction', 'Speed', 'Systemic Therapy', 'Techniques', 'Time', 'Translating', 'Treatment Efficacy', 'Tumor Angiogenesis', 'Tumor Burden', 'United States', 'Venous', 'Visual', 'analysis pipeline', 'base', 'cancer type', 'care costs', 'clinical implementation', 'clinical translation', 'contrast enhanced', 'curative treatments', 'data acquisition', 'deep learning', 'feasibility testing', 'flexibility', 'image reconstruction', 'imaging biomarker', 'improved', 'individualized medicine', 'ineffective therapies', 'insight', 'interest', 'liver imaging', 'mortality', 'motion sensitivity', 'novel', 'outcome forecast', 'prevent', 'rapid technique', 'reconstruction', 'response', 'routine imaging', 'side effect', 'spatiotemporal', 'tool', 'treatment strategy', 'tumor', 'tumor microenvironment']",NIBIB,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,464700
"Functional Cardiovascular 4D MRI in Congenital Heart Disease SUMMARY / ABSTRACT Congenital heart disease (CHD) is the most common birth defect, affecting 1.2% of all live births. Imaging plays a major role in managing CHD but remains challenging for evaluating complex cardiac and vascular abnormalities across a wide range of age and habitus. To address these limitations, the PIs have developed cardiovascular 4D flow MRI which can measure complex 3D blood flow in-vivo, a task difficult or impossible to obtain with other imaging strategies. Recent efforts have focused on two forms of CHD: 1) bicuspid aortic valve (BAV) which is the most common form of CHD, and 2) single ventricle physiology (SVP), one of the most severe forms of CHD. Our 4D flow MRI studies have successfully identified new hemodynamic biomarkers to better characterize CHD. We were the first to establish a physiologic link between aberrant 3D blood flow, elevated wall shear stress (WSS), aortopathy phenotype, and aortic wall tissue degeneration on histopathology in patients with BAV. In patients with SVP, our findings demonstrated relationships between surgical correction strategies and flow distribution to the lungs, a known factor implicated in SVP outcome. We have achieved successful clinical translation at Northwestern, where 4D flow MRI is now used as a clinical tool in diagnostic MRI exams for patients with CHD and aortic disease. Over the past four years, the PIs have assembled one of the largest 4D MRI databases with over 2500 patient exams. For this renewal application, we identified a need to increase the dynamic range of 4D MRI flow sensitivity to account for data complexity (3D + time) and the wide age range in CHD by a combination of dual-venc flow encoding, compressed sensing, and SSFP imaging. Second, three is a need for longitudinal studies to identify predictors of BAV and SVP outcome. Third, making these unique but complex 4D MRI data sets and analysis tools more widely available to the greater research community is challenging. In addition, no automated methods currently exist for advanced processing such as atlas based analysis across large cohorts. Analysis is thus time consuming and requires manual interactions (e.g. 3D vessel segmentation) which limits reproducibility and translation. To address this need, an established Northwestern data archival and pipeline processing resource based on remote high-performance computing clusters (NUNDA) will be utilized for standardized data archival, sharing, and pipeline processing of 4D MRI data. This platform will provide the unique opportunity to utilize annotated data available in the 4D MRI database (>1300 BAV, SVP, and control 4D MRI data analyzed in the initial funding cycle) for application of machine learning concepts to establish (semi-)automated 4D MRI analysis workflows in NUNDA. Thus, the renewal application for this study aims to 1) develop a rapid (15 min) non-contrast 4D MRI for clinical translation, 2) leverage the existing large 4D MRI database to identify 4D MRI metrics predictive of long-term (> 5 years) CHD patient outcome, and 3) establish a remote NUNDA platform for 4D MRI data sharing and automated analysis across large cohorts. PROJECT NARRATIVE Our goal is to develop non-contrast 4D MRI, a new diagnostic test to achieve an improved assessment for the most common and one of the most severe forms of congenital heart disease: bicuspid aortic valve and single ventricle physiology. We will leverage an existing large 4D MRI database to allow for long-term 5-8-year follow-up to establish new measures for improved outcome prediction and therapy management for patients with bicuspid aortic valve and single ventricle physiology. A comprehensive data archive will be established to allow for the dissemination of the 4D MRI data, analysis tools, and study results to the greater research community.",Functional Cardiovascular 4D MRI in Congenital Heart Disease,10117035,R01HL115828,"['3-Dimensional', '4D MRI', 'Acceleration', 'Address', 'Adult', 'Affect', 'Age', 'Anatomy', 'Aortic Diseases', 'Archives', 'Atlases', 'Biological Markers', 'Blood flow', 'Cardiac Output', 'Cardiovascular system', 'Child', 'Clinical', 'Common Ventricle', 'Communities', 'Complex', 'Congenital Abnormality', 'Consumption', 'Contrast Media', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease Progression', 'Exposure to', 'Funding', 'General Anesthesia', 'Goals', 'Growth', 'Heart Abnormalities', 'Heart Rate', 'High Performance Computing', 'Histopathology', 'Hospitals', 'Image', 'Infant', 'Link', 'Live Birth', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Operative Surgical Procedures', 'Outcome', 'Outcome Study', 'Oxygen', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Play', 'Population', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Role', 'Secure', 'Sex Differences', 'Testing', 'Time', 'Translations', 'adverse outcome', 'analysis pipeline', 'aortic valve', 'automated analysis', 'base', 'bicuspid aortic valve', 'clinical translation', 'cluster computing', 'cohort', 'congenital heart disorder', 'data analysis pipeline', 'data archive', 'data sharing', 'data standards', 'design', 'exercise capacity', 'flexibility', 'follow-up', 'hemodynamics', 'improved', 'improved outcome', 'in vivo', 'novel', 'novel diagnostics', 'outcome prediction', 'patient population', 'pediatric patients', 'prevent', 'shear stress', 'spatiotemporal', 'tissue degeneration', 'tool', 'vascular abnormality']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,709759
"FreeSurfer Development, Maintenance, and Hardening Abstract: Imaging of the human brain has seen explosive growth in the last two decades mainly through the various modalities of MRI. The massive amount of data requires automatic and robust tools for analysis. FreeSurfer (FS, surfer.nmr.mgh.harvard.edu) is one of the preeminent tools used for neuroimage analysis. FS has more than 44,000 downloads, and the core FS manuscripts have been cited more than 22,000 times. FS is part of the analysis core for many NIH-funded large-scale data acquisition projects such as the Human Connectome Project (HCP), Alzheimer's Disease Neuroimaging Initiative (ADNI), Framingham Heart Study (FHS), The Adolescent Brain Cognitive Development (ABCD), as well as the UK BioBank. One third of the 600+ ADNI-based publications cite FS. Simply put, much of the innovative research done in neuroimaging would not be possible without FS. Started in 1998, FS is best known for providing detailed and automated anatomical analysis of T1-weighted MRI images, especially for the cortical surface. However, FS anatomical analysis provides an ideal substrate for all modes of brain imaging including functional MRI, diffusion MRI, PET, optical/NIRS, as well as EEG/MEG. FS provides tools to perform these analyses as well as software to integrate with other analysis tools (e.g., SPM, FSL, AFNI). FS has been used for presurgical planning and even in the operating room.  The original grant mostly centered around Sequence Adaptive Multimodal Segmentation (SAMSEG). SAMSEG uses parametric Bayesian generative modeling to segment brain images. The SAMSEG framework fits atlas priors and multivariate Gaussian intensity models to brain images (including MRI artifacts such as bias fields). SAMSEG can take any modality or combination of modalities as input. Since it adapts its intensity model, it is robust to differences in scanner. Since it is a generative model, it is easy to extend to encompass more segmentation details. For example, the SAMSEG framework has been used to segment hippocampal subfield, amygdalar nuclei, thalamic nuclei, and extracerebral structures.  The main vision for the renewal is to extend the SAMSEG framework to accommodate longitudinal models, incorporate more anatomical details, and to use SAMSEG output as a basis for cortical surface placement that is, like SAMSEG, modality independent and capable of using any combination of modalities. In addition, we propose a series of new tools that will assist in the individual and group analysis of large studies by creating study-specific models. In addition to this new technical development, we are requesting support for software engineering, maintenance, and user support – mundane and not innovative, but high-impact this type of support is critical to the thousands of researchers who rely on FreeSurfer. Narrative: This work will support the popular FreeSurfer neuroimaging analysis software program used by thousands of researchers world-wide. FreeSurfer uses cutting edge algorithms to automatically extract a host of biomarkers from brain imaging data which can be used for research, pharmaceutical evaluation, and diagnosis. This proposal will allow for continued support of FreeSurfer from the developers as well as new development to make FreeSurfer faster, more robust, and easier to interpret.","FreeSurfer Development, Maintenance, and Hardening",10130964,R01EB023281,"['Adolescent', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Bayesian Modeling', 'Biological Markers', 'Blood Vessels', 'Brain', 'Brain imaging', 'Cell Nucleus', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Documentation', 'Electroencephalography', 'Engineering', 'Evaluation', 'Fatty acid glycerol esters', 'Framingham Heart Study', 'Free Will', 'Functional Magnetic Resonance Imaging', 'Funding', 'Gaussian model', 'Grant', 'Growth', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Industrialization', 'Inherited', 'Lesion', 'Leukoaraiosis', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuscripts', 'Modality', 'Modeling', 'Morphologic artifacts', 'Multiple Sclerosis Lesions', 'Neurosciences', 'Operating Rooms', 'Optics', 'Output', 'Pharmacologic Substance', 'Positron-Emission Tomography', 'Probability', 'Publications', 'Research', 'Research Personnel', 'Series', 'Software Engineering', 'Stream', 'Structure', 'Surface', 'System', 'Testing', 'Thalamic Nuclei', 'Time', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'biobank', 'bone', 'cognitive development', 'connectome', 'cranium', 'data acquisition', 'deep learning', 'human imaging', 'innovation', 'large scale data', 'multimodality', 'neuroimaging', 'programs', 'success', 'synergism', 'tool', 'white matter']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,555356
"Next-generation in-vivo fetal neuroimaging Next-Generation In-Vivo Fetal Neuroimaging The overall objective of this project is to dramatically improve fetal magnetic resonance imaging (MRI) to advance research in early human brain development and neurodevelopmental disorders, the burden of which is, unfortunately, high because of their life-long impact and high prevalence. Fetal MRI has been the technique of choice in studying prenatal brain development. Fetal motion, however, makes MRI slice acquisition unreliable at best, as the fetus frequently moves while the prescribed slices are imaged. Uncompensated fetal motion disrupts 3D coverage of the anatomy and reduces the spatial resolution of slice-to-volume reconstructions. Repeating the scans does not ensure full 3D coverage of the anatomy, but increases total acquisition time. This, in turn, dramatically reduces the success rate and reliability of fetal MRI in studying the development of transient fetal brain compartments that are selectively sensitive to injury over the course of fetal development. To mitigate these issues and improve fetal MRI, we propose to automatically measure fetal brain position and prospectively navigate slices to each new position in real-time. The impact of this approach will be to dramatically increase the success rate and spatial resolution of fetal MRI for the in-vivo investigation of developing brain compartments, while, in parallel, reducing scan time, effectively making fetal MRI less burdensome for the mother, more accurate, and cost effective. By eliminating the manual re- adjustment of stack-of-slice positions, the time that elapses between scans will be virtually continuous. Our proposed technique will also make fetal MRI less operator-dependent and thus, more reproducible across sites, which is essential to conducting multi-center studies and clinical trials. Prospective navigation of fetal MRI slices to compensate for motion requires the development of novel, real-time image processing algorithms to recognize the fetal brain and its position and orientation; to track fetal motion to steer slices; and to detect and re-acquire motion corrupted slices. In this project, we will develop innovative deep learning models to process fetal MRI slices in real-time; will translate those models into an integrated system to prospectively navigate fetal MRI slices; and will validate the system on fetuses scanned at various gestational ages. To assess the utility and impact of the proposed technology, we will measure subplate volume in fetuses. The four specific aims of this study are to 1) assess fetal MRI via variable density image acquisition and reconstruction; 2) achieve real-time recognition of the fetal brain in MRI slices; 3) develop a system of real-time fetal head motion tracking and steering of slices; and 4) measure the subplate volume in the developing fetal brain using MRI. These aims will collectively translate and validate new imaging and image processing techniques to advance fetal MRI, and effectively eliminate a critical barrier to making progress in the fields of developmental neurology and neuroscience. Project Narrative: The proposed research aims to develop, translate, and validate innovative in-vivo imaging technologies to improve imaging and studying the development of the human fetal brain before birth. The technology will enable and improve studies on the development of the brain in fetuses with congenital disorders or fetuses at risk of having neurodevelopmental issues later in life. This in-turn is expected to result in timely and more effective treatments and therapeutic interventions that will lead to vastly improved patient outcomes in both the short- and long-term, effectively reducing the burden of human disabilities arising from congenital disorders.",Next-generation in-vivo fetal neuroimaging,10280126,R01EB031849,"['3-Dimensional', 'Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Birth', 'Brain', 'Cell Proliferation', 'Cell physiology', 'Classification', 'Clinical Trials', 'Cognitive', 'Complex', 'Congenital Disorders', 'Data', 'Data Set', 'Development', 'Fetal Development', 'Fetus', 'Gestational Age', 'Head', 'Health Care Costs', 'High Prevalence', 'Human', 'Hypoxia', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury', 'Investigation', 'Life', 'Live Birth', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Mental Health', 'Modeling', 'Morphologic artifacts', 'Mothers', 'Motion', 'Multicenter Studies', 'Neurodevelopmental Disorder', 'Neurology', 'Neurons', 'Neurosciences', 'Noise', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Play', 'Positioning Attribute', 'Process', 'Property', 'Real-Time Systems', 'Relaxation', 'Reproducibility', 'Research', 'Resolution', 'Role', 'Rotation', 'Sampling', 'Scanning', 'Second Pregnancy Trimester', 'Signal Transduction', 'Site', 'Slice', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Uterus', 'absorption', 'brain tissue', 'cognitive disability', 'congenital heart disorder', 'convolutional neural network', 'cost effective', 'deep learning', 'density', 'disability', 'effective therapy', 'fetal', 'fetus at risk', 'image processing', 'image reconstruction', 'imaging study', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'large datasets', 'migration', 'myelination', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'new technology', 'next generation', 'novel', 'prenatal', 'prospective', 'real-time images', 'reconstruction', 'recurrent neural network', 'success', 'virtual']",NIBIB,BOSTON CHILDREN'S HOSPITAL,R01,2021,588593
"A novel method for volumetric oxygen mapping in living retina PROJECT SUMMARY It is widely accepted that oxygen deficiency is a culprit and a marker of several major retinal diseases, including diabetic retinopathy, age-related macular degeneration, glaucoma etc. However, it remains to be extremely challenging to measure oxygen in vivo in the eye, and no tools currently exist that can provide 3D oxygen distributions in the retina with high spatial resolution at appropriate imaging speeds. The goal of this project is to overcome these limitations and develop a new optical imaging technique for volumetric oxygen mapping in retina. Our approach will leverage the recently developed potent oxygen probes (such as Oxyphor 2P), whose phosphorescence decay times serve as quantitative markers of local oxygen partial pressures (pO2) in living tissues. To enable volumetric imaging with high throughput, we propose to develop a novel imaging instrument, termed oblique scanning laser ophthalmoscope (oSLO). oSLO is based on the concept of single lens scanned light sheet microscopy and enables volumetric phosphorescence lifetime imaging without time- consuming plane-by-plane pixel-wise sectioning. Our new method should be able to achieve 10 kilohertz voxel rate that is three orders of magnitude higher than the current state-of-the-art two-photon phosphorescence lifetime microscopy (2PLM). In this project we will: (Aim 1) develop a phosphorescence lifetime-based oSLO for volumetric pO2 mapping in living retina in mouse. The new design will allow parallel detection of signals at depth from each scanned location, so that the need in conventional depth sectioning is eliminated and imaging throughput is greatly increased. We will (Aim 2) dynamically image responses of retina and choroid to systemic hypoxia challenge using Oxyphor 2P. We will (Aim 3) then bridge oSLO measurements and label-free applications by multimodal imaging with visible light optical coherence tomography (vis-OCT). Using vascular pO2 as the ground-truth, we will develop a deep spectral training (DSL) algorithm to supervise the inverse calculation of vis-OCT for robust and reliable label-free retinal oximetry. This study will enable the first direct quantitative imaging of interactions between the two circulatory systems in retina (i.e. retinal and choroidal circulation), providing unprecedented information about retinal oxygen supply. IMPACT ON PUBLIC HEALTH: Successful completion of this program will deliver a new ground-breaking methodology for mapping oxygen in the retina that will greatly improve our understanding of retinal diseases. NARRATIVE Oxygen is essential in the retina, and the deficiency of oxygen is a culprit in a broad spectrum of retinal diseases. However, it remains challenging to measure oxygen in vivo in the eye. This multidisciplinary proposal is to develop a disruptive imaging method to provide unprecedented volumetric oxygen mapping in living mouse retina, as well as a deep learning method, to translate our oxygen measurements into label-free retinal oximetry for future clinical applications.",A novel method for volumetric oxygen mapping in living retina,10098478,R01EY032163,"['3-Dimensional', 'Address', 'Affect', 'Age related macular degeneration', 'American', 'Biochemistry', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Cardiovascular system', 'Cell Respiration', 'Choroid', 'Consumption', 'Data', 'Data Set', 'Detection', 'Diabetic Retinopathy', 'Dyes', 'Eye', 'Fluorescence Angiography', 'Fundus', 'Future', 'Glaucoma', 'Goals', 'Human', 'Hypoxia', 'Image', 'Imaging Device', 'Imaging Techniques', 'Inhalation', 'Label', 'Lasers', 'Life', 'Light', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Medicine', 'Metabolic', 'Methodology', 'Methods', 'Microscopy', 'Multimodal Imaging', 'Mus', 'Nobel Prize', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Oxygen', 'Oxygen saturation measurement', 'Partial Pressure', 'Pathologic', 'Pathology', 'Photons', 'Physiology', 'Public Health', 'Resolution', 'Retina', 'Retinal Diseases', 'Role', 'Scanning', 'Signal Pathway', 'Signal Transduction', 'Speed', 'Supervision', 'Time', 'Tissues', 'Training', 'Translating', 'Vascular System', 'Visible Radiation', 'adaptive optics', 'algorithm training', 'base', 'choroidal circulation', 'clinical application', 'clinical translation', 'deep learning', 'design', 'hemodynamics', 'human imaging', 'imaging modality', 'improved', 'in vivo', 'learning network', 'learning strategy', 'lens', 'multidisciplinary', 'novel', 'novel imaging technique', 'optical imaging', 'phosphorescence', 'porphyrin a', 'programs', 'quantitative imaging', 'response', 'retina circulation', 'retinal imaging', 'sensor', 'success', 'tool', 'two photon microscopy', 'two-photon']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,552744
"Rapid Low-Cost Quantitative 3D MRI and Gait Assessment of the Knee Project Abstract Motivation: Osteoarthritis (OA) is a painful disease that affects tens of millions of Americans, but is poorly understood, resulting in a lack of treatments. Enabling low-cost approaches for widespread study of risk factors, onset and early progression of OA will enable better understanding of OA mechanisms, treatment development, and triage of patients to different treatments based on speciﬁc disease phenotypes. Multiple systemic factors, biochemical factors, and other risk factors are associated with OA, but causes are difﬁ- cult to isolate and study during slow progression. Currently OA is diagnosed as joint-space narrowing using X-ray radiography, at a stage well beyond when interventions can be effective. Magnetic resonance imaging (MRI) of- fers sensitivity to morphologic and biochemical changes, but most methods are impractical for widespread clinical or research use. Usually MRI exams study only one knee, precluding the opportunity to compare knees. Sim- ilarly, biomechanics assessment typically requires numerous tests using advanced and rarely-available equip- ment and time-intensive analysis by skilled personnel, making this a challenge for widespread use. We have shown rapid, simultaneous 3D scanning of both knees with quantitative relaxometry and diffusion map- ping of connective tissues, combined with novel visualization of longitudinal change validated in a population with anterior cruciate ligament (ACL) tears. We have developed fully-automated cartilage and meniscus seg- mentation to simplify post-processing. (Our automated cartilage segmentation variability approaches that of reader-to-reader variability.) We now propose to combine MRI acquisition, reconstruction and analysis tech- niques with simple measures of kinematics into a widely applicable low-cost imaging and biomechanical test, which we will validate in subjects with ACL-injury and subjects with varying Kellgren-Lawrence grades of OA. Approach: We will begin by developing a robust 5-to-8-minute bilateral knee MRI exam, using an efﬁcient 3D isotropic acquisition and novel deep-learning based image reconstructions. This will be followed with automated cartilage segmentation and quantitative analysis (thickness, T2, diffusion) of all 3 knee plates and automated semiquantitative scoring approaches for synovitis, bone marrow and cartilage lesions. Inertial measurement units (IMUs) will be used to measure kinematics, and gait asymmetries. We will continue our studies in ACL pa- tients to validate techniques and to develop asymmetry analyses for both imaging and biomechanical measures. Finally, in subjects with varying OA grade, we will evaluate the potential of the overall low-cost approach to relate asymmetry and longitudinal change measures to progression and OA grade. Signiﬁcance: This project will develop an acquisition and analysis pipeline to quantify knee changes and left/right asymmetries that precede OA. We will characterize methods in idiopathic OA subjects and ACL- injured subjects at risk of post-traumatic OA. The very low target cost, under $120/subject, will ultimately enable widespread study of early onset and progression of different OA types, leading to earlier and better treatments. Project Narrative Osteoarthritis remains the leading cause of disability, and effective treatment will require efﬁcient assessment of disease risk-factors, onset, and progression, both for development and personalization of minimally invasive interventions. We propose a 5-minute 3D MRI exam of both knees without radiation or contrast injection, that will be combined with low-cost measures of knee motion and fully automated analysis methods to provide quan- titative measurements of cartilage, tendon, ligament, bone and ﬁbrocartilage health and asymmetries between knees. This low-cost, rapid, bilateral assessment will enable research studies in large populations, as well as adding quantitative bilateral information to clinical scans to dramatically improve understanding of onset of dif- ferent types of osteoarthritis.",Rapid Low-Cost Quantitative 3D MRI and Gait Assessment of the Knee,10232306,R01AR077604,"['3-Dimensional', 'Affect', 'American', 'Anterior Cruciate Ligament', 'Articulation', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Marrow', 'Bone Spur', 'Cartilage', 'Chronic', 'Clinical', 'Cluster Analysis', 'Connective Tissue', 'Cost Measures', 'Coupled', 'Data', 'Data Pooling', 'Degenerative polyarthritis', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Enrollment', 'Environment', 'Equipment', 'Etiology', 'Evaluation', 'Female', 'Fibrocartilages', 'Future', 'Gait', 'Gait abnormality', 'Goals', 'Health', 'Human Resources', 'Image', 'Imaging Techniques', 'Inflammatory', 'Injections', 'Injury', 'Intervention', 'Joints', 'Kellgren-Lawrence grade', 'Knee', 'Knee Osteoarthritis', 'Left', 'Length', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Meniscus structure of joint', 'Methods', 'Morphology', 'Motion', 'Motivation', 'Output', 'Pain', 'Patient Triage', 'Patients', 'Population', 'Protocols documentation', 'Protons', 'Quality of life', 'Quantitative Evaluations', 'Radiation', 'Reader', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Risk Factors', 'Roentgen Rays', 'Sampling', 'Scanning', 'Sex Differences', 'Slice', 'Surface', 'Synovitis', 'Techniques', 'Tendon structure', 'Testing', 'Thick', 'Time', 'Tissues', 'Visualization', 'analysis pipeline', 'anterior cruciate ligament injury', 'anterior cruciate ligament rupture', 'automated analysis', 'base', 'bone', 'cohort', 'cost', 'deep learning', 'density', 'disability', 'disease phenotype', 'disorder risk', 'early onset', 'effective therapy', 'gait examination', 'high body mass index', 'image reconstruction', 'improved', 'kinematics', 'learning classifier', 'meniscus injury', 'minimally invasive', 'novel', 'predictive test', 'primary outcome', 'quantitative imaging', 'reconstruction', 'research study', 'sensor', 'societal costs', 'therapy development', 'tissue biomarkers']",NIAMS,STANFORD UNIVERSITY,R01,2021,651069
"Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T Project Summary The goal of this project is to develop a framework for high-performance parallel transmission (pTx) that is trans- ferable to a wide range of MRI scanners, and apply it to push the spatial encoding limits of echo planar imaging (EPI) at 7 Tesla. EPI is by far the most widely used pulse sequence for rapid functional, diffusion, and perfusion imaging, and has been the focus of considerable development in recent years to increase its speed and spatial resolution. Now there is a strong desire to push EPI's spatial resolution down to the micro scale. For functional MRI (fMRI), this would enable imaging of ﬁne structures (layers, columns, and nuclei) of cortical and subcortical architecture while better resolving the hemodynamic response. For diffusion MRI (dMRI), micro scale EPI would improve surface and laminar analysis of ﬁbers in the cortex, as well as brain parcelation using fractional anisotropy differences between gray matter regions, while broadly reducing partial volume effects. It would further enable EPI to be broadly applied to accelerate anatomic scans that are geometrically matched to fMRI and dMRI scans. However, increasing the resolution of single-shot EPI requires longer readouts which extend echo times and re- duce functional contrast in fMRI and signal-to-noise in dMRI at 7 Tesla, while increasing geometric distortions and blurring. Segmented or multishot EPI is a classic method to increase spatial resolution without increasing readout durations, but is underutilized, primarily due to its high sensitivity to motion and dynamic phase changes between shots which cause large image artifacts.  We propose to develop a new multishot EPI technique called shuttered EPI, which addresses the lim- itations of conventional multishot EPI by imaging a set of spatially disjoint shutters in each shot. The shutters are produced by a multidimensional excitation pulse and are spatially shifted between shots to cover an entire slice. However, with thin slices the length of the excitation pulses are impractical (20-100 ms). Many-coil pTx (> 8 coils) can shorten the length of these pulses to feasible durations, but current 7 Tesla scanners have only 8 transmit channels due to cost, footprint, cabling, and other constraints. In the ﬁrst project period we pioneered a technique called array-compressed pTx (acpTx) which overcomes this limitation. Using acpTx, 8 transmit chan- nels can control an arbitrarily large number of coils, where the channels and coils are connected via an array compression network that is optimized with RF pulses for speciﬁc excitations. In this project, we will develop and apply acpTx methods and hardware (a many-coil head transmit array and an 8 channel-to-many coil array com- pression network) to achieve feasible RF pulse durations when exciting the shutter patterns required for shuttered EPI. These developments will be implemented on two major 7T scanner platforms and evaluated in submillimeter (600 micron) fMRI and dMRI acquisitions. Overall, the project encompasses the synergistic design of RF pulses, hardware, acquisitions and reconstructions to achieve a major advance in spatial encoding. Project Narrative Diffusion and functional magnetic resonance imaging (MRI) at 7 Tesla ﬁeld strength using echo planar imaging (EPI) has the potential to deliver clear images of brain structure and function at the level of layers, columns, and nuclei. However, when existing EPI scans are pushed to the spatial resolutions required to resolve these structures, they become highly sensitive to off resonance-induced geometric distortions, relaxation-induced blur- ring, physiological noise and motion. To address this problem, in this project we will develop many-coil array- compressed parallel transmission and apply it to enable shuttered multishot EPI scans that are robust to these effects.",Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T,10093035,R01EB016695,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Anisotropy', 'Architecture', 'Biological', 'Brain', 'Brain imaging', 'Cell Nucleus', 'Data', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Echo-Planar Imaging', 'Elements', 'Fiber', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Head', 'Homebound Persons', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Length', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methods', 'Morphologic artifacts', 'Motion', 'Noise', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Physiological', 'Problem Formulations', 'Relaxation', 'Research Project Grants', 'Resolution', 'Scanning', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Structure', 'Surface', 'System', 'Techniques', 'Thinness', 'Time', 'base', 'blood oxygen level dependent', 'cost', 'design', 'gray matter', 'hemodynamics', 'image reconstruction', 'improved', 'magnetic field', 'motion sensitivity', 'neuroimaging', 'perfusion imaging', 'phase change', 'reconstruction', 'response', 'simulation', 'spectroscopic imaging', 'time use', 'transmission process', 'virtual']",NIBIB,VANDERBILT UNIVERSITY,R01,2021,558172
"Simulation Tools for 3D and 4D CT and Dosimetry Abstract Photon-counting CT (PCCT) is a major technological advance in CT imaging. Using photon-counting instead of current energy-integrating detectors, PCCT can offer superior performance in terms of spatial resolution, artifact reduction, and most notably, material decomposition. PCCT’s energy differentiation utility offers an ability to more precisely distinguish different materials and optimize and expand the use of contrast agents in CT. With these abilities, PCCT can significantly facilitate quantitative imaging, reduce radiation exposure, and enable revolutionary new applications in functional and physiological imaging beyond existing CT techniques. To realize the full potential of PCCT in clinical practice, the technology needs comprehensive assessments and application-based optimizations. Effective design and deployment of PCCT depends on many design and use choices that should be made in view of the eventual clinical utility. Making these choices requires large scale trials on actual patients. However, such trials are challenging, considering the need to make many decisions prior to prototyping, the limited numbers of prototype PCCT scanners available today, and the often-unknown ground-truth in the patient images. Even for existing prototype systems, many decisions require repetitive trials with multiple acquisitions. This is both unethical and impractical considering radiation safety concerns and costs. These challenges can be overcome by utilizing virtual imaging trials (VITs) using computerized patients and imaging models. VITs provide an efficient means with which to determine the most effective and optimized design and use of imaging technologies with complete control over the study design. In our prior funded project, we developed a VIT framework to evaluate standard energy-integrating detector CT technologies. In this project, we expand the applicability of this framework to photon-counting detector CT. Specifically, we enhance our computational XCAT phantoms to model the necessary higher-resolution detail including normal and abnormal tissue heterogeneities and intra-organ contrast perfusion diversity across populations (Aim 1). To image the phantoms, we develop the first PCCT simulator capable of mimicking existing and emerging prototypes (Aim 2). The enhanced VIT framework will provide the essential foundation with which to comprehensively evaluate and optimize PCCT technologies and applications. In Aim 3, we assess and optimize the use of PCCT for morphological, textural, and compositional quantification in select oncologic and cardiac applications, two leading health detriments in the US where PCCT can offer a notable impact. The results will be the first of their kind in comprehensively evaluating the task-based merits and capabilities of PCCT, determining optimum dose per patient size for PCCT imaging of patients for cancerous lesions and cardiac plaque/stenoses, and helping to establish the effective utility of PCCT in clinical care. The purpose of this project is to develop and utilize a virtual framework to comprehensively evaluate and optimize emerging photon-counting devices and applications in CT imaging. The results will be the first of their kind evaluating the task-based merits and capabilities of photon-counting CT and will help establish its effectual utility in oncologic and cardiac care.",Simulation Tools for 3D and 4D CT and Dosimetry,10189580,R01EB001838,"['3-Dimensional', 'Abdomen', 'Anatomy', 'Cancerous', 'Cardiac', 'Caring', 'Clinic', 'Clinical', 'Computer software', 'Contrast Media', 'Data', 'Detection', 'Development', 'Devices', 'Disease', 'Dose', 'Ensure', 'Ethics', 'Evaluation', 'Foundations', 'Functional Imaging', 'Funding', 'Health', 'Heterogeneity', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Industry', 'Lesion', 'Manufacturer Name', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Noise', 'Organ', 'Pathologic', 'Patient imaging', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Population', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Research Design', 'Resolution', 'Resources', 'Role', 'Safety', 'Scientist', 'Series', 'Specimen', 'Stenosis', 'System', 'Task Performances', 'Techniques', 'Technology', 'Texture', 'Tissue Model', 'Tissues', 'Work', 'X-Ray Computed Tomography', 'analytical method', 'base', 'cardiac plaque', 'clinical application', 'clinical care', 'clinical practice', 'computerized', 'computerized tools', 'cost', 'cost efficient', 'deep learning', 'design', 'detector', 'dosimetry', 'experimental study', 'human imaging', 'human subject', 'improved', 'insight', 'learning strategy', 'photon-counting detector', 'prototype', 'quantitative imaging', 'simulation', 'soft tissue', 'tool', 'unethical', 'virtual', 'virtual imaging']",NIBIB,DUKE UNIVERSITY,R01,2021,534495
"Quantitative and Spectroscopic Imaging of Skeletal Muscle Changes in Sarcopenia at High Field Project Summary Sarcopenia, a condition characterized by loss of muscle mass and function in the elderly, is of increasing relevance in the United States due to its aging population. It is generally agreed that the weakening of the muscle in sarcopenia cannot be explained by loss of muscle mass alone, but the mechanisms behind this remain poorly understood. This is partly due to the lack of non-invasive techniques for observing muscle structure and composition in high detail. We propose to develop MRI techniques to measure muscle morphology, microstructure, and fat content to get a detailed view of the changes in muscle quantity and quality in patients with sarcopenia and how they relate to more easily attainable measurements of muscle function such as grip strength and gait speed. This would provide an important contribution to the ongoing debate about how such measurements could be used to define sarcopenia, which would pave the way for treatment development. We aim to develop novel methods to investigate the structure and composition of muscle using ultra-high-field MRI. Specifically, we aim to (1) obtain water-based images of skeletal muscle macro- and microstructure with unparalleled efficiency, image quality, and resolution; (2) obtain images of the spatial distribution of intramyocellular lipids in skeletal muscle, measuring both methyl and methylene to estimate saturation; and (3) to conduct a study comparing skeletal muscle structure and quality by looking at MR measurements of T2 relaxation rates, diffusivity (as proxies for inflammation and fiber size, respectively), fat fraction, and lipid composition, in subjects with sarcopenia and healthy controls and see how these quantities correlate to muscle function. This project has several innovative aspects. First, we will develop a method to estimate muscle morphology, T2 relaxation rates, and diffusivity with a single MRI sequence. Importantly, this will make the developed method easy to run at other MRI sites. Second, we will devise methods to perform robust, efficient imaging of intramyocellular lipid droplet distribution and saturation in human skeletal muscle in vivo at high field. Both of these methods will have unparalleled signal-to-noise ratio and robustness against image artifacts. The significance of this work is the investigation of the role of inflammation, fiber size, and lipid distribution in the weakening of muscle in sarcopenia and how these measurements are related to muscle function. The resulting conclusions and techniques may help establish a common standard for the definition of sarcopenia and aid in the development of future treatments for this condition. Project Narrative Sarcopenia, the loss of muscle mass and function with age, is a condition bound to increase in prevalence with an aging population. The muscle changes involved include not only reduction in mass but also changes in muscle quality not easily visualized with current methods. This work aims to develop efficient MRI techniques to investigate these changes in better detail, improving scientific understanding of the mechanisms of sarcopenia and how they relate to muscle function.",Quantitative and Spectroscopic Imaging of Skeletal Muscle Changes in Sarcopenia at High Field,10125507,K99AG066815,"['3-Dimensional', 'Affect', 'Age', 'Awareness', 'Biological Markers', 'Clinical', 'Communities', 'Consensus', 'Data', 'Development', 'Diagnostic', 'Diffuse', 'Diffusion', 'Elderly', 'Evaluation', 'Fatty acid glycerol esters', 'Fiber', 'Fracture', 'Frequencies', 'Future', 'Gait speed', 'Geriatrics', 'Goals', 'Hand Strength', 'Health', 'Health Personnel', 'Hospitalization', 'Human', 'Image', 'Imaging Techniques', 'Inflammation', 'Investigation', 'Life Expectancy', 'Lipids', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Marker', 'Methods', 'Morphologic artifacts', 'Morphology', 'Muscle', 'Muscle function', 'Muscular Atrophy', 'Noise', 'Patients', 'Phase', 'Physiologic pulse', 'Predisposition', 'Prevalence', 'Protons', 'Proxy', 'Relaxation', 'Research', 'Resolution', 'Role', 'Running', 'Signal Transduction', 'Site', 'Skeletal Muscle', 'Soleus Muscle', 'Spatial Distribution', 'Spectrum Analysis', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Treatment Effectiveness', 'United States', 'Water', 'Work', 'aging population', 'base', 'bone imaging', 'carbene', 'clinical biomarkers', 'design', 'falls', 'imaging biomarker', 'imaging modality', 'improved', 'in vivo', 'innovation', 'muscle form', 'muscle strength', 'muscular structure', 'novel', 'potential biomarker', 'quantitative imaging', 'radio frequency', 'recruit', 'sarcopenia', 'spectroscopic imaging', 'therapy development']",NIA,MASSACHUSETTS GENERAL HOSPITAL,K99,2021,114480
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10162472,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2021,283097
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10256621,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2021,447500
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876
"Detection and evolution of diffusely abnormal white matter in multiple sclerosis: a deep learning approach Multiple sclerosis (MS) is the most widespread non-traumatic, demyelinating disorder in young adults. Magnetic resonance imaging (MRI) aids in both diagnosing MS and assisting clinical management of patients. In addition to focal MS lesions, diffusely abnormal white matter (DAWM) is also seen on brain MRI in MS patients. While not understood completely, DAWM is thought to be a predictor of disease burden, possibly appears early on in the disease, and may be a marker of neurodegeneration in MS. However, longitudinal studies of DAWM are lacking, and segmentation of DAWM is manual, making it difficult to study the evolution of DAWM. The main objective of this proposal is to longitudinally study the development of DAWM in MS. This objective will be realized by analyzing preexisting longitudinal MRI data acquired on 1008 MS patients who participated in phase 3, blinded, multi-center clinical trial, referred to as CombiRx that was supported by NIH. The CombiRx data includes multi-contrast MRI and various clinical measures. Automatic identification of DAWM is a critical component of this proposal. Based on our preliminary studies, deep Learning (a class of machine learning algorithms) has the potential to automatically identify DAWM and estimate its volume. We will use the large CombiRx MRI data for training, validation, and testing of the deep learning models, and to study DAWM evolution in this MS cohort. The proposal has two major aims. In the first aim we will develop a deep learning model based on fully-convolutional neural networks for automatic segmentation of DAWM, gray matter, normal appearing white matter, and T2-hyperintense lesions guided by manual segmentation of two neuroimaging experts. In the second aim we will segment DAWM and all brain tissues, including focal lesions, at baseline and all available follow-up scans in the CombiRx cohort (up to 6.5 years). The temporal changes in volume, location, and MRI parameters of DAWM and focal T2 lesions will be computed. We will finally test whether DAWM is precursor to focal T2 lesions, associated with T2 lesion resolution, or a separate disease process altogether. If DAWM is shown to occur early on in the disease, it is possible to intervene sooner for improved outcome. Similarly, if DAWM is shown to be related to disease activity, it can serve as an objective and quantitative measure of the disease. Such an objective measurement would be highly valuable in developing targeted therapies and also in evaluating the treatment effect in MS patients. The main objective of this proposal is to study the evolution of diffusely appearing white matter (DAWM) in multiple sclerosis (MS) using a novel deep learning approach. The results of this study are expected to be highly valuable in evaluating the treatment effect in individual MS patients. These results can also help reduce time and money in conducting clinical trials substantially, which would lead to early introduction of promising drugs into the market. Finally, if DAWM occurs early on in the disease, as suggested by some of the publications, it is possible to therapeutically intervene sooner for improved outcome.",Detection and evolution of diffusely abnormal white matter in multiple sclerosis: a deep learning approach,10217627,R21NS118320,"['Affect', 'Artificial Intelligence', 'Attenuated', 'Big Data', 'Blinded', 'Brain', 'Cerebrospinal Fluid', 'Characteristics', 'Clinical', 'Clinical Management', 'Complex', 'Conduct Clinical Trials', 'Data', 'Demyelinating Diseases', 'Demyelinations', 'Detection', 'Development', 'Diagnosis', 'Diffuse', 'Disease', 'Disease Progression', 'Engineering', 'Evolution', 'Frequencies', 'Functional disorder', 'Future', 'Gliosis', 'Goals', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Label', 'Lead', 'Learning', 'Lesion', 'Liquid substance', 'Location', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Multi-Institutional Clinical Trial', 'Multiple Sclerosis', 'Multiple Sclerosis Lesions', 'Nature', 'Nerve Degeneration', 'Pathologic Processes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Prevalence', 'Process', 'Protons', 'Publications', 'Randomized Clinical Trials', 'Recovery', 'Relapsing-Remitting Multiple Sclerosis', 'Reporting', 'Resolution', 'Resources', 'Role', 'Scanning', 'T2 weighted imaging', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'automated segmentation', 'axonopathy', 'base', 'brain tissue', 'burden of illness', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'density', 'follow-up', 'gray matter', 'imaging modality', 'improved outcome', 'large datasets', 'machine learning algorithm', 'model development', 'multiple sclerosis patient', 'nervous system disorder', 'neuroimaging', 'novel', 'success', 'targeted treatment', 'treatment effect', 'white matter', 'young adult']",NINDS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2021,234000
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,10136081,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'detection test', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,821265
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,10170765,R21EB025621,"['Abdomen', 'Acoustics', 'Adult', 'Age', 'Anatomy', 'Area', 'Award', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Evaluation', 'Excision', 'Family suidae', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Measurement', 'Metals', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translations', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization', 'Work', 'algorithm training', 'base', 'convolutional neural network', 'cost', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'metallicity', 'obese patients', 'obese person', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,235027
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,10116379,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2021,195000
"Next-Generation Cardiovascular MRI powered by Artificial Intelligence Project Summary/Abstract: Despite the accuracy and versatility of cardiovascular MRI, its footprint is only 1% among cardiac imaging tests (SPECT, echocardiography, CT, MRI) in the US. While there are several factors such as referral patterns favoring SPECT and echocardiography among cardiologists that account for low utilization, the two addressable obstacles that preclude widespread adoption are lengthy scan time (imaging facility operational cost) and reading (physician cost). These obstacles must be addressed for community hospitals with limited resources to adopt cardiovascular MRI into clinical routine practice. While compressed sensing (CS), since its introduction into the MRI world in 2007, has led to highly-accelerated cardiovascular MRI acquisitions, the subsequent image reconstruction remains too slow (> 5 min for 2D time series, > 1 hour for 3D time series) for clinical translation (unmet need 1). Downstream, image analysis for cardiovascular MRI is notoriously labor intensive (e.g. 30- to 60-min) and limited (“circles” at two cardiac phases for cine MRI, whereas perfusion and late gadolinium-enhanced (LGE) images are evaluated visually), for what is essentially a basic computer vision task (unmet need 2). In direct response, we will address these two unmet needs and unlock the enormous potential of CMR using deep learning (DL). DL applications have exploded since advancements in optimization and GPU hardware. While several recent studies have applied neural networks such as convolutional neural networks (CNNs), U-Nets, and Generative Adversarial Nets (GANs) for reconstruction and segmentation, no study has implemented an inline end-to-end pipeline that receives raw k-space from the MRI scanner and delivers both reconstructed images and fully processed images automatically with high speed (< 1 min). The objectives of this study are: a) developing a network for image reconstruction with maximal acceleration (aim 1), (b) developing a network for image processing tasks (aim 2), and c) developing an integrated, end-to-end network that does both (aim 3). By developing an architecture that can simultaneously learn maximal acceleration, fine tune end-to-end performance, and perform reconstruction/inference using feed-forward networks, we anticipate a disruptive technology that will lead to a paradigm shift in cardiovascular MRI and increase its footprint in community hospitals. This 2-year study is doable because of the requisite database of raw k-space (not derived from DICOM) data (N = 617) and annotated cardiac MR images (N=3,021) from over 3,000 patients existing at our institution. Success of this proposal will deliver a disruptive technology that has potential to cause a paradigm shift in cardiovascular MRI and enable widespread adoption of cardiovascular MRI into clinical routine practice. PROJECT NARRATIVE: The goal of this proposal is to develop a new-generation cardiovascular MRI technology empowered by artificial intelligence, more specifically deep learning. The proposed technology accurately reconstructs cardiovascular images and segments cardiac regions of interest within 1 min without any human intervention. This disruptive technology addresses the two major bottlenecks – lengthy scan time and reading – that preclude widespread adoption of cardiovascular MRI by community hospitals.",Next-Generation Cardiovascular MRI powered by Artificial Intelligence,10226541,R21EB030806,"['3-Dimensional', '4D MRI', 'Acceleration', 'Address', 'Adopted', 'Adoption', 'Adult', 'Agreement', 'Architecture', 'Artificial Intelligence', 'Cardiac', 'Cardiovascular system', 'Childhood', 'Cine Magnetic Resonance Imaging', 'Classification', 'Clinical', 'Community Hospitals', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Digital Imaging and Communications in Medicine', 'Echocardiography', 'Gadolinium', 'Generations', 'Goals', 'Hour', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Institution', 'Intervention', 'Learning', 'Magnetic Resonance Imaging', 'Patients', 'Pattern', 'Performance', 'Perfusion', 'Phase', 'Physicians', 'Process', 'Protocols documentation', 'Reading', 'Reporting', 'Resources', 'Sampling', 'Scanning', 'Series', 'Speed', 'Technology', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'cardiovascular imaging', 'clinical practice', 'clinical translation', 'computer science', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'empowered', 'experimental study', 'heart imaging', 'high reward', 'high risk', 'image processing', 'image reconstruction', 'imaging Segmentation', 'imaging facilities', 'interest', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'outcome forecast', 'reconstruction', 'response', 'risk prediction', 'routine practice', 'signal processing', 'single photon emission computed tomography', 'success']",NIBIB,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2021,189806
"Machine learning algorithms to analyze large medical image datasets Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. Our overall objective for this research is to dramatically reduce the burden of creating high quality reference labels by requiring only a small set of such labels from experts. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. This will enable us to apply ML techniques to generate high quality labels of the large amounts of unlabeled data that are already available, which in turn will facilitate the assessment of potential quantitative imaging biomarkers. We will develop, extend and evaluate novel algorithms that represent three distinct strategies for reducing labelling cost. These three strategies are learning from unlabelled data incorporating a novel strategy for characterizing uncertainty, optimizing sample selection for expert quality labelling with a novel form of Active Learning especially suited for deep learning, and reducing the cost of achieving quality labeling by replacing or augmenting an expert with a crowd of inexperts. We will then implement and distribute these novel algorithms, facilitating the replication of our experiments. Finally, we will demonstrate the practical efficacy of these three strategies by applying them to the important challenge of identifying quantitative imaging biomarkers that best capture alterations in brain structure that are associated with characteristics of ASD. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes. Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes.",Machine learning algorithms to analyze large medical image datasets,10182522,R01LM013608,"['Active Learning', 'Address', 'Adoption', 'Algorithms', 'Benchmarking', 'Brain', 'Characteristics', 'Child', 'Clinical', 'Collection', 'Crowding', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Fatigue', 'Image', 'Image Analysis', 'Informatics', 'Interruption', 'Label', 'Learning', 'Life', 'Machine Learning', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Noise', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Reference Standards', 'Research', 'Sampling', 'Speed', 'Structure', 'Techniques', 'Training', 'Uncertainty', 'Update', 'autism spectrum disorder', 'base', 'clinical decision-making', 'cost', 'crowdsourcing', 'deep learning', 'design', 'experimental study', 'imaging Segmentation', 'imaging biomarker', 'improved', 'innovation', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'novel', 'novel strategies', 'prevent', 'quantitative imaging', 'radiologist', 'success', 'supervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,369580
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,10077550,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2021,190362
"Cooperative Control Robotics and Computer Vision: Development of Semi-Autonomous Temporal Bone and Skull Base Surgery Project Summary I am an assistant professor in the department of Otolaryngology-Head and Neck Surgery at the Johns Hopkins School of Medicine, where my practice is focused on neurotology and lateral skull base surgery. I am applying for a mentored surgeon-scientist career development award (CDA) to obtain further training in robotics, deep learning and computer vision. This will further my long-term career goals of improving neurotologic surgical outcomes through novel applications of engineering methods and ultimately to investigate semi-autonomous, robotic interventions in the inner ear and skull base which are beyond the limits of the human hand alone.  Operating in the temporal bone and lateral skull base is technically demanding due to complex three- dimensional anatomy, small working spaces and delicate neurovascular structures. Many of these challenges are ideally suited to semi-autonomous surgical platforms to augment a surgeon’s skills with robotic and image- guided assistance. Despite the widespread implementation of robotic surgery and image guidance in other areas of the body, the field of neurotology has had relatively little adoption of this technology. We believe one reason for this is the precise registration needed in this field, where millimeter differences differentiate a successful from a catastrophic result. This CDA proposes expanding on my prior work investigating cooperative control robotics and virtual safety barriers by using computer vision and deep learning networks to develop highly accurate surgical image registration. This CDA aims to provide me with multi-disciplinary training in the departments of Otolaryngology, Biomedical Engineering and Computer Science. Specific training goals include: (1) Training in robotics, statistical shape modeling and computer tomography landmark segmentation, (2) Training in deep learning networks and computer vision video image registration, (3) Integrating this training, with my knowledge of temporal bone and skull base surgery to develop into an independent investigator (4) Pursue additional training in the ethical and responsible conduct of research.  The research plan addresses the hypothesis that virtual safety barriers can be accurately enforced by a cooperative control robot, and computer vision methods can be used to automate accurate placement and registration of these safety barriers. I believe that the integration of these techniques will allow for semi- autonomous surgical methods resulting in improved surgical safety and efficiency. The specific aims of the proposal are to: (1) Develop and Validate Cooperative Control Robot Enforced Virtual Safety Barriers for Cortical Mastoidectomy (2) Develop and Test Autonomous Segmentation of Lateral Skull Base Anatomy (3) Develop Video-Based, Fiducial-less, Surgical Image Registration to Detect and Update the 3-D Position of Temporal Bone Anatomy from Intraoperative Stereoscopic Microscope Video. Project Narrative The research proposed here will investigate the feasibility of using novel applications of computer vision and cooperative control robotics to enforce virtual safety barriers in neurotologic surgery. Our long-term goal is to develop semi-autonomous, robotic methods to improve the safety and efficiency of neurotologic surgery, and open the possibilities for surgical interventions which currently are beyond the abilities of the human hand alone.",Cooperative Control Robotics and Computer Vision: Development of Semi-Autonomous Temporal Bone and Skull Base Surgery,10283480,K08DC019708,"['3-Dimensional', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Area', 'Atlases', 'Automobile Driving', 'Automobiles', 'Biomedical Engineering', 'Cadaver', 'Cochlea', 'Complex', 'Computer Vision Systems', 'Computers', 'Consumption', 'Data', 'Drug Delivery Systems', 'Dura Mater', 'Electromagnetics', 'Engineering', 'Equilibrium', 'Ethics', 'Facial nerve structure', 'Feedback', 'Future', 'Goals', 'Hand', 'Head and Neck Surgery', 'Hearing', 'Human', 'Image', 'Image-Guided Surgery', 'Intervention', 'Judgment', 'K-Series Research Career Programs', 'Knowledge', 'Labyrinth', 'Lateral', 'Left', 'Manuals', 'Mentors', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Monitor', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Otolaryngology', 'Outcome', 'Patients', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Robot', 'Robotics', 'Safety', 'Scientist', 'Shapes', 'Sigmoid colon', 'Site', 'Speed', 'Structure', 'Surface', 'Surgeon', 'Surgical Instruments', 'Surgical complication', 'System', 'Tactile', 'Techniques', 'Technology', 'Temporal bone structure', 'Testing', 'Time', 'Training', 'Tremor', 'Update', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'career', 'computer science', 'deep learning', 'digital', 'digital imaging', 'image guided', 'image registration', 'improved', 'instrument', 'learning network', 'medical schools', 'microscopic imaging', 'millimeter', 'multidisciplinary', 'neurovascular', 'novel', 'professor', 'responsible research conduct', 'robot control', 'simulation', 'skills', 'skull base', 'stereoscopic', 'success', 'surgery outcome', 'three-dimensional modeling', 'virtual', 'vision development']",NIDCD,JOHNS HOPKINS UNIVERSITY,K08,2021,191792
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10226322,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data repository', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2021,220287
"Radiomics signatures and patient outcomes in intracerebral hemorrhage PROJECT SUMMARY / ABSTRACT The following K23 proposal is for Dr. Sam Payabvash, a Neuroradiologist and Assistant Professor of Radiology at Yale University. Dr. Payabvash is a physician-scientist with specialized expertise at the intersection of neuroscience, neuroimaging, and computer vision. His career goal is to find new treatment targets and to provide personalized care for patients with cerebrovascular disease. Intracerebral hemorrhage (ICH) is one of the most devastating cerebrovascular diseases with no effective treatment. To date, imaging markers of ICH risk- stratification and outcome prediction have been subjective and descriptive in nature, leaving a large gap for automated assessment of imaging feautres embedded in medical images. Preliminary results by Dr. Payabvash have demonstrated the feasibility of a research plan to apply automated feature extraction pipelines and machine learning algorithms to harness the information in medical images for early risk-stratification and identification of potential treatment targets in ICH. In this proposal, Dr. Payabvash will use detailed clinical and imaging data of 3,991 patients from NIH-funded clinical trials, online archives, and institutional registries at Yale, Tufts, and University College of London. He will apply machine-learning algorithms to identify those imaging features of brain hemorrhage on baseline head CT scan that are related to symptom severity at presentation (aim 1). Then, he will use imaging features of hemorrhage to identify those patients who are at risk for early expansion of hematoma (aim 2a), or surrounding edema (aim 2b). These two “modifiable” indicators of poor outcome are considered potential treatment targets in ICH patients. Finally, he will combine admission clinical information and imaging features to build a risk-stratification tool for long-term outcome prediction (aim 3). Under the expert mentorship of Dr. Kevin Sheth (Chief of Neurocritical Care), Dr. Todd Constable (Director of MRI Research), and Dr. Ronald Coifman (Professor of Mathematics), this K23 award will allow Dr. Payabvash to (1) identify and address the most pressing issues in cerebrovascular disease with innovative neurogaming tools; (2) gain expertise in advanced statistical analysis of brain scans; and (3) expand his knowledge in machine learning and computer vision for assessment of medical images. Dr. Payabvash will receive didactic training in neuroimaging statistical analysis, machine learning, deep neural networks, and computer vision. The proposed research and career development plans draw on the wealth of resources available at Yale, including a Regional Coordinating Center for the NIH StrokeNet, the Center for Research Computing; High Performance Computing services, and cutting-edge image processing and analysis infrastructure. At the conclusion of this award period, Dr. Payabvash will be well-positioned to become an independently-funded investigator conducting high-quality research in advanced neuroimaging techniques and analysis aimed at improving the care of patients with cerebrovascular disease. PROJECT NARRATIVE Intracerebral hemorrhage (ICH) is a severely debilitating cerebrovascular disease, which affects over 70,000 patients per year in the U.S., and is responsible for over half of stroke-related disability worldwide. So far, the diagnosis, surveillance, and prediction of outcome in intracerebral hemorrhage have mainly relied on visual and subjective assessment of head CT scans. Computerized assessment of medical images and machine learning algorithms can extract hidden features from CT scans and provide innovative tools for accurate outcome prediction and personalized treatment decisions in patients with hemorrhagic stroke.",Radiomics signatures and patient outcomes in intracerebral hemorrhage,10301527,K23NS118056,"['Address', 'Admission activity', 'Affect', 'Age', 'Atlases', 'Award', 'Biologic Characteristic', 'Biological', 'Biological Markers', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Brain scan', 'Caring', 'Cellularity', 'Cerebral hemisphere hemorrhage', 'Cerebrovascular Disorders', 'Cerebrum', 'Characteristics', 'Clinical', 'Clinical Trials', 'Computer Vision Systems', 'Data', 'Deterioration', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Edema', 'Funding', 'Future', 'Genomics', 'Goals', 'Grant', 'Growth', 'Head', 'Healthcare', 'Hematoma', 'Hemoglobin', 'Hemorrhage', 'Heterogeneity', 'High Performance Computing', 'Hour', 'Human', 'Image', 'Image Analysis', 'Inflammatory', 'Infrastructure', 'Knowledge', 'Lead', 'Lesion', 'Linear Models', 'Location', 'London', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Mentored Patient-Oriented Research Career Development Award', 'Mentorship', 'Modeling', 'Nature', 'Necrosis', 'Neurologic', 'Neurologic Deficit', 'Neurologic Symptoms', 'Neurosciences', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Positioning Attribute', 'Process', 'Prognostic Factor', 'Proteomics', 'Radiology Specialty', 'Reading', 'Registries', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rogaine', 'Scientist', 'Services', 'Severities', 'Shapes', 'Signal Transduction', 'Statistical Data Interpretation', 'Stroke', 'Symptoms', 'Techniques', 'Texture', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Writing', 'X-Ray Computed Tomography', 'automated analysis', 'base', 'bioimaging', 'blood-brain barrier disruption', 'career', 'career development', 'clinical risk', 'college', 'computerized', 'cytotoxic', 'data archive', 'deep neural network', 'density', 'disability', 'effective therapy', 'evidence base', 'feature extraction', 'feature selection', 'follow-up', 'functional independence', 'image processing', 'imaging biomarker', 'improved', 'innovation', 'machine learning algorithm', 'metabolomics', 'modifiable risk', 'neuroimaging', 'neuroimaging marker', 'new therapeutic target', 'novel', 'online repository', 'outcome prediction', 'personalized care', 'personalized medicine', 'precision medicine', 'professor', 'prognostic', 'quantitative imaging', 'radiomics', 'research and development', 'risk stratification', 'skills', 'statistics', 'tool', 'treatment optimization']",NINDS,YALE UNIVERSITY,K23,2021,194939
"CT and CXR Phenotyping Platform for Assessing COVID-19 Susceptibility and Severity Abstract COVID-19 was declared a pandemic by WHO on March 11. Since then, there have been 8.15 million confirmed cases worldwide with a case fatality rate ranging from 16.3% to 0.1%. In the US, there have been 2,187,202 cases with a 5.4% case fatality rate as of June 16, 2020. The magnitude of this infectious disease has stressed the need to develop novel methodologies to define who are at the highest risk of developing acute symptoms. X-Ray (CXR) and Computed Tomography (CT) play a fundamental role in the detection and follow-up of the COVID-19 lung injury. It also provides a unique opportunity to define quantitative biomarkers that may identify susceptible subjects to the acute phase of the disease using pre-infection and early infection radiological exams. This proposal's broad objective is to provide a better understanding of acute COVID-19 susceptibility markers based on artificial intelligence approaches on radiological exams, both CT and CXR. CT offers a unique way to phenotype the lung and its changes. Subtle changes of normal parenchyma have been associated with systemic inflammation that can be detected on CT. We hypothesize that susceptible subjects for acute COVID- 19 disease evolution will express inflamed normal parenchymal signatures that can be measured on CT scan prior to the infection or in the early phases of the viral infection. We will develop new computational approaches to identify radiographic patterns consistent with inflamed normal parenchyma as well as early COVID-19 injury and compute radiomics signature that can capture the heterogeneity of the radiographic expression for each lung pattern. We will define new CT-based biomarkers for acute COVID-19 susceptibility using Gradient Boosting decision trees and feature importance. We will then translate the quantification of the most relevant features in CXR image using image translation approaches based on deep neural networks. Finally, we will integrate these automated tools in the CIP workstation using clinically friendly end-to-end workflows to empower clinical investigations across the world. We will continue the support and dissemination of this tool across the research community. Over the last 15 years, our group has developed the Chest Imaging Platform (CIP), an NIH-funded open-source software tool for the automated phenotyping of chest CT scans that is widely used in the chronic lung disease research community. Since the beginning of the pandemic, CIP has been used to the characterization of COVID-19 using existing densitometric metrics. Our commitment to open science in the form of open toolkits that are freely distributed is fundamental to catalyze the application of AI and imaging in the context of this pandemic. Project Narrative As of June 16, there has been 2.18 million confirmed cases of COVID-19 in the United States with 118,435 fatalities. Unlike many other diseases, only general epidemiological factors are available for describing the susceptibility to COVID-19 and its acute phase. Biomarkers computed from CT and CXR images of the chest provides a personalized approach to define prognostic markers of disease susceptibility.",CT and CXR Phenotyping Platform for Assessing COVID-19 Susceptibility and Severity,10196276,R21LM013670,"['2019-nCoV', 'Acute', 'Architecture', 'Artificial Intelligence', 'Biological Markers', 'COVID-19', 'COVID-19 patient', 'COVID-19 susceptibility', 'Case Fatality Rates', 'Chest', 'Chronic', 'Chronic lung disease', 'Clinical', 'Communicable Diseases', 'Communities', 'Data', 'Decision Trees', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Disease', 'Disease susceptibility', 'Epidemiologic Factors', 'Evolution', 'Funding', 'Goals', 'Heterogeneity', 'Image', 'Immune response', 'Infection', 'Inflammatory', 'Injury', 'Intensive Care', 'Lung', 'Lung Inflammation', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modality', 'Outcome', 'Patient Care', 'Pattern', 'Phase', 'Phenotype', 'Play', 'Predisposition', 'Prognostic Marker', 'Radiology Specialty', 'Research', 'Resolution', 'Response Elements', 'Roentgen Rays', 'Role', 'SARS-CoV-2 infection', 'Scanning', 'Severities', 'Severity of illness', 'Smoking', 'Software Tools', 'Stress', 'Structure of parenchyma of lung', 'Techniques', 'Technology', 'Thoracic Radiography', 'Training', 'Translating', 'Translations', 'United States', 'United States National Institutes of Health', 'Virus', 'Virus Diseases', 'X-Ray Computed Tomography', 'acute care', 'acute symptom', 'base', 'chest computed tomography', 'clinical investigation', 'clinical translation', 'deep learning', 'deep neural network', 'follow-up', 'high risk', 'imaging platform', 'interest', 'learning strategy', 'lung injury', 'novel', 'open data', 'open source', 'pandemic disease', 'personalized approach', 'predictive modeling', 'prognostic', 'radiomics', 'response', 'severe COVID-19', 'systemic inflammatory response', 'therapeutic development', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R21,2021,155730
"Virtual Biopsy with Tissue-level Accuracy in Glioma Project Summary This is a Bioengineering Research Grant (BRG) proposal in response to PAR-19-158 to further develop and validate a non-invasive panel of the most critical glioma molecular markers (IDH, 1p/19q, MGMT) using standard clinical MRI T2-weighted images and deep learning, and extend the performance to tissue-level accuracies. Currently, the only reliable way of obtaining molecular marker status is through direct tissue sampling of the tumor, requiring either a craniotomy and stereotactic biopsy or a large open surgical resection. Noninvasive determination of molecular markers with tissue-level accuracy would be transformational in the management of gliomas, reducing or eliminating the risks and costs associated with a neurosurgical procedure, accelerating the time to definitive treatment, improving patient experience and ultimately patient outcomes and survival time. Artificial intelligence such as deep learning has emerged as a powerful method for classification of imaging data that can exceed human performance. Preliminary work using our novel voxel-wise classification-segmentation approach with the NIH/NCI TCIA glioma database has outperformed any prior noninvasive methods for determination of IDH, 1p/19q, and MGMT methylation, achieving accuracies of 97%, 93%, and 95%, respectively. The approach however, needs to be validated beyond the TCIA and accuracies need to be extended in order to achieve tissue level performance. This will be accomplished by using our top-performing voxel-wise classification framework, leveraging marker-specific targeted sample sizes, and gaining a final boost from deep-learning artifact correction networks. In Aim 1 we will curate a database of over 2000 gliomas including 500 subjects from our institution, 1200 subjects from our external collaborators, and over 300 subjects from the TCIA. We will train our voxel-wise deep learning classifiers to determine molecular status based on clinical T2-weighted MR images with target accuracies of 97%. In Aim 2 we will rigorously evaluate the motion and noise sensitivity of the networks and create an artifact correction network with the goals of 1) recovering accuracies in the setting of large amounts of motion/noise and 2) further boosting accuracy to tissue-level performance even in the absence of visible artifact. In Aim 3 we will deploy a complete end-to-end clinical workflow and evaluate real-world live performance of the AI tool on 300 prospectively acquired brain tumor cases and 300 subjects from our external collaborators. The AI tool will be made available for deployment at other medical centers. The developed framework can also be extended to additional markers in a straightforward fashion. In summary, this BRG proposal will further develop, refine and validate a non-invasive MRI-based method for determining the most critical glioma molecular markers rivaling tissue-level accuracies to significantly reduce and in many cases eliminate the need for stereotactic biopsy. Project Narrative Knowledge of molecular status for a variety of markers in gliomas has moved to the forefront in clinical decision- making. This requires direct tissue sampling either from an invasive brain biopsy or open surgical resection. In this Bioengineering Research Grant proposal in response to PAR-19-158, we will develop and validate a non- invasive method to determine a panel of the most critical molecular markers (IDH, 1p/19q and MGMT methylation) with near tissue-level accuracies using routine T2-weighted (T2w) MR images and deep learning algorithms to significantly reduce and in many cases eliminate the need for stereotactic biopsy in glioma.",Virtual Biopsy with Tissue-level Accuracy in Glioma,10226632,R01CA260705,"['19q', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Automation', 'Biology', 'Biomedical Engineering', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Classification', 'Clinical', 'Computerized Medical Record', 'Craniotomy', 'Data', 'Data Set', 'Databases', 'Digital Imaging and Communications in Medicine', 'Excision', 'Glioma', 'Goals', 'Human', 'Hyperacusis', 'Image', 'Institution', 'Knowledge', 'MGMT gene', 'Magnetic Resonance Imaging', 'Manuals', 'Medical center', 'Methods', 'Methylation', 'Molecular', 'Molecular Analysis', 'Morphologic artifacts', 'Motion', 'Neurosurgical Procedures', 'Noise', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Process', 'Prospective cohort', 'Reporting', 'Research Project Grants', 'Resources', 'Risk', 'Sample Size', 'Sensitivity and Specificity', 'T2 weighted imaging', 'Testing', 'The Cancer Genome Atlas', 'The Cancer Imaging Archive', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Tumor Tissue', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'clinical decision-making', 'clinical implementation', 'clinical translation', 'contrast imaging', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'large datasets', 'learning classifier', 'learning strategy', 'molecular marker', 'motion sensitivity', 'mutational status', 'novel', 'outcome forecast', 'prospective', 'response', 'surgical risk', 'tool', 'tumor', 'virtual biopsy']",NCI,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,655597
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,10179376,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,449722
"Ultra-Fast Knee MRI with Deep Learning ABSTRACT Fast, robust and reliable quantitative knee joint MR imaging would be a significant step forward in studying joint degeneration, injury and osteoarthritis (OA). Automation of compositional and morphological feature extraction of the tissues in the knee it is an essential step for translation to clinical practice of promising quantitative techniques. It would enable the analysis of large patient cohorts and assist the radiologist/clinician in augmenting the value of MRI. Automation of several human tasks has been achieved in the last few years by the usage of Deep Learning techniques. With the availability of large amounts of annotated data and processing power, using the concepts of transforming data to knowledge by the observation of examples, supervised learning can today accomplish challenges never demonstrated before. In addition to image analysis and interpretation, Deep Learning is revolutionizing the acquisition and reconstruction aspects of the pipeline. Models can learn a direct mapping between under sampled k-space and image domain. While Deep Learning application to musculoskeletal imaging showed promising results when applied in a controlled setting, it is well understood that generalization beyond the statistical distribution of the training set is still an unmet challenge. In MRI this translates into poor performances when trained models are tested on different imaging protocols or images acquired on different MRI systems. With this proposal, we aim to leverage on this recent advancement and filling the existing gaps. We aim to study novel integrated models able to simultaneously accelerate MRI acquisition and automate the image processing that can overcome the limitation of single domain application. Fast image acquisition and accurate image post processing are typically considered to be separate problems. However, the neural networks optimization design gives us an opportunity to integrate the two to maximize both acceleration and machine-based image processing and interpretation. We will use both publicly available benchmark dataset (FastMRI) and internally collected dataset to build deep learning models able to accurately reconstruct under sampled MRI acquisitions. We will use a dataset prospectively acquired during the course of this study to validate the clinical applicability of the developed methods. Specifically, we will test the hypothesis that the proposed integrated pipeline can be applied in clinical setting for a fast and intelligent knee scan obtaining image quality comparable to standard acquisition and automated processing accuracy comparable with human reproducibility. Additionally, we propose to make our annotated image datasets and trained models a shared resource, a centralized, open evaluation platform for MRI reconstruction and image post processing techniques. NARRATIVE This study aims to use Deep Learning to simultaneously accelerate knee MRI acquisition and automate post processing pipelines including multi tissue segmentation, detection and severity staging of osteoarthritis degenerative changes. The proposed study builds a novel translational platform to revolutionize knee MR images in research studies, but also is paradigm-shifting in that it may provide a first step towards on real time automatic image inspection and personalized imaging protocolling.",Ultra-Fast Knee MRI with Deep Learning,10177641,R01AR078762,"['3-Dimensional', 'Acceleration', 'Area', 'Automation', 'Bayesian Modeling', 'Benchmarking', 'Cartilage', 'Characteristics', 'Clinical', 'Collection', 'Complement', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Ensure', 'Evaluation', 'Human', 'Image', 'Image Analysis', 'Injury', 'Intelligence', 'Knee', 'Knee joint', 'Label', 'Lead', 'Learning', 'Licensing', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Patient Triage', 'Patients', 'Performance', 'Probability', 'Process', 'Protocols documentation', 'Protons', 'Radiology Specialty', 'Reader', 'Reading', 'Reproducibility', 'Research', 'Resolution', 'Resource Sharing', 'Sampling', 'Scanning', 'Severities', 'Signal Transduction', 'Staging', 'Standardization', 'Statistical Distributions', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translating', 'Translations', 'Uncertainty', 'Vendor', 'base', 'clinical application', 'clinical practice', 'clinical translation', 'clinically relevant', 'cohort', 'computerized data processing', 'convolutional neural network', 'data space', 'data to knowledge', 'deep learning', 'density', 'design', 'domain mapping', 'experimental study', 'feature extraction', 'heterogenous data', 'image processing', 'image reconstruction', 'imaging system', 'joint destruction', 'learning ability', 'musculoskeletal imaging', 'neural network', 'new technology', 'novel', 'open source', 'preservation', 'prospective', 'radiologist', 'reconstruction', 'recruit', 'research study', 'sensor', 'supervised learning', 'tool', 'validation studies']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,574344
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,10162650,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'algorithm training', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual clinical trial', 'virtual patient']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2021,384396
"Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images ABSTRACT The goal of this R03 Small Grant Program for NIDDK is to provide additional funding for Dr. Kline to expand upon his work on his K award and apply his expertise to new image acquisitions and problems related to renal imaging. Dr. Kline’s work has piqued the interest of many internal and external investigators and has led to recent collaborations with Drs. Rule, Denic, and Kim. Together with Dr. Erickson, this new research team has prepared this R03 proposal which takes advantage of the unique expertise of each team member. The focus of this proposal is to bridge the gap between microscopic observations and those assessable non-invasively by radiological imaging. To do this, we have established a unique dataset of renal CT imaging data and corresponding biopsy measured nephron densities. We have also generated a large database of gold-standard segmentation data of kidneys, cortical regions, and medullary pyramids. Using this existing data, we propose to: (i) develop tools for segmentation of kidneys, segmentation of individual medullary pyramids, and imputing missing parts of the kidneys outside of the imaged field-of-view in the CT image, and (ii) to establish imaging biomarkers of early CKD, and correlate macroscopic imaging findings to underlying microscopic structure. This research will be facilitated by Mayo Clinic’s outstanding clinical and research environment dedicated to improving patient care, as well as the Aging Kidney Anatomy Study (PI: Rule), which led to the generation of this unique and well characterized dataset. Dr. Kline’s background in imaging technologies and image processing makes him particularly well suited to perform this research. In addition to the above aims, near the end of this research project Dr. Kline will submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of renal imaging biomarkers. Obtaining this R03 Award will greatly facilitate Dr. Kline’s transition into a prosperous independent researcher focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. Narrative Non-invasive methods for characterizing micro-structural changes of the kidney during aging as well as in health and disease are currently not possible. This research program proposes to use our existing database of renal imaging and renal biopsy data to bridge the gap between macroscopic radiological findings on computed tomography images to those assessable in microscopic images of renal biopsies. This program will develop new automated methods for performing measurements on the images, as well as use machine/deep learning methods to search for new imaging biomarkers that relate to nephron density and size, as well as establish their usefulness for early chronic kidney disease detection and transplant planning.",Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images,10224190,R03DK125632,"['Abdomen', 'Affect', 'Aging', 'Albuminuria', 'Anatomy', 'Area', 'Arteries', 'Artificial Intelligence', 'Autosomal Dominant Polycystic Kidney', 'Award', 'Biopsy', 'Chronic Kidney Failure', 'Clinic', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrosis', 'Funding', 'Generations', 'Goals', 'Gold', 'Grant', 'Health', 'Hepatic Cyst', 'Hour', 'Hypertension', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'K-Series Research Career Programs', 'Kidney', 'Kidney Diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Microscopic', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrons', 'Organ', 'Outcome', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Polycystic Kidney Diseases', 'Radiologic Finding', 'Renal Blood Flow', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Scanning', 'Semantics', 'Services', 'Stenosis', 'Structure', 'Surveys', 'Techniques', 'Technology', 'Time', 'Transplantation', 'Tubular formation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'automated analysis', 'automated image analysis', 'automated segmentation', 'base', 'clinical decision-making', 'clinical practice', 'deep learning', 'density', 'early detection biomarkers', 'graft failure', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'interstitial', 'kidney biopsy', 'learning strategy', 'living kidney donor', 'member', 'microscopic imaging', 'non-invasive imaging', 'novel', 'novel imaging technology', 'personalized decision', 'precision medicine', 'prognostic value', 'programs', 'radiological imaging', 'research clinical testing', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,R03,2021,119250
"Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging PROJECT SUMMARY/ABSTRACT There has been significant work in creating tools that leverage computer vision algorithms to automate medical image analysis. Most of these algorithms have been developed for natural images, which are usually single static images that can be treated individually. However, medical images are usually part of a study that may include various views and orientations that are considered together with other clinical data when making a diagnosis. Three dimensional convolution neural networks (CNN) can address this issue in part when images are evenly spaced, but many medical imaging modalities such as ultrasound (US), fluoroscopy, and biopsy imaging have variable orientations and irregular spacing. Graph convolutional networks (GCN) have the potential to address this issue as they generalize the assumptions of CNNs to work on arbitrarily structured graphs. Automatic thyroid nodule detection in ultrasound (US) is one application that such a graph-based approach could have a large impact. The thyroid cancer incidence rate has tripled in the past thirty years, with an estimated cost of $18-21 billon in 2019. US is the imaging modality of choice, which consists of multiple 2D images of different locations and orientations. US readings are often vague and subjective in nature, which has resulted in a steady increase in the number of biopsies performed over the past 20 years. It is estimated that about one-third of all thyroid biopsy procedures performed in the United States are medically unnecessary, leading to the unmet need for noninvasive diagnostic tests that can reliably identify which nodules require a biopsy. The research objective of this R21 is to develop a new graph-based approach to leverage spatial information contained within imaging studies that will be combined with biomarkers and other known risk factors. Our graph model will enable more complete detection of thyroid cancer, as well as the prediction of future cancer aggression, both with spatially localized explanations. GCN features will be used to predict voxel-level cancer suspicion, thereby enabling a novel method for performing “imaging biopsy.” Finally, voxel-level suspicion maps will be aggregated into patient-level quantitative imaging biomarkers and combined with clinical data to create a multimodal nomogram for performing risk stratification. PROJECT NARRATIVE Medical image analysis plays an important role in computer aided detection and diagnosis, but usually focuses on individual images in isolation. Graph convolutional networks have the ability to utilize the relationships be- tween images in a study to aggregate information and make a more accurate evaluation. The focus of this project is to implement a graph-based approach for distinguishing indolent from aggressive thyroid cancer, thus pre- venting patients from receiving unnecessary treatment and incurring associated negative functional outcomes.",Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging,10110934,R21EB030691,"['3-Dimensional', 'Address', 'Age', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Attention', 'Biological Markers', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Diagnostic tests', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fluoroscopy', 'Functional disorder', 'Future', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'Indolent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Manuals', 'Maps', 'Medical', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Nodule', 'Nomograms', 'Pathology', 'Patient risk', 'Patients', 'Pattern', 'Physiological', 'Play', 'Probability', 'Procedures', 'Protocols documentation', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Role', 'Savings', 'Series', 'Signal Transduction', 'Structure', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Tweens', 'Ultrasonography', 'United States', 'Work', 'base', 'body system', 'cancer imaging', 'cancer risk', 'clinical imaging', 'clinically significant', 'computer aided detection', 'convolutional neural network', 'cost estimate', 'deep learning', 'detection platform', 'functional outcomes', 'image registration', 'imaging biomarker', 'imaging modality', 'imaging study', 'innovation', 'mortality', 'multimodality', 'network models', 'noninvasive diagnosis', 'novel', 'patient stratification', 'predictive modeling', 'prevent', 'quantitative imaging', 'radiologist', 'risk stratification', 'tool', 'treatment planning', 'unnecessary treatment', 'ward']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,224566
"Quantification of Liver Fibrosis with MRI and Deep Learning Project Summary/Abstract  Chronic liver disease (CLD) is a common cause of morbidity and mortality in the U.S. and throughout the world. In 2017, CLD had an age-adjusted death rate of 10.9/100,000 total population and an estimated lifetime cost of fatty liver disease alone in the U.S. of ~$222 billion. Liver fibrosis (LF) is the most important and only histologic feature known to predict outcomes from CLD. The current standard for assessing LF is biopsy, which is costly, prone to sampling error, and invasive with poor patient acceptance. Thus, there is an urgent unmet need for noninvasive, highly accurate and precise diagnostic technologies for detection and quantification of LF. Our overarching objective is to apply Deep Learning (DL) methods using conventional non-elastographic magnetic resonance (MR) images, MR elastography (MRE), and clinical data to accurately detect and measure LF in children and adults with CLD, using biopsy-derived histologic data as the reference standard. In this project, we will dedicate our efforts to accomplishing the following specific aims. In Aim 1, we will develop and validate a DL framework to accurately segment liver and spleen in order to extract radiomic (gray-scale signal intensity distribution, shape and morphology, volumetry, and inter-voxel signal intensity pattern and texture) and deep features (complex abstractions of patterns non-linearly constructed throughout the transformation estimated by data-driven DL training procedures) from conventional multiparametric MRI. These features allow detection of liver and spleen structural abnormalities/tissue aberrations. In Aim 2, we will develop and validate an “ensemble” DL model (LFNet) to predict biopsy-derived LF stage and LF percentage using the integration of conventional multimodal MRI radiomic and deep features, MRE data, as well as clinical data. In Aim 3, we will develop and validate a DL model (LSNet) to quantify MRE-derived liver stiffness (LS) using conventional multiparametric MRI radiomic and deep features as well as clinical data. The proposed models will help physicians to more accurately detect and follow CLD by 1) quantifying LS from conventional MR imaging without the need for MRE; and, more importantly, 2) predicting histologic LF stage and LF percentage without the need for biopsy, while avoiding inter- radiologist variability, reducing radiologist workload, and ultimately reducing healthcare costs. We will validate the models using both internal and independent external data from various scanners and sites. The techniques we develop are expected to improve medical diagnosis and prognostication in the same way as DL has revolutionized other fields. This study will significantly impact public health because it will allow physicians and researchers to more accurately diagnose and quantify CLD and LF as well as permit more frequent assessments in a noninvasive, patient-centric manner, thus potentially improving patient outcomes while lowering healthcare costs. The techniques we develop also can be readily extended for the prediction of other important liver-related clinical outcomes, including impending complications such as portal hypertension, time to liver transplant/transplant listing, and mortality risk, among others. Project Narrative  Chronic liver disease (CLD) is a common cause of illness and death worldwide, and it is a significant healthcare and financial burden. Liver fibrosis (LF) is a measurable feature of CLD that is important to assess the severity of disease, evaluate for progression and therapy response, and predict outcomes. We propose to apply artificial intelligence methods to noninvasive conventional magnetic resonance images and readily- available clinical data for accurate detection and quantification of LF, thus significantly impacting public health by facilitating personalized therapies without the need for liver biopsy, improved outcomes, and lower healthcare costs.",Quantification of Liver Fibrosis with MRI and Deep Learning,10096229,R01EB030582,"['Address', 'Adult', 'Age', 'American', 'Appearance', 'Artificial Intelligence', 'Bilirubin', 'Biopsy', 'Body mass index', 'Cessation of life', 'Characteristics', 'Child', 'Childhood', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Complex', 'Computer-Assisted Diagnosis', 'Crowding', 'Data', 'Data Set', 'Databases', 'Death Rate', 'Decision Making', 'Descriptor', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Evaluation', 'Eye', 'Fatty Liver', 'Financial Hardship', 'Goals', 'Health Care Costs', 'Health Expenditures', 'Healthcare', 'Histologic', 'Human', 'Image', 'Individual', 'Institution', 'Laboratories', 'Length of Stay', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Magnetic Resonance Elastography', 'Magnetic Resonance Imaging', 'Maps', 'Mathematics', 'Measurable', 'Measures', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Population', 'Portal Hypertension', 'Procedures', 'Property', 'Public Health', 'Reference Standards', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Risk Factors', 'Running', 'Sampling Errors', 'Series', 'Severity of illness', 'Shapes', 'Signal Transduction', 'Site', 'Spleen', 'Staging', 'Structural defect', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissues', 'Training', 'Transplantation', 'Vendor', 'Viral hepatitis', 'Visual', 'Workload', 'accurate diagnosis', 'accurate diagnostics', 'chronic liver disease', 'classification algorithm', 'clinical risk', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'diagnostic technologies', 'elastography', 'hospital readmission', 'hospitalization rates', 'improved', 'improved outcome', 'learning strategy', 'life time cost', 'liver biopsy', 'liver transplantation', 'mortality', 'mortality risk', 'multimodality', 'multitask', 'non-linear transformation', 'outcome prediction', 'personalized diagnostics', 'personalized medicine', 'predictive modeling', 'prognostic', 'radiologist', 'radiomics', 'response', 'sex']",NIBIB,CINCINNATI CHILDRENS HOSP MED CTR,R01,2021,628266
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,10150027,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2021,695400
"Motion-Resolved, Comprehensive Quantitative Tissue Characterization Using MR Multitasking PROJECT SUMMARY  Quantitative magnetic resonance imaging (MRI) measures tissue parameters such as T1, T2, T2*, and diffusion to detect subtle differences in tissue states (such as microstructure, diffuse fibrosis, edema, hemorrhage, and iron content) from neurological, oncological, and cardiovascular diseases. Because each parameter offers complementary tissue information, multiparameter mapping is very promising for risk assessment, early detection, accurate staging, and treatment monitoring of disease. However, quantitative MRI is typically very time consuming and difficult to perform. Each parameter is typically measured from its own series of images, so measuring multiple parameters leads to long, inefficient scanning sessions. Furthermore, cardiac and breathing motion creates misalignment between images, causing additional problems.  The standard approach to motion is to either remove it (e.g., ask the patient to hold their breath) or to synchronize image acquisition with it (e.g., using electrocardiography (ECG) to monitor cardiac motion). This approach makes scan times even longer, limits imaging to patients who can repeatedly perform long breath holds (which is difficult for aging or weak patients) and who have predictable cardiac motion (which is not true of patients with cardiac arrhythmias). Furthermore, these methods are often unreliable and difficult to perform.  This project is to develop and validate a new technology, MR Multitasking, to perform multiple simultaneous measurements in a single, push-button scan that is both comfortable for patients and simple for technologists to perform. MR Multitasking redesigns quantitative MRI around the concept of images as functions of many time dimensions, each corresponding to a different dynamic process (e.g., motion, T1, T2, T2*, and diffusion), and then uses mathematical models called low-rank tensors to perform fast, multidimensional imaging. This allows continuous acquisition of imaging data even while the subject is moving, providing motion-resolved parameter maps without breath holding or motion synchronization. We will scan healthy subjects, liver patients, prostate cancer patients, and cardiovascular patients to develop and validate this technology and use artificial intelligence to quickly reconstruct images from the collected data. The resulting tool will be applicable to any organ system, offering clinicians and investigators a valuable tool to answer a wide range of biomedical questions. PROJECT NARRATIVE  This project is to develop and validate a one-stop, push-button solution for comprehensive, motion- resolved quantitative magnetic resonance imaging (MRI). This will be accomplished by cultivating a new technology, MR Multitasking, which can measure multiple tissue biomarkers in a single scan, even in moving organs. The resulting technology will be applicable to any organ system, offering clinicians and investigators a valuable tool to diagnose, monitor, and study a wide range of diseases.","Motion-Resolved, Comprehensive Quantitative Tissue Characterization Using MR Multitasking",10084899,R01EB028146,"['Address', 'Aging', 'Algorithms', 'Arrhythmia', 'Artificial Intelligence', 'Blood flow', 'Breathing', 'Cancer Patient', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Collection', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diffuse', 'Diffusion', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Electrocardiogram', 'Fibrosis', 'Hemorrhage', 'Image', 'Iron', 'Joints', 'Lead', 'Lipids', 'Liver', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetism', 'Malignant neoplasm of prostate', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Nature', 'Neurologic', 'Organ', 'Patients', 'Physiological', 'Positioning Attribute', 'Predisposition', 'Process', 'Property', 'Recovery', 'Reproducibility', 'Research', 'Research Personnel', 'Respiration', 'Risk Assessment', 'Scanning', 'Series', 'Signal Transduction', 'Source', 'Staging', 'System', 'Technology', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Validation', 'body system', 'deep learning', 'heart motion', 'image reconstruction', 'magnetic field', 'magnetohydrodynamic', 'mathematical model', 'multitask', 'new technology', 'prospective', 'quantitative imaging', 'reconstruction', 'respiratory', 'time use', 'tissue biomarkers', 'tool']",NIBIB,CEDARS-SINAI MEDICAL CENTER,R01,2021,616003
"Leveraging deep learning for markerless motion management in radiation therapy Leveraging deep learning for markerless motion management in radiation therapy Project Summary Organ motion is a predominant limiting factor for the maximum exploitation of modern radiation therapy (RT). Adverse influence of the organ motion is aggravated in hypofractionated treatment because of protracted dose delivery. Current image guided RT often relies on the use of implanted fiducial markers (FMs) for online/offline target localization, which is invasive and costly, and introduces possible bleeding, infection and discomfort of the patient. In this project, we harness the enormous potential of deep learning and investigate a novel markerless localization strategy by combined use of a pre-trained deep learning model and kV X-ray projection or cone beam CT images. We hypothesize that incorporation of deep layers of image information allows us to visualize otherwise invisible target in real-time and greatly reduce the uncertainties in beam targeting. Specific aims of the project are to: (1) Develop a DL-based tumor target localization framework for image guided RT (IGRT); (2) Apply the DL-based strategy to localize prostate target on 2D kV X-ray projection and 3D CBCT images; and (3) Evaluate the potential clinical impact of the DL strategy for pancreatic IGRT. This study brings up, for the first time, highly accurate markerless target localization based on deep learning and provides a clinically sensible solution for IGRT of prostate and pancreas cancers or other types of cancers. Successful completion of this investigation will significantly advance the current beam targeting technique and provide radiation oncology discipline a powerful way to safely and reliably escalate the radiation dose for precision RT. Given its significant promise to optimally cater for inter- and intra-fractional uncertainties, the study should lead to substantial improvement in patient care and enables us to utilize maximally the technical capability of modern RT such as IMRT and VMAT. Given the dose responsive nature of various cancers and that the proposed method requires no hardware modification, this research should lead to a widespread impact on the management of neoplasmic diseases affected by organ motion. Leveraging deep learning for markerless motion management in radiation therapy Project Narrative This project is aimed at establishing a deep learning-based image guidance strategy for motion management in prostate and pancreas radiation therapy. Successful completion of this investigation will significantly advance the current beam targeting technique and provide radiation oncology discipline a powerful way to safely and reliably escalate the radiation dose for precision radiation therapy. The research should thus lead to a widespread impact on the management of various neoplasmic diseases affected by organ motion.",Leveraging deep learning for markerless motion management in radiation therapy,10235308,R01CA256890,"['3-Dimensional', 'Affect', 'Brain', 'Clinical', 'Complication', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Disease', 'Dose', 'Duodenum', 'Felis catus', 'Head and neck structure', 'Hemorrhage', 'Image', 'Implant', 'Infection', 'Intensity-Modulated Radiotherapy', 'Investigation', 'Lead', 'Learning', 'Liver', 'Location', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Malignant neoplasm of prostate', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Monitor', 'Motion', 'Nature', 'Neoplasms', 'Normal tissue morphology', 'Organ', 'Pancreas', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Prostate', 'Radiation Dose Unit', 'Radiation Oncology', 'Radiation therapy', 'Radiosurgery', 'Research', 'Retrospective Studies', 'Roentgen Rays', 'Site', 'System', 'Techniques', 'Time', 'Training', 'Uncertainty', 'Vertebral column', 'X-Ray Computed Tomography', 'base', 'cancer type', 'cone-beam computed tomography', 'conventional therapy', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'experimental study', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'improved', 'indexing', 'learning strategy', 'novel', 'pancreas imaging', 'predictive modeling', 'real time model', 'respiratory', 'treatment planning', 'tumor']",NCI,STANFORD UNIVERSITY,R01,2021,442403
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,10137892,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated algorithm', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'risk prediction', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,482108
"A machine learning ultrasound beamformer based on realistic wave physics for high body mass index imaging PROJECT SUMMARY  Obesity is a significant and growing problem in the United States. Currently, 68.5% of the U.S. population is overweight, with approximately 37.7% of the overweight population being obese. The significant health problems associated with overweightedness and obesity, the “body habitus” of this population combined with the significant challenges in medical imaging of these individuals reduces the effectiveness of healthcare for this population. In ultrasound imaging, the quality of abdominal ultrasound exams are significantly affected by obesity.  Fundamentally, an ultrasound image relies on acoustic propagation to a target, reflection, and then propagation back to the surface. The process of beamforming, which converts the surface measurement to an image, is sensitive to the low amplitude reflections from different tissue layers and tissue properties. Typically, the additional fat and connective tissue layers in obese patients can significantly degrade ultrasound image quality by introducing multi-path reverberation and phase aberration that obscure or distort these low amplitude reflections.  However, due to the computational complexity of describing ultrasound propagation and reflection in heterogeneous media, beamformers currently rely on simplified models that do not describe the propagation physics directly. We propose a generational leap in how we approach ultrasound beamforming by using physically and anatomically realistic wave propagation models and measurements that can effectively harness the power of data-driven and rapidly evolving machine learning beamformers. A custom highly realistic simulation tool that we have developed will use acoustical maps of the fine structures in the human body based on photographic cryosections. This physics-based approach will allow us to develop high quality training data and to understand the physical mechanisms for image quality improvement. These simulations will be calibrated to ex vivo and in vivo human data to subsequently generate a large data set that can be used to train a machine- learning-based real-time beamformer. We will focus on two sources of image degradation which we have identified to be particularly deleterious: multipath reverberation and aberration of the focusing profile. The proposed neural network beamformer filters incoherent noise, such as multi-path reverberation, and corrects aberration in the radiofrequency channel signals.  After training the beamformer and implementing it in real-time, a pilot human study in liver ultrasound imaging will be conducted to determine the improvement in image quality in high-body-mass index individuals, where diagnostic imaging is problematic due to image degradation. This technique is highly translatable to other clinical scenarios, varying from cardiac to transcranial to obstetric imaging, by changing the anatomical model. Furthermore, the physical concepts that will be extracted from the learned representation, can be used to improve the design process for ultrasound equipment, including transmit sequences, and transducers. RELEVANCE TO PUBLIC HEALTH Ultrasound beamforming, the process of transforming ultrasound into an image, is based on the principles of wave propagation which are complex due to the soft tissue structure in the human anatomy. Currently, ultrasound imaging uses simplified models of wave propagation. Here we address these limitations with physically and anatomically realistic propagation models based on the human anatomy that can effectively train and harness the power of machine learning beamformers. This technique directly addresses the principal challenge and objective of ultrasound beamforming, which is to limit unwanted acoustical effects from superficial tissue while maximizing signal from deep targets. The advancement of the proposed technology addresses the clear clinical need to provide diagnostic imaging to the growing population of body-limited imaging cases.",A machine learning ultrasound beamformer based on realistic wave physics for high body mass index imaging,10130064,R01EB029419,"['3-Dimensional', 'Abdomen', 'Acoustics', 'Address', 'Affect', 'Anatomic Models', 'Anatomy', 'Back', 'Cardiac', 'Carotid Arteries', 'Characteristics', 'Clinical', 'Complex', 'Connective Tissue', 'Custom', 'Data', 'Data Set', 'Databases', 'Dependence', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of obstetrics', 'Effectiveness', 'Equipment', 'Fatty acid glycerol esters', 'Generations', 'Health', 'Healthcare', 'Human', 'Human body', 'Image', 'Individual', 'Left', 'Link', 'Liver', 'Machine Learning', 'Maps', 'Measurement', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Noise', 'Obesity', 'Overweight', 'Patients', 'Phase', 'Physics', 'Population', 'Process', 'Property', 'Public Health', 'Resolution', 'Signal Transduction', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'Transducers', 'Ultrasonic wave', 'Ultrasonography', 'United States', 'Weight', 'base', 'deep learning', 'design', 'health care quality', 'high body mass index', 'human data', 'human study', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging system', 'improved', 'in vivo', 'in vivo imaging', 'large datasets', 'learning strategy', 'liver imaging', 'neural network', 'obese patients', 'prototype', 'radio frequency', 'relating to nervous system', 'simulation', 'soft tissue', 'sound', 'tissue phantom', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,521287
"Nonlinear performance analysis and prediction for robust low dose lung CT 1 PROJECT SUMMARY / ABSTRACT  2 Nonlinear algorithms such as model-based reconstruction (MBR) and deep learning (DL) reconstruction have  3 sparked tremendous research interest in recent years. Compared to traditional linear approaches, the nonline-  4 arity of these algorithm transcends traditional signal-to-noise requirement and offer flexibility to draw information  5 from a variety of sources (e.g., statistical model, prior image, dictionary, training data). MBR has enabled numer-  6 ous advancements including low-dose CT and advanced scanning protocols. Deep learning algorithms are rap-  7 idly emerging and have demonstrated superior dose vs. image quality tradeoffs in research settings. However,  8 widespread clinical adoption of nonlinear algorithms has been impeded by the lack of a lack of systematic, quan-  9 titative methods for performance analysis. Nonlinear methods come with numerous dependencies on the imag- 10 ing techniques, the imaging target, and the prior information, and the data itself. The relationship between these 11 dependencies and image quality is often opaque. Furthermore, improper selection of algorithmic parameters can 12 lead to erroneous features (e.g., smaller lesions, texture) in the reconstruction. Therefore, methods to quantify 13 and predict performance permit efficient and quantifiable performance evaluation to provide the robust control 14 and understanding of imaging output necessary for reliable clinical application and regulatory oversight. 15 We propose to establish a robust, predictive framework for performance assessment and optimization that can 16 be generalized to any reconstruction method. We quantify performance in turns of the perturbation response and 17 covariance as a function of imaging techniques, system configurations, patient anatomy, and, importantly, the 18 perturbation itself. The perturbation response quantifies the appearance (e.g., biases, blurs, distortions), and, 19 together with the covariance, allows the computation of more complex metrics such as task-based performance 20 and radiomic measures including size, shape, and texture information. We illustrate utility of the approach in lung 21 imaging with the following specific aims: Aim 1: Develop a lesion library and generate perturbations encom- 22 passing clinically relevant features. We will extract lesions from public databases and develop methods lesion 23 emulation in for realistic CT simulation and physical data via 3D printing technology. Aim 2: Develop a gener- 24 alized prediction framework for perturbation response and covariance. Using analytical and neural network 25 modeling, we will establish a framework that predicts perturbation response and covariance across imaging 26 scenarios for classes of algorithms with increasing data-dependence including MBR with a Huber penalty, MBR 27 with dictionary regularization, and a deep learning reconstructor. Aim 3: Develop assessment and optimiza- 28 tion strategies to drive robust, low dose lung screening CT methods. We will optimize and adapt nonlinear 29 algorithms and protocols for lung cancer screening to achieve faithful representations of clinical features. This 30 work has the potential to drive much-needed quantitative assessment standards that directly relate image quality 31 to diagnostic performance and optimal strategies for robust, reliable clinical deployment of nonlinear algorithms. 32 PROJECT NARRATIVE Major research efforts have been devoted to the development of nonlinear reconstruction algorithms – from model-based reconstruction to deep learning, these algorithms have demonstrated many advantages such as improved image quality, reduced radiation dose, and additional diagnostic information that are not achievable with traditional linear reconstructions. However, only a disproportionately small number has reach the clinic due to the lack of a predictive image quality analysis framework to quantify diagnostic performance, control algorithm behavior, and ensure consistent performance for robust clinical deployment. The propose effort use a combination of analytic and machine learning approaches to drive much-needed quantitative assessment standards that directly relate image quality to diagnostic performance and establish optimal strategies for robust, reliable clinical deployment of nonlinear algorithms.",Nonlinear performance analysis and prediction for robust low dose lung CT,10121056,R01CA249538,"['3D Print', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Appearance', 'Beauty', 'Behavior', 'Biological Models', 'Clinic', 'Clinical', 'Complex', 'Data', 'Databases', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Dictionary', 'Digital Libraries', 'Dimensions', 'Dose', 'Ensure', 'Evaluation', 'Genes', 'Image', 'Image Analysis', 'Imaging Techniques', 'Lead', 'Lesion', 'Libraries', 'Lung', 'Lung CAT Scan', 'Lung nodule', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Nodule', 'Noise', 'Non-linear Models', 'Outcome', 'Output', 'Patients', 'Performance', 'Play', 'Predictive Analytics', 'Property', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Role', 'Sampling', 'Scanning', 'Scheme', 'Shapes', 'Signal Transduction', 'Source', 'Statistical Models', 'System', 'Techniques', 'Technology', 'Texture', 'Training', 'Transcend', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical translation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'exhaustion', 'flexibility', 'imaging system', 'improved', 'insight', 'interest', 'low dose computed tomography', 'lung cancer screening', 'machine learning method', 'neural network', 'novel', 'predicting response', 'quantitative imaging', 'radiomics', 'reconstruction', 'response', 'screening', 'shape analysis', 'simulation', 'success', 'targeted imaging']",NCI,JOHNS HOPKINS UNIVERSITY,R01,2021,512567
"Improving Virtual Gross Anatomy: Enhancing the Information Content of Cadaveric CT Scans Project Summary The long-term goal of this research is to establish a pipeline for automated image processing that enhances cadaveric non-contrast enhanced (NCE) CT data and extracts meaningful models and metrics to improve anatomy research and education. The objective is to develop the necessary toolset for this image processing, and feature extraction. The central hypothesis is that it is possible to enrich the information content of biomedical imaging data, particularly that of cadaveric NCE CT imaging, for use in gross anatomy education and research. The rationale behind this project is that cadaveric dissection, while an important part of anatomy education, is limited due to sample size, infrastructure, cost, and time. Biomedical imaging can preserve specimens for posterity and be used to supplement this material by providing statistical and quantitative information from anatomical structures. This research will attempt to establish a working pipeline for efficient information extraction through the following specific aims: (1) Improving inter-observer anatomical agreement in cadaveric CT scans; (2) Develop an approach to automatically segment anatomical structures from non-contrast enhanced CT images; and (3) Establish normal variation of anatomical structures and its relationship to pathologies. This project is innovative because it applies artificial intelligence to efficiently extract anatomical information from cadaveric NCE CT imaging, which has only been performed with traditional registration- dependent methods that often fail and are domain specific, acting on a single organ at a time. In addition, this project works with multi-species data to enhance human image data.  This project is significant because it will allow students to understand anatomical variation better by both expanding student exposure to more samples, while also extracting useful representations and analytics from these samples for education and research. The expected outcome of this project is a toolset that is capable of enhancing anatomy education and research by increasing soft-tissue contrast, automatically segmenting the kidneys, liver, mandible, and intraosseus sites of the cranial nerves, and performing statistical analysis on these organs, including but not limited to statistical shape modelling and shape analysis. This will have a positive impact on anatomical education and student retention because it will provide students with a broader range of sample variability information which will decrease pervading biases in medical training that result from small, limited sample sizes, and improve medical training. Project Narrative Dissection is a critical component of anatomy education but is limited due to the infrastructure required by the institution, the amount of variability in the available specimens, and the limited number of specimens available within the course. Biomedical imaging and analysis can be used to supplement dissection, allowing for an expansion in the number of anatomical specimens that students can observe and the amount of clinically relevant material that is available to students to improve their understanding of pathology and variation. This will expand student exposure to anatomical variation, produce more proficient medical professionals, and improve anatomy research.",Improving Virtual Gross Anatomy: Enhancing the Information Content of Cadaveric CT Scans,10141430,F31EB030904,"['3-Dimensional', 'Address', 'Agreement', 'Anatomic Models', 'Anatomy', 'Artificial Intelligence', 'Blood coagulation', 'Buffaloes', 'Cadaver', 'Characteristics', 'Clinical', 'Computer Models', 'Contrast Media', 'Coupled', 'Cranial Nerves', 'Data', 'Development', 'Diagnostic', 'Disease', 'Dissection', 'Education', 'Exposure to', 'Gifts', 'Goals', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Individual', 'Information Retrieval', 'Infrastructure', 'Institution', 'Kidney', 'Lead', 'Libraries', 'Liver', 'Machine Learning', 'Mandible', 'Manuals', 'Medical', 'Medical Students', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Nature', 'Noise', 'Organ', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Population', 'Preservation Technique', 'Process', 'Reading', 'Research', 'Research Personnel', 'Sample Size', 'Sampling', 'Scanning', 'Shapes', 'Signal Transduction', 'Site', 'Specimen', 'Statistical Data Interpretation', 'Structure', 'Students', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Variant', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'bioimaging', 'clinically relevant', 'cohort', 'contrast enhanced', 'cost', 'deep learning', 'demographics', 'education research', 'feature extraction', 'human imaging', 'image processing', 'image registration', 'improved', 'innovation', 'interest', 'non-invasive imaging', 'posters', 'preservation', 'programs', 'quantitative imaging', 'retention rate', 'segmentation algorithm', 'shape analysis', 'soft tissue', 'success', 'virtual']",NIBIB,STATE UNIVERSITY OF NEW YORK AT BUFFALO,F31,2021,30805
"Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions Project Summary Fluoroscopy guidance using C-arm X-ray systems is used in more than 17 million procedures across the US and constitutes the state-of-care for various percutaneous procedures, including internal ﬁxation of pelvic ring injuries. To infer procedural progress from 2D radiographs, well-deﬁned views onto anatomy must be achieved and restored multiple times during surgery. This process, known as ”ﬂuoro hunting”, is associated with 4.7 s of excessive ﬂuoroscopy time per C-arm position (c. f. 120 s total per ﬁxation), yielding radiographs that are never interpreted clinically, but drastically increasing procedure time and radiation dose to patient and surgical staff.  Our long-term project goal is to use concepts from machine learning and active vision to develop task-aware algorithms for autonomous robotic C-arm servoing that interpret intra-operative radiographs and autonomously adjust the C-arm pose to acquire ﬂuoroscopic images that are optimal for inference. We have three speciﬁc aims: 1) Detecting unfavorable K-wire trajectories from monoplane ﬂuoroscopy images: We will extend a physics-based sim- ulation framework for ﬂuoroscopy from CT that enables fast generation of structured and realistic radiographs documenting procedural progress. Based on this data, we will train a state-of-the-art convolutional neural net- work that interprets ﬂuoroscopic images to infer procedural progress. 2) Developing and validating a task-aware imaging system in silico: Using the autonomous interpretation tools and simulation pipeline available through Aim 1, we will train an artiﬁcial agent based on reinforcement learning and active vision. This agent will be capable of analyzing intra-operative ﬂuoroscopic images to autonomously adjust the C-arm pose to yield task- optimal views onto anatomy. 3) Demonstrating feasibility of our task-aware imaging concept ex vivo: Our third aim will establish task-aware C-arm imaging in controlled clinical environments. We will attempt internal ﬁxation of anterior pelvic ring fractures and our task-aware artiﬁcial agent will interpret intra-operatively acquired ra- diographs to infer procedural progress and suggest optimal C-arm poses that will be realized manually with an optically-tracked mobile C-arm system.  This work combines the expertise of a computer scientist, a surgical robotics expert, and an orthopedic trauma surgeon to explore the untapped, understudied area of autonomous imaging enabled by advances in machine learning in ﬂuoroscopy-guided procedures. This development has only recently been made feasible by innovations in fast ﬂuoroscopy simulation from CT to provide structured data for training that is sufﬁciently realistic to warrant generalization to clinical data. With support from the NIH Trailblazer Award, our team will be the ﬁrst to investigate autonomous and task-aware C-arm imaging systems, paving the way for a new paradigm in medical image acquisition, which will directly beneﬁt millions of patients by task-oriented image acquisition on a patient-speciﬁc basis. Subsequent R01 funding will customize this concept to other high-volume procedures, such as vertebroplasty. Project Narrative Fluoroscopy guidance using C-arm X-ray systems is the state-of-care for percutaneous fracture ﬁxation, and requires surgeons to achieve and reproduce well deﬁned views onto anatomy to infer procedural progress. This requirement alone is estimated to contribute 4.7 s of ﬂuoroscopy time per C-arm repositioning (c. f. 120 s total per ﬁxation), drastically increasing procedure time and radiation dose to patient and surgical team. The goal of this project is to develop machine learning-based C-arm servoing algorithms that introduce task awareness by interpreting intra-operative radiographs and autonomously adjusting the C-arm pose to task-optimal views.",Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions,10143238,R21EB028505,"['3-Dimensional', 'Age-Years', 'Algorithms', 'Anatomy', 'Anterior', 'Area', 'Artificial Intelligence', 'Assessment tool', 'Automobile Driving', 'Award', 'Awareness', 'Back', 'Bladder', 'Cadaver', 'Caring', 'Clinical', 'Clinical Data', 'Compression Fracture', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Environment', 'Exhibits', 'Expert Systems', 'Fluoroscopy', 'Fracture', 'Fracture Fixation', 'Funding', 'Generations', 'Goals', 'Image', 'Incidence', 'Injury', 'Intervention', 'Label', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Modality', 'Modernization', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Patients', 'Pelvis', 'Physics', 'Population', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Psychological reinforcement', 'Radiation Dose Unit', 'Risk', 'Robotics', 'Roentgen Rays', 'Scientist', 'Specimen', 'Structure', 'Surgeon', 'System', 'Testing', 'Time', 'Training', 'Trauma', 'United States', 'United States National Institutes of Health', 'Variant', 'Vertebral column', 'Width', 'Work', 'active vision', 'adverse outcome', 'algorithm training', 'arm', 'base', 'bone', 'convolutional neural network', 'deep learning algorithm', 'deep reinforcement learning', 'femoral artery', 'imaging modality', 'imaging system', 'improved outcome', 'in silico', 'innovation', 'learning algorithm', 'mortality', 'multitask', 'novel strategies', 'pre-clinical', 'sample fixation', 'simulation', 'spine bone structure', 'structured data', 'success', 'tool', 'trauma surgery']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,197201
"Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT PROJECT SUMMARY Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT Coronary artery disease remains a major public health problem worldwide. It causes approximately 1 of every 6 deaths in the United States. Imaging of myocardial perfusion (delivery of blood to the heart muscle) by myocardial perfusion single photon emission tomography (MPS) allows physicians to detect disease before heart attacks occur and is currently used to predict risk in millions of patients annually. Under the current grant, we have established a unique collaborative multicenter registry including over 23,000 imaging datasets (REFINE SPECT) with both prognostic (major adverse cardiovascular events) and diagnostic (invasive catheterization) outcomes. Using this registry, we have demonstrated that a combination of MPS image analysis and artificial intelligence (AI) tools achieved superior predictive performance compared to visual assessment by experienced readers or current state-of-the-art quantitative techniques. In the renewal, we plan to expand REFINE SPECT with now-available enhanced datasets (adding CT and myocardial blood flow information) and leverage latest AI advances to provide a personalized decision support tool for patient-specific cardiovascular risk assessment and estimation of benefit from revascularization following MPS. The overall aim is to optimize the clinical capabilities of MPS in risk prediction and treatment guidance by integrating all available imaging and clinical data with state-of-the-art AI methods. For this work, we propose the following 3 specific aims: (1) To expand and enhance our REFINE SPECT registry including CT and MPS flow data, (2) To develop fully automated techniques for all MPS and CT image analysis, (3) To apply explainable deep learning time-to-event AI models for optimal prediction of MACE and benefit from revascularization from all image and clinical data. This work will result in an immediately deployable clinical tool, which will optimally predict risk of adverse events and establish the relative benefits from specific therapies, beyond what is possible by subjective visual analysis and mental integration of all imaging (MPS, CT, flow), and clinical data by physicians. Such quantitative integrative methods are not yet available, leaving the current practice for assessing risk and recommending therapy highly subjective. The precise quantitative results will be presented to clinicians in easy to understand terms (e.g., % risk per year, or relative risk of one therapy vs. the alternative) for a specific patient. Additionally, our methods to make AI conclusions more tangible will improve adoption of this technology. All results will be derived fully automatically thus eliminating any variability. Our approach will fit into current MPS practice and will be immediately translatable to clinics worldwide. Most importantly, this research will allow patients to benefit from increased precision and accuracy in risk assessment, thereby optimizing the use of imaging in guiding patient management decisions and ultimately improving outcomes. PROJECT NARRATIVE Myocardial perfusion imaging with SPECT is often used to predict who is at risk of heart attack and should undergo treatment such as coronary bypass or stenting; however, physicians read images visually and report results with wide variability. With the latest artificial intelligence tools and new types of imaging (including CT and fast SPECT scans), the investigators propose to develop and validate an automated clinical tool to optimize risk prediction and objectively establish the relative benefit of a specific therapy. This new tool will consider all available patient images and other relevant information to provide a personalized explanation and precise calculation of risk and potential benefits from therapy for each patient.",Quantitative Prediction of Disease and Outcomes from Next Generation SPECT and CT,10110023,R01HL089765,"['Adoption', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blood', 'Blood flow', 'Calcium', 'Cardiovascular system', 'Catheterization', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Data', 'Coronary Arteriosclerosis', 'Coronary Artery Bypass', 'Country', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Deposition', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Event', 'Grant', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Injections', 'International', 'Joints', 'Maps', 'Measures', 'Methods', 'Modeling', 'Myocardial', 'Myocardial Infarction', 'Myocardial perfusion', 'Myocardium', 'Outcome', 'Patient imaging', 'Patients', 'Perception', 'Performance', 'Perfusion', 'Photons', 'Physicians', 'Positron-Emission Tomography', 'Psyche structure', 'Public Health', 'Reader', 'Recommendation', 'Registries', 'Relative Risks', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Risk Factors', 'Scanning', 'Site', 'Statistical Models', 'Stents', 'Stress', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Visual', 'Work', 'X-Ray Computed Tomography', 'adverse event risk', 'attenuation', 'cardiovascular risk factor', 'clinically relevant', 'deep learning', 'experience', 'improved', 'improved outcome', 'multidisciplinary', 'next generation', 'non-invasive imaging', 'novel', 'perfusion imaging', 'personalized decision', 'prognostic', 'radiotracer', 'relating to nervous system', 'risk prediction', 'single photon emission computed tomography', 'support tools', 'time use', 'tomography', 'tool']",NHLBI,CEDARS-SINAI MEDICAL CENTER,R01,2021,777637
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,10150910,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction', 'risk prediction model', 'risk stratification', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2021,984177
"Fast Multi-dimensional Diffusion MRI with Sparse Sampling and Model-based Deep Learning Reconstruction Project Summary: Neurodegenerative disorders are a significant public health and economic problem and are the leading cause of disability worldwide. Understanding the specific degenerative processes that are actively progressing over the course of the illness is crucial for developing targeted drugs therapies and deciding treatment options. Additionally, understanding the structural connectivity changes to tease apart the specific circuitry affected is crucial in developing circuit specific non-invasive brain stimulation therapies. Diffusion- based MRI assays can provide microstructural measures that are highly sensitive to (i) the neurodegenerative processes and (ii) connectivity changes. Advanced modeling approaches can be utilized to further enhance the specificity of the microstructural measures to the underlying neurodegenerative processes. However, their utility is often limited to pure white matter regions. At the typical spatial resolution of diffusion MRI (~2mm isotropic voxel size), significant partial volume effects exist in most brain voxels (e.g., voxels with multiple tissue types, heterogenous fibers with different properties). In whole brain studies, this compromises the specificity of the disease processes identified by the advanced modeling approaches; it also contributes to inaccurate connectivity mapping. Additionally, the diffusion parameter encoding space is currently limited to one or two shells of low b-values (b<2000s/mm2), which limits the unique determination of several relevant microstructural parameters. The main objective of the proposal is the development, validation and clinical translation of a diffusion MRI assay that enable efficient encoding of diffusion parameter space at sub- millimeter voxel resolution for joint microstructure and connectivity mapping in the whole brain. Our overall hypothesis is that the proposed framework can significantly improve the validity of microstructural modeling in most brain voxels. The proposed development will make use of SNR-efficient 3D multi-slab acquisitions. Coupled with time-efficient sparse k-q sampling, the encoding will span over multiple b-shells. To allow the unique determination of several relevant microstructural parameters, multicompartmental T2 information will be utilized. The proposed developments will be enabled by two advanced reconstruction methods: structured low- rank matrix completion, a novel integrative framework for MRI reconstructions that enables several capabilities including multi-echo imaging and self-calibrating reconstruction; and model-based deep learning, a novel deep architecture to solve MR reconstruction algorithms using neural networks in a systematic fashion. These methods overcome several inefficiencies associated with extending the 3D multi-slab acquisition for multi- dimensional imaging in the k-q-TE space. To ensure scientific rigor, we will comprehensively validate our technology on dedicated diffusion phantoms along with healthy volunteers using different quantification metrics. We also validate the capability of the dMRI assay using a multi-modal MRI study in a cross-sectional study on a cohort of Huntington's disease. PROJECT NARRATIVE Neurodegenerative disorders are a significant public health and economic problem affecting about 450 million people worldwide are the leading cause of disability and ill-health according to world health organization. The main objective of the proposal is the development, validation and translation of a non-invasive diffusion MRI assay, that enable efficient encoding of diffusion parameter space to characterize the neurodegenerative processes that drive the progression of neurodegeneration. We validate the framework in a cohort of Huntington's disease, with the prospect of extending these studies to understand the neurodegenerative cascade in the entire class of neurodegenerative diseases, including Parkinson's and Alzheimer's.",Fast Multi-dimensional Diffusion MRI with Sparse Sampling and Model-based Deep Learning Reconstruction,10183606,R01EB031169,"['3-Dimensional', 'Acceleration', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Architecture', 'Biological Assay', 'Biological Markers', 'Brain', 'Cause of Death', 'Clinical Research', 'Complement', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Demyelinations', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disadvantaged', 'Disease', 'Effectiveness of Interventions', 'Ensure', 'Fiber', 'Financial compensation', 'Health', 'Human', 'Huntington Disease', 'Image', 'Intervention', 'Iron', 'Joints', 'Lead', 'Learning Module', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Myelin', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurons', 'Outcome', 'Parkinson Disease', 'Pattern', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Physics', 'Play', 'Process', 'Property', 'Protocols documentation', 'Public Health', 'Recovery', 'Resolution', 'Sampling', 'Signal Transduction', 'Specificity', 'Structure', 'Study models', 'Symptoms', 'Techniques', 'Technology', 'Time', 'Tissue Model', 'Tissues', 'Translations', 'Validation', 'Water', 'Work', 'World Health Organization', 'advanced disease', 'axonal degeneration', 'base', 'biophysical model', 'brain circuitry', 'clinical translation', 'cohort', 'deep learning', 'design', 'disability', 'effectiveness evaluation', 'health economics', 'healthy volunteer', 'high resolution imaging', 'image reconstruction', 'improved', 'in vivo', 'multimodality', 'neural network', 'neuroinflammation', 'neuron loss', 'noninvasive brain stimulation', 'novel', 'physical property', 'reconstruction', 'targeted treatment', 'white matter']",NIBIB,UNIVERSITY OF IOWA,R01,2021,333401
"OCT and OCTA image processing for retinal assessment of people with MS Project Summary/Abstract (Max 30 lines of text) Although magnetic resonance imaging (MRI) is necessary for diagnosing multiple sclerosis (MS), it has been challenging to acquire consistent MRI measurements of MS disease burden. Spectral domain optical coherence tomography (OCT) of the retina has emerged as a complementary source of imaging biomarkers, wherein retinal thickness measurements have been shown to correlate well with MS disease burden. As well, OCT angiography (OCTA)—a new imaging modality acquired with the same OCT scanner—yields multiple new biomarkers among which macular vessel density has been shown to correlate with MS disability. There is strong evidence that OCT and OCTA may provide much needed imaging biomarkers for MS, but there are remaining technical challenges to overcome. Many algorithms for computation of retinal layer thicknesses from OCT images have been developed, but measurement of longitudinal changes in individual MS subjects remains highly challenging, especially in MS where yearly changes are small relative to intrinsic measurement variations. We propose a novel iterative registration and deep learning segmentation algorithm for longitudinal OCT retinal image segmentation. Development of automatic algorithms for analysis of OCTA images is in an early stage and there are opportunities for significant improvements. We will develop a deep network for OCTA vessel segmentation and biomarker computation that both suppresses artifacts that are common in OCTA and provides consistent results across different scanners. As both OCT and OCTA become more widely used in the characterization and management of MS, it is becoming increasingly important to jointly characterize these biomarkers and relate them to disease status, which is currently characterized largely by clinical evaluations. We will address the central question of whether OCT and OCTA can be used to predict disease progression by developing a new disease progression score for MS based on multiple OCT and OCTA measurements as well as clinical and MRI biomarkers, acquired in both single and multiple imaging visits. The proposed research will: 1) Develop a fast, topologically-correct longitudinal segmentation method for the macula; 2) Develop a method for artifact-suppressed and consistent computation of OCTA features in the macula; 3) Develop a disease progression score to jointly characterize longitudinal retinal OCT and OCTA measurements in MS; and 4) Carry out longitudinal studies of healthy controls and people with MS using OCT and OCTA measurements. We will assess whether average features within the macula or features averaged over smaller segments yield better estimates of progression. We will also assess whether OCT alone or OCT together with OCTA provide better estimates of progression. Image processing and disease progression algorithms will be made freely available to the research community. The proposed research will greatly advance the use of OCT and OCTA in characterizing longitudinal changes in the retina, potentially leading to standard eye measurements for monitoring and managing MS and other neurological and eye diseases. Project Narrative Monitoring the progression of multiple sclerosis (MS) has been challenging due to the inconsistency and variability of both clinical and magnetic resonance imaging assessments. This project will develop methods and software for analysis of both optical coherence tomography (OCT) and OCT angiography (OCTA) scans of the retina, both of which show correlation to disability in MS. At the conclusion of the grant, software implementing the methods will be made available to the research community in a highly portable computer language.",OCT and OCTA image processing for retinal assessment of people with MS,10127738,R01EY032284,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Anatomy', 'Angiography', 'Bayesian Modeling', 'Behavior', 'Biological', 'Biological Markers', 'Central Nervous System Diseases', 'Clinic', 'Clinical', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'Data', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Endothelium', 'Equilibrium', 'Esthesia', 'Evaluation', 'Event', 'Eye', 'Eye diseases', 'Failure', 'Foundations', 'Four-dimensional', 'Future', 'Grant', 'Graph', 'Image', 'Imaging Device', 'Individual', 'Language', 'Learning', 'Literature', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multiple Sclerosis', 'Muscular Atrophy', 'Neurodegenerative Disorders', 'Optical Coherence Tomography', 'Play', 'Process', 'Relapse', 'Research', 'Retina', 'Role', 'Sampling', 'Scanning', 'Severities', 'Source', 'Spinal Cord Lesions', 'Technology', 'Testing', 'Text', 'Thick', 'Thinness', 'Time', 'Training', 'Variant', 'Vision', 'Visit', 'advanced disease', 'automated algorithm', 'base', 'burden of illness', 'cerebral atrophy', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'density', 'disability', 'efficacy evaluation', 'experience', 'ganglion cell', 'gray matter', 'image processing', 'imaging Segmentation', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'learning progression', 'macula', 'macular edema', 'magnetic resonance imaging biomarker', 'nervous system disorder', 'novel', 'novel diagnostics', 'open source', 'portability', 'random forest', 'recursive neural network', 'research clinical testing', 'retina blood vessel structure', 'retinal imaging', 'segmentation algorithm', 'three dimensional structure', 'tool', 'treatment choice', 'white matter']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,441023
"A comprehensive deep learning framework for MRI reconstruction PROJECT SUMMARY/ABSTRACT The primary goal of this investigation is to develop and validate a comprehensive, robust deep learning (DL) framework that improves MRI reconstruction beyond the limits of existing technology. The proposed framework uses “plug-and-play” algorithms to combine physics-driven MR acquisition models with state-of-the-art learned image models, which are instantiated by image denoising subroutines. To fully exploit the rich structure of MR images, we propose to use DL-based denoisers that are trained in an application-speciﬁc manner. The proposed framework, termed PnP-DL, offers advantages over other existing DL methods, as well as compressed sensing (CS). Compared to existing DL methods for MRI reconstruction, PnP-DL is more immune to inevitable variations in the forward model, such as changes in the coil sensitivities or undersampling pattern, allowing it to generalize across applications and acquisition settings. Compared to CS, PnP-DL recovers images faster, with higher quality, and with potentially superior diagnostic value. Our preliminary results highlight the potential of PnP-DL to advance MRI technology. In this work, we will fur- ther develop PnP-DL and validate it in these major applications: cardiac cine, 2D brain, and 3D brain imaging. In Aim 1, we will train and optimize convolutional neural network-based application-speciﬁc denoisers for the above-mentioned applications. The denoiser with the best denoising performance will be selected for further investigation. In Aim 2, we will develop and compare different PnP algorithms. The algorithm yielding the best combination of reconstruction accuracy and computational speed will be implemented in Gadgetron for inline processing. In Aim 3, we will compare the performance of PnP-DL to other state-of-the-art methods using retro- spectively undersampled data. This study will demonstrate that, in terms of image quality, PnP-DL is superior to CS and existing DL methods and, despite higher acceleration, is non-inferior to parallel MRI with rate-2 acceler- ation. In Aim 4, we will evaluate the performance of PnP-DL using prospectively undersampled data from adult and pediatric patients. Successful completion of this project will demonstrate that PnP-DL outperforms state- of-the-art methods in terms of image quality while exhibiting a level of robustness and broad applicability that has eluded other DL-based MRI reconstruction methods. The acceleration and image quality improvement afforded by these developments will beneﬁt almost all MRI applications, including pediatric imaging, where reducing sedation is a pressing need, and high-dimensional imaging applications (e.g., whole-heart 4D ﬂow imaging), which are too slow for routine clinical use. PROJECT NARRATIVE Magnetic Resonance Imaging (MRI) has many advantages over other imaging methods, but MRI is slow. Addi- tional developments are required to shorten the scan time, improve patient comfort, reduce the use of sedation for imaging children, and improve image quality. In this project, we will develop faster and more accurate methods for MRI. These efforts should lead to signiﬁcant improvements in the diagnosis of different diseases, so that patients may beneﬁt from appropriate treatment.",A comprehensive deep learning framework for MRI reconstruction,10211757,R01EB029957,"['3-Dimensional', '4D MRI', 'Acceleration', 'Address', 'Adoption', 'Adult', 'Algorithms', 'Anesthesia procedures', 'Architecture', 'Awareness', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Breathing', 'Cardiac', 'Child', 'Childhood', 'Clinical', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Exhibits', 'Formulation', 'Goals', 'Headache', 'Heart', 'Heart Diseases', 'Image', 'Imaging Device', 'Imaging technology', 'Immune', 'Investigation', 'Lead', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Modeling', 'Motion', 'Network-based', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physics', 'Play', 'Predisposition', 'Process', 'Pythons', 'Recovery', 'Rest', 'Sampling', 'Scanning', 'Sedation procedure', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'computer framework', 'convolutional neural network', 'cost', 'data acquisition', 'data space', 'deep learning', 'denoising', 'design', 'heart imaging', 'high dimensionality', 'image reconstruction', 'imaging modality', 'improved', 'learning strategy', 'musculoskeletal imaging', 'neural network architecture', 'novel', 'pediatric patients', 'prospective', 'real-time images', 'reconstruction', 'repository']",NIBIB,OHIO STATE UNIVERSITY,R01,2021,613825
"Reconstruction of robust, high SNR functional brain images using machine learning and oscillatory steady state MRI Project Summary/Abstract: Functional magnetic resonance imaging (fMRI) is an important tool both clinically and in scientific research, with broad applications ranging from cognitive neuroscience to presurgical planning. FMRI can generate whole brain neuronal activation maps, yet it is an inherently low signal to noise ratio (SNR) method due to the relatively small changes in activation signal relative to the baseline signal. The overarching goal of this project is to develop and validate robust, high SNR fMRI by using a novel acquisition method, oscillating steady state (OSS) fMRI, along with machine learning (ML) techniques, to reconstruct high-quality images of the OSS fMRI data. OSS fMRI can increase SNR by >2x compared to the current state-of-the-art in fMRI acquisition methods, and this boost is roughly equivalent to the SNR gain going from a 3T MRI scanner to a 7T MRI scanner. The SNR increase is a direct result of the steady state approach. However, with a more complex, oscillating acquisition, OSS fMRI can be more susceptible to common MRI artifacts than traditional methods if left uncorrected. Two of the most common sources of MRI artifacts are changes in the main magnetic field (B0) due to physiological noise (such as respiration) and patient motion. This project will develop robust, high SNR fMRI at 3T by incorporating the effects of (1) B0 changes and (2) patient motion into the OSS signal model and image reconstruction algorithms. A new image reconstruction that incorporates neural networks will correct for B0 fluctuations and remove B0 induced artifacts. We will train a neural network to generate B0 field maps using data from a conventional, physics-based two echo field mapping technique to implicitly incorporate prior information of the physics into the reconstruction, while also providing a fast, ML-based field mapping method. To correct for subject motion, we will develop a neural network that estimates rigid-body motion parameters from sequential image frames in the fMRI scan. These motion parameters will be used in an iterative image reconstruction to produce high-quality resting-state and task-based fMRI, even in the presence of subject motion. The technology developed in this proposal will result in improved functional MRI that has the potential to significantly advance both the study of the human brain and the treatment of neurological disorders. The University of Michigan is one of the top research universities in the US, and provides an ideal environment and infrastructure to complete the proposed research strategy. The Functional Magnetic Resonance Laboratory and the Electrical Engineering and Computer Science Department at UM have all the necessary hardware and computational resources needed for this project, including two state-of-the-art GE 3T MRI scanners and extensive GPU hardware for the machine learning components of the project. Furthermore, Drs. Jeffrey Fessler and Douglas Noll have proven expertise in fMRI image acquisition and reconstruction, as well as extensive mentorship experience, that will help guide this project and my training. Project Narrative Functional magnetic resonance imaging (fMRI) is used to measure brain function, and it has revolutionized our understanding of cognitive processes during the last 25 years and has also been used as a tool for presurgical mapping of language and other sensitive brain regions. More recently, fMRI is being used as a biomarker for the progression of neurologic and psychiatric diseases, for example, in Alzheimer’s disease, multiple sclerosis, and major depression. In this project we will improve fMRI techniques by developing new methods that are more robust to common sources of MRI image degradation, which will improve the sharpness of the fMRI images without increasing instrumentation costs.","Reconstruction of robust, high SNR functional brain images using machine learning and oscillatory steady state MRI",10196983,F32EB029289,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Brain imaging', 'Brain region', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Dictionary', 'Echo-Planar Imaging', 'Electrical Engineering', 'Elements', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Head', 'Head Movements', 'Human', 'Hybrids', 'Image', 'Imaging Phantoms', 'Imaging Techniques', 'Infrastructure', 'Laboratories', 'Language', 'Left', 'Length', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Maps', 'Measures', 'Mental disorders', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Morphologic artifacts', 'Motion', 'Multiple Sclerosis', 'Neurologic Process', 'Neurons', 'Noise', 'Patients', 'Physics', 'Physiological', 'Research', 'Resolution', 'Respiration', 'Rest', 'Scanning', 'Signal Transduction', 'Site', 'Source', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Universities', 'base', 'blood oxygen level dependent', 'cognitive neuroscience', 'cognitive process', 'computer science', 'computing resources', 'cost', 'experience', 'functional MRI scan', 'image reconstruction', 'imaging modality', 'improved', 'in vivo', 'instrumentation', 'magnetic field', 'nervous system disorder', 'neural network', 'novel', 'open source', 'progression marker', 'reconstruction', 'tool']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,F32,2021,66390
"Deformable motion compensation for 3D image-guided interventional radiology PROJECT SUMMARY / ABSTRACT C-arm cone-beam CT (CBCT) plays an increasing role in guidance of interventional radiology (IR) procedures in the abdo- men, with special emphasis in embolization procedures, such as transarterial chemoembolization (TACE) for treatment of hepatocellular carcinoma (HCC) or transarterial embolization (TAE) for control of internal hemorrhage. However, relatively long scan time of CBCT results in artifacts arising from organ motion (respiratory and cardiac motion and peristalsis). This poses a significant challenge to guidance in interventional radiology: for example, motion artifacts were found to render up to 25% of CBCT images un-interpretable in image-guided TACE, and 18% in CBCT-guided emergency TAE. The impact of motion is most significant in cases of single or isolated lesions treated with selective embolization that requires visual- ization of very small vascular structures. Existing motion correction methods often invoke assumption of periodicity, lim- iting their applicability outside of cardiac and respiratory motions, or rely on fiducial tracking or gated acquisition that disrupt IR workflow and/or increase radiation dose. Therefore, the application of CBCT in image-guided interventional procedures in the abdomen would significantly benefit from new methods that estimate complex deformable motion directly from image data. “Autofocus” techniques based on maximization of a regularized image sharpness criterion were shown to yield effective patient motion compensation in extremity, head and cardiac CBCT. However, current applications of such methods are limited to rigid motions. We hypothesize that deformable organ motion compensation in interven- tional soft-tissue CBCT can be achieved with advanced autofocus techniques using multiple locally rigid regions of in- terest, preconditioned with basic motion characteristics obtained through a machine learning decision framework. The following aims will be pursued: 1) Develop a joint multi-region autofocus optimization method to compensate deforma- ble organ motion. This includes incorporation into a comprehensive artifacts correction and image reconstruction pipe- line, design of multi-stage optimization schedules for convergence acceleration, and performance evaluation in deforma- ble phantoms, and cadaver and animal experiments. 2) Develop a decision framework for preconditioning of the motion compensation method through a combination of projection-based approaches for physiological signal estimations (res- piratory cycle) and a multi-input, multi-branch, deep learning architecture trained on extremely realistic simulated data that will estimate basic properties of motion (spatial distribution of amplitude, direction, and frequency) from an initial motion-contaminated image and its associated raw projection data. 3) Evaluate deformable motion compensation in animal experiments and in a clinical study in 50 cases of CBCT-guided TACE and assess image quality via expert observer evaluation of satisfaction and utility. The proposed work will yield a robust, practical method for compensation of deform- able soft-tissue motion in CBCT, removing a critical impediment to 3D guidance in IR. The deformable autofocus frame- work will be applicable to other interventions in which soft-tissue motion diminishes CBCT guidance, such as image-guided radiation therapy. PROJECT NARRATIVE Interventional Cone Beam CT (CBCT) provides critical 3D information to guide minimally-invasive procedures in the abdomen, but CBCT image quality is often compromised by organ deformation due to breathing, cardiac, and peristaltic motions. We propose a novel framework to mitigate the effects of this complex deformable motion using only the CBCT image data, without a need for gating, external trackers, or fiducial markers. This algorithm will remove a major impediment to 3D guidance in procedures such as transcatheter embolization procedures in the abdomen.",Deformable motion compensation for 3D image-guided interventional radiology,10100337,R01EB030547,"['3-Dimensional', 'Abdomen', 'Acceleration', 'Affect', 'Algorithms', 'Angiography', 'Animal Experiments', 'Animals', 'Architecture', 'Arterial Embolization', 'Arteries', 'Blood Vessels', 'Breathing', 'Cadaver', 'Cardiac', 'Characteristics', 'Chemoembolization', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Emergency Situation', 'Evaluation', 'Exhibits', 'Family suidae', 'Financial compensation', 'Fluoroscopy', 'Frequencies', 'Head', 'Hemorrhage', 'Image', 'Intervention', 'Interventional radiology', 'Joints', 'Learning', 'Lesion', 'Limb structure', 'Liver', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Motion', 'Organ', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Periodicity', 'Peristalsis', 'Physiological', 'Play', 'Primary carcinoma of the liver cells', 'Procedures', 'Property', 'Prostate Ablation', 'Radiation Dose Unit', 'Recurrence', 'Reporting', 'Residual state', 'Role', 'Scanning', 'Schedule', 'Signal Transduction', 'Spatial Distribution', 'Structure', 'Techniques', 'Testing', 'Therapeutic Embolization', 'Three-Dimensional Image', 'Time', 'Training', 'Validation', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'arm', 'base', 'clinical application', 'cone-beam computed tomography', 'convolutional neural network', 'deep learning', 'design', 'experimental study', 'feeding', 'heart motion', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'image reconstruction', 'imaging modality', 'improved', 'internal control', 'minimally invasive', 'novel', 'preconditioning', 'radiologist', 'respiratory', 'satisfaction', 'simulation', 'soft tissue', 'standard care', 'tumor']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2021,368438
"Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT) ABSTRACT: The intersection of healthcare and biomedical research is at an inflection point with the convergence of the digital revolution, advances in imaging, nanotechnology, big data science, and precision or personalized medicine. There is a wealth of meaningful, but complex information that could be extracted from imaging data but is not optimally utilized for patient care. Cancer care exemplifies the current challenges which include early detection, accurate distinction of pre- neoplastic and neoplastic lesions, prediction of tumor aggressiveness, determining infiltrative tumor margins during surgical treatment, tracking tumor evolution/ metastasis pattern, recurrence, and potential acquired resistance to treatments over time. Major strides have been made in the personalization of cancer therapies such as immunotherapy, but the availability of specific, relevant, and timely medical data and information is of critical importance to realizing the full potential of precision medicine. Nowhere is this more acutely evident than during interventions in the operating and procedure rooms. Novel methods of image guidance, data integration, information extraction, and knowledge transfer are needed to enable clinicians to fully leverage the information available, especially before, during and after invasive procedures. We are excited to re-submit a proposal for a new P41 biomedical resource center (BTRC) called Advanced Technologies for NCIGT(AT-NCIGT) with 3 TRDs, 10 new collaborative and 10 new service projects, all of which aim to investigate develop and disseminate new technologies for image guided therapy (IGT). The 3 components are Imaging Cancer Heterogeneity for IGT, Deep Learning for IGT and Intraoperative devices for IGT. These new technologies alone and in combinations will allow for greater understanding of disease state, treatment guidance, integration/navigation and in-vivo monitoring of tissue responses and improve the precision of invasive procedures. Thus the overall goal of this proposal is to investigate, develop and disseminate novel technologies for extracting new tissue characteristics (technology research and development core TRD 1: Imaging cancer heterogeneity; analyze them and make them available through state-of-the-art algorithmic and data curation approaches (Deep Learning TRD 2); and enable precise tissue sampling surgical navigation and in-vivo tissue response through the results of novel Intraoperative devices (Intraoperative devices for IGT: TRD 3). In order to effectively disseminate all this new knowledge we have 10 new collaborative and 10 new service projects and will share these novel tools through our established mechanisms, from current BTRC- National Center for Image Guided Therapy (NCIGT), which continues to be dedicated to the innovating for IGT into interventional radiology, surgery, radiation oncology, and procedure-based medicine. Project Narrative The Advanced Technologies-National Center for Image guided Therapy (AT-NCIGT) is a research and technology center with the mission of advancing patient care, by developing novel innovative tools for image guided Therapy (IGT). The three technologies encompass Imaging Cancer Heterogeneity, Deep learning and Intraoperative devices for image guided therapy which will be investigated both individually and in cross TR &D combinations. We will disseminate all technologies through a national network of collaborators, making these discoveries available to the larger medical community.",Advanced Technologies - National Center for Image Guided Therapy (AT-NCIGT),10090279,P41EB028741,"['3-Dimensional', 'Acute', 'Algorithms', 'Architecture', 'Atlas of Cancer Mortality in the United States', 'Augmented Reality', 'Biomedical Research', 'Biopsy Specimen', 'Blood', 'Brain', 'Brain Neoplasms', 'Cells', 'Characteristics', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Conventional Surgery', 'Data', 'Development', 'Devices', 'Diffusion', 'Discipline', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Evolution', 'Foundations', 'Goals', 'Health Care Research', 'Heterogeneity', 'Histopathology', 'Image', 'Imaging Device', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Information Retrieval', 'Infrastructure', 'Intervention', 'Interventional radiology', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Lung', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant neoplasm of prostate', 'Mass Spectrum Analysis', 'Medical', 'Medicine', 'Metabolic Marker', 'Metabolism', 'Metadata', 'Methods', 'Microscopic', 'Mission', 'Modeling', 'Molecular', 'Morphology', 'Nanotechnology', 'Navigation System', 'Needles', 'Neoplasm Metastasis', 'Operating Rooms', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Pattern', 'Physiologic pulse', 'Procedures', 'Prostate', 'Radiation Oncology', 'Recurrence', 'Research', 'Resistance', 'Resolution', 'Retrieval', 'Risk Assessment', 'Sampling', 'Services', 'Signal Transduction', 'Source', 'Specimen', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Supervision', 'T2 weighted imaging', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Visualization', 'base', 'big-data science', 'biomedical resource', 'brain surgery', 'cancer care', 'cancer heterogeneity', 'cancer imaging', 'cancer therapy', 'data curation', 'data integration', 'deep learning', 'design', 'digital', 'image guided', 'image guided therapy', 'image registration', 'imaging modality', 'improved', 'in vivo', 'in vivo monitoring', 'innovation', 'ion mobility', 'learning strategy', 'machine learning algorithm', 'mass spectrometer', 'metabolic imaging', 'microdevice', 'neoplastic', 'new technology', 'novel', 'novel strategies', 'overtreatment', 'personalized cancer therapy', 'personalized medicine', 'precision medicine', 'prostate biopsy', 'protocol development', 'response', 'surgery outcome', 'technology research and development', 'tissue oxygenation', 'tool', 'trait', 'tumor', 'tumor heterogeneity', 'tumor hypoxia']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2021,1527478
"Developing computational algorithms for histopathological image analysis Project Summary  Histopathology is the cornerstone of disease diagnosis and prognosis. With the advance of imaging technology, whole-slide image (WSI) scanning of tissue slides is becoming a routine clinical procedure and producing a massive amount of data that captures histopathological details in high resolution. Most current pathological image analysis methods, similar to general image analysis approaches, mainly focus on morphology features, such as tissue texture and granularity, but ignore the complex hierarchical structures of tissues. Cells are the fundamental building blocks to tissues. Different types of cells are first organized into cellular components, which together with the extracellular matrix, form different types of tissue architectures. Understanding the interactions among these different types of cells can provide critical insights into biology and disease status. However, there are some major computational challenges: (1) How to identify and classify different types of cells in tissue, (2) how to characterize the highly complex and heterogeneous spatial organization of tissue, and (3) how to integrate histopathology data with other types of data to study disease status and progression. The goal of this proposal is to develop novel computational methods to analyze histopathology image data to study disease status and progression. In order to achieve this goal, we have built a strong research team with complementary expertise in image analysis, machine learning, statistical modeling, and clinical pathology. Specifically, we will develop novel algorithms to: (1) classify different types of cells from histopathology tissue WSI scans, (2) characterize and quantify cell spatial distribution and cell-cell interactions, and (3) integrate histopathology data with other types data to study disease progression. All proposed methods were motivated by real-world biological and clinical applications across different types of diseases, such as liver diseases, infectious diseases, and cancer. If implemented successfully, the proposed study will facilitate the analysis and modeling of data generated from histopathology tissue slides to improve disease risk assessment, diagnosis, and outcome prediction. Narrative Technological advances in histopathology imaging and computing have enabled the in-depth characterization of pathology tissues. The overarching goal of this proposal is to develop computational algorithms to analyze histopathology image data to study disease status and progression.",Developing computational algorithms for histopathological image analysis,10097119,R01GM140012,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Bayesian Method', 'Biological', 'Biology', 'Biomedical Research', 'Cell Communication', 'Cells', 'Classification', 'Clinical', 'Clinical Pathology', 'Communicable Diseases', 'Communities', 'Complex', 'Computational algorithm', 'Computer Models', 'Computing Methodologies', 'Data', 'Diagnosis', 'Disease', 'Disease Progression', 'Evaluation', 'Extracellular Matrix', 'Genomics', 'Goals', 'Graph', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histologic', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Intuition', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscope', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Network-based', 'Pathologic', 'Pathologist', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Physics', 'Procedures', 'Research', 'Resolution', 'Risk Assessment', 'Scanning', 'Slide', 'Spatial Distribution', 'Stains', 'Statistical Models', 'Structure', 'Texture', 'Tissue imaging', 'Tissues', 'base', 'cancer type', 'cell type', 'clinical application', 'clinical care', 'convolutional neural network', 'data integration', 'data modeling', 'deep learning algorithm', 'digital', 'digital pathology', 'disease diagnosis', 'disorder risk', 'drug discovery', 'experience', 'improved', 'insight', 'machine learning method', 'molecular pathology', 'multiple datasets', 'novel', 'outcome forecast', 'outcome prediction', 'particle', 'pathology imaging', 'predictive modeling', 'software development', 'user friendly software', 'whole slide imaging']",NIGMS,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,409167
"Deep learning and topological approaches to identify kidney tissue features associated with adverse outcomes after nephrectomy ABSTRACT Pathologic assessment of kidney biopsy tissue remains the best predictor of adverse outcomes in patients with kidney diseases. These features are largely independent of disease etiology and are not well reflected in non- invasive tests (e.g. serum creatinine and albuminuria). Quantitative assessment of these parameters is time consuming and maybe flawed by heterogeneity of pathologic features within kidney tissue. We propose to evaluate and optimize computational image analysis approaches to support pathologic analysis of large pieces of cancer-free kidney tissue from patients who underwent nephrectomy which we have collected (n > 220). Computer-assisted analysis of glomerular phenotypes in these samples show that morphometric features in glomeruli without obvious pathology precede established pathologic changes. We hypothesize that evaluation of cancer-free kidney tissue will inform about subclinical damage in the remaining kidney which is associated with relevant pathologic and clinical parameters. We propose to assess glomeruli, arteries and tubuli, and determine the spatial inter-relationship of the assessed features within the kidney tissue. The examination of significantly larger pieces of kidney tissue than those obtained by needle biopsy allows to include 20 times more glomeruli (nephrectomy samples: avrg. 256 glomeruli/sample; needle biopsy: avrg. 13/sample) with the vast majority considered “normal appearing” as per standard pathologic criteria. In addition, these samples include a significant larger number of blood vessels (nephrectomy samples: avrg. 18 arteries/sample; needle biopsy: avrg. 1/sample) allowing a more robust evaluation of the vasculature. We propose to apply and optimize our detection and segmentation approach to detect glomeruli, arteries and tubular segments to train convolutional neural networks and use topological image analysis to automate the identification of visual and sub-visual features. In addition, we will assess the spatial relationship between individual features (glomeruli, arteries and tubular segments and features of the same category, i.e. globally sclerosed glomeruli, arteries with hyalinosis, atrophied tubuli) within the section. To determine reproducibility of our approach, we will assess a second tissue section from a separate part of the same samples. Specifically, we propose an algorithmic detection and characterization of kidney features using deep learning, a topological image analysis for discovery of novel sub-visual features in kidney tissue images and to determine spatial relatedness of these features. If successful, we will validate our analytical approach in future independent studies. For this purpose, we are already prospectively collecting kidney tissue and longitudinal clinical data from consented patients undergoing nephrectomies, allowing association of specific features with clinical relevant outcomes. LAY NARRATIVE Patients who have one kidney removed because of cancer or other reasons, are at risk of experiencing kidney failure after the surgery due to damage to the remaining kidney, but it is difficult to know why the kidney fails and how to prevent or treat it. Evaluation of kidney tissue is the best way to determine how strong or weak the kidney is at time of surgery and how to best manage kidney-related complications afterwards. We propose a detailed analysis of pieces of tissue not affected by the tumor from the removed kidney using advanced computer-assisted analysis methods (“convolutional neural networks” and “topological image analysis”) to more accurately evaluate the status of the kidney, predict what will happen to the kidney function in the future and thereby guide therapy.",Deep learning and topological approaches to identify kidney tissue features associated with adverse outcomes after nephrectomy,10229784,R21DK126329,"['Acute', 'Albuminuria', 'Algorithms', 'Arteries', 'Atrophic', 'Blood Vessels', 'Categories', 'Chronic Kidney Failure', 'Classification', 'Clinical', 'Clinical Data', 'Collection', 'Computer Assisted', 'Consent', 'Consumption', 'Contralateral', 'Creatinine', 'Data', 'Data Analyses', 'Detection', 'Diabetes Mellitus', 'Diabetic Nephropathy', 'Disease', 'Distant', 'Elderly', 'Etiology', 'Evaluation', 'Excision', 'Fibrosis', 'Functional disorder', 'Future', 'Glomerulonephritis', 'Heterogeneity', 'Human', 'Hypertension', 'Image', 'Image Analysis', 'Individual', 'Kidney', 'Kidney Diseases', 'Kidney Failure', 'Malignant Neoplasms', 'Manuals', 'Masks', 'Measures', 'Methods', 'Modernization', 'Needle biopsy procedure', 'Needles', 'Nephrectomy', 'Nephrotic Syndrome', 'Neural Network Simulation', 'Obesity', 'Operative Surgical Procedures', 'Organ', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Phenotype', 'Population', 'Renal function', 'Reproducibility', 'Research', 'Risk', 'Risk Factors', 'Sampling', 'Scanning', 'Serum', 'Spatial Distribution', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Training', 'Tubular formation', 'Visual', 'adverse outcome', 'base', 'clinically relevant', 'cohort', 'convolutional neural network', 'cost effective', 'deep learning', 'experience', 'glomerulosclerosis', 'histological stains', 'improved', 'insight', 'interstitial', 'kidney biopsy', 'kidney imaging', 'morphometry', 'novel', 'outcome prediction', 'prevent', 'prospective', 'renal damage', 'serial imaging', 'spatial relationship', 'tumor', 'user-friendly']",NIDDK,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2021,234000
"Pooled analysis of multiple sclerosis findings on multi-site 7 Tesla MRI Project Summary/Abstract Background: Although current MRI performs well as a tool to measure white matter (WM) inflammation in MS, its ability to quantify gray matter (GM) pathology, meningeal inflammation, and chronic inflammatory changes are limited. For this reason, researchers have looked to 7-tesla (7T) MRI for more robust in vivo measures of pathology. Although the increased sensitivity of 7T MRI for these aspects of MS have stimulated much interest, the impact of previous studies have been limited due to small sample sizes, varying methodologies, cumbersome analysis methods, and conflicting results – all of which have limited the generalizability of findings and more widespread dissemination of the use of this tool. Objective: In this study, we aim to advance the use of 7T MRI as a tool for diagnosis, prognosis, and treatment effect monitoring by performing multi-site, large sample size evaluation of imaging correlates of cortical and deep GM lesions, chronic active WM lesions (WM lesions with paramagnetic rims on MRI), and meningeal inflammation (leptomeningeal inflammation (LME) on MRI) and validation of their clinical relevance. We also will look develop automated tools for identification and quantification of these findings on 7T MRI. Study Design: Imaging and clinical data will be derived from previous and ongoing studies of the use of 7T MRI in MS performed at multiple collaborative sites under the umbrella of the North American Imaging in MS (NAIMS) Collaborative, including the University of Maryland, Baltimore, Harvard-Brigham and Women’s Hospital, the National Institutes of Neurological Disorders and Stroke, the University of Pennsylvania, and the Montreal Neurological Institute at McGill University. This includes data on up to 814 individual persons with MS, 1232 individual study visits, and a follow up period of up to 5 years. GM lesions, WM lesions with paramagnetic rims, and LME will be identified on 7T, with critical evaluation of methods and their relationship to clinical data. Further, the manual analysis results will be used as training sets for deep learning algorithms for identification of these abnormalities on future 7T MRI scans. Impact: This study would provide the data on measurement variability and generalizable clinical importance of the imaging findings being investigated, along with providing automated tools for future, high-throughput studies. In advancing these precise measures of aspects of MS pathology only poorly measured on lower field MRI, this study will lead to more accurate MS diagnoses, improvements in the ability to monitor changes in MS pathology over time, and perhaps lead to the screening of new pharmaceutical interventions to target GM lesions, WM lesions with paramagnetic rims, and LME. Project Narrative In this study, multiple institutions performing research using 7-tesla (7T) MRI research on patients with multiple sclerosis (MS) will combine data for a large scale, pooled analysis project. The investigators will refine methods for visualizing cortical and deep gray matter lesions, chronically inflamed white matter lesions, and meningeal inflammation on 7T MRI in MS and will evaluate their clinical relevance on a large scale and develop machine learning algorithms for future identification. It is expected that validating findings on 7T and their clinical relevance along with providing automated tools for analysis will lead to the use of 7T MRI as a more widespread clinical tool, resulting in earlier diagnoses, better prognostication, and more effective treatment monitoring in MS.",Pooled analysis of multiple sclerosis findings on multi-site 7 Tesla MRI,10278178,R01NS122980,"['Algorithmic Analysis', 'American', 'Autopsy', 'Baltimore', 'Biological Markers', 'Caring', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Conflict (Psychology)', 'Consumption', 'Data', 'Data Pooling', 'Demyelinations', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Functional disorder', 'Future', 'Histopathology', 'Hospitals', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Impaired cognition', 'Individual', 'Inflammation', 'Inflammatory', 'Institutes', 'Institution', 'Intervention', 'Lead', 'Lesion', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Maryland', 'Masks', 'Measurement', 'Measures', 'Meningeal', 'Meninges', 'Methodology', 'Methods', 'Monitor', 'Multiple Sclerosis', 'Multiple Sclerosis Lesions', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Neurologic', 'Outcome', 'Pathology', 'Patient Care', 'Pennsylvania', 'Persons', 'Pharmacologic Substance', 'Phase', 'Predisposition', 'Protocols documentation', 'Research', 'Research Design', 'Research Personnel', 'Research Project Grants', 'Sample Size', 'Scanning', 'Site', 'Standardization', 'Structure', 'Thalamic structure', 'Time', 'Training', 'Universities', 'Validation', 'Visit', 'Visualization', 'Woman', 'accurate diagnosis', 'clinical care', 'clinically relevant', 'cognitive disability', 'comparative', 'deep learning algorithm', 'disability', 'effective therapy', 'follow-up', 'gray matter', 'high throughput analysis', 'imaging study', 'in vivo', 'insight', 'interest', 'large datasets', 'machine learning algorithm', 'magnetic field', 'multiple sclerosis patient', 'outcome forecast', 'physically handicapped', 'prognostic', 'prognostic tool', 'screening', 'tool', 'treatment effect', 'white matter']",NINDS,UNIVERSITY OF MARYLAND BALTIMORE,R01,2021,535821
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",10075930,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Reference Standards', 'Research', 'Risk', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'diagnostic technologies', 'disorder subtype', 'elastography', 'hepatocellular injury', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'risk stratification', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,448421
"Perceptual integration of luminance, texture and color cues for visual boundary segmentation Project Summary One of the most essential computations performed by the visual system is segmenting images into regions corresponding to distinct surfaces. This in turn requires identifying the boundaries separating image regions, a process known as boundary segmentation. Computational analyses of natural images have revealed that many visual cues are available at region boundaries, including differences in luminance, texture, and color. It is known that these cues combine for tasks like edge localization and orientation discrimination. However, it remains unclear how these various cues are weighted and combined for boundary segmentation.  In collaborative work with Canadian colleagues at McGill University in Montreal, we have developed a novel machine learning framework for characterizing human performance on boundary segmentation tasks using naturalistic micro-pattern stimuli. Our method makes use of the Filter-Rectify-Filter (FRF) model often applied to characterizing texture boundary segmentation. The major innovation of our approach is that we fit the FRF model directly to thousands of psychophysical stimulus-response observations to estimate its major defining parameters. We have recently applied this approach to investigating spatial strategies for contrast boundary segmentation and comparing competing hypotheses of how contrast modulation is integrated across orientation channels. In this grant, we propose to apply both classical psychophysical techniques and our novel machine learning methodology to understanding the computations employed to combine luminance, texture and color cues for segmentation.  In Aim 1, we focus on modeling segmentation of luminance-defined boundaries, comparing the case where each surface has uniform luminance, giving rise to a sharp edge (luminance step), to the more naturalistic case where the two surfaces have differing proportions of dark and light micro-patterns on either side of the boundary with no sharp edge (luminance texture). We will apply our machine learning methodology to test the hypothesis that different neural mechanisms may be involved in segmenting these two different kinds of luminance boundaries. In Aim 2, we ask how observers integrate first-order (luminance) and second-order (texture) cues for boundary segmentation, and if there are differences in cue combination strategies for luminance steps and luminance textures. We will also compare models embodying competing hypotheses of the underlying neural mechanisms of cue combination. In Aim 3, we extend the analyses in Aims 1 and 2 beyond simple luminance differences to include differences in color. Finally, Aim 4 is a pedagogical aim of promoting undergraduate research. Project Narrative Segmenting natural images into regions corresponding to distinct surfaces is an essential visual task, yet the underlying computations for boundary segmentation remain poorly understood. In this project, we will apply classical psychophysical techniques and our novel machine learning methodology to understand how multiple cues, including luminance, texture, and color, combine to enable boundary segmentation. We hope to develop and test computational models of boundary segmentation, with the ultimate goal of gaining insight into the underlying neural mechanisms employed for this essential natural vision task.","Perceptual integration of luminance, texture and color cues for visual boundary segmentation",10201916,R15EY032732,"['Address', 'Biological', 'Color', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'Cues', 'Data', 'Discrimination', 'Educational process of instructing', 'Environment', 'Goals', 'Grant', 'Human', 'Image', 'Journals', 'Laboratories', 'Light', 'Literature', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Positioning Attribute', 'Process', 'Psychophysics', 'Publications', 'Research', 'Response to stimulus physiology', 'Series', 'Side', 'Source', 'Stimulus', 'Surface', 'Techniques', 'Testing', 'Texture', 'Universities', 'Vision', 'Vision research', 'Visual', 'Visual system structure', 'Work', 'computer studies', 'experience', 'innovation', 'insight', 'interest', 'laboratory curriculum', 'luminance', 'neuromechanism', 'neurophysiology', 'novel', 'pedagogy', 'undergraduate research', 'undergraduate student', 'vision science']",NEI,FLORIDA GULF COAST UNIVERSITY,R15,2021,374345
"Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system Abstract Numerous small vessels making up the central nervous system blood and lymphatic vascular networks are heterogeneous and region-specific dynamic structures, whose segments, position, shape and function can change in response to physiological and pathophysiological conditions. To date it has not been possible to integrate blood and lymphatic vascular elements and their microenvironment to achieve a holistic quantitative characterization of the combined brain and meningeal tissue-scale vascular networks, its structure and function in normal and disease states. This application proposes to develop microscopy- based high-throughput image analysis techniques for automated extraction of blood and lymphatic vascular networks enabling quantitative morphodynamic characterization of cerebrovascular microenvironment changes in two intracranial compartments – the brain and dura mater. The study will focus on new algorithms for precise region-specific microvessel registration, mosaicing, segmentation, fusion and colocalization for constructing large tissue scale spatially aligned dual blood/lymphatic vascular network structural maps in the animals of both sexes, as well as characterization of heterogeneities of microvascular networks, including blood and lymphatic vasculature, under estrogen and sleep deprivation (the conditions relevant to multiple cerebrovascular disorders) compared to physiological settings. In other words, advanced microscopy-based techniques will be used to image blood and lymphatic vessels at sub-micron resolution in dura mater and the brain, and then cutting-edge deep machine learning imaging analysis methods will be employed to segment and quantify these vessels, their geometry, vessel wall structure, functionality, and interrelationship. Detailed structural analysis of microvascular networks is essential for accurate evaluation of the distribution of physical forces, substrate delivery and tissue clearance of waste, as well as sex differences and consequences of intracranial networks remodeling under physiological and pathological conditions. This will create knowledge enabling a better understanding of the pathogenesis of vascular impairments under estrogen and sleep deprivation, identify common molecular mechanisms and the efficacy and effectiveness of different therapeutic treatments. Without the ability to construct total structural and functional blood/lymphatic vascular network maps from studies limited to individual tissue component parts, it is little wonder that translation from the molecular and cellular levels to the whole organ and system levels is deficient and hinders translational progress towards a comprehensive understanding of the pathophysiology associated with a range of neurological disorders. Detailed analysis of structural relationships of both blood and lymphatic circulation in the brain system will have a direct impact on our general understanding of vascular function in brain/meningeal communication, and the cause and resolution of numerous diseases resulting from intracranial vascular disorders including impact of sex hormone (estrogen) deprivation, sleep deprivation, migraines, stroke, multiple sclerosis, dural arterio-venous fistulae, intradural hygroma and hematoma, spontaneous cerebral spinal fluid leaks, and intradural aneurysms that can lead to the development of neurological and cognitive impairment, including Alzheimer's. Quantitative description of blood and lymphatic vessel network structures using image analytics and machine learning algorithms distributed as software tools will have broad applications to quantification of other thin complex curvilinear anatomical structures (i.e. nerves, neuronal circuits, neurons, and neuroglia). The new software for blood and vessel network measurement will enable translation of fundamental pathophysiological knowledge gained from this proposal towards the development and assessment of the effectiveness of treatments and therapeutic interventions to enhance health, lengthen life, and reduce illness and disability associated with a range of neurological disorders.",Quantitative analysis of estrogen and sleep deprivation-induced blood and lymphatic vascular remodeling in the brain system,10138039,R01NS110915,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Aneurysm', 'Animals', 'Arteriovenous fistula', 'Blood', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Cardiovascular system', 'Cephalic', 'Cerebrospinal Fluid', 'Cerebrovascular Disorders', 'Chronic', 'Chronic Insomnia', 'Communication', 'Complex', 'Computer software', 'Cystic Lymphangioma', 'Development', 'Disease', 'Dura Mater', 'Dural Arteriovenous Fistulas', 'Effectiveness', 'Elements', 'Estrogens', 'Evaluation', 'Female', 'Functional disorder', 'Geometry', 'Gonadal Steroid Hormones', 'Health', 'Hematoma', 'Heterogeneity', 'Hybrids', 'Image', 'Image Analysis', 'Imaging Techniques', 'Impaired cognition', 'Impairment', 'Individual', 'Knowledge', 'Lead', 'Life', 'Link', 'Lymphatic', 'Lymphatic System', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Meningeal', 'Metabolism', 'Methods', 'Microscopy', 'Migraine', 'Modeling', 'Molecular', 'Morphology', 'Mosaicism', 'Multiple Sclerosis', 'Mus', 'Nerve', 'Neuraxis', 'Neuroglia', 'Neurologic', 'Neurons', 'Optical Coherence Tomography', 'Parietal', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Physiological', 'Positioning Attribute', 'Resolution', 'Route', 'Sex Differences', 'Shapes', 'Site', 'Sleep', 'Sleep Deprivation', 'Sleep Disorders', 'Sleep disturbances', 'Software Tools', 'Stroke', 'Structure', 'Subdural Hematoma', 'Subdural Hygroma', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Thinness', 'Tissues', 'Translations', 'Treatment Effectiveness', 'Vascular Diseases', 'Vascular remodeling', 'Vascular resistance', 'Venous', 'associated symptom', 'base', 'body system', 'cerebral microvasculature', 'cerebrovascular', 'clinically relevant', 'confocal imaging', 'deep learning', 'deprivation', 'detection limit', 'disability', 'effectiveness evaluation', 'geometric structure', 'in vivo', 'lymphatic circulation', 'lymphatic vasculature', 'lymphatic vessel', 'machine learning algorithm', 'male', 'microleakage', 'nervous system disorder', 'neuronal circuitry', 'noninvasive diagnosis', 'novel', 'response', 'sex', 'sleep pattern', 'solute', 'stem', 'submicron', 'tool', 'wasting']",NINDS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2021,534438
"Application of Advanced Quantitative Methods to Schizophrenia Research PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found a decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Prefrontal white matter is among the areas usually involved. Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities, suggesting that abnormalities causing diminished FA are subtle, and that postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a FIC/NIMH collaboration with the Macedonian Academy of Sciences and Arts, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the spatial orientation of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high- resolution images of Bielschowsky stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This technique yields clear images of individual axons that can be traced and measured in 3 dimensions. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin- related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models in three multi-omics data fusion approaches to combine different types of high-dimensional data, including those produced by Aims 1 and 2, with known structural properties of axons and myelin in white matter, in order to build a model or detect novel dependencies of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. NARRATIVE Our ongoing research in North Macedonia and at Columbia University / New York State Psychiatric Institute has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale to study schizophrenia.",Application of Advanced Quantitative Methods to Schizophrenia Research,10099068,R01MH125030,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Antibodies', 'Architecture', 'Area', 'Arts', 'Autopsy', 'Axon', 'Biochemical', 'Biochemistry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Confocal Microscopy', 'Consensus', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Electron Microscope', 'Electron Microscopy', 'Electrons', 'Evaluation', 'Face', 'Fiber', 'Forensic Medicine', 'Genetic Transcription', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Individual', 'Institutes', 'Interviewer', 'Knowledge', 'Label', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofibrillary Tangles', 'Neurofilament Proteins', 'New York', 'Oligodendroglia', 'Online Systems', 'Optic Nerve', 'Paraffin', 'Pathologist', 'Pharmaceutical Preparations', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Schizophrenia', 'Science', 'Shotguns', 'Silver Staining', 'Space Perception', 'Stains', 'Structure', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Toxicology', 'Training', 'Transcript', 'Triad Acrylic Resin', 'Universities', 'Variant', 'Visualization', 'base', 'cognitive function', 'cohort', 'data archive', 'data fusion', 'deep neural network', 'density', 'design', 'diffusion anisotropy', 'high resolution imaging', 'histological studies', 'imaging study', 'innovation', 'instrument', 'interest', 'microscopic imaging', 'multidimensional data', 'multiple omics', 'network models', 'novel', 'precursor cell', 'psychologic', 'reconstruction', 'sex', 'symposium', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,641403
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",10139080,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'machine learning method', 'myocardial injury', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2021,790095
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10188526,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2021,388359
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10183329,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2021,797476
"Characterization of Early Response to Chronic Lung Injury using Chest CT Project Summary  In some individuals chronic tobacco smoke exposure results in emphysema and pulmonary fibrosis. Both of these parenchymal changes are irreversible, highlighting the importance of the early identification of their development and progression. Unfortunately, currently available methods for detecting the presence and evolution of these changes have limited sensitivity and specificity for very early disease and for subtle disease progression. Dr. Ash’s work has shown that automated objective analysis of computed tomography (CT) scans of the chest can detect clinically relevant radiologic findings called interstitial changes that may represent early pulmonary fibrosis, even in individuals without visually apparent disease. In the first aim of this proposal, Dr. Ash will refine and utilize a more sensitive and specific automated CT analysis tool that he and his lab have developed for the detection of both emphysema and interstitial changes. He will determine if emphysema and interstitial changes detected using this method are clinically significant in those patients deemed normal by previously performed visual analysis and in those deemed normal by other objective approaches. In the second aim, he will determine if areas of locally high density tissue in visually normal appearing lung parenchyma measured using augmented versions of his objective analysis tools are associated with mortality, other clinical outcomes, and peripheral measures of inflammation. Finally, in the third aim he will utilize these techniques to analyze longitudinal CT scans from the COPDGene study that were obtained over 10 years of follow-up, and will identify factors that predict or modify the development and progression of parenchymal changes on CT.  Dr. Ash will perform this work in the Division of Pulmonary and Critical Care Medicine at Brigham and Women’s Hospital (BWH), a core teaching hospital of Harvard Medical School, under the mentorship of Dr. George Washko, an expert in the field of medical image analysis and the co-principal investigator of the Applied Chest Imaging Laboratory at BWH. With the guidance of Dr. Washko and his scientific advisory committee, Dr. Ash has developed a comprehensive five year training program to develop the skills needed to become an independent investigator with expertise in quantitative image analysis, including predictive modeling and statistical machine learning.  Dr. Ash is dedicated to a career in academic medicine. His goal is to become a clinician-scientist using the skills gained during this award to improve our ability to detect and monitor smoking related lung disease. The techniques he has proposed may help identify modifiable risk factors and treatments for smoking related lung disease, determine which patients are likely to benefit from treatment, and monitor the response to therapy. Project Narrative Cigarette smoking results in emphysema and pulmonary fibrosis, but only in a minority of smokers. This proposal aims to use advanced objective analysis of chest computed tomography images to detect the earliest manifestations of smoking related lung disease. This will enable us to identify susceptible patients at the earliest possible moment, track their disease progression, and ultimately shift treatment strategies from palliating disease related symptoms to preventing disease development.",Characterization of Early Response to Chronic Lung Injury using Chest CT,10079021,K08HL145118,"['Advisory Committees', 'Area', 'Award', 'Chest', 'Chronic', 'Cicatrix', 'Clinical', 'Critical Care', 'Densitometry', 'Detection', 'Development', 'Development Plans', 'Disease', 'Disease Progression', 'Early identification', 'Educational workshop', 'Evolution', 'Fibrosis', 'Goals', 'Hospitals', 'Image', 'Image Analysis', 'Imaging Techniques', 'Individual', 'Inflammation', 'Inflammatory', 'Laboratories', 'Lung', 'Lung diseases', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Minority', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Outcome', 'Patients', 'Peripheral', 'Pharmaceutical Preparations', 'Predictive Factor', 'Primary Prevention', 'Principal Investigator', 'Publications', 'Pulmonary Emphysema', 'Pulmonary Fibrosis', 'Radiologic Finding', 'Radiology Specialty', 'Research Personnel', 'Risk', 'Risk Factors', 'Scanning', 'Scientist', 'Sensitivity and Specificity', 'Severity of illness', 'Smoker', 'Smoking', 'Structure of parenchyma of lung', 'Symptoms', 'Teaching Hospitals', 'Techniques', 'Tissues', 'Tobacco smoke', 'Training', 'Training Programs', 'Visual', 'Woman', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'career', 'career development', 'chest computed tomography', 'cigarette smoking', 'clinically relevant', 'clinically significant', 'convolutional neural network', 'deep learning', 'density', 'disorder prevention', 'disorder risk', 'exercise capacity', 'follow-up', 'improved', 'interstitial', 'lung injury', 'mange', 'medical schools', 'modifiable risk', 'mortality', 'new technology', 'novel', 'palliate', 'palliating symptoms', 'palliation', 'predictive modeling', 'prevent', 'protein biomarkers', 'pulmonary function', 'quantitative imaging', 'respiratory', 'response', 'skills', 'smoking-related lung disease', 'statistical and machine learning', 'tool', 'treatment strategy']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,K08,2021,170320
"Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction Nuclear medicine imaging in children has been shown to have significant clinical value across all organ systems. In providing this significant benefit it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that of adults, owing to their higher tissue sensitivity and longer potential lifespan. The governing principle of this project will be to minimize radiation dose while methodically ensuring that lesion detection performance is fully preserved. This will be accomplished by using validations based on both numerical and physician observers measuring performance in tasks that emulate those performed clinically. We will employ two approaches in tandem to enable lowering dose while maintaining performance. First, we will use advanced image reconstruction and processing techniques. Corrections for various forms of image quality degradation will be incorporated in the reconstruction, and deep learning (DL) will be used for post-reconstruction denoising. Second, we will develop methods to correct for both body and respiratory motion, which degrade diagnostic accuracy. Correcting for body and respiratory motion will allow dose to be reduced without loss of image quality and will also offer a technological alternative to using sedation or even general anesthesia to minimize motion when imaging children. For this investigation we have selected 99mTc-labeled dimercaptosuccinic acid (DMSA) renal imaging as a testbed to demonstrate our approaches. Damage to the renal cortex resulting from infection of the kidneys is a critical issue in children, including newborns and toddlers. DMSA SPECT is the “gold-standard” in the evaluation of pyelonephritis and renal scarring post- infection. The concepts we will demonstrate for reduction of radiation dose and correction of motion with DMSA will be translatable to other SPECT (and PET) studies in pediatric imaging and beyond.  Our Specific Aims are: 1. Establish infrastructure for investigating and evaluating advanced reconstruction and motion correction; 2. Determine the extent of radiation dose reduction to pediatric patients through improved reconstruction and DL denoising while maintaining optimal full-dose lesion detection accuracy; 3. Develop data-driven and depth-sensing camera methods for body and respiratory motion estimation and correction; and 4. Conduct numerical and physician observer studies to validate the level of dose reduction enabled by DL denoising and motion correction. Narrative  In nuclear medicine imaging, it is critical to minimize the radiation dose used in pediatric patients, whose risk for adverse health effects (such as cancer) per unit administered activity is much higher than that in adults, owing to their higher tissue sensitivity and longer potential lifespan. Correcting for body and respiratory motion occurring during imaging will improve the quality of the formed three-dimensional images of the patient by reducing blurring and image artifacts and offer a technological alternative to using sedation or even general anesthesia to reduce motion when imaging children, which can bear health risks of its own. We propose an advanced reconstruction methodology which would enable reduction in the amount of activity administered and compensate for patient motion during imaging.",Improving Pediatric SPECT Imaging: Enhanced Lesion Detection with Dose Reduction through Advanced Reconstruction and Motion Correction,10168531,R01EB029315,"['3-Dimensional', 'Adult', 'Algorithms', 'American', 'Area', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'DMSA', 'Data', 'Databases', 'Detection', 'Development', 'Discipline of Nuclear Medicine', 'Dose', 'Enhancing Lesion', 'Ensure', 'European', 'Evaluation', 'Freedom', 'Gaussian model', 'General Anesthesia', 'Gold', 'Guidelines', 'Health', 'Hybrids', 'Image', 'Imaging problem', 'Infection', 'Infrastructure', 'Investigation', 'Kidney', 'Label', 'Lesion', 'Longevity', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Morphologic artifacts', 'Motion', 'Newborn Infant', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Procedures', 'Pyelonephritis', 'ROC Curve', 'Radiation Dose Unit', 'Respiration', 'Risk', 'Scheme', 'Sedation procedure', 'Societies', 'Statistical Study', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Tissues', 'Toddler', 'Ursidae Family', 'Validation', 'base', 'body system', 'cardiac single photon emission computed tomography', 'clinically significant', 'deep learning', 'denoising', 'denoising deep learning', 'diagnostic accuracy', 'image processing', 'image reconstruction', 'improved', 'innovation', 'kidney cortex', 'kidney infection', 'molecular imaging', 'pediatric patients', 'preservation', 'reconstruction', 'renal scarring', 'respiratory', 'response', 'single photon emission computed tomography']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2021,724046
"Fast motion-robust fetal neuroimaging with MRI PROJECT SUMMARY/ABSTRACT Fetal-brain magnetic resonance imaging (MRI) has become an invaluable tool for studying the early development of the brain and can resolve diagnostic ambiguities that may remain after routine ultrasound exams. Unfortunately, high levels of fetal and maternal motion (1) limit fetal MRI to rapid two-dimensional (2D) sequences and frequently introduce dramatic artifacts such as (2) image misorientation relative to the standard sagittal, coronal, axial planes needed for clinical assessment and (3) partial to complete signal loss. These factors lead to the inefficient practice of repeating ~30 s stack-of-slices acquisitions until motion-free images have been obtained. Throughout the session, technologists manually adjust the orientation of scans in response to motion, and about 38% of datasets are typically discarded. Thus, subject motion is the fundamental impediment to reaping the full benefits of MRI for answering clinical and investigational questions in the fetus. The overarching goal of this project is to overcome the challenges posed by motion by exploiting innovations in deep learning, which have enabled image-analysis algorithms with unprecedented speed and reliability. We propose to integrate these into the MRI acquisition pipeline to unlock the potential of fetal MRI. We will develop practical pulse-sequence technology for automated and dynamically motion-corrected fetal neuroimaging without the need for external hardware or calibration. We hypothesize that this will radically improve the quality and success rates of clinical and research studies, while dramatically reducing patient discomfort and cost. We propose as Aim 1 to eradicate (2) the vulnerability of acquisitions to image-brain misorientation with rapid, automated prescription of standard anatomical planes. In Aim 2, we propose to address (3) motion during the scan with real-time correction of fetal-head motion. An anatomical stack-of-slices acquisition will be interleaved with volumetric navigators. These will be used to measure motion as it happens in the scanner and to adaptively update the slice tilt/position. We propose as Aim 3 to develop a 3D radial sequence and estimate motion between subsets of radial spokes for real-time self-navigation. Adaptively updating the orientation of spokes and selectively re-acquiring corrupted subsets at the end of the scan will enable 3D imaging of the fetal brain (1). Since the applicant has a physics background, the proposed training program at MIT and HMS will focus on deep learning and fetal development/neuroscience during the K99 phase to develop the skills needed for transitioning to independence in the R00 phase. The applicant’s goal is to become a fetal image acquisition and analysis scientist acting as bridge between deep learning, MRI and clinical fetal-imaging applications to shift the boundaries of what is currently possible with state-of-the-art technology. Fulfilling the research aims will promote this, as it will result in a practical framework for automation and motion correction, applicable to a wide variety of fetal neuroimaging sequences. PROJECT NARRATIVE Subject motion is the fundamental impediment to reaping the full benefits of fetal-brain magnetic resonance imaging, as it frequently produces images with dramatic artifacts. The goal of this project is to exploit innovations in deep learning and integrate them into the acquisition pipeline to overcome the challenges posed by motion in fetal neuroimaging studies. This will be achieved by using fast, automated scan prescription of standard anatomical planes and by adaptively updating the acquisition as motion happens in the scanner, based on sub-second navigator scans interleaved with the imaging sequence.",Fast motion-robust fetal neuroimaging with MRI,10197182,K99HD101553,"['3-Dimensional', 'Address', 'Algorithmic Analysis', 'Amniotic Fluid', 'Anatomy', 'Automation', 'Brain', 'Brain imaging', 'Calibration', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Data Set', 'Development', 'Diagnostic', 'Echo-Planar Imaging', 'Fetal Development', 'Fetus', 'Geometry', 'Goals', 'Head', 'Image', 'Individual', 'Label', 'Lead', 'Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Masks', 'Measures', 'Morphologic artifacts', 'Motion', 'Neurosciences', 'Patients', 'Phase', 'Physics', 'Physiologic pulse', 'Population', 'Positioning Attribute', 'Radial', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Sampling', 'Scanning', 'Scientist', 'Signal Transduction', 'Slice', 'Speed', 'Technology', 'Thick', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Training Programs', 'Translating', 'Ultrasonography', 'Update', 'Work', 'base', 'clinical investigation', 'convolutional neural network', 'cost', 'deep learning', 'echo detection', 'experience', 'fetal', 'image archival system', 'improved', 'innovation', 'interest', 'neuroimaging', 'novel', 'prospective', 'radiologist', 'reconstruction', 'repaired', 'research study', 'response', 'skills', 'success', 'tool', 'two-dimensional']",NICHD,MASSACHUSETTS GENERAL HOSPITAL,K99,2021,109671
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10143312,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2021,499966
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,10091434,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2021,498914
"ClearScope Combined in vivo and ex vivo three-dimensional (3D) whole-brain imaging of non-transgenic and transgenic animal models holds the promise of novel insights into neural network connectivity patterns. With regard to ex vivo light microscopic imaging of 3D whole-brain datasets, the best approach is brain clearing followed by whole-brain light sheet microscopy (LSM) because of its unique combination of speed, 3D resolving power, and low phototoxicity compared to confocal and multiphoton microscopy. Unlike other methods, the combined brain clearing / LSM approach makes it possible to use intact tissue and retain all intracellular connections within the brain structure. However, LSM systems commercially available are not suitable for ex vivo light microscopic imaging of 3D whole-brain datasets in advanced connectomics research. Recently, Dr. Raju Tomer (Dept. Biol. Sci., Columbia Univ., New York, NY) developed light sheet theta microscopy (LSTM), essentially a unique arrangement of two light sheets oblique to the specimen and one detection objective perpendicular to the specimen. This novel microscope is the basis for a number of capabilities in LSTM that are not all available with any other commercially available LSM systems. The LSTM technology has distinct advantages over confocal and other light sheet microscopes, including the unmatched ability to image thicker tissue specimens over a larger lateral area (XY) at higher optical resolutions, while maintaining fast imaging speed, high imaging quality, and low photo-bleaching. This promising technology serves as the basis for this Lab to Marketplace proposal to develop the ClearScope™, which refines and improves Dr. Tomer's original LSTM system to create a successful commercial microscope for wide-spread adoption. The key technical objectives for developing the ClearScope as a commercial product include creating and testing (i) a ClearScope prototype based on an optimized microscope hardware design; (ii) novel microscope hardware components for the ClearScope, comprising a novel chamber that contains the investigated specimen and the immersion medium, and a novel detection objective changer; (iii) novel control and image acquisition software for the ClearScope; and importantly, (iv) novel software that surpasses the existing state-of-the-art technology to assemble acquired image stacks into large 3D image volumes exceeding 10TB without need to downsample the image information. The production version of the ClearScope will benefit the neuroscience research community, pharmacological and biotechnological R&D, and society in general by improving understanding of neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions. In particular, this will result in an improved basis for developing novel treatment strategies for complex brain diseases. The proposed project will enable important new research, that is not currently feasible, into whole-brain neural network connectivity patterns by means of ex vivo light microscopic imaging of three-dimensional whole-brain datasets. To achieve this, the proposed project will create the ClearScope light sheet microscope featuring signficant capabilities to image thick specimens of unlimited lateral (XY) size with resolution that permits investigatons of subcellular structures to distinguish adjacent neuronal processes (axons, dendrites, varicosities and dendritic spines). Because these features are not all available with any commercially available light sheet microscopes, the benefit for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be the possibility to better understand neural network connectivity patterns as well as the neuropathological underpinnings of the large-scale connectional alterations associated with human neuropsychiatric and neurological conditions, ultimately resulting in an improved basis for developing novel treatment strategies for complex brain diseases.",ClearScope,10159328,R44MH116827,"['3-Dimensional', 'Address', 'Adoption', 'Animal Model', 'Area', 'Axon', 'Behavioral Research', 'Benchmarking', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Confocal Microscopy', 'Data Set', 'Dendrites', 'Dendritic Spines', 'Detection', 'Development', 'Human', 'Image', 'Immersion', 'Lateral', 'Legal patent', 'Light', 'Lighting', 'Literature', 'Methods', 'Michigan', 'Microscope', 'Microscopy', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurons', 'Neurosciences Research', 'New York', 'Optics', 'Pattern', 'Performance', 'Pharmacology', 'Phase', 'Photobleaching', 'Phototoxicity', 'Preparation', 'Process', 'Production', 'Rattus', 'Refractive Indices', 'Research', 'Resolution', 'Societies', 'Specimen', 'Speed', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Image', 'Tissues', 'Transgenic Animals', 'Translations', 'Universities', 'Validation', 'Varicosity', 'base', 'brain research', 'design', 'ex vivo imaging', 'improved', 'in vivo', 'innovation', 'insight', 'microscopic imaging', 'multiphoton microscopy', 'neural network', 'neuropsychiatry', 'new technology', 'nonhuman primate', 'novel', 'prototype', 'research and development', 'tool', 'treatment strategy', 'usability', 'user-friendly']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2021,969855
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,10066353,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2021,373738
"Robust quantitative MR imaging markers of response to therapy in Crohn’s Disease Project Summary: Crohn's disease (CD) is a chronic inflammatory disease of the gastrointestinal tract that has a prevalence of over 800,000 in the US alone. The economic impact is disproportionally high because it affects primarily young individuals. The characteristic periods of remission and relapse necessitate frequent hospitalizations. There has been a recent shift in clinical practice from a reactive to a proactive CD treatment strategy, recently coined as “treat-to-target”, where patients are treated to achieve not only an initial response-to-therapy, but also longer clinical remissions and improved mucosal healing. However, this approach requires the regular assessment of disease activity using objective markers enabling treatments to be tailored to the individual patient. Therefore, there is an unmet need for new tools to improve diagnostic accuracy, to quantify disease burden, and to monitor treatment efficacy. Our application in response to PAR-19-056, “Robust quantitative MR imaging markers of response to therapy in Crohn's disease” is aimed at developing and evaluating noninvasive, contrast and radiation-free quantitative imaging markers for assessing disease activity and for monitoring response to therapy. Currently available non-contrast MR imaging (MRI) sequences such as diffusion-weighted MRI (DW-MRI) and the calculated apparent diffusion coefficient (ADC) maps are attractive but limited in providing robust and reproducible markers. Different imaging protocols or different scanners result in different ADC values. Our primary goal is to develop robust and reliable quantitative DW-MR imaging markers for the non-contrast and non-invasive assessment of CD. The proposed novel MRI acquisition and model fitting techniques will provide measurements of slow and fast diffusion as well as fraction of fast diffusion, as highly accurate, quantitative biomarkers for cell proliferation, density and size, and tissue perfusion—all indices that characterize the extent of disease activity (i.e., inflammation) in the tissue micro-structure of the bowel. To achieve this goal, we will first develop and implement an advanced distortion and motion corrected (DiMoCo) DW-MRI technique and a spatially constrained probabilistic intravoxel incoherent motion (SPIM) model to compute robust and reproducible markers. Next, we will reduce the imaging time with estimated x4 acceleration with an accelerated image acquisition and a new, advanced deep learning-based parameter estimation technique. The proposed imaging techniques and software tools will provide robust quantitative markers, thereby enabling the accurate assessment of CD activity and response to therapy. They will also reduce the need for invasive endoscopy procedures as well as the total number of other tests typically ordered for monitoring disease, effectively reducing both the disease burden and the overall cost of healthcare. Another important goal is to develop and broadly disseminate open source software that will enable the standardized evaluation of other diseases presently evaluated with DW-MRI that would benefit from the advanced diagnostic and assessment capabilities of the proposed DiMoCo SPIM-DW-MRI technique. Project Narrative: Crohn's disease (CD) is a chronic inflammatory disease of the gastrointestinal tract that impacts over 800,000 patients in the US alone, where characteristic periods of remission and relapse necessitate frequent, costly hospitalizations and symptoms such as bloody diarrhea, abdominal pain, general malaise, and fever significantly compromise quality of life. There is a need for new tools aimed at the reliable assessment of disease activity by using objective markers to improve diagnostic accuracy, quantify disease burden, and monitor treatment efficacy, enabling subsequent treatments tailored to the individual patient's disease profile. The primary objective of this project is three-fold: First, to develop and validate a novel, noninvasive, contrast- and radiation-free quantitative MR imaging and image analysis technique, i.e., DiMoCo-SPIM that will generate robust and reproducible imaging markers from DW-MRI that will enable clinicians to more accurately assess bowel inflammation and response to therapy; second, to develop a machine learning technique that reduces the imaging time (x4 acceleration); and third, to make image analysis software developed in this proposal available in multiple clinical domains that presently evaluate various diseases with MRI and would benefit from the improved diagnostic and assessment capabilities of this computationally-driven technique.",Robust quantitative MR imaging markers of response to therapy in Crohn’s Disease,10121764,R01DK125561,"['Abdominal Pain', 'Acceleration', 'Adult', 'Affect', 'Aftercare', 'Biological', 'Biological Markers', 'Brain', 'Cell Proliferation', 'Characteristics', 'Child', 'Clinical', 'Clinical Markers', 'Coin', 'Computer software', 'Contrast Media', 'Crohn&apos', 's disease', 'Deposition', 'Diagnostic', 'Diffusion', 'Digestive System Disorders', 'Disease', 'Disease Management', 'Disease remission', 'Endoscopy', 'Estimation Techniques', 'Evaluation', 'Fever', 'Gadolinium', 'Goals', 'Health Care Costs', 'Hemorrhagic colitis', 'Hospital Costs', 'Hospitalization', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Immunomodulators', 'Individual', 'Inflammation', 'Intestines', 'Ionizing radiation', 'Laboratory Markers', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malaise', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Mucous Membrane', 'Operative Surgical Procedures', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Perfusion', 'Pharmaceutical Preparations', 'Physiological', 'Predisposition', 'Prevalence', 'Procedures', 'Protocols documentation', 'Quality of life', 'Radiation', 'Relapse', 'Reporting', 'Reproducibility', 'Respiration', 'Safety', 'Software Tools', 'Standardization', 'Structure', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'base', 'burden of illness', 'cell motility', 'chronic inflammatory disease', 'clinical decision-making', 'clinical practice', 'clinical remission', 'contrast enhanced', 'deep learning', 'density', 'diagnostic accuracy', 'diffusion weighted', 'economic impact', 'efficacy evaluation', 'healing', 'imaging biomarker', 'imaging modality', 'imaging software', 'improved', 'indexing', 'individual patient', 'individualized medicine', 'molecular marker', 'novel', 'open source', 'quantitative imaging', 'response', 'response biomarker', 'soft tissue', 'software development', 'success', 'tool', 'treatment strategy', 'water diffusion']",NIDDK,BOSTON CHILDREN'S HOSPITAL,R01,2021,391320
"A High Performance Research Image Repository (RIR) for the Washington University Center of High Performance Computing (CHPC) Project Summary/Abstract: We propose to build a Research Image Repository (RIR) to house large collections of biomedical imaging data. The RIR will include datasets produced locally at Washington University: The Connectome Coordination Facility (CCF) (which itself includes the Human Connectome Project (HCP) Young Adult study, The Lifespan related projects, the Disease related projects, and assorted HCP-related projects), The Knight Alzheimer Disease Research Center (ADRC), the Adolescent Brain Cognitive Development (ABCD) Study, The Comprehensive Neuro-Oncology Data Repository (CONDR), and the clinically-based PACS image repository. In addition, copies of external data collections such as the UK Biobank, The Alzheimer's Disease Neuroimaging Initiative (ADNI), and The Cancer Image Archive (TCIA) will be maintained. The RIR includes a data management software solution that will introduce many novel features (such as `data tagging' to enrich datasets, and advanced search features) and will allow us to leverage existing storage including the Center for High Performance Computing's (CHPC) 1.4PB of BeeGFS `scratch' storage, solid-state NVMe drives integrated into the compute nodes, and 10PB of ZFS-based storage. All storage will be presented to the user as a single file-system, while data will be migrated to different performance tiers based on the storage requirements of the datasets or processing algorithms. The RIR will be integrated into the CHPC for data processing. The proposal also includes two NVIDIA DGX A100 GPU servers providing state-of-the-art GPU- based processing power. The combination of high-quality, diverse sets of biomedical imaging data with next- generation computing power will have a transformative effect on biomedical imaging processing pipelines and nowhere will the effects be more profound than in the emerging field of Deep Learning for image processing. Project Narrative: We propose to build a Research Image Repository (RIR) to house large collections of biomedical imaging data. The RIR will be integrated into Washington University in St. Louis's Center for High Performance Computing (CHPC) to process the data and will leverage over 11PB of existing storage.",A High Performance Research Image Repository (RIR) for the Washington University Center of High Performance Computing (CHPC),10177147,S10OD030477,"['Adolescent', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Brain', 'Clinical', 'Collection', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Disease', 'High Performance Computing', 'Human', 'Longevity', 'Performance', 'Research', 'System', 'The Cancer Imaging Archive', 'Universities', 'Washington', 'base', 'biobank', 'bioimaging', 'cognitive development', 'computerized data processing', 'connectome', 'data management', 'data repository', 'deep field survey', 'deep learning', 'image archival system', 'image processing', 'neuro-oncology', 'neuroimaging', 'next generation', 'novel', 'solid state', 'young adult']",OD,WASHINGTON UNIVERSITY,S10,2021,1927344
"Osteoarthritis: Quantitative Evaluation of Whole Joint Disease with MRI Project Summary Osteoarthritis (OA) is an enormous clinical problem and worldwide cause of disability. Development of new therapies for OA is hampered by a lack of sensitive imaging tests that respond to changes in disease status. Recently FDA and CE approved clinical knee 7T MRI has the potential to add sensitivity and specificity to advanced MRI biomarkers of OA progression. This project will compare changes seen at 3T and 7T across two different vendors systems and assess the potential for 7T MRI to improve our ability to study and develop new disease- modifying therapies. This study will enhance future studies and clinical exams at 7T and can be used to improve routine 3T MRI though machine learning reconstruction and enhanced understanding of OA disease mechanisms. Understanding the relative strengths of 3T and 7T MRI in this important clinical application is critical to developing new disease-modifying treatments for patients with OA. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for development of disease-modifying treatments. This work aims to develop novel 3D imaging approaches using 3T and 7T magnetic resonance imaging (MRI), to quantitatively assess joint health across different tissues in osteoarthritis.",Osteoarthritis: Quantitative Evaluation of Whole Joint Disease with MRI,10190939,R01EB002524,"['Address', 'Affect', 'Biochemical', 'Biomechanics', 'Cartilage', 'Chemicals', 'Clinical', 'Degenerative polyarthritis', 'Detection', 'Development', 'Diagnostic Imaging', 'Diagnostic radiologic examination', 'Disease', 'Ensure', 'Environment', 'Evaluation', 'Extracellular Matrix', 'Funding', 'Future', 'GAG Gene', 'Health', 'Human', 'Hydroxyl Radical', 'Image', 'Imaging Techniques', 'Imaging technology', 'Joints', 'Knee', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Meniscus structure of joint', 'Methodology', 'Methods', 'Morphology', 'Musculoskeletal', 'Orthopedics', 'Patients', 'Pharmacologic Substance', 'Population', 'Proteoglycan', 'Quality of life', 'Quantitative Evaluations', 'Replacement Arthroplasty', 'Research', 'Resolution', 'Roentgen Rays', 'Scanning', 'Sensitivity and Specificity', 'Site', 'Specificity', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Treatment Efficacy', 'Vendor', 'Work', 'arthropathies', 'clinical application', 'clinical examination', 'clinical imaging', 'clinically significant', 'cost', 'design', 'disability', 'efficacy evaluation', 'efficacy trial', 'imaging approach', 'imaging detection', 'imaging modality', 'imaging system', 'improved', 'innovation', 'magnetic resonance imaging biomarker', 'mechanical properties', 'molecular marker', 'novel', 'novel therapeutics', 'patient population', 'quantitative imaging', 'rapid technique', 'reconstruction', 'soft tissue', 'tool', 'treatment strategy']",NIBIB,STANFORD UNIVERSITY,R01,2021,611185
"Imaging and Analysis Techniques to Construct a Cell Census Atlas of the Human Brain Admin Supplement Abstract The ~86 billion neurons that form the human brain are organized at multiple scales, ranging from the fine details of an individual neuron’s dendritic arborization, to local circuits that are embedded within large-scale systems spanning the brain. In this project, we will image across this vast range of scales to create a multiscale atlas akin to Google Earth for the human brain that can visualize hemisphere-wide networks and then zoom in to see individual, labeled cells at micron resolution in the frontal temporal lobe. This dramatic advance will be made possible through the use of an array of imaging technologies, including light-sheet microscopy (LSM), tissue clearing, immunohistochemistry (IMH), magnetic resonance imaging (MRI) and newly developed techniques in Optical Coherence Tomography (OCT). OCT in particular is a potentially transformative technology as it provides micron resolution over large volumes of tissue, images all of the tissue (as opposed to fluorescence), does not require mounting and staining and hence can be automated, and is essentially distortion free as it images the tissue prior to cutting. LSM-based IMH will provide molecular, morphological and spatial properties of cells that will enable us to develop cellular classification systems, while OCT images of the same tissue will enable us to remove the distortions induced by cutting and clearing, and transfer information to whole-hemisphere MRI for atlasing and in vivo inference. This transfer of information depends critically on the ability to register images across a huge range of resolutions and contrast types. For this we propose to use the endogenous fiducial landmarks provided by the cerebral vasculature. To take full advantage of the vasculature using deep learning requires a training set of labeled vessels in each of our imaging modalities across an array of examples. The goal of this supplement is to provide these labelings including the assessment of intra- and inter-rater reliability. Relevance Automated segmentation of neurons, glia, cortical areas and laminar boundaries will enable new and more specific types of analyses of neuroimaging data. In particular, the ability to probe cellular and laminar properties of specific cortical areas may provide significant advances in developmental disorders such as Alzheimer’s, autism, schizophrenia and dyslexia. To facilitate these advances we propose to label cerebral vessels, then use the manual labeling to develop a deep learning-based technique to register images from microscopy to whole-hemisphere MRI.",Imaging and Analysis Techniques to Construct a Cell Census Atlas of the Human Brain Admin Supplement,10307352,U01MH117023,"['Alzheimer&apos', 's Disease', 'Area', 'Atlases', 'Brain', 'Cells', 'Censuses', 'Cerebrovascular system', 'Cerebrum', 'Classification', 'Data', 'Dyslexia', 'Fluorescence', 'Goals', 'Human', 'Image', 'Imaging technology', 'Immunohistochemistry', 'Individual', 'Label', 'Light', 'Magnetic Resonance Imaging', 'Manuals', 'Microscopy', 'Molecular', 'Morphology', 'Neuroglia', 'Neurons', 'Optical Coherence Tomography', 'Planet Earth', 'Property', 'Resolution', 'Schizophrenia', 'Stains', 'System', 'Techniques', 'Technology', 'Temporal Lobe', 'Tissue imaging', 'Tissues', 'Training', 'autism spectrum disorder', 'automated segmentation', 'base', 'deep learning', 'developmental disease', 'imaging modality', 'in vivo', 'microscopic imaging', 'neuroimaging']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,U01,2021,99916
"Multi-Site Clinical Data to Power MRI Biomarker of Neonatal Brain Injury Abstract This project aims to release our recently gathered existing clinically-acquired data for neonatal hypoxic ischemic encephalopathy (HIE). HIE affects 1-5/1000 term-born neonates and is a major cause of early-childhood mortality and morbidity. Neonatal brain magnetic resonance imaging (MRI) is acquired routinely for the clinical care of HIE. Neonatal brain MRI is expected to reveal 3D neuroanatomic mechanisms of adverse outcomes so that we can design new treatments specifically target those mechanisms. Neonatal brain MRI also carries hope to identify those neonates who are at risk to develop adverse outcomes later in life, so that early intervention program can target those at-risk neonates for maximum benefit. Despite MRI's vital role in caring for HIE, the current norm in clinical practice is to read MRI visually by expert neuroradiologist or neurologist. Expert reads, however, has many limitations – subjective, qualitative, insufficient to reveal mechanisms, and inadequate to predict outcomes. Objective and quantitative analysis of MRI is possible with the rise of artificial intelligence (AI) in medical and neuroimaging informatics. A major limitation, however, is the lack of publicly-available data on HIE. Our project aims to fill this gap, by archiving and releasing our clinically-acquired, large-scale (N=231), and multi-site (2 hospitals) data on HIE. Our data was acquired partly funded by NIH R01 (2012-2017) and foundations (2016-2020). Our data is comprehensive, including clinical data elements (from both mothers and neonates), neonatal brain MRI (structural and diffusion sequences), expert-consensus annotation of lesion regions in neonatal brain MRI, NICU outcome (death/survival, length of stay), and 2-year-old neurocognitive outcomes (normal/adverse, yes/no for development dealy, yes/no for the hearing/visual/motor impairment, and yes/no for cerebral palsy). Our data is also representative, coming from patients with different racial/ethnicity groups, in patients with a wide range of outcomes, from different MRI scanners (Siemens 3T or GE 1.5T), with different imaging protocols, and MRI scanned on different days of life. We will also derive new data from existing data. The anonymized (de-identified) data will be released to the NCBI dbGaP platform with the “Controlled Access” option, requiring IRB and data use agreement (DUA). The derived data will be released to dbGaP with the “Open Access” option, freely downloadable without any approval. Both release options are consistent with other clinical and MRI data that have already been released on dbGaP. We hope this first comprehensive data will boost future collaborative efforts for AI to automatically identify HIE lesions in MRI, and for AI to accurately predict HIE outcome integrating clinical and MRI information. Project Narrative We aim to publicly release our existing clinically-acquired data for neonatal brain injury caused by hypoxic ischemic encephalopathy (HIE). Our data were retrospectively collected partially funded by NIH R01 (2012-2017) and two other foundational/institutional grant (2016-2020); our data is comprehensive (clinical data from mothers and neonates, neonatal brain MRI with expert-consensus annotations of HIE lesions, and complete set of outcome measures by 2 years of age); our data is representative (MRI scanner, age at MRI, MRI protocol, patient outcomes, patient racial/ethnicity groups); and our data is multi-site (2 hospitals) and large-scale (N=231 compared to proprietary studies with dozens of patients). We plan to use this first public clinical and brain MRI data for HIE to boost artificial intelligence (AI) research for HIE lesion detection and outcome prediction, toward promoting outcomes in this vulnerable neonatal population.",Multi-Site Clinical Data to Power MRI Biomarker of Neonatal Brain Injury,10194889,R03HD104891,"['2 year old', '3-Dimensional', 'Address', 'Affect', 'Age', 'Agreement', 'Alzheimer&apos', 's Disease', 'Archives', 'Artificial Intelligence', 'Atlases', 'Authorization documentation', 'Biological Markers', 'Brain', 'Brain Injuries', 'Brain Neoplasms', 'Caring', 'Cerebral Palsy', 'Cessation of life', 'Child Health', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collection', 'Consensus', 'Consumption', 'Data', 'Data Element', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Early Intervention', 'Ethnic group', 'Foundations', 'Frequencies', 'Funding', 'Future', 'Grant', 'Hearing', 'Hospitals', 'Human Development', 'Image', 'Informatics', 'Injury', 'Institutional Review Boards', 'International', 'Knowledge', 'Length of Stay', 'Lesion', 'Life', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Maps', 'Medical', 'Medical Imaging', 'Metadata', 'Morbidity - disease rate', 'Mothers', 'Motor', 'National Institute of Child Health and Human Development', 'Neonatal', 'Neonatal Brain Injury', 'Neonatal Intensive Care Units', 'Neurocognitive', 'Neurocognitive Deficit', 'Neurologist', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Population', 'Protocols documentation', 'Race', 'Reader', 'Reporting', 'Research', 'Risk', 'Role', 'Sample Size', 'Signal Transduction', 'Site', 'Standardization', 'Structure', 'Study of magnetics', 'Therapeutic', 'Time', 'Treatment outcome', 'United States National Institutes of Health', 'Visual', 'adverse outcome', 'base', 'clinical care', 'clinical practice', 'clinical research site', 'cohort', 'cranium', 'data access', 'data de-identification', 'database of Genotypes and Phenotypes', 'design', 'early childhood', 'improved', 'improved outcome', 'intervention program', 'magnetic resonance imaging biomarker', 'meetings', 'mortality', 'motor impairment', 'natural hypothermia', 'neonatal brain', 'neonatal hypoxic-ischemic brain injury', 'neonatal outcome', 'neonate', 'neuroimaging', 'novel', 'outcome forecast', 'outcome prediction', 'patient registry', 'response', 'sex', 'success', 'symposium', 'targeted treatment', 'visual motor']",NICHD,BOSTON CHILDREN'S HOSPITAL,R03,2021,94911
"Virtual growing child 5-dimensional functional models for treating respiratory anomalies Thoracic Insufficiency Syndrome (TIS) is a group of serious disorders of the pediatric thorax resulting in an inability of the thorax to support respiration or lung growth. TIS is associated with at least 28 pediatric syndromes, with an estimated health care cost per patient that can easily exceed a million dollars. In TIS, three-dimensional deformity of the thoracic components anatomically and functionally reduces the volume available for ventilation. Pediatric specialists dealing with TIS currently face several serious challenges: (a) The complex interplay among dynamic and growing thoracic structures and its influence on thoracic function and growth are not understood at present. (b) The prime outcome measure for the corrective procedures has remained the radiographic Cobb angle of the spine, a 60-year old metric with poor correlation with lung dynamic function and limited true health assessment value. (c) A normative imaging database with functional metrics describing dynamics and growth of the thoracic structures of the normal pediatric population does not exist. Due to these hurdles, innovations in growth-modulating surgical techniques are difficult to achieve. Supported by extensive preliminary results based on dynamic MRI (dMRI) of patients and normal subjects, the overarching goal of this proposal is to develop novel dynamic functional metrics for TIS by establishing a normative database of dMRI images and anatomic and functional models and metrics, and to translate these to develop markers of TIS and of its corrective-surgery outcomes. The project has three aims. Aim 1: To develop a new methodology called The Virtual Growing Child (VGC) consisting of 4 key components: a) To build a normative database of dMRI images prospectively gathered from 200 normal children divided into 10 groups. b) To build population anatomic models involving key thoraco-abdominal objects following an established automatic anatomy recognition (AAR) technology and deep learning (DL) techniques. c) To develop and validate joint AAR-DL algorithms to segment these objects in dMRI images of TIS patients. d) To build a normative database of measurements derived from dMRI images describing normal thoracic architecture, dynamic function, and growth. The database will also include a full battery of Pulmonary Function Testing data and anthropometric measurements. Aim 2: To test retrospectively the utility of the VGC ensemble in deriving markers of TIS and its surgical treatment effects on a cohort of 100 TIS patients. Aim 3: To retrospectively test the utility of the VGC approach for planning surgery in 30 TIS patients by comparing VGC-guided surgical planning to the current planning method. The post-operative key dMRI parameters of patients whose surgical plan would have changed due to VGC data will be compared to those of patients whose plan did not change. Expected outcomes: (i) A unique registry of thoracic dMRI of 200 normal pediatric subjects, segmented objects, and the associated anatomic, dynamic, and developmental parameters. (ii) A validated VGC approach for studying TIS which can also be utilized for studying other pediatric and adult thoracic disorders. Thoracic Insufficiency Syndrome (TIS) is a group of serious disorders of the pediatric thorax. Currently there are no reliable and scientific functional metrics to describe these disorders and their treatment effects. This grant application proposes to build an innovative methodology called the Virtual Growing Child (VGC) based on dynamic MRI of the thorax, construct a comprehensive normative database of MRI images and associated measurements, and utilize the VGC methodology to scientifically characterize TIS and arrive at innovative surgical planning methods.",Virtual growing child 5-dimensional functional models for treating respiratory anomalies,10086887,R01HL150147,"['3-Dimensional', 'Abdomen', 'Address', 'Adult', 'Aftercare', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Applications Grants', 'Architecture', 'Birth', 'Chest', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Databases', 'Deformity', 'Development', 'Diagnostic radiologic examination', 'Dimensions', 'Disease', 'Face', 'Gender', 'Goals', 'Growth', 'Health Care Costs', 'Image', 'Incidence', 'Joints', 'Life', 'Lung', 'MRI Scans', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Names', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedic Procedures', 'Outcome', 'Outcome Measure', 'Patients', 'Population', 'Population Group', 'Postoperative Period', 'Procedures', 'Pulmonary function tests', 'Registries', 'Respiration', 'Rod', 'Scanning', 'Sensitivity and Specificity', 'Specialist', 'Spinal', 'Spinal Fusion', 'Spirometry', 'Structure', 'Syndrome', 'Techniques', 'Technology', 'Testing', 'Thoracic Diseases', 'Tidal Volume', 'Time', 'Translating', 'Vertebral column', 'Vital capacity', 'age group', 'base', 'clinical outcome measures', 'cohort', 'deep learning', 'deep learning algorithm', 'health assessment', 'innovation', 'novel', 'prospective', 'pulmonary function', 'respiratory', 'surgery outcome', 'treatment effect', 'ventilation', 'virtual']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2021,769122
