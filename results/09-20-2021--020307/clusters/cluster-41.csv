text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"MegaPredict for predicting natural product uses and their drug interactions Project Summary The objective of ‘MegaPredict’ is to enable scientists to generate predictions for a natural product (or any molecule) and identify targets for efficacy assessment as well as identify any potential liabilities. We are building on our previous work which has compiled a comprehensive collection of datasets for structure-activity data for a broad variety of disease targets and other properties, in a form ready for model building. All of these models utilize the many sources of curated open data, including ChEMBL, ToxCast etc. We have developed a prototype of MegaPredict that utilizes Bayesian algorithm and ECFP6 fingerprints to output a list of prioritized ‘targets’. We realize that neither the algorithm or the descriptors may be optimal therefore we propose to address this as we validate MegaPredict and develop a product over this proposal. Our team is suitably qualified to develop the software needed and we will leverage our large collaborator network to assist us in validating the activity of compounds. We will initially create a script to take a natural product and score it against many thousands of machine learning models then rank the outputs to propose efficacy targets. We will use over 12,000 ChEMBL derived target-assay / bioactivity groups extracted from the ChEMBL v24 database, as well as EPA Tox21 measurements and other public datasets, using methodology that we have already partially developed. We can repeat this process for over 200 published compounds and access the outputs versus what is known. We intend to compare how the approach performs with synthetic drugs or drug-like compounds as well as natural products. We will assess whether other machine learning algorithms and molecular descriptors can improve predictions. As we generate machine learning models such as Linear Logistic Regression, AdaBoost Decision Tree, Random Forest, Support Vector Machine and deep neural networks (DNN) of varying depth we will assess the predictions for natural products and compare with the Bayesian approach. We will compare ECFP6 with other 2D, 3D descriptors and physicochemical properties in order to identify the optimal combination for generating predictions for natural products and compare how this differs for synthetic compounds. We will validate our predictions for natural product efficacy assessment. We will work closely with multiple academic groups to generate predictions for at least 20 natural products of interest against over 20 different targets or diseases. Our goal will be to identify potential targets that were previously unknown and then generate in vitro data inhouse or with academic collaborators. Develop a prototype user interface for input of a structure, processing an input molecule and output of prioritized targets and liabilities. We have developed multiple software prototypes (e. Assay Central, MegaTox, etc.) previously and will ensure a user-friendly interface and develop new visualization methods and algorithms for prioritizing potential predicted targets based on the outputs of thousands of machine learning models. In Phase I, we will use the software internally with collaborators to rapidly prototype it. In Phase II we will develop a commercial product, and greatly expand our validation by building a larger network of academic and industry partners that would help to prioritize features of most relevance. Using the machine learning models which we have for natural products is limited because ECFP6 fingerprints cannot distinguish between these very different classes of molecules. But this provides us with an opportunity by going for a ""pharmacophore"" style approach (ideally without using 3D conformations directly). We will therefore focus on developing a ‘3D shape-based fingerprint’ or developing a novel ‘2D fingerprint’ that captures the ‘3D shape’ for natural- and druglike molecules. Currently, the public datasets in ChEMBL and PubChem etc. are made up of mostly druglike molecules, but if we have fingerprints that can compare drug-like and natural product-like molecules then we can likely reliably use our MegaPredict models for natural products as well. We can also attempt to rank natural products with our ChEMBL models or we can look through catalogs of druglike compounds using models derived from natural products. That would be an important innovation. Additionally, in Phase II it would be important to see if we could find uses for natural products with any of the 7000 rare diseases. Developing software that predicts potential natural product drug interactions with various targets could be useful to regulatory organizations as well as the pharmaceutical industry and may broaden utility of being able to more effectively mix natural product and druglike compounds in models will have a profound effect on the value of cheminformatics in this arena. Project Narrative Natural products have long been a source of therapeutics for human healthcare. Yet, some of the challenges with developing natural product treatments are identifying potential human disease related targets and avoiding others that might lead to undesirable natural product-drug interactions. Now there is considerable data in the public domain for millions of molecules with thousands of targets and ADME/T related properties that it is possible to use a suite of machine learning models for prospective prediction and profiling of a molecule’s properties from structure alone. We aim to build on our preliminary efforts to date to create a prototype for MegaPredict using various machine learning models which will enable academic and industrial scientists to generate predictions for a natural product or any molecule of interest and identify potential targets for efficacy and toxicity liability assessment. We will experimentally validate these predictions in-house or through our network of collaborators.",MegaPredict for predicting natural product uses and their drug interactions,9846761,R43AT010585,"['3-Dimensional', 'Address', 'Algorithms', 'Bayesian Method', 'Bayesian learning', 'Biological Assay', 'Catalogs', 'Chemical Models', 'Chemistry', 'Collection', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Decision Trees', 'Descriptor', 'Disease', 'Drug Industry', 'Drug Interactions', 'Drug Targeting', 'Ensure', 'Fingerprint', 'G-Protein-Coupled Receptors', 'Goals', 'Healthcare', 'Human', 'Imagery', 'In Vitro', 'Industrialization', 'Lead', 'Literature', 'Logistic Regressions', 'Machine Learning', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Natural Product Drug', 'Natural Products', 'Output', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Phosphotransferases', 'Process', 'Property', 'PubChem', 'Public Domains', 'Publishing', 'Rare Diseases', 'Running', 'Scientist', 'Shapes', 'Software Tools', 'Source', 'Structure', 'Testing', 'Therapeutic', 'Toxic effect', 'Validation', 'Viral', 'Work', 'base', 'cheminformatics', 'commercial application', 'deep neural network', 'drug discovery', 'human disease', 'improved', 'in vivo', 'industry partner', 'innovation', 'interest', 'learning strategy', 'machine learning algorithm', 'model building', 'novel', 'open data', 'pharmacophore', 'predictive modeling', 'predictive tools', 'process repeatability', 'prospective', 'prototype', 'random forest', 'software development', 'statistics', 'symposium', 'synthetic drug', 'tool', 'user-friendly', 'web interface', 'web-based tool']",NCCIH,"COLLABORATIONS PHARMACEUTICALS, INC.",R43,2019,68862,-0.020567816531801533
"Machine learning approaches for improved accuracy and speed in sequence annotation Summary/Abstract Alignment of biological sequences is a key step in understanding their evolution, function, and patterns of activity. Here, we describe Machine Learning approaches to improve both accuracy and speed of highly- sensitive sequence alignment. To improve accuracy, we develop methods to reduce erroneous annotation caused by (1) the existence of low complexity and repetitive sequence and (2) the overextension of alignments of true homologs into unrelated sequence. We describe approaches based on both hidden Markov models and Artificial Neural Networks to dramatically reduce these sorts of sequence annotation error. We also address the issue of annotation speed, with development of a custom Deep Learning architecture designed to very quickly filter away large portions of candidate sequence comparisons prior to the relatively-slow sequence-alignment step. The results of these efforts will be incorporated into forks of the open source sequence alignment tools HMMER, MMSeqs, and (where appropriate) BLAST; we will also work with community developers of annotation pipelines, such as RepeatMasker and IMG/M, to incorporate these approaches. The development and incorporation into these widely used bioinformatics tools will lead to widespread impact on sequence annotation efforts. Narrative Modern molecular biology depends on effective methods for creating sequence alignments quickly and accurately. This proposal describes a plan to develop novel Machine Learning approaches that will dramatically increase the speed of highly-sensitive sequence alignment, and will also address two significant sources of erroneous sequence annotation, (i) the presence of repetitive sequence in biological sequences, and (ii) the tendency for sequence alignment algorithms to extend alignments beyond the boundaries of true homology. The proposed methods represent a mix of applications of hidden Markov models and Artificial Neural Networks, and build on prior success in applying such methods to the problem of sensitive sequence annotation.",Machine learning approaches for improved accuracy and speed in sequence annotation,9887588,R01GM132600,"['Address', 'Algorithms', 'Architecture', 'Bioinformatics', 'Biological', 'Classification', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Custom', 'DNA Transposable Elements', 'Data Set', 'Deletion Mutation', 'Descriptor', 'Development', 'Error Sources', 'Evolution', 'Foundations', 'Genome', 'Genomics', 'Hour', 'Human', 'Human Genome', 'Industry Standard', 'Insertion Mutation', 'Institutes', 'Intervention', 'Joints', 'Label', 'Letters', 'Licensing', 'Machine Learning', 'Manuals', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Molecular Biology', 'Network-based', 'Nucleotides', 'Pattern', 'Pilot Projects', 'Proteins', 'Repetitive Sequence', 'Sequence Alignment', 'Sequence Analysis', 'Source', 'Speed', 'Statistical Models', 'Takifugu', 'Work', 'annotation  system', 'artificial neural network', 'base', 'bioinformatics tool', 'computing resources', 'convolutional neural network', 'deep learning', 'density', 'design', 'genomic data', 'improved', 'markov model', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'software development', 'statistics', 'success', 'tool']",NIGMS,UNIVERSITY OF MONTANA,R01,2019,286435,-0.02923790451955877
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,9733308,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2019,388750,0.006199432394427103
"Incorporating molecular network knowledge into predictive data-driven models Modern computational techniques based on machine-learning (ML) and, more recently, deep-learning (DL) are playing a critical role in realizing the precision medicine initiative. However, there is a critical need to systematically combine these powerful data-driven techniques with prior molecular network knowledge to make more accurate predictive models while also satisfactorily explaining their predictions in terms of mechanisms underlying complex traits and diseases. I propose to use domain specific knowledge from biology and computing to tackle three outstanding problems: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? ​Network-constrained Deep Learning for Metadata Imputation: ​​Most multifactorial phenotypes are tissue dependent and manifest differently depending on age, sex, and ethnicity. However, a majority of publicly-available genomic data lack these labels. I will develop a network-guided approach to predict missing metadata of samples based on their expression profiles by designing novel data-driven models where the model architecture and/or structure of the input data are constrained by an underlying gene network. ​Network-guided Functional Analysis of Genomic Data: ​​High-throughput experiments often generate lists of genes of interest that are hard to interpret. Functional enrichment analysis (FEA) is a powerful tool that attaches functional meaning to an experimental set of genes by summarizing them into sets of pathways/processes. However, standard FEA analysis is limited by incomplete knowledge of gene function, lack of context of the underlying gene network, and noise in expression data. I will address these limitations by developing a network-guided approach that jointly captures genes, their interactions, and their known biological pathways/processes into a common, low-dimensional space that facilitates deriving biological meaning by comparing the distance between the experimental gene set and the pathway/process of interest. ​Joint Multi-Species Genomic Data Analysis and Knowledge Transfer: ​​In particular, finding the optimal model system to use in a follow-up study based on genetic signatures derived from human experiments is challenging because genetic networks can be quite different from species to species. I propose to use data-driven models to embed heterogeneous networks comprised of human genes and model species genes into a common, low-dimensional space to better compare genetic signatures between two (or even multiple) species. I will apply these methods to three specific tasks, but I emphasize that the results of this study will be transferable to any other biological problem where complex gene/protein interactions are a major component. I have surrounded myself with a great support team and developed a strong professional development plan. The freedom and support provided by the F32 fellowship will be instrumental in achieving my goal of becoming a professor with an independent research group. This proposal aims to develop novel computational approaches that systematically combine prior molecular network knowledge, powerful data-driven computational techniques, and large transcriptome data collections to answer three critical questions in biomedicine: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? The core goal of my fellowship is to achieve this by infusing prior-knowledge into state-of-the-art data-driven statistical/machine learning methods so that we can overcome two major hurdles in studying complex, multifactorial traits and diseases: a) complex genetic interactions underlie multi-factorial traits and diseases, and b) these traits and diseases often differ in how they manifest from patient to patient.",Incorporating molecular network knowledge into predictive data-driven models,9835005,F32GM134595,"['Accounting', 'Address', 'Age', 'Architecture', 'Back', 'Binding', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Cell physiology', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Collection', 'Development Plans', 'Dimensions', 'Disease', 'Engineering', 'Ethnic Origin', 'Expression Profiling', 'Fellowship', 'Follow-Up Studies', 'Freedom', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Human', 'Joints', 'Knowledge', 'Label', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Nature', 'Noise', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Process', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Source', 'Structure', 'Techniques', 'Tissues', 'Translating', 'base', 'data to knowledge', 'deep learning', 'design', 'disease phenotype', 'driving force', 'experimental study', 'functional genomics', 'gene function', 'genetic association', 'genetic signature', 'genomic data', 'genomic profiles', 'human data', 'human model', 'interest', 'learning strategy', 'mathematical sciences', 'novel', 'predictive modeling', 'professor', 'sex', 'tool', 'trait', 'transcriptome']",NIGMS,MICHIGAN STATE UNIVERSITY,F32,2019,61610,-0.00950025913806063
"Reproducible Analytics for Secondary Analyses of ImmPort Vaccination-Related Cytometry Data Project Summary The immunology database and analysis portal (ImmPort, http://immport.niaid.nih.gov) is the NIAID-funded public resource for data archive and dissemination from clinical trials and mechanistic research projects. Among the current 291 studies archived in ImmPort, 114 are focused on vaccine responses (91 for influenza vaccine responses), which is the largest category when organized by research focus. As the most effective method of preventing infectious diseases, development of the next-generation vaccines is faced with the bottleneck that traditional empirical design becomes ineffective to stimulate human protective immunity against HIV, RSV, CMV, and other recent major public health threats. This project will focus on three important aspects of informatics approaches to secondary analysis of ImmPort data for influenza vaccination research: a) expanding the data analytical capabilities of ImmPort and ImmPortGalaxy through adding innovative computational methods for user-friendly unsupervised identification of cell populations, b) processing and analyzing a subset of the existing human influenza vaccination study data in ImmPort to identify cell-based biomarkers using the new computational methods, and c) returning data analysis results with data analytical provenance to ImmPort for dissemination of derived data, software tools, as well as semantic assertions of the identified biomarkers. Each aspect is one specific research aim in the proposed work. The project outcome will not only demonstrate the utility of the ImmPort data archive but also generate a foundation for the Human Vaccine Project (HVP) to establish pilot programs for influenza vaccine research, which currently include Vanderbilt University Medical Center; University of California San Diego (UCSD); Scripps Research Institute; La Jolla Institute of Allergy and Immunology; and J. Craig Venter Institute (JCVI). Once such computational analytical workflow is established, it can be applied to the secondary analysis of other ImmPort studies as well as to support the user-driven analytics of their own cytometry data. Each of the specific aims contains innovative methods or new applications of the existing methods. The computational method for population identification in Aim 1 is a newly developed constrained data clustering method, which combines advantages of unsupervised and supervised learning. Cutting-edge machine learning approaches including random forest will be used in Aim 2 for the identification of biomarkers across study cohorts, in addition to the traditional statistical hypothesis testing. Standardized knowledge representation to be developed in Aim 3 for cell-based biomarkers is also innovative, as semantic networks with inferring and deriving capabilities can be built based on the machine-readable knowledge assertions. The proposed work, when accomplished, will foster broader collaboration between ImmPort and the existing vaccine research consortia. It will also accelerate the deployment of up-to-date informatics software tools on ImmPortGalaxy. Project Narrative Flow cytometry (FCM) plays important roles in human influenza vaccination studies through interrogating immune cellular functions and quantifying the immune responses in different conditions. This project will extend the current data analytical capabilities of the Immunology Database and Analysis Portal (ImmPort) through adding novel data analytical methods and software tools for user-friendly identification of cell populations from FCM data in ImmPort influenza vaccine response studies. The derived data and the knowledge generated from the secondary analysis of the ImmPort vaccination study data will be deposited back to ImmPort and shared with the Human Vaccines Project (HVP) consortium for dissemination.",Reproducible Analytics for Secondary Analyses of ImmPort Vaccination-Related Cytometry Data,9724345,UH2AI132342,"['Academic Medical Centers', 'Address', 'Archives', 'Back', 'Biological Markers', 'California', 'Categories', 'Cells', 'Characteristics', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer Analysis', 'Computing Methodologies', 'Cytomegalovirus', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Databases', 'Deposition', 'Development', 'Disease', 'Failure', 'Flow Cytometry', 'Fostering', 'Foundations', 'Funding', 'Genetic Transcription', 'HIV', 'Human', 'Hypersensitivity', 'Imagery', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunology', 'Incidence', 'Influenza', 'Influenza vaccination', 'Informatics', 'Institutes', 'Knowledge', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Maps', 'Measles', 'Medical', 'Meta-Analysis', 'Metadata', 'Methods', 'Mumps', 'Names', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Play', 'Poliomyelitis', 'Population', 'Population Statistics', 'Prevalence', 'Prevention strategy', 'Process', 'Public Health', 'Readability', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Institute', 'Research Project Grants', 'Respiratory Syncytial Virus Vaccines', 'Respiratory syncytial virus', 'Role', 'Secondary to', 'Semantics', 'Smallpox', 'Software Tools', 'Source', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Universities', 'Vaccination', 'Vaccine Design', 'Vaccine Research', 'Vaccines', 'Work', 'analytical method', 'base', 'biomarker discovery', 'biomarker identification', 'catalyst', 'cohort', 'comparative', 'computer infrastructure', 'computerized tools', 'data archive', 'data mining', 'data portal', 'data resource', 'design', 'experience', 'experimental study', 'immune function', 'improved', 'influenza virus vaccine', 'information organization', 'innovation', 'neoplastic', 'news', 'novel', 'novel strategies', 'novel vaccines', 'prevent', 'programs', 'public-private partnership', 'random forest', 'response', 'response biomarker', 'secondary analysis', 'statistics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'user-friendly', 'vaccine development', 'vaccine response', 'vaccine trial', 'vaccine-induced immunity']",NIAID,"J. CRAIG VENTER INSTITUTE, INC.",UH2,2019,292500,-0.01343498468642556
"Development of a novel photocatalytic system for direct deoxyfunctionalization of alcohols involving machine learning Project Summary Development of general and efficient methods for functionalization of alcohols is highly warranted due to the ubiquity and prominence of this functional group in natural products. Such methods would allow for late-stage diversification of complex molecules and, consequently, could have a broad impact in natural product synthesis and preparation of relevant pharmaceutical materials. However, owing to the chemical inertness of alcohols, most methods typically require installation of activating groups for functionalization, making them unattractive from an atom- and step-economical perspective. Nonetheless, many advances have been made. In particular, the Barton-McCombie reaction has become an indispensable tool for reductive functionalization of alcohols. Unfortunately, this transformation requires pre- functionalization of the alcohol substrate, employs highly toxic tin reagents, and invokes the use high reaction temperatures or harmful UV light for initiation of radical intermediates. Furthermore, the overall transformation is limited to H-atom incorporation or reductive coupling with alkenes. Lastly, only a few deoxygenation methods exist that are amenable for late-stage and site-selective deoxygenation in complex systems. Moreover, physical organic chemistry tools available to facilitate the selection of a set of conditions or parameters to afford site-selectivity are limited. In this proposal, we will develop a mild and practical photocatalytic deoxygenation of alcohols. Our strategy will focus on solving the inherent limitation of the Barton McCombie reaction by 1) avoiding the use of toxic tin reagents, 2) obviating the need for pre-functionalization of the alcohol substrate, and 3) allowing for modular coupling of formed alkyl radicals via Ni-catalysis. Specific aim 1 explores the development of a novel photoredox-catalyzed deoxygenation of alcohols. In addition, we outline a general protocol for deoxyfunctionalization of alcohols via inception of the alkyl radical intermediate, formed via β-scission, with various radical electrophiles. Moreover, we highlight an innovative method for the direct cross-coupling of alcohols via metallophotoredox catalysis in both racemic and enantioselective fashion. Specific aim 2 addresses the design strategy for implementing physical chemistry techniques such as Machine Learning in order to facilitate optimization and prediction of reaction performance in multi-dimensional chemical space. Also, we outline applying this strategy to identify a set of optimal conditions to confer site-selective functionalization in complex polyols. Project Narrative Mild and site-controlled deoxygenation of alcohols could significantly accelerate the late-stage synthesis/diversification of important organic molecules; however, current methods often employ toxic tin reagents, harsh reaction conditions, and require prefunctionalization of the alcohols employed. The strategy proposed would allow for a mild photocatalytic deoxygenation, as well as deoxyfunctionalization, of alcohols that solves the aforementioned limitations of prior art. Moreover, the proposed strategy outlines implementation of physical organic chemistry tools Machine Learning in order to facilitate optimization and prediction of reaction performance in multi-dimensional chemical space.",Development of a novel photocatalytic system for direct deoxyfunctionalization of alcohols involving machine learning,9759306,F32GM129910,"['Address', 'Alcohol consumption', 'Alcohols', 'Alkenes', 'Arts', 'Catalysis', 'Chemicals', 'Complex', 'Coupling', 'Development', 'Employment', 'Intercept', 'Machine Learning', 'Methods', 'Natural Products', 'Organic Chemistry', 'Organic Synthesis', 'Performance', 'Pharmacologic Substance', 'Phosphines', 'Physical Chemistry', 'Preparation', 'Protocols documentation', 'Reaction', 'Reagent', 'Site', 'System', 'Techniques', 'Temperature', 'Tin', 'Ultraviolet Rays', 'Visible Radiation', 'alcohol involvement', 'catalyst', 'design', 'functional group', 'innovation', 'novel', 'polyol', 'predictive tools', 'tool']",NIGMS,PRINCETON UNIVERSITY,F32,2019,61226,-0.03443947027676879
"Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data Big data is now ubiquitous in every field of modern scientific research. Many contemporary applications, such as the recent national microbiome initiative (NMI), greatly demand highly flexible statistical machine learning methods that can produce both interpretable and reproducible results. Thus, it is of paramount importance to identify crucial causal factors that are responsible for the response from a large number of available covariates, which can be statistically formulated as the false discovery rate (FDR) control in general high-dimensional nonlinear models. Despite the enormous applications of shotgun metagenomic studies, most existing investigations concentrate on the study of bacterial organisms. However, viruses and virus-host interactions play important roles in controlling the functions of the microbial communities. In addition, viruses have been shown to be associated with complex diseases. Yet, investigations into the roles of viruses in human diseases are significantly underdeveloped. The objective of this proposal is to develop mathematically rigorous and computationally efficient approaches to deal with highly complex big data and the applications of these approaches to solve fundamental and important biological and biomedical problems. There are four interrelated aims. In Aim 1, we will theoretically investigate the power of the recently proposed model-free knockoffs (MFK) procedure, which has been theoretically justified to control FDR in arbitrary models and arbitrary dimensions. We will also theoretically justify the robustness of MFK with respect to the misspecification of covariate distribution. These studies will lay the foundations for our developments in other aims. In Aim 2, we will develop deep learning approaches to predict viral contigs with higher accuracy, integrate our new algorithm with MFK to achieve FDR control for virus motif discovery, and investigate the power and robustness of our new procedure. In Aim 3, we will take into account the virus-host motif interactions and adapt our algorithms and theories in Aim 2 for predicting virus-host infectious interaction status. In Aim 4, we will apply the developed methods from the first three aims to analyze the shotgun metagenomics data sets in ExperimentHub to identify viruses and virus-host interactions associated with several diseases at some target FDR level. Both the algorithms and results will be disseminated through the web. The results from this study will be important for metagenomics studies under a variety of environments. Big data is ubiquitous in biological research. Identifying causal factors associated with complex diseases or traits from big data is highly important and challenging. New statistical and computational tools will be developed to control False Discovery Rate (FDR) for molecular sequence data based on the novel model-free knockoffs framework. They will be used to detect sequence motifs for viruses and motif-pairs for virus-host interactions, and to analyze multiple metagenomics data sets related to complex diseases.",Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data,9753295,R01GM131407,"['Address', 'Algorithms', 'Archaea', 'Attention', 'Bacteria', 'Big Data', 'Biological', 'Bypass', 'Cells', 'Colorectal Cancer', 'Complex', 'Computer software', 'Consult', 'Coupled', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Effectiveness', 'Environment', 'Foundations', 'Frequencies', 'Gaussian model', 'Genes', 'Genetic Materials', 'Genomics', 'Healthcare', 'Human', 'Internet', 'Investigation', 'Joints', 'Length', 'Linear Regressions', 'Literature', 'Liver Cirrhosis', 'Machine Learning', 'Marines', 'Mathematics', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Sequence Data', 'Mutation', 'Neurosciences', 'Non-Insulin-Dependent Diabetes Mellitus', 'Non-linear Models', 'Obesity', 'Organism', 'Performance', 'Planet Earth', 'Play', 'Procedures', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Sampling Studies', 'Shotguns', 'Social Sciences', 'Testing', 'Theoretical Studies', 'Tissues', 'Training', 'Viral', 'Virus', 'Visualization software', 'Work', 'base', 'biological research', 'computerized tools', 'contig', 'dark matter', 'deep learning', 'deep learning algorithm', 'design', 'flexibility', 'high dimensionality', 'human disease', 'human tissue', 'improved', 'interest', 'learning strategy', 'metagenomic sequencing', 'microbial community', 'microbiome', 'microbiome research', 'model design', 'model development', 'new technology', 'novel', 'power analysis', 'response', 'simulation', 'theories', 'trait', 'user-friendly', 'virus host interaction', 'virus identification']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,279949,0.0020086665593188288
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9772541,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structural Models', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,264255,-0.016037481156380606
"Multiscale ab initio QM/MM and machine learning methods for accelerated free energy simulations Q-Chem is a state-of-the-art commercial computational quantum chemistry program that has aided about 60,000 users in their modeling of molecular processes in a wide range of disciplines, including biology, chemistry, and materials science. In this proposal, we seek to significantly reduce the computational time (now around 500,000 CPU hours) required to obtain accurate free energy profiles of enzymatic reactions. Specifically, we propose to use a multiple time step (MTS) simulation method, where a low-level (and less accurate) quantum chemistry method is used to propagate the system (i.e. move all atoms) at each time step (usually 0.5 or 1 fs), and then a high-level (i.e. more accurate and expensive) quantum chemistry method is used to correct the force on the atoms at longer time intervals. In this way, the simulation can be performed at the high-level energy surface in a fraction of time, compared with simulations performed only using the high-level quantum chemical method. In the Phase I proposal, our goal is to allow the high-level force update only once every 40—50 fs by identifying appropriate lower-level theories (Aim 1) and incorporating machine-learning techniques (Aim 2). This will accelerate accurate free energy simulations by 20—25 fold, reducing the overall computer time to around 25,000 CPU hours. Thus, our new MTS simulation method will make it feasible to routinely perform computational studies on enzymatic reaction mechanism. The addition of these new tools will also further strengthen Q-Chem's position as a global leader in the molecular modeling software market, making our program the most efficient and reliable computational quantum chemistry package for simulating large, complex chemical/biological systems. In this project, we seek to significantly reduce the computational time (ca. 500,000 CPU hours) required to obtain accurate free energy profiles of enzymatic reactions to ca. 25,000 CPU Hours. Building upon sophisticated quantum mechanics, this can lead to reliable and quick predictions of enzyme activities.",Multiscale ab initio QM/MM and machine learning methods for accelerated free energy simulations,9778517,R43GM133270,"['Acceleration', 'Accounting', 'Adopted', 'Back', 'Biochemical', 'Biochemical Reaction', 'Biology', 'Biomedical Research', 'Chemicals', 'Chemistry', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Computers', 'Development', 'Discipline', 'Enzymes', 'Foundations', 'Free Energy', 'Goals', 'Hour', 'Hybrids', 'Lead', 'Machine Learning', 'Maps', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Pathway interactions', 'Performance', 'Phase', 'Positioning Attribute', 'Potential Energy', 'Process', 'Protein Conformation', 'Proteins', 'Quantum Mechanics', 'Reaction', 'Recipe', 'Research', 'Research Personnel', 'Sampling', 'Scheme', 'Solvents', 'Surface', 'System', 'Techniques', 'Time', 'Update', 'biological systems', 'computer studies', 'cost', 'density', 'enzyme activity', 'enzyme model', 'improved', 'innovation', 'learning strategy', 'materials science', 'molecular mechanics', 'molecular modeling', 'programs', 'quantum', 'quantum chemistry', 'quantum computing', 'simulation', 'theories', 'time interval', 'tool']",NIGMS,"Q-CHEM, INC.",R43,2019,132011,0.0075339792926001296
"Computational Techniques for Advancing Untargeted Metabolomics Analysis PROJECT SUMMARY/ABSTRACT Detecting and quantifying products of cellular metabolism using mass spectrometry (MS) has already shown great promise in biomarker discovery, nutritional analysis and other biomedical research fields. Despite recent advances in analysis techniques, our ability to interpret MS measurements remains limited. The biggest challenge in metabolomics is annotation, where measured compounds are assigned chemical identities. The annotation rates of current computational tools are low. For several surveyed metabolomics studies, less than 20% of all compounds are annotated. Another contributing factor to low annotation rates is the lack of systematic ways of designing a candidate set, a listing of putative chemical identities that can be used during annotation. Relying on exiting databases is problematic as considering the large combinatorial space of molecular arrangements, there are many biologically relevant compounds not catalogued in databases or documented in the literature. A secondary yet important challenge is interpreting the measurements to understand the metabolic activity of the sample under study. Current techniques are limited in utilizing complex information about the sample to elucidate metabolic activity. The goal of this project is to develop computational techniques to advance the interpretation of large-scale metabolomics measurements. To address current challenges, we propose to pursue three Aims: (1) Engineering candidate sets that enhance biological discovery. (2) Developing new techniques for annotation including using deep learning and incremental build out methods to recommend novel chemical structures that best explain the measurements. (3) Constructing probabilistic models to analyze metabolic activity. Each technique will be rigorously validated computationally and experimentally using chemical standards. Two detailed case studies on the intestinal microbiota will allow us to further validate our tools. Microbiota-derived metabolites have been detected in circulation and shown to engage host cellular pathways in organs and tissues beyond the digestive system. Identifying these metabolites is thus critical for understanding the metabolic function of the microbiota and elucidating their mechanisms. The complex test cases will challenge our techniques, provide feedback during development, and allow us to further disseminate our techniques. We will work closely with early adopters of our tools, as proposed in supporting letters, to further validate our tools and encourage wide adoption. All proposed tools will be open source and made accessible through the web. Our tools promise to change current practices in interpreting metabolomics data beyond what is currently possible with databases, current annotation tools, statistical and overrepresentation analysis, or combinations thereof. The use of machine learning and large data sets as proposed herein defines the most promising research direction in metabolomics analysis. PROJECT NARRATIVE  Untargeted Metabolomics is a recently developed technique that allows the measurement of thousands of molecules in a biological sample. This work proposes several novel computational techniques that address limitations of current metabolomics analysis tools. We anticipate that this work will advance discoveries in biomedical research and have direct benefits to human health.",Computational Techniques for Advancing Untargeted Metabolomics Analysis,9886611,R01GM132391,"['Address', 'Adoption', 'Biological', 'Biomedical Research', 'Blood Circulation', 'Case Study', 'Chemical Structure', 'Chemicals', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Engineering', 'Ensure', 'Feedback', 'Goals', 'Health', 'Human', 'Internet', 'Intestines', 'Label', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Medical', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Nutritional', 'Organ', 'Pathway interactions', 'Performance', 'Play', 'Probability', 'Property', 'PubChem', 'PubMed', 'Public Domains', 'Research', 'Research Personnel', 'Role', 'Running', 'Sampling', 'Statistical Models', 'Structure', 'Subject Headings', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Uncertainty', 'Validation', 'Work', 'annotation  system', 'base', 'biomarker discovery', 'chemical standard', 'combinatorial', 'computerized tools', 'cost', 'dark matter', 'deep learning', 'design', 'drug development', 'drug discovery', 'experimental study', 'gastrointestinal system', 'gut microbiota', 'interest', 'metabolome', 'metabolomics', 'microbiota', 'microbiota metabolites', 'neural network', 'novel', 'nutrition', 'open source', 'physical property', 'small molecule', 'tool']",NIGMS,TUFTS UNIVERSITY MEDFORD,R01,2019,379614,-0.014710457854306224
"Bayesian Machine Learning Tools for Analyzing Microbiome Dynamics The human microbiota plays an important role in health and disease, and its therapeutic manipulation is being actively investigated for a wide range of diseases that span every NIH institute. Our microbiota are inherently dynamic, and analyzing these time-dependent properties is key to robustly linking the microbiota to disease, and predicting the effects of therapies targeting the microbiota; indeed, longitudinal microbiome data is being acquired with increasing frequency, and is a major component of many NIH-funded projects. However, there is currently a dearth of computational tools for analyzing microbiome time-series data, which presents several special challenges including high measurement noise, irregular and sparse temporal sampling, and complex dependencies between variables. The objective of this proposal is to introduce new capabilities, improve on, and provide state-of-the-art implementations of tools for analyzing dynamics, or patterns of change in microbiome time-series data. The tools we develop will use Bayesian machine learning methods, which are well-recognized for their strong conceptual and practical advantages, particularly in biomedical domains. Tools will be rigorously tested and validated on synthetic and real human microbiome data, including publicly available datasets and those from collaborators providing 16S rRNA sequencing, metagenomic, and metabolomics data. We propose three specific aims. For Aim 1, we will develop integrated Bayesian machine learning tools for predicting population dynamics of the microbiome and its responses to perturbations. These tools will include a new model that simultaneously learns groups of microbes with similar interaction structure and predicts their behavior over time, and that incorporates prior phylogenetic information. The model will be further improved by incorporating stochastic microbial dynamics and errors in measurements throughout the model. For Aim 2, we will develop Bayesian machine learning tools to predict host status from microbiome dynamics. The tools will learn easily interpretable, human-readable rules that predict host status from microbiome time-series data, and will be further extended to handle a variety of longitudinal study designs. For Aim 3, we will engineer our microbiome dynamics analysis software tools for optimal performance, ease-of- use, maintainability, extensibility, and dissemination to the community. In total, the proposed work will yield a suite of contemporary software tools for analyzing microbiome dynamics, with expected broad use and major impact. The software will allow investigators to answer important scientific and translational questions about the microbiome, including discovering which microbial taxa or their metagenomes are affected over time by perturbations such as changes in diet or invasion by pathogens; predicting the effects of these perturbations over time, including changes in composition or stability of the gut microbiota; and finding temporal signatures in multi-‘omic microbiome data that predict disease risk in the human host. The human microbiota, or collection of micro-organisms living on and within us, plays an important role in health, and when disrupted or abnormal, may contribute to many types of diseases including infections, kidney diseases, bowel diseases, diabetes, heart diseases, arthritis, allergies, brain diseases, and cancer. Sophisticated computer-based tools are needed to make sense of human microbiota data, particularly time- series data, which can yield important insights into how our microbiomes change over time. This work will develop new and improved computer-based tools for analyzing microbiota time-series data, which will be made freely available and will enable scientists to increase our fundamental knowledge about how our microbiota affect us and ultimately to apply this knowledge to prevent and treat human illnesses.",Bayesian Machine Learning Tools for Analyzing Microbiome Dynamics,9787546,R01GM130777,"['16S ribosomal RNA sequencing', 'Affect', 'Algorithms', 'Antibiotics', 'Arthritis', 'Autoimmunity', 'Bayesian learning', 'Behavior', 'Biological Markers', 'Biological Models', 'Brain Diseases', 'Cardiovascular Diseases', 'Childhood', 'Clostridium difficile', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Set', 'Dependence', 'Diabetes Mellitus', 'Diet', 'Disease', 'Engineering', 'Environmental Exposure', 'Frequencies', 'Funding', 'Health', 'Heart Diseases', 'Human', 'Human Microbiome', 'Hypersensitivity', 'Infection', 'Institutes', 'Intervention', 'Intestines', 'Investigation', 'Kidney Diseases', 'Knowledge', 'Learning', 'Link', 'Longitudinal Studies', 'Malignant Neoplasms', 'Measurement', 'Medical', 'Metagenomics', 'Microbe', 'Modeling', 'Names', 'Noise', 'Oligosaccharides', 'Outcome', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Play', 'Population Dynamics', 'Property', 'Pythons', 'Readability', 'Recurrence', 'Research Design', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Series', 'Shotguns', 'Software Engineering', 'Software Tools', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Work', 'base', 'computerized tools', 'design', 'disorder risk', 'dynamic system', 'gut microbiota', 'human data', 'human microbiota', 'human subject', 'improved', 'insight', 'learning algorithm', 'learning strategy', 'man', 'metabolomics', 'metagenome', 'microbial', 'microbiome', 'microbiome analysis', 'microbiome sequencing', 'microbiota', 'microorganism', 'nervous system disorder', 'novel', 'open source', 'pathogen', 'predictive tools', 'prevent', 'response', 'software development', 'targeted treatment', 'tool']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R01,2019,312939,0.015329395905026993
"Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach Project Summary Biology is full of stunning examples of emergent behaviors – behaviors that arise from, but cannot be reduced to, the interactions of the constituent parts that make up the system under consideration. These behaviors span the full spectrum of length scales, from the emergence of distinct cell fates (e.g. neurons, muscle, etc.) due to the interactions of genes within cells, to the formation of complex ecological communities arising from the interactions of thousands of species. The overarching goal of my research is to develop new conceptual, theoretical, and computational tools to model such emergent, system-level behaviors in biology. To do so, we utilize an interdisciplinary approach that is grounded in Biological Physics, but draws heavily from Machine Learning, Information Theory, and Theoretical Ecology. Our work is unified and distinguished by our deep commitment to integrating theory with the vast amount of biological data now being generated by modern DNA sequencing-based techniques and quantitative microscopy. An important goal of the proposed research is to find common concepts and tools that transcend traditional biological sub-disciplines and models systems. The proposed research pursues four distinct but conceptually interrelated research directions: (1) understanding how distinct cell fates emerge from bimolecular interactions within mammalian cells (2) investigating how bimolecular networks within cells exploit energy consumption to improve computations, with applications to Synthetic Biology; (3) identifying the ecological principles governing community assembly in microbial communities and developing techniques for synthetically engineering ecological communities; and (4) developing new machine learning algorithms and techniques for biological data analysis. In addition to developing physics-based models for diverse biological phenomena, the proposed research will yield a series of practical important tools and algorithms which we will make publically available including: (1) a new linear-algebra based algorithm for assessing the fidelity of directed differentiation and cellular reprogramming protocols and visualizing reprogramming/differentiation dynamics and (2) improved algorithms for inferring microbial interactions in the human microbiome from high-throughput sequence data. These computational tools will allow scientists to realize the immense therapeutic potential of cellular reprogramming and microbial ecology-based techniques for studying and treating human disease. Project Narrative This project will develop new theoretical and computational tools that will allow scientists to realize the immense therapeutic potential of cellular reprogramming (the conversion of one cell type into another cell type) and microbial ecology-based techniques for studying and treating human diseases.",Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach,9745646,R35GM119461,"['Algorithms', 'Behavior', 'Biological', 'Biological Models', 'Biological Phenomena', 'Biology', 'Cells', 'Communities', 'Complex', 'Consumption', 'DNA sequencing', 'Data', 'Data Analyses', 'Discipline', 'Ecology', 'Engineering', 'Goals', 'Human Microbiome', 'Information Theory', 'Length', 'Linear Algebra', 'Machine Learning', 'Mammalian Cell', 'Modeling', 'Modernization', 'Muscle', 'Neurons', 'Physics', 'Protocols documentation', 'Quantitative Microscopy', 'Research', 'Scientist', 'Series', 'System', 'Systems Biology', 'Techniques', 'Therapeutic', 'Transcend', 'Work', 'base', 'cell type', 'computerized tools', 'gene interaction', 'human disease', 'improved', 'interdisciplinary approach', 'machine learning algorithm', 'microbial', 'microbial community', 'microorganism interaction', 'synthetic biology', 'theories', 'tool']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2019,323318,-0.011384054376679578
"Accelerating phage evolution and tools via synthetic biology and machine learning Summary Phages, which are the naturally evolved predators of bacteria, may hold the key to combating bacterial pathogens, including the looming threat of multidrug resistant bacteria. Phages are viruses which while harmless to humans and have been successfully engineered as tools to separate, concentrate, and detect their bacterial hosts. Additionally, phages have been used as therapeutic agents to treat patients infected with pathogens resistant to known antibiotics. While the potential benefits of phages are numerous, certain limitations must be addressed in order to fully employ them. The central hypothesis of this proposal is that both top-down and bottom-up approaches can be utilized to design and synthesize novel phages, through a combination of synthetic biology and machine learning. This will result in phage-based tools with increased functionality and customizable host ranges. The rationale for the proposed research is that as the threat of bacterial infections including those with multi-drug resistance continues to grow, phages, which have evolved to efficiently recognize and kill bacteria, will become indispensable tools. Therefore, the ability to rapidly design and engineer new phages for biosensing and therapeutics will be a critical advantage to human health. The proposal contains three specific aims which are supported by preliminary data and cited literature. Aim 1: Site-directed conjugation for advanced phage-based biosensors and therapeutics. Under this aim, phages will be modified with alkyne-containing unnatural amino acids allowing their direct conjugation to 1) azide decorated magnetic nanoparticles, and 2) azide terminated polyethylene glycol. The modifications will allow the development of magnetic phages for bacteria separation and detection, and phages that are more effective therapeutics due to their ability to avoid a patient’s innate immune response, respectively. Aim 2: Decoding phage biorecognition elements using machine learning. In this aim, machine learning will be used to model the binding of phages and their bacterial hosts. The model will enable the prediction of host interactions as well as allow the design and synthesis of novel phage tail fibers which can target specific bacterial isolates. Aim 3: Repurposing phage biorecognition for a broader host ranges. Under the final aim, phage-binding proteins will be replaced with those known to recognize conserved regions of the bacterial LPS, resulting in a phage with a much broader host range. This approach is innovative because it uses top-down characterizations for bottom-up design and synthesis of novel phages. Traditional phage screening methods will be replaced with the rapid synthesis of phages, which are optimized for a particular bacterial isolate. Following the successful completion of the specific aims, the expected outcome is the design and synthesis of phages that can be used to target a selected group of bacteria within Enterobacteriaceae for advanced biosensing and therapeutics. A publically available computer model will allow rapid design of custom phage biorecognition elements which can be added to functionalized phages. These technologies will allow researchers to tip the scales of the co-evolutionary arms race between phage and bacteria. Narrative The project is relevant to public health because it accelerates the development of phage-based tools for the rapid detection of bacterial pathogens in human, food, and environmental samples, and the treatment of diseases from multidrug resistant bacteria by integrating machine learning and synthetic biology. Thus, it is specifically relevant to part of NIH's mission that pertains to the diagnosis, prevention, and cure of human diseases.",Accelerating phage evolution and tools via synthetic biology and machine learning,9714883,R01EB027895,"['Acinetobacter baumannii', 'Address', 'Alkynes', 'Amino Acid Sequence', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Azides', 'Bacteria', 'Bacterial Genome', 'Bacterial Infections', 'Bacteriophage T4', 'Bacteriophages', 'Binding', 'Binding Proteins', 'Biosensing Techniques', 'Biosensor', 'CRISPR/Cas technology', 'Capsid', 'Chemistry', 'Clinical', 'Computer Simulation', 'Consumption', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Drug resistance', 'Elements', 'Engineering', 'Enterobacteriaceae', 'Environment', 'Escherichia coli', 'Evolution', 'Family', 'Fiber', 'Food', 'Future', 'Genes', 'Genome', 'Goals', 'Health', 'Human', 'Infection', 'Innate Immune Response', 'Innate Immune System', 'Intervention', 'Life', 'Literature', 'Machine Learning', 'Magnetic nanoparticles', 'Magnetism', 'Methods', 'Mission', 'Modeling', 'Modification', 'Multi-Drug Resistance', 'Multidrug-resistant Acinetobacter', 'Multiple Bacterial Drug Resistance', 'Natural Immunity', 'Outcome', 'Patients', 'Phenotype', 'Polyethylene Glycols', 'Prevention', 'Process', 'Property', 'Public Health', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Site', 'Specificity', 'Surface', 'System', 'Tail', 'Technology', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'United States National Institutes of Health', 'Viral', 'Virus', 'arm', 'base', 'combat', 'design', 'human disease', 'innovation', 'next generation', 'novel', 'pathogen', 'pathogenic bacteria', 'rapid detection', 'receptor', 'resistance mechanism', 'screening', 'synthetic biology', 'tool', 'unnatural amino acids']",NIBIB,CORNELL UNIVERSITY,R01,2019,666637,-0.014024871418949031
"Computational Explorations of Unconventional Approaches to Control Noncovalent Interactions PROJECT SUMMARY The research interests of my group are rooted in explorations of new and useful conceptual models to improve the control and prediction of noncovalent interactions. Our research involves the use of a variety of computational quantum chemical tools, applications of density functional theory (DFT), cheminformatics, and machine-learning methods. A premise of our research is that aromaticity may be used to modulate many types of noncovalent interactions (such as hydrogen bonding, π-stacking, anion-π interactions). The reciprocal relationship we find, between “aromaticity” in molecules and the strengths of “noncovalent interactions,” is surprising especially since they are typically considered as largely separate ideas in chemistry. The innovation of this research is that it will enable use of intuitive “back-of-the-envelope” electron-counting rules (such as the 4n+2πe Hückel rule for aromaticity) to make predictions of experimental outcomes regarding the impact of noncovalent interactions. A five-year goal is to realize the use of our conceptual models in real synthetic examples prepared by our experimental collaborators. My research vision is to bridge discoveries of innovative concepts to their practical impacts for biomedical and biomolecular research. PROJECT NARRATIVE This research proposal includes four projects that are jointly motivated by the challenge to control and predict noncovalent interactions in organic and biomolecular systems. The proposed work involves applications of a variety of computational quantum chemical tools and synergistic investigations with experimental collaborators. We seek to identify new and useful concepts to guide experimental designs of novel “non-natural” molecular systems (e.g., receptors, biosensors, and hydrogels) that have potential biomedical applications.",Computational Explorations of Unconventional Approaches to Control Noncovalent Interactions,9798401,R35GM133548,"['Anions', 'Back', 'Biosensor', 'Chemicals', 'Chemistry', 'Electrons', 'Experimental Designs', 'Goals', 'Hydrogels', 'Hydrogen Bonding', 'Intuition', 'Investigation', 'Machine Learning', 'Modeling', 'Molecular', 'Outcome', 'Plant Roots', 'Research', 'Research Project Summaries', 'Research Proposals', 'System', 'Vision', 'Work', 'cheminformatics', 'density', 'improved', 'innovation', 'interest', 'learning strategy', 'novel', 'quantum computing', 'receptor', 'theories', 'tool']",NIGMS,UNIVERSITY OF HOUSTON,R35,2019,377200,0.010728018099676492
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9806367,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2019,184118,-0.006425567258379811
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,9642618,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Effectiveness', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Imagery', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Universities', 'Virginia', 'absorption', 'artificial neural network', 'base', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2019,375602,-0.004678109880344061
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9705993,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'analysis pipeline', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2019,314000,-0.01053293752745621
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9750722,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'predictive modeling', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2019,527585,0.018909860294231837
"Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria Project Summary/Abstract Fungal and bacterial pathogens are a major threat to human health. Few therapeutics exist to treat fungal infections while bacteria are becoming increasingly resistant to existing therapeutics. Humans have been using natural products to treat infections for thousands of years, long before the causal agents of infection were understood. Natural products have continued to be used as therapeutics in the modern age of medicine. Rates of rediscovery of known natural products have increased in traditional sources of natural products, such as soil bacteria. Recently, symbiotic Actinobacteria from insect agricultural systems have been recognized as a promising source of bioactive compounds, especially antifungal agents. These bacteria often produce natural products that defend an insect’s fungal crop from pathogenic fungus. The work proposed here will use chemical biology approaches such as phenotypic interaction screens, genomics, and a new bioinformatics approach to systematically search for bioactive natural products produced by Actinobacteria symbionts and other organisms in insect agricultural systems. The first part of this proposal focuses on using existing techniques to identify new bioactive natural products. Phenotypic interaction screens can identify bioactive natural products by determining if a symbiotic bacteria produces a natural product that inhibits the growth of a fungal pathogen and vice-versa. We will then use genomic sequencing, bioinformatics, and heterologous expression to identify and characterize biosynthetic gene clusters (BGCs) that are not expressed in the phenotypic interaction screens. The second part of the proposed work involves the use of a new bioinformatics technique to identify interesting bioactive natural products. Existing bioinformatics techniques identify BGCs and predict the most likely chemical structure of the corresponding natural product. However, they do not conclude anything concerning the functional role that the natural product plays. The technique developed here will use machine learning to predict the function that the natural product fulfills in the ecological context of the organism. This algorithm will facilitate the identification of bioactive natural products with therapeutically relevant functions. Project Narrative Fungal infections are an underappreciated threat to human health with high mortality rates and few effective therapeutic agents for treatment. Symbiotic Actinobacteria from insect agricultural systems are a promising source of antifungal agents since they often produce natural products with antifungal activity protecting an insect’s fungal crop from pathogenic fungus. The work proposed here will use phenotypic interaction screens, genome sequencing, and the development of a novel bioinformatics method to systematically mine Actinobacteria for antifungal and antibacterial products – leading to the discovery of new bioactive small molecules along with a deeper understanding of how natural products mediate the interaction between species in insect agricultural systems.",Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria,9716392,F32GM128267,"['Actinobacteria class', 'Age', 'Agriculture', 'Algorithms', 'Anti-Bacterial Agents', 'Antibiotics', 'Antifungal Agents', 'Ants', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bioinformatics', 'Biological Assay', 'Biology', 'Breathing', 'Chemical Structure', 'Chemicals', 'Collaborations', 'Computational Biology', 'Computing Methodologies', 'Data Set', 'Development', 'Ecosystem', 'Gene Cluster', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Infection', 'Insecta', 'Learning', 'Life', 'Literature', 'Machine Learning', 'Mediating', 'Medicine', 'Methods', 'Mining', 'Modernization', 'Molecular Structure', 'Mycoses', 'Natural Products', 'Organism', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Public Health', 'Resistance', 'Role', 'Soil', 'Source', 'Structure', 'System', 'Techniques', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'Validation', 'Work', 'base', 'bioactive natural products', 'drug discovery', 'fungus', 'genetic information', 'genome sequencing', 'human disease', 'machine learning algorithm', 'mortality', 'novel', 'pathogen', 'pathogenic bacteria', 'pathogenic fungus', 'post-doctoral training', 'prediction algorithm', 'small molecule', 'symbiont']",NIGMS,HARVARD MEDICAL SCHOOL,F32,2019,61226,0.00023423470145451824
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9654021,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2019,1354555,0.019443859235429715
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9823400,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2019,583885,0.019443859235429715
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design Our Vision: We propose DeepLink, a versatile data translator that integrate multi-scale, heterogeneous, and multi-source biomedical and clinical data. The primary goal of DeepLink is to enable meaningful bidirectional translation between clinical and molecular science by closing the interoperability gap between models and knowledge at different scales. The translator will enhance clinical science with molecular insights from basic and translational research (e.g. genetic variants, protein interactions, pathway functions, and cellular organization), and enable the molecular sciences by connecting biological discoveries with their pathophysiological consequences (e.g. diseases, signs and symptoms, pharmacological effects, physiological systems). Fundamental differences in the language and semantics used to describe the models and knowledge between the clinical and molecular domains results in an interoperability gap. DeepLink will systematically and comprehensively close this gap. We will begin with the latest technology in semantic knowledge graphs to support an extensible architecture for dynamic data federation and knowledge harmonization. We will design a system for multi-scale model integration that is ontology-based and will combine model execution with prior, curated biomedical knowledge. Our design strategy will be iterative and participatory and anchored by 10 major milestones. In a series of demonstrations of DeepLink’s functions, we will address one of the major challenges facing translational science: reproducibility of biomedical research findings that are based on evolving molecular datasets. Reproducibility of analyses and replication of results are central to scientific advancement. Many landmark studies have used data that are constantly being updated, curated, and pared down over time. Our series of demonstrations projects are designed to prototype the technology required for a scalable and robust translator as well as the techniques we will use to close the interoperability gap for a specific use case. The demonstration project will, itself, will be a significant and novel contribution to science. DeepLink will be able to answer questions that are currently enigmatic. Examples include: - From clinicians: What is the comparative effectiveness of all the treatments for disease Y given a patient's genetic/metabolic/proteomic profile? What are the functional variants in cell type X that are associated with differential treatment outcomes? What metabolite perturbations in cell type Y are associated with different subtypes of disease X? - From basic science researchers: What is known about disease Y across all model organisms (even those not designed to model Y)? What are all the clinical phenotypes that result from a change in function in protein X? Which biological pathways are affected by a pathogenic variant of disease Y? What patient data are available to evaluate a molecularlyderived clinical hypothesis? Challenges and Our Approaches: DeepLink will close the interoperability gap that currently prohibits molecular discoveries from leading to clinical innovations. DeepLink will be technologically driven, addressing the challenges associated with large, heterogeneous, semantically ambiguous, continuously changing, partially overlapping, and contextually dependent data by using (1) scalable, distributed, and versioned graph stores; (2) semantic technologies such as ontologies and Linked Data; (3) network analysis quality control methods; (4) machine-learning focused data fusion methods; (5) context-aware text mining, entity recognition and relation extraction; (6) multi-scale knowledge discovery using patient and molecular data; and (7) presentation of actionable knowledge to clinicians and basic scientists via user-friendly interfaces. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9855180,OT3TR002027,"['Address', 'Affect', 'Animal Model', 'Architecture', 'Awareness', 'Basic Science', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Data', 'Data Set', 'Disease', 'Genetic', 'Goals', 'Graph', 'Knowledge', 'Knowledge Discovery', 'Language', 'Link', 'Machine Learning', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Pathogenicity', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacology', 'Physiological', 'Proteins', 'Proteomics', 'Quality Control', 'Reproducibility', 'Research Personnel', 'Science', 'Scientist', 'Semantics', 'Series', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'Treatment outcome', 'Update', 'Variant', 'Vision', 'base', 'cell type', 'clinical phenotype', 'comparative effectiveness', 'design', 'disorder subtype', 'genetic variant', 'innovation', 'insight', 'interoperability', 'molecular domain', 'multi-scale modeling', 'novel', 'prototype', 'text searching', 'user-friendly']",NCATS,COLUMBIA UNIVERSITY HEALTH SCIENCES,OT3,2019,702655,-0.03314015309472689
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9608754,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,356625,-0.017877975374573828
"Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Summary: Viruses are ubiquitous in almost every ecological environment including the human body, water, soil, etc. They play important roles in the normal function of human microbiome. Many viruses have been shown to be associated with human diseases. However, our understanding of the roles of viruses in ecological communities is very limited. Recent technological and computational advances make it possible to have a deep understanding of the roles of viruses in public health and the environment. Metagenomics studies from various environments including the human microbiome projects (HMP), global ocean, and the earth microbiome projects have generated large amounts of short read data. Viruses are present in most of these metagenomic data sets and their hosts are unknown. In this proposal, the investigators will develop computational approaches for the identification of viral sequences from metagenomic data sets and for the study of virus-host interactions. For the identification of viral sequences from metagenomics samples, novel statistical measures using word patterns will first be developed. Second, a unified naïve Bayesian integrative approach by combining information from word patterns, gene directionality, and gene annotation will be studied. Third, the identified viral sequences from metagenomes will be further assembled to construct complete viral genomes using a novel binning approach to be developed by the investigators. Finally, the remaining reads will be assigned to the corresponding bins. For the study of virus- host interactions, computational methods to estimate the reliability of virus-host interactions from high-throughput experiments will first be developed. Then machine learning approaches will be developed to predict viruses infecting certain hosts. Finally, a network logistic regression approach will be developed to predict virus-host interactions. These computational approaches for the identification of viral sequences and for predicting virus-host interactions will be applied to a public liver cirrhosis and a unique metagenomics data set to understand how metagenomes change with health status, identify viruses and virus-host interactions associated with disease status and accurately predict disease status using bacteria, viruses and virus-host interactions. The developed computational methods will also be used to analyze metageomic data from various locations based on the TARA ocean data and a unique time series data to understand how environmental factors affect virus abundance and virus-host interactions. Some of the predictions will be experimentally validated. Software derived from the proposal will be developed and freely distributed to the scientific community. Project Narrative Viruses are abundant in many environments and are important to public health. New statistical and computational tools will be developed for the identification of viral sequences from metagenomics samples and for the prediction of virus-host interactions. These tools will be used to analyze microbial data sets related to liver cirrhosis and travelers’ diarrhea as well as marine metagenomics data sets from various geographic locations and time series.",Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications,9755666,R01GM120624,"['Affect', 'Bacteria', 'Biological', 'Body Water', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Environment', 'Environment and Public Health', 'Environmental Risk Factor', 'Functional disorder', 'Genes', 'Genome', 'Geographic Locations', 'Health', 'Health Status', 'Human', 'Human Microbiome', 'Human body', 'Liver Cirrhosis', 'Location', 'Logistic Regressions', 'Machine Learning', 'Marines', 'Measures', 'Metagenomics', 'Methods', 'Microbe', 'Network-based', 'Oceans', 'Organism', 'Pattern', 'Planet Earth', 'Play', 'Policies', 'Public Health', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Series', 'Soil', 'Technology', 'Time', 'Traveler&apos', 's diarrhea', 'Viral', 'Viral Genome', 'Virus', 'Virus Diseases', 'Visualization software', 'base', 'computer studies', 'computerized tools', 'contig', 'design', 'experimental study', 'gut metagenome', 'human disease', 'interest', 'metagenome', 'microbial', 'microbial community', 'microbiome', 'novel', 'particle', 'statistics', 'tool', 'user-friendly', 'virus host interaction']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,24201,0.02105506451195426
"Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Summary: Viruses are ubiquitous in almost every ecological environment including the human body, water, soil, etc. They play important roles in the normal function of human microbiome. Many viruses have been shown to be associated with human diseases. However, our understanding of the roles of viruses in ecological communities is very limited. Recent technological and computational advances make it possible to have a deep understanding of the roles of viruses in public health and the environment. Metagenomics studies from various environments including the human microbiome projects (HMP), global ocean, and the earth microbiome projects have generated large amounts of short read data. Viruses are present in most of these metagenomic data sets and their hosts are unknown. In this proposal, the investigators will develop computational approaches for the identification of viral sequences from metagenomic data sets and for the study of virus-host interactions. For the identification of viral sequences from metagenomics samples, novel statistical measures using word patterns will first be developed. Second, a unified naïve Bayesian integrative approach by combining information from word patterns, gene directionality, and gene annotation will be studied. Third, the identified viral sequences from metagenomes will be further assembled to construct complete viral genomes using a novel binning approach to be developed by the investigators. Finally, the remaining reads will be assigned to the corresponding bins. For the study of virus- host interactions, computational methods to estimate the reliability of virus-host interactions from high-throughput experiments will first be developed. Then machine learning approaches will be developed to predict viruses infecting certain hosts. Finally, a network logistic regression approach will be developed to predict virus-host interactions. These computational approaches for the identification of viral sequences and for predicting virus-host interactions will be applied to a public liver cirrhosis and a unique metagenomics data set to understand how metagenomes change with health status, identify viruses and virus-host interactions associated with disease status and accurately predict disease status using bacteria, viruses and virus-host interactions. The developed computational methods will also be used to analyze metageomic data from various locations based on the TARA ocean data and a unique time series data to understand how environmental factors affect virus abundance and virus-host interactions. Some of the predictions will be experimentally validated. Software derived from the proposal will be developed and freely distributed to the scientific community. Project Narrative Viruses are abundant in many environments and are important to public health. New statistical and computational tools will be developed for the identification of viral sequences from metagenomics samples and for the prediction of virus-host interactions. These tools will be used to analyze microbial data sets related to liver cirrhosis and travelers’ diarrhea as well as marine metagenomics data sets from various geographic locations and time series.",Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications,9668156,R01GM120624,"['Affect', 'Bacteria', 'Biological', 'Body Water', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Environment', 'Environment and Public Health', 'Environmental Risk Factor', 'Functional disorder', 'Genes', 'Genome', 'Geographic Locations', 'Health', 'Health Status', 'Human', 'Human Microbiome', 'Human body', 'Liver Cirrhosis', 'Location', 'Logistic Regressions', 'Machine Learning', 'Marines', 'Measures', 'Metagenomics', 'Methods', 'Microbe', 'Network-based', 'Oceans', 'Organism', 'Pattern', 'Planet Earth', 'Play', 'Policies', 'Public Health', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Series', 'Soil', 'Technology', 'Time', 'Traveler&apos', 's diarrhea', 'Viral', 'Viral Genome', 'Virus', 'Virus Diseases', 'Visualization software', 'base', 'computer studies', 'computerized tools', 'contig', 'design', 'experimental study', 'gut metagenome', 'human disease', 'interest', 'metagenome', 'microbial', 'microbial community', 'microbiome', 'novel', 'particle', 'statistics', 'tool', 'user-friendly', 'virus host interaction']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,381513,0.02105506451195426
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,9786702,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Infrastructure', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'Standardization', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2019,431816,-0.014942555153853036
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9739188,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Simulation', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in vivo', 'insight', 'intracranial artery', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'multiple omics', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'single photon emission computed tomography', 'spatiotemporal', 'supervised learning', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2019,506426,-0.015410318001293041
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,10012251,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computer Simulation', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2019,141763,0.01469389239847055
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,9769745,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computer Simulation', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2019,998631,0.01469389239847055
"An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography SUMMARY – OVERALL Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function. Although the basic electron cryo-tomography technique has been used for several decades, the technology is being revolutionized by recent advances in sample preparation, electron cryo-microscopy hardware, improved capabilities for automatic data collection, direct electron detection imaging devices, and phase plate technologies. Combined, these advances led to the ability to generate extraordinarily large numbers of cellular cryo-tomograms of exquisite quality. In principle, such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. However, collection of cellular data is now at a far faster rate than can currently be analyzed with existing methods, producing a serious barrier to progress: to match the data production rates of a single laboratory, at least 50 experienced scientists would need to handle the data analysis. The primary goal of this Program Project is to establish quantitative and highly automated tools for the reconstruction and interpretation of highly complex cellular tomographic data. We have assembled a highly synergistic team of PIs with complimentary expertise in cutting-edge computational and experimental electron microscopy techniques to achieve this goal through collaborative efforts. Project 1 (Hanein & Penczek) focuses on development and implementation of tomogram quality assessment and validation techniques and on experimentally guided optimization of data collection strategies. Project 2 focuses on automatic tomographic reconstruction technology, extraction of various features from the tomograms, and the analysis of distribution patterns derived from the extracted features. Project 3 focuses on development of quantitative tools for tomogram annotation through deep learning and sub-tomogram alignment as well as interactive visualization tools. The set of highly automated tools developed in this Program Project will permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study. NARRATIVE Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function and—with recent instrumental advances—it is now possible to image hundreds of cells per months, enabling collection of cellular data at a far faster rate than can currently be analyzed. Such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. This Program Project brings together an accomplished team of investigators to develop new strategies for effectively processing and interpreting this massive influx of data, developing a set of highly automated tools to permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study.",An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography,9769773,P01GM121203,"['Address', 'Algorithms', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biology', 'Cancer Diagnostics', 'Cell physiology', 'Cells', 'Classification', 'Collection', 'Complex', 'Computing Methodologies', 'Cryo-electron tomography', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Electrons', 'Environment', 'Floods', 'Goals', 'Health', 'Heart', 'Human', 'Image', 'Imaging Device', 'Individual', 'Knowledge', 'Laboratories', 'Methodology', 'Methods', 'Molecular', 'Molecular Structure', 'Morphology', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Preparation', 'Process', 'Production', 'Real-Time Systems', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Tomogram', 'Validation', 'Variant', 'Visualization software', 'base', 'computer framework', 'convolutional neural network', 'deep learning', 'electron tomography', 'experience', 'imaging detection', 'improved', 'insight', 'knowledge base', 'learning strategy', 'nanomachine', 'novel diagnostics', 'particle', 'programs', 'reconstruction', 'response', 'software development', 'statistics', 'tomography', 'tool', 'virtual']",NIGMS,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,P01,2019,928444,-0.015563272989212886
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9761970,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'lead optimization', 'learning network', 'multidisciplinary', 'neural network', 'novel', 'off-label use', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2019,1212566,-0.023328805200991107
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9638561,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computational platform', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'human microbiota', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiome research', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2019,364865,0.025021311430388115
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9626416,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Infrastructure', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2019,2000000,-0.02625320684986402
"Simulation of Proton Translocation in Biomolecules PROJECT SUMMARY  The transport of protons in biomolecular systems is a phenomenon of fundamental importance to processes such as ATP synthesis, enzyme catalysis, the maintenance of pH gradients, proton pumping, viral infection, and substrate/ion transport across membranes via protein transporters, symporters, and antiporters. Modeling biomolecular proton translocation in silico is a significant challenge due to the complex chemical reactions involved in Grotthuss proton shutting between water molecules and with protonatable amino acids, as well as the complexity of the target biomolecular systems. In most cases, it is not only important to understand the mechanism of proton binding and transport, but also its coupling to other mechanistically relevant biomolecular processes, such as protein conformational changes, substrate binding, other protonation events, and dynamic hydration.  In this project the continued development and application of a powerful multiscale computer simulation methodology is described for the study of proton transport in several key classes of proton translocating biomolecular systems, including channels (influenza A and B M2 channels), antiporters/symporters (ClC Cl-/H+ antiporter and phosphate transporter, respectively), and transporters (proton-coupled oligopeptide transporter and EmrE multidrug transporter). The overall research plan is made possible by a novel reactive molecular dynamics simulation approach integrated with quantum mechanics/molecular mechanics (QM/MM) methods that allows for the study of explicit long-length and -time scale proton transport through water molecules and ionizable molecular groups in hydrogen-bonded networks, as well as by new innovations in enhanced free energy sampling methodology, machine learning, kinetic network theory, and coarse-graining. A primary goal in the research with this methodology in hand is to reveal the mechanisms of proton transport, as well as its coupling to hydration and conformational changes, in the above mentioned biomolecular systems. All of these studies will be carried out in collaboration with leading experimentalists, while continuing to add a new dimension to the field of biomolecular computer simulation as a whole. 1 PROJECT NARRATIVE  In this project, computer simulations will be used to study proton transport in several important biomolecular systems. Proton translocation is of fundamental significance throughout biology, as demonstrated by the pH-dependence of biomolecular structure and function and the central role of transmembrane proton gradients in bioenergy conversion. Moreover, understanding proton transport is of fundamental importance and direct relevance to numerous aspects of human health, including metabolism, aging, diabetes, neurodegeneration, retinal degeneration, antivral and anti-bacterial therapeutics, and homeostasis. 1",Simulation of Proton Translocation in Biomolecules,9770887,R01GM053148,"['ATP Synthesis Pathway', 'Achievement', 'Aging', 'Agreement', 'Amino Acids', 'Anions', 'Anti-Bacterial Agents', 'Area', 'Behavior', 'Binding', 'Biology', 'Carrier Proteins', 'Catalysis', 'Charge', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Consult', 'Coupled', 'Coupling', 'Data', 'Defect', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diffusion', 'Dimensions', 'Elements', 'Entropy', 'Enzymes', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Grain', 'Hand', 'Health', 'Homeostasis', 'Human', 'Hydration status', 'Hydrogen Bonding', 'Influenza', 'Influenza A virus', 'Influenza B Virus', 'Inorganic Phosphate Transporter', 'Ion Transport', 'Kinetics', 'Length', 'Letters', 'Machine Learning', 'Maintenance', 'Mechanics', 'Medical', 'Medicine', 'Membrane', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Motion', 'Mutation', 'Nerve Degeneration', 'Oligopeptides', 'Outcome', 'Pharmaceutical Preparations', 'Process', 'Progress Reports', 'Protein Conformation', 'Proteins', 'Proton Pump', 'Protons', 'Publishing', 'Quantum Mechanics', 'Reaction', 'Research', 'Research Personnel', 'Research Support', 'Retinal Degeneration', 'Role', 'Sampling', 'Sampling Biases', 'Specificity', 'Structure', 'System', 'Therapeutic', 'Time', 'Transport Process', 'Travel', 'United States National Institutes of Health', 'Virus Diseases', 'Water', 'Wisconsin', 'anti-influenza drug', 'antiporter', 'chemical bond', 'chemical reaction', 'experimental study', 'innovation', 'inorganic phosphate', 'insight', 'migration', 'molecular dynamics', 'molecular mechanics', 'multi drug transporter', 'novel', 'pH gradient', 'protonation', 'quantum', 'simulation', 'symporter', 'theories']",NIGMS,UNIVERSITY OF CHICAGO,R01,2019,310328,-0.021394193005354483
"Simulation of Proton Translocation in Biomolecules PROJECT SUMMARY  The transport of protons in biomolecular systems is a phenomenon of fundamental importance to processes such as ATP synthesis, enzyme catalysis, the maintenance of pH gradients, proton pumping, viral infection, and substrate/ion transport across membranes via protein transporters, symporters, and antiporters. Modeling biomolecular proton translocation in silico is a significant challenge due to the complex chemical reactions involved in Grotthuss proton shutting between water molecules and with protonatable amino acids, as well as the complexity of the target biomolecular systems. In most cases, it is not only important to understand the mechanism of proton binding and transport, but also its coupling to other mechanistically relevant biomolecular processes, such as protein conformational changes, substrate binding, other protonation events, and dynamic hydration.  In this project the continued development and application of a powerful multiscale computer simulation methodology is described for the study of proton transport in several key classes of proton translocating biomolecular systems, including channels (influenza A and B M2 channels), antiporters/symporters (ClC Cl-/H+ antiporter and phosphate transporter, respectively), and transporters (proton-coupled oligopeptide transporter and EmrE multidrug transporter). The overall research plan is made possible by a novel reactive molecular dynamics simulation approach integrated with quantum mechanics/molecular mechanics (QM/MM) methods that allows for the study of explicit long-length and -time scale proton transport through water molecules and ionizable molecular groups in hydrogen-bonded networks, as well as by new innovations in enhanced free energy sampling methodology, machine learning, kinetic network theory, and coarse-graining. A primary goal in the research with this methodology in hand is to reveal the mechanisms of proton transport, as well as its coupling to hydration and conformational changes, in the above mentioned biomolecular systems. All of these studies will be carried out in collaboration with leading experimentalists, while continuing to add a new dimension to the field of biomolecular computer simulation as a whole. 1 PROJECT NARRATIVE  In this project, computer simulations will be used to study proton transport in several important biomolecular systems. Proton translocation is of fundamental significance throughout biology, as demonstrated by the pH-dependence of biomolecular structure and function and the central role of transmembrane proton gradients in bioenergy conversion. Moreover, understanding proton transport is of fundamental importance and direct relevance to numerous aspects of human health, including metabolism, aging, diabetes, neurodegeneration, retinal degeneration, antivral and anti-bacterial therapeutics, and homeostasis. 1",Simulation of Proton Translocation in Biomolecules,9965046,R01GM053148,"['ATP Synthesis Pathway', 'Achievement', 'Aging', 'Agreement', 'Amino Acids', 'Anions', 'Anti-Bacterial Agents', 'Area', 'Behavior', 'Binding', 'Biology', 'Carrier Proteins', 'Catalysis', 'Charge', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Consult', 'Coupled', 'Coupling', 'Data', 'Defect', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diffusion', 'Dimensions', 'Elements', 'Entropy', 'Enzymes', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Grain', 'Hand', 'Health', 'Homeostasis', 'Human', 'Hydration status', 'Hydrogen Bonding', 'Influenza', 'Influenza A virus', 'Influenza B Virus', 'Inorganic Phosphate Transporter', 'Ion Transport', 'Kinetics', 'Length', 'Letters', 'Machine Learning', 'Maintenance', 'Mechanics', 'Medical', 'Medicine', 'Membrane', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Motion', 'Mutation', 'Nerve Degeneration', 'Oligopeptides', 'Outcome', 'Pharmaceutical Preparations', 'Process', 'Progress Reports', 'Protein Conformation', 'Proteins', 'Proton Pump', 'Protons', 'Publishing', 'Quantum Mechanics', 'Reaction', 'Research', 'Research Personnel', 'Research Support', 'Retinal Degeneration', 'Role', 'Sampling', 'Sampling Biases', 'Specificity', 'Structure', 'System', 'Therapeutic', 'Time', 'Transport Process', 'Travel', 'United States National Institutes of Health', 'Virus Diseases', 'Water', 'Wisconsin', 'anti-influenza drug', 'antiporter', 'chemical bond', 'chemical reaction', 'experimental study', 'innovation', 'inorganic phosphate', 'insight', 'migration', 'molecular dynamics', 'molecular mechanics', 'multi drug transporter', 'novel', 'pH gradient', 'protonation', 'quantum', 'simulation', 'symporter', 'theories']",NIGMS,UNIVERSITY OF CHICAGO,R01,2019,109700,-0.021394193005354483
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,10012976,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2019,277141,-0.003855832141052464
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,9767141,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2019,886748,-0.003855832141052464
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,9744013,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Algorithms', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelium', 'Esophageal', 'Esophageal Adenocarcinoma', 'Esophagitis', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Intelligence', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stem cells', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2019,171720,0.0009292704546150253
"Successful Clinical Response In Pneumonia Therapy (SCRIPT) Systems Biology Center Overall Project Summary: This innovative integrated systems biology application seeks to delineate the complex host/pathogen interactions occurring at the alveolar level that lead to unsuccessful response to therapy in serious pneumonia. To achieve this objective, we will leverage our unique access to alveolar fluid collected as part of routine clinical care in mechanically ventilated patients with suspected pneumonia in our medical intensive care unit. Bronchoalveolar lavage fluid will be obtained serially from well characterized mechanically ventilated patients with Pseudomonas or Acinetobacter pneumonia. Both of these CDC- designated serious hazard level pathogens have clinical failure rates as high as 50%. A robust clinical definition will allow comparison of both host and pathogen signatures associated with failure of therapy vs. success. These clinical specimens and extensive patient phenomics will anchor two mutually supportive and iterative research projects. Project One will deploy robust tools for flow sorting macrophage and lymphocyte subset populations, isolating RNA from these populations, and performing transcriptomic and epigenomic analysis to compare successful and unsuccessful host responses to infection. Project Two will focus on both specific pathogen genomic profiles associated with unsuccessful outcome. Changes in microbiome communities will be comprehensively assessed by shotgun deep sequencing to detect bacteriophage, other virus, and fungal DNA, in addition to bacterial. The Technology Core will perform cell sorting of NBBAL macrophage and lymphocyte subsets, RNA sequencing, and whole genome methylation, and perform parallel studies in a unique humanized alveolar macrophage mouse model. A Data Management and Bioinformatics Core will develop tools to reduce the dimensionality of these large comprehensive datasets, including the clinical phenomics, and provide them to the Modeling Core. The Modeling Core will then use innovative modeling approaches including a model of the alveolus during pneumonia as an ecosystem out of balance combined with unique machine learning tools and neural networks to generate biomarkers of host, pathogen and/or microbiome patterns predictive of successful pneumonia outcome. Predictive biomarkers developed in the Modeling Core will then be validated in a prospective confirmatory cohort of patients in whom analogous data will be generated. The Administrative Core will perform the outward-facing role of education and outreach to the community and sponsor, as well as regularly exchanging datasets, analytic tools, and specimens with NIH-sponsored/approved repository sites. Project Narrative: The Successful Clinical Response In Pneumonia Treatment (SCRIPT) systems biology center seeks to delineate the complex host/pathogen interactions occurring at the alveolar level that lead to unsuccessful response to therapy in serious pneumonia. We will leverage our unique access to alveolar fluid collected as part of routine clinical care in mechanically ventilated patients to generate clinical phenomic, transcriptomic, epigenomic and metagenomic data that describe the host response, pathogen characteristics and microbiome of the alveolar space during pneumonia. We will then integrate this comprehensive phenotypic data into an ecosystem-based model to generate predictive biomarkers of pneumonia outcome for subsequent validation in a second cohort and tested for causality in a humanized alveolar macrophage mouse model.",Successful Clinical Response In Pneumonia Therapy (SCRIPT) Systems Biology Center,9626377,U19AI135964,"['Acinetobacter', 'Address', 'Alveolar', 'Alveolar Macrophages', 'Alveolus', 'Animal Model', 'Antibiotic Therapy', 'Bacteriophages', 'Bioinformatics', 'Biological Markers', 'Bronchoalveolar Lavage', 'Bronchoalveolar Lavage Fluid', 'Cause of Death', 'Cell Separation', 'Cells', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Microbiology', 'Clinical Trials', 'Collection', 'Communities', 'Complex', 'DNA Viruses', 'DNA sequencing', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Education and Outreach', 'Equilibrium', 'Etiology', 'Failure', 'Fungal DNA', 'Generations', 'Genes', 'Genetic', 'Goals', 'Human', 'Immune response', 'Infection', 'Intensive Care Units', 'Lead', 'Link', 'Liquid substance', 'Lymphocyte Subset', 'Lymphoid Cell', 'Machine Learning', 'Mechanics', 'Medical', 'Metagenomics', 'Methylation', 'Modeling', 'Multiomic Data', 'Myeloid Cells', 'Nosocomial Infections', 'Nosocomial pneumonia', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Pneumonia', 'Population', 'Preparation', 'Prospective cohort', 'Protocols documentation', 'Pseudomonas', 'Pseudomonas aeruginosa', 'Pseudomonas aeruginosa infection', 'RNA', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Sampling', 'Science', 'Secondary to', 'Shotguns', 'Site', 'Sorting - Cell Movement', 'Specimen', 'Standardization', 'Stream', 'System', 'Systems Biology', 'Technology', 'Testing', 'Treatment Failure', 'United States National Institutes of Health', 'Validation', 'Virulence', 'analytical tool', 'base', 'clinical care', 'cohort', 'data management', 'data pipeline', 'deep sequencing', 'epigenomics', 'experience', 'genomic data', 'genomic profiles', 'hazard', 'humanized mouse', 'improved', 'innovation', 'macrophage', 'microbiome', 'microbiome composition', 'mouse model', 'multiple omics', 'neural network', 'new therapeutic target', 'novel', 'pathogen', 'pathogen genomics', 'phenomics', 'phenotypic data', 'pneumonia model', 'predictive marker', 'predictive tools', 'prospective', 'repository', 'response', 'success', 'tool', 'transcriptome sequencing', 'transcriptomics', 'viral DNA', 'whole genome']",NIAID,NORTHWESTERN UNIVERSITY AT CHICAGO,U19,2019,2400000,-0.00714896901616763
"Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence Abstract Enzyme functionality is a critical component of all life systems. Whereas advances in experimental methodology have enabled a better understanding of factors that control enzyme function, critical components of the reaction space such as highly unstable intermediates and transition states are best accessed for evaluation through computational simulations. Similarly, computational methodology continues to provide a key resource for probing excited-state processes such as bioluminescence. Combined ab initio quantum mechanical molecular mechanical (ai-QM/MM) simulations are, in principle, the preferred choice in the modeling of both processes. But ai-QM/MM modeling of enzymatic reactions is now severely limited by its computational cost, where a direct ai-QM/MM free energy simulation of an enzymatic reaction can take 500,000 or more CPU hours. Meanwhile, ai-QM/MM modeling of firefly bioluminescence is also hindered by the computational accuracy, where it has yet to produce quantitatively correct predictions for the bioluminescence spectral shift with site-directed mutagenesis. The goal of this proposal is to accelerate ai-QM/MM simulations of enzymatic reaction free energy and to improve the quality of ai-QM/MM-simulated bioluminescence spectra, so that ai-QM/MM simulations can be routinely performed by experimental groups. This will be achieved via a) using a lower-level (semi-empirical QM/MM) Hamiltonian for sampling; b) an enhancement to the similarity between the two Hamiltonians by calibrating the low-level Hamiltonian using the reaction pathway force matching approach, in conjunction with several other methods. The expected outcomes of this collaborative effort include: a) advanced methodologies for accelerated reaction free energy simulations and accurate bioluminescence spectra predictions, which will be released through multiple software platforms; b) a fundamental understanding of reactions such as Kemp elimination and polymerase-eta catalyzed DNA replication; c) a deeper insight into the role of macromolecular environment in the modulation of enzyme catalytic activities or bioluminescence wavelengths, which can further enhance our capability of designing new enzymes and bioluminescence probes. Narrative This project aims to develop quantum-mechanics-based computational methods to more quickly model enzymatic reactions and more accurately model bioluminescence spectra. It will lead to reliable and efficient computational tools for use by the general scientific community. It will facilitate the probe of enzymatic reaction mechanisms and the computer-aided design of new bioluminescence probes.",Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence,9864664,R01GM135392,"['Adopted', 'Biochemical Reaction', 'Bioluminescence', 'Calibration', 'Communities', 'Computer Simulation', 'Computer software', 'Computer-Aided Design', 'Computing Methodologies', 'DNA biosynthesis', 'DNA-Directed DNA Polymerase', 'Electrostatics', 'Environment', 'Enzymes', 'Evaluation', 'Fireflies', 'Free Energy', 'Freedom', 'Generations', 'Goals', 'Hour', 'Ions', 'Life', 'Machine Learning', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Multienzyme Complexes', 'Outcome', 'Pathway interactions', 'Polymerase', 'Process', 'Protocols documentation', 'Quantum Mechanics', 'Reaction', 'Resources', 'Role', 'Sampling', 'Site-Directed Mutagenesis', 'System', 'Temperature', 'Thermodynamics', 'Time', 'base', 'computerized tools', 'cost', 'design', 'experimental group', 'improved', 'innovation', 'insight', 'multi-scale modeling', 'mutant', 'quantum', 'simulation', 'theories']",NIGMS,UNIVERSITY OF OKLAHOMA NORMAN,R01,2019,269849,0.004757267089744818
"CSHL Computational and Comparative Genomics Course The Cold Spring Harbor Laboratory proposes to continue a course entitled “Computational and Comparative Genomics”, to be held in the Fall of 2017 – 2019. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases that they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. NARRATIVE The Computational & Comparative Genomics, a 9 day course, is designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,9724498,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'Course Content', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genome', 'Home environment', 'Institution', 'International', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Research Training', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Training Programs', 'Universities', 'Update', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'graduate student', 'instructor', 'interest', 'laboratory experience', 'lecturer', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2019,67704,0.006835991535404915
"Bridging Statistical Inference and Mechanistic Network Models for HIV/AIDS Network models are used to investigate the spread of HIV/AIDS, but rather than assuming that the members of a population of interest are fully mixed, the network approach enables individual-level specification of contact patterns by considering the structure of connections among the members of the population. By representing individuals as nodes and contacts between pairs of individuals as edges, this network depiction enables identification of individuals who drive the epidemic, allows for accurate assessment of study power in cluster- randomized trials, and makes it possible to evaluate the impact of interventions on the individuals themselves, their partners, and the broader network. There are currently two major mathematical paradigms to the modeling of networks: the statistical approach and the mechanistic approach. In the statistical approach, one specifies a model that states the likelihood of observing a given network, whereas in the mechanistic approach one specifies a set of domain-specific mechanistic rules at the level of individual nodes, the actors in the network, that are used to evolve the network over time. Given that mechanistic models directly model individual-level behaviors – modification of which is the foundation of most prevention measures – they are a natural fit for infectious diseases. Another attractive feature of mechanistic models is their scalability as they can be implemented for networks consisting of thousands or even millions of nodes, making it possible to simulate population-wide implementation of interventions. Lack of statistical methods for calibrating these models to empirical data has however impeded their use in real-world settings, a limitation that stems from the fact that there are typically no closed-form likelihood functions available for these models due the exponential increase in the number of ways, as a function of network size, of arriving at a given observed network. We propose to overcome this gap by advancing inferential and model selection methods for mechanistic network models, and by developing a framework for investigating their similarities with statistical network models. We base our approach on approximate Bayesian computation (ABC), a family of methods developed specifically for settings where likelihood functions are intractable or unavailable. Our specific aims are the following. Aim 1: To develop a statistically principled framework for estimating parameter values and their uncertainty for mechanistic network models. Aim 2: To develop a statistically principled method for model choice between two competing mechanistic network models and estimating the uncertainty surrounding this choice. Aim 3: To establish a framework for mapping mechanistic network models to statistical models. We also propose to implement these methods in open source software, using a combination of Python and C/C++, to facilitate their dissemination and adoption. We believe that the research proposed here can help harness mechanistic network models – and with that leverage some of the insights developed in the network science community over the past decade and more – to help eradicate this disease. PROJECT NARRATIVE Network models are used to gain a more precise understanding of human behavioral factors associated with the spread of HIV/AIDS in order to develop more effective interventions to halt the epidemic. There are two main mathematical paradigms for modeling networks, the statistical approach and the mechanistic approach, and given that the latter directly models individual-level behaviors – modification of which is the foundation of most prevention measures – mechanistic models are a natural fit for infectious diseases. Lack of statistical methods for calibrating these models to empirical data has so far impeded their use in real-world settings, and we therefore propose to develop parameter inference and model selection methods for mechanistic network models in order to endow the biomedical community with these powerful tools.",Bridging Statistical Inference and Mechanistic Network Models for HIV/AIDS,9817000,R01AI138901,"['AIDS prevention', 'AIDS/HIV problem', 'Adoption', 'Automobile Driving', 'Bayesian Analysis', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Biological', 'Cluster randomized trial', 'Communicable Diseases', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Dimensions', 'Disease', 'Epidemic', 'Ethics', 'Evaluation', 'Evolution', 'Family', 'Foundations', 'Goals', 'HIV', 'Health Sciences', 'Human', 'Individual', 'Infection', 'Intervention', 'Learning', 'Likelihood Functions', 'Logistics', 'Machine Learning', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Pattern', 'Physics', 'Population', 'Prevention Measures', 'Prevention strategy', 'Probability', 'Process', 'Property', 'Public Health', 'Pythons', 'Research', 'Research Personnel', 'SET Domain', 'Science', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Structure', 'Time', 'Uncertainty', 'base', 'effective intervention', 'high dimensionality', 'indexing', 'innovation', 'insight', 'interest', 'member', 'network models', 'open source', 'pandemic disease', 'pathogen', 'pre-exposure prophylaxis', 'simulation', 'statistics', 'stem', 'tool', 'treatment adherence', 'treatment strategy']",NIAID,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2019,334891,-0.013768338903354802
"Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity Project Summary Antimicrobial resistance is an increasing problem, and current drug pipelines are not keeping pace with the rise of antimicrobial resistance. An alternative strategy is to boost host immunity. An often overlooked side-effect of the vitamin and mineral supplementation projects of the 1940s is that these supplements greatly reduced infectious disease burden. Recent work has shown that further gains may be possible, especially in adding phytochemicals back to highly processed diets typically consumed in the United States. However, we lack a fundamental understanding of how these components are processed by the microbiome, and how diet-derived molecules, microbiome and host immune system work together to resist infectious disease. A key barrier preventing us from making these discoveries is that each individual assay (microbiome, host gene expression metabolome, dietary compounds) is expensive and highly multivariate. Three key insights that enable the current project are the miniaturization of DNA and RNA sequencing assays on advanced nanoliter- scale liquid handling robots, greatly reducing the cost, the combination of untargeted and targeted mass spectrometry on the same samples in high throughput to enable discovery of a much greater chemical space, and the ability to use explicitly spatial maps on multiple scales to integrate the dataset throughout the body and enable both visual analytics and deep learning approaches based on spatial data. These breakthroughs will provide a fundamentally new understanding of how dietary metabolites promote disease resistance, and will allow us to develop a new infrastructure to integrate results from many investigators in different laboratories studying various aspects of these systems. Additionally, the results will allow us to choose biomaterials and biomarkers in human subjects that provide maximum information about internal nutritional and immune status. Results will be tested against the NHANES and American Gut cohorts. The results of this project will therefore be: 3D maps of mouse models showing how the microbiome, diet, and host gene expression produce immunity; an infrastructure for creating and sharing these maps; and a preliminary test of whether the results extend to large human populations. Project Narrative The public health relevance of this proposal is that it will provide an infrastructure for analyzing impacts of dietary components and microbiomes throughout the body. The analysis of these maps will help us identify dietary components that improve resistance to infectious disease.",Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity,9785812,DP1AT010885,"['3-Dimensional', 'American', 'Antimicrobial Resistance', 'Back', 'Biocompatible Materials', 'Biological Assay', 'Biological Markers', 'Chemicals', 'Communicable Diseases', 'Consumption', 'DNA sequencing', 'Data', 'Data Set', 'Diet', 'Dietary Component', 'Disease Resistance', 'Enhancers', 'Gene Expression', 'Human', 'Immune system', 'Immunity', 'Individual', 'Infrastructure', 'Laboratory Study', 'Liquid substance', 'Maps', 'Mass Spectrum Analysis', 'Metabolite Interaction', 'Microbe', 'Minerals', 'Miniaturization', 'National Health and Nutrition Examination Survey', 'Nutritional status', 'Pharmaceutical Preparations', 'Phytochemical', 'Population', 'Process', 'Research Personnel', 'Resistance', 'Robot', 'Sampling', 'Supplementation', 'System', 'Testing', 'United States', 'Visual', 'Vitamins', 'Work', 'base', 'burden of illness', 'cohort', 'cost', 'deep learning', 'human subject', 'immunological status', 'improved', 'insight', 'metabolome', 'microbiome', 'mouse model', 'nanolitre scale', 'prevent', 'public health relevance', 'side effect', 'transcriptome sequencing']",NCCIH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",DP1,2019,1085000,-0.010643740948265314
"Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions Project Summary/Abstract DNA sequencing has spawned the “microbiome revolution” -- thousands of microbes and a dizzying number of microbial interactions that are associated with human health and disease. Unfortunately, most species in the microbiome are known only by a (partial) genome. The limited phenotypic data on newly discovered bacteria reveal species that behave unlike any of our model organisms. While genome-scale modeling plays an important role in understanding the microbiome, the paucity of phenotypic data for most species prevents detailed simulation of the microbial communities that affect our health. This project will develop an automated system for profiling, synthesizing, and modeling microbial communities. The center of our approach is Deep Phenotyping, an automated robotic platform that performs complex growth experiments on demand. Data from Deep Phenotyping will be used to train metabolic and statistical models of the oral pathogens Streptococcus mutans and Candida albicans to predict conditions that keep both microbes in a nonpathogenic state. Project Narrative The microbiome revolution has uncovered thousands of species of bacteria with roles in health and disease. This project automates the identification of interactions between environments, genes, and the microbes that live in and around us. Understanding these interactions is a critical step in re-engineering the microbiome to improve human health.","Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions",9651956,R21EB027396,"['Affect', 'Animal Model', 'Antibiotics', 'Area', 'Bacteria', 'Biochemical Pathway', 'Bioinformatics', 'Biological', 'Biological Assay', 'Candida albicans', 'Carbon', 'Coculture Techniques', 'Collaborations', 'Combinatorics', 'Communities', 'Complex', 'Computer software', 'DNA sequencing', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Future', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Human Microbiome', 'Hybrids', 'Image', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Metabolic', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral', 'Oral candidiasis', 'Pathway interactions', 'Phenotype', 'Play', 'Positioning Attribute', 'Regulator Genes', 'Research Personnel', 'Robotics', 'Role', 'Shapes', 'Source', 'Statistical Models', 'Streptococcus mutans', 'Structure', 'System', 'Technology', 'Time', 'Training', 'Work', 'base', 'combinatorial', 'cost', 'design', 'dysbiosis', 'experience', 'experimental study', 'fitness', 'fungus', 'genome-wide', 'improved', 'instrumentation', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microorganism interaction', 'network models', 'open source', 'oral pathogen', 'pathogenic fungus', 'phenotypic data', 'preference', 'prevent', 'screening', 'simulation', 'transcription factor', 'transcriptome sequencing', 'transposon sequencing']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2019,219161,-0.005299649305378121
"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",Joint Analysis of Microbiome and Other Genomic Data Types,9763572,R01GM129512,"['Achievement', 'Address', 'Area', 'Automobile Driving', 'Biological', 'Birth', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Early Diagnosis', 'Future', 'Genes', 'Genetic', 'Genomics', 'Grouping', 'Health', 'Human Genome Project', 'Joints', 'Lasso', 'Learning', 'Machine Learning', 'Maintenance', 'Maps', 'Medical', 'Menopause', 'Metabolic', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Modification', 'Molecular Target', 'Network-based', 'Outcome', 'Pathway interactions', 'Performance', 'Phylogenetic Analysis', 'Pregnancy Outcome', 'Premature Birth', 'Procedures', 'Public Health', 'Quantitative Trait Loci', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Structure', 'System', 'Taxonomy', 'Training', 'Woman', 'Work', 'base', 'biological systems', 'computerized tools', 'experience', 'genetic variant', 'genomic data', 'human disease', 'improved', 'interest', 'loss of function', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiome analysis', 'microbiome components', 'microbiome composition', 'microbiome research', 'new therapeutic target', 'novel', 'open source', 'population stratification', 'predictive modeling', 'simulation', 'software development', 'therapeutic target', 'tool', 'translational study', 'user friendly software', 'vaginal microbiome']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,396000,-0.0028019561353570654
"Dopaminergic encoding of counterfactual information in human striatum ﻿    DESCRIPTION (provided by applicant): Diseases and disorders directly affected by dopamine systems (e.g., drug addiction and Parkinson's disease) highlight the importance of these systems in motivated human behavior and cognition. The dopamine system is known to be a critical component of normal learning, reward processing, and decision-making (reviewed in Montague et al., 2004). Unfortunately, our present knowledge of dopamine systems in human brains is relatively sparse compared to the wealth of experimentation and computational modeling on these systems in rodents and non-human primates. Previously, technological constraints have limited direct experimentation in human brains. This proposal capitalizes on our group's recent technological innovation, which was supported by the NIH R21 mechanism - CEBRA: R21DA024140 - and resulted in the successful completion of the first sub-second measurements of dopamine release in a human brain. Furthermore, these measurements took place during an active decision-making task that was framed by computational models of learning and reward processing (Kishida et al., 2011 and Kishida et al., under review). We propose to pursue three specific aims, which combine our technological advance with active learning tasks designed to probe the role of dopamine in human behavior. Our aims incorporate three learning signals, where actual and counterfactual experience will each be examined in human striatal responses. The proposed work will inform on the controversial role for dopamine in reward/movement interactions. The experiments proposed will yield unprecedented insight into the function of the dopamine system in the humans afflicted with Parkinson's disease and Essential Tremor. With the support of the NIH (R21DA024140), our team successfully developed a complete prototype system for making electrochemical measurements of dopamine delivery in the human brain. Feasibility has been demonstrated by obtaining the first dopamine measurements in the striata of subjects with Parkinson's during a decision-making task. This substantial preliminary work is now ready for a larger scale with specific hypothesis testing about the role of dopamine systems in Parkinson's disease, Essential tremor, and human decision-making and behavior. PUBLIC HEALTH RELEVANCE: Experiments and computational models (primarily investigated in rodents and non-human primates) suggest dopamine systems in the brain are essential for normal learning, reward-processing, and ongoing decision- making. This proposal builds upon our group's innovative work, which - for the first time - recorded sub- second measurements of dopamine in human subjects and amalgamated these measurements with computational models of dopamine function. Herein we propose to use this newly developed technology to generate unprecedented insight into the function of dopamine systems directly in humans.",Dopaminergic encoding of counterfactual information in human striatum,9749260,R01NS092701,"['Active Learning', 'Acute', 'Affect', 'Animal Model', 'Behavior', 'Brain', 'Brain Diseases', 'Cells', 'Cessation of life', 'Cognition', 'Cognitive', 'Computer Simulation', 'Corpus striatum structure', 'Coupling', 'Data', 'Decision Making', 'Disease', 'Dopamine', 'Drug Addiction', 'Electrodes', 'Essential Tremor', 'Exploratory/Developmental Grant', 'Funding', 'Human', 'Knowledge', 'Learning', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Movement Disorders', 'Operative Surgical Procedures', 'Parkinson Disease', 'Participant', 'Patients', 'Periodicity', 'Phase', 'Play', 'Replacement Therapy', 'Research Personnel', 'Rewards', 'Rodent', 'Role', 'Sample Size', 'Scanning', 'Signal Transduction', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'blood oxygenation level dependent response', 'cognitive function', 'design', 'dopamine system', 'dopaminergic neuron', 'experience', 'experimental study', 'extracellular', 'human subject', 'implantation', 'innovation', 'insight', 'nonhuman primate', 'prototype', 'public health relevance', 'putamen', 'reduce symptoms', 'relating to nervous system', 'response', 'reward processing', 'social', 'symptomatic improvement', 'technological innovation', 'temporal measurement']",NINDS,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2019,564964,-0.0009656777602808868
"Genetic neuroscience: How human genes and alleles shape neuronal phenotypes Genetic studies have identified many specific loci with significant associations to psychiatric disorders. However, unless we can develop useful approaches for systematically turning genetic information into neurobiological insights about brain disorders, there is a danger that costly and hard-won genetic findings will not be exploitable to understand pathophysiology and generate important therapeutic hypotheses. The goal of our collaborative, interdisciplinary effort is to develop powerful, generalizable approaches for discovering how risk variants for psychiatric disorders shape neurobiological processes at multiple levels of analysis, and to identify the processes whose dysregulation underlies disease. To do this, we propose to develop new experimental and inferential systems to bridge a longstanding gap between human genetics and experimental biology. We aim to identify biological causes and effects that span the genetic, molecular, and cellular levels of the nervous system. Our interdisciplinary team will develop new experimental systems that measure genetic influences across levels of analysis (RNA, proteins, and cellular function including physiology) in precise, scalable, well- controlled ways. We will make use of emerging cellular systems including three-dimensional cortical spheroids and organoids, and radically novel “population in a dish” experimental systems that collect data on cells from hundreds of donors in a shared environment, inferring donor identity at the time of phenotypic readout. The analysis of such systems in turn requires sophisticated inferential strategies and new ideas from computer science. We propose to develop and widely share experimental and computational resources, including cell lines, methods, datasets, and analytic tools. The successful completion of this work will identify key neurobiological processes for multiple psychiatric disorders, and fortify many other scientists in making such connections in their own work. We hope in so doing to create a new kind of interdisciplinary science that – by combining the strengths of data-driven, unbiased human genetics with the power of emerging experimental systems – transforms the rate at which human- genetic leads lead to insights about disease mechanisms. To better understand common, severe psychiatric illnesses and develop improved treatments for them, we need to understand what specific aspects of brain biology give rise to each disorder. Here a team of scientists with diverse areas of expertise – from neuroscience to computer science to psychiatry to human genetics to stem cell biology – come together to develop a set of next-generation scientific approaches to this important problem, and to generate new methods and data sets that we will widely share. Our team will work to understand how aspects of brain biology at many levels – genes, molecules, and cells – act upon one another to create vulnerability to psychiatric illness.",Genetic neuroscience: How human genes and alleles shape neuronal phenotypes,9757833,U01MH115727,"['Affect', 'Alleles', 'Architecture', 'Area', 'Awareness', 'Biological', 'Biological Assay', 'Biology', 'Brain', 'Brain Diseases', 'California', 'Cell Differentiation process', 'Cell Line', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Computer Analysis', 'Data', 'Data Science', 'Data Set', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Experimental Models', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic study', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Institutes', 'Investments', 'Ion Channel', 'Lead', 'Libraries', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microglia', 'Molecular', 'Molecular Biology', 'Mutation', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Organoids', 'Penetrance', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Process', 'Property', 'Proteins', 'Psychiatry', 'RNA', 'Regenerative Medicine', 'Resources', 'Risk', 'Sampling', 'Science', 'Scientist', 'Shapes', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Work', 'analytical tool', 'cell type', 'computer science', 'computing resources', 'cost', 'cytokine', 'excitatory neuron', 'experimental study', 'genetic information', 'human data', 'improved', 'induced pluripotent stem cell', 'inhibitory neuron', 'innovation', 'insight', 'loss of function mutation', 'multidimensional data', 'neurophysiology', 'next generation', 'novel', 'protein expression', 'protein function', 'rare variant', 'response', 'risk variant', 'stem cell biology', 'translational neuroscience', 'whole genome']",NIMH,"BROAD INSTITUTE, INC.",U01,2019,4129117,-0.01639504357277716
"Bioinformatics Tools for Circadian Biology Circadian rhythms are fundamental for understanding biology: they date back to the origin of life, they are found in virtually every species from cyanobacteria to mammals, and they coordinate many important biological functions from the sleep-wake cycle, to metabolism, and to cognitive functions. Circadian rhythms are equally fundamental for health and medicine: modifications in diet have been linked to modification in circadian rhythms at the molecular level; disruptions of circadian rhythms have been linked to health problems ranging from depression, to learning disorders, to diabetes, to obesity, to cardiovascular disease, to cancer, and to premature ageing; finally, a large fraction of drug targets have been found to oscillate in a circadian manner in one or several tissues, suggesting that a better understanding of circadian oscillations at the molecular level could have direct applications to precision medicine, for instance by optimizing the time at which drugs are taken.  To better understand circadian oscillations at the molecular level, modern high-throughput technologies are being used to measure the concentrations of many molecular species, including transcripts, proteins, and metabolites along the circadian cycle in different organs and tissues, and under different conditions. However, the informatics tools for processing, analyzing, and integrating the growing wealth of molecular circadian data are not yet in place.  This effort will fill this fundamental gap by developing and disseminating informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine. Specifically, through a close collaborations between computational and experimental scientists, this effort will: (1) Bring the power of deep learning methods to bear on the analyses of omic time series to determine, for instance, which molecular species are oscillating, their characteristics (period, phase, amplitude), and to predict the time/phase associated with a measurement taken at a single time point; (2) Develop Cyber-TC, an extension of the widely used Cyber-T software, for the differential analysis of circadian omic time series and expand MotifMap, a widely used genome-wide map of regulatory sites to better understand circadian regulation; and (3) Develop Circadiomics, an integrated database and web portal as a one-stop shop for circadian data, annotations, and analyses. All data, software, and results will be freely available for academic research purposes and broadly disseminated through multiple channels to benefit both the circadian community and the broader bioinformatics community. Circadian rhythms are fundamental for biology and medicine. Modern high-throughput technologies are revealing how the concentrations of many molecular species, including transcripts, proteins, and metabolites oscillate with the day and night cycle in almost every species, tissue, and cell. In close collaboration with biologists, this project will develop the informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine.",Bioinformatics Tools for Circadian Biology,9690782,R01GM123558,"['Address', 'Ally', 'Architecture', 'Back', 'Biogenesis', 'Bioinformatics', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Cells', 'Characteristics', 'Circadian Dysregulation', 'Circadian Rhythms', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Cyanobacterium', 'Data', 'Databases', 'Diabetes Mellitus', 'Diet', 'Disease', 'Drug Targeting', 'Feedback', 'Future', 'Gene Expression Regulation', 'Health', 'Homeostasis', 'Laboratories', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Link', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Metabolism', 'Modernization', 'Modification', 'Molecular', 'Obesity', 'Organ', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Premature aging syndrome', 'Proteomics', 'Research', 'Role', 'Scientist', 'Series', 'Site', 'Sleep Wake Cycle', 'System', 'Testing', 'Time', 'Tissues', 'Transcript', 'Update', 'Ursidae Family', 'Vision', 'annotation  system', 'bioinformatics tool', 'circadian', 'circadian regulation', 'cognitive function', 'cognitive process', 'deep learning', 'direct application', 'genome-wide', 'high throughput analysis', 'high throughput technology', 'informatics\xa0tool', 'insight', 'learning strategy', 'member', 'metabolomics', 'novel', 'precision medicine', 'protein metabolite', 'software development', 'tool', 'transcriptomics', 'virtual', 'web portal']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2019,328155,-0.0017346248703934489
"Computational and Experimental Resources for Virome Analysis in Inflammatory Bowel Disease (CERVAID) SUMMARY  While the role of the bacterial microbiome in human health and disease is well established, few studies have evaluated the contribution of the virome. Recently, we demonstrated that alterations in the enteric virome in adulthood are associated with diseases such as inflammatory bowel disease (IBD) and AIDS. In a cross- sectional comparison of IBD cases and household controls, a significant expansion of the Caudovirales, an order of phages, and anelloviruses, a family of eukaryotic DNA viruses, was observed. Advancing understanding of the IBD virome beyond this finding is limited by: (1) A lack of well defined longitudinal human cohorts to enable discovery of temporal associations of the virome with health and disease; (2) The challenge of viral “dark matter”. Dark matter refers to the typically >50% of the sequences present in purified virus preparations cannot be classified due to a lack of statistically significant alignment to known reference sequences. Thus, current virome studies effectively assess < 50% of the virome, thereby compromising our ability to detect important associations between the virome and disease; (3) Inadequate experimental systems to manipulate the virome. Although sequencing has identified many novel eukaryotic viruses, there are only cell culture systems for a limited number of viruses; moreover, there are no small animal infection models for newly described viruses. In addition while a tremendous diversity of phage has been identified, only a tiny fraction have known hosts and an even smaller fraction has been cultured. Thus, there are significant barriers that must be overcome to be able to experimentally test the impact of either eukaryotic viruses or phages in murine IBD models. These barriers to understanding the role of the IBD virome will be addressed as follows: Aim 1 will define the enteric virome and bacterial microbiome in a longitudinal cohort of IBD patients and household controls and identify virome associations with IBD. In Aim 2 novel computational tools to identify and characterize viruses present in enteric viromes will be developed, including approaches to classify dark matter. In Aim 3 novel experimental systems for functional virome analysis, including novel cultures of both eukaryotic viruses and phages as well as animal infection models, will be developed with the end goal of evaluating causal roles for the viruses and phage in existing muring IBD models. Together, these Aims will not only address significant barriers in understanding of IBD, but will provide a wealth of tangible computational and experimental resources to advance the general field of virome studies.   NARRATIVE The overall goal of this project is to develop novel computational and experimental tools to address challenges in understanding the role of viruses in inflammatory bowel disease. These tools will facilitate studies of not only inflammatory bowel disease, but also broader studies of the relationship of the human virome to other diseases.  ",Computational and Experimental Resources for Virome Analysis in Inflammatory Bowel Disease (CERVAID),9707307,RC2DK116713,"['Acquired Immunodeficiency Syndrome', 'Address', 'Adult', 'Animal Model', 'Animals', 'Bacteria', 'Bacterial Infections', 'Bacteriophages', 'Bioinformatics', 'Biology', 'Caudovirales', 'Cell Culture System', 'Cell Culture Techniques', 'Chronic', 'Classification', 'Clinical', 'Communities', 'Computer Analysis', 'Computer software', 'DNA Viruses', 'Databases', 'Defect', 'Development', 'Digestive System Disorders', 'Disease', 'Disease model', 'Enteral', 'Family', 'Feces', 'Genome', 'Gnotobiotic', 'Goals', 'Health', 'High-Throughput Nucleotide Sequencing', 'Household', 'Human', 'Immune system', 'Infection', 'Inflammatory Bowel Diseases', 'Longitudinal cohort', 'Machine Learning', 'Metabolic Diseases', 'Metadata', 'Metagenomics', 'Modeling', 'Mus', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Norovirus', 'Open Reading Frames', 'Parasitic infection', 'Pathogenesis', 'Pathogenicity', 'Pathology', 'Patients', 'Play', 'Population', 'Preparation', 'Resource Development', 'Resources', 'Ribosomal RNA', 'Role', 'System', 'Taxonomy', 'Testing', 'Time', 'Viral', 'Viral Genes', 'Viral Genome', 'Virus', 'Virus Diseases', 'bacterial resistance', 'bacteriome', 'base', 'case control', 'cohort', 'computerized tools', 'contig', 'dark matter', 'early childhood', 'experimental analysis', 'genome annotation', 'gut microbiome', 'human virome', 'improved', 'metagenome', 'microbial', 'molecular sequence database', 'multidisciplinary', 'novel', 'phenomenological models', 'protein function', 'software development', 'stool sample', 'tool', 'virology', 'virome']",NIDDK,WASHINGTON UNIVERSITY,RC2,2019,1872216,-0.0014658066699308966
"Development of dictyBase, an online informatics resource PROJECT SUMMARY dictyBase is the model organism database (MOD) for the eukaryote Dictyostelium discoideum and related species. A community resource, widely supported by the research community, dictyBase contains gold standard expert literature curation of genes, functional annotations using the Gene Ontology and a wide range of genomic resources. Dictyostelium is widely used to study cellular processes such as cell motility, chemotaxis, signal transduction, cellular response to drugs, and host-pathogen interactions. Dictyostelium's genome contains significant orthologs of vertebrate, yeast and microbial genes, attracting researchers interested in a wide variety of biological topics including human disease, multicellular differentiation and comparative genomics. dictyBase enables researchers to search, view and download up-to-date genomic, functional and technical information. It is also widely used by teachers/instructors due to the wealth of available teaching materials and research protocols. Dictyostelium investigators depend on dictyBase as their primary community resource, where help from dictyBase staff (dictyBase help line) or from other users (Dicty ListServ, moderated by dictyBase) is available. We are in the final stages of deploying our completely new technology stack. By the end of this year dictyBase will be run entirely as a cloud-based application. This propoal seeks support to continue operating and expanding this important community resource. Our goals for this proposal are: (Aim 1) To continue (a) expert curation by dictyBase curators and enable (b) Community curation leveraging our strong relationship with the community. We will use additional sequence data to (c) update the AX4 reference genome sequence and improve the efficiency of curation by using (d) Deep learning-based linking of papers to genes prioritizing them for further analysis and curation. (Aim 2) We will improve dictyBase utility and usability by implementing (a) Bulk annotation methods for importing large-scale data sets using both (i) a web interface and (ii) a script/command line method. (b) We will add 10 additional Dictyostelid genomes using automated methods to annotate them. We will improve usability by implementing a (c) concurrent blast search with a new user interface and integrate this with the JBrowse display. (Aim 3) To expand the data and increase the richness of annotations available in dictyBase we will implement mechanisms to capture, store and display: (a) additional context to GO annotations (i) using existing GO extensions and (ii) annotating and displaying biological pathways using GO CAM models; (b) integrate and display genome wide insertion mutant information for over 20 thousand insertional mutants; and (c) develop a graphical display of spatial expression data using Dictyostelium anatomy ontology terms (i) by adding a track in JBrowse for genes annotated with spatial / anatomy expression terms, and (ii) creating a graphical display of these annotations via our Circos-based dashboard tool. As other data sets become available we will add them to dictyBase and develop methods to display the data and make it searchable. PROJECT NARRATIVE dictyBase is the model organism database (MOD) for the eukaryote Dictyostelium discoideum and related species, Dictyostelium is widely used for research in the biomedical, genetic, and environmental domains. The database uses the genome of Dictyostelium to organize biological knowledge developed using this experimental system, and dictyBase is manually curated and up-to-date with current literature. This application proposes capturing new types of data and providing tools to search and visualize that data.","Development of dictyBase, an online informatics resource",9738586,R01GM064426,"['Anatomy', 'Animals', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Cell physiology', 'Chemotaxis', 'Code', 'Collaborations', 'Communities', 'DNA sequencing', 'Data', 'Data Display', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Dictyostelium', 'Dictyostelium discoideum', 'Disease', 'Engineering', 'Eukaryota', 'FAIR principles', 'Funding', 'Gene Proteins', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Gold', 'Information Resources', 'Investments', 'Knowledge', 'Link', 'Literature', 'Manuals', 'Methods', 'Modeling', 'Names', 'Nomenclature', 'Ontology', 'Orthologous Gene', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Plants', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Resource Informatics', 'Resources', 'Running', 'Signal Transduction', 'Site', 'Students', 'Supervision', 'System', 'Teaching Materials', 'United States National Institutes of Health', 'Update', 'Work', 'Yeasts', 'analytical tool', 'base', 'cell motility', 'cloud based', 'comparative genomics', 'contig', 'dashboard', 'data warehouse', 'deep learning', 'experimental study', 'genome annotation', 'genome-wide', 'human disease', 'improved', 'instructor', 'interest', 'microbial', 'model organisms databases', 'mutant', 'new technology', 'novel', 'pathogen', 'reference genome', 'response', 'teacher', 'tool', 'usability', 'web interface']",NIGMS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,506287,-0.013996539826401644
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9653955,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2019,587448,-0.02014861257209457
"Learning Dynamics of Biological Processes from Time Course Omics Datasets Complex biological processes, including organ development, immune response and disease progression, are inherently dynamic. Learning their regulatory architecture requires understanding how components of a large system dynamically interact with each other and give rise to emergent behavior. Recent experimental advances have made ii possible to investigate these biological systems in a data-driven fashion al high temporal resolution, allowing identification of new genes and their regulatory interactions. Longitudinal omics data sets are becoming increasingly common in clinical practice as well. Information on these collections of interacting genes can be integrated to gain systems-level insights into the roles of biological pathways and processes, including progression of diseases. Consequently, developing interpretable methods for learning functional relationships among genes, proteins or metabolites from high-dimensional time series data has become a timely research problem. The nature of these time-course data sets presents exciting opportunities and interesting challenges from a statistical perspective. Typical time-course omics data sets are challenging because of their high-dimensionality and non-linear relationships among system components. To tackle these challenges, one needs sophisticated dimension-reduction techniques that are biologically meaningful, computationally efficient and allow uncertainty quantification. Methods that incorporate prior biological information (e.g., pathway membership, protein-protein interactions) into the data analysis are good candidates for analyzing such high-dimensional systems using small samples. Here, we will develop three core methods to address the above challenges - (Aim 1): an empirical Bayes framework for clustering high-dimensional omics time-course data using prior biological knowledge; (Aim 2): a quantile-based Granger causality framework for learning interactions among genes or metabolites from their lead-lag relationships; and (Aim 3): a decision tree ensemble framework for searching cascades of interactions among genes from their temporal expression profiles. Our interdisciplinary team of statisticians and scientists will analyze time-course omics data from three research projects: (i) innate immune response systems in Drosophila, (ii) developmental process in mouse models, and (ii) longitudinal metabolite profiling of TB patients. These insights will be used to build and validate our methodology, which will be implemented in a publicly available software. This proposal is innovative in its incorporation of prior biological knowledge in the framework of novel dimension reduction techniques for interrogating high-dimensional time-course omics data. This research is significant in that it will impact basic sciences by elucidating data-driven, testable hypotheses on the regulatory architecture of biological processes, and clinical practice by monitoring disease progression and prognosis. n/a",Learning Dynamics of Biological Processes from Time Course Omics Datasets,9903643,R01GM135926,"['Biological Process', 'Data Set', 'Instruction', 'Learning', 'Time']",NIGMS,CORNELL UNIVERSITY,R01,2019,351443,-0.004839555722562042
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs. PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,9902031,U54AT008909,"['Address', 'Archives', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Drug usage', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Infrastructure', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Procedures', 'Process', 'Quality Control', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Structure', 'Vulnerable Populations', 'Work', 'base', 'clinical risk', 'clinically relevant', 'data archive', 'data warehouse', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository', 'web portal']",NCCIH,WASHINGTON STATE UNIVERSITY,U54,2019,158967,-0.015473216185000669
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs.         PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.            ",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,9776453,U54AT008909,"['Address', 'Archives', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Drug usage', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Infrastructure', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Procedures', 'Process', 'Quality Control', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Structure', 'Vulnerable Populations', 'Work', 'base', 'clinical risk', 'clinically relevant', 'data archive', 'data warehouse', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository', 'web portal']",NCCIH,WASHINGTON STATE UNIVERSITY,U54,2019,2464888,-0.015473216185000669
"Tools for rapid and accurate structure elucidation of natural products Mapping the Secondary Metabolomes of Marine Cyanobacteria Bacteria are extraordinarily prolific sources of structurally unique and biologically active natural products that derive from a diversity of fascinating biochemical pathways. However, the complete structure elucidation of natural products is often the most time consuming and costly endeavor in natural product drug discovery programs. Compounding this, advancements in genome sequencing have accelerated the identification of unique modular biosynthetic gene clusters in prokaryotes and revealed a wealth of new compounds yet to be isolated and biologically and chemically characterized. Resultantly, there is an urgent and continuing need in this field to connect biosynthetic gene clusters to their respective MS fragmentation signatures in the MS2 molecular networks. The capacity to make such connections will accelerate new compound discovery as well as create associations between gene cluster and biosynthetic pathway, and aid in fast and accurate structure elucidations. Combined with this informatics approach, this proposed continuation project explores innovative methods by which to solve complex molecular structures by enhanced MS and NMR experiments, as well as the development of new algorithms by which to accelerate their analysis. Thus, the overarching goal of this grant is to develop efficient methods that facilitate automated structural classification, structural feature discovery and ultimately efficient structure elucidation of natural products (or any small molecule) and to build an infrastructure that interacts with data input from the community. We will achieve this with the following four specific aims: Aim 1. Integration of MS2 molecular networking with gene cluster networking to rapidly and efficiently locate natural products that have unique molecular architectures; Aim 2. To develop a suite of high sensitivity pulse sequences for natural product structure elucidation; Aim 3. To develop NMR based molecular networking strategies using Deep Convolutional Neural Networks (DCNNs) to facilitate the categorization and structure elucidation of organic compounds; Aim 4. To integrate NMR molecular networking and MS2-based molecular networking as an efficient structure characterization and elucidation strategy. By achieving these aims we will develop an innovative workflow for finding new compounds and for determining their structures, both quickly and accurately. The connection between gene cluster and molecule will shed light on stereochemistry and potential halogenations and methylations. This information can then be used in combination with more efficient NMR and MS methods to accurately determine structures. These tools will be widely shared, such as through the Global Natural Products Social (GNPS) Molecular Network, to enhance the overall capacity of the natural products and organic chemistry communities to solve complex molecular structures.   Natural products are compounds produced by natural sources and about 50 % of FDA approved drugs can trace their origin back to natural products. This proposal aims to use our data set of natural products produced by cyanobacteria for development of analytical tools that will speed- up and stream-line the discovery and structure elucidation of new compounds.  ",Tools for rapid and accurate structure elucidation of natural products,9690083,R01GM107550,"['Algae', 'Algorithms', 'Architecture', 'Back', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Chemicals', 'Classification', 'Communities', 'Complex', 'Consumption', 'Cyanobacterium', 'Data', 'Data Set', 'Development', 'FDA approved', 'Family', 'Gene Cluster', 'Genomics', 'Goals', 'Grant', 'Informatics', 'Infrastructure', 'Light', 'Marines', 'Mass Spectrum Analysis', 'Methods', 'Methylation', 'Molecular', 'Molecular Structure', 'Natural Product Drug', 'Natural Products', 'Organic Chemistry', 'Pathway interactions', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Progress Reports', 'Prokaryotic Cells', 'Source', 'Speed', 'Stream', 'Structure', 'Techniques', 'Time', 'analog', 'analytical tool', 'base', 'convolutional neural network', 'cost', 'deep learning', 'drug discovery', 'experimental study', 'fascinate', 'genome sequencing', 'halogenation', 'innovation', 'metabolome', 'novel', 'programs', 'prototype', 'scaffold', 'small molecule', 'social', 'stereochemistry', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,530377,-0.022975238041999104
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9649188,U24DK112331,"['ATAC-seq', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Cost efficiency', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Infrastructure', 'Institutes', 'Knowledge', 'Lead', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'analysis pipeline', 'base', 'bisulfite sequencing', 'data resource', 'epigenomics', 'exercise intervention', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'individual response', 'insight', 'machine learning algorithm', 'medical schools', 'methylome', 'mortality risk', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2019,2593647,-0.015560819001912658
"Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition",9650596,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'machine learning algorithm', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R01,2019,472976,-0.01134044728429158
"Center for Sub-Cellular Genomics A cell is a highly complex system with distributed molecular physiologies in structured sub- cellular compartments whose interplay with the nuclear genome determine the functional characteristics of the cell. A classic example of distributed genomic processes is found in neurons. Learning and memory requires modulation of individual synapses through RNA localization, localized translation, and localized metabolites such as those from dendritic mitochondria. Dendrites of neurons integrate distributed synaptic signals into both electrical and nuclear transcriptional response. Dysfunction of these distributed genomic functions in neurons can result in a broad spectrum of neuropsychiatric diseases such as bipolar and depressive disorders, autism, among others. Understanding complex genomic interactions within a single cell requires new technologies: we need nano-scale ability to make genome-wide measurements at highly localized compartments and to effect highly localized functional genomic manipulations, especially in live tissues. To address this need, we propose to establish a Center for Sub-Cellular Genomics using neurons as model systems. The center will develop new optical and nanotechnology approaches to isolate sub-cellular scale components for genomic, metabolomics, and lipidomic analyses. The center will also develop new mass spectrometry methods, molecular biology methods, and informatics models to create a platform technology for sub-cellular genomics. Many human diseases, especially neuropsychiatric diseases, can be traced to dysfunction of organelles and other sub-cellular components. This project will create novel technologies to study function and dysfunction of sub-cellular processes and apply them to study of neurons.",Center for Sub-Cellular Genomics,9772520,RM1HG010023,"['Address', 'Alzheimer&apos', 's Disease', 'Attention', 'Automobile Driving', 'Awareness', 'Biological Assay', 'Biological Models', 'Bipolar Disorder', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Cellular biology', 'Characteristics', 'Chromatin', 'Communities', 'Complex', 'Data', 'Dendrites', 'Depressive disorder', 'Devices', 'Disease', 'Education and Outreach', 'Educational workshop', 'Functional disorder', 'Genetic Transcription', 'Genome', 'Genomics', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Informatics', 'Institution', 'Investigation', 'Learning', 'Liquid substance', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Memory', 'Mental Depression', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Molecular Biology', 'Motivation', 'Nanotechnology', 'Neurodegenerative Disorders', 'Neurons', 'Nuclear', 'Optical Methods', 'Optics', 'Organelles', 'Output', 'Pathway interactions', 'Phenotype', 'Philadelphia', 'Physiology', 'Process', 'Proteins', 'RNA', 'Regulation', 'Research Project Grants', 'Resolution', 'Risk', 'Rodent', 'Role', 'Schizophrenia', 'Signal Transduction', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Traumatic Brain Injury', 'Variant', 'Work', 'autism spectrum disorder', 'base', 'deep learning', 'epigenomics', 'exosome', 'experience', 'flexibility', 'functional genomics', 'genome-wide', 'human disease', 'informatics\xa0tool', 'macromolecule', 'metabolomics', 'multimodality', 'nanoscale', 'neuropsychiatric disorder', 'new technology', 'novel', 'outreach', 'response', 'subcellular targeting', 'technology development', 'technology validation', 'transcriptome', 'welfare', 'whole genome']",NHGRI,UNIVERSITY OF PENNSYLVANIA,RM1,2019,500000,-0.022357379423709384
"Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties ABSTRACT Mesenchymal stem cells (MSCs) have broad-based potential in regenerative medicine cell therapies and can be isolated from a variety of different tissues. Though MSCs from different tissues are phenotypically similar, a barrier to their clinical use is the high variability of their trophic and regenerative properties. This variability suggests that inherent differences exist in the molecular machinery guiding MSC properties between different MSC populations, yet, to date, these differences are ill-defined. To this end, we have preliminary evidence that MSC phenotypes correlate to their regenerative outcomes. In this study, we aim to elucidate how the molecular and cellular properties of distinct MSC populations determine their regenerative properties. Our hypothesis is that MSCs from different tissues have different regenerative properties which correlate to specific molecular profiles defined by gene expression and transcriptional activity. To test this hypothesis, the project proposed has three Specific Aims (SAs). In SA1, we will determine how tissue-specificity dictates gene expression and dynamic transcription factor activity of distinct MSCs. SA2 will determine how differences in the cellular and molecular properties of MSCs correlate to MSC phenotype. Finally, in SA3, we will determine how the molecular profiles and cellular activities of MSCs dictate their regenerative properties. Findings of the proposed study will provide novel insights about how the distinct molecular profiles of MSCs dictate their biological and physiological properties. In a therapeutic context, this would enable the development of innovative screening technologies for MSC therapies to identify and enrich for the most appropriate MSC for the specific therapeutic application. PROPOSAL NARRATIVE Stem cell therapies are emerging as a new treatment approach to regenerate lost tissues, treat ischemic disorders, and treat chronic inflammatory conditions. Many of these approaches use stem cells from adults which are present in various regions throughout the body. Our research team is working to better understand how and why these adult stem cells behave the way they do so that we can better determine how to use them in different therapies to treat debilitating health conditions.",Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties,9835275,R01DE028657,"['Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Angiogenic Factor', 'Automobile Driving', 'Biological', 'Biological Process', 'Bone Marrow', 'Bone Regeneration', 'Bone Tissue', 'Cell Culture Techniques', 'Cell Separation', 'Cell Therapy', 'Cells', 'Chronic', 'Clinical', 'Clinical Trials', 'Computer Simulation', 'Data', 'Dental', 'Dental Pulp', 'Development', 'Disease', 'ENG gene', 'Emerging Technologies', 'Fatty acid glycerol esters', 'Funding Mechanisms', 'Gene Expression', 'Gene Expression Profile', 'Genetic Transcription', 'Gingiva', 'Health', 'Immunophenotyping', 'Inflammation', 'Inflammatory', 'Knowledge', 'Link', 'Maintenance', 'Mesenchymal Stem Cells', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Muscle', 'Natural regeneration', 'Operative Surgical Procedures', 'Oral', 'Osteogenesis', 'Outcome', 'Pathway interactions', 'Performance', 'Phenotype', 'Physiological', 'Population', 'Population Heterogeneity', 'Production', 'Property', 'Regenerative Medicine', 'Regulation', 'Reporting', 'Research', 'Rodent Model', 'Role', 'Signal Pathway', 'Sorting - Cell Movement', 'Specificity', 'Stem cells', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Tooth structure', 'United States National Institutes of Health', 'Work', 'adult stem cell', 'alveolar bone', 'angiogenesis', 'base', 'bone', 'clinical translation', 'healthy volunteer', 'in vivo', 'innovation', 'insight', 'interest', 'machine learning algorithm', 'molecular phenotype', 'next generation sequencing', 'novel', 'oral tissue', 'osteogenic', 'population based', 'regenerative', 'regenerative therapy', 'screening', 'self-renewal', 'stem cell differentiation', 'stem cell population', 'stem cell therapy', 'stemness', 'transcription factor', 'transcriptome']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,398630,-0.03311920471056417
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,9573854,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2018,388750,0.006199432394427103
"Machine Learning for Generalized Multiscale Modeling Project Summary/Abstract  This project develops machine learning approaches that describe statistical systems in biology. By combining analytic results calculated from the exact probabilistic description of the system with machine learning inference, our new methods present exciting opportunities to model previously inaccessible complex dynamics. The resulting Boltzmann machine-like learning algorithms present a new class of modeling techniques based on the powerful in- ference of arti cial neural networks. Further development of this approach will bring the groundbreaking advances from the surge of recent interest in machine learning into the biological modeling eld. The mathematical methods we develop will be used to derive e cient algorithms for multiscale simulation, directly applicable to large scale biological modeling. In particular, the algorithms will be used to study the dynamics of stochastic biochemistry at synapses, with direct relevance to learning and memory formation in the brain. Current studies of these processes are limited by the long timescales involved and the highly spatially organized structures featured. In addition to leveraging the machine learning expertise we are developing, we also employ new electron microscopy datasets to produce 3D reconstructions of neural tissue with unprecedented accuracy. Consequentially, we will be able to study the fundamental mechanisms underlying synaptic plasticity, as well as the biochemical basis of oscillatory behavior in networks of neurons that occurs during sleep. Furthermore, the interactions of these highly stochastic ion channels with electrical in neurons will be explored through groundbreaking hybrid simulation environments. The software that we will develop combines existing popular simulation tools into multiscale approaches, and will be distributed as a powerful tool to the broader biological modeling community. Its usage in further computational experiments can present a key advancement in the development of pharmaceuticals, allowing the direct study of the interactions of biochemistry and whole neuron electrophysiology without making limiting assumptions to sim- plify the simulations. This has promising implications for intervening in age-related learning de cits, as well as in neurological disorders such as Alzheimers. Finally, this proposal will bring together our existing multiscale modeling community, the National Center for Multi-scale Modeling of Biological Systems (MMBioS), with the MSM consortium. The interactions of these organizations and their communities of expert researchers will foster new collaborative work on exciting multiscale problems in biology, including applications of the machine learning frameworks and software we are developing. 1 Project Narrative  A wide variety of biological systems can be described statistically, from molecular biochemistry up to the network level activity of neurons. This work develops machine learning approaches to approximate these systems, enabling new simulation methods that bridge di erent levels of description. The resulting computational studies aim to shed light on the basis of learning and computation in the brain, and will enable the development of pharmaceutical targets for learning de cits associated with aging and neurological disorders such as Alzheimers. 1",Machine Learning for Generalized Multiscale Modeling,9791802,R56AG059602,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Area', 'Behavior', 'Biochemical', 'Biochemistry', 'Biological Models', 'Biological Neural Networks', 'Biology', 'Brain', 'Calcium', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consequentialism', 'Coupling', 'Data Set', 'Development', 'Dimensions', 'Electron Microscopy', 'Electrophysiology (science)', 'Environment', 'Equation', 'Equilibrium', 'Evolution', 'Fostering', 'Hybrids', 'Image', 'Investigation', 'Ion Channel', 'Learning', 'Libraries', 'Light', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'National Institute of General Medical Sciences', 'Neurons', 'Neuropil', 'Neurosciences', 'Pharmacologic Substance', 'Physics', 'Population', 'Potassium Channel', 'Process', 'Pythons', 'Reaction', 'Research Personnel', 'Sleep', 'Structure', 'Synapses', 'Synaptic plasticity', 'System', 'Techniques', 'Time', 'Tissues', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'age related', 'base', 'biological systems', 'calmodulin-dependent protein kinase II', 'computer studies', 'experimental study', 'information processing', 'insight', 'interest', 'mathematical methods', 'men who have sex with men', 'microscopic imaging', 'multi-scale modeling', 'nervous system disorder', 'particle', 'postsynaptic', 'reconstruction', 'relating to nervous system', 'simulation', 'software development', 'success', 'tool', 'working group']",NIA,UNIVERSITY OF CALIFORNIA-IRVINE,R56,2018,619053,-0.00021429556651096667
"A Modular Automated Platform for Large-scale Drosophila Experiments and Handling PROJECT SUMMARY / ABSTRACT Animal model systems are a powerful tool researchers use to investigate almost all aspects of biology: genetics, development, neuroscience, disease, and more. And fruit flies – Drosophila melanogaster – with their small size, easy care, and remarkable array of available genetic toolkits, occupy a sweet spot on the model organism spectrum. Over 75% of human diseases with a genetic basis have an analogue in the fly, and Drosophila have been a part of the research for six Nobel prizes. Furthermore, the advent of CRISPR/cas9 and other modern genetic tools has opened the door to modeling other diseases and pathways, leading to greater use of Drosophila for drug screens. A great deal of the work (and the majority of the budget) involved in fly experiments is tedious manual labor, and with advances in computer vision, machine learning, and other analytic techniques, the stage is set to automate many phenotypic screens. In this Phase I SBIR, we propose a robotic system – modular automated platform for large-scale experiments (MAPLE) – that can accomplish a wide variety of fly-handling tasks in Drosophila labs. This robot is the fruit fly version of a liquid handling robot, with a large, open workspace that can house a plethora of modules and several manipulators that can move small parts and animals around that workspace. Building on a collaboration between the de Bivort Lab and FlySorter completed in 2017, we will design, fabricate and validate a commercial system that can collect virgin flies, run behavioral assays, conduct drug screens, and adapt to the needs of fly labs through easy-to-code Python scripts. By strategically combining modules and instructions to the robot, MAPLE can perform a wide variety of tasks in a fly lab, saving experimentalists from repetitive chores, cutting labor costs, and increasing scientific output. Just as pipette robots have become standard equipment in wet labs, we envision our fly handling robot will be the engine that powers Drosophila labs in academia and pharma, enabling new kinds of experiments and freeing researchers from the drudgery of fly pushing. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are a powerful model organism used in the study of disease, neuroscience, development, genetics, and recently in drug screens, too, largely through phenotypic screening. This labor-intensive work is time consuming and expensive, and ripe for automation. We propose a fly-handling robot – analogous to a liquid pipetting robot in a wet lab – that can perform a variety of tasks in Drosophila labs, free researchers from the drudgery of fly pushing, and enable a broader spectrum of experiments that will increase scientific knowledge.",A Modular Automated Platform for Large-scale Drosophila Experiments and Handling,9623017,R43MH119092,"['Academia', 'Address', 'Affect', 'Air', 'Anesthesia procedures', 'Animal Model', 'Animals', 'Architecture', 'Automation', 'Basic Science', 'Behavior', 'Behavioral Assay', 'Biological Models', 'Biology', 'Budgets', 'CRISPR/Cas technology', 'Carbon Dioxide', 'Caring', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Data Collection', 'Deposition', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Screening', 'Drug usage', 'Ensure', 'Equipment', 'Feedback', 'Genetic', 'Genetic Screening', 'Genetic study', 'Grant', 'Hand', 'Human', 'Instruction', 'Knowledge', 'Libraries', 'Liquid substance', 'Machine Learning', 'Manuals', 'Modeling', 'Modernization', 'Neurosciences', 'Nobel Prize', 'Organism', 'Output', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Protocols documentation', 'Pythons', 'Reagent', 'Research', 'Research Personnel', 'Robot', 'Robotics', 'Running', 'Savings', 'Scanning', 'Small Business Innovation Research Grant', 'Speed', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Transgenic Organisms', 'Travel', 'Universities', 'Update', 'Vacuum', 'Work', 'analog', 'bone', 'cost', 'design', 'drug discovery', 'experimental study', 'flexibility', 'fly', 'graduate student', 'health science research', 'human disease', 'improved', 'operation', 'programs', 'repository', 'robot control', 'screening', 'tool', 'touchscreen']",NIMH,"FLYSORTER, LLC",R43,2018,348007,-0.025634296235288383
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9543557,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,264277,-0.016037481156380606
"Bayesian Machine Learning Tools for Analyzing Microbiome Dynamics The human microbiota plays an important role in health and disease, and its therapeutic manipulation is being actively investigated for a wide range of diseases that span every NIH institute. Our microbiota are inherently dynamic, and analyzing these time-dependent properties is key to robustly linking the microbiota to disease, and predicting the effects of therapies targeting the microbiota; indeed, longitudinal microbiome data is being acquired with increasing frequency, and is a major component of many NIH-funded projects. However, there is currently a dearth of computational tools for analyzing microbiome time-series data, which presents several special challenges including high measurement noise, irregular and sparse temporal sampling, and complex dependencies between variables. The objective of this proposal is to introduce new capabilities, improve on, and provide state-of-the-art implementations of tools for analyzing dynamics, or patterns of change in microbiome time-series data. The tools we develop will use Bayesian machine learning methods, which are well-recognized for their strong conceptual and practical advantages, particularly in biomedical domains. Tools will be rigorously tested and validated on synthetic and real human microbiome data, including publicly available datasets and those from collaborators providing 16S rRNA sequencing, metagenomic, and metabolomics data. We propose three specific aims. For Aim 1, we will develop integrated Bayesian machine learning tools for predicting population dynamics of the microbiome and its responses to perturbations. These tools will include a new model that simultaneously learns groups of microbes with similar interaction structure and predicts their behavior over time, and that incorporates prior phylogenetic information. The model will be further improved by incorporating stochastic microbial dynamics and errors in measurements throughout the model. For Aim 2, we will develop Bayesian machine learning tools to predict host status from microbiome dynamics. The tools will learn easily interpretable, human-readable rules that predict host status from microbiome time-series data, and will be further extended to handle a variety of longitudinal study designs. For Aim 3, we will engineer our microbiome dynamics analysis software tools for optimal performance, ease-of- use, maintainability, extensibility, and dissemination to the community. In total, the proposed work will yield a suite of contemporary software tools for analyzing microbiome dynamics, with expected broad use and major impact. The software will allow investigators to answer important scientific and translational questions about the microbiome, including discovering which microbial taxa or their metagenomes are affected over time by perturbations such as changes in diet or invasion by pathogens; predicting the effects of these perturbations over time, including changes in composition or stability of the gut microbiota; and finding temporal signatures in multi-‘omic microbiome data that predict disease risk in the human host. The human microbiota, or collection of micro-organisms living on and within us, plays an important role in health, and when disrupted or abnormal, may contribute to many types of diseases including infections, kidney diseases, bowel diseases, diabetes, heart diseases, arthritis, allergies, brain diseases, and cancer. Sophisticated computer-based tools are needed to make sense of human microbiota data, particularly time- series data, which can yield important insights into how our microbiomes change over time. This work will develop new and improved computer-based tools for analyzing microbiota time-series data, which will be made freely available and will enable scientists to increase our fundamental knowledge about how our microbiota affect us and ultimately to apply this knowledge to prevent and treat human illnesses.",Bayesian Machine Learning Tools for Analyzing Microbiome Dynamics,9640012,R01GM130777,"['16S ribosomal RNA sequencing', 'Affect', 'Algorithms', 'Antibiotics', 'Arthritis', 'Autoimmunity', 'Behavior', 'Biological Markers', 'Biological Models', 'Brain Diseases', 'Cardiovascular Diseases', 'Childhood', 'Clostridium difficile', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Set', 'Dependence', 'Diabetes Mellitus', 'Diet', 'Disease', 'Engineering', 'Environmental Exposure', 'Frequencies', 'Funding', 'Health', 'Heart Diseases', 'Human', 'Human Microbiome', 'Hypersensitivity', 'Infection', 'Institutes', 'Intervention', 'Intestines', 'Investigation', 'Kidney Diseases', 'Knowledge', 'Learning', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical', 'Metagenomics', 'Microbe', 'Modeling', 'Names', 'Noise', 'Oligosaccharides', 'Outcome', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Play', 'Population Dynamics', 'Property', 'Pythons', 'Readability', 'Recurrence', 'Research Design', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Series', 'Shotguns', 'Software Engineering', 'Software Tools', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Work', 'base', 'computerized tools', 'design', 'disorder risk', 'dynamic system', 'gut microbiota', 'human data', 'human microbiota', 'human subject', 'improved', 'insight', 'learning strategy', 'man', 'metabolomics', 'metagenome', 'microbial', 'microbiome', 'microbiome analysis', 'microbiome sequencing', 'microbiota', 'microorganism', 'multiple omics', 'nervous system disorder', 'novel', 'open source', 'pathogen', 'predictive tools', 'prevent', 'response', 'software development', 'targeted treatment', 'tool']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R01,2018,327382,0.015329395905026993
"Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data Big data is now ubiquitous in every field of modern scientific research. Many contemporary applications, such as the recent national microbiome initiative (NMI), greatly demand highly flexible statistical machine learning methods that can produce both interpretable and reproducible results. Thus, it is of paramount importance to identify crucial causal factors that are responsible for the response from a large number of available covariates, which can be statistically formulated as the false discovery rate (FDR) control in general high-dimensional nonlinear models. Despite the enormous applications of shotgun metagenomic studies, most existing investigations concentrate on the study of bacterial organisms. However, viruses and virus-host interactions play important roles in controlling the functions of the microbial communities. In addition, viruses have been shown to be associated with complex diseases. Yet, investigations into the roles of viruses in human diseases are significantly underdeveloped. The objective of this proposal is to develop mathematically rigorous and computationally efficient approaches to deal with highly complex big data and the applications of these approaches to solve fundamental and important biological and biomedical problems. There are four interrelated aims. In Aim 1, we will theoretically investigate the power of the recently proposed model-free knockoffs (MFK) procedure, which has been theoretically justified to control FDR in arbitrary models and arbitrary dimensions. We will also theoretically justify the robustness of MFK with respect to the misspecification of covariate distribution. These studies will lay the foundations for our developments in other aims. In Aim 2, we will develop deep learning approaches to predict viral contigs with higher accuracy, integrate our new algorithm with MFK to achieve FDR control for virus motif discovery, and investigate the power and robustness of our new procedure. In Aim 3, we will take into account the virus-host motif interactions and adapt our algorithms and theories in Aim 2 for predicting virus-host infectious interaction status. In Aim 4, we will apply the developed methods from the first three aims to analyze the shotgun metagenomics data sets in ExperimentHub to identify viruses and virus-host interactions associated with several diseases at some target FDR level. Both the algorithms and results will be disseminated through the web. The results from this study will be important for metagenomics studies under a variety of environments. Big data is ubiquitous in biological research. Identifying causal factors associated with complex diseases or traits from big data is highly important and challenging. New statistical and computational tools will be developed to control False Discovery Rate (FDR) for molecular sequence data based on the novel model-free knockoffs framework. They will be used to detect sequence motifs for viruses and motif-pairs for virus-host interactions, and to analyze multiple metagenomics data sets related to complex diseases.",Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data,9674585,R01GM131407,"['Address', 'Algorithms', 'Archaea', 'Attention', 'Bacteria', 'Big Data', 'Biological', 'Bypass', 'Cells', 'Colorectal Cancer', 'Complex', 'Computer software', 'Consult', 'Coupled', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Effectiveness', 'Environment', 'Foundations', 'Frequencies', 'Gaussian model', 'Genes', 'Genetic Materials', 'Genomics', 'Healthcare', 'Human', 'Internet', 'Investigation', 'Joints', 'Length', 'Linear Regressions', 'Literature', 'Liver Cirrhosis', 'Machine Learning', 'Marines', 'Mathematics', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Sequence Data', 'Mutation', 'Neurosciences', 'Non-Insulin-Dependent Diabetes Mellitus', 'Non-linear Models', 'Obesity', 'Organism', 'Performance', 'Planet Earth', 'Play', 'Procedures', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Sampling Studies', 'Shotguns', 'Social Sciences', 'Testing', 'Theoretical Studies', 'Tissues', 'Training', 'Viral', 'Virus', 'Visualization software', 'Work', 'base', 'biological research', 'computerized tools', 'dark matter', 'deep learning', 'design', 'flexibility', 'high dimensionality', 'human disease', 'human tissue', 'improved', 'interest', 'learning strategy', 'metagenomic sequencing', 'microbial community', 'microbiome', 'microbiome research', 'model design', 'model development', 'new technology', 'novel', 'power analysis', 'response', 'simulation', 'theories', 'trait', 'user-friendly', 'virus host interaction', 'virus identification']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,289700,0.0020086665593188288
"Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach Project Summary Biology is full of stunning examples of emergent behaviors – behaviors that arise from, but cannot be reduced to, the interactions of the constituent parts that make up the system under consideration. These behaviors span the full spectrum of length scales, from the emergence of distinct cell fates (e.g. neurons, muscle, etc.) due to the interactions of genes within cells, to the formation of complex ecological communities arising from the interactions of thousands of species. The overarching goal of my research is to develop new conceptual, theoretical, and computational tools to model such emergent, system-level behaviors in biology. To do so, we utilize an interdisciplinary approach that is grounded in Biological Physics, but draws heavily from Machine Learning, Information Theory, and Theoretical Ecology. Our work is unified and distinguished by our deep commitment to integrating theory with the vast amount of biological data now being generated by modern DNA sequencing-based techniques and quantitative microscopy. An important goal of the proposed research is to find common concepts and tools that transcend traditional biological sub-disciplines and models systems. The proposed research pursues four distinct but conceptually interrelated research directions: (1) understanding how distinct cell fates emerge from bimolecular interactions within mammalian cells (2) investigating how bimolecular networks within cells exploit energy consumption to improve computations, with applications to Synthetic Biology; (3) identifying the ecological principles governing community assembly in microbial communities and developing techniques for synthetically engineering ecological communities; and (4) developing new machine learning algorithms and techniques for biological data analysis. In addition to developing physics-based models for diverse biological phenomena, the proposed research will yield a series of practical important tools and algorithms which we will make publically available including: (1) a new linear-algebra based algorithm for assessing the fidelity of directed differentiation and cellular reprogramming protocols and visualizing reprogramming/differentiation dynamics and (2) improved algorithms for inferring microbial interactions in the human microbiome from high-throughput sequence data. These computational tools will allow scientists to realize the immense therapeutic potential of cellular reprogramming and microbial ecology-based techniques for studying and treating human disease. Project Narrative This project will develop new theoretical and computational tools that will allow scientists to realize the immense therapeutic potential of cellular reprogramming (the conversion of one cell type into another cell type) and microbial ecology-based techniques for studying and treating human diseases.",Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach,9507677,R35GM119461,"['Algorithms', 'Behavior', 'Biological', 'Biological Models', 'Biological Phenomena', 'Biology', 'Cells', 'Communities', 'Complex', 'Consumption', 'DNA sequencing', 'Data', 'Data Analyses', 'Discipline', 'Ecology', 'Engineering', 'Goals', 'Human Microbiome', 'Information Theory', 'Length', 'Linear Algebra', 'Machine Learning', 'Mammalian Cell', 'Modeling', 'Modernization', 'Muscle', 'Neurons', 'Physics', 'Protocols documentation', 'Quantitative Microscopy', 'Research', 'Scientist', 'Series', 'System', 'Systems Biology', 'Techniques', 'Therapeutic', 'Transcend', 'Work', 'base', 'cell type', 'computerized tools', 'gene interaction', 'human disease', 'improved', 'interdisciplinary approach', 'microbial', 'microbial community', 'microorganism interaction', 'synthetic biology', 'theories', 'tool']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2018,316544,-0.011384054376679578
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9530668,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'predictive modeling', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2018,584485,0.018909860294231837
"Reproducible Analytics for Secondary Analyses of ImmPort Vaccination-Related Cytometry Data Project Summary The immunology database and analysis portal (ImmPort, http://immport.niaid.nih.gov) is the NIAID-funded public resource for data archive and dissemination from clinical trials and mechanistic research projects. Among the current 291 studies archived in ImmPort, 114 are focused on vaccine responses (91 for influenza vaccine responses), which is the largest category when organized by research focus. As the most effective method of preventing infectious diseases, development of the next-generation vaccines is faced with the bottleneck that traditional empirical design becomes ineffective to stimulate human protective immunity against HIV, RSV, CMV, and other recent major public health threats. This project will focus on three important aspects of informatics approaches to secondary analysis of ImmPort data for influenza vaccination research: a) expanding the data analytical capabilities of ImmPort and ImmPortGalaxy through adding innovative computational methods for user-friendly unsupervised identification of cell populations, b) processing and analyzing a subset of the existing human influenza vaccination study data in ImmPort to identify cell-based biomarkers using the new computational methods, and c) returning data analysis results with data analytical provenance to ImmPort for dissemination of derived data, software tools, as well as semantic assertions of the identified biomarkers. Each aspect is one specific research aim in the proposed work. The project outcome will not only demonstrate the utility of the ImmPort data archive but also generate a foundation for the Human Vaccine Project (HVP) to establish pilot programs for influenza vaccine research, which currently include Vanderbilt University Medical Center; University of California San Diego (UCSD); Scripps Research Institute; La Jolla Institute of Allergy and Immunology; and J. Craig Venter Institute (JCVI). Once such computational analytical workflow is established, it can be applied to the secondary analysis of other ImmPort studies as well as to support the user-driven analytics of their own cytometry data. Each of the specific aims contains innovative methods or new applications of the existing methods. The computational method for population identification in Aim 1 is a newly developed constrained data clustering method, which combines advantages of unsupervised and supervised learning. Cutting-edge machine learning approaches including random forest will be used in Aim 2 for the identification of biomarkers across study cohorts, in addition to the traditional statistical hypothesis testing. Standardized knowledge representation to be developed in Aim 3 for cell-based biomarkers is also innovative, as semantic networks with inferring and deriving capabilities can be built based on the machine-readable knowledge assertions. The proposed work, when accomplished, will foster broader collaboration between ImmPort and the existing vaccine research consortia. It will also accelerate the deployment of up-to-date informatics software tools on ImmPortGalaxy. Project Narrative Flow cytometry (FCM) plays important roles in human influenza vaccination studies through interrogating immune cellular functions and quantifying the immune responses in different conditions. This project will extend the current data analytical capabilities of the Immunology Database and Analysis Portal (ImmPort) through adding novel data analytical methods and software tools for user-friendly identification of cell populations from FCM data in ImmPort influenza vaccine response studies. The derived data and the knowledge generated from the secondary analysis of the ImmPort vaccination study data will be deposited back to ImmPort and shared with the Human Vaccines Project (HVP) consortium for dissemination.",Reproducible Analytics for Secondary Analyses of ImmPort Vaccination-Related Cytometry Data,9577591,UH2AI132342,"['Academic Medical Centers', 'Address', 'Archives', 'Back', 'Biological Markers', 'California', 'Categories', 'Cells', 'Characteristics', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer Analysis', 'Computing Methodologies', 'Cytomegalovirus', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Databases', 'Deposition', 'Development', 'Disease', 'Failure', 'Flow Cytometry', 'Fostering', 'Foundations', 'Funding', 'Genetic Transcription', 'HIV', 'Human', 'Hypersensitivity', 'Imagery', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunology', 'Incidence', 'Influenza', 'Influenza vaccination', 'Informatics', 'Institutes', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Maps', 'Measles', 'Medical', 'Meta-Analysis', 'Metadata', 'Methods', 'Mumps', 'Names', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Play', 'Poliomyelitis', 'Population', 'Population Statistics', 'Prevalence', 'Prevention strategy', 'Process', 'Public Health', 'Readability', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Institute', 'Research Project Grants', 'Respiratory Syncytial Virus Vaccines', 'Respiratory syncytial virus', 'Role', 'Secondary to', 'Semantics', 'Smallpox', 'Software Tools', 'Source', 'Standardization', 'Supervision', 'Technology', 'Testing', 'Therapeutic', 'Universities', 'Vaccination', 'Vaccine Design', 'Vaccine Research', 'Vaccines', 'Work', 'analytical method', 'base', 'biomarker discovery', 'biomarker identification', 'catalyst', 'cohort', 'comparative', 'computer infrastructure', 'computerized tools', 'data archive', 'data mining', 'data portal', 'data resource', 'design', 'experience', 'experimental study', 'forest', 'immune function', 'improved', 'influenza virus vaccine', 'information organization', 'innovation', 'neoplastic', 'news', 'novel', 'novel strategies', 'novel vaccines', 'prevent', 'programs', 'public-private partnership', 'response', 'response biomarker', 'secondary analysis', 'statistics', 'success', 'tool', 'user-friendly', 'vaccine development', 'vaccine response', 'vaccine trial', 'vaccine-induced immunity']",NIAID,"J. CRAIG VENTER INSTITUTE, INC.",UH2,2018,243750,-0.01343498468642556
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9579149,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2018,314000,-0.01053293752745621
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9451318,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2018,1354554,0.019443859235429715
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design Our Vision: We propose DeepLink, a versatile data translator that integrate multi-scale, heterogeneous, and multi-source biomedical and clinical data. The primary goal of DeepLink is to enable meaningful bidirectional translation between clinical and molecular science by closing the interoperability gap between models and knowledge at different scales. The translator will enhance clinical science with molecular insights from basic and translational research (e.g. genetic variants, protein interactions, pathway functions, and cellular organization), and enable the molecular sciences by connecting biological discoveries with their pathophysiological consequences (e.g. diseases, signs and symptoms, pharmacological effects, physiological systems). Fundamental differences in the language and semantics used to describe the models and knowledge between the clinical and molecular domains results in an interoperability gap. DeepLink will systematically and comprehensively close this gap. We will begin with the latest technology in semantic knowledge graphs to support an extensible architecture for dynamic data federation and knowledge harmonization. We will design a system for multi-scale model integration that is ontology-based and will combine model execution with prior, curated biomedical knowledge. Our design strategy will be iterative and participatory and anchored by 10 major milestones. In a series of demonstrations of DeepLink’s functions, we will address one of the major challenges facing translational science: reproducibility of biomedical research findings that are based on evolving molecular datasets. Reproducibility of analyses and replication of results are central to scientific advancement. Many landmark studies have used data that are constantly being updated, curated, and pared down over time. Our series of demonstrations projects are designed to prototype the technology required for a scalable and robust translator as well as the techniques we will use to close the interoperability gap for a specific use case. The demonstration project will, itself, will be a significant and novel contribution to science. DeepLink will be able to answer questions that are currently enigmatic. Examples include: - From clinicians: What is the comparative effectiveness of all the treatments for disease Y given a patient's genetic/metabolic/proteomic profile? What are the functional variants in cell type X that are associated with differential treatment outcomes? What metabolite perturbations in cell type Y are associated with different subtypes of disease X? - From basic science researchers: What is known about disease Y across all model organisms (even those not designed to model Y)? What are all the clinical phenotypes that result from a change in function in protein X? Which biological pathways are affected by a pathogenic variant of disease Y? What patient data are available to evaluate a molecularlyderived clinical hypothesis? Challenges and Our Approaches: DeepLink will close the interoperability gap that currently prohibits molecular discoveries from leading to clinical innovations. DeepLink will be technologically driven, addressing the challenges associated with large, heterogeneous, semantically ambiguous, continuously changing, partially overlapping, and contextually dependent data by using (1) scalable, distributed, and versioned graph stores; (2) semantic technologies such as ontologies and Linked Data; (3) network analysis quality control methods; (4) machine-learning focused data fusion methods; (5) context-aware text mining, entity recognition and relation extraction; (6) multi-scale knowledge discovery using patient and molecular data; and (7) presentation of actionable knowledge to clinicians and basic scientists via user-friendly interfaces. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9635840,OT3TR002027,"['Address', 'Affect', 'Animal Model', 'Architecture', 'Awareness', 'Basic Science', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Data', 'Data Set', 'Disease', 'Genetic', 'Goals', 'Graph', 'Knowledge', 'Knowledge Discovery', 'Language', 'Link', 'Machine Learning', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Pathogenicity', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pharmacology', 'Physiological', 'Proteins', 'Proteomics', 'Quality Control', 'Reproducibility', 'Research Personnel', 'Science', 'Scientist', 'Semantics', 'Series', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'Treatment outcome', 'Update', 'Variant', 'Vision', 'base', 'cell type', 'clinical phenotype', 'comparative effectiveness', 'design', 'disorder subtype', 'genetic variant', 'innovation', 'insight', 'interoperability', 'molecular domain', 'multi-scale modeling', 'novel', 'prototype', 'text searching', 'user-friendly']",NCATS,COLUMBIA UNIVERSITY HEALTH SCIENCES,OT3,2018,854309,-0.03314015309472689
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9406318,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cancer Etiology', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2018,356625,-0.017877975374573828
"Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Summary: Viruses are ubiquitous in almost every ecological environment including the human body, water, soil, etc. They play important roles in the normal function of human microbiome. Many viruses have been shown to be associated with human diseases. However, our understanding of the roles of viruses in ecological communities is very limited. Recent technological and computational advances make it possible to have a deep understanding of the roles of viruses in public health and the environment. Metagenomics studies from various environments including the human microbiome projects (HMP), global ocean, and the earth microbiome projects have generated large amounts of short read data. Viruses are present in most of these metagenomic data sets and their hosts are unknown. In this proposal, the investigators will develop computational approaches for the identification of viral sequences from metagenomic data sets and for the study of virus-host interactions. For the identification of viral sequences from metagenomics samples, novel statistical measures using word patterns will first be developed. Second, a unified naïve Bayesian integrative approach by combining information from word patterns, gene directionality, and gene annotation will be studied. Third, the identified viral sequences from metagenomes will be further assembled to construct complete viral genomes using a novel binning approach to be developed by the investigators. Finally, the remaining reads will be assigned to the corresponding bins. For the study of virus- host interactions, computational methods to estimate the reliability of virus-host interactions from high-throughput experiments will first be developed. Then machine learning approaches will be developed to predict viruses infecting certain hosts. Finally, a network logistic regression approach will be developed to predict virus-host interactions. These computational approaches for the identification of viral sequences and for predicting virus-host interactions will be applied to a public liver cirrhosis and a unique metagenomics data set to understand how metagenomes change with health status, identify viruses and virus-host interactions associated with disease status and accurately predict disease status using bacteria, viruses and virus-host interactions. The developed computational methods will also be used to analyze metageomic data from various locations based on the TARA ocean data and a unique time series data to understand how environmental factors affect virus abundance and virus-host interactions. Some of the predictions will be experimentally validated. Software derived from the proposal will be developed and freely distributed to the scientific community. Project Narrative Viruses are abundant in many environments and are important to public health. New statistical and computational tools will be developed for the identification of viral sequences from metagenomics samples and for the prediction of virus-host interactions. These tools will be used to analyze microbial data sets related to liver cirrhosis and travelers’ diarrhea as well as marine metagenomics data sets from various geographic locations and time series.",Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications,9465505,R01GM120624,"['Affect', 'Bacteria', 'Biological', 'Body Water', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Environment', 'Environment and Public Health', 'Environmental Risk Factor', 'Functional disorder', 'Genes', 'Genome', 'Geographic Locations', 'Health', 'Health Status', 'Human', 'Human Microbiome', 'Human body', 'Liver Cirrhosis', 'Location', 'Logistic Regressions', 'Machine Learning', 'Marines', 'Measures', 'Metagenomics', 'Methods', 'Microbe', 'Network-based', 'Oceans', 'Organism', 'Pattern', 'Planet Earth', 'Play', 'Policies', 'Public Health', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Series', 'Soil', 'Technology', 'Time', 'Traveler&apos', 's diarrhea', 'Viral', 'Viral Genome', 'Virus', 'Virus Diseases', 'Visualization software', 'base', 'computer studies', 'computerized tools', 'design', 'experimental study', 'gut metagenome', 'human disease', 'interest', 'metagenome', 'microbial', 'microbial community', 'microbiome', 'novel', 'particle', 'statistics', 'tool', 'user-friendly', 'virus host interaction']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,375463,0.02105506451195426
"Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Summary: Viruses are ubiquitous in almost every ecological environment including the human body, water, soil, etc. They play important roles in the normal function of human microbiome. Many viruses have been shown to be associated with human diseases. However, our understanding of the roles of viruses in ecological communities is very limited. Recent technological and computational advances make it possible to have a deep understanding of the roles of viruses in public health and the environment. Metagenomics studies from various environments including the human microbiome projects (HMP), global ocean, and the earth microbiome projects have generated large amounts of short read data. Viruses are present in most of these metagenomic data sets and their hosts are unknown. In this proposal, the investigators will develop computational approaches for the identification of viral sequences from metagenomic data sets and for the study of virus-host interactions. For the identification of viral sequences from metagenomics samples, novel statistical measures using word patterns will first be developed. Second, a unified naïve Bayesian integrative approach by combining information from word patterns, gene directionality, and gene annotation will be studied. Third, the identified viral sequences from metagenomes will be further assembled to construct complete viral genomes using a novel binning approach to be developed by the investigators. Finally, the remaining reads will be assigned to the corresponding bins. For the study of virus- host interactions, computational methods to estimate the reliability of virus-host interactions from high-throughput experiments will first be developed. Then machine learning approaches will be developed to predict viruses infecting certain hosts. Finally, a network logistic regression approach will be developed to predict virus-host interactions. These computational approaches for the identification of viral sequences and for predicting virus-host interactions will be applied to a public liver cirrhosis and a unique metagenomics data set to understand how metagenomes change with health status, identify viruses and virus-host interactions associated with disease status and accurately predict disease status using bacteria, viruses and virus-host interactions. The developed computational methods will also be used to analyze metageomic data from various locations based on the TARA ocean data and a unique time series data to understand how environmental factors affect virus abundance and virus-host interactions. Some of the predictions will be experimentally validated. Software derived from the proposal will be developed and freely distributed to the scientific community. Project Narrative Viruses are abundant in many environments and are important to public health. New statistical and computational tools will be developed for the identification of viral sequences from metagenomics samples and for the prediction of virus-host interactions. These tools will be used to analyze microbial data sets related to liver cirrhosis and travelers’ diarrhea as well as marine metagenomics data sets from various geographic locations and time series.",Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications,9704539,R01GM120624,"['Affect', 'Bacteria', 'Biological', 'Body Water', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Environment', 'Environment and Public Health', 'Environmental Risk Factor', 'Functional disorder', 'Genes', 'Genome', 'Geographic Locations', 'Health', 'Health Status', 'Human', 'Human Microbiome', 'Human body', 'Liver Cirrhosis', 'Location', 'Logistic Regressions', 'Machine Learning', 'Marines', 'Measures', 'Metagenomics', 'Methods', 'Microbe', 'Network-based', 'Oceans', 'Organism', 'Pattern', 'Planet Earth', 'Play', 'Policies', 'Public Health', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Series', 'Soil', 'Technology', 'Time', 'Traveler&apos', 's diarrhea', 'Viral', 'Viral Genome', 'Virus', 'Virus Diseases', 'Visualization software', 'base', 'computer studies', 'computerized tools', 'design', 'experimental study', 'gut metagenome', 'human disease', 'interest', 'metagenome', 'microbial', 'microbial community', 'microbiome', 'novel', 'particle', 'statistics', 'tool', 'user-friendly', 'virus host interaction']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,57657,0.02105506451195426
"Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria Project Summary/Abstract Fungal and bacterial pathogens are a major threat to human health. Few therapeutics exist to treat fungal infections while bacteria are becoming increasingly resistant to existing therapeutics. Humans have been using natural products to treat infections for thousands of years, long before the causal agents of infection were understood. Natural products have continued to be used as therapeutics in the modern age of medicine. Rates of rediscovery of known natural products have increased in traditional sources of natural products, such as soil bacteria. Recently, symbiotic Actinobacteria from insect agricultural systems have been recognized as a promising source of bioactive compounds, especially antifungal agents. These bacteria often produce natural products that defend an insect’s fungal crop from pathogenic fungus. The work proposed here will use chemical biology approaches such as phenotypic interaction screens, genomics, and a new bioinformatics approach to systematically search for bioactive natural products produced by Actinobacteria symbionts and other organisms in insect agricultural systems. The first part of this proposal focuses on using existing techniques to identify new bioactive natural products. Phenotypic interaction screens can identify bioactive natural products by determining if a symbiotic bacteria produces a natural product that inhibits the growth of a fungal pathogen and vice-versa. We will then use genomic sequencing, bioinformatics, and heterologous expression to identify and characterize biosynthetic gene clusters (BGCs) that are not expressed in the phenotypic interaction screens. The second part of the proposed work involves the use of a new bioinformatics technique to identify interesting bioactive natural products. Existing bioinformatics techniques identify BGCs and predict the most likely chemical structure of the corresponding natural product. However, they do not conclude anything concerning the functional role that the natural product plays. The technique developed here will use machine learning to predict the function that the natural product fulfills in the ecological context of the organism. This algorithm will facilitate the identification of bioactive natural products with therapeutically relevant functions. Project Narrative Fungal infections are an underappreciated threat to human health with high mortality rates and few effective therapeutic agents for treatment. Symbiotic Actinobacteria from insect agricultural systems are a promising source of antifungal agents since they often produce natural products with antifungal activity protecting an insect’s fungal crop from pathogenic fungus. The work proposed here will use phenotypic interaction screens, genome sequencing, and the development of a novel bioinformatics method to systematically mine Actinobacteria for antifungal and antibacterial products – leading to the discovery of new bioactive small molecules along with a deeper understanding of how natural products mediate the interaction between species in insect agricultural systems.",Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria,9540546,F32GM128267,"['Actinobacteria class', 'Age', 'Agriculture', 'Algorithms', 'Anti-Bacterial Agents', 'Antibiotics', 'Antifungal Agents', 'Ants', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bioinformatics', 'Biological Assay', 'Biology', 'Breathing', 'Chemical Structure', 'Chemicals', 'Collaborations', 'Computational Biology', 'Computing Methodologies', 'Data Set', 'Development', 'Ecosystem', 'Gene Cluster', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Infection', 'Insecta', 'Learning', 'Life', 'Literature', 'Machine Learning', 'Mediating', 'Medicine', 'Methods', 'Mining', 'Modernization', 'Molecular Structure', 'Mycoses', 'Natural Products', 'Organism', 'Pathogenicity', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Public Health', 'Resistance', 'Role', 'Soil', 'Source', 'System', 'Techniques', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'Validation', 'Work', 'base', 'bioactive natural products', 'drug discovery', 'fungus', 'genetic information', 'genome sequencing', 'human disease', 'mortality', 'novel', 'pathogen', 'post-doctoral training', 'prediction algorithm', 'small molecule', 'symbiont']",NIGMS,HARVARD MEDICAL SCHOOL,F32,2018,58282,0.00023423470145451824
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,9589711,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'Standardization', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2018,439996,-0.014942555153853036
"Developing Advanced Algorithms to Address Major Computational Challenges in Current Microbiome Research Abstract We propose a three-year interdisciplinary research plan to address two key issues currently facing the metagenomics community. The first issue concerns accurate construction and annotation of OTU tables using  of millions of 16S rRNA sequences, which is one of the most important yet most difficult problems inmicrobiome data analysis. Currently, it lacks computational algorithms capable of handling extremely large sequence data and constructing biologically consistent OTU tables. We propose a novel method that performs OTU table construction and annotation simultaneously by utilizing input and reference sequences, reference annotations, and data clustering structure within one analytical framework. Dynamic data-driven cutoffs are derived to identify OTUs that are consistent not only with data clustering structure but also with reference annotations. When successfully implemented, our method will generally address the computational needs of processing hundreds of millions of 16S rRNA reads that are currently being generated by large-scale studies. The second issue concerns developing novel methods to extract pertinent information from massive sequence data, thereby facilitating the field shifting from descriptive research to mechanistic studies. We are particularly interested in microbial community dynamics analysis, which can provide a wealth of insight into disease development unattainable through a static experiment design, and lays a critical foundation for developing probiotic and antibiotic strategies to manipulate microbial communities. Traditionally, system dynamics is approached through time-course studies. However, due to economical and logistical constraints, time-course studies are generally limited by the number of samples examined and the time period followed. With the rapid development of sequencing technology, many thousands of samples are being collected in large-scale studies. This provides us with a unique opportunity to develop a novel analytical strategy to use static data, instead of time-course data, to study microbial community dynamics. To our knowledge, this is the first time that massive static data is used to study dynamic aspects of microbial communities. When successfully implemented, our approach can effectively overcome the sampling limitation of time-course studies, and opens a new avenue of research to study microbial dynamics underlying disease development without performing a resource-intensive time-course study. The proposed pipeline will be intensively tested on a large oral microbiome dataset consisting of ~2,600 subgingival samples (~330M reads). The analysis can significantly advance our understanding of dynamic behaviors of oral microbial communities possibly contributing to the development of periodontal disease. To our knowledge, no prior work has been performed on this scale to study oral microbial community dynamics. We have assembled a multidisciplinary team that covers expertise spanning the areas of machine learning, bioinformatics, and oral microbiology. The expected outcome of this work will be a set of computational tools of high utility for the microbiology community and beyond. The human microbiome plays essential roles in many important physiological processes. We propose an interdisciplinary research plan to address some major computational challenges in current microbiome research. If successfully implemented, this work could significantly expand the capacity of existing pipelines for large-scale data analysis and scientific discovery, resulting in a significant impact on the field.",Developing Advanced Algorithms to Address Major Computational Challenges in Current Microbiome Research,9474101,R01AI125982,"['Address', 'Algorithms', 'Antibiotics', 'Area', 'Big Data', 'Bioinformatics', 'Biological', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Epidemiology', 'Floods', 'Foundations', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Interdisciplinary Study', 'Knowledge', 'Logistics', 'Machine Learning', 'Metagenomics', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral Microbiology', 'Outcome', 'Periodontal Diseases', 'Physiological Processes', 'Play', 'Probiotics', 'Research', 'Resources', 'Ribosomal RNA', 'Role', 'Sampling', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Work', 'base', 'cohort', 'computerized tools', 'design', 'dynamic system', 'epidemiology study', 'experimental study', 'human microbiota', 'innovation', 'insight', 'interest', 'microbial', 'microbial community', 'microbiome', 'microbiome research', 'multidisciplinary', 'novel', 'open source', 'operational taxonomic units', 'oral behavior', 'oral microbial community', 'oral microbiome', 'response', 'tumor progression', 'web app']",NIAID,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2018,350321,0.009772908439857167
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,9589783,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computer Simulation', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2018,1076717,0.01469389239847055
"An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography SUMMARY – OVERALL Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function. Although the basic electron cryo-tomography technique has been used for several decades, the technology is being revolutionized by recent advances in sample preparation, electron cryo-microscopy hardware, improved capabilities for automatic data collection, direct electron detection imaging devices, and phase plate technologies. Combined, these advances led to the ability to generate extraordinarily large numbers of cellular cryo-tomograms of exquisite quality. In principle, such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. However, collection of cellular data is now at a far faster rate than can currently be analyzed with existing methods, producing a serious barrier to progress: to match the data production rates of a single laboratory, at least 50 experienced scientists would need to handle the data analysis. The primary goal of this Program Project is to establish quantitative and highly automated tools for the reconstruction and interpretation of highly complex cellular tomographic data. We have assembled a highly synergistic team of PIs with complimentary expertise in cutting-edge computational and experimental electron microscopy techniques to achieve this goal through collaborative efforts. Project 1 (Hanein & Penczek) focuses on development and implementation of tomogram quality assessment and validation techniques and on experimentally guided optimization of data collection strategies. Project 2 focuses on automatic tomographic reconstruction technology, extraction of various features from the tomograms, and the analysis of distribution patterns derived from the extracted features. Project 3 focuses on development of quantitative tools for tomogram annotation through deep learning and sub-tomogram alignment as well as interactive visualization tools. The set of highly automated tools developed in this Program Project will permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study. NARRATIVE Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function and—with recent instrumental advances—it is now possible to image hundreds of cells per months, enabling collection of cellular data at a far faster rate than can currently be analyzed. Such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. This Program Project brings together an accomplished team of investigators to develop new strategies for effectively processing and interpreting this massive influx of data, developing a set of highly automated tools to permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study.",An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography,9416022,P01GM121203,"['Address', 'Algorithms', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biological Neural Networks', 'Biology', 'Cancer Diagnostics', 'Cell physiology', 'Cells', 'Classification', 'Collection', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Electrons', 'Environment', 'Floods', 'Goals', 'Health', 'Heart', 'Human', 'Image', 'Imaging Device', 'Individual', 'Knowledge', 'Laboratories', 'Methodology', 'Methods', 'Molecular', 'Molecular Structure', 'Morphology', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Preparation', 'Process', 'Production', 'Real-Time Systems', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Stimulus', 'System', 'Techniques', 'Technology', 'Tomogram', 'Validation', 'Variant', 'Visualization software', 'base', 'computer framework', 'deep learning', 'electron tomography', 'experience', 'imaging detection', 'improved', 'insight', 'knowledge base', 'learning strategy', 'nanomachine', 'novel diagnostics', 'particle', 'programs', 'reconstruction', 'response', 'software development', 'statistics', 'tomography', 'tool', 'virtual']",NIGMS,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,P01,2018,981617,-0.015563272989212886
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9570304,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Simulation', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Supervision', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in vivo', 'insight', 'intracranial artery', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'single photon emission computed tomography', 'spatiotemporal', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2018,528639,-0.015410318001293041
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9420621,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'human microbiota', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiome research', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2018,374683,0.025021311430388115
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9486312,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Biological Neural Networks', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Label', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'lead optimization', 'learning network', 'multidisciplinary', 'novel', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2018,1527746,-0.023328805200991107
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9420662,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2018,2000000,-0.02625320684986402
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),9527792,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug Addiction', 'Drug Receptors', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Epigenetic Process', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Source', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'algorithmic methodologies', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'cloud platform', 'computational chemistry', 'computer science', 'data mining', 'design', 'distinguished professor', 'dopamine transporter', 'drug abuse prevention', 'falls', 'genome-wide', 'genome-wide analysis', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'novel therapeutics', 'operation', 'prevent', 'professor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2018,1080816,-0.0072398512779657176
"Simulation of Proton Translocation in Biomolecules PROJECT SUMMARY  The transport of protons in biomolecular systems is a phenomenon of fundamental importance to processes such as ATP synthesis, enzyme catalysis, the maintenance of pH gradients, proton pumping, viral infection, and substrate/ion transport across membranes via protein transporters, symporters, and antiporters. Modeling biomolecular proton translocation in silico is a significant challenge due to the complex chemical reactions involved in Grotthuss proton shutting between water molecules and with protonatable amino acids, as well as the complexity of the target biomolecular systems. In most cases, it is not only important to understand the mechanism of proton binding and transport, but also its coupling to other mechanistically relevant biomolecular processes, such as protein conformational changes, substrate binding, other protonation events, and dynamic hydration.  In this project the continued development and application of a powerful multiscale computer simulation methodology is described for the study of proton transport in several key classes of proton translocating biomolecular systems, including channels (influenza A and B M2 channels), antiporters/symporters (ClC Cl-/H+ antiporter and phosphate transporter, respectively), and transporters (proton-coupled oligopeptide transporter and EmrE multidrug transporter). The overall research plan is made possible by a novel reactive molecular dynamics simulation approach integrated with quantum mechanics/molecular mechanics (QM/MM) methods that allows for the study of explicit long-length and -time scale proton transport through water molecules and ionizable molecular groups in hydrogen-bonded networks, as well as by new innovations in enhanced free energy sampling methodology, machine learning, kinetic network theory, and coarse-graining. A primary goal in the research with this methodology in hand is to reveal the mechanisms of proton transport, as well as its coupling to hydration and conformational changes, in the above mentioned biomolecular systems. All of these studies will be carried out in collaboration with leading experimentalists, while continuing to add a new dimension to the field of biomolecular computer simulation as a whole. 1 PROJECT NARRATIVE  In this project, computer simulations will be used to study proton transport in several important biomolecular systems. Proton translocation is of fundamental significance throughout biology, as demonstrated by the pH-dependence of biomolecular structure and function and the central role of transmembrane proton gradients in bioenergy conversion. Moreover, understanding proton transport is of fundamental importance and direct relevance to numerous aspects of human health, including metabolism, aging, diabetes, neurodegeneration, retinal degeneration, antivral and anti-bacterial therapeutics, and homeostasis. 1",Simulation of Proton Translocation in Biomolecules,9543037,R01GM053148,"['ATP Synthesis Pathway', 'Achievement', 'Aging', 'Agreement', 'Amino Acids', 'Anions', 'Anti-Bacterial Agents', 'Area', 'Behavior', 'Binding', 'Biology', 'Carrier Proteins', 'Catalysis', 'Charge', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Consult', 'Coupled', 'Coupling', 'Data', 'Defect', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diffusion', 'Dimensions', 'Elements', 'Entropy', 'Enzymes', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Grain', 'Hand', 'Health', 'Homeostasis', 'Human', 'Hydration status', 'Hydrogen Bonding', 'Influenza', 'Influenza A virus', 'Influenza B Virus', 'Inorganic Phosphate Transporter', 'Ion Transport', 'Kinetics', 'Length', 'Letters', 'Machine Learning', 'Maintenance', 'Mechanics', 'Medical', 'Medicine', 'Membrane', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Motion', 'Mutation', 'Nerve Degeneration', 'Oligopeptides', 'Outcome', 'Pharmaceutical Preparations', 'Process', 'Progress Reports', 'Protein Conformation', 'Proteins', 'Proton Pump', 'Protons', 'Publishing', 'Quantum Mechanics', 'Reaction', 'Research', 'Research Personnel', 'Research Support', 'Retinal Degeneration', 'Role', 'Sampling', 'Sampling Biases', 'Specificity', 'Structure', 'System', 'Therapeutic', 'Time', 'Transport Process', 'Travel', 'United States National Institutes of Health', 'Virus Diseases', 'Water', 'Wisconsin', 'anti-influenza drug', 'antiporter', 'chemical bond', 'chemical reaction', 'experimental study', 'innovation', 'inorganic phosphate', 'insight', 'migration', 'molecular dynamics', 'molecular mechanics', 'multi drug transporter', 'novel', 'pH gradient', 'protonation', 'quantum', 'simulation', 'symporter', 'theories']",NIGMS,UNIVERSITY OF CHICAGO,R01,2018,310328,-0.021394193005354483
"Integration and Visualization of Diverse Biological Data ﻿    DESCRIPTION (provided by applicant): The onset of most human disease involves multiple, molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway and treatment contexts. While this system has been probed by the thousands of functional genomics and quantitative genetic studies, careful extraction of signals relevant to these specific contexts is a challenging problem. General integration of these heterogeneous data was an important first step in detecting signals that be used to build networks to generate experimentally-testable hypotheses. However, only by dealing with the fact that disease happens at the intersection of multiple contexts and by integrating functional genomics with quantitative genetics will we be able to move toward a molecular-level understanding of human pathophysiology, which will pave the way to new therapy and drug development.  The long-term goal of this project is to enable such discoveries through the development of innovative bioinformatics frameworks for integrative analysis of diverse functional genomic data. In the previous funding periods, we developed accurate data integration and visualization methodologies for most common model organisms and human, created methods for tissue-specific data analysis, and applied these methods to make novel insights about important biological processes. We further enabled experimental biological discovery by implementing these methods in publicly accessible interactive systems that are popular with experimental biologists.  Leveraging our prior work, we now will directly address the challenge of enabling data-driven study of molecular mechanisms underlying human disease by developing novel semi-supervised and multi-task machine learning approaches and implementing them in a real-time integration system capable of predicting genome-scale functional and mechanism-specific networks focused on any biological context of interest. This will allow any biomedical researcher to quickly make data-driven hypotheses about function, interactions, and regulation of genes involved in hypertension in the kidney glomerulus or to predict new regulatory interactions relevant to Parkinson's disease that affect the ubiquitination pathway in Substantia nigra. Furthermore, we will develop methods for disease gene discovery that leverage these highly specific networks for functional analysis of quantitative genetics data. Our deliverable will be a general, robust, user-friendly, and automatically updated system for user-driven functional genomic data integration and functional analysis of quantitative genetics data. Throughout this work, we (with our close experimental and clinical collaborators) will also apply our methods to chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders both as case studies for the iterative improvement of our methods and to make direct contribution to better understanding of these diseases. PUBLIC HEALTH RELEVANCE: We will create a web-accessible system that will enable biologists and clinicians to generate hypotheses regarding disease-linked genes, molecular mechanisms underlying genetic disorders, and drug discovery for more targeted treatment. Underlying this user-friendly web interface will be novel algorithms for on-the-fly integration of  vast amount of functional genomics and quantitative genetics data based on the context(s) defined by the biologist or clinician. As applied to the three case study areas, chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders, our system has the potential to identify novel disease genes and pathways and to enable development of better diagnostic biomarkers, drug targets, and, in the longer term, treatments.",Integration and Visualization of Diverse Biological Data,9415436,R01GM071966,"['Address', 'Affect', 'Algorithms', 'Animal Model', 'Area', 'Bioinformatics', 'Biological', 'Biological Process', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Complex', 'Computer Systems', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Drug Targeting', 'Expert Systems', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Databases', 'Genetic Diseases', 'Genetic study', 'Goals', 'Gold', 'Human', 'Hypertension', 'Imagery', 'Kidney Glomerulus', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nephrology', 'Network-based', 'Parkinson Disease', 'Pathway interactions', 'Quantitative Genetics', 'Real-Time Systems', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Substantia nigra structure', 'Supervision', 'System', 'Systems Integration', 'Time', 'Tissues', 'Training', 'Ubiquitination', 'Update', 'Work', 'autism spectrum disorder', 'base', 'clinical investigation', 'data integration', 'data visualization', 'diagnostic biomarker', 'drug development', 'drug discovery', 'experimental study', 'functional genomics', 'gene discovery', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'multitask', 'novel', 'novel therapeutics', 'public health relevance', 'targeted treatment', 'therapy development', 'user-friendly', 'web interface', 'web-accessible']",NIGMS,PRINCETON UNIVERSITY,R01,2018,445349,-0.010965965588003362
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,9588814,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2018,906891,-0.003855832141052464
"Successful Clinical Response In Pneumonia Therapy (SCRIPT) Systems Biology Center Overall Project Summary: This innovative integrated systems biology application seeks to delineate the complex host/pathogen interactions occurring at the alveolar level that lead to unsuccessful response to therapy in serious pneumonia. To achieve this objective, we will leverage our unique access to alveolar fluid collected as part of routine clinical care in mechanically ventilated patients with suspected pneumonia in our medical intensive care unit. Bronchoalveolar lavage fluid will be obtained serially from well characterized mechanically ventilated patients with Pseudomonas or Acinetobacter pneumonia. Both of these CDC- designated serious hazard level pathogens have clinical failure rates as high as 50%. A robust clinical definition will allow comparison of both host and pathogen signatures associated with failure of therapy vs. success. These clinical specimens and extensive patient phenomics will anchor two mutually supportive and iterative research projects. Project One will deploy robust tools for flow sorting macrophage and lymphocyte subset populations, isolating RNA from these populations, and performing transcriptomic and epigenomic analysis to compare successful and unsuccessful host responses to infection. Project Two will focus on both specific pathogen genomic profiles associated with unsuccessful outcome. Changes in microbiome communities will be comprehensively assessed by shotgun deep sequencing to detect bacteriophage, other virus, and fungal DNA, in addition to bacterial. The Technology Core will perform cell sorting of NBBAL macrophage and lymphocyte subsets, RNA sequencing, and whole genome methylation, and perform parallel studies in a unique humanized alveolar macrophage mouse model. A Data Management and Bioinformatics Core will develop tools to reduce the dimensionality of these large comprehensive datasets, including the clinical phenomics, and provide them to the Modeling Core. The Modeling Core will then use innovative modeling approaches including a model of the alveolus during pneumonia as an ecosystem out of balance combined with unique machine learning tools and neural networks to generate biomarkers of host, pathogen and/or microbiome patterns predictive of successful pneumonia outcome. Predictive biomarkers developed in the Modeling Core will then be validated in a prospective confirmatory cohort of patients in whom analogous data will be generated. The Administrative Core will perform the outward-facing role of education and outreach to the community and sponsor, as well as regularly exchanging datasets, analytic tools, and specimens with NIH-sponsored/approved repository sites. Project Narrative: The Successful Clinical Response In Pneumonia Treatment (SCRIPT) systems biology center seeks to delineate the complex host/pathogen interactions occurring at the alveolar level that lead to unsuccessful response to therapy in serious pneumonia. We will leverage our unique access to alveolar fluid collected as part of routine clinical care in mechanically ventilated patients to generate clinical phenomic, transcriptomic, epigenomic and metagenomic data that describe the host response, pathogen characteristics and microbiome of the alveolar space during pneumonia. We will then integrate this comprehensive phenotypic data into an ecosystem-based model to generate predictive biomarkers of pneumonia outcome for subsequent validation in a second cohort and tested for causality in a humanized alveolar macrophage mouse model.",Successful Clinical Response In Pneumonia Therapy (SCRIPT) Systems Biology Center,9454818,U19AI135964,"['Acinetobacter', 'Address', 'Alveolar', 'Alveolar Macrophages', 'Alveolus', 'Animal Model', 'Antibiotic Therapy', 'Bacteriophages', 'Bioinformatics', 'Biological Markers', 'Biological Neural Networks', 'Bronchoalveolar Lavage', 'Bronchoalveolar Lavage Fluid', 'Cause of Death', 'Cell Separation', 'Cells', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Microbiology', 'Clinical Trials', 'Collection', 'Communities', 'Complex', 'DNA Viruses', 'DNA sequencing', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Education and Outreach', 'Equilibrium', 'Etiology', 'Failure', 'Fungal DNA', 'Generations', 'Genes', 'Genetic', 'Goals', 'Human', 'Immune response', 'Infection', 'Intensive Care Units', 'Lead', 'Link', 'Liquid substance', 'Lymphocyte Subset', 'Lymphoid Cell', 'Machine Learning', 'Mechanics', 'Medical', 'Metagenomics', 'Methylation', 'Modeling', 'Myeloid Cells', 'Nosocomial Infections', 'Nosocomial pneumonia', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Pneumonia', 'Population', 'Preparation', 'Prospective cohort', 'Protocols documentation', 'Pseudomonas', 'Pseudomonas aeruginosa', 'RNA', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Sampling', 'Science', 'Secondary to', 'Shotguns', 'Site', 'Sorting - Cell Movement', 'Specimen', 'Standardization', 'Stream', 'System', 'Systems Biology', 'Technology', 'Testing', 'Treatment Failure', 'United States National Institutes of Health', 'Validation', 'Virulence', 'analytical tool', 'base', 'clinical care', 'cohort', 'data management', 'deep sequencing', 'epigenomics', 'experience', 'genomic data', 'genomic profiles', 'hazard', 'humanized mouse', 'improved', 'innovation', 'macrophage', 'microbiome', 'microbiome composition', 'mouse model', 'multiple omics', 'new therapeutic target', 'novel', 'pathogen', 'phenomics', 'phenotypic data', 'pneumonia model', 'predictive marker', 'predictive tools', 'prospective', 'repository', 'response', 'success', 'tool', 'transcriptome sequencing', 'transcriptomics', 'viral DNA', 'whole genome']",NIAID,NORTHWESTERN UNIVERSITY AT CHICAGO,U19,2018,2400000,-0.00714896901616763
"CSHL Computational and Comparative Genomics Course The Cold Spring Harbor Laboratory proposes to continue a course entitled “Computational and Comparative Genomics”, to be held in the Fall of 2017 – 2019. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases that they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. NARRATIVE The Computational & Comparative Genomics, a 9 day course, is designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,9545035,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'Course Content', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genome', 'Home environment', 'Institution', 'International', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Research Training', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Training Programs', 'Universities', 'Update', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'graduate student', 'instructor', 'interest', 'laboratory experience', 'lecturer', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2018,67704,0.006835991535404915
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9394010,U24DK112331,"['ATAC-seq', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Cost efficiency', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Lead', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Research Infrastructure', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'base', 'bisulfite sequencing', 'data resource', 'epigenomics', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'individual response', 'insight', 'medical schools', 'methylome', 'mortality', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2018,1639153,-0.015560819001912658
"A Systems Biology Approach to Investigate the Structure Changes of Biological Network Project Summary/Abstract Networks have been widely used to describe many biological processes. Understanding the structure of biological network, especially regulatory network, will provide a key to discovering the mechanisms underlying important biological processes and pathogenesis of diseases. One of the most challenging tasks in systems biology is how to correctly reconstruct the networks from the high-dimensional data generated by modern genomic technology. Most network inference methods assume the network structure is time-invariant. Some recent studies revealed the structures of some biological networks are non-stationary or time-varying. For example, the neural information flow networks of brains are changing during learning process. Importantly, cancer studies found the native T cells would be converted into senescent T cells due to the structure changes of genetic network during tumorigenesis. The stationary network inference methods can't be used to reconstruct the time-varying network. Non-stationary network inference methods are urgently needed to investigate the time-varying networks at different stages. Some researchers have attempted to develop some time-varying network inference methods. However, the inferred networks using existing methods are only correlation or causality graphs, not regulatory networks which require activation & inhibition information. This project aims to develop novel non-stationary network inference methods to reconstruct time-varying regulatory networks from time series data. Since the networks are highly complex, it is not realistic to manually verify large networks as being used by the traditional methods. We will develop a powerful Model Checker, which is a Turing Award winning technique for hardware system verification, to intelligently verify the inferred time-varying networks. Our long-term goal is to integrate the statistical inference and model checking techniques in a unified platform to automatically reconstruct and verify time-varying networks. This integrative systems biology approach will make the large-network inference and verification automatic, intelligent and efficient. Recent cancer studies show that, restoring senescent T cells represents a promising strategy for cancer treatment. In collaboration with cancer immunologist, we will apply computational-experimental approaches to investigate what structure changes of the genetic network and how they induce T-cell's functional changes and influence its fate decision making from naive T-cells to senescent T-cells. Answering these questions will significantly improve our understanding of the mechanisms underlying the T cell differentiation during tumorigenesis. Public Health Relevance/Narrative This project aims to develop a novel systems biology approach to reconstruct the time-varying biological networks from high-dimensional data in collaboration with the cancer immunologist. The proposed research has relevance to public health, because it seeks to investigate what and how the structure changes of genetic network induce the T-cell's functional changes during tumorigenesis, which will ultimately improve our understanding of the mechanisms underlying the T cell differentiation and cancer.",A Systems Biology Approach to Investigate the Structure Changes of Biological Network,9655801,R15GM129696,"['Algorithms', 'Attention', 'Award', 'Bayesian Modeling', 'Biological', 'Biological Process', 'Brain', 'Cancer Immunology Science', 'Cells', 'Code', 'Collaborations', 'Complex', 'Data', 'Databases', 'Decision Making', 'Development', 'Disease', 'Drosophila genus', 'Etiology', 'Evolution', 'Gene Structure', 'Genetic', 'Genomics', 'Goals', 'Graph', 'Immunologist', 'Knowledge', 'Laboratories', 'Learning', 'Life Cycle Stages', 'Location', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Muscle Development', 'Mutation', 'Pathogenesis', 'Process', 'Public Health', 'Regulator Genes', 'Regulatory T-Lymphocyte', 'Research', 'Research Personnel', 'Series', 'Structure', 'System', 'Systems Biology', 'T cell differentiation', 'T-Lymphocyte', 'Techniques', 'Technology', 'Time', 'Work', 'base', 'cancer therapy', 'computer studies', 'exhaust', 'experimental study', 'high dimensionality', 'improved', 'neoplastic cell', 'next generation sequencing', 'novel', 'public health relevance', 'reconstruction', 'relating to nervous system', 'senescence', 'tool', 'tumor microenvironment', 'tumorigenesis']",NIGMS,SAINT LOUIS UNIVERSITY,R15,2018,454500,-0.007081348225802629
"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",Joint Analysis of Microbiome and Other Genomic Data Types,9577818,R01GM129512,"['Achievement', 'Address', 'Area', 'Automobile Driving', 'Biological', 'Birth', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Early Diagnosis', 'Future', 'Genes', 'Genetic', 'Genomics', 'Grouping', 'Health', 'Human Genome Project', 'Joints', 'Lasso', 'Learning', 'Machine Learning', 'Maintenance', 'Maps', 'Medical', 'Menopause', 'Metabolic', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Modification', 'Molecular Target', 'Network-based', 'Outcome', 'Pathway interactions', 'Performance', 'Phylogenetic Analysis', 'Pregnancy Outcome', 'Premature Birth', 'Procedures', 'Public Health', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Structure', 'System', 'Taxonomy', 'Training', 'Woman', 'Work', 'base', 'biological systems', 'computerized tools', 'experience', 'genetic variant', 'genomic data', 'human disease', 'improved', 'interest', 'loss of function', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiome analysis', 'microbiome components', 'microbiome composition', 'microbiome research', 'new therapeutic target', 'novel', 'open source', 'population stratification', 'predictive modeling', 'simulation', 'software development', 'therapeutic target', 'tool', 'translational study', 'user friendly software', 'vaginal microbiome']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2018,396000,-0.0028019561353570654
"Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition",9452089,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Gene Targeting', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R01,2018,591415,-0.01134044728429158
"Dopaminergic encoding of counterfactual information in human striatum ﻿    DESCRIPTION (provided by applicant): Diseases and disorders directly affected by dopamine systems (e.g., drug addiction and Parkinson's disease) highlight the importance of these systems in motivated human behavior and cognition. The dopamine system is known to be a critical component of normal learning, reward processing, and decision-making (reviewed in Montague et al., 2004). Unfortunately, our present knowledge of dopamine systems in human brains is relatively sparse compared to the wealth of experimentation and computational modeling on these systems in rodents and non-human primates. Previously, technological constraints have limited direct experimentation in human brains. This proposal capitalizes on our group's recent technological innovation, which was supported by the NIH R21 mechanism - CEBRA: R21DA024140 - and resulted in the successful completion of the first sub-second measurements of dopamine release in a human brain. Furthermore, these measurements took place during an active decision-making task that was framed by computational models of learning and reward processing (Kishida et al., 2011 and Kishida et al., under review). We propose to pursue three specific aims, which combine our technological advance with active learning tasks designed to probe the role of dopamine in human behavior. Our aims incorporate three learning signals, where actual and counterfactual experience will each be examined in human striatal responses. The proposed work will inform on the controversial role for dopamine in reward/movement interactions. The experiments proposed will yield unprecedented insight into the function of the dopamine system in the humans afflicted with Parkinson's disease and Essential Tremor. With the support of the NIH (R21DA024140), our team successfully developed a complete prototype system for making electrochemical measurements of dopamine delivery in the human brain. Feasibility has been demonstrated by obtaining the first dopamine measurements in the striata of subjects with Parkinson's during a decision-making task. This substantial preliminary work is now ready for a larger scale with specific hypothesis testing about the role of dopamine systems in Parkinson's disease, Essential tremor, and human decision-making and behavior. PUBLIC HEALTH RELEVANCE: Experiments and computational models (primarily investigated in rodents and non-human primates) suggest dopamine systems in the brain are essential for normal learning, reward-processing, and ongoing decision- making. This proposal builds upon our group's innovative work, which - for the first time - recorded sub- second measurements of dopamine in human subjects and amalgamated these measurements with computational models of dopamine function. Herein we propose to use this newly developed technology to generate unprecedented insight into the function of dopamine systems directly in humans.",Dopaminergic encoding of counterfactual information in human striatum,9536159,R01NS092701,"['Active Learning', 'Acute', 'Affect', 'Animal Model', 'Behavior', 'Brain', 'Brain Diseases', 'Cells', 'Cessation of life', 'Cognition', 'Cognitive', 'Computer Simulation', 'Corpus striatum structure', 'Coupling', 'Data', 'Decision Making', 'Disease', 'Dopamine', 'Drug Addiction', 'Electrodes', 'Essential Tremor', 'Exploratory/Developmental Grant', 'Funding', 'Human', 'Knowledge', 'Learning', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Movement Disorders', 'Operative Surgical Procedures', 'Parkinson Disease', 'Participant', 'Patients', 'Periodicity', 'Phase', 'Play', 'Replacement Therapy', 'Research Personnel', 'Rewards', 'Rodent', 'Role', 'Sample Size', 'Scanning', 'Signal Transduction', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'blood oxygenation level dependent response', 'cognitive function', 'design', 'dopamine system', 'dopaminergic neuron', 'experience', 'experimental study', 'extracellular', 'human subject', 'implantation', 'innovation', 'insight', 'nonhuman primate', 'prototype', 'public health relevance', 'putamen', 'reduce symptoms', 'relating to nervous system', 'response', 'reward processing', 'social', 'symptomatic improvement', 'technological innovation', 'temporal measurement']",NINDS,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2018,492125,-0.0009656777602808868
"Dopaminergic encoding of counterfactual information in human striatum ﻿    DESCRIPTION (provided by applicant): Diseases and disorders directly affected by dopamine systems (e.g., drug addiction and Parkinson's disease) highlight the importance of these systems in motivated human behavior and cognition. The dopamine system is known to be a critical component of normal learning, reward processing, and decision-making (reviewed in Montague et al., 2004). Unfortunately, our present knowledge of dopamine systems in human brains is relatively sparse compared to the wealth of experimentation and computational modeling on these systems in rodents and non-human primates. Previously, technological constraints have limited direct experimentation in human brains. This proposal capitalizes on our group's recent technological innovation, which was supported by the NIH R21 mechanism - CEBRA: R21DA024140 - and resulted in the successful completion of the first sub-second measurements of dopamine release in a human brain. Furthermore, these measurements took place during an active decision-making task that was framed by computational models of learning and reward processing (Kishida et al., 2011 and Kishida et al., under review). We propose to pursue three specific aims, which combine our technological advance with active learning tasks designed to probe the role of dopamine in human behavior. Our aims incorporate three learning signals, where actual and counterfactual experience will each be examined in human striatal responses. The proposed work will inform on the controversial role for dopamine in reward/movement interactions. The experiments proposed will yield unprecedented insight into the function of the dopamine system in the humans afflicted with Parkinson's disease and Essential Tremor. With the support of the NIH (R21DA024140), our team successfully developed a complete prototype system for making electrochemical measurements of dopamine delivery in the human brain. Feasibility has been demonstrated by obtaining the first dopamine measurements in the striata of subjects with Parkinson's during a decision-making task. This substantial preliminary work is now ready for a larger scale with specific hypothesis testing about the role of dopamine systems in Parkinson's disease, Essential tremor, and human decision-making and behavior. PUBLIC HEALTH RELEVANCE: Experiments and computational models (primarily investigated in rodents and non-human primates) suggest dopamine systems in the brain are essential for normal learning, reward-processing, and ongoing decision- making. This proposal builds upon our group's innovative work, which - for the first time - recorded sub- second measurements of dopamine in human subjects and amalgamated these measurements with computational models of dopamine function. Herein we propose to use this newly developed technology to generate unprecedented insight into the function of dopamine systems directly in humans.",Dopaminergic encoding of counterfactual information in human striatum,9744955,R01NS092701,"['Active Learning', 'Acute', 'Affect', 'Animal Model', 'Behavior', 'Brain', 'Brain Diseases', 'Cells', 'Cessation of life', 'Cognition', 'Cognitive', 'Computer Simulation', 'Corpus striatum structure', 'Coupling', 'Data', 'Decision Making', 'Disease', 'Dopamine', 'Drug Addiction', 'Electrodes', 'Essential Tremor', 'Exploratory/Developmental Grant', 'Funding', 'Human', 'Knowledge', 'Learning', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Movement Disorders', 'Operative Surgical Procedures', 'Parkinson Disease', 'Participant', 'Patients', 'Periodicity', 'Phase', 'Play', 'Replacement Therapy', 'Research Personnel', 'Rewards', 'Rodent', 'Role', 'Sample Size', 'Scanning', 'Signal Transduction', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'blood oxygenation level dependent response', 'cognitive function', 'design', 'dopamine system', 'dopaminergic neuron', 'experience', 'experimental study', 'extracellular', 'human subject', 'implantation', 'innovation', 'insight', 'nonhuman primate', 'prototype', 'public health relevance', 'putamen', 'reduce symptoms', 'relating to nervous system', 'response', 'reward processing', 'social', 'symptomatic improvement', 'technological innovation', 'temporal measurement']",NINDS,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2018,72839,-0.0009656777602808868
"Improving safety and efficacy of platelet transfusion through systems biology Project Summary Platelet transfusion is critical for severely bleeding patients and nearly 6 million units are transfused in the United States and Europe annually. In the United States, platelets are typically stored for 5 days resulting in a waste of 20% of their supply. Short storage duration is a consequence of bacterial contamination and platelet quality considerations. Though many methods have been developed for bacterial testing and pathogen inactivation, fewer have been developed for improving quality of stored platelets. Platelet additive solutions have the possibility to increase storage quality and duration, reduce plasma-related allergic reactions, impact the efficacy of pathogen reduction techniques, and save plasma which can then be used as an additional transfusion product. While the benefits are well known, there has been little progress in developing new platelet additive solutions for increasing quality and safety of platelet transfusion because there is a lack of broad understanding of biochemical and signaling changes during storage. There has been interest to utilize high-throughput metabolite profiling for global understanding of platelet metabolic decline but data analysis of complex datasets has been a daunting challenge. In Phase I of this program, we developed the first, robust computational platform involving statistical analysis and systems biology of metabolic and signaling networks to interpret and analyze PLT metabolomic and proteomic profiles in a complete network context. Using time- course global, quantitative metabolite profiling, we determined that PLTs undergo a non-linear decay process and computationally identified key metabolic enzymes and cellular process that drive this decay. Based on the computational results, we have devised two novel additive solution strategies to mitigate the decay process and improve the length of PLT units. In this Phase II proposal, we will validate the computationally determined additive solutions for efficacy in alleviating the non-linear decay process through 1) metabolomics experiments, and 2) non-metabolic PLT physiology experiments including cell activation and hemostatic effectiveness. A successful additive solution will be progressed to media refinement and preclinical testing. Project Narrative Platelet transfusion units are typically stored for five days in the United States leading to a waste of 20% of units and potential quality concerns. The field is open for innovation as most storage media technologies are derived from work from the early 1990s. This proposal will develop novel computational methods to comprehensively understand the degradation of platelets under storage conditions and experimentally validate new additive solutions for increasing platelet quality and extending shelf life, an area that accounts for $2.5 billion of hospital costs.",Improving safety and efficacy of platelet transfusion through systems biology,9506810,R44HL127843,"['Accounting', 'Agreement', 'Algorithms', 'Allergic Reaction', 'Area', 'Biochemical', 'Biological', 'Blood', 'Blood Component Removal', 'Blood Platelets', 'Cell physiology', 'Cells', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Effectiveness', 'Enzymes', 'Equipment and supply inventories', 'Europe', 'Formulation', 'Glutathione', 'Hemorrhage', 'Hemostatic Agents', 'Hospital Costs', 'In Vitro', 'Intervention', 'Length', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Mathematics', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Methods', 'Modeling', 'Pathway interactions', 'Patients', 'Phase', 'Physiology', 'Plasma', 'Platelet Transfusion', 'Preclinical Testing', 'Process', 'Production', 'Proteomics', 'Reaction', 'Recovery', 'Resources', 'Risk', 'Safety', 'Signal Pathway', 'Signal Transduction', 'State Hospitals', 'Statistical Data Interpretation', 'Supplementation', 'Surveys', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Transfusion', 'United States', 'Validation', 'Work', 'base', 'care costs', 'cost', 'design', 'experimental study', 'human subject', 'improved', 'insight', 'interest', 'metabolic profile', 'metabolomics', 'model design', 'novel', 'open innovation', 'oxidative damage', 'pathogen', 'predictive modeling', 'preservation', 'programs', 'statistics', 'success', 'time use', 'wasting']",NHLBI,"SINOPIA BIOSCIENCES, INC.",R44,2018,428727,-0.007148481059462428
"Bioinformatics Tools for Circadian Biology Circadian rhythms are fundamental for understanding biology: they date back to the origin of life, they are found in virtually every species from cyanobacteria to mammals, and they coordinate many important biological functions from the sleep-wake cycle, to metabolism, and to cognitive functions. Circadian rhythms are equally fundamental for health and medicine: modifications in diet have been linked to modification in circadian rhythms at the molecular level; disruptions of circadian rhythms have been linked to health problems ranging from depression, to learning disorders, to diabetes, to obesity, to cardiovascular disease, to cancer, and to premature ageing; finally, a large fraction of drug targets have been found to oscillate in a circadian manner in one or several tissues, suggesting that a better understanding of circadian oscillations at the molecular level could have direct applications to precision medicine, for instance by optimizing the time at which drugs are taken.  To better understand circadian oscillations at the molecular level, modern high-throughput technologies are being used to measure the concentrations of many molecular species, including transcripts, proteins, and metabolites along the circadian cycle in different organs and tissues, and under different conditions. However, the informatics tools for processing, analyzing, and integrating the growing wealth of molecular circadian data are not yet in place.  This effort will fill this fundamental gap by developing and disseminating informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine. Specifically, through a close collaborations between computational and experimental scientists, this effort will: (1) Bring the power of deep learning methods to bear on the analyses of omic time series to determine, for instance, which molecular species are oscillating, their characteristics (period, phase, amplitude), and to predict the time/phase associated with a measurement taken at a single time point; (2) Develop Cyber-TC, an extension of the widely used Cyber-T software, for the differential analysis of circadian omic time series and expand MotifMap, a widely used genome-wide map of regulatory sites to better understand circadian regulation; and (3) Develop Circadiomics, an integrated database and web portal as a one-stop shop for circadian data, annotations, and analyses. All data, software, and results will be freely available for academic research purposes and broadly disseminated through multiple channels to benefit both the circadian community and the broader bioinformatics community. Circadian rhythms are fundamental for biology and medicine. Modern high-throughput technologies are revealing how the concentrations of many molecular species, including transcripts, proteins, and metabolites oscillate with the day and night cycle in almost every species, tissue, and cell. In close collaboration with biologists, this project will develop the informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine.",Bioinformatics Tools for Circadian Biology,9699855,R01GM123558,"['Address', 'Ally', 'Architecture', 'Back', 'Biogenesis', 'Bioinformatics', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Cells', 'Characteristics', 'Circadian Rhythms', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Cyanobacterium', 'Data', 'Databases', 'Diabetes Mellitus', 'Diet', 'Disease', 'Drug Targeting', 'Feedback', 'Future', 'Gene Expression Regulation', 'Health', 'Homeostasis', 'Informatics', 'Laboratories', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Link', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Metabolism', 'Modernization', 'Modification', 'Molecular', 'Obesity', 'Organ', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Premature aging syndrome', 'Proteomics', 'Regulation', 'Research', 'Role', 'Scientist', 'Series', 'Site', 'Sleep Wake Cycle', 'System', 'Testing', 'Time', 'Tissues', 'Transcript', 'Update', 'Ursidae Family', 'Vision', 'annotation  system', 'cognitive function', 'cognitive process', 'deep learning', 'direct application', 'genome-wide', 'high throughput analysis', 'high throughput technology', 'insight', 'learning strategy', 'member', 'metabolomics', 'novel', 'precision medicine', 'protein metabolite', 'software development', 'tool', 'transcriptomics', 'virtual', 'web portal']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2018,75000,-0.0017346248703934489
"Bioinformatics Tools for Circadian Biology Circadian rhythms are fundamental for understanding biology: they date back to the origin of life, they are found in virtually every species from cyanobacteria to mammals, and they coordinate many important biological functions from the sleep-wake cycle, to metabolism, and to cognitive functions. Circadian rhythms are equally fundamental for health and medicine: modifications in diet have been linked to modification in circadian rhythms at the molecular level; disruptions of circadian rhythms have been linked to health problems ranging from depression, to learning disorders, to diabetes, to obesity, to cardiovascular disease, to cancer, and to premature ageing; finally, a large fraction of drug targets have been found to oscillate in a circadian manner in one or several tissues, suggesting that a better understanding of circadian oscillations at the molecular level could have direct applications to precision medicine, for instance by optimizing the time at which drugs are taken.  To better understand circadian oscillations at the molecular level, modern high-throughput technologies are being used to measure the concentrations of many molecular species, including transcripts, proteins, and metabolites along the circadian cycle in different organs and tissues, and under different conditions. However, the informatics tools for processing, analyzing, and integrating the growing wealth of molecular circadian data are not yet in place.  This effort will fill this fundamental gap by developing and disseminating informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine. Specifically, through a close collaborations between computational and experimental scientists, this effort will: (1) Bring the power of deep learning methods to bear on the analyses of omic time series to determine, for instance, which molecular species are oscillating, their characteristics (period, phase, amplitude), and to predict the time/phase associated with a measurement taken at a single time point; (2) Develop Cyber-TC, an extension of the widely used Cyber-T software, for the differential analysis of circadian omic time series and expand MotifMap, a widely used genome-wide map of regulatory sites to better understand circadian regulation; and (3) Develop Circadiomics, an integrated database and web portal as a one-stop shop for circadian data, annotations, and analyses. All data, software, and results will be freely available for academic research purposes and broadly disseminated through multiple channels to benefit both the circadian community and the broader bioinformatics community. Circadian rhythms are fundamental for biology and medicine. Modern high-throughput technologies are revealing how the concentrations of many molecular species, including transcripts, proteins, and metabolites oscillate with the day and night cycle in almost every species, tissue, and cell. In close collaboration with biologists, this project will develop the informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine.",Bioinformatics Tools for Circadian Biology,9537614,R01GM123558,"['Address', 'Ally', 'Architecture', 'Back', 'Biogenesis', 'Bioinformatics', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Cells', 'Characteristics', 'Circadian Rhythms', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Cyanobacterium', 'Data', 'Databases', 'Diabetes Mellitus', 'Diet', 'Disease', 'Drug Targeting', 'Feedback', 'Future', 'Gene Expression Regulation', 'Health', 'Homeostasis', 'Informatics', 'Laboratories', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Link', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Metabolism', 'Modernization', 'Modification', 'Molecular', 'Obesity', 'Organ', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Premature aging syndrome', 'Proteomics', 'Regulation', 'Research', 'Role', 'Scientist', 'Series', 'Site', 'Sleep Wake Cycle', 'System', 'Testing', 'Time', 'Tissues', 'Transcript', 'Update', 'Ursidae Family', 'Vision', 'annotation  system', 'cognitive function', 'cognitive process', 'deep learning', 'direct application', 'genome-wide', 'high throughput analysis', 'high throughput technology', 'insight', 'learning strategy', 'member', 'metabolomics', 'novel', 'precision medicine', 'protein metabolite', 'software development', 'tool', 'transcriptomics', 'virtual', 'web portal']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2018,329257,-0.0017346248703934489
"Genetic neuroscience: How human genes and alleles shape neuronal phenotypes Genetic studies have identified many specific loci with significant associations to psychiatric disorders. However, unless we can develop useful approaches for systematically turning genetic information into neurobiological insights about brain disorders, there is a danger that costly and hard-won genetic findings will not be exploitable to understand pathophysiology and generate important therapeutic hypotheses. The goal of our collaborative, interdisciplinary effort is to develop powerful, generalizable approaches for discovering how risk variants for psychiatric disorders shape neurobiological processes at multiple levels of analysis, and to identify the processes whose dysregulation underlies disease. To do this, we propose to develop new experimental and inferential systems to bridge a longstanding gap between human genetics and experimental biology. We aim to identify biological causes and effects that span the genetic, molecular, and cellular levels of the nervous system. Our interdisciplinary team will develop new experimental systems that measure genetic influences across levels of analysis (RNA, proteins, and cellular function including physiology) in precise, scalable, well- controlled ways. We will make use of emerging cellular systems including three-dimensional cortical spheroids and organoids, and radically novel “population in a dish” experimental systems that collect data on cells from hundreds of donors in a shared environment, inferring donor identity at the time of phenotypic readout. The analysis of such systems in turn requires sophisticated inferential strategies and new ideas from computer science. We propose to develop and widely share experimental and computational resources, including cell lines, methods, datasets, and analytic tools. The successful completion of this work will identify key neurobiological processes for multiple psychiatric disorders, and fortify many other scientists in making such connections in their own work. We hope in so doing to create a new kind of interdisciplinary science that – by combining the strengths of data-driven, unbiased human genetics with the power of emerging experimental systems – transforms the rate at which human- genetic leads lead to insights about disease mechanisms. To better understand common, severe psychiatric illnesses and develop improved treatments for them, we need to understand what specific aspects of brain biology give rise to each disorder. Here a team of scientists with diverse areas of expertise – from neuroscience to computer science to psychiatry to human genetics to stem cell biology – come together to develop a set of next-generation scientific approaches to this important problem, and to generate new methods and data sets that we will widely share. Our team will work to understand how aspects of brain biology at many levels – genes, molecules, and cells – act upon one another to create vulnerability to psychiatric illness.",Genetic neuroscience: How human genes and alleles shape neuronal phenotypes,9568024,U01MH115727,"['Affect', 'Alleles', 'Architecture', 'Area', 'Awareness', 'Biological', 'Biological Assay', 'Biology', 'Brain', 'Brain Diseases', 'California', 'Cell Differentiation process', 'Cell Line', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Computer Analysis', 'Data', 'Data Science', 'Data Set', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Experimental Models', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic study', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Institutes', 'Investments', 'Ion Channel', 'Lead', 'Libraries', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microglia', 'Molecular', 'Molecular Biology', 'Mutation', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Organoids', 'Penetrance', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Process', 'Property', 'Proteins', 'Psychiatry', 'RNA', 'Regenerative Medicine', 'Resources', 'Risk', 'Sampling', 'Science', 'Scientist', 'Shapes', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Work', 'analytical tool', 'cell type', 'computer science', 'computing resources', 'cost', 'cytokine', 'excitatory neuron', 'experimental study', 'genetic information', 'high dimensionality', 'human data', 'improved', 'induced pluripotent stem cell', 'inhibitory neuron', 'innovation', 'insight', 'loss of function mutation', 'neurophysiology', 'next generation', 'novel', 'protein expression', 'protein function', 'rare variant', 'response', 'risk variant', 'stem cell biology', 'translational neuroscience', 'whole genome']",NIMH,"BROAD INSTITUTE, INC.",U01,2018,4132864,-0.01639504357277716
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9518337,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2018,537909,-0.02014861257209457
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs.         PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.            ",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,9567502,U54AT008909,"['Address', 'Archives', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Drug usage', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Procedures', 'Process', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Vulnerable Populations', 'Work', 'base', 'clinical risk', 'clinically relevant', 'data archive', 'data warehouse', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository', 'web portal']",NCCIH,WASHINGTON STATE UNIVERSITY,U54,2018,1776346,-0.015473216185000669
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs. PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,9592655,U54AT008909,"['Address', 'Archives', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Drug usage', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Procedures', 'Process', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Vulnerable Populations', 'Work', 'base', 'clinical risk', 'clinically relevant', 'data archive', 'data warehouse', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository', 'web portal']",NCCIH,WASHINGTON STATE UNIVERSITY,U54,2018,151564,-0.015473216185000669
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs.         PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.            ",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,9746827,U54AT008909,"['Address', 'Archives', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Drug usage', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Procedures', 'Process', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Vulnerable Populations', 'Work', 'base', 'clinical risk', 'clinically relevant', 'data archive', 'data warehouse', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository', 'web portal']",NCCIH,WASHINGTON STATE UNIVERSITY,U54,2018,888473,-0.015473216185000669
"Tools for rapid and accurate structure elucidation of natural products Mapping the Secondary Metabolomes of Marine Cyanobacteria Bacteria are extraordinarily prolific sources of structurally unique and biologically active natural products that derive from a diversity of fascinating biochemical pathways. However, the complete structure elucidation of natural products is often the most time consuming and costly endeavor in natural product drug discovery programs. Compounding this, advancements in genome sequencing have accelerated the identification of unique modular biosynthetic gene clusters in prokaryotes and revealed a wealth of new compounds yet to be isolated and biologically and chemically characterized. Resultantly, there is an urgent and continuing need in this field to connect biosynthetic gene clusters to their respective MS fragmentation signatures in the MS2 molecular networks. The capacity to make such connections will accelerate new compound discovery as well as create associations between gene cluster and biosynthetic pathway, and aid in fast and accurate structure elucidations. Combined with this informatics approach, this proposed continuation project explores innovative methods by which to solve complex molecular structures by enhanced MS and NMR experiments, as well as the development of new algorithms by which to accelerate their analysis. Thus, the overarching goal of this grant is to develop efficient methods that facilitate automated structural classification, structural feature discovery and ultimately efficient structure elucidation of natural products (or any small molecule) and to build an infrastructure that interacts with data input from the community. We will achieve this with the following four specific aims: Aim 1. Integration of MS2 molecular networking with gene cluster networking to rapidly and efficiently locate natural products that have unique molecular architectures; Aim 2. To develop a suite of high sensitivity pulse sequences for natural product structure elucidation; Aim 3. To develop NMR based molecular networking strategies using Deep Convolutional Neural Networks (DCNNs) to facilitate the categorization and structure elucidation of organic compounds; Aim 4. To integrate NMR molecular networking and MS2-based molecular networking as an efficient structure characterization and elucidation strategy. By achieving these aims we will develop an innovative workflow for finding new compounds and for determining their structures, both quickly and accurately. The connection between gene cluster and molecule will shed light on stereochemistry and potential halogenations and methylations. This information can then be used in combination with more efficient NMR and MS methods to accurately determine structures. These tools will be widely shared, such as through the Global Natural Products Social (GNPS) Molecular Network, to enhance the overall capacity of the natural products and organic chemistry communities to solve complex molecular structures.   Natural products are compounds produced by natural sources and about 50 % of FDA approved drugs can trace their origin back to natural products. This proposal aims to use our data set of natural products produced by cyanobacteria for development of analytical tools that will speed- up and stream-line the discovery and structure elucidation of new compounds.  ",Tools for rapid and accurate structure elucidation of natural products,9708387,R01GM107550,"['Algae', 'Algorithms', 'Architecture', 'Back', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Biological Neural Networks', 'Chemicals', 'Classification', 'Communities', 'Complex', 'Cyanobacterium', 'Data', 'Data Set', 'Development', 'FDA approved', 'Family', 'Gene Cluster', 'Genomics', 'Goals', 'Grant', 'Informatics', 'Light', 'Marines', 'Mass Spectrum Analysis', 'Methods', 'Methylation', 'Molecular', 'Molecular Structure', 'Natural Product Drug', 'Natural Products', 'Organic Chemistry', 'Pathway interactions', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Progress Reports', 'Prokaryotic Cells', 'Research Infrastructure', 'Source', 'Speed', 'Stream', 'Structure', 'Techniques', 'Time', 'analog', 'analytical tool', 'base', 'cost', 'deep learning', 'drug discovery', 'experimental study', 'fascinate', 'genome sequencing', 'halogenation', 'innovation', 'metabolome', 'novel', 'programs', 'prototype', 'scaffold', 'small molecule', 'social', 'stereochemistry', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2018,47285,-0.022975238041999104
"Tools for rapid and accurate structure elucidation of natural products Mapping the Secondary Metabolomes of Marine Cyanobacteria Bacteria are extraordinarily prolific sources of structurally unique and biologically active natural products that derive from a diversity of fascinating biochemical pathways. However, the complete structure elucidation of natural products is often the most time consuming and costly endeavor in natural product drug discovery programs. Compounding this, advancements in genome sequencing have accelerated the identification of unique modular biosynthetic gene clusters in prokaryotes and revealed a wealth of new compounds yet to be isolated and biologically and chemically characterized. Resultantly, there is an urgent and continuing need in this field to connect biosynthetic gene clusters to their respective MS fragmentation signatures in the MS2 molecular networks. The capacity to make such connections will accelerate new compound discovery as well as create associations between gene cluster and biosynthetic pathway, and aid in fast and accurate structure elucidations. Combined with this informatics approach, this proposed continuation project explores innovative methods by which to solve complex molecular structures by enhanced MS and NMR experiments, as well as the development of new algorithms by which to accelerate their analysis. Thus, the overarching goal of this grant is to develop efficient methods that facilitate automated structural classification, structural feature discovery and ultimately efficient structure elucidation of natural products (or any small molecule) and to build an infrastructure that interacts with data input from the community. We will achieve this with the following four specific aims: Aim 1. Integration of MS2 molecular networking with gene cluster networking to rapidly and efficiently locate natural products that have unique molecular architectures; Aim 2. To develop a suite of high sensitivity pulse sequences for natural product structure elucidation; Aim 3. To develop NMR based molecular networking strategies using Deep Convolutional Neural Networks (DCNNs) to facilitate the categorization and structure elucidation of organic compounds; Aim 4. To integrate NMR molecular networking and MS2-based molecular networking as an efficient structure characterization and elucidation strategy. By achieving these aims we will develop an innovative workflow for finding new compounds and for determining their structures, both quickly and accurately. The connection between gene cluster and molecule will shed light on stereochemistry and potential halogenations and methylations. This information can then be used in combination with more efficient NMR and MS methods to accurately determine structures. These tools will be widely shared, such as through the Global Natural Products Social (GNPS) Molecular Network, to enhance the overall capacity of the natural products and organic chemistry communities to solve complex molecular structures.   Natural products are compounds produced by natural sources and about 50 % of FDA approved drugs can trace their origin back to natural products. This proposal aims to use our data set of natural products produced by cyanobacteria for development of analytical tools that will speed- up and stream-line the discovery and structure elucidation of new compounds.  ",Tools for rapid and accurate structure elucidation of natural products,9514181,R01GM107550,"['Algae', 'Algorithms', 'Architecture', 'Back', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Biological Neural Networks', 'Chemicals', 'Classification', 'Communities', 'Complex', 'Cyanobacterium', 'Data', 'Data Set', 'Development', 'FDA approved', 'Family', 'Gene Cluster', 'Genomics', 'Goals', 'Grant', 'Informatics', 'Light', 'Marines', 'Mass Spectrum Analysis', 'Methods', 'Methylation', 'Molecular', 'Molecular Structure', 'Natural Product Drug', 'Natural Products', 'Organic Chemistry', 'Pathway interactions', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Progress Reports', 'Prokaryotic Cells', 'Research Infrastructure', 'Source', 'Speed', 'Stream', 'Structure', 'Techniques', 'Time', 'analog', 'analytical tool', 'base', 'cost', 'deep learning', 'drug discovery', 'experimental study', 'fascinate', 'genome sequencing', 'halogenation', 'innovation', 'metabolome', 'novel', 'programs', 'prototype', 'scaffold', 'small molecule', 'social', 'stereochemistry', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2018,541095,-0.022975238041999104
"Center for Sub-Cellular Genomics A cell is a highly complex system with distributed molecular physiologies in structured sub- cellular compartments whose interplay with the nuclear genome determine the functional characteristics of the cell. A classic example of distributed genomic processes is found in neurons. Learning and memory requires modulation of individual synapses through RNA localization, localized translation, and localized metabolites such as those from dendritic mitochondria. Dendrites of neurons integrate distributed synaptic signals into both electrical and nuclear transcriptional response. Dysfunction of these distributed genomic functions in neurons can result in a broad spectrum of neuropsychiatric diseases such as bipolar and depressive disorders, autism, among others. Understanding complex genomic interactions within a single cell requires new technologies: we need nano-scale ability to make genome-wide measurements at highly localized compartments and to effect highly localized functional genomic manipulations, especially in live tissues. To address this need, we propose to establish a Center for Sub-Cellular Genomics using neurons as model systems. The center will develop new optical and nanotechnology approaches to isolate sub-cellular scale components for genomic, metabolomics, and lipidomic analyses. The center will also develop new mass spectrometry methods, molecular biology methods, and informatics models to create a platform technology for sub-cellular genomics. Many human diseases, especially neuropsychiatric diseases, can be traced to dysfunction of organelles and other sub-cellular components. This project will create novel technologies to study function and dysfunction of sub-cellular processes and apply them to study of neurons.",Center for Sub-Cellular Genomics,9488697,RM1HG010023,"['Address', 'Alzheimer&apos', 's Disease', 'Attention', 'Autistic Disorder', 'Automobile Driving', 'Awareness', 'Biological Assay', 'Biological Models', 'Bipolar Disorder', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Cellular biology', 'Characteristics', 'Chromatin', 'Communities', 'Complex', 'Data', 'Dendrites', 'Depressive disorder', 'Devices', 'Disease', 'Education and Outreach', 'Educational workshop', 'Functional disorder', 'Genetic Transcription', 'Genome', 'Genomics', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Informatics', 'Institution', 'Investigation', 'Learning', 'Liquid substance', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Memory', 'Mental Depression', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Molecular Biology', 'Motivation', 'Nanotechnology', 'Neurodegenerative Disorders', 'Neurons', 'Nuclear', 'Optical Methods', 'Optics', 'Organelles', 'Output', 'Pathway interactions', 'Phenotype', 'Philadelphia', 'Physiology', 'Process', 'Proteins', 'RNA', 'Regulation', 'Research Project Grants', 'Resolution', 'Risk', 'Rodent', 'Role', 'Schizophrenia', 'Signal Transduction', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Traumatic Brain Injury', 'Variant', 'Work', 'autism spectrum disorder', 'base', 'deep learning', 'epigenomics', 'exosome', 'experience', 'flexibility', 'functional genomics', 'genome-wide', 'human disease', 'macromolecule', 'metabolomics', 'multimodality', 'nanoscale', 'neuropsychiatric disorder', 'new technology', 'novel', 'outreach', 'response', 'subcellular targeting', 'technology development', 'technology validation', 'tool', 'transcriptome', 'welfare', 'whole genome']",NHGRI,UNIVERSITY OF PENNSYLVANIA,RM1,2018,1000000,-0.022357379423709384
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9365558,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Cereals', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Models', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'molecular modeling', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2017,264299,-0.016037481156380606
"Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach Project Summary Biology is full of stunning examples of emergent behaviors – behaviors that arise from, but cannot be reduced to, the interactions of the constituent parts that make up the system under consideration. These behaviors span the full spectrum of length scales, from the emergence of distinct cell fates (e.g. neurons, muscle, etc.) due to the interactions of genes within cells, to the formation of complex ecological communities arising from the interactions of thousands of species. The overarching goal of my research is to develop new conceptual, theoretical, and computational tools to model such emergent, system-level behaviors in biology. To do so, we utilize an interdisciplinary approach that is grounded in Biological Physics, but draws heavily from Machine Learning, Information Theory, and Theoretical Ecology. Our work is unified and distinguished by our deep commitment to integrating theory with the vast amount of biological data now being generated by modern DNA sequencing-based techniques and quantitative microscopy. An important goal of the proposed research is to find common concepts and tools that transcend traditional biological sub-disciplines and models systems. The proposed research pursues four distinct but conceptually interrelated research directions: (1) understanding how distinct cell fates emerge from bimolecular interactions within mammalian cells (2) investigating how bimolecular networks within cells exploit energy consumption to improve computations, with applications to Synthetic Biology; (3) identifying the ecological principles governing community assembly in microbial communities and developing techniques for synthetically engineering ecological communities; and (4) developing new machine learning algorithms and techniques for biological data analysis. In addition to developing physics-based models for diverse biological phenomena, the proposed research will yield a series of practical important tools and algorithms which we will make publically available including: (1) a new linear-algebra based algorithm for assessing the fidelity of directed differentiation and cellular reprogramming protocols and visualizing reprogramming/differentiation dynamics and (2) improved algorithms for inferring microbial interactions in the human microbiome from high-throughput sequence data. These computational tools will allow scientists to realize the immense therapeutic potential of cellular reprogramming and microbial ecology-based techniques for studying and treating human disease. Project Narrative This project will develop new theoretical and computational tools that will allow scientists to realize the immense therapeutic potential of cellular reprogramming (the conversion of one cell type into another cell type) and microbial ecology-based techniques for studying and treating human diseases.",Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach,9317502,R35GM119461,"['Algorithms', 'Behavior', 'Biological', 'Biological Models', 'Biological Phenomena', 'Biology', 'Cells', 'Communities', 'Complex', 'Consumption', 'DNA sequencing', 'Data', 'Data Analyses', 'Discipline', 'Ecology', 'Engineering', 'Goals', 'Human Microbiome', 'Information Theory', 'Length', 'Linear Algebra', 'Machine Learning', 'Mammalian Cell', 'Modeling', 'Modernization', 'Muscle', 'Neurons', 'Physics', 'Protocols documentation', 'Quantitative Microscopy', 'Research', 'Scientist', 'Series', 'System', 'Systems Biology', 'Techniques', 'Therapeutic', 'Transcend', 'Work', 'base', 'cell type', 'computerized tools', 'gene interaction', 'human disease', 'improved', 'interdisciplinary approach', 'microbial', 'microbial community', 'microorganism interaction', 'synthetic biology', 'theories', 'tool']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2017,309030,-0.011384054376679578
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9355693,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2017,406785,0.018909860294231837
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9209155,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2017,1354554,0.019443859235429715
"Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Summary: Viruses are ubiquitous in almost every ecological environment including the human body, water, soil, etc. They play important roles in the normal function of human microbiome. Many viruses have been shown to be associated with human diseases. However, our understanding of the roles of viruses in ecological communities is very limited. Recent technological and computational advances make it possible to have a deep understanding of the roles of viruses in public health and the environment. Metagenomics studies from various environments including the human microbiome projects (HMP), global ocean, and the earth microbiome projects have generated large amounts of short read data. Viruses are present in most of these metagenomic data sets and their hosts are unknown. In this proposal, the investigators will develop computational approaches for the identification of viral sequences from metagenomic data sets and for the study of virus-host interactions. For the identification of viral sequences from metagenomics samples, novel statistical measures using word patterns will first be developed. Second, a unified naïve Bayesian integrative approach by combining information from word patterns, gene directionality, and gene annotation will be studied. Third, the identified viral sequences from metagenomes will be further assembled to construct complete viral genomes using a novel binning approach to be developed by the investigators. Finally, the remaining reads will be assigned to the corresponding bins. For the study of virus- host interactions, computational methods to estimate the reliability of virus-host interactions from high-throughput experiments will first be developed. Then machine learning approaches will be developed to predict viruses infecting certain hosts. Finally, a network logistic regression approach will be developed to predict virus-host interactions. These computational approaches for the identification of viral sequences and for predicting virus-host interactions will be applied to a public liver cirrhosis and a unique metagenomics data set to understand how metagenomes change with health status, identify viruses and virus-host interactions associated with disease status and accurately predict disease status using bacteria, viruses and virus-host interactions. The developed computational methods will also be used to analyze metageomic data from various locations based on the TARA ocean data and a unique time series data to understand how environmental factors affect virus abundance and virus-host interactions. Some of the predictions will be experimentally validated. Software derived from the proposal will be developed and freely distributed to the scientific community. Project Narrative Viruses are abundant in many environments and are important to public health. New statistical and computational tools will be developed for the identification of viral sequences from metagenomics samples and for the prediction of virus-host interactions. These tools will be used to analyze microbial data sets related to liver cirrhosis and travelers’ diarrhea as well as marine metagenomics data sets from various geographic locations and time series.",Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications,9312083,R01GM120624,"['Affect', 'Bacteria', 'Biological', 'Body Water', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Environment', 'Environment and Public Health', 'Environmental Risk Factor', 'Functional disorder', 'Genes', 'Genome', 'Geographic Locations', 'Health', 'Health Status', 'Human', 'Human Microbiome', 'Human body', 'Liver Cirrhosis', 'Location', 'Logistic Regressions', 'Machine Learning', 'Marines', 'Measures', 'Metagenomics', 'Methods', 'Microbe', 'Network-based', 'Oceans', 'Organism', 'Pattern', 'Planet Earth', 'Play', 'Policies', 'Public Health', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Series', 'Soil', 'Technology', 'Time', 'Traveler&apos', 's diarrhea', 'Viral', 'Viral Genome', 'Virus', 'Virus Diseases', 'Visualization software', 'base', 'computer studies', 'computerized tools', 'design', 'experimental study', 'human disease', 'interest', 'metagenome', 'microbial', 'microbial community', 'microbiome', 'novel', 'particle', 'statistics', 'tool', 'user-friendly', 'virus host interaction']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2017,395858,0.02105506451195426
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9260548,R01GM120033,"['Address', 'Algorithms', 'Alpha Cell', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cancer Etiology', 'Cardiovascular system', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical practice', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2017,356625,-0.017877975374573828
"Developing Advanced Algorithms to Address Major Computational Challenges in Current Microbiome Research Abstract We propose a three-year interdisciplinary research plan to address two key issues currently facing the metagenomics community. The first issue concerns accurate construction and annotation of OTU tables using  of millions of 16S rRNA sequences, which is one of the most important yet most difficult problems inmicrobiome data analysis. Currently, it lacks computational algorithms capable of handling extremely large sequence data and constructing biologically consistent OTU tables. We propose a novel method that performs OTU table construction and annotation simultaneously by utilizing input and reference sequences, reference annotations, and data clustering structure within one analytical framework. Dynamic data-driven cutoffs are derived to identify OTUs that are consistent not only with data clustering structure but also with reference annotations. When successfully implemented, our method will generally address the computational needs of processing hundreds of millions of 16S rRNA reads that are currently being generated by large-scale studies. The second issue concerns developing novel methods to extract pertinent information from massive sequence data, thereby facilitating the field shifting from descriptive research to mechanistic studies. We are particularly interested in microbial community dynamics analysis, which can provide a wealth of insight into disease development unattainable through a static experiment design, and lays a critical foundation for developing probiotic and antibiotic strategies to manipulate microbial communities. Traditionally, system dynamics is approached through time-course studies. However, due to economical and logistical constraints, time-course studies are generally limited by the number of samples examined and the time period followed. With the rapid development of sequencing technology, many thousands of samples are being collected in large-scale studies. This provides us with a unique opportunity to develop a novel analytical strategy to use static data, instead of time-course data, to study microbial community dynamics. To our knowledge, this is the first time that massive static data is used to study dynamic aspects of microbial communities. When successfully implemented, our approach can effectively overcome the sampling limitation of time-course studies, and opens a new avenue of research to study microbial dynamics underlying disease development without performing a resource-intensive time-course study. The proposed pipeline will be intensively tested on a large oral microbiome dataset consisting of ~2,600 subgingival samples (~330M reads). The analysis can significantly advance our understanding of dynamic behaviors of oral microbial communities possibly contributing to the development of periodontal disease. To our knowledge, no prior work has been performed on this scale to study oral microbial community dynamics. We have assembled a multidisciplinary team that covers expertise spanning the areas of machine learning, bioinformatics, and oral microbiology. The expected outcome of this work will be a set of computational tools of high utility for the microbiology community and beyond. The human microbiome plays essential roles in many important physiological processes. We propose an interdisciplinary research plan to address some major computational challenges in current microbiome research. If successfully implemented, this work could significantly expand the capacity of existing pipelines for large-scale data analysis and scientific discovery, resulting in a significant impact on the field.",Developing Advanced Algorithms to Address Major Computational Challenges in Current Microbiome Research,9270498,R01AI125982,"['Address', 'Algorithms', 'Antibiotics', 'Area', 'Big Data', 'Bioinformatics', 'Biological', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Epidemiology', 'Floods', 'Foundations', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Interdisciplinary Study', 'Knowledge', 'Logistics', 'Machine Learning', 'Metagenomics', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral', 'Oral Microbiology', 'Outcome', 'Periodontal Diseases', 'Physiological Processes', 'Play', 'Probiotics', 'Research', 'Resources', 'Ribosomal RNA', 'Role', 'Sampling', 'Structure', 'System', 'Taxonomy', 'Technology', 'Testing', 'Time', 'Work', 'base', 'cohort', 'computerized tools', 'design', 'dynamic system', 'epidemiology study', 'experimental study', 'innovation', 'insight', 'interest', 'microbial', 'microbial community', 'microbiome', 'microbiota', 'multidisciplinary', 'novel', 'open source', 'oral behavior', 'oral microbiome', 'response', 'tumor progression', 'web app']",NIAID,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2017,311153,0.009772908439857167
"A platform for mining, visualization and design of microbial interaction networks Project Summary One of the burning questions in the study of the human microbiome is whether and how it is possible to design specific strategies for rebalancing the taxonomic and functional properties of human-associated microbial communities, triggering the transition from “disease states” to “healthy states”. While empirical studies provide strong support for the idea that we may be able to cure, or at least  treat, a number of diseases by simply transplanting microbiomes, or inducing changes through taxonomic or environmental perturbations, to date little mechanistic understanding exists on how microbial communities work, and on how to extend microbiome research from an empirical science to a systematic, quantitative field of biomedicine. We propose here to establish a computational platform--   a database (Aim 1) with fully integrated analytical software (Aims 2 and 3) --- developed for and with the cooperation of the scientific community. The resource goes beyond cataloguing microbial abundances under different condition; its aim is to enable an understanding of networks of interacting species and their condition-dependence, with the goal of eventually facilitating disease diagnosis and prognosis, and designing therapeutic strategies for microbiome intervention. Our project is centered around three key aims: 1.	The creation of a Microbial Interaction Network Database (MIND), a public resource that will collect data on inter-species interactions from metagenomic sequencing projects, computer simulations and direct experiments. This database will be accessed through a web-based platform complemented with tools for microbial interaction network analysis and visualization, akin to highly fruitful tools previously developed for the study of genetic networks; the database will also serve as the public repository of microbial networks associated with human diseases; 2.	The implementation of an integrated tool for simulation of interspecies interactions under different environments, based on genomic data and whole-cell models of metabolism; 3.	The implementation of new algorithms for microbial community analysis and engineering. These algorithms, including stoichiometric, machine-learning and statistical approaches will facilitate a “synthetic ecology” approach to help design strategies (e.g. microbial transplants or probiotic mixtures) for preventing and targeting microbiome-associated diseases. Our work will fill a major gap in current microbiome research, creating the first platform for global microbial interaction data integration, mining and computation. Project Narrative Among the major developments of the genomic revolution has been the ability to identify thousands of microbial species and strains living in communities in 5 major habitats in the human body, and the recognition that the relative abundances of these populations is strongly correlated with environment: disease state, diet, treatment protocol and so on. A major challenge in utilizing the deluge of health relevant data is structuring it into a database that facilitates understanding inter-microbial interactions in these communities. The aim of this proposal is to create a database and integrated computational platform, open to and contributed to by the research community, which will greatly accelerate the conversion of data into health related actionable knowledge.","A platform for mining, visualization and design of microbial interaction networks",9221662,R01GM121950,"['Affect', 'Algorithms', 'Cataloging', 'Catalogs', 'Cell model', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Development', 'Diet', 'Discipline', 'Disease', 'Ecology', 'Ecosystem', 'Empirical Research', 'Engineering', 'Environment', 'Evolution', 'Future', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Habitats', 'Health', 'Human', 'Human Biology', 'Human Microbiome', 'Human body', 'Imagery', 'Individual', 'Intervention', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurable', 'Mediating', 'Metabolic', 'Metabolism', 'Metadata', 'Methods', 'Microbe', 'Mining', 'Nature', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pattern', 'Population', 'Preventive Medicine', 'Probiotics', 'Property', 'Research', 'Resources', 'Science', 'Scientist', 'Structure', 'Taxonomy', 'Technology', 'Therapeutic', 'Time', 'Transplantation', 'Treatment Protocols', 'Work', 'base', 'computer framework', 'data integration', 'data to knowledge', 'design', 'disease diagnosis', 'experimental study', 'feeding', 'genome-wide', 'genomic data', 'human disease', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microbiota transplantation', 'microorganism interaction', 'novel diagnostics', 'novel therapeutics', 'open source', 'outcome forecast', 'prevent', 'repository', 'simulation', 'tool', 'user-friendly']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2017,377226,0.025021311430388115
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9248178,U24HG009446,"['ATAC-seq', 'Alleles', 'Alpha Cell', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2017,2000000,-0.02625320684986402
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),9321115,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug Addiction', 'Drug Receptors', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Epigenetic Process', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Source', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'algorithmic methodologies', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'cloud platform', 'computational chemistry', 'computer science', 'data mining', 'design', 'distinguished professor', 'dopamine transporter', 'drug abuse prevention', 'falls', 'genome-wide', 'genome-wide analysis', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'novel therapeutics', 'operation', 'prevent', 'professor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2017,1080816,-0.0072398512779657176
"Integration and Visualization of Diverse Biological Data ﻿    DESCRIPTION (provided by applicant): The onset of most human disease involves multiple, molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway and treatment contexts. While this system has been probed by the thousands of functional genomics and quantitative genetic studies, careful extraction of signals relevant to these specific contexts is a challenging problem. General integration of these heterogeneous data was an important first step in detecting signals that be used to build networks to generate experimentally-testable hypotheses. However, only by dealing with the fact that disease happens at the intersection of multiple contexts and by integrating functional genomics with quantitative genetics will we be able to move toward a molecular-level understanding of human pathophysiology, which will pave the way to new therapy and drug development.  The long-term goal of this project is to enable such discoveries through the development of innovative bioinformatics frameworks for integrative analysis of diverse functional genomic data. In the previous funding periods, we developed accurate data integration and visualization methodologies for most common model organisms and human, created methods for tissue-specific data analysis, and applied these methods to make novel insights about important biological processes. We further enabled experimental biological discovery by implementing these methods in publicly accessible interactive systems that are popular with experimental biologists.  Leveraging our prior work, we now will directly address the challenge of enabling data-driven study of molecular mechanisms underlying human disease by developing novel semi-supervised and multi-task machine learning approaches and implementing them in a real-time integration system capable of predicting genome-scale functional and mechanism-specific networks focused on any biological context of interest. This will allow any biomedical researcher to quickly make data-driven hypotheses about function, interactions, and regulation of genes involved in hypertension in the kidney glomerulus or to predict new regulatory interactions relevant to Parkinson's disease that affect the ubiquitination pathway in Substantia nigra. Furthermore, we will develop methods for disease gene discovery that leverage these highly specific networks for functional analysis of quantitative genetics data. Our deliverable will be a general, robust, user-friendly, and automatically updated system for user-driven functional genomic data integration and functional analysis of quantitative genetics data. Throughout this work, we (with our close experimental and clinical collaborators) will also apply our methods to chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders both as case studies for the iterative improvement of our methods and to make direct contribution to better understanding of these diseases. PUBLIC HEALTH RELEVANCE: We will create a web-accessible system that will enable biologists and clinicians to generate hypotheses regarding disease-linked genes, molecular mechanisms underlying genetic disorders, and drug discovery for more targeted treatment. Underlying this user-friendly web interface will be novel algorithms for on-the-fly integration of  vast amount of functional genomics and quantitative genetics data based on the context(s) defined by the biologist or clinician. As applied to the three case study areas, chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders, our system has the potential to identify novel disease genes and pathways and to enable development of better diagnostic biomarkers, drug targets, and, in the longer term, treatments.",Integration and Visualization of Diverse Biological Data,9266422,R01GM071966,"['Address', 'Affect', 'Algorithms', 'Animal Model', 'Area', 'Bioinformatics', 'Biological', 'Biological Process', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Complex', 'Computer Systems', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Drug Targeting', 'Expert Systems', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Databases', 'Genetic study', 'Goals', 'Gold', 'Hereditary Disease', 'Human', 'Hypertension', 'Imagery', 'Kidney Glomerulus', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nephrology', 'Network-based', 'Parkinson Disease', 'Pathway interactions', 'Quantitative Genetics', 'Real-Time Systems', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Substantia nigra structure', 'Supervision', 'System', 'Systems Integration', 'Time', 'Tissues', 'Training', 'Ubiquitination', 'Update', 'Work', 'autism spectrum disorder', 'base', 'clinical investigation', 'data integration', 'data visualization', 'diagnostic biomarker', 'drug development', 'drug discovery', 'experimental study', 'functional genomics', 'gene discovery', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'multitask', 'novel', 'novel therapeutics', 'public health relevance', 'targeted treatment', 'therapy development', 'user-friendly', 'web interface', 'web-accessible']",NIGMS,PRINCETON UNIVERSITY,R01,2017,445349,-0.010965965588003362
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design A fundamental challenge to translate insights between biomedical researchers, who study biological mechanisms, and clinicians, who diagnose patient symptoms, is that many links between biological processes and disease pathophysiology are poorly understood. A comprehensive Biomedical Translator must enable chains of inference across objects as diverse as genetic mutations, molecular effects, tissue-specific expression patterns, cellular processes, organ phenotypes, disease states, patient symptoms, and drug responses, a challenge beyond the scope of any one organization. Fortunately, many individual links in this chain have been made by experiments yielding statistical connections between individual data types. High-throughput perturbation screens link chemical and genetic perturbations to cellular phenotypes such as gene-expression patterns, cell survival, or changes in phosphorylation. Genetic association studies link mutations to human disease or intermediate phenotypes and biomarkers. Electronic medical records (EMR) link diseases or human phenotypes to diagnostic or current procedural terminology (CPT) codes, and clinical trials link the impact of drugs and drug candidates on disease states. In principle, incorporating these links into chains of inference could translate results between the full set of data types within them. In practice, each link is maintained by experts with domain-specific experiments, semantic terminology, and methodological standards. While a key challenge faced by a global Biomedical Translator is to establish consistent standards across these existing data types, a more important goal is to develop a principled and robust framework to (a) model biological systems and experimental approaches to investigate them; (b) organize knowledge about biological mechanism and disease; and (c) incorporate diverse datasets that serve as windows into the underlying and unknown state of nature. We propose to implement a Biomedical Translator as a probabilistic graphical model, a paradigm from artificial intelligence (AI) research. Just as separate research communities form weakly coupled parts of the translation process, graphical models allow global inferences from weakly coupled “nodes”. These inferences require each node to publish only probability distributions, enabling interoperability without necessarily having global entity-resolution standards, and benefit from paradigms for quality control, fault tolerance, and relevance assessment common in AI research. We hypothesize that a limited number of APIs, implemented as probability computations by communities around the world, would yield a Biomedical Translator as an emergent property of weakly coupled knowledge sources. From basic properties of graphical models, such a Translator could probabilistically translate among any data types connected within it, allowing for relatively complex query concepts. For example: What cellular processes in which tissues are impacted in a patient-based EMR? What genetic mutations sensitize cells to small-molecule treatment effects? Which small molecules mimic genetic “experiments of nature” that protect against disease? To illustrate the value of these resources and our architectural paradigm, we propose a demonstration project to implement a Biomedical Translator supporting queries between small molecules, biological processes, genes, and disease. The demonstration project will provide a valuable first step to confront key data-integration and organizational challenges and will enable previously impossible queries, such as identifying small molecules that perturb the same biological processes implicated by human genetics in a disease context. In this capacity, such Translator could realistically identify existing drugs for known symptoms (i.e., repurposing), but could more broadly serve as an engine for hypothesis generation and biological discovery, suggesting pre-clinical small molecules to develop based on their observed biological activity, or providing heretofore novel links between cellular protein function and disease pathophysiology. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9540181,OT3TR002025,"['Architecture', 'Artificial Intelligence', 'Biological', 'Biological Models', 'Biological Process', 'Cell Survival', 'Cell physiology', 'Cells', 'Clinical Trials', 'Communities', 'Complex', 'Computerized Medical Record', 'Coupled', 'Current Procedural Terminology Codes', 'DNA Sequence Alteration', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Functional disorder', 'Gene Expression Profile', 'Generations', 'Genetic', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Link', 'Methodology', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Organ', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphorylation', 'Probability', 'Processed Genes', 'Property', 'Publishing', 'Quality Control', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Semantics', 'Source', 'Symptoms', 'Terminology', 'Tissues', 'Translating', 'Translation Process', 'base', 'biological systems', 'chemical genetics', 'data integration', 'design', 'drug candidate', 'experimental study', 'genetic association', 'human disease', 'insight', 'interoperability', 'novel', 'phenotypic biomarker', 'pre-clinical', 'protein function', 'response', 'small molecule', 'treatment effect']",NCATS,"BROAD INSTITUTE, INC.",OT3,2017,651119,-0.005297611872854379
"CSHL Computational and Comparative Genomics Course The Cold Spring Harbor Laboratory proposes to continue a course entitled “Computational and Comparative Genomics”, to be held in the Fall of 2017 – 2019. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases that they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. NARRATIVE The Computational & Comparative Genomics, a 9 day course, is designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,9357752,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'Course Content', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genome', 'Home environment', 'Institution', 'International', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Research Training', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Training Programs', 'Universities', 'Update', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'graduate student', 'instructor', 'interest', 'laboratory experience', 'lecturer', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2017,62304,0.006835991535404915
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9246108,U24DK112331,"['ATAC-seq', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Lead', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Research Infrastructure', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'base', 'bisulfite sequencing', 'cost', 'data resource', 'epigenomics', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'insight', 'medical schools', 'methylome', 'mortality', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2017,93230,-0.015560819001912658
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9508669,U24DK112331,"['ATAC-seq', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Lead', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Research Infrastructure', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'base', 'bisulfite sequencing', 'cost', 'data resource', 'epigenomics', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'insight', 'medical schools', 'methylome', 'mortality', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2017,162828,-0.015560819001912658
"Improving safety and efficacy of platelet transfusion through systems biology Project Summary Platelet transfusion is critical for severely bleeding patients and nearly 6 million units are transfused in the United States and Europe annually. In the United States, platelets are typically stored for 5 days resulting in a waste of 20% of their supply. Short storage duration is a consequence of bacterial contamination and platelet quality considerations. Though many methods have been developed for bacterial testing and pathogen inactivation, fewer have been developed for improving quality of stored platelets. Platelet additive solutions have the possibility to increase storage quality and duration, reduce plasma-related allergic reactions, impact the efficacy of pathogen reduction techniques, and save plasma which can then be used as an additional transfusion product. While the benefits are well known, there has been little progress in developing new platelet additive solutions for increasing quality and safety of platelet transfusion because there is a lack of broad understanding of biochemical and signaling changes during storage. There has been interest to utilize high-throughput metabolite profiling for global understanding of platelet metabolic decline but data analysis of complex datasets has been a daunting challenge. In Phase I of this program, we developed the first, robust computational platform involving statistical analysis and systems biology of metabolic and signaling networks to interpret and analyze PLT metabolomic and proteomic profiles in a complete network context. Using time- course global, quantitative metabolite profiling, we determined that PLTs undergo a non-linear decay process and computationally identified key metabolic enzymes and cellular process that drive this decay. Based on the computational results, we have devised two novel additive solution strategies to mitigate the decay process and improve the length of PLT units. In this Phase II proposal, we will validate the computationally determined additive solutions for efficacy in alleviating the non-linear decay process through 1) metabolomics experiments, and 2) non-metabolic PLT physiology experiments including cell activation and hemostatic effectiveness. A successful additive solution will be progressed to media refinement and preclinical testing. Project Narrative Platelet transfusion units are typically stored for five days in the United States leading to a waste of 20% of units and potential quality concerns. The field is open for innovation as most storage media technologies are derived from work from the early 1990s. This proposal will develop novel computational methods to comprehensively understand the degradation of platelets under storage conditions and experimentally validate new additive solutions for increasing platelet quality and extending shelf life, an area that accounts for $2.5 billion of hospital costs.",Improving safety and efficacy of platelet transfusion through systems biology,9347295,R44HL127843,"['Accounting', 'Agreement', 'Algorithms', 'Allergic Reaction', 'Area', 'Biochemical', 'Biological', 'Biological Preservation', 'Blood', 'Blood Component Removal', 'Blood Platelets', 'Caring', 'Cell physiology', 'Cells', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Effectiveness', 'Enzymes', 'Equipment and supply inventories', 'Europe', 'Formulation', 'Glutathione', 'Hemorrhage', 'Hemostatic Agents', 'Hospital Costs', 'In Vitro', 'Intervention', 'Length', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Mathematics', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Methods', 'Modeling', 'Pathway interactions', 'Patients', 'Phase', 'Physiology', 'Plasma', 'Platelet Transfusion', 'Preclinical Testing', 'Process', 'Production', 'Proteomics', 'Reaction', 'Recovery', 'Resources', 'Risk', 'Safety', 'Signal Pathway', 'Signal Transduction', 'State Hospitals', 'Statistical Data Interpretation', 'Supplementation', 'Surveys', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Transfusion', 'United States', 'Validation', 'Work', 'base', 'cost', 'design', 'experimental study', 'human subject', 'improved', 'insight', 'interest', 'metabolic profile', 'metabolomics', 'model design', 'novel', 'open innovation', 'oxidative damage', 'pathogen', 'programs', 'statistics', 'success', 'time use', 'wasting']",NHLBI,"SINOPIA BIOSCIENCES, INC.",R44,2017,1099022,-0.007148481059462428
"Dopaminergic encoding of counterfactual information in human striatum ﻿    DESCRIPTION (provided by applicant): Diseases and disorders directly affected by dopamine systems (e.g., drug addiction and Parkinson's disease) highlight the importance of these systems in motivated human behavior and cognition. The dopamine system is known to be a critical component of normal learning, reward processing, and decision-making (reviewed in Montague et al., 2004). Unfortunately, our present knowledge of dopamine systems in human brains is relatively sparse compared to the wealth of experimentation and computational modeling on these systems in rodents and non-human primates. Previously, technological constraints have limited direct experimentation in human brains. This proposal capitalizes on our group's recent technological innovation, which was supported by the NIH R21 mechanism - CEBRA: R21DA024140 - and resulted in the successful completion of the first sub-second measurements of dopamine release in a human brain. Furthermore, these measurements took place during an active decision-making task that was framed by computational models of learning and reward processing (Kishida et al., 2011 and Kishida et al., under review). We propose to pursue three specific aims, which combine our technological advance with active learning tasks designed to probe the role of dopamine in human behavior. Our aims incorporate three learning signals, where actual and counterfactual experience will each be examined in human striatal responses. The proposed work will inform on the controversial role for dopamine in reward/movement interactions. The experiments proposed will yield unprecedented insight into the function of the dopamine system in the humans afflicted with Parkinson's disease and Essential Tremor. With the support of the NIH (R21DA024140), our team successfully developed a complete prototype system for making electrochemical measurements of dopamine delivery in the human brain. Feasibility has been demonstrated by obtaining the first dopamine measurements in the striata of subjects with Parkinson's during a decision-making task. This substantial preliminary work is now ready for a larger scale with specific hypothesis testing about the role of dopamine systems in Parkinson's disease, Essential tremor, and human decision-making and behavior. PUBLIC HEALTH RELEVANCE: Experiments and computational models (primarily investigated in rodents and non-human primates) suggest dopamine systems in the brain are essential for normal learning, reward-processing, and ongoing decision- making. This proposal builds upon our group's innovative work, which - for the first time - recorded sub- second measurements of dopamine in human subjects and amalgamated these measurements with computational models of dopamine function. Herein we propose to use this newly developed technology to generate unprecedented insight into the function of dopamine systems directly in humans.",Dopaminergic encoding of counterfactual information in human striatum,9308020,R01NS092701,"['Active Learning', 'Acute', 'Affect', 'Animal Model', 'Behavior', 'Brain', 'Brain Diseases', 'Cells', 'Cessation of life', 'Cognition', 'Cognitive', 'Computer Simulation', 'Corpus striatum structure', 'Coupling', 'Data', 'Decision Making', 'Disease', 'Dopamine', 'Drug Addiction', 'Electrodes', 'Essential Tremor', 'Exploratory/Developmental Grant', 'Funding', 'Human', 'Knowledge', 'Learning', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Movement Disorders', 'Operative Surgical Procedures', 'Parkinson Disease', 'Participant', 'Patients', 'Periodicity', 'Phase', 'Play', 'Replacement Therapy', 'Research Personnel', 'Rewards', 'Rodent', 'Role', 'Sample Size', 'Scanning', 'Signal Transduction', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'blood oxygenation level dependent response', 'cognitive function', 'design', 'dopamine system', 'dopaminergic neuron', 'experience', 'experimental study', 'extracellular', 'human subject', 'implantation', 'innovation', 'insight', 'nonhuman primate', 'prototype', 'public health relevance', 'putamen', 'reduce symptoms', 'relating to nervous system', 'response', 'reward processing', 'social', 'symptomatic improvement', 'technological innovation', 'temporal measurement']",NINDS,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2017,492125,-0.0009656777602808868
"Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition",9302935,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Gene Targeting', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R01,2017,668125,-0.01134044728429158
"Genetic neuroscience: How human genes and alleles shape neuronal phenotypes Genetic studies have identified many specific loci with significant associations to psychiatric disorders. However, unless we can develop useful approaches for systematically turning genetic information into neurobiological insights about brain disorders, there is a danger that costly and hard-won genetic findings will not be exploitable to understand pathophysiology and generate important therapeutic hypotheses. The goal of our collaborative, interdisciplinary effort is to develop powerful, generalizable approaches for discovering how risk variants for psychiatric disorders shape neurobiological processes at multiple levels of analysis, and to identify the processes whose dysregulation underlies disease. To do this, we propose to develop new experimental and inferential systems to bridge a longstanding gap between human genetics and experimental biology. We aim to identify biological causes and effects that span the genetic, molecular, and cellular levels of the nervous system. Our interdisciplinary team will develop new experimental systems that measure genetic influences across levels of analysis (RNA, proteins, and cellular function including physiology) in precise, scalable, well- controlled ways. We will make use of emerging cellular systems including three-dimensional cortical spheroids and organoids, and radically novel “population in a dish” experimental systems that collect data on cells from hundreds of donors in a shared environment, inferring donor identity at the time of phenotypic readout. The analysis of such systems in turn requires sophisticated inferential strategies and new ideas from computer science. We propose to develop and widely share experimental and computational resources, including cell lines, methods, datasets, and analytic tools. The successful completion of this work will identify key neurobiological processes for multiple psychiatric disorders, and fortify many other scientists in making such connections in their own work. We hope in so doing to create a new kind of interdisciplinary science that – by combining the strengths of data-driven, unbiased human genetics with the power of emerging experimental systems – transforms the rate at which human- genetic leads lead to insights about disease mechanisms. To better understand common, severe psychiatric illnesses and develop improved treatments for them, we need to understand what specific aspects of brain biology give rise to each disorder. Here a team of scientists with diverse areas of expertise – from neuroscience to computer science to psychiatry to human genetics to stem cell biology – come together to develop a set of next-generation scientific approaches to this important problem, and to generate new methods and data sets that we will widely share. Our team will work to understand how aspects of brain biology at many levels – genes, molecules, and cells – act upon one another to create vulnerability to psychiatric illness.",Genetic neuroscience: How human genes and alleles shape neuronal phenotypes,9479556,U01MH115727,"['Affect', 'Alleles', 'Architecture', 'Area', 'Awareness', 'Biological', 'Biological Assay', 'Biology', 'Brain', 'Brain Diseases', 'California', 'Cell Differentiation process', 'Cell Line', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Computer Analysis', 'Data', 'Data Science', 'Data Set', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Experimental Models', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic study', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Institutes', 'Investments', 'Ion Channel', 'Lead', 'Libraries', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microglia', 'Molecular', 'Molecular Biology', 'Mutation', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Organoids', 'Penetrance', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Process', 'Property', 'Proteins', 'Psychiatry', 'RNA', 'Regenerative Medicine', 'Resources', 'Risk', 'Sampling', 'Science', 'Scientist', 'Shapes', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Work', 'analytical tool', 'cell type', 'computer science', 'computing resources', 'cost', 'cytokine', 'excitatory neuron', 'experimental study', 'genetic information', 'high dimensionality', 'human data', 'improved', 'induced pluripotent stem cell', 'inhibitory neuron', 'innovation', 'insight', 'loss of function mutation', 'neurophysiology', 'next generation', 'novel', 'protein expression', 'protein function', 'rare variant', 'response', 'risk variant', 'stem cell biology', 'translational neuroscience', 'whole genome']",NIMH,"BROAD INSTITUTE, INC.",U01,2017,4412707,-0.01639504357277716
"Development of integrative models for early liver toxicity assessment ﻿    DESCRIPTION (provided by applicant): Computational toxicology has become a critical area of research due to the burgeoning need to evaluate thousands of pharmaceutical and environmental chemicals with unknown toxicity profiles, the high demand in time and resources by current experimental toxicity testing, and the growing ethical concerns over animal use in toxicity studies. Despite tremendous efforts, little success has been attained thus far in the development of predictive computational models for toxicity, primarily due to the complexity of toxicity mechanisms as well as the lack of high-quality experimental data for model development.  A critical challenge in toxicity testing of chemicals is that toxicity effects are doe-dependent: the true toxic hits may show no toxicity at all at low dose level. Therefore, traditiona high-throughput screening (HTS) that test chemicals only at a single concentration is not suitable for toxicity screening. On the contrary, the recently developed quantitative high-throughput screening (qHTS) platforms can evaluate each chemical across a broad range of concentrations, and is gaining ever-increasing popularity as a tool for in vitro toxicity profiling The concentration-response information generated by qHTS are expected to provide more accurate and comprehensive information of the toxicity effects of chemicals, offering promising data that can be mined to estimate in vivo toxicities of chemicals. However, our previous studies showed that if processed inappropriately, such concentration-response information contribute little to improve the toxicity prediction. This is especially true when multiple types of qHTS data are used together. Therefore, in this study, we will extend our previous approaches to develop novel statistical and computational tools that can curate, preprocess, and normalize the concentration-response information from multiple different qHTS databases.  Traditionally, toxicity models are based on either the chemical data (such as the quantitative structure- activity relationship analysis), or the in vitro toxicity profiling data (such as the in vitro-in vivo extrapolations). Our previous experiences suggested that integrating biological descriptors such as the in vitro cytotoxicity profiles or the short-term toxigenomic data, with chemical structural features is able to predict rodent acute liver toxicity with reasonable accuracy. Therefore, the second part of this proposal will be devoted to develop novel computational models for hepatotoxicity prediction by integrating qHTS toxicity profiles and chemical structural information In Aim 1, we will curate, preprocess, and normalize collected public liver toxicity datasets. In ths study, we will model toxicity effects using multiple large public datasets such as HTS and qHTS bioassay data (Tox21[1] and ToxCast[2]), hepatotoxicity side effect reports on marketed failed drugs[3], the Liver Toxicity Knowledge Base Benchmark Dataset (LTKB-BD[4]), etc. Statistical methods for cross-study validation and quality control will be applied to the collected datasets to ensure computational compatibility and to select the appropriate datasets for analysis. In Aim 2, we will develop predictive models for chemicals' liver toxicity based on an integrative modeling workflow that will make use of both structural and in vitro toxicity profiles of a chemical. Our previous studies [5] showed that models using both in vitro toxicity profiles and chemical structural data have better accuracy for rodent acute liver toxicity than models using either data type alone. Here, we will develop a novel modeling workflow that start with defining the functional clusters of chemicals via curated qHTS toxicity profiles, and is followed by developing computational models to correlate chemical and biological data with overall toxicity risks in humans. The predictive models will be validated using independent datasets with over 800 compounds. In Aim 3, we propose to prioritize the qHTS profiling assays used in the model for future toxicity testing. We will evaluate all the in vitro assays as biological descriptors from thee perspectives, including descriptor importance in the integrative toxicity model, correlation with i vivo DILI outcomes, and level of information content estimated by a novel approach based on network analysis. PUBLIC HEALTH RELEVANCE: In this study we aim to develop computational models that can identify potential liver toxicants. Liver toxicity is a significant contributor to the high attition rate in drug development. Moreover, toxic chemicals in food, water, and consumer products all pose serious risks for liver toxicity. As a result, there is great interest in developing high-throughput, high-content experimental and computational tools to evaluate the liver toxicity of thousands of pharmaceutical and environmental chemicals. This study focuses on developing novel informatics tools that enable the extraction and integration of chemical concentration-response information from multiple quantitative high-throughput screening databases for model development, and developing statistical models that are able to integrate this concentration-response information with chemical structural features to predict their risk of liver toxicity.  ",Development of integrative models for early liver toxicity assessment,9333370,R03ES026397,"['Acute', 'Address', 'Adverse effects', 'Algorithms', 'Animals', 'Area', 'Benchmarking', 'Biological', 'Biological Assay', 'Chemical Models', 'Chemicals', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Dose', 'Dreams', 'Ensure', 'Ethics', 'Food', 'Future', 'Gene Expression', 'Genomics', 'Goals', 'Gold', 'Hepatotoxicity', 'Human', 'In Vitro', 'Informatics', 'International', 'Liver', 'Machine Learning', 'Marketing', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Environmental Health Sciences', 'Nature', 'Network-based', 'North Carolina', 'Outcome', 'Pathway Analysis', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Poison', 'Process', 'Productivity', 'Quality Control', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Resources', 'Risk', 'Rodent', 'Scientist', 'Shapes', 'Statistical Methods', 'Statistical Models', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicogenetics', 'Toxicology', 'Translational Research', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'Universities', 'Variant', 'Water', 'base', 'computational toxicology', 'computerized tools', 'consumer product', 'cost', 'cost effective', 'cytotoxicity', 'data modeling', 'drug development', 'drug market', 'drug withdrawal', 'environmental chemical', 'experience', 'high throughput screening', 'improved', 'in vitro Assay', 'in vivo', 'interest', 'knowledge base', 'liver injury', 'model development', 'novel', 'novel strategies', 'preclinical study', 'predictive modeling', 'programs', 'public health relevance', 'response', 'screening', 'success', 'tool', 'toxicant', 'validation studies']",NIEHS,UT SOUTHWESTERN MEDICAL CENTER,R03,2017,81000,-0.0023448403877898384
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs.         PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.            ",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,9346658,U54AT008909,"['Address', 'Archives', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Drug usage', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Procedures', 'Process', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Vulnerable Populations', 'Work', 'base', 'clinical risk', 'clinically relevant', 'data archive', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository', 'web portal']",NCCIH,WASHINGTON STATE UNIVERSITY,U54,2017,1832235,-0.015473216185000669
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs. PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,9386165,U54AT008909,"['Address', 'Archives', 'Clinical', 'Clinical Management', 'Clinical assessments', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Drug usage', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Procedures', 'Process', 'Quality Control', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Vulnerable Populations', 'Work', 'base', 'clinical risk', 'clinically relevant', 'data archive', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository', 'web portal']",NCCIH,UNIVERSITY OF WASHINGTON,U54,2017,284531,-0.015473216185000669
"Bioinformatics Tools for Circadian Biology Circadian rhythms are fundamental for understanding biology: they date back to the origin of life, they are found in virtually every species from cyanobacteria to mammals, and they coordinate many important biological functions from the sleep-wake cycle, to metabolism, and to cognitive functions. Circadian rhythms are equally fundamental for health and medicine: modifications in diet have been linked to modification in circadian rhythms at the molecular level; disruptions of circadian rhythms have been linked to health problems ranging from depression, to learning disorders, to diabetes, to obesity, to cardiovascular disease, to cancer, and to premature ageing; finally, a large fraction of drug targets have been found to oscillate in a circadian manner in one or several tissues, suggesting that a better understanding of circadian oscillations at the molecular level could have direct applications to precision medicine, for instance by optimizing the time at which drugs are taken.  To better understand circadian oscillations at the molecular level, modern high-throughput technologies are being used to measure the concentrations of many molecular species, including transcripts, proteins, and metabolites along the circadian cycle in different organs and tissues, and under different conditions. However, the informatics tools for processing, analyzing, and integrating the growing wealth of molecular circadian data are not yet in place.  This effort will fill this fundamental gap by developing and disseminating informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine. Specifically, through a close collaborations between computational and experimental scientists, this effort will: (1) Bring the power of deep learning methods to bear on the analyses of omic time series to determine, for instance, which molecular species are oscillating, their characteristics (period, phase, amplitude), and to predict the time/phase associated with a measurement taken at a single time point; (2) Develop Cyber-TC, an extension of the widely used Cyber-T software, for the differential analysis of circadian omic time series and expand MotifMap, a widely used genome-wide map of regulatory sites to better understand circadian regulation; and (3) Develop Circadiomics, an integrated database and web portal as a one-stop shop for circadian data, annotations, and analyses. All data, software, and results will be freely available for academic research purposes and broadly disseminated through multiple channels to benefit both the circadian community and the broader bioinformatics community. Circadian rhythms are fundamental for biology and medicine. Modern high-throughput technologies are revealing how the concentrations of many molecular species, including transcripts, proteins, and metabolites oscillate with the day and night cycle in almost every species, tissue, and cell. In close collaboration with biologists, this project will develop the informatics tools that will enable the collection, integration, and analyses of this wealth of information and lead to novel and fundamental insights about the organization and regulation of circadian oscillations, their roles in health and disease, and their future applications to precision medicine.",Bioinformatics Tools for Circadian Biology,9325275,R01GM123558,"['Address', 'Ally', 'Architecture', 'Back', 'Biogenesis', 'Bioinformatics', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Cells', 'Characteristics', 'Circadian Rhythms', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Cyanobacterium', 'Data', 'Databases', 'Diabetes Mellitus', 'Diet', 'Disease', 'Drug Targeting', 'Feedback', 'Future', 'Gene Expression Regulation', 'Health', 'Homeostasis', 'Informatics', 'Laboratories', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Link', 'Malignant Neoplasms', 'Mammals', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Mental Depression', 'Metabolism', 'Modernization', 'Modification', 'Molecular', 'Obesity', 'Organ', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Plasticizers', 'Premature aging syndrome', 'Proteomics', 'Regulation', 'Research', 'Role', 'Scientist', 'Series', 'Site', 'Sleep Wake Cycle', 'System', 'Testing', 'Time', 'Tissues', 'Transcript', 'Update', 'Ursidae Family', 'Vision', 'annotation  system', 'cognitive function', 'cognitive process', 'direct application', 'genome-wide', 'high throughput analysis', 'high throughput technology', 'insight', 'learning strategy', 'member', 'metabolomics', 'novel', 'precision medicine', 'protein metabolite', 'software development', 'tool', 'transcriptomics', 'virtual', 'web portal']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2017,324508,-0.0017346248703934489
"Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach Project Summary Biology is full of stunning examples of emergent behaviors – behaviors that arise from, but cannot be reduced to, the interactions of the constituent parts that make up the system under consideration. These behaviors span the full spectrum of length scales, from the emergence of distinct cell fates (e.g. neurons, muscle, etc.) due to the interactions of genes within cells, to the formation of complex ecological communities arising from the interactions of thousands of species. The overarching goal of my research is to develop new conceptual, theoretical, and computational tools to model such emergent, system-level behaviors in biology. To do so, we utilize an interdisciplinary approach that is grounded in Biological Physics, but draws heavily from Machine Learning, Information Theory, and Theoretical Ecology. Our work is unified and distinguished by our deep commitment to integrating theory with the vast amount of biological data now being generated by modern DNA sequencing-based techniques and quantitative microscopy. An important goal of the proposed research is to find common concepts and tools that transcend traditional biological sub-disciplines and models systems. The proposed research pursues four distinct but conceptually interrelated research directions: (1) understanding how distinct cell fates emerge from bimolecular interactions within mammalian cells (2) investigating how bimolecular networks within cells exploit energy consumption to improve computations, with applications to Synthetic Biology; (3) identifying the ecological principles governing community assembly in microbial communities and developing techniques for synthetically engineering ecological communities; and (4) developing new machine learning algorithms and techniques for biological data analysis. In addition to developing physics-based models for diverse biological phenomena, the proposed research will yield a series of practical important tools and algorithms which we will make publically available including: (1) a new linear-algebra based algorithm for assessing the fidelity of directed differentiation and cellular reprogramming protocols and visualizing reprogramming/differentiation dynamics and (2) improved algorithms for inferring microbial interactions in the human microbiome from high-throughput sequence data. These computational tools will allow scientists to realize the immense therapeutic potential of cellular reprogramming and microbial ecology-based techniques for studying and treating human disease. Project Narrative This project will develop new theoretical and computational tools that will allow scientists to realize the immense therapeutic potential of cellular reprogramming (the conversion of one cell type into another cell type) and microbial ecology-based techniques for studying and treating human diseases.",Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach,9137947,R35GM119461,"['Algorithms', 'Behavior', 'Biological', 'Biological Models', 'Biological Phenomena', 'Biology', 'Cells', 'Communities', 'Complex', 'Consumption', 'DNA Sequence', 'Data', 'Data Analyses', 'Discipline', 'Ecology', 'Engineering', 'Goals', 'High-Throughput Nucleotide Sequencing', 'Human Microbiome', 'Information Theory', 'Length', 'Linear Algebra', 'Machine Learning', 'Mammalian Cell', 'Modeling', 'Muscle', 'Neurons', 'Physics', 'Protocols documentation', 'Quantitative Microscopy', 'Research', 'Scientist', 'Series', 'System', 'Systems Biology', 'Techniques', 'Therapeutic', 'Transcend', 'Work', 'base', 'cell type', 'computerized tools', 'gene interaction', 'human disease', 'improved', 'interdisciplinary approach', 'microbial', 'microbial community', 'microorganism interaction', 'synthetic biology', 'theories', 'tool']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2016,302664,-0.011384054376679578
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9241579,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'improved', 'infancy', 'insight', 'model building', 'network models', 'novel', 'research study', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2016,409580,0.018909860294231837
"A Machine-Learning Based Software Widget for Resolving Metabolite Identities Owing to recent technological advances in measurement platforms, it is now possible to simultaneously detect and characterize a very large number of metabolites covering a substantial fraction of the small molecules present in a biological sample. This presents an exciting opportunity to develop potentially transformative approaches to study cells and organisms. One major challenge in realizing this potential lies in processing and analyzing the data. A typical dataset from an untargeted experiment contains many of thousands of “features,” each of which could correspond to a unique metabolite. Analyzing such datasets to obtain meaningful biological information depends on reliably and efficiently resolving the chemical identities of the detected features. Currently, in silico fragmentation methods predict candidate metabolites that are scored and ranked based on how well the fragmentation explains the observed MS/MS spectrum, and on other factors influencing fragmentation such as bond dissociation energies and ionization conditions. Deciding which candidate metabolites is the best match for a particular feature in the context of the biological sample, however, is a daunting task. Extensive testing of candidate metabolites against chemical standards library may be prohibitive in terms of cost and efforts. We seek to develop software-enabled workflows centered on resolving metabolite identities. Our approach is to exploit knowledge of the biological context of a sample to identify the metabolites. Recognizing that the metabolites present in a sample result from enzyme-catalyzed biochemical reactions active in the corresponding biological system, we employ topological analysis and inference to best map the metabolites implied by the detected features to metabolic pathways that are feasible based on the genome(s) of cells in the biological system. Aim 1 develops a computational method based on Bayesian-inference to enhance candidate metabolite rankings that are obtained via in silico fragmentation analysis. Our method utilizes all available information (database lookups, in silico fragmentation analysis, and network/pathway context) to maximally inform and adjust the rankings. Aim 2 will build software widgets to implement the metabolite identification workflow within a data-analytics framework. As the analytics framework, we will use Orange, which allows the user to create interactive data analysis pipelines through a plug-and-play graphical user interface (GUI). Aim 3 will validate the computational method and software widget implementation. Experimental validation will utilize high-purity standards to confirm (or reject) the computationally assigned metabolite identities. Widget implementation will be evaluated through a focus group discussion with the widget users in the labs directed by the PIs. As project outcomes, we anticipate both a methodological advance in analyzing mass signature data as well as a suite of easily accessible software in the form of widgets. Metabolomics is concerned with the comprehensive characterization of the small molecule metabolites in biological systems. Owing to recent technological advances in measurement platforms, it is now possible to simultaneously detect and characterize a very large number of metabolites. Prospectively, advanced computational tools and software for metabolomics data analysis can aid discovery efforts aimed at identifying novel bioactive metabolites that could be developed into diagnostic indicators or therapeutic agents. ",A Machine-Learning Based Software Widget for Resolving Metabolite Identities,9223450,R03CA211839,"['Address', 'Algorithms', 'Attention', 'Automatic Data Processing', 'Bayesian Analysis', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Cells', 'Chemicals', 'Classification', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Databases', 'Diagnostic', 'Dissociation', 'Environment', 'Enzymes', 'Feedback', 'Focus Groups', 'Genes', 'Genome', 'Goals', 'Human', 'Knowledge', 'Libraries', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Metabolic Pathway', 'Metabolism', 'Methodology', 'Methods', 'Nuclear Magnetic Resonance', 'Oranges', 'Organism', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Pattern', 'Play', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Statistical Data Interpretation', 'Statistical Models', 'Surveys', 'Testing', 'Therapeutic Agents', 'Time', 'Uncertainty', 'Validation', 'Visual', 'base', 'biological systems', 'chemical standard', 'computerized tools', 'cost', 'database query', 'flexibility', 'functional outcomes', 'graphical user interface', 'heuristics', 'inhibitor/antagonist', 'instrument', 'ionization', 'mass spectrometer', 'member', 'metabolomics', 'novel', 'programs', 'protein expression', 'research study', 'small molecule', 'software development']",NCI,TUFTS UNIVERSITY MEDFORD,R03,2016,147569,-0.03428861084923099
"Developing Advanced Algorithms to Address Major Computational Challenges in Current Microbiome Research Abstract We propose a three-year interdisciplinary research plan to address two key issues currently facing the metagenomics community. The first issue concerns accurate construction and annotation of OTU tables using  of millions of 16S rRNA sequences, which is one of the most important yet most difficult problems inmicrobiome data analysis. Currently, it lacks computational algorithms capable of handling extremely large sequence data and constructing biologically consistent OTU tables. We propose a novel method that performs OTU table construction and annotation simultaneously by utilizing input and reference sequences, reference annotations, and data clustering structure within one analytical framework. Dynamic data-driven cutoffs are derived to identify OTUs that are consistent not only with data clustering structure but also with reference annotations. When successfully implemented, our method will generally address the computational needs of processing hundreds of millions of 16S rRNA reads that are currently being generated by large-scale studies. The second issue concerns developing novel methods to extract pertinent information from massive sequence data, thereby facilitating the field shifting from descriptive research to mechanistic studies. We are particularly interested in microbial community dynamics analysis, which can provide a wealth of insight into disease development unattainable through a static experiment design, and lays a critical foundation for developing probiotic and antibiotic strategies to manipulate microbial communities. Traditionally, system dynamics is approached through time-course studies. However, due to economical and logistical constraints, time-course studies are generally limited by the number of samples examined and the time period followed. With the rapid development of sequencing technology, many thousands of samples are being collected in large-scale studies. This provides us with a unique opportunity to develop a novel analytical strategy to use static data, instead of time-course data, to study microbial community dynamics. To our knowledge, this is the first time that massive static data is used to study dynamic aspects of microbial communities. When successfully implemented, our approach can effectively overcome the sampling limitation of time-course studies, and opens a new avenue of research to study microbial dynamics underlying disease development without performing a resource-intensive time-course study. The proposed pipeline will be intensively tested on a large oral microbiome dataset consisting of ~2,600 subgingival samples (~330M reads). The analysis can significantly advance our understanding of dynamic behaviors of oral microbial communities possibly contributing to the development of periodontal disease. To our knowledge, no prior work has been performed on this scale to study oral microbial community dynamics. We have assembled a multidisciplinary team that covers expertise spanning the areas of machine learning, bioinformatics, and oral microbiology. The expected outcome of this work will be a set of computational tools of high utility for the microbiology community and beyond. The human microbiome plays essential roles in many important physiological processes. We propose an interdisciplinary research plan to address some major computational challenges in current microbiome research. If successfully implemented, this work could significantly expand the capacity of existing pipelines for large-scale data analysis and scientific discovery, resulting in a significant impact on the field.",Developing Advanced Algorithms to Address Major Computational Challenges in Current Microbiome Research,9158909,R01AI125982,"['Address', 'Algorithms', 'Antibiotics', 'Area', 'Big Data', 'Bioinformatics', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Epidemiology', 'Floods', 'Foundations', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Interdisciplinary Study', 'Knowledge', 'Machine Learning', 'Metagenomics', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral', 'Oral Microbiology', 'Outcome', 'Periodontal Diseases', 'Physiological Processes', 'Play', 'Probiotics', 'Process', 'Reading', 'Research', 'Resources', 'Ribosomal RNA', 'Role', 'Sampling', 'Structure', 'Technology', 'Testing', 'Time', 'Work', 'abstracting', 'base', 'cohort', 'computerized tools', 'design', 'dynamic system', 'epidemiology study', 'innovation', 'insight', 'interest', 'microbial', 'microbial community', 'microbiome', 'microbiota', 'multidisciplinary', 'novel', 'open source', 'oral behavior', 'oral microbiome', 'research study', 'response', 'tumor progression', 'web app']",NIAID,STATE UNIVERSITY OF NEW YORK AT BUFFALO,R01,2016,311803,0.009772908439857167
"Reactome: An Open Knowledgebase of Human Pathways DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community. RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.",Reactome: An Open Knowledgebase of Human Pathways,9005867,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'mobile computing', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2016,1271107,0.029996726469028782
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design Our Vision: We propose DeepLink, a versatile data translator that integrate multi-scale, heterogeneous, and multi-source biomedical and clinical data. The primary goal of DeepLink is to enable meaningful bidirectional translation between clinical and molecular science by closing the interoperability gap between models and knowledge at different scales. The translator will enhance clinical science with molecular insights from basic and translational research (e.g. genetic variants, protein interactions, pathway functions, and cellular organization), and enable the molecular sciences by connecting biological discoveries with their pathophysiological consequences (e.g. diseases, signs and symptoms, pharmacological effects, physiological systems). Fundamental differences in the language and semantics used to describe the models and knowledge between the clinical and molecular domains results in an interoperability gap. DeepLink will systematically and comprehensively close this gap. We will begin with the latest technology in semantic knowledge graphs to support an extensible architecture for dynamic data federation and knowledge harmonization. We will design a system for multi-scale model integration that is ontology-based and will combine model execution with prior, curated biomedical knowledge. Our design strategy will be iterative and participatory and anchored by 10 major milestones. In a series of demonstrations of DeepLink’s functions, we will address one of the major challenges facing translational science: reproducibility of biomedical research findings that are based on evolving molecular datasets. Reproducibility of analyses and replication of results are central to scientific advancement. Many landmark studies have used data that are constantly being updated, curated, and pared down over time. Our series of demonstrations projects are designed to prototype the technology required for a scalable and robust translator as well as the techniques we will use to close the interoperability gap for a specific use case. The demonstration project will, itself, will be a significant and novel contribution to science. DeepLink will be able to answer questions that are currently enigmatic. Examples include: - From clinicians: What is the comparative effectiveness of all the treatments for disease Y given a patient's genetic/metabolic/proteomic profile? What are the functional variants in cell type X that are associated with differential treatment outcomes? What metabolite perturbations in cell type Y are associated with different subtypes of disease X? - From basic science researchers: What is known about disease Y across all model organisms (even those not designed to model Y)? What are all the clinical phenotypes that result from a change in function in protein X? Which biological pathways are affected by a pathogenic variant of disease Y? What patient data are available to evaluate a molecularlyderived clinical hypothesis? Challenges and Our Approaches: DeepLink will close the interoperability gap that currently prohibits molecular discoveries from leading to clinical innovations. DeepLink will be technologically driven, addressing the challenges associated with large, heterogeneous, semantically ambiguous, continuously changing, partially overlapping, and contextually dependent data by using (1) scalable, distributed, and versioned graph stores; (2) semantic technologies such as ontologies and Linked Data; (3) network analysis quality control methods; (4) machine-learning focused data fusion methods; (5) context-aware text mining, entity recognition and relation extraction; (6) multi-scale knowledge discovery using patient and molecular data; and (7) presentation of actionable knowledge to clinicians and basic scientists via user-friendly interfaces. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9338982,OT3TR002027,"['Address', 'Affect', 'Animal Model', 'Architecture', 'Basic Science', 'Biological', 'Biomedical Research', 'Cell physiology', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Data', 'Data Set', 'Disease', 'Genetic', 'Goals', 'Graph', 'Knowledge', 'Knowledge Discovery', 'Language', 'Link', 'Machine Learning', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Physiological', 'Proteins', 'Proteomics', 'Quality Control', 'Reproducibility', 'Research Personnel', 'Science', 'Scientist', 'Semantics', 'Series', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'Treatment outcome', 'Update', 'Variant', 'Vision', 'base', 'cell type', 'clinical phenotype', 'comparative effectiveness', 'design', 'disorder subtype', 'genetic variant', 'innovation', 'insight', 'interoperability', 'molecular domain', 'multi-scale modeling', 'novel', 'prototype', 'text searching', 'user-friendly']",NCATS,COLUMBIA UNIVERSITY HEALTH SCIENCES,OT3,2016,1183132,-0.03314015309472689
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,9268117,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost effectiveness', 'cost efficient', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2016,1378926,-0.015882011109088226
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),9118144,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'cloud platform', 'computational chemistry', 'computer science', 'data mining', 'design', 'distinguished professor', 'dopamine transporter', 'drug abuse prevention', 'epigenetic marker', 'falls', 'genome-wide', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'operation', 'predictive modeling', 'prevent', 'professor', 'receptor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2016,1070007,-0.0072398512779657176
"Integration and Visualization of Diverse Biological Data ﻿    DESCRIPTION (provided by applicant): The onset of most human disease involves multiple, molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway and treatment contexts. While this system has been probed by the thousands of functional genomics and quantitative genetic studies, careful extraction of signals relevant to these specific contexts is a challenging problem. General integration of these heterogeneous data was an important first step in detecting signals that be used to build networks to generate experimentally-testable hypotheses. However, only by dealing with the fact that disease happens at the intersection of multiple contexts and by integrating functional genomics with quantitative genetics will we be able to move toward a molecular-level understanding of human pathophysiology, which will pave the way to new therapy and drug development.  The long-term goal of this project is to enable such discoveries through the development of innovative bioinformatics frameworks for integrative analysis of diverse functional genomic data. In the previous funding periods, we developed accurate data integration and visualization methodologies for most common model organisms and human, created methods for tissue-specific data analysis, and applied these methods to make novel insights about important biological processes. We further enabled experimental biological discovery by implementing these methods in publicly accessible interactive systems that are popular with experimental biologists.  Leveraging our prior work, we now will directly address the challenge of enabling data-driven study of molecular mechanisms underlying human disease by developing novel semi-supervised and multi-task machine learning approaches and implementing them in a real-time integration system capable of predicting genome-scale functional and mechanism-specific networks focused on any biological context of interest. This will allow any biomedical researcher to quickly make data-driven hypotheses about function, interactions, and regulation of genes involved in hypertension in the kidney glomerulus or to predict new regulatory interactions relevant to Parkinson's disease that affect the ubiquitination pathway in Substantia nigra. Furthermore, we will develop methods for disease gene discovery that leverage these highly specific networks for functional analysis of quantitative genetics data. Our deliverable will be a general, robust, user-friendly, and automatically updated system for user-driven functional genomic data integration and functional analysis of quantitative genetics data. Throughout this work, we (with our close experimental and clinical collaborators) will also apply our methods to chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders both as case studies for the iterative improvement of our methods and to make direct contribution to better understanding of these diseases. PUBLIC HEALTH RELEVANCE: We will create a web-accessible system that will enable biologists and clinicians to generate hypotheses regarding disease-linked genes, molecular mechanisms underlying genetic disorders, and drug discovery for more targeted treatment. Underlying this user-friendly web interface will be novel algorithms for on-the-fly integration of  vast amount of functional genomics and quantitative genetics data based on the context(s) defined by the biologist or clinician. As applied to the three case study areas, chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders, our system has the potential to identify novel disease genes and pathways and to enable development of better diagnostic biomarkers, drug targets, and, in the longer term, treatments.",Integration and Visualization of Diverse Biological Data,9057057,R01GM071966,"['Address', 'Affect', 'Algorithms', 'Animal Model', 'Area', 'Bioinformatics', 'Biological', 'Biological Process', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Complex', 'Computer Systems', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Drug Targeting', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Databases', 'Genetic study', 'Goals', 'Gold', 'Health', 'Hereditary Disease', 'Human', 'Hypertension', 'Imagery', 'Kidney Glomerulus', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nephrology', 'Network-based', 'Parkinson Disease', 'Pathway interactions', 'Quantitative Genetics', 'Real-Time Systems', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Substantia nigra structure', 'System', 'Systems Integration', 'Time', 'Tissues', 'Training', 'Ubiquitination', 'Update', 'Work', 'autism spectrum disorder', 'base', 'clinical investigation', 'data integration', 'data visualization', 'diagnostic biomarker', 'drug development', 'drug discovery', 'functional genomics', 'gene discovery', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'multitask', 'novel', 'novel therapeutics', 'research study', 'targeted treatment', 'therapy development', 'user-friendly', 'web interface', 'web-accessible']",NIGMS,PRINCETON UNIVERSITY,R01,2016,445349,-0.010965965588003362
"Biomedical Data Translator Technical Feasibility Assessment and Architecture Design A fundamental challenge to translate insights between biomedical researchers, who study biological mechanisms, and clinicians, who diagnose patient symptoms, is that many links between biological processes and disease pathophysiology are poorly understood. A comprehensive Biomedical Translator must enable chains of inference across objects as diverse as genetic mutations, molecular effects, tissue-specific expression patterns, cellular processes, organ phenotypes, disease states, patient symptoms, and drug responses, a challenge beyond the scope of any one organization. Fortunately, many individual links in this chain have been made by experiments yielding statistical connections between individual data types. High-throughput perturbation screens link chemical and genetic perturbations to cellular phenotypes such as gene-expression patterns, cell survival, or changes in phosphorylation. Genetic association studies link mutations to human disease or intermediate phenotypes and biomarkers. Electronic medical records (EMR) link diseases or human phenotypes to diagnostic or current procedural terminology (CPT) codes, and clinical trials link the impact of drugs and drug candidates on disease states. In principle, incorporating these links into chains of inference could translate results between the full set of data types within them. In practice, each link is maintained by experts with domain-specific experiments, semantic terminology, and methodological standards. While a key challenge faced by a global Biomedical Translator is to establish consistent standards across these existing data types, a more important goal is to develop a principled and robust framework to (a) model biological systems and experimental approaches to investigate them; (b) organize knowledge about biological mechanism and disease; and (c) incorporate diverse datasets that serve as windows into the underlying and unknown state of nature. We propose to implement a Biomedical Translator as a probabilistic graphical model, a paradigm from artificial intelligence (AI) research. Just as separate research communities form weakly coupled parts of the translation process, graphical models allow global inferences from weakly coupled “nodes”. These inferences require each node to publish only probability distributions, enabling interoperability without necessarily having global entity-resolution standards, and benefit from paradigms for quality control, fault tolerance, and relevance assessment common in AI research. We hypothesize that a limited number of APIs, implemented as probability computations by communities around the world, would yield a Biomedical Translator as an emergent property of weakly coupled knowledge sources. From basic properties of graphical models, such a Translator could probabilistically translate among any data types connected within it, allowing for relatively complex query concepts. For example: What cellular processes in which tissues are impacted in a patient-based EMR? What genetic mutations sensitize cells to small-molecule treatment effects? Which small molecules mimic genetic “experiments of nature” that protect against disease? To illustrate the value of these resources and our architectural paradigm, we propose a demonstration project to implement a Biomedical Translator supporting queries between small molecules, biological processes, genes, and disease. The demonstration project will provide a valuable first step to confront key data-integration and organizational challenges and will enable previously impossible queries, such as identifying small molecules that perturb the same biological processes implicated by human genetics in a disease context. In this capacity, such Translator could realistically identify existing drugs for known symptoms (i.e., repurposing), but could more broadly serve as an engine for hypothesis generation and biological discovery, suggesting pre-clinical small molecules to develop based on their observed biological activity, or providing heretofore novel links between cellular protein function and disease pathophysiology. n/a",Biomedical Data Translator Technical Feasibility Assessment and Architecture Design,9337924,OT3TR002025,"['Architecture', 'Artificial Intelligence', 'Biological', 'Biological Markers', 'Biological Process', 'Cell Survival', 'Cell physiology', 'Cells', 'Clinical Trials', 'Communities', 'Complex', 'Computerized Medical Record', 'Coupled', 'Current Procedural Terminology Codes', 'DNA Sequence Alteration', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Functional disorder', 'Gene Expression Profile', 'Generations', 'Genetic', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Link', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Organ', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphorylation', 'Probability', 'Processed Genes', 'Property', 'Publishing', 'Quality Control', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Semantics', 'Source', 'Symptoms', 'Terminology', 'Tissues', 'Translating', 'Translation Process', 'base', 'biological systems', 'chemical genetics', 'data integration', 'design', 'disease phenotype', 'drug candidate', 'genetic association', 'human disease', 'insight', 'interoperability', 'novel', 'pre-clinical', 'protein function', 'research study', 'response', 'small molecule', 'treatment effect']",NCATS,"BROAD INSTITUTE, INC.",OT3,2016,399608,-0.005297611872854379
"CSHL Computational and Comparative Genomics Course DESCRIPTION (provided by applicant): The Cold Spring Harbor Laboratory proposes to continue a course entitled ""Computational and Comparative Genomics"", to be held in the fall of 2014 - 2016. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. PUBLIC HEALTH RELEVANCE: The Computational & Comparative Genomics is a 6 day course designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,9097763,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'Course Content', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Educational process of instructing', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomics', 'Health', 'Home environment', 'Institution', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Peptide Sequence Determination', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Universities', 'Update', 'base', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'genome sequencing', 'graduate student', 'instructor', 'interest', 'laboratory experience', 'lecturer', 'meetings', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2016,52816,0.0068194514194369615
"Dopaminergic encoding of counterfactual information in human striatum ﻿    DESCRIPTION (provided by applicant): Diseases and disorders directly affected by dopamine systems (e.g., drug addiction and Parkinson's disease) highlight the importance of these systems in motivated human behavior and cognition. The dopamine system is known to be a critical component of normal learning, reward processing, and decision-making (reviewed in Montague et al., 2004). Unfortunately, our present knowledge of dopamine systems in human brains is relatively sparse compared to the wealth of experimentation and computational modeling on these systems in rodents and non-human primates. Previously, technological constraints have limited direct experimentation in human brains. This proposal capitalizes on our group's recent technological innovation, which was supported by the NIH R21 mechanism - CEBRA: R21DA024140 - and resulted in the successful completion of the first sub-second measurements of dopamine release in a human brain. Furthermore, these measurements took place during an active decision-making task that was framed by computational models of learning and reward processing (Kishida et al., 2011 and Kishida et al., under review). We propose to pursue three specific aims, which combine our technological advance with active learning tasks designed to probe the role of dopamine in human behavior. Our aims incorporate three learning signals, where actual and counterfactual experience will each be examined in human striatal responses. The proposed work will inform on the controversial role for dopamine in reward/movement interactions. The experiments proposed will yield unprecedented insight into the function of the dopamine system in the humans afflicted with Parkinson's disease and Essential Tremor. With the support of the NIH (R21DA024140), our team successfully developed a complete prototype system for making electrochemical measurements of dopamine delivery in the human brain. Feasibility has been demonstrated by obtaining the first dopamine measurements in the striata of subjects with Parkinson's during a decision-making task. This substantial preliminary work is now ready for a larger scale with specific hypothesis testing about the role of dopamine systems in Parkinson's disease, Essential tremor, and human decision-making and behavior. PUBLIC HEALTH RELEVANCE: Experiments and computational models (primarily investigated in rodents and non-human primates) suggest dopamine systems in the brain are essential for normal learning, reward-processing, and ongoing decision- making. This proposal builds upon our group's innovative work, which - for the first time - recorded sub- second measurements of dopamine in human subjects and amalgamated these measurements with computational models of dopamine function. Herein we propose to use this newly developed technology to generate unprecedented insight into the function of dopamine systems directly in humans.",Dopaminergic encoding of counterfactual information in human striatum,9131824,R01NS092701,"['Active Learning', 'Acute', 'Affect', 'Animal Model', 'Behavior', 'Brain', 'Cells', 'Cessation of life', 'Cognition', 'Cognitive', 'Computer Simulation', 'Corpus striatum structure', 'Coupling', 'Data', 'Decision Making', 'Disease', 'Dopamine', 'Drug Addiction', 'Electrodes', 'Essential Tremor', 'Exploratory/Developmental Grant', 'Funding', 'Health', 'Human', 'Knowledge', 'Learning', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Movement Disorders', 'Operative Surgical Procedures', 'Parkinson Disease', 'Participant', 'Patients', 'Phase', 'Play', 'Replacement Therapy', 'Research Personnel', 'Rewards', 'Rodent', 'Role', 'Sample Size', 'Scanning', 'Signal Transduction', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'blood oxygenation level dependent response', 'cognitive function', 'design', 'dopamine system', 'dopaminergic neuron', 'experience', 'extracellular', 'human subject', 'implantation', 'innovation', 'insight', 'nonhuman primate', 'prototype', 'putamen', 'reduce symptoms', 'relating to nervous system', 'research study', 'response', 'reward processing', 'social', 'symptomatic improvement', 'technological innovation', 'temporal measurement']",NINDS,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2016,492125,-0.0009656777602808868
"Development of integrative models for early liver toxicity assessment ﻿    DESCRIPTION (provided by applicant): Computational toxicology has become a critical area of research due to the burgeoning need to evaluate thousands of pharmaceutical and environmental chemicals with unknown toxicity profiles, the high demand in time and resources by current experimental toxicity testing, and the growing ethical concerns over animal use in toxicity studies. Despite tremendous efforts, little success has been attained thus far in the development of predictive computational models for toxicity, primarily due to the complexity of toxicity mechanisms as well as the lack of high-quality experimental data for model development.  A critical challenge in toxicity testing of chemicals is that toxicity effects are doe-dependent: the true toxic hits may show no toxicity at all at low dose level. Therefore, traditiona high-throughput screening (HTS) that test chemicals only at a single concentration is not suitable for toxicity screening. On the contrary, the recently developed quantitative high-throughput screening (qHTS) platforms can evaluate each chemical across a broad range of concentrations, and is gaining ever-increasing popularity as a tool for in vitro toxicity profiling The concentration-response information generated by qHTS are expected to provide more accurate and comprehensive information of the toxicity effects of chemicals, offering promising data that can be mined to estimate in vivo toxicities of chemicals. However, our previous studies showed that if processed inappropriately, such concentration-response information contribute little to improve the toxicity prediction. This is especially true when multiple types of qHTS data are used together. Therefore, in this study, we will extend our previous approaches to develop novel statistical and computational tools that can curate, preprocess, and normalize the concentration-response information from multiple different qHTS databases.  Traditionally, toxicity models are based on either the chemical data (such as the quantitative structure- activity relationship analysis), or the in vitro toxicity profiling data (such as the in vitro-in vivo extrapolations). Our previous experiences suggested that integrating biological descriptors such as the in vitro cytotoxicity profiles or the short-term toxigenomic data, with chemical structural features is able to predict rodent acute liver toxicity with reasonable accuracy. Therefore, the second part of this proposal will be devoted to develop novel computational models for hepatotoxicity prediction by integrating qHTS toxicity profiles and chemical structural information In Aim 1, we will curate, preprocess, and normalize collected public liver toxicity datasets. In ths study, we will model toxicity effects using multiple large public datasets such as HTS and qHTS bioassay data (Tox21[1] and ToxCast[2]), hepatotoxicity side effect reports on marketed failed drugs[3], the Liver Toxicity Knowledge Base Benchmark Dataset (LTKB-BD[4]), etc. Statistical methods for cross-study validation and quality control will be applied to the collected datasets to ensure computational compatibility and to select the appropriate datasets for analysis. In Aim 2, we will develop predictive models for chemicals' liver toxicity based on an integrative modeling workflow that will make use of both structural and in vitro toxicity profiles of a chemical. Our previous studies [5] showed that models using both in vitro toxicity profiles and chemical structural data have better accuracy for rodent acute liver toxicity than models using either data type alone. Here, we will develop a novel modeling workflow that start with defining the functional clusters of chemicals via curated qHTS toxicity profiles, and is followed by developing computational models to correlate chemical and biological data with overall toxicity risks in humans. The predictive models will be validated using independent datasets with over 800 compounds. In Aim 3, we propose to prioritize the qHTS profiling assays used in the model for future toxicity testing. We will evaluate all the in vitro assays as biological descriptors from thee perspectives, including descriptor importance in the integrative toxicity model, correlation with i vivo DILI outcomes, and level of information content estimated by a novel approach based on network analysis.    PUBLIC HEALTH RELEVANCE: In this study we aim to develop computational models that can identify potential liver toxicants. Liver toxicity is a significant contributor to the high attition rate in drug development. Moreover, toxic chemicals in food, water, and consumer products all pose serious risks for liver toxicity. As a result, there is great interest in developing high-throughput, high-content experimental and computational tools to evaluate the liver toxicity of thousands of pharmaceutical and environmental chemicals. This study focuses on developing novel informatics tools that enable the extraction and integration of chemical concentration-response information from multiple quantitative high-throughput screening databases for model development, and developing statistical models that are able to integrate this concentration-response information with chemical structural features to predict their risk of liver toxicity.  ",Development of integrative models for early liver toxicity assessment,9017336,R03ES026397,"['Acute', 'Address', 'Adverse effects', 'Algorithms', 'Animals', 'Area', 'Benchmarking', 'Biological', 'Biological Assay', 'Chemicals', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Dose', 'Dreams', 'Ensure', 'Ethics', 'Food', 'Future', 'Gene Expression', 'Genomics', 'Goals', 'Gold', 'Health', 'Hepatotoxicity', 'Human', 'In Vitro', 'Informatics', 'International', 'Liver', 'Machine Learning', 'Marketing', 'Mining', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Environmental Health Sciences', 'Nature', 'North Carolina', 'Outcome', 'Pathway Analysis', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Poison', 'Process', 'Productivity', 'Quality Control', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Resources', 'Risk', 'Rodent', 'Scientist', 'Shapes', 'Statistical Methods', 'Statistical Models', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicogenetics', 'Toxicology', 'Translational Research', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'Universities', 'Variant', 'Water', 'base', 'computerized tools', 'consumer product', 'cost', 'cost effective', 'cytotoxicity', 'data modeling', 'drug development', 'drug market', 'drug withdrawal', 'environmental chemical', 'experience', 'high throughput screening', 'improved', 'in vitro Assay', 'in vivo', 'interest', 'knowledge base', 'liver injury', 'model building', 'model development', 'novel', 'novel strategies', 'post-market', 'preclinical study', 'predictive modeling', 'programs', 'response', 'screening', 'success', 'tool', 'toxicant', 'validation studies']",NIEHS,UT SOUTHWESTERN MEDICAL CENTER,R03,2016,81000,-0.0023448403877898384
"The q-bio Summer School DESCRIPTION (provided by applicant): The purpose of the Annual q-bio Summer School, founded in 2007 in Los Alamos, NM, is to advance predictive modeling of cellular regulatory systems by providing trtaining in mathematical, statistical, and computational techniques that are important in systems and synthetic biology. A secondary goal is to advance the careers of researchers new to quantitative biology. The school consists of courses in six subjects: 1) stochastic gene regulation, 2) cell signaling, 3) biomolecular simulations, 4) viral dynamics, 5) synthetic biology, and 6) computational neuroscience. Demand for training in quantitative biology is increasing rapidly-the number of qualified summer school applicants increased from fewer than 40 in 2010 to over 170 in 2012. In response to this demand, we expanded the school in 2012 to accommodate more students. The school now takes place at two campuses, in Santa Fe, NM (courses 1-4) and in San Diego, CA (courses 5-6). Approximately 30 students attend at each campus and are diverse in terms of educational background (mathematics, engineering, physical sciences, and biology), career level (~75% are graduate students, ~20% are postdocs, and ~5% are more advanced), and demographics (gender, race, ethnicity, and worldwide geographical origin). Students attend all core lectures in the courses offered at their campus, as well as specialized course-specific lectures, student get-to-know-me talks, and other talks (e.g., talks focused on career skills), and participate in hands-on computer labs and mentored projects. After two intensive weeks, all students gather in Santa Fe for a 2-day q- bio Student Symposium, which features student projects reports, student poster presentations, and external invited speakers. All students then attend the 4-day q-bio Conference, an international conference attended by >200 researchers. All q-bio Summer School participants can expect the following: a) broad exposure to mathematical/statistical/computational tools used in quantitative biology, b) in-depth training in techniques of special interest (i.e., in one of the six course subjects) through course-specific lectures, computer labs, and mentored projects; c) multiple opportunities to practice scientific communication through talks and poster presentations; d) exposure to cutting-edge research, and e) extensive networking opportunities with peers and thought leaders. Lecturers and speakers include more than 50 different researchers active in quantitative biology, including very distinguished scientists. For example, in 2013, confirmed lecturers include six academicians. By the time the students attend the q-bio Conference, they are equipped with a powerful social network that facilitates interactions, idea exchange, and initiation of collaborative research. The long-term goal of the school is to change the way biological research is conducted, making biology a more quantitative field, like physics and chemistry. In this effort, the organizers are supported by significant goodwill from the international quantitative biology community and a number of local institutions, including two national centers for systems biology. However, to maintain and improve the school, additional financial support is required. PUBLIC HEALTH RELEVANCE: Many future biomedical and biotechnological advances in synthetic and systems biology will require investigators who have the ability to carefully integrate quantitative experimentation with mathematical, statistical and computational modeling. The goal of the q-bio Summer School is to prepare a new generation of quantitative biologists who are adept at modeling and/or working with modelers to advance our predictive understanding of cellular regulatory systems. The complexity and importance of these systems, which govern cellular activities and fates, provides motivation for developing a scientific and engineering workforce equipped to deal with the complexity.",The q-bio Summer School,9002062,R25GM105608,"['Behavior', 'Bioinformatics', 'Biological', 'Biology', 'Career Choice', 'Career Mobility', 'Cell model', 'Cell physiology', 'Cells', 'Chemistry', 'Communication', 'Communities', 'Complex', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Cues', 'Data', 'Education', 'Educational Background', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ethnic Origin', 'Event', 'Exposure to', 'Financial Support', 'Funding', 'Future', 'Gender', 'Gene Expression Regulation', 'Generations', 'Goals', 'Health', 'Heterogeneity', 'Immune system', 'Individual', 'Institution', 'International', 'Internet', 'Machine Learning', 'Mathematics', 'Mentors', 'Minority-Serving Institution', 'Modeling', 'Molecular', 'Motivation', 'National Institute of General Medical Sciences', 'Neurons', 'Occupations', 'Participant', 'Physics', 'Population', 'Postdoctoral Fellow', 'Professional Competence', 'Qualifying', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Scientist', 'Series', 'Signal Transduction', 'Social Network', 'Statistical Data Interpretation', 'Statistical Models', 'Students', 'Synthetic Genes', 'System', 'Systems Biology', 'Techniques', 'Time', 'Training', 'Underrepresented Groups', 'United States National Institutes of Health', 'Viral', 'Woman', 'Work', 'biochemical model', 'biological research', 'career', 'career development', 'computational neuroscience', 'computerized tools', 'demographics', 'graduate student', 'improved', 'interest', 'learning materials', 'lecture notes', 'lecturer', 'lectures', 'mathematical model', 'member', 'model design', 'multidisciplinary', 'peer', 'physical science', 'posters', 'predictive modeling', 'programs', 'research study', 'response', 'simulation', 'skills', 'statistics', 'symposium', 'synthetic biology', 'tool']",NIGMS,"NEW MEXICO CONSORTIUM, INC.",R25,2016,168780,-0.007862520247307419
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs.         PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.            ",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,9135193,U54AT008909,"['Address', 'Archives', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Infrastructure Activities', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Procedures', 'Process', 'Qualifying', 'Quality Control', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Vulnerable Populations', 'Work', 'base', 'clinically relevant', 'data archive', 'data mining', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'online repository', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository']",NCCIH,UNIVERSITY OF WASHINGTON,U54,2016,1928492,-0.015473216185000669
"Reactome: An Open Knowledgebase of Human Pathways DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community. RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.",Reactome: An Open Knowledgebase of Human Pathways,8840984,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2015,1243799,0.029996726469028782
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models DESCRIPTION (provided by applicant): Malaria is one of the most devastating infectious diseases in the world. Development of novel antimalarial strategies is urgently needed due to the rapid evolution and spread of drug resistance in malaria parasites Plasmodium. The long term goal of this proposed project is to develop a systems-level understanding of the molecular basis of parasitism, pathogenesis, and drug resistance. We will implement approaches that combine machine learning, probabilistic modeling, and genome-wide association analysis to develop more robust computational solutions and identify a comprehensive set of genes or gene products in biological networks that show an increase in genetic variability that can be associated with drug resistance, pathogenesis, virulence, responses to environmental challenges, or with other interesting phenotypes. The three specific aims are:  1. To identify network components using effective remote homology based methods. We will address a critical barrier in malaria research: our inability to assign functional annotation to over 60% of the predicted gene products in the genome of Plasmodium falciparum. We will use a machine learning approach to detect evolutionarily conserved characteristics of the genes/proteins for network inference.  2. To infer the topology and dynamic interplay of cellular networks. Robust models will be developed to reconstruct the gene regulatory networks, signaling cascades and metabolic pathways that define the genetic basis for disease phenotypes.  3. To identify evolutionary signatures of network models by genome-wide association studies (GWAS).  GWAS including Single Nucleotide Polymorphism (SNP) screening of multiple strains with varying phenotypes will serve as an effective means for high throughput wet-lab validations of networks in response to drug treatment. Such networks are the cornerstones of a systems-level view of pathogen biology, a view that will allow us to transform disparate types of data into biological insights for drug development. Malaria remains one of the most important infectious diseases in the world today, infecting 300-500 million people yearly and resulting in 1-2 million deaths, primarily of young children. This study will develop computational solutions to problems that hitherto have prevented us from gaining a global view of how infection by the malaria parasite leads to the development of the disease. This global overview will help us develop specific solutions to the problems of preventing and treating malaria.",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,8919401,SC1GM100806,"['Address', 'Algorithms', 'Antimalarials', 'Biological', 'Biology', 'Cell Cycle', 'Cessation of life', 'Characteristics', 'Child', 'Clinical', 'Communicable Diseases', 'Complement', 'Complex', 'Data', 'Data Analyses', 'Development', 'Disease', 'Drug Targeting', 'Drug resistance', 'Erythrocytes', 'Evolution', 'Funding', 'Gene Duplication', 'Gene Proteins', 'Genes', 'Genetic', 'Genome', 'Genome Components', 'Genomics', 'Goals', 'Grant', 'Horizontal Gene Transfer', 'Immune', 'Infection', 'Knowledge', 'Lead', 'Life Cycle Stages', 'Life Style', 'Machine Learning', 'Malaria', 'Measures', 'Metabolic Pathway', 'Methods', 'Modeling', 'Molecular', 'Open Reading Frames', 'Parasites', 'Pathogenesis', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Population', 'Process', 'Protein Family', 'Proteins', 'Regulator Genes', 'Research', 'Resistance', 'Role', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Solutions', 'Statistical Models', 'System', 'Systems Biology', 'Testing', 'Validation', 'Virulence', 'Work', 'base', 'comparative genomics', 'data mining', 'disease phenotype', 'drug development', 'genome wide association study', 'insight', 'interest', 'mortality', 'network models', 'novel', 'novel therapeutics', 'parasite genome', 'parasitism', 'pathogen', 'pressure', 'prevent', 'research study', 'response', 'screening', 'transcription factor', 'transcriptomics', 'vaccine development']",NIGMS,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2015,367500,-0.027892075884011002
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8889700,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2015,2005492,-0.015882011109088226
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),8896676,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'computational chemistry', 'computer science', 'data mining', 'design', 'dopamine transporter', 'drug abuse prevention', 'epigenetic marker', 'falls', 'genome-wide', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'operation', 'predictive modeling', 'prevent', 'professor', 'receptor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2015,1064603,-0.0072398512779657176
"Integration and Visualization of Diverse Biological Data ﻿    DESCRIPTION (provided by applicant): The onset of most human disease involves multiple, molecular-level changes to the complex system of interacting genes and pathways that function differently in specific cell-lineage, pathway and treatment contexts. While this system has been probed by the thousands of functional genomics and quantitative genetic studies, careful extraction of signals relevant to these specific contexts is a challenging problem. General integration of these heterogeneous data was an important first step in detecting signals that be used to build networks to generate experimentally-testable hypotheses. However, only by dealing with the fact that disease happens at the intersection of multiple contexts and by integrating functional genomics with quantitative genetics will we be able to move toward a molecular-level understanding of human pathophysiology, which will pave the way to new therapy and drug development.  The long-term goal of this project is to enable such discoveries through the development of innovative bioinformatics frameworks for integrative analysis of diverse functional genomic data. In the previous funding periods, we developed accurate data integration and visualization methodologies for most common model organisms and human, created methods for tissue-specific data analysis, and applied these methods to make novel insights about important biological processes. We further enabled experimental biological discovery by implementing these methods in publicly accessible interactive systems that are popular with experimental biologists.  Leveraging our prior work, we now will directly address the challenge of enabling data-driven study of molecular mechanisms underlying human disease by developing novel semi-supervised and multi-task machine learning approaches and implementing them in a real-time integration system capable of predicting genome-scale functional and mechanism-specific networks focused on any biological context of interest. This will allow any biomedical researcher to quickly make data-driven hypotheses about function, interactions, and regulation of genes involved in hypertension in the kidney glomerulus or to predict new regulatory interactions relevant to Parkinson's disease that affect the ubiquitination pathway in Substantia nigra. Furthermore, we will develop methods for disease gene discovery that leverage these highly specific networks for functional analysis of quantitative genetics data. Our deliverable will be a general, robust, user-friendly, and automatically updated system for user-driven functional genomic data integration and functional analysis of quantitative genetics data. Throughout this work, we (with our close experimental and clinical collaborators) will also apply our methods to chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders both as case studies for the iterative improvement of our methods and to make direct contribution to better understanding of these diseases.         PUBLIC HEALTH RELEVANCE: We will create a web-accessible system that will enable biologists and clinicians to generate hypotheses regarding disease-linked genes, molecular mechanisms underlying genetic disorders, and drug discovery for more targeted treatment. Underlying this user-friendly web interface will be novel algorithms for on-the-fly integration of  vast amount of functional genomics and quantitative genetics data based on the context(s) defined by the biologist or clinician. As applied to the three case study areas, chronic kidney disease, cardiovascular disease/hypertension, and autism spectrum disorders, our system has the potential to identify novel disease genes and pathways and to enable development of better diagnostic biomarkers, drug targets, and, in the longer term, treatments.            ",Integration and Visualization of Diverse Biological Data,8886554,R01GM071966,"['Address', 'Affect', 'Algorithms', 'Animal Model', 'Area', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Complex', 'Computer Systems', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Drug Targeting', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Databases', 'Genetic study', 'Goals', 'Gold', 'Hereditary Disease', 'Human', 'Hypertension', 'Imagery', 'Kidney Glomerulus', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Letters', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nephrology', 'Network-based', 'Parkinson Disease', 'Pathway interactions', 'Quantitative Genetics', 'Real-Time Systems', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Substantia nigra structure', 'System', 'Systems Integration', 'Time', 'Tissues', 'Training', 'Ubiquitination', 'Update', 'Work', 'autism spectrum disorder', 'base', 'clinical investigation', 'data integration', 'data visualization', 'drug development', 'drug discovery', 'functional genomics', 'gene discovery', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'innovation', 'insight', 'interest', 'multitask', 'novel', 'public health relevance', 'research study', 'targeted treatment', 'therapy development', 'user-friendly', 'web interface', 'web-accessible']",NIGMS,PRINCETON UNIVERSITY,R01,2015,473642,-0.010965965588003362
"CSHL Computational and Comparative Genomics Course DESCRIPTION (provided by applicant): The Cold Spring Harbor Laboratory proposes to continue a course entitled ""Computational and Comparative Genomics"", to be held in the fall of 2014 - 2016. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. PUBLIC HEALTH RELEVANCE: The Computational & Comparative Genomics is a 6 day course designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,8898177,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomics', 'Health', 'Home environment', 'Institution', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Peptide Sequence Determination', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Universities', 'Update', 'base', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'genome sequencing', 'graduate student', 'instructor', 'interest', 'lecturer', 'meetings', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2015,52816,0.0068194514194369615
"Dopaminergic encoding of counterfactual information in human striatum ﻿    DESCRIPTION (provided by applicant): Diseases and disorders directly affected by dopamine systems (e.g., drug addiction and Parkinson's disease) highlight the importance of these systems in motivated human behavior and cognition. The dopamine system is known to be a critical component of normal learning, reward processing, and decision-making (reviewed in Montague et al., 2004). Unfortunately, our present knowledge of dopamine systems in human brains is relatively sparse compared to the wealth of experimentation and computational modeling on these systems in rodents and non-human primates. Previously, technological constraints have limited direct experimentation in human brains. This proposal capitalizes on our group's recent technological innovation, which was supported by the NIH R21 mechanism - CEBRA: R21DA024140 - and resulted in the successful completion of the first sub-second measurements of dopamine release in a human brain. Furthermore, these measurements took place during an active decision-making task that was framed by computational models of learning and reward processing (Kishida et al., 2011 and Kishida et al., under review). We propose to pursue three specific aims, which combine our technological advance with active learning tasks designed to probe the role of dopamine in human behavior. Our aims incorporate three learning signals, where actual and counterfactual experience will each be examined in human striatal responses. The proposed work will inform on the controversial role for dopamine in reward/movement interactions. The experiments proposed will yield unprecedented insight into the function of the dopamine system in the humans afflicted with Parkinson's disease and Essential Tremor. With the support of the NIH (R21DA024140), our team successfully developed a complete prototype system for making electrochemical measurements of dopamine delivery in the human brain. Feasibility has been demonstrated by obtaining the first dopamine measurements in the striata of subjects with Parkinson's during a decision-making task. This substantial preliminary work is now ready for a larger scale with specific hypothesis testing about the role of dopamine systems in Parkinson's disease, Essential tremor, and human decision-making and behavior.   PUBLIC HEALTH RELEVANCE: Experiments and computational models (primarily investigated in rodents and non-human primates) suggest dopamine systems in the brain are essential for normal learning, reward-processing, and ongoing decision- making. This proposal builds upon our group's innovative work, which - for the first time - recorded sub- second measurements of dopamine in human subjects and amalgamated these measurements with computational models of dopamine function. Herein we propose to use this newly developed technology to generate unprecedented insight into the function of dopamine systems directly in humans.          ",Dopaminergic encoding of counterfactual information in human striatum,9029452,R01NS092701,"['Active Learning', 'Acute', 'Affect', 'Animal Model', 'Behavior', 'Brain', 'Cells', 'Cessation of life', 'Cognition', 'Cognitive', 'Computer Simulation', 'Corpus striatum structure', 'Coupling', 'Data', 'Decision Making', 'Disease', 'Dopamine', 'Drug Addiction', 'Electrodes', 'Essential Tremor', 'Exploratory/Developmental Grant', 'Funding', 'Health', 'Human', 'Knowledge', 'Learning', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Movement Disorders', 'Operative Surgical Procedures', 'Parkinson Disease', 'Participant', 'Patients', 'Phase', 'Play', 'Replacement Therapy', 'Research Personnel', 'Rewards', 'Rodent', 'Role', 'Sample Size', 'Scanning', 'Signal Transduction', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'United States National Institutes of Health', 'Work', 'base', 'blood oxygenation level dependent response', 'cognitive function', 'design', 'dopamine system', 'dopaminergic neuron', 'experience', 'extracellular', 'human subject', 'implantation', 'innovation', 'insight', 'nonhuman primate', 'prototype', 'putamen', 'relating to nervous system', 'research study', 'response', 'reward processing', 'social', 'technological innovation', 'temporal measurement']",NINDS,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2015,507375,-0.0009656777602808868
"The q-bio Summer School DESCRIPTION (provided by applicant): The purpose of the Annual q-bio Summer School, founded in 2007 in Los Alamos, NM, is to advance predictive modeling of cellular regulatory systems by providing trtaining in mathematical, statistical, and computational techniques that are important in systems and synthetic biology. A secondary goal is to advance the careers of researchers new to quantitative biology. The school consists of courses in six subjects: 1) stochastic gene regulation, 2) cell signaling, 3) biomolecular simulations, 4) viral dynamics, 5) synthetic biology, and 6) computational neuroscience. Demand for training in quantitative biology is increasing rapidly-the number of qualified summer school applicants increased from fewer than 40 in 2010 to over 170 in 2012. In response to this demand, we expanded the school in 2012 to accommodate more students. The school now takes place at two campuses, in Santa Fe, NM (courses 1-4) and in San Diego, CA (courses 5-6). Approximately 30 students attend at each campus and are diverse in terms of educational background (mathematics, engineering, physical sciences, and biology), career level (~75% are graduate students, ~20% are postdocs, and ~5% are more advanced), and demographics (gender, race, ethnicity, and worldwide geographical origin). Students attend all core lectures in the courses offered at their campus, as well as specialized course-specific lectures, student get-to-know-me talks, and other talks (e.g., talks focused on career skills), and participate in hands-on computer labs and mentored projects. After two intensive weeks, all students gather in Santa Fe for a 2-day q- bio Student Symposium, which features student projects reports, student poster presentations, and external invited speakers. All students then attend the 4-day q-bio Conference, an international conference attended by >200 researchers. All q-bio Summer School participants can expect the following: a) broad exposure to mathematical/statistical/computational tools used in quantitative biology, b) in-depth training in techniques of special interest (i.e., in one of the six course subjects) through course-specific lectures, computer labs, and mentored projects; c) multiple opportunities to practice scientific communication through talks and poster presentations; d) exposure to cutting-edge research, and e) extensive networking opportunities with peers and thought leaders. Lecturers and speakers include more than 50 different researchers active in quantitative biology, including very distinguished scientists. For example, in 2013, confirmed lecturers include six academicians. By the time the students attend the q-bio Conference, they are equipped with a powerful social network that facilitates interactions, idea exchange, and initiation of collaborative research. The long-term goal of the school is to change the way biological research is conducted, making biology a more quantitative field, like physics and chemistry. In this effort, the organizers are supported by significant goodwill from the international quantitative biology community and a number of local institutions, including two national centers for systems biology. However, to maintain and improve the school, additional financial support is required. PUBLIC HEALTH RELEVANCE: Many future biomedical and biotechnological advances in synthetic and systems biology will require investigators who have the ability to carefully integrate quantitative experimentation with mathematical, statistical and computational modeling. The goal of the q-bio Summer School is to prepare a new generation of quantitative biologists who are adept at modeling and/or working with modelers to advance our predictive understanding of cellular regulatory systems. The complexity and importance of these systems, which govern cellular activities and fates, provides motivation for developing a scientific and engineering workforce equipped to deal with the complexity.",The q-bio Summer School,8802880,R25GM105608,"['Behavior', 'Bioinformatics', 'Biological', 'Biology', 'Career Choice', 'Cell model', 'Cell physiology', 'Cells', 'Chemistry', 'Communication', 'Communities', 'Complex', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Cues', 'Data', 'Education', 'Educational Background', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ethnic Origin', 'Event', 'Exposure to', 'Financial Support', 'Funding', 'Future', 'Gender', 'Gene Expression Regulation', 'Generations', 'Goals', 'Health', 'Heterogeneity', 'Immune system', 'Individual', 'Institution', 'International', 'Internet', 'Machine Learning', 'Mathematics', 'Mentors', 'Minority-Serving Institution', 'Modeling', 'Molecular', 'Motivation', 'National Institute of General Medical Sciences', 'Neurons', 'Occupations', 'Participant', 'Physics', 'Population', 'Postdoctoral Fellow', 'Qualifying', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Scientist', 'Series', 'Signal Transduction', 'Social Network', 'Statistical Data Interpretation', 'Statistical Models', 'Students', 'Synthetic Genes', 'System', 'Systems Biology', 'Techniques', 'Time', 'Training', 'Underrepresented Minority', 'United States National Institutes of Health', 'Viral', 'Woman', 'Work', 'biochemical model', 'biological research', 'career', 'career development', 'computational neuroscience', 'computerized tools', 'demographics', 'graduate student', 'improved', 'interest', 'lecture notes', 'lecturer', 'lectures', 'mathematical model', 'member', 'model design', 'multidisciplinary', 'peer', 'physical science', 'posters', 'predictive modeling', 'programs', 'research study', 'response', 'simulation', 'skills', 'statistics', 'symposium', 'synthetic biology', 'tool']",NIGMS,"NEW MEXICO CONSORTIUM, INC.",R25,2015,169997,-0.007862520247307419
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,8836569,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,2687363,-0.006729347387595173
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,9132876,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,413294,-0.006729347387595173
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,9133491,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,115911,-0.006729347387595173
"Natural Product-Drug Interaction Research: The Roadmap to Best Practices ﻿    DESCRIPTION (provided by applicant): As natural products (NP) sales increase, the risk of adverse NP-drug interactions (NPDIs) increases, yet the pharmacokinetic (PK) elucidation and clinical relevance of putative NPDIs remain elusive. Assessing the risk of NPDIs is more challenging than that of drug-drug interactions (DDIs), often due to relatively scant PK knowledge of individual NP constituents that perpetrate these interactions. The proposed U54 Center will develop a roadmap for NPDI research through a series of well-designed human in vitro and in vivo studies (termed Interaction Projects) on 4-6 priority NPs that pose a potential risk for clinically relevant NPDIs. A repository will be developed for the data generated from the Interaction Projects, and results will be communicated to various target audiences through a public portal. This U54 Center is composed of an accomplished team of investigators, including pharmacokineticists with expertise in NPDIs, complemented by expertise in NP chemistry, DDIs, and health information communication. In collaboration with the Steering Committee, an innovative strategy that combines a mechanistic approach with practical considerations (e.g., popularity of the NPs) will be used to select and prioritize 4-6 NPs for further investigation in te Interaction Projects. Mechanistic aspects include curated clinical NDPI data from the widely used Drug Interaction Database (DIDB) of the Informatics Core, structural alerts, and compelling preliminary clinical and in silico NPDI data. Once selected, the NPs will be entered into a Decision Tree for assessment of NPDI liability and probable significance of interactions with victim drugs. In parallel, the Pharmacology Core will develop detailed Statements of Work for the human in vitro and in vivo studies - while the Analytical Core will source, acquire, and characterize the selected NPs - for the Interaction Projects. Upon completion of each project, the Analytical Core will analyze the PK samples, and the Pharmacology Core will develop physiologically-based PK models for further assessment of the clinical relevance of the Interaction Project results. Throughout these projects, the Informatics Core will create a data repository embedded within a public portal web-based application named, NaPDI app, for Natural Product-Drug Interaction application. The repository, built using the DIDB framework, will allow researchers to access both raw data and summarized results. The U54 Center will also develop and share Best Practices recommended for the conduct of NPDI studies, based on the experience with and results from the Interaction Projects, with the research communities via the public portal. Effective dissemination of the Interaction Project results will be ensured through user experience and brand content studies with target audiences - researchers/practitioners and lay public - to refine the public portal content. The Informatics Core will ensure that the U54 Center's results are archived, organized, analyzed, and well-publicized, allowing for improved design of future NPDI research and ultimately, improved decisions on the optimal management of clinically relevant NPDIs.         PUBLIC HEALTH RELEVANCE: The goal of this proposed Center of Excellence is to provide leadership on how best to study potential adverse interactions between natural products and conventional medications. The uniquely experienced and multidisciplinary team of investigators will work with NCCAM officials to identify a priority list of natural products that could alter dru disposition and, in turn, significantly alter the efficacy and safety of conventional medications; challenges inherent to studying these interactions will be addressed using a combination of novel and established approaches. Upon assessment of the selected natural products and potential drug interactions through the Interaction Projects, a repository and web-based public portal will be developed that allows other researchers to access the generated data for further analysis and communicate the health implications of the results to health care practitioners and the public.            ",Natural Product-Drug Interaction Research: The Roadmap to Best Practices,8977997,U54AT008909,"['Address', 'Archives', 'Biological Factors', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computer Simulation', 'Data', 'Databases', 'Decision Trees', 'Drug Interactions', 'Drug Kinetics', 'Ensure', 'Future', 'Goals', 'Health', 'Healthcare', 'Human', 'In Vitro', 'Individual', 'Informatics', 'Infrastructure Activities', 'Investigation', 'Knowledge', 'Leadership', 'Literature', 'Methods', 'Names', 'National Center for Complementary and Alternative Medicine', 'Natural Product Drug', 'Natural Products Chemistry', 'Nature', 'Online Systems', 'Pharmaceutical Preparations', 'Pharmacology', 'Procedures', 'Process', 'Qualifying', 'Quality Control', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Sales', 'Sampling', 'Series', 'Source', 'Vulnerable Populations', 'Work', 'base', 'clinically relevant', 'data mining', 'design', 'experience', 'improved', 'in vivo', 'innovation', 'liquid chromatography mass spectrometry', 'models and simulation', 'multidisciplinary', 'novel', 'operation', 'perpetrators', 'pharmacokinetic model', 'public health relevance', 'quality assurance', 'repository']",NCCIH,UNIVERSITY OF WASHINGTON,U54,2015,2015154,-0.015473216185000669
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.          RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8661774,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2014,1248956,0.029996726469028782
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8668954,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'screening', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2014,1029385,-0.019583936904124178
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models     DESCRIPTION (provided by applicant): Malaria is one of the most devastating infectious diseases in the world. Development of novel antimalarial strategies is urgently needed due to the rapid evolution and spread of drug resistance in malaria parasites Plasmodium. The long term goal of this proposed project is to develop a systems-level understanding of the molecular basis of parasitism, pathogenesis, and drug resistance. We will implement approaches that combine machine learning, probabilistic modeling, and genome-wide association analysis to develop more robust computational solutions and identify a comprehensive set of genes or gene products in biological networks that show an increase in genetic variability that can be associated with drug resistance, pathogenesis, virulence, responses to environmental challenges, or with other interesting phenotypes. The three specific aims are:  1. To identify network components using effective remote homology based methods. We will address a critical barrier in malaria research: our inability to assign functional annotation to over 60% of the predicted gene products in the genome of Plasmodium falciparum. We will use a machine learning approach to detect evolutionarily conserved characteristics of the genes/proteins for network inference.  2. To infer the topology and dynamic interplay of cellular networks. Robust models will be developed to reconstruct the gene regulatory networks, signaling cascades and metabolic pathways that define the genetic basis for disease phenotypes.  3. To identify evolutionary signatures of network models by genome-wide association studies (GWAS).  GWAS including Single Nucleotide Polymorphism (SNP) screening of multiple strains with varying phenotypes will serve as an effective means for high throughput wet-lab validations of networks in response to drug treatment. Such networks are the cornerstones of a systems-level view of pathogen biology, a view that will allow us to transform disparate types of data into biological insights for drug development.          Malaria remains one of the most important infectious diseases in the world today, infecting 300-500 million people yearly and resulting in 1-2 million deaths, primarily of young children. This study will develop computational solutions to problems that hitherto have prevented us from gaining a global view of how infection by the malaria parasite leads to the development of the disease. This global overview will help us develop specific solutions to the problems of preventing and treating malaria.            ",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,8735167,SC1GM100806,"['Address', 'Algorithms', 'Antimalarials', 'Biological', 'Biology', 'Cell Cycle', 'Cessation of life', 'Characteristics', 'Child', 'Clinical', 'Communicable Diseases', 'Complement', 'Complex', 'Data', 'Data Analyses', 'Development', 'Disease', 'Drug Targeting', 'Drug resistance', 'Erythrocytes', 'Evolution', 'Funding', 'Gene Duplication', 'Gene Proteins', 'Genes', 'Genetic', 'Genome', 'Genome Components', 'Genomics', 'Goals', 'Grant', 'Horizontal Gene Transfer', 'Immune', 'Infection', 'Knowledge', 'Lead', 'Life Cycle Stages', 'Life Style', 'Machine Learning', 'Malaria', 'Measures', 'Metabolic Pathway', 'Methods', 'Modeling', 'Molecular', 'Open Reading Frames', 'Parasites', 'Pathogenesis', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Population', 'Process', 'Protein Family', 'Proteins', 'Regulator Genes', 'Research', 'Resistance', 'Role', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Solutions', 'Statistical Models', 'System', 'Systems Biology', 'Testing', 'Validation', 'Virulence', 'Work', 'base', 'comparative genomics', 'data mining', 'disease phenotype', 'drug development', 'genome wide association study', 'insight', 'interest', 'mortality', 'network models', 'novel', 'novel therapeutics', 'parasite genome', 'parasitism', 'pathogen', 'pressure', 'prevent', 'research study', 'response', 'screening', 'transcription factor', 'transcriptomics', 'vaccine development']",NIGMS,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2014,367500,-0.027892075884011002
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8725717,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2014,2015775,-0.015882011109088226
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),8743368,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'computational chemistry', 'computer science', 'data mining', 'design', 'dopamine transporter', 'drug abuse prevention', 'epigenetic marker', 'falls', 'genome-wide', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'operation', 'predictive modeling', 'prevent', 'professor', 'receptor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2014,1094316,-0.0072398512779657176
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of time- and space-varying (rather than static) gene network learning, and Bayesian  inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks.  We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during  breast cancer progression and reversal. Since any complex biological processes such as development and  disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is  unreasonable to assume that the underlying network of gene interaction is invariant throughout the process.  But modern experimental and computational methodology is not able to identify such time/space specific  network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the  functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the  grasp of convention methods and requires the methodological innovations we propose. Unraveling and  characterizing such dynamic activities and trajectories of biological networks can provide a more  comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to  better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of  key elements in the network responsible for the functional integrity of the network and the system; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell  differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment  scheme.  PHS 398/2590 (Rev. 09/04, Reissued 4/2006) Page Continuation Format Page",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,8727043,R01GM093156,"['Accounting', 'Algorithmic Software', 'Algorithms', 'Automobile Driving', 'Bayesian Analysis', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Breast', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell physiology', 'ChIP-seq', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Immune response', 'Indium', 'Investigation', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Mediating', 'Messenger RNA', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Physiological Processes', 'Play', 'Process', 'Property', 'Proteins', 'Regulator Genes', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Terminology', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'biological systems', 'cell behavior', 'driving force', 'environmental change', 'gene interaction', 'grasp', 'improved', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'prevent', 'research study', 'response', 'sound', 'tomography', 'tool', 'trend', 'tumor progression', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2014,434355,-0.009118741527541118
"CSHL Computational and Comparative Genomics Course     DESCRIPTION (provided by applicant): The Cold Spring Harbor Laboratory proposes to continue a course entitled ""Computational and Comparative Genomics"", to be held in the fall of 2014 - 2016. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions.         PUBLIC HEALTH RELEVANCE: The Computational & Comparative Genomics is a 6 day course designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.                 ",CSHL Computational and Comparative Genomics Course,8737540,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomics', 'Home environment', 'Institution', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Peptide Sequence Determination', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Universities', 'Update', 'base', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'genome sequencing', 'graduate student', 'instructor', 'interest', 'lecturer', 'meetings', 'programs', 'promoter', 'public health relevance', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2014,52816,0.0068194514194369615
"The q-bio Summer School     DESCRIPTION (provided by applicant): The purpose of the Annual q-bio Summer School, founded in 2007 in Los Alamos, NM, is to advance predictive modeling of cellular regulatory systems by providing trtaining in mathematical, statistical, and computational techniques that are important in systems and synthetic biology. A secondary goal is to advance the careers of researchers new to quantitative biology. The school consists of courses in six subjects: 1) stochastic gene regulation, 2) cell signaling, 3) biomolecular simulations, 4) viral dynamics, 5) synthetic biology, and 6) computational neuroscience. Demand for training in quantitative biology is increasing rapidly-the number of qualified summer school applicants increased from fewer than 40 in 2010 to over 170 in 2012. In response to this demand, we expanded the school in 2012 to accommodate more students. The school now takes place at two campuses, in Santa Fe, NM (courses 1-4) and in San Diego, CA (courses 5-6). Approximately 30 students attend at each campus and are diverse in terms of educational background (mathematics, engineering, physical sciences, and biology), career level (~75% are graduate students, ~20% are postdocs, and ~5% are more advanced), and demographics (gender, race, ethnicity, and worldwide geographical origin). Students attend all core lectures in the courses offered at their campus, as well as specialized course-specific lectures, student get-to-know-me talks, and other talks (e.g., talks focused on career skills), and participate in hands-on computer labs and mentored projects. After two intensive weeks, all students gather in Santa Fe for a 2-day q- bio Student Symposium, which features student projects reports, student poster presentations, and external invited speakers. All students then attend the 4-day q-bio Conference, an international conference attended by >200 researchers. All q-bio Summer School participants can expect the following: a) broad exposure to mathematical/statistical/computational tools used in quantitative biology, b) in-depth training in techniques of special interest (i.e., in one of the six course subjects) through course-specific lectures, computer labs, and mentored projects; c) multiple opportunities to practice scientific communication through talks and poster presentations; d) exposure to cutting-edge research, and e) extensive networking opportunities with peers and thought leaders. Lecturers and speakers include more than 50 different researchers active in quantitative biology, including very distinguished scientists. For example, in 2013, confirmed lecturers include six academicians. By the time the students attend the q-bio Conference, they are equipped with a powerful social network that facilitates interactions, idea exchange, and initiation of collaborative research. The long-term goal of the school is to change the way biological research is conducted, making biology a more quantitative field, like physics and chemistry. In this effort, the organizers are supported by significant goodwill from the international quantitative biology community and a number of local institutions, including two national centers for systems biology. However, to maintain and improve the school, additional financial support is required.         PUBLIC HEALTH RELEVANCE: Many future biomedical and biotechnological advances in synthetic and systems biology will require investigators who have the ability to carefully integrate quantitative experimentation with mathematical, statistical and computational modeling. The goal of the q-bio Summer School is to prepare a new generation of quantitative biologists who are adept at modeling and/or working with modelers to advance our predictive understanding of cellular regulatory systems. The complexity and importance of these systems, which govern cellular activities and fates, provides motivation for developing a scientific and engineering workforce equipped to deal with the complexity.            ",The q-bio Summer School,8643269,R25GM105608,"['Behavior', 'Bioinformatics', 'Biological', 'Biology', 'Career Choice', 'Cell model', 'Cell physiology', 'Cells', 'Chemistry', 'Communication', 'Communities', 'Complex', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Cues', 'Data', 'Education', 'Educational Background', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ethnic Origin', 'Event', 'Exposure to', 'Financial Support', 'Funding', 'Future', 'Gender', 'Gene Expression Regulation', 'Generations', 'Goals', 'Heterogeneity', 'Immune system', 'Individual', 'Institution', 'International', 'Internet', 'Machine Learning', 'Mathematics', 'Mentors', 'Minority-Serving Institution', 'Modeling', 'Molecular', 'Motivation', 'National Institute of General Medical Sciences', 'Neurons', 'Occupations', 'Participant', 'Physics', 'Population', 'Postdoctoral Fellow', 'Qualifying', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Scientist', 'Series', 'Signal Transduction', 'Social Network', 'Statistical Data Interpretation', 'Statistical Models', 'Students', 'Synthetic Genes', 'System', 'Systems Biology', 'Techniques', 'Time', 'Training', 'Underrepresented Minority', 'United States National Institutes of Health', 'Viral', 'Woman', 'Work', 'biochemical model', 'biological research', 'career', 'career development', 'computational neuroscience', 'computerized tools', 'demographics', 'graduate student', 'improved', 'interest', 'lecture notes', 'lecturer', 'lectures', 'mathematical model', 'member', 'model design', 'multidisciplinary', 'peer', 'physical science', 'posters', 'predictive modeling', 'programs', 'public health relevance', 'research study', 'response', 'simulation', 'skills', 'statistics', 'symposium', 'synthetic biology', 'tool']",NIGMS,"NEW MEXICO CONSORTIUM, INC.",R25,2014,171217,-0.007862520247307419
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.       PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8601095,R01GM071966,"['Address', 'Algorithms', 'Bayesian Method', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Cloud Computing', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Microvascular Dysfunction', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2014,391301,-0.011141717306708643
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8640966,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2014,2699376,-0.006729347387595173
"Identification of Therapeutic Small Molecules for Myotonic Dystrophy Type 1     DESCRIPTION (provided by applicant): Myotonic dystrophy (DM1) is the most common adult onset muscular dystrophy in humans. Currently, there is no cure or an FDA approved drug for DM1 and related diseases. DM1 is an autosomal dominant disorder resulting from the expansion of a CTG-repeat sequence in the 3' untranslated region of the DMPK gene. This defect results in the expression of mutant DMPK RNAs encoding expanded CUG repeats (CUGexp) that form large intra nuclear RNA-protein complexes or foci. Expression of CUGexp RNAs leads to abnormal RNA splicing, which in turn has been linked to the development of key features of DM1 pathology. We hypothesize that small molecules that degrade or disperse CUGexp RNAs in DM1 cells can re-establish normal splice patterns and reverse DM1 pathology. To test this hypothesis, we have developed a primary HTS and a secondary hit validation assay to identify small-molecules that selectively alter the biology of DMPK CUGexp RNAs without affecting the normal DMPK transcripts. Our in house library was developed using a robust machine learning chemoinformatics platform and consists of 40,000 highly diverse small-molecules representing a library of several million compounds. Preliminary results obtained from a screen of 2,500 compounds demonstrate that our strategy allows the rapid identification of potent molecules that successfully reverse DM1 pathology in both patient cells and DM1 mouse models. In a concerted effort to identify a set of potent lead compounds that can be developed as a therapeutic cocktail for DM1 we propose the following Aims: Aim 1. Implement primary HTS and the secondary hit validation assay to screen 20,000 molecules from our in-house library. Aim 2. Test hits in tertiary DM1 patient cell-based assays to identify highly potent leads that reverse five key cellular DM1 phenotypes. Selectivity, toxicity and synergy of leads will be measured in parallel. Aim 3. The chemical structure of lead compounds will be reiteratively refined to optimize pharmacological properties and establish structure-activity relationships.          We have developed a HTS screen to identify compounds that alter the biology of toxic CUGexp RNAs in myotonic dystrophy 1 (DM1). This screen will be used to identify therapeutic compounds that can be used to treat DM1.            ",Identification of Therapeutic Small Molecules for Myotonic Dystrophy Type 1,8695714,R21NS077722,"['3&apos', ' Untranslated Regions', 'Adult', 'Affect', 'Biological Assay', 'Biology', 'Cells', 'Chemical Structure', 'Defect', 'Development', 'Disease', 'FDA approved', 'Genes', 'Housing', 'Human', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Measures', 'Muscular Dystrophies', 'Myoblasts', 'Myotonic Dystrophy', 'Nuclear RNA', 'Pathology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Property', 'Protein Kinase C Alpha', 'RNA', 'RNA Splicing', 'Structure-Activity Relationship', 'Testing', 'Therapeutic', 'Toxic effect', 'Transcript', 'Validation', 'base', 'mouse model', 'mutant', 'protein complex', 'small molecule', 'therapeutic target']",NINDS,UNIVERSITY OF SOUTHERN CALIFORNIA,R21,2013,15680,-0.0430613028763152
"HyPhy: Molecular Evolutionary Analyses    DESCRIPTION (provided by applicant): Project Description HyPhy (http://www.hyphy.org) is a scriptable software platform designed to enable flexible and powerful analyses of DNA, RNA, codon, amino acid and other types of sequence data in an evolutionary context. Such analyses have become an indispensable component of most research studies that make use of comparative genomic data. Biologists and bioinformaticians increasingly recognize the benefits of molecular evolutionary analyses. Since its initial release in 2001, HyPhy has become a relatively stable and mature product, and has been downloaded by more than 4,500 unique users, integrated into several popular web-based genomic data analysis servers, cited in over 400 peer-reviewed publications and described in three book chapters, in spite of the fact that the development of the package has never been directly funded. This proposal seeks support to improve the quality, performance, reliability, modularity, documentation and feature sets of the HyPhy system. Specific aims can be divided into four major areas: 1. Software engineering, testing, and documentation of the HyPhy codebase. 2. The development of a high-performance engine for phylogenetic maximum likelihood model fitting and inference. 3. Extension of a newly-initiated toolbox for machine learning applications in molecular evolution. 4. Creation and maintenance of a wiki-themed documentation resource.      PUBLIC HEALTH RELEVANCE: Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.           Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.",HyPhy: Molecular Evolutionary Analyses,8542870,R01GM093939,"['Amino Acids', 'Animal Model', 'Area', 'Biomedical Research', 'Book Chapters', 'Classification', 'Code', 'Codon Nucleotides', 'Collection', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Development', 'Documentation', 'Drug resistance', 'Evolution', 'Funding', 'Gene Mutation', 'Genes', 'Genetic Programming', 'Genome', 'Genomics', 'Goals', 'Human', 'Immune response', 'Internet', 'Language', 'Libraries', 'Likelihood Functions', 'Machine Learning', 'Maintenance', 'Modeling', 'Molecular', 'Molecular Evolution', 'Molecular Sequence Data', 'Online Systems', 'Pathogenicity', 'Pattern', 'Peer Review', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Procedures', 'Publications', 'RNA', 'Research Personnel', 'Resources', 'Software Engineering', 'Study models', 'System', 'Testing', 'Viral', 'Work', 'acronyms', 'base', 'combinatorial', 'comparative genomics', 'design', 'flexibility', 'improved', 'pathogen', 'pressure', 'programs', 'protein structure function', 'public health relevance', 'research study', 'tool', 'user-friendly', 'wiki']",NIGMS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2013,265099,-0.00574404411469761
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.          RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8473164,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Computers', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablets', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2013,1216983,0.029996726469028782
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models     DESCRIPTION (provided by applicant): Malaria is one of the most devastating infectious diseases in the world. Development of novel antimalarial strategies is urgently needed due to the rapid evolution and spread of drug resistance in malaria parasites Plasmodium. The long term goal of this proposed project is to develop a systems-level understanding of the molecular basis of parasitism, pathogenesis, and drug resistance. We will implement approaches that combine machine learning, probabilistic modeling, and genome-wide association analysis to develop more robust computational solutions and identify a comprehensive set of genes or gene products in biological networks that show an increase in genetic variability that can be associated with drug resistance, pathogenesis, virulence, responses to environmental challenges, or with other interesting phenotypes. The three specific aims are:  1. To identify network components using effective remote homology based methods. We will address a critical barrier in malaria research: our inability to assign functional annotation to over 60% of the predicted gene products in the genome of Plasmodium falciparum. We will use a machine learning approach to detect evolutionarily conserved characteristics of the genes/proteins for network inference.  2. To infer the topology and dynamic interplay of cellular networks. Robust models will be developed to reconstruct the gene regulatory networks, signaling cascades and metabolic pathways that define the genetic basis for disease phenotypes.  3. To identify evolutionary signatures of network models by genome-wide association studies (GWAS).  GWAS including Single Nucleotide Polymorphism (SNP) screening of multiple strains with varying phenotypes will serve as an effective means for high throughput wet-lab validations of networks in response to drug treatment. Such networks are the cornerstones of a systems-level view of pathogen biology, a view that will allow us to transform disparate types of data into biological insights for drug development.          Malaria remains one of the most important infectious diseases in the world today, infecting 300-500 million people yearly and resulting in 1-2 million deaths, primarily of young children. This study will develop computational solutions to problems that hitherto have prevented us from gaining a global view of how infection by the malaria parasite leads to the development of the disease. This global overview will help us develop specific solutions to the problems of preventing and treating malaria.            ",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,8539050,SC1GM100806,"['Address', 'Algorithms', 'Antimalarials', 'Biological', 'Biology', 'Cell Cycle', 'Cessation of life', 'Characteristics', 'Child', 'Clinical', 'Communicable Diseases', 'Complement', 'Complex', 'Data', 'Data Analyses', 'Development', 'Disease', 'Drug Targeting', 'Drug resistance', 'Erythrocytes', 'Evolution', 'Funding', 'Gene Duplication', 'Gene Proteins', 'Genes', 'Genetic', 'Genome', 'Genome Components', 'Genomics', 'Goals', 'Grant', 'Horizontal Gene Transfer', 'Immune', 'Infection', 'Knowledge', 'Lead', 'Life Cycle Stages', 'Life Style', 'Machine Learning', 'Malaria', 'Measures', 'Metabolic Pathway', 'Methods', 'Modeling', 'Molecular', 'Open Reading Frames', 'Parasites', 'Pathogenesis', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Population', 'Process', 'Protein Family', 'Proteins', 'Regulator Genes', 'Research', 'Resistance', 'Role', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Solutions', 'Statistical Models', 'System', 'Systems Biology', 'Testing', 'Validation', 'Virulence', 'Work', 'base', 'comparative genomics', 'data mining', 'disease phenotype', 'drug development', 'genome wide association study', 'insight', 'interest', 'mortality', 'network models', 'novel', 'novel therapeutics', 'parasite genome', 'parasitism', 'pathogen', 'pressure', 'prevent', 'research study', 'response', 'screening', 'transcription factor', 'transcriptomics', 'vaccine development']",NIGMS,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2013,354638,-0.027892075884011002
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8464703,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'screening', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2013,1054947,-0.019583936904124178
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8722983,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,115680,-0.015882011109088226
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8548395,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,1871839,-0.015882011109088226
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of time- and space-varying (rather than static) gene network learning, and Bayesian  inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks.  We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during  breast cancer progression and reversal. Since any complex biological processes such as development and  disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is  unreasonable to assume that the underlying network of gene interaction is invariant throughout the process.  But modern experimental and computational methodology is not able to identify such time/space specific  network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the  functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the  grasp of convention methods and requires the methodological innovations we propose. Unraveling and  characterizing such dynamic activities and trajectories of biological networks can provide a more  comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to  better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of  key elements in the network responsible for the functional integrity of the network and the system; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell  differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment  scheme.  PHS 398/2590 (Rev. 09/04, Reissued 4/2006) Page Continuation Format Page",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,8531961,R01GM093156,"['Accounting', 'Algorithms', 'Automobile Driving', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Breast', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell physiology', 'ChIP-seq', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Immune response', 'Indium', 'Investigation', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Mediating', 'Messenger RNA', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Physiological Processes', 'Play', 'Process', 'Property', 'Proteins', 'Regulator Genes', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Terminology', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'biological systems', 'cell behavior', 'driving force', 'environmental change', 'gene interaction', 'grasp', 'improved', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'prevent', 'research study', 'response', 'sound', 'tomography', 'tool', 'trend', 'tumor progression', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2013,422340,-0.009118741527541118
"The q-bio Summer School     DESCRIPTION (provided by applicant): The purpose of the Annual q-bio Summer School, founded in 2007 in Los Alamos, NM, is to advance predictive modeling of cellular regulatory systems by providing trtaining in mathematical, statistical, and computational techniques that are important in systems and synthetic biology. A secondary goal is to advance the careers of researchers new to quantitative biology. The school consists of courses in six subjects: 1) stochastic gene regulation, 2) cell signaling, 3) biomolecular simulations, 4) viral dynamics, 5) synthetic biology, and 6) computational neuroscience. Demand for training in quantitative biology is increasing rapidly-the number of qualified summer school applicants increased from fewer than 40 in 2010 to over 170 in 2012. In response to this demand, we expanded the school in 2012 to accommodate more students. The school now takes place at two campuses, in Santa Fe, NM (courses 1-4) and in San Diego, CA (courses 5-6). Approximately 30 students attend at each campus and are diverse in terms of educational background (mathematics, engineering, physical sciences, and biology), career level (~75% are graduate students, ~20% are postdocs, and ~5% are more advanced), and demographics (gender, race, ethnicity, and worldwide geographical origin). Students attend all core lectures in the courses offered at their campus, as well as specialized course-specific lectures, student get-to-know-me talks, and other talks (e.g., talks focused on career skills), and participate in hands-on computer labs and mentored projects. After two intensive weeks, all students gather in Santa Fe for a 2-day q- bio Student Symposium, which features student projects reports, student poster presentations, and external invited speakers. All students then attend the 4-day q-bio Conference, an international conference attended by >200 researchers. All q-bio Summer School participants can expect the following: a) broad exposure to mathematical/statistical/computational tools used in quantitative biology, b) in-depth training in techniques of special interest (i.e., in one of the six course subjects) through course-specific lectures, computer labs, and mentored projects; c) multiple opportunities to practice scientific communication through talks and poster presentations; d) exposure to cutting-edge research, and e) extensive networking opportunities with peers and thought leaders. Lecturers and speakers include more than 50 different researchers active in quantitative biology, including very distinguished scientists. For example, in 2013, confirmed lecturers include six academicians. By the time the students attend the q-bio Conference, they are equipped with a powerful social network that facilitates interactions, idea exchange, and initiation of collaborative research. The long-term goal of the school is to change the way biological research is conducted, making biology a more quantitative field, like physics and chemistry. In this effort, the organizers are supported by significant goodwill from the international quantitative biology community and a number of local institutions, including two national centers for systems biology. However, to maintain and improve the school, additional financial support is required.         PUBLIC HEALTH RELEVANCE: Many future biomedical and biotechnological advances in synthetic and systems biology will require investigators who have the ability to carefully integrate quantitative experimentation with mathematical, statistical and computational modeling. The goal of the q-bio Summer School is to prepare a new generation of quantitative biologists who are adept at modeling and/or working with modelers to advance our predictive understanding of cellular regulatory systems. The complexity and importance of these systems, which govern cellular activities and fates, provides motivation for developing a scientific and engineering workforce equipped to deal with the complexity.            ",The q-bio Summer School,8475276,R25GM105608,"['Behavior', 'Bioinformatics', 'Biological', 'Biology', 'Career Choice', 'Cell model', 'Cell physiology', 'Cells', 'Chemistry', 'Communication', 'Communities', 'Complex', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Cues', 'Data', 'Education', 'Educational Background', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ethnic Origin', 'Event', 'Exposure to', 'Financial Support', 'Funding', 'Future', 'Gender', 'Gene Expression Regulation', 'Generations', 'Goals', 'Heterogeneity', 'Immune system', 'Individual', 'Institution', 'International', 'Internet', 'Machine Learning', 'Mathematics', 'Mentors', 'Minority-Serving Institution', 'Modeling', 'Molecular', 'Motivation', 'National Institute of General Medical Sciences', 'Neurons', 'Occupations', 'Participant', 'Physics', 'Population', 'Postdoctoral Fellow', 'Qualifying', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Scientist', 'Series', 'Signal Transduction', 'Social Network', 'Statistical Data Interpretation', 'Statistical Models', 'Students', 'Synthetic Genes', 'System', 'Systems Biology', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Viral', 'Woman', 'Work', 'biochemical model', 'biological research', 'career', 'career development', 'computational neuroscience', 'computerized tools', 'demographics', 'graduate student', 'improved', 'interest', 'lecture notes', 'lecturer', 'lectures', 'mathematical model', 'member', 'model design', 'multidisciplinary', 'peer', 'physical science', 'posters', 'predictive modeling', 'programs', 'public health relevance', 'research study', 'response', 'simulation', 'skills', 'statistics', 'symposium', 'synthetic biology', 'tool']",NIGMS,"NEW MEXICO CONSORTIUM, INC.",R25,2013,174626,-0.007862520247307419
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.       PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8403055,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2013,378540,-0.011141717306708643
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8447583,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2013,2703817,-0.006729347387595173
"ISMB 2012 Conference Support for Students & Young Scientists     DESCRIPTION (provided by applicant): The 2012 Intelligent Systems for Molecular Biology (ISMB) conference in will be held in Long Beach, California, with 1,500-1,700 attendees, including 33-38% students/post doctoral researchers. ISMB brings together graduate students, post doctoral researchers, faculty, research staff and senior scientists of many different nationalities, all of whom are studying or working in computer science, molecular biology, mathematics or statistics. The conference brings biologists and computational scientists together to focus on research centered on actual biological problems rather than simply theoretical calculations. The combined focus on ""intelligent systems"" and actual biological data makes ISMB a highly relevant meeting, and many years of producing the event has resulted in a professionally organized and respected annual conference. The ISMB conference presents the latest research methods and results developed through the application of computer programming to the study of biological sciences, including advances in sequencing genomes that may lead to a better understanding of how, for instance, cells interact for the treatment of diseases such as cancer. Presentations may describe methods and advances associated with the analysis of existing biological literature, including benchmarking experiments, to create a better public understanding of scientific research reports. Overall, ISMB serves to educate attendees on the latest developments that will further drive the research methods and results of the field of computational biology. Students and scientists are able to return to their labs to appy what they have learned as they advance their own research efforts or begin investigating new areas they were exposed to as a result of attending ISMB. The scientific program for each ISMB meeting includes parallel presentation tracks of original research papers, highlights of recently published papers, special sessions focused on emerging topics, technology demos, late breaking research and poster presentations, an art in science exhibition, tutorial workshops, special interest group meetings and a student symposium organized by and for students. For ISMB 2011, 258 original research papers were submitted and 48 selected for the Proceedings Track, while 88 previously published papers were submitted and 38 selected for the Highlights Track. In all, over 225 talks were presented during the course of the 2011 conference, and similar numbers are anticipated for 2012. In all cases, submissions are rigorously reviewed, typically by three members of each track's committee before approval by the track chair, insuring the highest possible quality of work is presented. The specific areas represented in the conference vary each year depending on the areas that researchers find most interesting and innovative, and therefore submit as papers and proposals. This proposal seeks funding to assist students and junior researchers in attending the conference, thus exposing them to the latest research of their own areas as well as areas that may be new to them.        PUBLIC HEALTH RELEVANCE: Bioinformatics is well established as an essential tool for understanding biological systems, largely driven by genomic sequence efforts due to the usefulness of genomic data in the quest to develop new and improved treatments for and prevention of disease is highly dependent on one's ability to electronically access and manipulate it. The Intelligent Systems for Molecular Biology (ISMB) conference series directly addresses these questions by showcasing the latest advances in the field and exposing what's on the horizon of future discoveries, but is distinguished from many other events in computational biology or artificial intelligence by an insistence that the researchers work with real molecular biology data, not theoretical or toy examples. Although the cultures of computer science and biology are so disparate, ISMB bridges this cultural gap by providing a forum among biological conferences that features technical advances as they occur, which otherwise may be shunned until a firm experimental result is published.              Bioinformatics is well established as an essential tool for understanding biological systems, largely driven by genomic sequence efforts due to the usefulness of genomic data in the quest to develop new and improved treatments for and prevention of disease is highly dependent on one's ability to electronically access and manipulate it. The Intelligent Systems for Molecular Biology (ISMB) conference series directly addresses these questions by showcasing the latest advances in the field and exposing what's on the horizon of future discoveries, but is distinguished from many other events in computational biology or artificial intelligence by an insistence that the researchers work with real molecular biology data, not theoretical or toy examples. Although the cultures of computer science and biology are so disparate, ISMB bridges this cultural gap by providing a forum among biological conferences that features technical advances as they occur, which otherwise may be shunned until a firm experimental result is published.            ",ISMB 2012 Conference Support for Students & Young Scientists,8317817,R13GM101868,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Arts', 'Benchmarking', 'Binding', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biology', 'California', 'Cells', 'Computational Biology', 'Computational Technique', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Educational workshop', 'Elements', 'Event', 'Evolution', 'Expert Systems', 'Faculty', 'Feedback', 'Financial Support', 'Funding', 'Future', 'Genomics', 'Graph', 'Group Meetings', 'Home environment', 'Human', 'International', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Limited Stage', 'Linguistics', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Metabolic Pathway', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Structure', 'Nationalities', 'Oral', 'Paper', 'Participant', 'Pattern Recognition', 'Peer Review', 'Phylogenetic Analysis', 'Postdoctoral Fellow', 'Published Comment', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Robotics', 'Science', 'Scientist', 'Senior Scientist', 'Sequence Analysis', 'Series', 'Specialist', 'Speed', 'Students', 'System', 'Technology', 'Time', 'Toy', 'Training', 'Validation', 'Work', 'biological systems', 'career', 'computer program', 'computer science', 'disorder prevention', 'exhibitions', 'experience', 'genome sequencing', 'graduate student', 'improved', 'information organization', 'innovation', 'interest', 'lectures', 'medical specialties', 'meetings', 'member', 'multidisciplinary', 'next generation', 'novel', 'parallel computing', 'posters', 'practical application', 'programs', 'research study', 'role model', 'satisfaction', 'skills', 'special interest group', 'statistics', 'symposium', 'tool']",NIGMS,INTERNATIONAL SOCIETY/COMP BIOLOGY,R13,2012,25000,0.015395034595981105
"Identification of Therapeutic Small Molecules for Myotonic Dystrophy Type 1     DESCRIPTION (provided by applicant): Myotonic dystrophy (DM1) is the most common adult onset muscular dystrophy in humans. Currently, there is no cure or an FDA approved drug for DM1 and related diseases. DM1 is an autosomal dominant disorder resulting from the expansion of a CTG-repeat sequence in the 3' untranslated region of the DMPK gene. This defect results in the expression of mutant DMPK RNAs encoding expanded CUG repeats (CUGexp) that form large intra nuclear RNA-protein complexes or foci. Expression of CUGexp RNAs leads to abnormal RNA splicing, which in turn has been linked to the development of key features of DM1 pathology. We hypothesize that small molecules that degrade or disperse CUGexp RNAs in DM1 cells can re-establish normal splice patterns and reverse DM1 pathology. To test this hypothesis, we have developed a primary HTS and a secondary hit validation assay to identify small-molecules that selectively alter the biology of DMPK CUGexp RNAs without affecting the normal DMPK transcripts. Our in house library was developed using a robust machine learning chemoinformatics platform and consists of 40,000 highly diverse small-molecules representing a library of several million compounds. Preliminary results obtained from a screen of 2,500 compounds demonstrate that our strategy allows the rapid identification of potent molecules that successfully reverse DM1 pathology in both patient cells and DM1 mouse models. In a concerted effort to identify a set of potent lead compounds that can be developed as a therapeutic cocktail for DM1 we propose the following Aims: Aim 1. Implement primary HTS and the secondary hit validation assay to screen 20,000 molecules from our in-house library. Aim 2. Test hits in tertiary DM1 patient cell-based assays to identify highly potent leads that reverse five key cellular DM1 phenotypes. Selectivity, toxicity and synergy of leads will be measured in parallel. Aim 3. The chemical structure of lead compounds will be reiteratively refined to optimize pharmacological properties and establish structure-activity relationships.          We have developed a HTS screen to identify compounds that alter the biology of toxic CUGexp RNAs in myotonic dystrophy 1 (DM1). This screen will be used to identify therapeutic compounds that can be used to treat DM1.            ",Identification of Therapeutic Small Molecules for Myotonic Dystrophy Type 1,8337720,R21NS077722,"['3&apos', ' Untranslated Regions', 'Adult', 'Affect', 'Biological Assay', 'Biology', 'Cells', 'Chemical Structure', 'Defect', 'Development', 'Disease', 'FDA approved', 'Genes', 'Housing', 'Human', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Measures', 'Muscular Dystrophies', 'Myoblasts', 'Myotonic Dystrophy', 'Nuclear RNA', 'Pathology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Property', 'Protein Kinase C Alpha', 'RNA', 'RNA Splicing', 'Structure-Activity Relationship', 'Testing', 'Therapeutic', 'Toxic effect', 'Transcript', 'Validation', 'base', 'mouse model', 'mutant', 'protein complex', 'small molecule', 'therapeutic target']",NINDS,UNIVERSITY OF SOUTHERN CALIFORNIA,R21,2012,205000,-0.0430613028763152
"HyPhy: Molecular Evolutionary Analyses    DESCRIPTION (provided by applicant): Project Description HyPhy (http://www.hyphy.org) is a scriptable software platform designed to enable flexible and powerful analyses of DNA, RNA, codon, amino acid and other types of sequence data in an evolutionary context. Such analyses have become an indispensable component of most research studies that make use of comparative genomic data. Biologists and bioinformaticians increasingly recognize the benefits of molecular evolutionary analyses. Since its initial release in 2001, HyPhy has become a relatively stable and mature product, and has been downloaded by more than 4,500 unique users, integrated into several popular web-based genomic data analysis servers, cited in over 400 peer-reviewed publications and described in three book chapters, in spite of the fact that the development of the package has never been directly funded. This proposal seeks support to improve the quality, performance, reliability, modularity, documentation and feature sets of the HyPhy system. Specific aims can be divided into four major areas: 1. Software engineering, testing, and documentation of the HyPhy codebase. 2. The development of a high-performance engine for phylogenetic maximum likelihood model fitting and inference. 3. Extension of a newly-initiated toolbox for machine learning applications in molecular evolution. 4. Creation and maintenance of a wiki-themed documentation resource.      PUBLIC HEALTH RELEVANCE: Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.           Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.",HyPhy: Molecular Evolutionary Analyses,8322626,R01GM093939,"['Amino Acids', 'Animal Model', 'Area', 'Biomedical Research', 'Book Chapters', 'Classification', 'Code', 'Codon Nucleotides', 'Collection', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Development', 'Documentation', 'Drug resistance', 'Evolution', 'Funding', 'Gene Mutation', 'Genes', 'Genetic Programming', 'Genome', 'Genomics', 'Goals', 'Human', 'Immune response', 'Internet', 'Language', 'Libraries', 'Likelihood Functions', 'Machine Learning', 'Maintenance', 'Modeling', 'Molecular', 'Molecular Evolution', 'Molecular Sequence Data', 'Online Systems', 'Pathogenicity', 'Pattern', 'Peer Review', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Procedures', 'Publications', 'RNA', 'Research Personnel', 'Resources', 'Software Engineering', 'Study models', 'System', 'Testing', 'Viral', 'Work', 'acronyms', 'base', 'combinatorial', 'comparative genomics', 'design', 'flexibility', 'improved', 'pathogen', 'pressure', 'programs', 'protein structure function', 'public health relevance', 'research study', 'tool', 'user-friendly', 'wiki']",NIGMS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2012,274156,-0.00574404411469761
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.        PUBLIC HEALTH RELEVANCE: RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                  RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8268588,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Computers', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablets', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2012,1300000,0.024848926801403746
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8274480,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2012,1070334,-0.019583936904124178
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8393965,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2012,75559,-0.019583936904124178
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models     DESCRIPTION (provided by applicant): Malaria is one of the most devastating infectious diseases in the world. Development of novel antimalarial strategies is urgently needed due to the rapid evolution and spread of drug resistance in malaria parasites Plasmodium. The long term goal of this proposed project is to develop a systems-level understanding of the molecular basis of parasitism, pathogenesis, and drug resistance. We will implement approaches that combine machine learning, probabilistic modeling, and genome-wide association analysis to develop more robust computational solutions and identify a comprehensive set of genes or gene products in biological networks that show an increase in genetic variability that can be associated with drug resistance, pathogenesis, virulence, responses to environmental challenges, or with other interesting phenotypes. The three specific aims are:  1. To identify network components using effective remote homology based methods. We will address a critical barrier in malaria research: our inability to assign functional annotation to over 60% of the predicted gene products in the genome of Plasmodium falciparum. We will use a machine learning approach to detect evolutionarily conserved characteristics of the genes/proteins for network inference.  2. To infer the topology and dynamic interplay of cellular networks. Robust models will be developed to reconstruct the gene regulatory networks, signaling cascades and metabolic pathways that define the genetic basis for disease phenotypes.  3. To identify evolutionary signatures of network models by genome-wide association studies (GWAS).  GWAS including Single Nucleotide Polymorphism (SNP) screening of multiple strains with varying phenotypes will serve as an effective means for high throughput wet-lab validations of networks in response to drug treatment. Such networks are the cornerstones of a systems-level view of pathogen biology, a view that will allow us to transform disparate types of data into biological insights for drug development.        PUBLIC HEALTH RELEVANCE: Malaria remains one of the most important infectious diseases in the world today, infecting 300-500 million people yearly and resulting in 1-2 million deaths, primarily of young children. This study will develop computational solutions to problems that hitherto have prevented us from gaining a global view of how infection by the malaria parasite leads to the development of the disease. This global overview will help us develop specific solutions to the problems of preventing and treating malaria.              Malaria remains one of the most important infectious diseases in the world today, infecting 300-500 million people yearly and resulting in 1-2 million deaths, primarily of young children. This study will develop computational solutions to problems that hitherto have prevented us from gaining a global view of how infection by the malaria parasite leads to the development of the disease. This global overview will help us develop specific solutions to the problems of preventing and treating malaria.            ",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,8266807,SC1GM100806,"['Address', 'Algorithms', 'Antimalarials', 'Biological', 'Biology', 'Cell Cycle', 'Cessation of life', 'Characteristics', 'Child', 'Clinical', 'Communicable Diseases', 'Complement', 'Complex', 'Data', 'Data Analyses', 'Development', 'Disease', 'Drug Delivery Systems', 'Drug resistance', 'Erythrocytes', 'Evolution', 'Funding', 'Gene Duplication', 'Gene Proteins', 'Genes', 'Genetic', 'Genome', 'Genome Components', 'Genomics', 'Goals', 'Grant', 'Horizontal Gene Transfer', 'Immune', 'Infection', 'Knowledge', 'Lead', 'Life Cycle Stages', 'Life Style', 'Machine Learning', 'Malaria', 'Measures', 'Metabolic Pathway', 'Methods', 'Modeling', 'Molecular', 'Open Reading Frames', 'Parasites', 'Pathogenesis', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Population', 'Process', 'Protein Family', 'Proteins', 'Regulator Genes', 'Research', 'Resistance', 'Role', 'Screening procedure', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Solutions', 'Statistical Models', 'System', 'Systems Biology', 'Testing', 'Validation', 'Virulence', 'Work', 'base', 'comparative genomics', 'data mining', 'disease phenotype', 'drug development', 'genome wide association study', 'insight', 'interest', 'mortality', 'network models', 'novel', 'novel therapeutics', 'parasite genome', 'parasitism', 'pathogen', 'pressure', 'prevent', 'research study', 'response', 'transcription factor', 'transcriptomics', 'vaccine development']",NIGMS,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2012,367500,-0.024610932848718403
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8402447,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Collection', 'Data Element', 'Data Set', 'Development', 'Disease', 'Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2012,2460045,-0.015882011109088226
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,8280356,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2012,218662,-0.013875384365428359
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of time- and space-varying (rather than static) gene network learning, and Bayesian  inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks.  We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during  breast cancer progression and reversal. Since any complex biological processes such as development and  disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is  unreasonable to assume that the underlying network of gene interaction is invariant throughout the process.  But modern experimental and computational methodology is not able to identify such time/space specific  network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the  functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the  grasp of convention methods and requires the methodological innovations we propose. Unraveling and  characterizing such dynamic activities and trajectories of biological networks can provide a more  comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to  better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of  key elements in the network responsible for the functional integrity of the network and the system; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell  differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment  scheme.  PHS 398/2590 (Rev. 09/04, Reissued 4/2006) Page Continuation Format Page",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,8294774,R01GM093156,"['Accounting', 'Algorithms', 'Automobile Driving', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Breast', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell physiology', 'ChIP-seq', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Immune response', 'Indium', 'Investigation', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Mediating', 'Messenger RNA', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Physiological Processes', 'Play', 'Process', 'Property', 'Proteins', 'Regulator Genes', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Terminology', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'biological systems', 'cell behavior', 'driving force', 'environmental change', 'gene interaction', 'grasp', 'improved', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'prevent', 'research study', 'response', 'sound', 'tomography', 'tool', 'trend', 'tumor progression', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2012,442016,-0.009118741527541118
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,8239531,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Health', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Validation', 'aged', 'arm', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2012,515296,0.008654472612793418
"Functional activity and inter-organismal interactions in the human microbiome    DESCRIPTION (provided by applicant): High-throughput sequencing has provided a tool capable of observing the human microbiome, but characterizing the biological roles and metabolic potential of these microbial communities remains a significant challenge. Increasing evidence points to the functional activity of gene products, rather than community taxonomic composition, as the most robust descriptor of the microflora's relationship with its host and as a potential point of intervention in modulating human health. Existing computational tools for exploring a newly sequenced metagenome rely heavily on sequence homology and do not yet leverage information from the thousands of publicly available functional experimental results. Likewise, no previous methods have provided genome-scale computational tools for biological hypothesis generation regarding specific molecular interactions among the microflora and with a human host. This proposal aims to develop computational methodology to interpret the functional activity of microfloral communities: 1. Integrate functional information from taxonomic, metagenomic, and metatranscriptomic datasets. We will develop methodology to unify these three representations of microbiome composition by incorporating  information from large scale functional genomic data collections. 2. Identify genomic predictors of inter-species functional activity, including host/microflora interactions and points of community-wide regulatory feedback. We will computationally screen microbiome assays for molecular interactions and regulatory motifs spanning multiple organisms in the community. 3. Implement these technologies as publicly available, accessible, and interpretable tools. We will provide freely available, open source, downloadable and web-based implementations of this methodology for use  by the bioinformatic and biological communities. As high-throughput sequencing becomes more widely used to study microbial communities in the human microbiome and in the environment, computational tools will be necessary to summarize their global functional activity and systems-level regulatory interactions. In the long term, by providing methodology to understand the human microbiome at the molecular level, we hope to enable its future use as a diagnostic indicator and as a point of intervention to improve human health.      PUBLIC HEALTH RELEVANCE: DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.              2 Project Narrative DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.",Functional activity and inter-organismal interactions in the human microbiome,8310258,R01HG005969,"['Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cells', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Sequence', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Diagnostic', 'Disease', 'Environment', 'Feedback', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Individual', 'Internet', 'Intervention', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic', 'Metagenomics', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Process', 'Proteins', 'Recombinant DNA', 'Research Personnel', 'Resources', 'Role', 'Sequence Homology', 'Signaling Molecule', 'System', 'Systems Biology', 'Taxon', 'Techniques', 'Technology', 'Testing', 'Tissues', 'base', 'computerized tools', 'functional genomics', 'improved', 'member', 'metagenome', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microorganism', 'novel', 'open source', 'public health relevance', 'repository', 'tool', 'transcriptomics']",NHGRI,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2012,367520,-0.0006828965044038874
"Functional activity and inter-organismal interactions in the human microbiome    DESCRIPTION (provided by applicant): High-throughput sequencing has provided a tool capable of observing the human microbiome, but characterizing the biological roles and metabolic potential of these microbial communities remains a significant challenge. Increasing evidence points to the functional activity of gene products, rather than community taxonomic composition, as the most robust descriptor of the microflora's relationship with its host and as a potential point of intervention in modulating human health. Existing computational tools for exploring a newly sequenced metagenome rely heavily on sequence homology and do not yet leverage information from the thousands of publicly available functional experimental results. Likewise, no previous methods have provided genome-scale computational tools for biological hypothesis generation regarding specific molecular interactions among the microflora and with a human host. This proposal aims to develop computational methodology to interpret the functional activity of microfloral communities: 1. Integrate functional information from taxonomic, metagenomic, and metatranscriptomic datasets. We will develop methodology to unify these three representations of microbiome composition by incorporating  information from large scale functional genomic data collections. 2. Identify genomic predictors of inter-species functional activity, including host/microflora interactions and points of community-wide regulatory feedback. We will computationally screen microbiome assays for molecular interactions and regulatory motifs spanning multiple organisms in the community. 3. Implement these technologies as publicly available, accessible, and interpretable tools. We will provide freely available, open source, downloadable and web-based implementations of this methodology for use  by the bioinformatic and biological communities. As high-throughput sequencing becomes more widely used to study microbial communities in the human microbiome and in the environment, computational tools will be necessary to summarize their global functional activity and systems-level regulatory interactions. In the long term, by providing methodology to understand the human microbiome at the molecular level, we hope to enable its future use as a diagnostic indicator and as a point of intervention to improve human health.      PUBLIC HEALTH RELEVANCE: DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.              2 Project Narrative DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.",Functional activity and inter-organismal interactions in the human microbiome,8537085,R01HG005969,"['Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cells', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Sequence', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Diagnostic', 'Disease', 'Environment', 'Feedback', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Individual', 'Internet', 'Intervention', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic', 'Metagenomics', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Process', 'Proteins', 'Recombinant DNA', 'Research Personnel', 'Resources', 'Role', 'Sequence Homology', 'Signaling Molecule', 'System', 'Systems Biology', 'Taxon', 'Techniques', 'Technology', 'Testing', 'Tissues', 'base', 'computerized tools', 'functional genomics', 'improved', 'member', 'metagenome', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microorganism', 'novel', 'open source', 'public health relevance', 'repository', 'tool', 'transcriptomics']",NHGRI,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2012,139853,-0.0006828965044038874
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.      PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.              Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.",Integration and visualization of diverse biological data,8209212,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'public health relevance', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2012,393228,-0.01872824039363682
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8337800,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Screening procedure', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2012,2751015,-0.006729347387595173
"Identification of Therapeutic Small Molecules for Myotonic Dystrophy Type 1     DESCRIPTION (provided by applicant): Myotonic dystrophy (DM1) is the most common adult onset muscular dystrophy in humans. Currently, there is no cure or an FDA approved drug for DM1 and related diseases. DM1 is an autosomal dominant disorder resulting from the expansion of a CTG-repeat sequence in the 3' untranslated region of the DMPK gene. This defect results in the expression of mutant DMPK RNAs encoding expanded CUG repeats (CUGexp) that form large intra nuclear RNA-protein complexes or foci. Expression of CUGexp RNAs leads to abnormal RNA splicing, which in turn has been linked to the development of key features of DM1 pathology. We hypothesize that small molecules that degrade or disperse CUGexp RNAs in DM1 cells can re-establish normal splice patterns and reverse DM1 pathology. To test this hypothesis, we have developed a primary HTS and a secondary hit validation assay to identify small-molecules that selectively alter the biology of DMPK CUGexp RNAs without affecting the normal DMPK transcripts. Our in house library was developed using a robust machine learning chemoinformatics platform and consists of 40,000 highly diverse small-molecules representing a library of several million compounds. Preliminary results obtained from a screen of 2,500 compounds demonstrate that our strategy allows the rapid identification of potent molecules that successfully reverse DM1 pathology in both patient cells and DM1 mouse models. In a concerted effort to identify a set of potent lead compounds that can be developed as a therapeutic cocktail for DM1 we propose the following Aims: Aim 1. Implement primary HTS and the secondary hit validation assay to screen 20,000 molecules from our in-house library. Aim 2. Test hits in tertiary DM1 patient cell-based assays to identify highly potent leads that reverse five key cellular DM1 phenotypes. Selectivity, toxicity and synergy of leads will be measured in parallel. Aim 3. The chemical structure of lead compounds will be reiteratively refined to optimize pharmacological properties and establish structure-activity relationships.        PUBLIC HEALTH RELEVANCE: We have developed a HTS screen to identify compounds that alter the biology of toxic CUGexp RNAs in myotonic dystrophy 1 (DM1). This screen will be used to identify therapeutic compounds that can be used to treat DM1.              We have developed a HTS screen to identify compounds that alter the biology of toxic CUGexp RNAs in myotonic dystrophy 1 (DM1). This screen will be used to identify therapeutic compounds that can be used to treat DM1.            ",Identification of Therapeutic Small Molecules for Myotonic Dystrophy Type 1,8258211,R21NS077722,"['3&apos', ' Untranslated Regions', 'Adult', 'Affect', 'Biological Assay', 'Biology', 'Cells', 'Chemical Structure', 'Defect', 'Development', 'Disease', 'FDA approved', 'Genes', 'Housing', 'Human', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Measures', 'Muscular Dystrophies', 'Myoblasts', 'Myotonic Dystrophy', 'Nuclear RNA', 'Pathology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Property', 'Protein Kinase C Alpha', 'RNA', 'RNA Splicing', 'Structure-Activity Relationship', 'Testing', 'Therapeutic', 'Toxic effect', 'Transcript', 'Validation', 'base', 'mouse model', 'mutant', 'protein complex', 'small molecule', 'therapeutic target']",NINDS,UNIVERSITY OF SOUTHERN CALIFORNIA,R21,2011,244750,-0.040088189360626886
"HyPhy: Molecular Evolutionary Analyses    DESCRIPTION (provided by applicant): Project Description HyPhy (http://www.hyphy.org) is a scriptable software platform designed to enable flexible and powerful analyses of DNA, RNA, codon, amino acid and other types of sequence data in an evolutionary context. Such analyses have become an indispensable component of most research studies that make use of comparative genomic data. Biologists and bioinformaticians increasingly recognize the benefits of molecular evolutionary analyses. Since its initial release in 2001, HyPhy has become a relatively stable and mature product, and has been downloaded by more than 4,500 unique users, integrated into several popular web-based genomic data analysis servers, cited in over 400 peer-reviewed publications and described in three book chapters, in spite of the fact that the development of the package has never been directly funded. This proposal seeks support to improve the quality, performance, reliability, modularity, documentation and feature sets of the HyPhy system. Specific aims can be divided into four major areas: 1. Software engineering, testing, and documentation of the HyPhy codebase. 2. The development of a high-performance engine for phylogenetic maximum likelihood model fitting and inference. 3. Extension of a newly-initiated toolbox for machine learning applications in molecular evolution. 4. Creation and maintenance of a wiki-themed documentation resource.      PUBLIC HEALTH RELEVANCE: Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.           Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.",HyPhy: Molecular Evolutionary Analyses,8143338,R01GM093939,"['Amino Acids', 'Animal Model', 'Area', 'Biomedical Research', 'Book Chapters', 'Classification', 'Code', 'Codon Nucleotides', 'Collection', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Development', 'Documentation', 'Drug resistance', 'Evolution', 'Funding', 'Gene Mutation', 'Genes', 'Genetic Programming', 'Genome', 'Genomics', 'Goals', 'Human', 'Immune response', 'Internet', 'Language', 'Libraries', 'Likelihood Functions', 'Machine Learning', 'Maintenance', 'Modeling', 'Molecular', 'Molecular Evolution', 'Molecular Sequence Data', 'Online Systems', 'Pathogenicity', 'Pattern', 'Peer Review', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Procedures', 'Publications', 'RNA', 'Research Personnel', 'Resources', 'Software Engineering', 'Study models', 'System', 'Testing', 'Viral', 'Work', 'acronyms', 'base', 'combinatorial', 'comparative genomics', 'design', 'flexibility', 'improved', 'pathogen', 'pressure', 'programs', 'protein structure function', 'public health relevance', 'research study', 'tool', 'user-friendly', 'wiki']",NIGMS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2011,275732,-0.00574404411469761
"Stochastic dynamics for multiscale biology    DESCRIPTION (provided by applicant):  Complex biological systems are increasingly subject to investigation by mathematical modeling in general and stochastic simulation in particular. Advanced mathematical methods will be used to generate next-generation computational methods and algorithms for (1) formulating these models, (2) simulating or sampling their stochastic dynamics, (3) reducing them to simpler approximating models for use in multiscale simulation, and (4) optimizing their unknown or partly known parameters to fit observed behaviors and/or measurements. The proposed methods are based on advances in applied statistical and stochastic mathematics, including advances arising from operator algebra, quantum field theory, stochastic processes, statistical physics, machine learning, and related mathematically grounded fields. A central technique in this work will be the use of the operator algebra formulation of the chemical master equation.       The biological systems to be studied include and are representative of high-value biomedical target systems whose complexity and spatiotemporal scale requires improved mathematical and computational methods, to obtain the scientific understanding underlying future medical intervention. Cancer research is broadly engaged in signal transduction systems and complexes with feedback, for which the yeast Ste5 MARK pathway is a model system. DNA damage sensing (through ATM) and repair control (though p53 and Mdm2) are at least equally important to cancer research owing to the central role that failure of these systems play in many cancers. The dendritic spine synapse system is central to neuroplasticity and therefore human learning and memory. It is critical to understand this neurobiological system well enough to protect it against neurodegenerative diseases and environmental insults. The project seeks fundamental mathematical breakthroughs in stochastic and multiscale modeling that will enable the scientific understanding of these complex systems necessary to create effective medical interventions of the future.           n/a",Stochastic dynamics for multiscale biology,8133946,R01GM086883,"['Affinity', 'Algorithms', 'Behavior', 'Binding', 'Binding Sites', 'Biological', 'Biological Models', 'Biology', 'Chemicals', 'Complex', 'Computational algorithm', 'Computing Methodologies', 'DNA Damage', 'Dendritic Spines', 'Diffusion', 'Drug Formulations', 'Equation', 'Equilibrium', 'Evolution', 'Failure', 'Feedback', 'Free Energy', 'Future', 'Graph', 'Human', 'Intervention', 'Investigation', 'Laws', 'Learning', 'M cell', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Memory', 'Methods', 'Modeling', 'Molecular', 'Neurobiology', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathway interactions', 'Physics', 'Play', 'Process', 'Production', 'Reaction', 'Role', 'Sampling', 'Scheme', 'Semantics', 'Signal Transduction', 'Simulate', 'Site', 'Speed', 'Stochastic Processes', 'Surface', 'Synapses', 'System', 'Techniques', 'Testing', 'Time', 'Transcriptional Regulation', 'Validation', 'Vertebral column', 'Work', 'Yeasts', 'anticancer research', 'base', 'biological systems', 'complex biological systems', 'improved', 'indexing', 'interest', 'mathematical model', 'models and simulation', 'multi-scale modeling', 'next generation', 'novel', 'quantum', 'reaction rate', 'repaired', 'simulation', 'spatiotemporal', 'syntax', 'theories']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2011,297497,0.012659053162600341
"Rational design of cytokine releasing angiogenic constructs    DESCRIPTION (provided by applicant): The development of organized vascular networks necessitates a tightly regulated interplay between variable cells, growth factors and soluble mediators. The applicant's long-term goal is to develop therapeutic angiogenic strategies based on the rational design of cytokine releasing constructs that promote vascular patterning and vessel stability. The objective of this proposal is to i) develop electrospun, three-dimensional constructs with patterned architecture, ii) demonstrate that the spatial and temporal delivery of two model angiogenic growth factors promotes the formation of an organized capillary network and iii) develop a computational model that can predict the biological effect of a growth factor releasing construct as a function of specified fabrication parameters. We hypothesize that guided therapeutic angiogenesis (i.e. patterned vascular networks) can be obtained by controlling the spatial and temporal presentation of soluble mediators at the site of ischemia. In AIM I, we will synthesize bFGF and G-CSF releasing electrospun constructs and determine their programmed delivery as a function of fabrication parameters. In AIM II, we will demonstrate the effect of spatial and temporal control of cytokine delivery in promoting directed angiogenesis in a three-dimensional in vitro angiogenesis model and we will develop a computational model/software that can predict the biological effect of different scaffold configurations. We will validate our model by assessing the angiogenic potential of our growth factor releasing constructs in a murine critical limb ischemic model.      PUBLIC HEALTH RELEVANCE: We are proposing to a) fabricate a growth factor releasing construct that regulates the spatio- temporal delivery of angiogenic cytokines and promotes the formation of organized capillary networks and b) develop a machine learning computational model that can predict the angiogenic potential of our construct as a function of fabrication parameters.           Project narrative We are proposing to a) fabricate a growth factor releasing construct that regulates the spatio- temporal delivery of angiogenic cytokines and promotes the formation of organized capillary networks and b) develop a machine learning computational model that can predict the angiogenic potential of our construct as a function of fabrication parameters.",Rational design of cytokine releasing angiogenic constructs,8112574,R21EB012136,"['Animal Model', 'Animals', 'Architecture', 'Biological', 'Blood Vessels', 'Blood capillaries', 'CSF3 gene', 'Cell Proliferation', 'Cell Transplantation', 'Clinical', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Fiber', 'Fibroblast Growth Factor 2', 'Gelatin', 'Goals', 'Growth', 'Growth Factor', 'In Vitro', 'Ischemia', 'Kinetics', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Mediator of activation protein', 'Modeling', 'Mus', 'Natural regeneration', 'Needles', 'Operative Surgical Procedures', 'Output', 'Pattern', 'Pharmacotherapy', 'Polymers', 'Process', 'Research', 'Series', 'Site', 'Specific qualifier value', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Effect', 'Tissue Engineering', 'angiogenesis', 'base', 'capillary', 'cell growth', 'cell motility', 'cytokine', 'design', 'electric field', 'high risk', 'interest', 'mathematical model', 'minimally invasive', 'multitask', 'nanofiber', 'novel', 'pre-clinical', 'programs', 'public health relevance', 'repaired', 'scaffold', 'spatiotemporal', 'success', 'therapeutic angiogenesis', 'tissue regeneration']",NIBIB,UNIVERSITY OF MIAMI CORAL GABLES,R21,2011,176524,0.0027302094494183024
"High Throughput Screen for Myotonic Dystrophy Type 1    DESCRIPTION (provided by applicant): Myotonic dystrophy (DM1) is the most common adult onset muscular dystrophy in humans. Currently, there is no cure or an FDA approved drug for DM1 and related diseases. The molecular basis of DM1 is the expansion of a CTG-repeat sequence in the 3' untranslated region of the protein kinase gene, DMPK. This defect results in the expression of mutant DMPK RNAs encoding expanded CUG repeats (CUGexp) that form large intra nuclear RNA-protein complexes or foci. Expression of CUGexp RNAs leads to abnormal RNA splicing, which in turn has been linked to the development of key features of DM1 pathology. We hypothesize that small molecules that degrade or disperse CUGexp RNAs in DM1 cells can re-establish normal splice patterns and reverse DM1 pathology. To test this hypothesis, we developed a primary HTS and a secondary hit validation assay to identify small-molecules that alter the biology of CUGexp RNAs without affecting the normal transcript. Our in house library was developed using a robust machine learning chemoinformatics platform and consists of 40,000 highly diverse small-molecules representing a library of over a million compounds. An initial screen of 2,500 small molecules from this library resulted in the identification of a potent lead compound, MDI16, which reverses aberrant RNA splice patterns in both DM1 patient myoblasts and in the HSALR mouse model for DM1. In a concerted effort to identify other potent lead compounds we propose the following: Aim 1. Implement primary HTS and the secondary hit validation assay in the MLPCN center. Aim 2. Test hits in tertiary cell-based assays to identify highly potent molecules that reverse four key cellular DM1 phenotypes. Aim 3. Characterize the selectivity and toxicity of lead compounds and identify their mechanism of action at the cellular level using a set of cell-based assays developed in the lab. Aim 4. In conjunction with the MLPCN center, we will refine the chemical structure of lead compounds reiteratively to optimize pharmacological properties and establish structure-activity relationships.      PUBLIC HEALTH RELEVANCE: Lay Summary Myotonic dystrophy type 1 is a neuromuscular disorder for which there is no treatment or cure. Over the past few years exciting strides in our understanding of the mechanistic basis of this disorder have been made. Thus the field is poised to make a major breakthrough and develop a drug for this disorder. We have developed a sensitive high throughput screen (HTS) to identify compounds that cure or ameliorate pathologies associated with myotonic dystrophy. Currently we have discovered potent molecules, which rescue DM1 pathology in both DM1 patient myoblasts and in DM1 mouse models. As our screens have been proven to identify potent molecules that rescue DM1 pathology, in this application we propose to identify other lead compounds by screening the MLPCN chemical library with our HTS. Identification of multiple leads will greatly improve the probability of a small molecule therapy for DM1.           Lay Summary Myotonic dystrophy type 1 is a neuromuscular disorder for which there is no treatment or cure. Over the past few years exciting strides in our understanding of the mechanistic basis of this disorder have been made. Thus the field is poised to make a major breakthrough and develop a drug for this disorder. We have developed a sensitive high throughput screen (HTS) to identify compounds that cure or ameliorate pathologies associated with myotonic dystrophy. Currently we have discovered potent molecules, which rescue DM1 pathology in both DM1 patient myoblasts and in DM1 mouse models. As our screens have been proven to identify potent molecules that rescue DM1 pathology, in this application we propose to identify other lead compounds by screening the MLPCN chemical library with our HTS. Identification of multiple leads will greatly improve the probability of a small molecule therapy for DM1.         ",High Throughput Screen for Myotonic Dystrophy Type 1,8209483,R03MH095544,"['3&apos', ' Untranslated Regions', 'Adult', 'Affect', 'Antisense Oligonucleotides', 'Binding', 'Biological Assay', 'Biology', 'Cells', 'Chemical Structure', 'Consult', 'Data', 'Defect', 'Development', 'Disease', 'Ectopic Expression', 'FDA approved', 'Genes', 'Housing', 'Human', 'In Vitro', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Mediating', 'Molecular', 'Muscular Dystrophies', 'Myoblasts', 'Myotonic Dystrophy', 'Neuromuscular Diseases', 'Nuclear RNA', 'Pathology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Probability', 'Property', 'Protein Family', 'Protein Kinase', 'Protein Kinase C Alpha', 'RNA', 'RNA Splicing', 'Screening procedure', 'Series', 'Structure-Activity Relationship', 'System', 'Testing', 'Therapeutic', 'Toxic effect', 'Transcript', 'Validation', 'base', 'high throughput screening', 'improved', 'in vivo', 'mouse model', 'mutant', 'protein complex', 'small molecule', 'small molecule libraries', 'therapeutic target', 'transcription factor']",NIMH,UNIVERSITY OF SOUTHERN CALIFORNIA,R03,2011,40750,-0.034894398651103165
"Pattern Discovery for comparative epigenomics    DESCRIPTION (provided by applicant): We propose a training program that will prepare an effective independent investigator in computational genomics. The candidate has a PhD in biology from the University of Cambridge and will extend his skills in both computational and wet-lab methods through a two-year program of organized mentorship and training, and a structured five-year research program.  This program will promote the command of machine learning as applied to functional genomics data. Dr. William Noble will mentor the candidate's scientific development. Dr. Noble is a recognized leader in computational biology and machine learning. He holds a dual appointment as Associate Professor in Genome Sciences and Com- puter Science and Engineering, and has trained numerous postdoctoral fellows and graduate students. Dr. Jeff Bilmes, Associate Professor of Electrical Engineering, will contribute to the mentoring effort, and a committee of experienced genome and computational biologists will advise on science and the candidate's career goals.  Research will focus on the analysis of multiple tracks of data from high-throughput sequencing assays, such as the ChIP-seq data produced by the ENCODE Project. These experiments allow us to obtain a more complete picture of the structure of human chromatin, revealing the behavior of transcription factors, the organization of epigenetic modifications, and the locations of accessible DNA across the entire genome at up to single-base resolution. A current challenge is to discover joint patterns across multiple tracks of these functional genomics results simultaneously. This project will (1) develop computational methods for identifying such patterns, providing new ways of finding both well-understood genomic features and novel functional elements, (2) apply those methods to characterize the similarities and differences among different biological samples, establishing a better understanding of chromatin, the bounds of its variation, and its role in human disease, and (3) validate computational findings with laboratory experiments. The project will use a dynamic Bayesian network (DBN), a type of probabilistic graphical model, to represent the statistical dependencies between observed data, such as sequencing tag density, on an inferred hidden state sequence.  The Department of Genome Sciences of the University Of Washington School Of Medicine provides an ideal setting for training a new independent investigator with an extensive program of formal and informal education for postdoctoral scientists, opportunities for collaboration with researchers with expertise in diverse areas, and modern computational and laboratory resources. This environment maximizes the potential for the candidate to obtain the training and perform the research necessary to establish himself as a skilled investigator with an independent research program.       PUBLIC HEALTH RELEVANCE: The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.              The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.            ",Pattern Discovery for comparative epigenomics,8164533,K99HG006259,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Appointment', 'Area', 'Base Pairing', 'Behavior', 'Biological', 'Biological Assay', 'Biology', 'Cell physiology', 'Cells', 'Censuses', 'Chromatin', 'Chromatin Structure', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Methylation', 'DNA Sequence', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Data Sources', 'Deoxyribonucleases', 'Dependency', 'Development', 'Digestion', 'Disease', 'Doctor of Philosophy', 'Education', 'Electrical Engineering', 'Elements', 'Engineering', 'Enhancers', 'Environment', 'Epigenetic Process', 'Event', 'Exposure to', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Human', 'Individual', 'Joints', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Outcome', 'Pattern', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Probability', 'Qualifying', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sampling', 'Schools', 'Science', 'Scientist', 'Seeds', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'Techniques', 'Time', 'Training', 'Training Programs', 'Transfection', 'Transgenic Mice', 'Universities', 'Variant', 'Washington', 'Work', 'base', 'career', 'cell type', 'chromatin immunoprecipitation', 'clinically relevant', 'comparative', 'computer based statistical methods', 'computer science', 'cytokine', 'density', 'disorder control', 'empowered', 'epigenomics', 'experience', 'follow-up', 'functional genomics', 'genome-wide', 'graduate student', 'histone modification', 'human disease', 'human tissue', 'improved', 'network models', 'new technology', 'novel', 'professor', 'programs', 'promoter', 'research study', 'skills', 'speech processing', 'transcription factor']",NHGRI,UNIVERSITY OF WASHINGTON,K99,2011,102709,-0.01774528520512218
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,8133157,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2011,218724,-0.013875384365428359
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of time- and space-varying (rather than static) gene network learning, and Bayesian  inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks.  We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during  breast cancer progression and reversal. Since any complex biological processes such as development and  disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is  unreasonable to assume that the underlying network of gene interaction is invariant throughout the process.  But modern experimental and computational methodology is not able to identify such time/space specific  network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the  functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the  grasp of convention methods and requires the methodological innovations we propose. Unraveling and  characterizing such dynamic activities and trajectories of biological networks can provide a more  comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to  better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of  key elements in the network responsible for the functional integrity of the network and the system; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell  differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment  scheme.  PHS 398/2590 (Rev. 09/04, Reissued 4/2006) Page Continuation Format Page",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,8079755,R01GM093156,"['Accounting', 'Algorithms', 'Automobile Driving', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Breast', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell physiology', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Disease', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Immune response', 'Indium', 'Investigation', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Mediating', 'Messenger RNA', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathway Analysis', 'Pathway interactions', 'Physiological Processes', 'Play', 'Process', 'Property', 'Proteins', 'Regulator Genes', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Terminology', 'Testing', 'Time', 'Tissues', 'Work', 'base', 'biological systems', 'cell behavior', 'driving force', 'environmental change', 'gene interaction', 'grasp', 'improved', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'prevent', 'research study', 'response', 'sound', 'tomography', 'tool', 'trend', 'tumor progression', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2011,444631,-0.009118741527541118
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,8059586,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Health', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Validation', 'aged', 'arm', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2011,512972,0.008654472612793418
"Functional activity and inter-organismal interactions in the human microbiome    DESCRIPTION (provided by applicant): High-throughput sequencing has provided a tool capable of observing the human microbiome, but characterizing the biological roles and metabolic potential of these microbial communities remains a significant challenge. Increasing evidence points to the functional activity of gene products, rather than community taxonomic composition, as the most robust descriptor of the microflora's relationship with its host and as a potential point of intervention in modulating human health. Existing computational tools for exploring a newly sequenced metagenome rely heavily on sequence homology and do not yet leverage information from the thousands of publicly available functional experimental results. Likewise, no previous methods have provided genome-scale computational tools for biological hypothesis generation regarding specific molecular interactions among the microflora and with a human host. This proposal aims to develop computational methodology to interpret the functional activity of microfloral communities: 1. Integrate functional information from taxonomic, metagenomic, and metatranscriptomic datasets. We will develop methodology to unify these three representations of microbiome composition by incorporating  information from large scale functional genomic data collections. 2. Identify genomic predictors of inter-species functional activity, including host/microflora interactions and points of community-wide regulatory feedback. We will computationally screen microbiome assays for molecular interactions and regulatory motifs spanning multiple organisms in the community. 3. Implement these technologies as publicly available, accessible, and interpretable tools. We will provide freely available, open source, downloadable and web-based implementations of this methodology for use  by the bioinformatic and biological communities. As high-throughput sequencing becomes more widely used to study microbial communities in the human microbiome and in the environment, computational tools will be necessary to summarize their global functional activity and systems-level regulatory interactions. In the long term, by providing methodology to understand the human microbiome at the molecular level, we hope to enable its future use as a diagnostic indicator and as a point of intervention to improve human health.      PUBLIC HEALTH RELEVANCE: DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.              2 Project Narrative DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.",Functional activity and inter-organismal interactions in the human microbiome,8150462,R01HG005969,"['Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cells', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Sequence', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Diagnostic', 'Disease', 'Environment', 'Feedback', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Individual', 'Internet', 'Intervention', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic', 'Metagenomics', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Process', 'Proteins', 'Recombinant DNA', 'Research Personnel', 'Resources', 'Role', 'Sequence Homology', 'Signaling Molecule', 'System', 'Systems Biology', 'Taxon', 'Techniques', 'Technology', 'Testing', 'Tissues', 'base', 'computerized tools', 'functional genomics', 'improved', 'member', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microorganism', 'novel', 'open source', 'public health relevance', 'repository', 'tool', 'transcriptomics']",NHGRI,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2011,407746,-0.0006828965044038874
"ISMB 2011 Conference Support for Students & Young Scientists    DESCRIPTION (provided by applicant): ISMB 2011 Conference Travel Support for Students and Young Scientists.  The Intelligent Systems for Molecular Biology (ISMB) conference in 2011 will be held in Vienna, Austria, as a conference of approximately 1,500-1,700 attendees, including 33-38% students/post doctoral researchers. ISMB brings together graduate students, post doctoral researchers, faculty, research staff and senior scientists of many different nationalities, all of whom are studying or working in computer science, molecular biology, mathematics and/or statistics. The conference brings biologists and computational scientists together to focus on research centered on actual biological problems rather than simply theoretical calculations. The combined focus on ""intelligent systems"" and actual biological data makes ISMB a highly relevant meeting, and many years of producing the event has resulted in a well organized, well attended, and respected annual conference. The ISMB conference presents the latest research methods and results developed through the application of computer programming to the study of biological sciences, including advances in sequencing genomes that may lead to a better understanding of how, for instance, cells interact for the treatment of diseases such as cancer. Additionally, presentations may describe methods and advances associated with the analysis of existing biological literature, including benchmarking experiments, to create a better public understanding of scientific research reports. Overall, ISMB serves to educate attendees on the latest developments that will further drive the research methods and results of the field of computational biology. Students and scientists are able to return to their labs to apply what they have learned as they advance their own research efforts. The scientific program for each ISMB meeting comprises parallel presentation tracks of original research papers, highlights of recently published research, topically focused special sessions on emerging topics, technology demos, tutorial workshops, special interest group meetings and a student symposium organized by and for students. As an example, for ISMB 2010, 234 original research papers were submitted and 48 selected for the Proceedings Track; 126 published papers were submitted and 42 selected for the Highlights Track; nine proposals were submitted and four selected for presentation along with two invited for the Special Sessions Track. In all, well over 200 talks were presented during the course of the 2010 conference, and similar numbers are anticipated for 2011. In all cases, submissions are rigorously reviewed, typically by three members of each track's committee before approval by the track chair, insuring the highest possible quality of work is presented. The specific areas represented in the conference vary each year depending on the areas that researchers find most interesting and innovative, and therefore submit as papers and proposals. This proposal seeks funding to assist students and junior researchers in attending the conference, thus exposing them to the latest research of their own areas as well as areas that may be new to them.      PUBLIC HEALTH RELEVANCE: Relevance Bioinformatics is well established as an essential tool for understanding biological systems. The widespread recognition of bioinformatics has been largely driven by genomic sequence efforts, because laboratory scientists recognize that the usefulness of genomic data in the quest to develop new and improved treatments for and prevention of disease is highly dependent on one's ability to electronically access and manipulate it. Biologists are routinely integrating computational tools into their research programs and creating large predictive models based on information found in databases and other electronic resources. The Intelligent Systems for Molecular Biology (ISMB) conference series directly addresses these questions by showcasing the latest advances in the field, as well as exposing what's on the horizon of future discoveries.           Relevance Bioinformatics is well established as an essential tool for understanding biological systems. The widespread recognition of bioinformatics has been largely driven by genomic sequence efforts, because laboratory scientists recognize that the usefulness of genomic data in the quest to develop new and improved treatments for and prevention of disease is highly dependent on one's ability to electronically access and manipulate it. Biologists are routinely integrating computational tools into their research programs and creating large predictive models based on information found in databases and other electronic resources. The Intelligent Systems for Molecular Biology (ISMB) conference series directly addresses these questions by showcasing the latest advances in the field, as well as exposing what's on the horizon of future discoveries.         ",ISMB 2011 Conference Support for Students & Young Scientists,8121309,R13GM097938,"['Address', 'Algorithms', 'Area', 'Austria', 'Benchmarking', 'Binding', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Cells', 'Computational Biology', 'Computational Technique', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Educational workshop', 'Electronics', 'Elements', 'Event', 'Evolution', 'Expert Systems', 'Faculty', 'Feedback', 'Financial Support', 'Funding', 'Future', 'Genomics', 'Graph', 'Group Meetings', 'Human', 'Industry', 'International', 'Knowledge', 'Laboratory Scientists', 'Lead', 'Learning', 'Limited Stage', 'Linguistics', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Metabolic Pathway', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Structure', 'Nationalities', 'Oral', 'Paper', 'Participant', 'Pattern Recognition', 'Peer Review', 'Phylogenetic Analysis', 'Postdoctoral Fellow', 'Published Comment', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Robotics', 'Role', 'Science', 'Scientist', 'Senior Scientist', 'Sequence Analysis', 'Series', 'Speed', 'Students', 'System', 'Technology', 'Time', 'Training', 'Travel', 'Validation', 'Vendor', 'Work', 'base', 'biological systems', 'career', 'computer program', 'computer science', 'computerized tools', 'cost', 'disorder prevention', 'exhibitions', 'experience', 'genome sequencing', 'graduate student', 'improved', 'information organization', 'innovation', 'interest', 'lectures', 'meetings', 'member', 'multidisciplinary', 'next generation', 'novel', 'parallel computing', 'posters', 'practical application', 'predictive modeling', 'programs', 'research study', 'role model', 'satisfaction', 'skills', 'special interest group', 'statistics', 'symposium', 'tool']",NIGMS,INTERNATIONAL SOCIETY/COMP BIOLOGY,R13,2011,20000,0.005934583765986762
"Integration and visualization of diverse biological data    DESCRIPTION (provided by applicant): Modern genome-scale experimental techniques enable for the first time in biological research the comprehensive monitoring of the entire molecular regulatory events leading to disease. Their integrative analyses hold the promise of generating specific, experimentally testable hypotheses, paving the way for a systems-level molecular view of complex disease. However, systems-level modeling of metazoan biology must address the challenges of: 1. biological complexity, including individual cell lineages and tissue types, 2. the increasingly large scale of data in higher organisms, and 3. the diversity of biomolecules and interaction mechanisms in the cell. The long-term goal of this research is to address these challenges through the development of bioinformatics frameworks for the study of gene function and regulation in complex biological systems thereby contributing to a greater understanding of human disease. In the initial funding period, we have developed accurate methods for integrating and visualizing diverse functional genomics data in S. cerevisiae and implemented them in interactive web-based systems for the biology community. Our methods have led to experimental discoveries of novel biology, are widely used by the yeast community, and are integrated with the SGD model organism database. We now propose to leverage our previous work to develop novel data integration and analysis methods and implement them in a public system for human data. In the proposed research period, we will create algorithms appropriate for integrating metazoan data in a tissue- and cell-lineage specific manner in health and disease. We will also develop novel hierarchical methods for predicting specific molecular interaction mechanisms and will extend our methods for integrating additional biomolecules. These methods will direct experiments focused on the glomerular kidney filter, a critical and complex component of the human vascular system whose dysfunction directly contributes to microvascular disease. Prediction of these cell-lineage specific functional networks will advance the understanding of the glomerulus function and its role in microvascular disease, leading to better clinical predictors, diagnoses, and treatments. From a technical perspective, application to glomerular biology will enable iterative improvement of the proposed methods based on experimental feedback. The end product of this research will be a general, robust, interactive, and automatically updated system for human data integration and analysis that will be freely available to the biomedical community. We will leverage parallel processing technologies (inspired by Google- type cloud computing solutions) to ensure interactive-analysis speed on the system. This system will allow biomedical researchers to synthesize, analyze, and visualize diverse data in human biology, enabling accurate predictions of biological networks and understanding their cell-lineage specificity and role in disease. Such integrative analyses will provide experimentally testable hypotheses, leading to a deeper understanding of complex disorders and paving the way to molecular-defined tissue targeted therapies and drug development.      PUBLIC HEALTH RELEVANCE: Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.              Our general system will enable integrative analysis of human functional genomics data in a cell-lineage and disease-focused manner, allowing biomedical researchers to identify potential clinical biomarkers and to formulate specific hypotheses elucidating the cause and development of a variety of complex disorders. Our application of this system to generate cell-lineage specific functional networks will lead to a better understanding of the glomerulus function and will directly benefit human health through the development of improved predictors, diagnoses, and treatments for microvascular disease.            ",Integration and visualization of diverse biological data,8041717,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Process', 'Biology', 'Cardiovascular Diseases', 'Case Study', 'Cell Lineage', 'Cells', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diabetic Angiopathies', 'Diagnosis', 'Disease', 'Endothelium', 'Ensure', 'Event', 'Feedback', 'Functional disorder', 'Funding', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Grant', 'Health', 'Histocompatibility Testing', 'Human', 'Human Biology', 'Imagery', 'Individual', 'Joints', 'Kidney', 'Kidney Diseases', 'Kidney Glomerulus', 'Lead', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Mus', 'Online Systems', 'Organism', 'Participant', 'Plasma', 'Progress Reports', 'Proteins', 'Publications', 'Research', 'Research Personnel', 'Role', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Sampling', 'Solutions', 'Specificity', 'Speed', 'Structure', 'Structure of glomerular mesangium', 'System', 'Systems Biology', 'Systems Integration', 'Techniques', 'Technology', 'Time', 'Tissues', 'Update', 'Urine', 'Vascular System', 'Work', 'Yeasts', 'base', 'biological research', 'biological systems', 'cell type', 'complex biological systems', 'data integration', 'drug development', 'functional genomics', 'gene function', 'genome database', 'human data', 'human disease', 'human tissue', 'improved', 'model organisms databases', 'novel', 'parallel processing', 'podocyte', 'research study', 'therapy development', 'transcriptomics']",NIGMS,PRINCETON UNIVERSITY,R01,2011,433016,-0.01872824039363682
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,8061704,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'information model', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2011,2923298,0.0014636343646040118
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.      PUBLIC HEALTH RELEVANCE:  Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,            Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8242999,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Screening procedure', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2011,2416667,-0.00659507966286947
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8147701,U19ES019528,[' '],NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2011,1090598,-0.019583936904124178
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,8131721,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative genomics', 'computerized data processing', 'cost effective', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2011,238085,-0.002276321716562226
"HyPhy: Molecular Evolutionary Analyses    DESCRIPTION (provided by applicant): Project Description HyPhy (http://www.hyphy.org) is a scriptable software platform designed to enable flexible and powerful analyses of DNA, RNA, codon, amino acid and other types of sequence data in an evolutionary context. Such analyses have become an indispensable component of most research studies that make use of comparative genomic data. Biologists and bioinformaticians increasingly recognize the benefits of molecular evolutionary analyses. Since its initial release in 2001, HyPhy has become a relatively stable and mature product, and has been downloaded by more than 4,500 unique users, integrated into several popular web-based genomic data analysis servers, cited in over 400 peer-reviewed publications and described in three book chapters, in spite of the fact that the development of the package has never been directly funded. This proposal seeks support to improve the quality, performance, reliability, modularity, documentation and feature sets of the HyPhy system. Specific aims can be divided into four major areas: 1. Software engineering, testing, and documentation of the HyPhy codebase. 2. The development of a high-performance engine for phylogenetic maximum likelihood model fitting and inference. 3. Extension of a newly-initiated toolbox for machine learning applications in molecular evolution. 4. Creation and maintenance of a wiki-themed documentation resource.      PUBLIC HEALTH RELEVANCE: Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.           Project Narrative Molecular evolutionary analyses are central to many aspects of basic, translational, and applied biomedical research. Examples include identifying gene mutations that allow pathogens to evade the immune response; prediction of the structure and function of proteins; estimating the evolutionary relatedness of human or other populations; characterizing the magnitude of selective pressure, either natural or artificial, on genes or species.",HyPhy: Molecular Evolutionary Analyses,7937611,R01GM093939,"['Amino Acids', 'Animal Model', 'Area', 'Biomedical Research', 'Book Chapters', 'Code', 'Codon Nucleotides', 'Collection', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Development', 'Documentation', 'Drug resistance', 'Evolution', 'Funding', 'Gene Mutation', 'Genes', 'Genetic Programming', 'Genome', 'Genomics', 'Goals', 'Human', 'Immune response', 'Internet', 'Language', 'Libraries', 'Machine Learning', 'Maintenance', 'Modeling', 'Molecular', 'Molecular Evolution', 'Molecular Sequence Data', 'Online Systems', 'Pathogenicity', 'Pattern', 'Peer Review', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Population', 'Procedures', 'Publications', 'Research Personnel', 'Resources', 'Software Engineering', 'Study models', 'System', 'Testing', 'Viral', 'Work', 'acronyms', 'base', 'combinatorial', 'comparative genomics', 'design', 'flexibility', 'improved', 'pathogen', 'pressure', 'programs', 'protein structure function', 'public health relevance', 'research study', 'tool', 'user-friendly', 'wiki']",NIGMS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2010,296413,-0.00574404411469761
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),8110238,U54CA121852,"['Address', 'Algorithms', 'Area', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Databases', 'Development', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Genes', 'Genetic Engineering', 'Genomics', 'Internet', 'Investigation', 'Literature', 'Machine Learning', 'Maps', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Research Personnel', 'Resources', 'Signal Pathway', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'base', 'biomedical ontology', 'computer framework', 'data mining', 'design', 'genome-wide', 'graphical user interface', 'knowledge base', 'multidisciplinary', 'natural language', 'novel', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2010,29814,0.013756726476284814
"Cytokine Signaling Network Response to Smallpox Vaccine    DESCRIPTION (provided by applicant):  The identification of the molecular and cellular basis for adverse events observed in patients immunized against smallpox is of great public health interest. This is especially true today given efforts to defend the U.S. population and military against potential bioterrorism agents. We have shown recently that adverse vents following smallpox vaccination correlate with systemic cytokine patterns, suggesting a role for cytokines in the pathogenesis of adverse events. A challenge to further delineating the immunological mechanisms of adverse events is that cytokines rarely act in isolation to induce an immune response, but rather they work in a complex network to which immune system cells respond. Cytokines are small signaling proteins that integrate the activities of immune system cells. While it is often well understood how they act individually, the behavior of cytokines as part of a signaling network is less well known and likely depends on the nature of the infecting organism. We propose to develop and evaluate a comprehensive strategy to identify detailed kinetic cytokine network models associated with adverse events following smallpox vaccination. This strategy will be developed and evaluated using proteomic time-series data available from 103 volunteers that are part of an ongoing NIAID/NIH-sponsored trial to evaluate the Aventis Pasteur Smallpox Vaccine (APSV). We will develop software tools using machine learning algorithms to automatically discover cytokine signaling network models from observed time-series cytokine expression levels. Once the underlying cytokine network model has been estimated, our goal is to use the dynamic model as a simulation tool to suggest ways to create vaccines that minimize the risk of adverse events associated with vaccination. The software tools developed in this proposal will be generally applicable for biomedical research to understand the biochemical interactions in time-series data, and, thus, a useful and novel software package will be made available to the vaccine research community. The experience and knowledge gained during the collaboration on this important research problem in immunology coupled with the didactic and mentoring portions of the training program will create a firm foundation upon which I can develop and test significant hypotheses for future studies on the immunology of infectious diseases.             n/a",Cytokine Signaling Network Response to Smallpox Vaccine,7791405,K25AI064625,"['Address', 'Adverse event', 'Algorithms', 'Behavior', 'Biochemical', 'Biomedical Research', 'Bioterrorism', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Coupled', 'Coupling', 'Cytokine Network Pathway', 'Cytokine Signaling', 'Data', 'Engineering', 'Equation', 'Event', 'Feedback', 'Foundations', 'Future', 'Goals', 'Immune response', 'Immune system', 'Immunization', 'Immunologics', 'Immunology', 'Individual', 'Infectious Disease Immunology', 'Kinetics', 'Knowledge', 'Machine Learning', 'Mentors', 'Methods', 'Military Personnel', 'Modeling', 'Molecular', 'Nature', 'Organism', 'Pathogenesis', 'Patients', 'Pattern', 'Population', 'Proteins', 'Proteomics', 'Public Health', 'Research', 'Research Personnel', 'Risk', 'Role', 'Series', 'Serum', 'Signal Transduction', 'Signaling Protein', 'Simulate', 'Smallpox', 'Smallpox Vaccine', 'Software Tools', 'Systems Biology', 'Testing', 'Time', 'Training Programs', 'Vaccination', 'Vaccine Research', 'Vaccines', 'Vent', 'Work', 'base', 'chemical reaction', 'cytokine', 'design', 'experience', 'interest', 'network models', 'novel', 'programs', 'protein expression', 'research study', 'response', 'simulation', 'software development', 'tool', 'volunteer']",NIAID,UNIVERSITY OF TULSA,K25,2010,113132,-0.01195330514054726
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8146748,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2010,27441,-0.019583936904124178
"Stochastic dynamics for multiscale biology    DESCRIPTION (provided by applicant):  Complex biological systems are increasingly subject to investigation by mathematical modeling in general and stochastic simulation in particular. Advanced mathematical methods will be used to generate next-generation computational methods and algorithms for (1) formulating these models, (2) simulating or sampling their stochastic dynamics, (3) reducing them to simpler approximating models for use in multiscale simulation, and (4) optimizing their unknown or partly known parameters to fit observed behaviors and/or measurements. The proposed methods are based on advances in applied statistical and stochastic mathematics, including advances arising from operator algebra, quantum field theory, stochastic processes, statistical physics, machine learning, and related mathematically grounded fields. A central technique in this work will be the use of the operator algebra formulation of the chemical master equation.       The biological systems to be studied include and are representative of high-value biomedical target systems whose complexity and spatiotemporal scale requires improved mathematical and computational methods, to obtain the scientific understanding underlying future medical intervention. Cancer research is broadly engaged in signal transduction systems and complexes with feedback, for which the yeast Ste5 MARK pathway is a model system. DNA damage sensing (through ATM) and repair control (though p53 and Mdm2) are at least equally important to cancer research owing to the central role that failure of these systems play in many cancers. The dendritic spine synapse system is central to neuroplasticity and therefore human learning and memory. It is critical to understand this neurobiological system well enough to protect it against neurodegenerative diseases and environmental insults. The project seeks fundamental mathematical breakthroughs in stochastic and multiscale modeling that will enable the scientific understanding of these complex systems necessary to create effective medical interventions of the future.           n/a",Stochastic dynamics for multiscale biology,7912919,R01GM086883,"['Affinity', 'Algorithms', 'Behavior', 'Binding', 'Binding Sites', 'Biological', 'Biological Models', 'Biology', 'Chemicals', 'Complex', 'Computing Methodologies', 'DNA Damage', 'Dendritic Spines', 'Diffusion', 'Drug Formulations', 'Equation', 'Equilibrium', 'Evolution', 'Failure', 'Feedback', 'Free Energy', 'Future', 'Graph', 'Human', 'Intervention', 'Investigation', 'Laws', 'Learning', 'M cell', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Memory', 'Methods', 'Modeling', 'Molecular', 'Neurobiology', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathway interactions', 'Physics', 'Play', 'Process', 'Production', 'Reaction', 'Role', 'Sampling', 'Scheme', 'Semantics', 'Signal Transduction', 'Simulate', 'Site', 'Speed', 'Stochastic Processes', 'Surface', 'Synapses', 'System', 'TP53 gene', 'Techniques', 'Testing', 'Time', 'Transcriptional Regulation', 'Validation', 'Vertebral column', 'Work', 'Yeasts', 'anticancer research', 'base', 'biological systems', 'complex biological systems', 'improved', 'indexing', 'interest', 'mathematical model', 'models and simulation', 'multi-scale modeling', 'next generation', 'novel', 'quantum', 'reaction rate', 'repaired', 'simulation', 'spatiotemporal', 'syntax', 'theories']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2010,304151,0.012659053162600341
"Rational design of cytokine releasing angiogenic constructs    DESCRIPTION (provided by applicant): The development of organized vascular networks necessitates a tightly regulated interplay between variable cells, growth factors and soluble mediators. The applicant's long-term goal is to develop therapeutic angiogenic strategies based on the rational design of cytokine releasing constructs that promote vascular patterning and vessel stability. The objective of this proposal is to i) develop electrospun, three-dimensional constructs with patterned architecture, ii) demonstrate that the spatial and temporal delivery of two model angiogenic growth factors promotes the formation of an organized capillary network and iii) develop a computational model that can predict the biological effect of a growth factor releasing construct as a function of specified fabrication parameters. We hypothesize that guided therapeutic angiogenesis (i.e. patterned vascular networks) can be obtained by controlling the spatial and temporal presentation of soluble mediators at the site of ischemia. In AIM I, we will synthesize bFGF and G-CSF releasing electrospun constructs and determine their programmed delivery as a function of fabrication parameters. In AIM II, we will demonstrate the effect of spatial and temporal control of cytokine delivery in promoting directed angiogenesis in a three-dimensional in vitro angiogenesis model and we will develop a computational model/software that can predict the biological effect of different scaffold configurations. We will validate our model by assessing the angiogenic potential of our growth factor releasing constructs in a murine critical limb ischemic model.      PUBLIC HEALTH RELEVANCE: We are proposing to a) fabricate a growth factor releasing construct that regulates the spatio- temporal delivery of angiogenic cytokines and promotes the formation of organized capillary networks and b) develop a machine learning computational model that can predict the angiogenic potential of our construct as a function of fabrication parameters.           Project narrative We are proposing to a) fabricate a growth factor releasing construct that regulates the spatio- temporal delivery of angiogenic cytokines and promotes the formation of organized capillary networks and b) develop a machine learning computational model that can predict the angiogenic potential of our construct as a function of fabrication parameters.",Rational design of cytokine releasing angiogenic constructs,7961101,R21EB012136,"['Animal Model', 'Animals', 'Architecture', 'Biological', 'Blood Vessels', 'Blood capillaries', 'CSF3 gene', 'Cell Proliferation', 'Cell Transplantation', 'Clinical', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Fiber', 'Fibroblast Growth Factor 2', 'Gelatin', 'Goals', 'Growth', 'Growth Factor', 'In Vitro', 'Ischemia', 'Kinetics', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Mediator of activation protein', 'Modeling', 'Mus', 'Natural regeneration', 'Needles', 'Operative Surgical Procedures', 'Output', 'Pattern', 'Pharmacotherapy', 'Polymers', 'Process', 'Research', 'Series', 'Site', 'Specific qualifier value', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Effect', 'Tissue Engineering', 'angiogenesis', 'base', 'capillary', 'cell growth', 'cell motility', 'cytokine', 'design', 'electric field', 'high risk', 'interest', 'mathematical model', 'minimally invasive', 'multitask', 'nanofiber', 'novel', 'pre-clinical', 'programs', 'public health relevance', 'repaired', 'scaffold', 'success', 'therapeutic angiogenesis', 'tissue regeneration']",NIBIB,UNIVERSITY OF MIAMI CORAL GABLES,R21,2010,221192,0.0027302094494183024
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,7887777,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2010,273884,-0.013875384365428359
"Functional activity and inter-organismal interactions in the human microbiome    DESCRIPTION (provided by applicant): High-throughput sequencing has provided a tool capable of observing the human microbiome, but characterizing the biological roles and metabolic potential of these microbial communities remains a significant challenge. Increasing evidence points to the functional activity of gene products, rather than community taxonomic composition, as the most robust descriptor of the microflora's relationship with its host and as a potential point of intervention in modulating human health. Existing computational tools for exploring a newly sequenced metagenome rely heavily on sequence homology and do not yet leverage information from the thousands of publicly available functional experimental results. Likewise, no previous methods have provided genome-scale computational tools for biological hypothesis generation regarding specific molecular interactions among the microflora and with a human host. This proposal aims to develop computational methodology to interpret the functional activity of microfloral communities: 1. Integrate functional information from taxonomic, metagenomic, and metatranscriptomic datasets. We will develop methodology to unify these three representations of microbiome composition by incorporating  information from large scale functional genomic data collections. 2. Identify genomic predictors of inter-species functional activity, including host/microflora interactions and points of community-wide regulatory feedback. We will computationally screen microbiome assays for molecular interactions and regulatory motifs spanning multiple organisms in the community. 3. Implement these technologies as publicly available, accessible, and interpretable tools. We will provide freely available, open source, downloadable and web-based implementations of this methodology for use  by the bioinformatic and biological communities. As high-throughput sequencing becomes more widely used to study microbial communities in the human microbiome and in the environment, computational tools will be necessary to summarize their global functional activity and systems-level regulatory interactions. In the long term, by providing methodology to understand the human microbiome at the molecular level, we hope to enable its future use as a diagnostic indicator and as a point of intervention to improve human health.      PUBLIC HEALTH RELEVANCE: DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.              2 Project Narrative DNA sequencing technology has recently allowed us to examine the microorganisms naturally residing in and on the human body, many of which are beneficial and some of which can be harmful. Although we can now gather data on the cellular behavior of these microbes and on their interactions with human beings, computational tools are needed to interpret this information. By developing new software to study these communities of microorganisms, we hope to eventually be able to detect when they may be causing disease and modify their composition to improve human health.",Functional activity and inter-organismal interactions in the human microbiome,8020799,R01HG005969,"['Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cells', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Diagnostic', 'Disease', 'Environment', 'Feedback', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Health', 'Human', 'Human Microbiome', 'Human body', 'Individual', 'Internet', 'Intervention', 'Machine Learning', 'Maps', 'Mentors', 'Metabolic', 'Metagenomics', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Molecular', 'Online Systems', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Process', 'Proteins', 'Recombinant DNA', 'Research Personnel', 'Resources', 'Role', 'Sequence Homology', 'Signaling Molecule', 'System', 'Systems Biology', 'Taxon', 'Techniques', 'Technology', 'Testing', 'Tissues', 'base', 'computerized tools', 'functional genomics', 'improved', 'member', 'metagenomic sequencing', 'microbial', 'microbial community', 'microbiome', 'microorganism', 'novel', 'open source', 'public health relevance', 'repository', 'tool', 'transcriptomics']",NHGRI,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2010,408559,-0.0006828965044038874
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,7797677,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Validation', 'aged', 'arm', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'public health relevance', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2010,518640,0.008654472612793418
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,8066269,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Validation', 'aged', 'arm', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'public health relevance', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2010,99944,0.008654472612793418
"Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin DESCRIPTION (provided by applicant): A major challenge in systems biology is to quantitatively understand and model the dynamic topological and functional properties of cellular networks, such as the spatial-temporally specific and context-dependent rewiring of transcriptional regulatory circuitry and signal transduction pathways that control cell behavior. Current efforts to study biological networks have primarily focused on creating a descriptive analysis of macroscopic properties. Such simple analyses offer limited insights into the remarkably complex functional and structural organization of a biological system, especially in a dynamic context. Furthermore, most existing techniques for reconstructing molecular networks based on high-throughput data ignore the dynamic aspect of the network topology and represent it as an invariant graph. To our knowledge the network itself is rarely considered as an object that is changing and evolving. In this proposal, we aim to develop principled machine learning algorithms that reverse engineer the temporally and spatially varying interactions between biological molecules from longitudinal or spatial experimental data. Our approaches will take into account biological prior information such as transcriptional factor binding targets, gene knockout experiments, gene ontology, and PPI. Contrary to traditional co-expression studies, our methods unfold the rewiring networks underlying the entire span of the biological process. This will make it possible to discover and trace transient molecular interactions, modules, and pathways during the progression of the process. We will also develop a Bayesian formalism to model and infer the ""dynamic network tomography"" - the meta-states that determine each molecule's function and relationship to other molecules, thereby driving the evolution of the network topology, possibly in response to internal perturbations or environmental changes. Using these new tools, we will carry out a case study on time series gene expression data from organotypic models of breast cancer progression/reversal to gain insight into the mechanisms that drive the temporal rewiring of gene networks during this process. Finally we will also deliver a software platform offering the tools developed in this project to the public. So far, there has not been work done to consider temporally and spatially varying biological interactions under a unified framework. Our proposed work represents an initial foray into this important problem. Our proposed work represents a significant step forward over the current methodology. We envisage a new paradigm that facilitates: 1) Statistical inference and learning of gene networks that are evolving over space and time, possibly in response to various stimuli and possibly mediating genome-environmental interactions. 2) Thorough exploration of the underlying functional underpinnings that drive the network rewiring, dynamic trajectory, and trend of functional evolution. 3) Uncovering transient events taking place in the dynamic systems, building predictive understanding of the mechanisms of gene regulation, network formation, and evolution. 4) Fast and accurate computational algorithms, with stronger statistical guarantee and greater scalability and robustness in large-scale dynamic network analysis. 5) A full spectrum of convenient software packages and user interfaces for dynamic network analysis, available to the public. PUBLIC HEALTH RELEVANCE: We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of time- and space-varying (rather than static) gene network learning, and Bayesian inference of the latent dynamic multi-functionality of genes/proteins in the context of such evolving networks. We intend to apply our method to the study of the dynamic genome-microenvironmental interactions during breast cancer progression and reversal. Since any complex biological processes such as development and disease pathogenesis involve intricate and transient regulatory events and signal transduction, it is unreasonable to assume that the underlying network of gene interaction is invariant throughout the process. But modern experimental and computational methodology is not able to identify such time/space specific network due to technical difficulty, therefore our proposed new methods for inferring evolving network, and the functional underpinnings behind network rewiring are not only needed, but also necessary; but it is beyond the grasp of convention methods and requires the methodological innovations we propose. Unraveling and characterizing such dynamic activities and trajectories of biological networks can provide a more comprehensive genetic and molecular view of complex biological processes and diseases, which may lead to better understanding of the mechanisms driving genome-microenvironmental interactions, and identification of key elements in the network responsible for the functional integrity of the network and the system; in addition, such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to cell differentiation and disease pathogenesis, and to develop improved diagnostic biomarkers and treatment scheme.",Time/Space-Varying Networks of Molecular Interactions: A New Paradigm for Studyin,7865088,R01GM093156,"['3-Dimensional', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'Architecture', 'Automobile Driving', 'Back', 'Behavior', 'Belief', 'Binding', 'Biochemical', 'Biological', 'Biological Markers', 'Biological Process', 'Case Study', 'Cell Cycle', 'Cell Differentiation process', 'Cell Line', 'Cell physiology', 'Characteristics', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Dependency', 'Development', 'Developmental Process', 'Diagnosis', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease Progression', 'Documentation', 'Drosophila genus', 'Drug Delivery Systems', 'Embryo', 'Engineering', 'Event', 'Evolution', 'Exhibits', 'Foundations', 'Gene Expression', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Targeting', 'Genes', 'Genetic', 'Genome', 'Graph', 'Hand', 'Heel', 'Human', 'Imagery', 'Immune response', 'Indium', 'Individual', 'Internet', 'Investigation', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Length', 'Light', 'Literature', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Molecular', 'Molecular Genetics', 'Molecular Profiling', 'Nature', 'Network-based', 'Ontology', 'Organism', 'Pathogenesis', 'Pathologic Processes', 'Pathway Analysis', 'Pathway interactions', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physiological Processes', 'Play', 'Problem Formulations', 'Process', 'Property', 'Proteins', 'Publications', 'Publishing', 'RNA Interference', 'Regulation', 'Regulator Genes', 'Regulatory Pathway', 'Reporting', 'Research', 'Role', 'Saccharomyces cerevisiae', 'Sampling', 'Scheme', 'Science', 'Seminal', 'Series', 'Signal Transduction', 'Signal Transduction Pathway', 'Simulate', 'Software Tools', 'Solutions', 'Source', 'Staging', 'Stimulus', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Time', 'Time Study', 'Tissues', 'Trees', 'Ursidae Family', 'Validation', 'Variant', 'Visual', 'Work', 'base', 'biological systems', 'cell behavior', 'combinatorial', 'computer based statistical methods', 'cost', 'design', 'driving force', 'environmental change', 'fitness', 'gene function', 'gene interaction', 'grasp', 'heuristics', 'improved', 'in vivo', 'innovation', 'insight', 'interest', 'knockout gene', 'malignant breast neoplasm', 'mathematical model', 'novel', 'peer', 'prevent', 'programs', 'promoter', 'protein protein interaction', 'public health relevance', 'research study', 'response', 'scale up', 'software systems', 'sound', 'success', 'tomography', 'tool', 'trait', 'trend', 'tumor progression', 'user friendly software', 'yeast two hybrid system']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2010,460864,-0.009287200209785632
"Interrogation of systems level mechanisms controlling DNA repair processes    DESCRIPTION (provided by applicant): A comprehensive model of a complete biological system will enable prediction of phenotypic outcomes in face of novel genetic and environmental perturbations. Such predictive power for cellular systems, such as DMA repair, will have tremendous impacts on early detection and diagnosis of genetic disorders and, ultimately in designing preventive and/or curative treatments. However, the full understanding of eukaryotic DMA repair systems presents a daunting challenge due to their enormous complexity, especially given that systems approaches are not yet sufficiently mature to mathematically model such complex processes. At a molecular level, eukaryotic genetic information processing is mirrored in a simplified manner by their evolutionary ancestors, the archaea. In Halobacterium NRC-1 we have a simple yet powerful model system of -2400 genes in which the underlying generalized principles of a systems approach can be delineated. This halophilic archaeon routinely mitigates damage from high salinity, UV radiation and desiccation-rehydration cycles. We will use this model system to address the hypothesis that the decision making process governing cell fate after exposure to DMA damaging events such as UV irradiation is mediated by robust gene regulatory networks that simultaneously process information on spectral characteristics of the impinging radiation, the nature and extent of DMA damage and the potential preparative role of cellular entrainment to diurnal cycles. This hypothesis is motivated by two main observations: a. in systems analysis of UV response, although extraordinarily resistant, not all expected repair genes in this microbe responded to irradiation or damage; b. many of these damage-unresponsive repair genes did, however, respond to day-night entrainment. At a fundamental level this suggested that the resident state of the cell at time of irradiation may influence the type of response elicited. A systems approach is ideally suited to delinate the networks underlying this decision making process. Specifically, we will measure dynamic global changes (degree of damage, mRNA /protein levels, protein-protein and protein-DNA interactions) in wild type and mutant strains (defective in sensors, signal transducers, regulators and repair proteins) subjected to combinatorial changes in incident radiation, type of damage inflicted and resident state of the cell at the time of radiation. Through an integrated analysis of these diverse systems level data we will statistically learn perturbation-induced rewiring of a gene regulatory network that processes environmental perturbations (input) into phenotype (output), i.e. a predictive model for regulatory mechanisms for repair. This basic model will serve as a template for designing systems approaches to model higher complexities of eukaryotic repair processes.           n/a",Interrogation of systems level mechanisms controlling DNA repair processes,7896417,R01GM077398,"['Address', 'Algorithms', 'Animal Model', 'Archaea', 'Architecture', 'Behavior', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Candidate Disease Gene', 'Cell Cycle Progression', 'Cell Size', 'Cell Survival', 'Cell physiology', 'Cells', 'Characteristics', 'Chromosomes, Human, Pair 4', 'Circadian Rhythms', 'Complex', 'Coupled', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'DNA biosynthesis', 'DNA lesion', 'DNA repair protein', 'DNA-Protein Interaction', 'Data', 'Decision Making', 'Desiccation', 'Disease', 'Early Diagnosis', 'Elements', 'Engineering', 'Environment', 'Epitopes', 'Equilibrium', 'Event', 'Exogenous Factors', 'Exposure to', 'Face', 'Gene Proteins', 'Genes', 'Genetic', 'Genetic Information Processing Pathway', 'Genetic Transcription', 'Genome', 'Global Change', 'Halobacterium', 'Heart', 'Hour', 'Human', 'Lead', 'Learning', 'Life', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Messenger RNA', 'Metabolism', 'Microbe', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Nucleotide Excision Repair', 'Organism', 'Outcome', 'Output', 'Oxidative Stress', 'Pathway interactions', 'Phenotype', 'Physiological Processes', 'Physiology', 'Preventive', 'Process', 'Protein Dynamics', 'Proteins', 'Radiation', 'Readiness', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Rehydrations', 'Resistance', 'Resources', 'Role', 'Signal Transduction', 'Skin Cancer', 'Source', 'Specific qualifier value', 'System', 'Systems Analysis', 'Systems Biology', 'Technology', 'Tertiary Protein Structure', 'Time', 'Transcript', 'Transducers', 'Translations', 'UV response', 'Ultraviolet Rays', 'biological research', 'biological systems', 'cell type', 'combinatorial', 'coping', 'cryptochrome', 'design', 'gene repair', 'genetic disorder diagnosis', 'halobacteria', 'information processing', 'interest', 'irradiation', 'knockout gene', 'mathematical model', 'mutant', 'novel', 'operation', 'predictive modeling', 'repaired', 'response', 'segregation', 'sensor', 'technology development', 'trait', 'ultraviolet damage', 'ultraviolet irradiation']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,R01,2010,332561,-0.024090090124445317
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7780085,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2010,3513343,0.0014636343646040118
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,8138946,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2010,745063,0.0014636343646040118
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8016739,U19ES019528,[' '],NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2010,1144284,-0.019583936904124178
"National Center: Multiscale Analysis of Genomic and Cellular Networks (MAGNet) A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.   n/a",National Center: Multiscale Analysis of Genomic and Cellular Networks (MAGNet),8012947,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2010,3757192,0.0136959529776102
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7910601,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative genomics', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2010,240491,-0.002276321716562226
"Computational Annotation of Orphan Metabolic Activities    DESCRIPTION (provided by applicant):  Even state-of-the-art homology methods cannot annotate metabolic genes with no or remote sequence identity to known enzymes. This presents a significant obstacle to network reconstruction, as about 30%- 40% (>1500) of known metabolic activities remain orphan, i.e. there are no known proteins catalyzing these activities in any organism. The scale of the orphan activities problem makes it arguably the single biggest challenge of modern biochemistry. We propose to develop, experimentally validate, and make available to the scientific community an efficient computational approach to fill the remaining gaps in metabolic networks. The main idea of the proposed method is to use genes assigned to the network neighbors of the remaining gaps as constraints in assigning genes for orphan activities. We demonstrate that this approach significantly outperforms simpler or existing methods. Our cross-validated results in model organisms demonstrate that the proposed method can predict the correct genes in more than 50% of the cases, without any sequence homology information. The calculations indicate that the prediction accuracy will also remain high in less studied organisms. Using the developed method we have already identified and validated a gene responsible for an E. coli metabolic activity which remained orphan for more than 25 years. There are four specific aims of the proposal: 1.) We will calculate the appropriate context-based descriptors of protein function for the majority of sequenced organisms. Many new functional descriptors will be developed and used for the predictions. 2.) We will investigate the ability of various machine learning approaches and fitness functions to integrate context-based descriptors. Based on the developed methodology we will make predictions for all orphan activities in sequenced organisms. 3.) The predictions will be available through a searchable and constantly updated Web server. We will also develop a method to detect functional misannotations and apply it to all public metabolic databases. 4.) In collaboration with the laboratories of Dr. Uwe Sauer (ETH Zurich) and Dr. George Church (Harvard) we will experimentally test at least 50 of the predicted genes without close sequence homologs in E. coli, B. subtilis, S. cerevisiae.           n/a",Computational Annotation of Orphan Metabolic Activities,7653790,R01GM079759,"['Animal Model', 'Arts', 'Base Sequence', 'Biochemical', 'Biochemical Pathway', 'Biochemistry', 'Biological Neural Networks', 'Church', 'Collaborations', 'Communities', 'Databases', 'Decision Trees', 'Descriptor', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Fusion', 'Genes', 'Genetic', 'Internet', 'Laboratories', 'Link', 'Machine Learning', 'Metabolic', 'Methodology', 'Methods', 'Operon', 'Organism', 'Orphan', 'Pathway interactions', 'Performance', 'Positioning Attribute', 'Proteins', 'Research Personnel', 'Saccharomyces cerevisiae', 'Sequence Homologs', 'Sequence Homology', 'Specific qualifier value', 'Structure', 'Testing', 'Update', 'Validation', 'base', 'computer based statistical methods', 'fitness', 'gene correction', 'gene function', 'genome sequencing', 'metabolomics', 'protein function', 'reconstruction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,397297,-0.014550063035094131
"Pathway Prediction and Assessment Integrating Multiple Evidence Types    DESCRIPTION (provided by applicant):    Metabolic pathway databases provide a biological framework in which relationships among an organism's genes may be revealed. This context can be exploited to boost the accuracy of genome annotation, to discover new targets for therapeutics, or to engineer metabolic pathways in bacteria to produce a historically expensive drug cheaply and quickly. But, knowledge of metabolism in ill-characterized species is limited and dependent on computational predictions of pathways. Our ultimate target is to develop methods for the prediction of novel metabolic pathways in any organism, coupled with robust assessment of the validity of any predicted pathway. We hypothesize that integrating evidence from multiple levels of an organism's metabolic network - from the fit of a pathway within the network to evolutionary relationships between pathways - will allow us to assess pathway validity and to predict novel metabolic pathways. We have successfully applied machine learning methods to the problem of identifying missing enzymes in metabolic pathways and believe similar methods will prove fruitful in this application. Our preliminary studies have identified several properties of predicted metabolic pathways that differ between sets of true positive pathway predictions (i.e., pathways known to occur in an organism) and sets of false positive pathway predictions. We will expand on these features and develop methods to address the following specific aims:      1) Identify features that are informative in distinguishing between correct and incorrect pathway predictions in computationally-generated pathway/genome databases based on predictions for highly-curated organisms (e.g., Escherichia coli and Arabidopsis thaliana).   2) Develop methods for computing the probability that a pathway is correctly predicted. Informative features identified in Specific Aim #1 will be integrated into a classifier that will compute the probability that a predicted pathway is correct given the associated evidence.   3) Extend the Pathologic program (the Pathway Tools algorithm used to infer the metabolic network of an organism) to predict alternate, previously unknown pathways in an organism. We will search the MetaCyc reaction space (comprising almost 6000 reactions) for novel subpathways, explicitly constraining our search using organism-specific evidence (i.e., homology, experimental evidence, etc.) at each step.          n/a",Pathway Prediction and Assessment Integrating Multiple Evidence Types,7685518,R01LM009651,"['Address', 'Algorithms', 'Antimalarials', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Databases', 'Development', 'Engineering', 'Enzymes', 'Escherichia', 'Escherichia coli', 'Future', 'Gene Expression', 'Genes', 'Genome', 'Gold', 'Government', 'Knowledge', 'Laboratory Research', 'Left', 'Machine Learning', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Molecular Profiling', 'Mouse-ear Cress', 'Organism', 'Pathologic', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Probability', 'Prodrugs', 'Property', 'Proteins', 'Reaction', 'Relative (related person)', 'Research', 'Research Institute', 'Research Personnel', 'Scientist', 'Series', 'Techniques', 'Training', 'Validation', 'Yeasts', 'base', 'design', 'genome database', 'metabolomics', 'new therapeutic target', 'novel', 'pathway tools', 'programs', 'reconstruction']",NLM,SRI INTERNATIONAL,R01,2009,175647,0.016028784102610667
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7914681,U54CA121852,"['Address', 'Algorithms', 'Area', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Databases', 'Development', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Genes', 'Genetic Engineering', 'Genomics', 'Internet', 'Investigation', 'Literature', 'Machine Learning', 'Maps', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Research Personnel', 'Resources', 'Signal Pathway', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'base', 'biomedical ontology', 'computer framework', 'data mining', 'design', 'genome-wide', 'graphical user interface', 'knowledge base', 'multidisciplinary', 'natural language', 'novel', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2009,116802,0.013756726476284814
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,7628516,R01GM074128,"['Address', 'Age', 'Algorithms', 'Amino Acids', 'Area', 'Automation', 'Binding', 'Biological', 'Biological Assay', 'Biological Process', 'Carbon', 'Cartoons', 'Cells', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Development', 'Disclosure', 'Disease', 'Expert Systems', 'Genomics', 'Glycoproteins', 'Goals', 'Graft Rejection', 'Human Genome', 'Isomerism', 'Knowledge', 'Learning', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Manuals', 'Mass Spectrum Analysis', 'Methods', 'Modification', 'Monosaccharides', 'Nature', 'Occupations', 'Organism', 'Pathway interactions', 'Pattern', 'Peptides', 'Play', 'Polymers', 'Polysaccharides', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Signal Transduction', 'Site', 'Specialist', 'Specific qualifier value', 'Spectrum Analysis', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'cancer cell', 'egg', 'enzyme activity', 'experience', 'glycosylation', 'glycosyltransferase', 'high throughput analysis', 'immune function', 'improved', 'novel', 'programs', 'prototype', 'sperm cell', 'sugar', 'tool']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2009,329306,-0.030082915348947005
"Cytokine Signaling Network Response to Smallpox Vaccine    DESCRIPTION (provided by applicant):  The identification of the molecular and cellular basis for adverse events observed in patients immunized against smallpox is of great public health interest. This is especially true today given efforts to defend the U.S. population and military against potential bioterrorism agents. We have shown recently that adverse vents following smallpox vaccination correlate with systemic cytokine patterns, suggesting a role for cytokines in the pathogenesis of adverse events. A challenge to further delineating the immunological mechanisms of adverse events is that cytokines rarely act in isolation to induce an immune response, but rather they work in a complex network to which immune system cells respond. Cytokines are small signaling proteins that integrate the activities of immune system cells. While it is often well understood how they act individually, the behavior of cytokines as part of a signaling network is less well known and likely depends on the nature of the infecting organism. We propose to develop and evaluate a comprehensive strategy to identify detailed kinetic cytokine network models associated with adverse events following smallpox vaccination. This strategy will be developed and evaluated using proteomic time-series data available from 103 volunteers that are part of an ongoing NIAID/NIH-sponsored trial to evaluate the Aventis Pasteur Smallpox Vaccine (APSV). We will develop software tools using machine learning algorithms to automatically discover cytokine signaling network models from observed time-series cytokine expression levels. Once the underlying cytokine network model has been estimated, our goal is to use the dynamic model as a simulation tool to suggest ways to create vaccines that minimize the risk of adverse events associated with vaccination. The software tools developed in this proposal will be generally applicable for biomedical research to understand the biochemical interactions in time-series data, and, thus, a useful and novel software package will be made available to the vaccine research community. The experience and knowledge gained during the collaboration on this important research problem in immunology coupled with the didactic and mentoring portions of the training program will create a firm foundation upon which I can develop and test significant hypotheses for future studies on the immunology of infectious diseases.             n/a",Cytokine Signaling Network Response to Smallpox Vaccine,8004341,K25AI064625,"['Address', 'Adverse event', 'Algorithms', 'Behavior', 'Biochemical', 'Biomedical Research', 'Bioterrorism', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Coupled', 'Coupling', 'Cytokine Network Pathway', 'Cytokine Signaling', 'Data', 'Engineering', 'Equation', 'Event', 'Feedback', 'Foundations', 'Future', 'Goals', 'Immune response', 'Immune system', 'Immunization', 'Immunologics', 'Immunology', 'Individual', 'Infectious Disease Immunology', 'Kinetics', 'Knowledge', 'Machine Learning', 'Mentors', 'Methods', 'Military Personnel', 'Modeling', 'Molecular', 'Nature', 'Organism', 'Pathogenesis', 'Patients', 'Pattern', 'Population', 'Proteins', 'Proteomics', 'Public Health', 'Research', 'Research Personnel', 'Risk', 'Role', 'Series', 'Serum', 'Signal Transduction', 'Signaling Protein', 'Simulate', 'Smallpox', 'Smallpox Vaccine', 'Software Tools', 'Systems Biology', 'Testing', 'Time', 'Training Programs', 'Vaccination', 'Vaccine Research', 'Vaccines', 'Vent', 'Work', 'base', 'chemical reaction', 'cytokine', 'design', 'experience', 'interest', 'network models', 'novel', 'programs', 'protein expression', 'research study', 'response', 'simulation', 'software development', 'tool', 'volunteer']",NIAID,UNIVERSITY OF TULSA,K25,2009,39676,-0.01195330514054726
"Cytokine Signaling Network Response to Smallpox Vaccine    DESCRIPTION (provided by applicant):  The identification of the molecular and cellular basis for adverse events observed in patients immunized against smallpox is of great public health interest. This is especially true today given efforts to defend the U.S. population and military against potential bioterrorism agents. We have shown recently that adverse vents following smallpox vaccination correlate with systemic cytokine patterns, suggesting a role for cytokines in the pathogenesis of adverse events. A challenge to further delineating the immunological mechanisms of adverse events is that cytokines rarely act in isolation to induce an immune response, but rather they work in a complex network to which immune system cells respond. Cytokines are small signaling proteins that integrate the activities of immune system cells. While it is often well understood how they act individually, the behavior of cytokines as part of a signaling network is less well known and likely depends on the nature of the infecting organism. We propose to develop and evaluate a comprehensive strategy to identify detailed kinetic cytokine network models associated with adverse events following smallpox vaccination. This strategy will be developed and evaluated using proteomic time-series data available from 103 volunteers that are part of an ongoing NIAID/NIH-sponsored trial to evaluate the Aventis Pasteur Smallpox Vaccine (APSV). We will develop software tools using machine learning algorithms to automatically discover cytokine signaling network models from observed time-series cytokine expression levels. Once the underlying cytokine network model has been estimated, our goal is to use the dynamic model as a simulation tool to suggest ways to create vaccines that minimize the risk of adverse events associated with vaccination. The software tools developed in this proposal will be generally applicable for biomedical research to understand the biochemical interactions in time-series data, and, thus, a useful and novel software package will be made available to the vaccine research community. The experience and knowledge gained during the collaboration on this important research problem in immunology coupled with the didactic and mentoring portions of the training program will create a firm foundation upon which I can develop and test significant hypotheses for future studies on the immunology of infectious diseases.             n/a",Cytokine Signaling Network Response to Smallpox Vaccine,7612652,K25AI064625,"['Address', 'Adverse event', 'Algorithms', 'Behavior', 'Biochemical', 'Biomedical Research', 'Bioterrorism', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Coupled', 'Coupling', 'Cytokine Network Pathway', 'Cytokine Signaling', 'Data', 'Engineering', 'Equation', 'Event', 'Feedback', 'Foundations', 'Future', 'Goals', 'Immune response', 'Immune system', 'Immunization', 'Immunologics', 'Immunology', 'Individual', 'Infectious Disease Immunology', 'Kinetics', 'Knowledge', 'Machine Learning', 'Mentors', 'Methods', 'Military Personnel', 'Modeling', 'Molecular', 'Nature', 'Organism', 'Pathogenesis', 'Patients', 'Pattern', 'Population', 'Proteins', 'Proteomics', 'Public Health', 'Research', 'Research Personnel', 'Risk', 'Role', 'Series', 'Serum', 'Signal Transduction', 'Signaling Protein', 'Simulate', 'Smallpox', 'Smallpox Vaccine', 'Software Tools', 'Systems Biology', 'Testing', 'Time', 'Training Programs', 'Vaccination', 'Vaccine Research', 'Vaccines', 'Vent', 'Work', 'base', 'chemical reaction', 'cytokine', 'design', 'experience', 'interest', 'network models', 'novel', 'programs', 'protein expression', 'research study', 'response', 'simulation', 'software development', 'tool', 'volunteer']",NIAID,UNIVERSITY OF ALABAMA AT BIRMINGHAM,K25,2009,70245,-0.01195330514054726
"Stochastic dynamics for multiscale biology    DESCRIPTION (provided by applicant):  Complex biological systems are increasingly subject to investigation by mathematical modeling in general and stochastic simulation in particular. Advanced mathematical methods will be used to generate next-generation computational methods and algorithms for (1) formulating these models, (2) simulating or sampling their stochastic dynamics, (3) reducing them to simpler approximating models for use in multiscale simulation, and (4) optimizing their unknown or partly known parameters to fit observed behaviors and/or measurements. The proposed methods are based on advances in applied statistical and stochastic mathematics, including advances arising from operator algebra, quantum field theory, stochastic processes, statistical physics, machine learning, and related mathematically grounded fields. A central technique in this work will be the use of the operator algebra formulation of the chemical master equation.       The biological systems to be studied include and are representative of high-value biomedical target systems whose complexity and spatiotemporal scale requires improved mathematical and computational methods, to obtain the scientific understanding underlying future medical intervention. Cancer research is broadly engaged in signal transduction systems and complexes with feedback, for which the yeast Ste5 MARK pathway is a model system. DNA damage sensing (through ATM) and repair control (though p53 and Mdm2) are at least equally important to cancer research owing to the central role that failure of these systems play in many cancers. The dendritic spine synapse system is central to neuroplasticity and therefore human learning and memory. It is critical to understand this neurobiological system well enough to protect it against neurodegenerative diseases and environmental insults. The project seeks fundamental mathematical breakthroughs in stochastic and multiscale modeling that will enable the scientific understanding of these complex systems necessary to create effective medical interventions of the future.           n/a",Stochastic dynamics for multiscale biology,7670408,R01GM086883,"['Affinity', 'Algorithms', 'Behavior', 'Binding', 'Binding Sites', 'Biological', 'Biological Models', 'Biology', 'Chemicals', 'Complex', 'Computing Methodologies', 'DNA Damage', 'Dendritic Spines', 'Diffusion', 'Drug Formulations', 'Equation', 'Equilibrium', 'Evolution', 'Failure', 'Feedback', 'Free Energy', 'Future', 'Graph', 'Human', 'Intervention', 'Investigation', 'Laws', 'Learning', 'M cell', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Memory', 'Methods', 'Modeling', 'Molecular', 'Neurobiology', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathway interactions', 'Physics', 'Play', 'Process', 'Production', 'Reaction', 'Role', 'Sampling', 'Scheme', 'Semantics', 'Signal Transduction', 'Simulate', 'Site', 'Speed', 'Stochastic Processes', 'Surface', 'Synapses', 'System', 'TP53 gene', 'Techniques', 'Testing', 'Time', 'Transcriptional Regulation', 'Validation', 'Vertebral column', 'Work', 'Yeasts', 'anticancer research', 'base', 'biological systems', 'complex biological systems', 'improved', 'indexing', 'interest', 'mathematical model', 'models and simulation', 'multi-scale modeling', 'next generation', 'novel', 'quantum', 'reaction rate', 'repaired', 'simulation', 'spatiotemporal', 'syntax', 'theories']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2009,311541,0.012659053162600341
"Experimental and Computational Studies of Concept Learning    DESCRIPTION (provided by applicant): This research is aimed at developing better understanding of how people bring their prior knowledge to the table when learning about new concepts. Both experimental studies and computational models of these processes will be used to further understanding of this fundamental aspect of human cognition. The proposal focuses on effects and interactions that show that memorized exemplars of a problem are involved with concept learning, on processes involved in unsupervised sorting without feedback, and on how these two processes interact with pre-existing concepts and relational knowledge. New computational models will incorporate exemplars and unsupervised learning into an existing model of knowledge and supervised learning, accounting for a variety of previously observed and newly predicted effects. Experiments involving human participants will investigate interactions of prior knowledge with frequency, exposure, and concept structure. Experiments are paired with the modeling so that new empirical discoveries will go hand-in-hand with theoretical development. If successful, this model will be the only one in the field that accounts for this range of phenomena, encompassing both statistical learning and use of prior knowledge in concept acquisition. Relevance to Public Health: Categorization and category learning are fundamental aspects of cognition, allowing people to intelligently respond to the world. As categorization can be impaired by neurological disorders such as Parkinson's disease, dementia, and amnesia, a rigorous understanding of the processes involved in normal populations aides the research and treatment of disorders in patients. This project will provide a detailed computational model of concept learning, which can then serve as a model to investigate what has gone wrong when the process is disrupted in clinical populations.           n/a",Experimental and Computational Studies of Concept Learning,7633119,F32MH076452,"['Accounting', 'Amnesia', 'Categories', 'Clinical', 'Cognition', 'Computer Simulation', 'Development', 'Disease', 'Feedback', 'Frequencies', 'Goals', 'Hand', 'Human', 'Individual', 'Intelligence', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Modeling', 'Parkinson&apos', 's Dementia', 'Participant', 'Patients', 'Population', 'Process', 'Public Health', 'Research', 'Role', 'Sorting - Cell Movement', 'Structure', 'Testing', 'Thinking', 'base', 'computer studies', 'experience', 'insight', 'nervous system disorder', 'research study', 'satisfaction', 'theories']",NIMH,NEW YORK UNIVERSITY,F32,2009,18437,0.009543027393898687
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7663288,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Computer Systems Development', 'Computer software', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Source', 'Structure', 'System', 'Systems Integration', 'Technology', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'meetings', 'models and simulation', 'open source', 'outreach', 'protein complex', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2009,437938,-0.0077085149231498175
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,7589834,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Aftercare', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Hippocampus (Brain)', 'Human Chromosomes', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Proteins', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Upper arm', 'Validation', 'aged', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'overexpression', 'postnatal', 'public health relevance', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2009,510289,0.008654472612793418
"Integrated Analysis of Genome-Wide Array Data    DESCRIPTION (provided by applicant): This project will develop an integrated desktop application to combine data from expression array, RNA transcript array, proteomics, SNP array (for polymorphism an analysis, as well as LOH and copy number determination), methylation array, histone modification array, promoter array, and microRNA array and metabolomics technologies. Current approaches to analysis of individual `omic' technologies suffer from problems of fragmentation, that present an incomplete view of the workings of the cell. However, effective integration into a single analytic platform is non-trivial. There is a need for a consistent approach, infrastructure, and interface between array types, to maximize ease of use, while recognizing and accommodating the specific computational and statistical requirements, and biological context, of each array. A central challenge is the need to create and work with lists of genomic regions of interest (GROIs) for each sample: we propose three novel approaches to aid in identification of GROIs. These lists must then be integrated with rectangular (sample by feature) data arrays to facilitate statistical analysis. Integration between array types occurs at the computational level, through a unified software package, statistically, through tools that seek statistical relationships between features from different arrays, biologically, through use of annotations (particularly gene ontology, protein- protein and protein-DNA interactions, and pathway membership) that document functional relationships between features, and through genomic interactions that suggest relationships between features that map to the same regions of the genome. The end product will support analysis of each platform separately, with a comprehensive suite of data management, statistical and heuristic analytic tools and the means to place findings of interest into a meaningful biological context through cross-reference to extensive biobases. Beyond that, a range of methods - statistical, biological and genomic - will be available to explore interactions and associations between platforms. PDF created with PDF Factory trial version www.pdffactory.com. PUBLIC HEALTH RELEVANCE: While the large-scale array technologies have provided an unprecedented capability to model cellular processes, both in normal functioning and disease states, this capability is utterly dependent on the availability of complex data management, computational, statistical and informatic software tools.  The utility of the next generation of arrays - which focus on critical regulation and control functions of the cell - will be stymied by an initial lack of suitable bioinformatic tools.  This proposal initiates an accelerated development of an integrated software package intended to empower biologists in the application and analysis of these powerful new technologies, with broadly reaching impact at all levels of biological and clinical research, and across every discipline.          n/a",Integrated Analysis of Genome-Wide Array Data,7788875,R43HG004677,"['Algorithms', 'Alternative Splicing', 'Binding', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Bite', 'Cell physiology', 'Cells', 'Classification', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'DNA copy number', 'DNA-Protein Interaction', 'Data', 'Data Linkages', 'Development', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Gene Expression', 'Genes', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Heating', 'Imagery', 'Individual', 'Informatics', 'Internet', 'Joints', 'Link', 'Loss of Heterozygosity', 'Machine Learning', 'Maps', 'Methylation', 'MicroRNAs', 'Modeling', 'Ontology', 'Pathway interactions', 'Phase', 'Polymorphism Analysis', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Regulation', 'Research Infrastructure', 'Resources', 'Sampling', 'Software Tools', 'Sorting - Cell Movement', 'Statistical Methods', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Transcript', 'Work', 'base', 'data management', 'empowered', 'genome wide association study', 'genome-wide analysis', 'heuristics', 'high throughput technology', 'histone modification', 'interest', 'metabolomics', 'new technology', 'next generation', 'novel', 'novel strategies', 'prognostic', 'promoter', 'public health relevance', 'tool', 'tool development']",NHGRI,EPICENTER SOFTWARE,R43,2009,142123,-0.026045745185661356
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7595813,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'biological systems', 'comparative', 'computer based statistical methods', 'data integration', 'design', 'flexibility', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface', 'web site']",NIGMS,PRINCETON UNIVERSITY,R01,2009,243004,-0.001167308278623237
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7850408,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'discount', 'drug discovery', 'empowered', 'fluorescence imaging', 'genome-wide', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,R01,2009,26557,-0.029107779443447324
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7625039,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Base Management', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data exchange', 'data format', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2009,536571,0.010822388629976675
"Interrogation of systems level mechanisms controlling DNA repair processes    DESCRIPTION (provided by applicant): A comprehensive model of a complete biological system will enable prediction of phenotypic outcomes in face of novel genetic and environmental perturbations. Such predictive power for cellular systems, such as DMA repair, will have tremendous impacts on early detection and diagnosis of genetic disorders and, ultimately in designing preventive and/or curative treatments. However, the full understanding of eukaryotic DMA repair systems presents a daunting challenge due to their enormous complexity, especially given that systems approaches are not yet sufficiently mature to mathematically model such complex processes. At a molecular level, eukaryotic genetic information processing is mirrored in a simplified manner by their evolutionary ancestors, the archaea. In Halobacterium NRC-1 we have a simple yet powerful model system of -2400 genes in which the underlying generalized principles of a systems approach can be delineated. This halophilic archaeon routinely mitigates damage from high salinity, UV radiation and desiccation-rehydration cycles. We will use this model system to address the hypothesis that the decision making process governing cell fate after exposure to DMA damaging events such as UV irradiation is mediated by robust gene regulatory networks that simultaneously process information on spectral characteristics of the impinging radiation, the nature and extent of DMA damage and the potential preparative role of cellular entrainment to diurnal cycles. This hypothesis is motivated by two main observations: a. in systems analysis of UV response, although extraordinarily resistant, not all expected repair genes in this microbe responded to irradiation or damage; b. many of these damage-unresponsive repair genes did, however, respond to day-night entrainment. At a fundamental level this suggested that the resident state of the cell at time of irradiation may influence the type of response elicited. A systems approach is ideally suited to delinate the networks underlying this decision making process. Specifically, we will measure dynamic global changes (degree of damage, mRNA /protein levels, protein-protein and protein-DNA interactions) in wild type and mutant strains (defective in sensors, signal transducers, regulators and repair proteins) subjected to combinatorial changes in incident radiation, type of damage inflicted and resident state of the cell at the time of radiation. Through an integrated analysis of these diverse systems level data we will statistically learn perturbation-induced rewiring of a gene regulatory network that processes environmental perturbations (input) into phenotype (output), i.e. a predictive model for regulatory mechanisms for repair. This basic model will serve as a template for designing systems approaches to model higher complexities of eukaryotic repair processes.           n/a",Interrogation of systems level mechanisms controlling DNA repair processes,7646234,R01GM077398,"['Address', 'Algorithms', 'Animal Model', 'Archaea', 'Architecture', 'Behavior', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Candidate Disease Gene', 'Cell Cycle Progression', 'Cell Size', 'Cell Survival', 'Cell physiology', 'Cells', 'Characteristics', 'Chromosomes, Human, Pair 4', 'Circadian Rhythms', 'Complex', 'Coupled', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'DNA biosynthesis', 'DNA lesion', 'DNA repair protein', 'DNA-Protein Interaction', 'Data', 'Decision Making', 'Desiccation', 'Disease', 'Early Diagnosis', 'Elements', 'Engineering', 'Environment', 'Epitopes', 'Equilibrium', 'Event', 'Exogenous Factors', 'Exposure to', 'Face', 'Gene Proteins', 'Genes', 'Genetic', 'Genetic Information Processing Pathway', 'Genetic Transcription', 'Genome', 'Global Change', 'Halobacterium', 'Heart', 'Hour', 'Human', 'Lead', 'Learning', 'Life', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Messenger RNA', 'Metabolism', 'Microbe', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Nucleotide Excision Repair', 'Operative Surgical Procedures', 'Organism', 'Outcome', 'Output', 'Oxidative Stress', 'Pathway interactions', 'Phenotype', 'Physiological Processes', 'Physiology', 'Preventive', 'Process', 'Protein Dynamics', 'Proteins', 'Radiation', 'Readiness', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Rehydrations', 'Resistance', 'Resources', 'Role', 'Signal Transduction', 'Skin Cancer', 'Source', 'Specific qualifier value', 'System', 'Systems Analysis', 'Systems Biology', 'Technology', 'Tertiary Protein Structure', 'Time', 'Transcript', 'Transducers', 'Translations', 'UV response', 'Ultraviolet Rays', 'biological research', 'biological systems', 'cell type', 'combinatorial', 'coping', 'cryptochrome', 'design', 'gene repair', 'genetic disorder diagnosis', 'halobacteria', 'information processing', 'interest', 'irradiation', 'knockout gene', 'mathematical model', 'mutant', 'novel', 'predictive modeling', 'repaired', 'response', 'segregation', 'sensor', 'technology development', 'trait', 'ultraviolet damage', 'ultraviolet irradiation']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,R01,2009,335920,-0.024090090124445317
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7941562,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2009,1038804,0.0014636343646040118
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7581087,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2009,3437506,0.0014636343646040118
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7676864,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2009,3464579,0.013756726476284814
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7669377,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2009,240426,-0.002276321716562226
"Computational Annotation of Orphan Metabolic Activities    DESCRIPTION (provided by applicant):  Even state-of-the-art homology methods cannot annotate metabolic genes with no or remote sequence identity to known enzymes. This presents a significant obstacle to network reconstruction, as about 30%- 40% (>1500) of known metabolic activities remain orphan, i.e. there are no known proteins catalyzing these activities in any organism. The scale of the orphan activities problem makes it arguably the single biggest challenge of modern biochemistry. We propose to develop, experimentally validate, and make available to the scientific community an efficient computational approach to fill the remaining gaps in metabolic networks. The main idea of the proposed method is to use genes assigned to the network neighbors of the remaining gaps as constraints in assigning genes for orphan activities. We demonstrate that this approach significantly outperforms simpler or existing methods. Our cross-validated results in model organisms demonstrate that the proposed method can predict the correct genes in more than 50% of the cases, without any sequence homology information. The calculations indicate that the prediction accuracy will also remain high in less studied organisms. Using the developed method we have already identified and validated a gene responsible for an E. coli metabolic activity which remained orphan for more than 25 years. There are four specific aims of the proposal: 1.) We will calculate the appropriate context-based descriptors of protein function for the majority of sequenced organisms. Many new functional descriptors will be developed and used for the predictions. 2.) We will investigate the ability of various machine learning approaches and fitness functions to integrate context-based descriptors. Based on the developed methodology we will make predictions for all orphan activities in sequenced organisms. 3.) The predictions will be available through a searchable and constantly updated Web server. We will also develop a method to detect functional misannotations and apply it to all public metabolic databases. 4.) In collaboration with the laboratories of Dr. Uwe Sauer (ETH Zurich) and Dr. George Church (Harvard) we will experimentally test at least 50 of the predicted genes without close sequence homologs in E. coli, B. subtilis, S. cerevisiae.           n/a",Computational Annotation of Orphan Metabolic Activities,7496031,R01GM079759,"['Animal Model', 'Arts', 'Base Sequence', 'Biochemical', 'Biochemical Genetics', 'Biochemical Pathway', 'Biochemistry', 'Biological Neural Networks', 'Church', 'Collaborations', 'Communities', 'Databases', 'Decision Trees', 'Descriptor', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Fusion', 'Genes', 'Genetic', 'Internet', 'Laboratories', 'Link', 'Machine Learning', 'Metabolic', 'Methodology', 'Methods', 'Numbers', 'Operon', 'Organism', 'Orphan', 'Pathway interactions', 'Performance', 'Positioning Attribute', 'Proteins', 'Range', 'Research Personnel', 'Saccharomyces cerevisiae', 'Sequence Homologs', 'Sequence Homology', 'Specific qualifier value', 'Structure', 'Testing', 'Update', 'Validation', 'base', 'computer based statistical methods', 'fitness', 'gene correction', 'gene function', 'genome sequencing', 'metabolomics', 'protein function', 'reconstruction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2008,383732,-0.014550063035094131
"Pathway Prediction and Assessment Integrating Multiple Evidence Types    DESCRIPTION (provided by applicant):    Metabolic pathway databases provide a biological framework in which relationships among an organism's genes may be revealed. This context can be exploited to boost the accuracy of genome annotation, to discover new targets for therapeutics, or to engineer metabolic pathways in bacteria to produce a historically expensive drug cheaply and quickly. But, knowledge of metabolism in ill-characterized species is limited and dependent on computational predictions of pathways. Our ultimate target is to develop methods for the prediction of novel metabolic pathways in any organism, coupled with robust assessment of the validity of any predicted pathway. We hypothesize that integrating evidence from multiple levels of an organism's metabolic network - from the fit of a pathway within the network to evolutionary relationships between pathways - will allow us to assess pathway validity and to predict novel metabolic pathways. We have successfully applied machine learning methods to the problem of identifying missing enzymes in metabolic pathways and believe similar methods will prove fruitful in this application. Our preliminary studies have identified several properties of predicted metabolic pathways that differ between sets of true positive pathway predictions (i.e., pathways known to occur in an organism) and sets of false positive pathway predictions. We will expand on these features and develop methods to address the following specific aims:      1) Identify features that are informative in distinguishing between correct and incorrect pathway predictions in computationally-generated pathway/genome databases based on predictions for highly-curated organisms (e.g., Escherichia coli and Arabidopsis thaliana).   2) Develop methods for computing the probability that a pathway is correctly predicted. Informative features identified in Specific Aim #1 will be integrated into a classifier that will compute the probability that a predicted pathway is correct given the associated evidence.   3) Extend the Pathologic program (the Pathway Tools algorithm used to infer the metabolic network of an organism) to predict alternate, previously unknown pathways in an organism. We will search the MetaCyc reaction space (comprising almost 6000 reactions) for novel subpathways, explicitly constraining our search using organism-specific evidence (i.e., homology, experimental evidence, etc.) at each step.          n/a",Pathway Prediction and Assessment Integrating Multiple Evidence Types,7504002,R01LM009651,"['Address', 'Algorithms', 'Antimalarials', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Coupled', 'Data', 'Data Set', 'Databases', 'Development', 'Engineering', 'Enzymes', 'Escherichia', 'Escherichia coli', 'Future', 'Gene Expression', 'Genes', 'Genome', 'Gold', 'Government', 'Knowledge', 'Laboratory Research', 'Left', 'Machine Learning', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Molecular Profiling', 'Mouse-ear Cress', 'Organism', 'Pathologic', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Probability', 'Prodrugs', 'Property', 'Proteins', 'Reaction', 'Relative (related person)', 'Research', 'Research Institute', 'Research Personnel', 'Scientist', 'Score', 'Series', 'Software Tools', 'Standards of Weights and Measures', 'Techniques', 'Training', 'Validation', 'Yeasts', 'base', 'design', 'genome database', 'metabolomics', 'novel', 'programs', 'reconstruction', 'therapeutic target', 'tool']",NLM,SRI INTERNATIONAL,R01,2008,176002,0.016028784102610667
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,7431760,R01GM074128,"['Address', 'Age', 'Algorithms', 'Amino Acids', 'Area', 'Automation', 'Binding', 'Biological', 'Biological Assay', 'Biological Process', 'Carbon', 'Cartoons', 'Cells', 'Chemicals', 'Class', 'Communities', 'Computer software', 'Data', 'Development', 'Disclosure', 'Disease', 'Expert Systems', 'Facility Construction Funding Category', 'Genomics', 'Glycoproteins', 'Goals', 'Graft Rejection', 'Human Genome', 'Isomerism', 'Knowledge', 'Learning', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Manuals', 'Mass Spectrum Analysis', 'Methods', 'Modification', 'Monosaccharides', 'Nature', 'Numbers', 'Occupations', 'Organism', 'Pathway interactions', 'Pattern', 'Peptides', 'Play', 'Polymers', 'Polysaccharides', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Range', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Score', 'Signal Transduction', 'Site', 'Specialist', 'Specific qualifier value', 'Spectrum Analysis', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Title', 'Training', 'Work', 'cancer cell', 'egg', 'enzyme activity', 'experience', 'glycosylation', 'glycosyltransferase', 'high throughput analysis', 'immune function', 'improved', 'novel', 'programs', 'prototype', 'sperm cell', 'sugar', 'tool']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2008,329296,-0.030082915348947005
"Cytokine Signaling Network Response to Smallpox Vaccine    DESCRIPTION (provided by applicant):  The identification of the molecular and cellular basis for adverse events observed in patients immunized against smallpox is of great public health interest. This is especially true today given efforts to defend the U.S. population and military against potential bioterrorism agents. We have shown recently that adverse vents following smallpox vaccination correlate with systemic cytokine patterns, suggesting a role for cytokines in the pathogenesis of adverse events. A challenge to further delineating the immunological mechanisms of adverse events is that cytokines rarely act in isolation to induce an immune response, but rather they work in a complex network to which immune system cells respond. Cytokines are small signaling proteins that integrate the activities of immune system cells. While it is often well understood how they act individually, the behavior of cytokines as part of a signaling network is less well known and likely depends on the nature of the infecting organism. We propose to develop and evaluate a comprehensive strategy to identify detailed kinetic cytokine network models associated with adverse events following smallpox vaccination. This strategy will be developed and evaluated using proteomic time-series data available from 103 volunteers that are part of an ongoing NIAID/NIH-sponsored trial to evaluate the Aventis Pasteur Smallpox Vaccine (APSV). We will develop software tools using machine learning algorithms to automatically discover cytokine signaling network models from observed time-series cytokine expression levels. Once the underlying cytokine network model has been estimated, our goal is to use the dynamic model as a simulation tool to suggest ways to create vaccines that minimize the risk of adverse events associated with vaccination. The software tools developed in this proposal will be generally applicable for biomedical research to understand the biochemical interactions in time-series data, and, thus, a useful and novel software package will be made available to the vaccine research community. The experience and knowledge gained during the collaboration on this important research problem in immunology coupled with the didactic and mentoring portions of the training program will create a firm foundation upon which I can develop and test significant hypotheses for future studies on the immunology of infectious diseases.             n/a",Cytokine Signaling Network Response to Smallpox Vaccine,7491749,K25AI064625,"['Address', 'Adverse event', 'Algorithms', 'Behavior', 'Biochemical', 'Biomedical Research', 'Bioterrorism', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Coupled', 'Coupling', 'Cytokine Network Pathway', 'Cytokine Signaling', 'Data', 'Engineering', 'Equation', 'Event', 'Feedback', 'Foundations', 'Future', 'Goals', 'Immune response', 'Immune system', 'Immunization', 'Immunologics', 'Immunology', 'Individual', 'Infectious Disease Immunology', 'Kinetics', 'Knowledge', 'Machine Learning', 'Mentors', 'Methods', 'Military Personnel', 'Modeling', 'Molecular', 'Nature', 'Organism', 'Pathogenesis', 'Patients', 'Pattern', 'Population', 'Proteins', 'Proteomics', 'Public Health', 'Research', 'Research Personnel', 'Risk', 'Role', 'Series', 'Serum', 'Signal Transduction', 'Signaling Protein', 'Simulate', 'Smallpox', 'Smallpox Vaccine', 'Software Tools', 'Systems Biology', 'Testing', 'Time', 'Today', 'Training Programs', 'Vaccination', 'Vaccine Research', 'Vaccines', 'Vent', 'Work', 'base', 'chemical reaction', 'cytokine', 'design', 'experience', 'interest', 'network models', 'novel', 'programs', 'protein expression', 'research study', 'response', 'simulation', 'software development', 'tool', 'volunteer']",NIAID,UNIVERSITY OF ALABAMA AT BIRMINGHAM,K25,2008,106794,-0.01195330514054726
"A Simulation Tool to Enable Identification of Critical Network Interactions Using    DESCRIPTION (provided by applicant): One of the main challenges in the discovery of intracellular biomarkers and identification of therapeutic targets is the lack of a mechanistic understanding of the complex underlying pathways. The tremendous increase in both the quantity and diversity of cellular data represents a significant challenge to researchers seeking to construct biologically relevant interaction maps, and objectively extract specific actionable information. Machine learning based clustering algorithms serve as a preliminary statistical data analysis metric, but they fail to capture the data in the proper biological context. While chemical kinetics based models have proved to be effective in elucidating the pathway mechanisms, accurate estimates for the model parameters are severely lacking and are often impossible to obtain owing to the inherent difficulties involved in making dynamic measurements of specific intracellular phenomena. Additionally, methods for rational prioritization and selection of critical intracellular interactions (in the absence of kinetic information) are sorely lacking. Therefore, there is a clear need for innovative software tools that enable quantitative analysis of available microarray data in a biological pathway context, ultimately leading to the objective identification of critical biological interactions, providing a direction for more focused future efforts. We propose to address this challenge by developing an automated software platform that utilizes microarray data to select and merge relevant canonical biological pathway models thereby placing significantly expressed genes in their biological context. The analysis software will utilize a microarray expression-weighted metric to objectively rank the most critical interactions within the network model using a novel chemical kinetics-free Boolean dynamics algorithm. In the Phase I effort, we will develop a software tool composed of an R library that enables the automated generation of a pathway model from a given microarray dataset. Additionally, a methodology, and associated R library will be developed to objectively rank critical interactions in the pathway model, using a microarray data expression-weighted metric. Demonstration and validation of proposed algorithm will be carried out using a well characterized lipopolysaccharide (LPS) stimulated RAW 264.7 macrophage system. In Phase II, we will extend the scope of the algorithmic framework to include proteomic and metabolomic weighting in the objective ranking of critical interactions, and add workflow improvements through the addition of a graphical user interface (GUI). Experimental verification and validation of critical interactions identified in Phase I will be carried out using gene-silencing techniques. We also intend to establish collaborative partnerships with commercial entities. The proposing team has extensive experience in the areas of systems biology and bioinformatics (CFDRC) and microarray data analysis (Shawn Levy, University of Vanderbilt). CFDRC has a strong track record in the commercialization of software and hardware. PUBLIC HEALTH RELEVANCE:  Recently, there has been a tremendous increase in both the amount and diversity of cellular data available to researchers, representing a clear need for the development of advanced computational analysis software to enable the discovery of biomarkers of disease states, and identification of new therapeutic targets. However, currently available analysis tools do not consider the data in a proper biological context. This research proposes to develop an automated software platform that utilizes available data to develop and analyze mathematical models of complex processes in an automated fashion, resulting in the identification of critical intracellular processes.             n/a",A Simulation Tool to Enable Identification of Critical Network Interactions Using,7482734,R43GM084890,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Bioinformatics', 'Biological', 'Biological Markers', 'Complex', 'Computer Analysis', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Future', 'Gene Silencing', 'Generations', 'Genes', 'Genomics', 'Kinetics', 'Lead', 'Libraries', 'Lipopolysaccharides', 'Machine Learning', 'Maps', 'Measurement', 'Methodology', 'Methods', 'Metric', 'Microarray Analysis', 'Modeling', 'Nature', 'Pathway Analysis', 'Pathway interactions', 'Phase', 'Process', 'Proteomics', 'Public Health', 'Research', 'Research Personnel', 'Software Tools', 'Statistical Data Interpretation', 'System', 'Systems Biology', 'Techniques', 'Title', 'Universities', 'Urination', 'Validation', 'Weight', 'base', 'chemical kinetics', 'commercialization', 'editorial', 'experience', 'graphical user interface', 'innovation', 'macrophage', 'mathematical model', 'metabolomics', 'network models', 'novel', 'novel therapeutics', 'simulation', 'therapeutic target', 'tool']",NIGMS,CFD RESEARCH CORPORATION,R43,2008,99571,0.029029448031347535
"Stochastic dynamics for multiscale biology    DESCRIPTION (provided by applicant):  Complex biological systems are increasingly subject to investigation by mathematical modeling in general and stochastic simulation in particular. Advanced mathematical methods will be used to generate next-generation computational methods and algorithms for (1) formulating these models, (2) simulating or sampling their stochastic dynamics, (3) reducing them to simpler approximating models for use in multiscale simulation, and (4) optimizing their unknown or partly known parameters to fit observed behaviors and/or measurements. The proposed methods are based on advances in applied statistical and stochastic mathematics, including advances arising from operator algebra, quantum field theory, stochastic processes, statistical physics, machine learning, and related mathematically grounded fields. A central technique in this work will be the use of the operator algebra formulation of the chemical master equation.       The biological systems to be studied include and are representative of high-value biomedical target systems whose complexity and spatiotemporal scale requires improved mathematical and computational methods, to obtain the scientific understanding underlying future medical intervention. Cancer research is broadly engaged in signal transduction systems and complexes with feedback, for which the yeast Ste5 MARK pathway is a model system. DNA damage sensing (through ATM) and repair control (though p53 and Mdm2) are at least equally important to cancer research owing to the central role that failure of these systems play in many cancers. The dendritic spine synapse system is central to neuroplasticity and therefore human learning and memory. It is critical to understand this neurobiological system well enough to protect it against neurodegenerative diseases and environmental insults. The project seeks fundamental mathematical breakthroughs in stochastic and multiscale modeling that will enable the scientific understanding of these complex systems necessary to create effective medical interventions of the future.           n/a",Stochastic dynamics for multiscale biology,7596501,R01GM086883,"['Affinity', 'Algorithms', 'Behavior', 'Binding', 'Binding Sites', 'Biological', 'Biological Models', 'Biology', 'Chemicals', 'Chromosome Pairing', 'Complex', 'Computing Methodologies', 'DNA Damage', 'Dendritic Spines', 'Diffusion', 'Drug Formulations', 'Equation', 'Equilibrium', 'Evolution', 'Failure', 'Feedback', 'Free Energy', 'Future', 'Graph', 'Human', 'Intervention', 'Investigation', 'Laws', 'Learning', 'M cell', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Memory', 'Methods', 'Modeling', 'Molecular', 'Neurobiology', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Numbers', 'Pathway interactions', 'Physics', 'Play', 'Process', 'Production', 'Purpose', 'Rate', 'Reaction', 'Role', 'Sampling', 'Scheme', 'Semantics', 'Signal Transduction', 'Simulate', 'Site', 'Speed', 'Stochastic Processes', 'Surface', 'Synapses', 'System', 'TP53 gene', 'Techniques', 'Testing', 'Time', 'Transcriptional Regulation', 'Validation', 'Vertebral column', 'Work', 'Yeasts', 'anticancer research', 'base', 'concept', 'improved', 'indexing', 'interest', 'mathematical model', 'models and simulation', 'multi-scale modeling', 'next generation', 'novel', 'quantum', 'reaction rate', 'repaired', 'simulation', 'spatiotemporal', 'syntax', 'theories']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2008,319129,0.012659053162600341
"Nation Center: Multi-Scale Study- Cellular Networks(RMI) A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genomewide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 1 investigators to combine molecular interaction clues from Core 2 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions. n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7674889,U54CA121852,"['Address', 'Algorithms', 'Area', 'Automobile Driving', 'Binding', 'Bioinformatics', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'DNA-Protein Interaction', 'Databases', 'Development', 'Dissection', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Genes', 'Genetic Engineering', 'Genomics', 'Individual', 'Internet', 'Investigation', 'Knowledge', 'Language', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Published Comment', 'Range', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'Science', 'Signal Pathway', 'Skeleton', 'Source', 'Structure', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'Work', 'base', 'computer framework', 'data mining', 'design', 'graphical user interface', 'improved', 'innovation', 'knowledge base', 'multidisciplinary', 'novel', 'response', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2008,113826,0.012558834867775053
"Experimental and Computational Studies of Concept Learning    DESCRIPTION (provided by applicant): This research is aimed at developing better understanding of how people bring their prior knowledge to the table when learning about new concepts. Both experimental studies and computational models of these processes will be used to further understanding of this fundamental aspect of human cognition. The proposal focuses on effects and interactions that show that memorized exemplars of a problem are involved with concept learning, on processes involved in unsupervised sorting without feedback, and on how these two processes interact with pre-existing concepts and relational knowledge. New computational models will incorporate exemplars and unsupervised learning into an existing model of knowledge and supervised learning, accounting for a variety of previously observed and newly predicted effects. Experiments involving human participants will investigate interactions of prior knowledge with frequency, exposure, and concept structure. Experiments are paired with the modeling so that new empirical discoveries will go hand-in-hand with theoretical development. If successful, this model will be the only one in the field that accounts for this range of phenomena, encompassing both statistical learning and use of prior knowledge in concept acquisition. Relevance to Public Health: Categorization and category learning are fundamental aspects of cognition, allowing people to intelligently respond to the world. As categorization can be impaired by neurological disorders such as Parkinson's disease, dementia, and amnesia, a rigorous understanding of the processes involved in normal populations aides the research and treatment of disorders in patients. This project will provide a detailed computational model of concept learning, which can then serve as a model to investigate what has gone wrong when the process is disrupted in clinical populations.           n/a",Experimental and Computational Studies of Concept Learning,7489320,F32MH076452,"['Accounting', 'Amnesia', 'Categories', 'Clinical', 'Cognition', 'Computer Simulation', 'Development', 'Disease', 'Feedback', 'Frequencies', 'Goals', 'Hand', 'Human', 'Individual', 'Intelligence', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Modeling', 'Parkinson&apos', 's Dementia', 'Participant', 'Patients', 'Population', 'Process', 'Public Health', 'Range', 'Research', 'Role', 'Sorting - Cell Movement', 'Structure', 'Testing', 'Thinking', 'base', 'computer studies', 'concept', 'experience', 'insight', 'nervous system disorder', 'research study', 'satisfaction', 'theories']",NIMH,NEW YORK UNIVERSITY,F32,2008,52898,0.009543027393898687
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7457647,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Facility Construction Funding Category', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Numbers', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Score', 'Software Tools', 'Source', 'Structure', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'models and simulation', 'open source', 'outreach', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2008,437938,-0.0077085149231498175
"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",Systems Biology for Studies of Cognition in Down Syndrome,7462512,R01HD056235,"['1 year old', '1-Phosphatidylinositol 3-Kinase', 'Acute', 'Address', 'Amyloid beta-Protein Precursor', 'Antibodies', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological Assay', 'Biological Neural Networks', 'Calcineurin', 'Calcineurin Pathway', 'Calcineurin inhibitor', 'Cell membrane', 'Cerebellum', 'Characteristics', 'Chromosomes, Human, Pair 16', 'Chromosomes, Human, Pair 21', 'Chronic', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Complex', 'Computer Simulation', 'Critical Pathways', 'Data', 'Databases', 'Development', 'Down Syndrome', 'Exposure to', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Guanine Nucleotide Exchange Factors', 'Hippocampus (Brain)', 'Human', 'Incidence', 'Individual', 'Infant', 'Learning', 'Life Expectancy', 'Live Birth', 'MAP Kinase Gene', 'MK801', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical', 'Memantine', 'Memory', 'Memory impairment', 'Methodology', 'Mitogen-Activated Protein Kinases', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Biology', 'Molecular Profiling', 'Mus', 'Mutate', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Neural Network Simulation', 'Nuclear', 'Numbers', 'Outcome', 'Output', 'Pathway interactions', 'Pentylenetetrazole', 'Pharmacological Treatment', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Phosphoinositide-3-Kinase, Catalytic, Gamma Polypeptide', 'Phosphoric Monoester Hydrolases', 'Phosphorylation', 'Population', 'Predictive Value', 'Protein Array', 'Protein Kinase', 'Protein Overexpression', 'Proteins', 'Public Health', 'Publishing', 'Research Personnel', 'Resources', 'Sampling', 'Set protein', 'Signal Pathway', 'Signal Transduction', 'Solutions', 'System', 'Systems Biology', 'Task Performances', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Transgenic Organisms', 'Trisomy', 'United States', 'Upper arm', 'Validation', 'aged', 'base', 'brain tissue', 'conditioned fear', 'design', 'familial Alzheimer disease', 'gene function', 'intersectin 1', 'male', 'mathematical model', 'mouse Ts1Cje', 'mouse Ts65Dn', 'mouse model', 'multidisciplinary', 'network models', 'novel', 'postnatal', 'rac GTP-Binding Proteins', 'receptor', 'response', 'social', 'synaptojanin', 'therapeutic target', 'therapy design', 'time interval']",NICHD,UNIVERSITY OF COLORADO DENVER,R01,2008,499742,0.008654472612793418
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7404447,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Compatible', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Information Systems', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Pliability', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'comparative', 'computer based statistical methods', 'concept', 'data integration', 'design', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface']",NIGMS,PRINCETON UNIVERSITY,R01,2008,243004,-0.001167308278623237
"Integrated Analysis of Genome-Wide Array Data    DESCRIPTION (provided by applicant): This project will develop an integrated desktop application to combine data from expression array, RNA transcript array, proteomics, SNP array (for polymorphism an analysis, as well as LOH and copy number determination), methylation array, histone modification array, promoter array, and microRNA array and metabolomics technologies. Current approaches to analysis of individual `omic' technologies suffer from problems of fragmentation, that present an incomplete view of the workings of the cell. However, effective integration into a single analytic platform is non-trivial. There is a need for a consistent approach, infrastructure, and interface between array types, to maximize ease of use, while recognizing and accommodating the specific computational and statistical requirements, and biological context, of each array. A central challenge is the need to create and work with lists of genomic regions of interest (GROIs) for each sample: we propose three novel approaches to aid in identification of GROIs. These lists must then be integrated with rectangular (sample by feature) data arrays to facilitate statistical analysis. Integration between array types occurs at the computational level, through a unified software package, statistically, through tools that seek statistical relationships between features from different arrays, biologically, through use of annotations (particularly gene ontology, protein- protein and protein-DNA interactions, and pathway membership) that document functional relationships between features, and through genomic interactions that suggest relationships between features that map to the same regions of the genome. The end product will support analysis of each platform separately, with a comprehensive suite of data management, statistical and heuristic analytic tools and the means to place findings of interest into a meaningful biological context through cross-reference to extensive biobases. Beyond that, a range of methods - statistical, biological and genomic - will be available to explore interactions and associations between platforms. PDF created with PDF Factory trial version www.pdffactory.com. PUBLIC HEALTH RELEVANCE: While the large-scale array technologies have provided an unprecedented capability to model cellular processes, both in normal functioning and disease states, this capability is utterly dependent on the availability of complex data management, computational, statistical and informatic software tools.  The utility of the next generation of arrays - which focus on critical regulation and control functions of the cell - will be stymied by an initial lack of suitable bioinformatic tools.  This proposal initiates an accelerated development of an integrated software package intended to empower biologists in the application and analysis of these powerful new technologies, with broadly reaching impact at all levels of biological and clinical research, and across every discipline.          n/a",Integrated Analysis of Genome-Wide Array Data,7538527,R43HG004677,"['Algorithms', 'Alternative Splicing', 'Binding', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Bite', 'Cell physiology', 'Cells', 'Classification', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'DNA copy number', 'DNA-Protein Interaction', 'Data', 'Data Linkages', 'Development', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'GDF15 gene', 'Gene Expression', 'Genes', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Heating', 'Histones', 'Imagery', 'Individual', 'Informatics', 'Internet', 'Joints', 'Link', 'Loss of Heterozygosity', 'Machine Learning', 'Maps', 'Methylation', 'MicroRNAs', 'Modeling', 'Modification', 'Numbers', 'Ontology', 'PLAB Protein', 'Pathway interactions', 'Phase', 'Polymorphism Analysis', 'Process', 'Proteins', 'Proteomics', 'Public Health', 'Purpose', 'RNA', 'Range', 'Regulation', 'Research Infrastructure', 'Resources', 'Sampling', 'Software Tools', 'Sorting - Cell Movement', 'Statistical Methods', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Transcript', 'Work', 'base', 'data management', 'genome-wide analysis', 'heuristics', 'high throughput technology', 'interest', 'metabolomics', 'new technology', 'next generation', 'novel', 'novel strategies', 'prognostic', 'promoter', 'tool', 'tool development']",NHGRI,EPICENTER SOFTWARE,R43,2008,157474,-0.026045745185661356
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7471355,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genome', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Numbers', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Rate', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'day', 'discount', 'drug discovery', 'fluorescence imaging', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,R01,2008,411777,-0.029107779443447324
"Robust computational framework for predictive ADME-Tox modeling    DESCRIPTION (provided by applicant):    This proposal seeks to establish a universally applicable and robust predictive ADME-Tox modeling framework based on rigorous Quantitative Structure Activity/Property Relationships (QSAR/QSPR) modeling. The framework has been refined in the course of many years of our research in the areas of QSPR methodology development and application to experimental datasets that led to novel analytical approaches, descriptors, model validation schemes, overall QSPR workflow design, and multiple end-point studies. This proposal focuses on the design of optimized QSPR protocols for the development of reliable predictors of critically important ADME-Tox properties. The ADME properties will include, but not limited to, water solubility, membrane permeability, P450 metabolism inhibition and induction, metabolic stability, human intestinal absorption, bioavailability, transporters and PK data; a variety of toxicological end-points vital to human health will be explored; they are available from recent initiatives on development and standardization of toxicity data, such as the US FDA, NIEHS, and EPA DSS-Tox and other database projects. The ultimate goal of this project is sharing both modeling software and specialized predictors with the research community via a web-based Predictive ADME-Tox Portal. The project objectives will be achieved via concurrent development of QSPR methodology (Specific Aim 1), building highly predictive, robust QSPR models of known ADME-Tox properties (Specific Aim 2), and the deployment of both modeling software and individual predictors via a specialized web-portal (Specific Aim 3). To achieve the goals of this project focusing on the development and delivery of specialized tools and rigorous predictors, we have assembled a research team of mostly senior investigators with complimentary skills and track records of accomplishment in the areas of computational drug discovery, experimental toxicology, statistical modeling, and software development and integration; two of the team members have had recent industrial experience before transitioning to academia. To the best of our knowledge, the results of this proposal will lead to the first publicly available in silico ADME-Tox modeling framework and predictors that can be used by the research community to analyze any set of chemicals (i.e., virtual and real compound sets). The framework will have a significant impact on compound prioritization, chemical library design, and candidate selection for preclinical and clinical development.            n/a",Robust computational framework for predictive ADME-Tox modeling,7433931,R21GM076059,"['Academia', 'Acute', 'Address', 'Area', 'Biological Availability', 'Cardiotoxicity', 'Cell Membrane Permeability', 'Chemicals', 'Chronic', 'Clinical', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Consensus', 'Cytochrome P450', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Drug Kinetics', 'End Point', 'Ensure', 'Environment', 'Goals', 'Health', 'Hepatotoxicity', 'Human', 'Individual', 'Internet', 'Intestinal Absorption', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Letters', 'Lung', 'Machine Learning', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Organ', 'Pharmacologic Substance', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Scheme', 'Scientist', 'Screening procedure', 'Secure', 'Source', 'Specialist', 'Standardization', 'Standards of Weights and Measures', 'Statistical Models', 'Statistically Significant', 'Structure', 'Students', 'Techniques', 'Technology', 'Testing', 'Toxic effect', 'Toxicology', 'Training', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'carcinogenicity', 'career', 'cluster computing', 'combinatorial', 'computer framework', 'data mining', 'design', 'drug discovery', 'experience', 'genotoxicity', 'innovation', 'knowledge of results', 'member', 'method development', 'neurotoxicity', 'novel', 'open source', 'pre-clinical', 'programs', 'protocol development', 'reproductive', 'skills', 'small molecule libraries', 'software development', 'tool', 'virtual', 'water solubility']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2008,322087,0.003137805965175737
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7440169,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Class', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Numbers', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'Spectrum Analysis', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2008,535031,0.010822388629976675
"Interrogation of systems level mechanisms controlling DNA repair processes    DESCRIPTION (provided by applicant): A comprehensive model of a complete biological system will enable prediction of phenotypic outcomes in face of novel genetic and environmental perturbations. Such predictive power for cellular systems, such as DMA repair, will have tremendous impacts on early detection and diagnosis of genetic disorders and, ultimately in designing preventive and/or curative treatments. However, the full understanding of eukaryotic DMA repair systems presents a daunting challenge due to their enormous complexity, especially given that systems approaches are not yet sufficiently mature to mathematically model such complex processes. At a molecular level, eukaryotic genetic information processing is mirrored in a simplified manner by their evolutionary ancestors, the archaea. In Halobacterium NRC-1 we have a simple yet powerful model system of -2400 genes in which the underlying generalized principles of a systems approach can be delineated. This halophilic archaeon routinely mitigates damage from high salinity, UV radiation and desiccation-rehydration cycles. We will use this model system to address the hypothesis that the decision making process governing cell fate after exposure to DMA damaging events such as UV irradiation is mediated by robust gene regulatory networks that simultaneously process information on spectral characteristics of the impinging radiation, the nature and extent of DMA damage and the potential preparative role of cellular entrainment to diurnal cycles. This hypothesis is motivated by two main observations: a. in systems analysis of UV response, although extraordinarily resistant, not all expected repair genes in this microbe responded to irradiation or damage; b. many of these damage-unresponsive repair genes did, however, respond to day-night entrainment. At a fundamental level this suggested that the resident state of the cell at time of irradiation may influence the type of response elicited. A systems approach is ideally suited to delinate the networks underlying this decision making process. Specifically, we will measure dynamic global changes (degree of damage, mRNA /protein levels, protein-protein and protein-DNA interactions) in wild type and mutant strains (defective in sensors, signal transducers, regulators and repair proteins) subjected to combinatorial changes in incident radiation, type of damage inflicted and resident state of the cell at the time of radiation. Through an integrated analysis of these diverse systems level data we will statistically learn perturbation-induced rewiring of a gene regulatory network that processes environmental perturbations (input) into phenotype (output), i.e. a predictive model for regulatory mechanisms for repair. This basic model will serve as a template for designing systems approaches to model higher complexities of eukaryotic repair processes.           n/a",Interrogation of systems level mechanisms controlling DNA repair processes,7473118,R01GM077398,"['Address', 'Algorithms', 'Animal Model', 'Archaea', 'Architecture', 'Behavior', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Candidate Disease Gene', 'Cell Cycle Progression', 'Cell Size', 'Cell Survival', 'Cell physiology', 'Cells', 'Characteristics', 'Chromosomes, Human, Pair 4', 'Circadian Rhythms', 'Complex', 'Computer information processing', 'Condition', 'Coupled', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'DNA biosynthesis', 'DNA lesion', 'DNA repair protein', 'DNA-Protein Interaction', 'Data', 'Decision Making', 'Desiccation', 'Disease', 'Early Diagnosis', 'Elements', 'Engineering', 'Environment', 'Epitopes', 'Equilibrium', 'Event', 'Exogenous Factors', 'Exposure to', 'Face', 'Gene Proteins', 'Genes', 'Genetic', 'Genetic Information Processing Pathway', 'Genetic Transcription', 'Genome', 'Global Change', 'Halobacterium', 'Heart', 'Hour', 'Human', 'Lead', 'Learning', 'Life', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Messenger RNA', 'Metabolism', 'Microbe', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Nucleotide Excision Repair', 'Numbers', 'Operative Surgical Procedures', 'Organism', 'Outcome', 'Output', 'Oxidative Stress', 'Pathway interactions', 'Phenotype', 'Physiological Processes', 'Physiology', 'Preventive', 'Process', 'Protein Dynamics', 'Proteins', 'Radiation', 'Readiness', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Rehydrations', 'Resistance', 'Resources', 'Role', 'Signal Transduction', 'Skin Cancer', 'Source', 'Specific qualifier value', 'System', 'Systems Analysis', 'Systems Biology', 'Technology', 'Tertiary Protein Structure', 'Time', 'Transcript', 'Transducers', 'Translations', 'UV response', 'Ultraviolet Rays', 'biological research', 'cell type', 'combinatorial', 'coping', 'cryptochrome', 'day', 'design', 'gene repair', 'genetic disorder diagnosis', 'halobacteria', 'interest', 'irradiation', 'knockout gene', 'mathematical model', 'mutant', 'novel', 'predictive modeling', 'repaired', 'response', 'segregation', 'sensor', 'technology development', 'trait', 'ultraviolet damage', 'ultraviolet irradiation']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,R01,2008,335920,-0.024090090124445317
"System-wide Study of Transcriptional Control of Metabolism    DESCRIPTION (provided by applicant): This proposal is in response to the NIH call for Exploratory Collaborations with National Centers for Biomedical Computing, PAR-06-223, and it will involve a collaboration between Columbia University's MAGNet NCBC and a team at Los Alamos National Laboratory. The aim of the proposal is a system-wide tudy of integrated transcriptional and metabolic networks in Eschericia coli K-12 strain, aiming at a similar analysis of a pathogen, Bacillus anthracis, at a later date. LANL hosts an experimental research program on bacterial metabolomics. Metabolites serve several functions. The most common one is being the precursors to various cellular components. They are also regulators of cellular functions by means of modulating metabolic reactions or binding to transcription factors and subsequently regulating gene expression. Conversely, the genes regulated by a transcription factor often encode enzymes, modulating the speed of metabolic reactions. Thus, to understand and ultimately predict the cellular response to an environmental change of interest (e.g., pathogen entry into its host environment), we must integrate the analysis of the transcriptome and metabolome. To address this need, we will work with the laboratories of Pat Unkefer and John Dunbar, which will produce data sets of about 300 joint metabolic/transcriptional profiles of E.coli under different steady-state growth conditions. The resources of MAGnet NCBC, specifically the algorithms within the geWorkbench bioinformatics platform produced by the center, will be leveraged to reconstruct cellular networks. Specifically, we expect that ARACNE, an algorithm originally developed by MAGNet for high-fidelity analysis of transcriptional networks in mammalian cells, is well positioned for reconstruction of metabolic networks from high throughput system-wide metabolic activity data, provide that appropriate modifications to deal with the specifics of the metabolic data are made. We will also adapt the algorithm to discover modulated interactions, that is, metabolic interactions that are conditional on the activity of a modulator gene (enzyme), or transcriptional interactions that require the presence of a metabolite to proceed. Such integrated genome/metabolome analysis has not been attempted yet. It will be a giant leap towards a complete understanding of cellular processes in an important organism. Because of the comparatively small size of bacterial genomes and metabolomes, it will be possible to perform system-wide analyses of interactions for the entire integrated genome and metabolome. While important in its own right, especially in view of the pathogenic nature of B. anthracis, this research would also represent an important test bed for a subsequent study of metabolic diseases in higher animals, including humans.           n/a",System-wide Study of Transcriptional Control of Metabolism,7387471,R21GM080216,"['Accounting', 'Address', 'Affect', 'Affinity', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Architecture', 'Autistic Disorder', 'Automobile Driving', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Bacillus anthracis', 'Bacterial Genome', 'Beds', 'Benchmarking', 'Binding', 'Biochemical', 'Biochemical Pathway', 'Biochemical Reaction', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Cadherins', 'Cell Adhesion Molecules', 'Cell Separation', 'Cell physiology', 'Cell-Cell Adhesion', 'Cells', 'Chemicals', 'Code', 'Collaborations', 'Commit', 'Communities', 'Complex', 'Computational Biology', 'Computational Technique', 'Computational algorithm', 'Computer Analysis', 'Computer Simulation', 'Computer software', 'Computers', 'Concentration measurement', 'Condition', 'Crystallography', 'DNA Binding', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Discipline', 'Disease', 'Dissection', 'Documentation', 'Drug Formulations', 'Drug Interactions', 'Educational workshop', 'Electrical Engineering', 'Engineering', 'Ensure', 'Environment', 'Enzyme Gene', 'Enzymes', 'Escherichia coli', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Health Sciences', 'Human', 'Imagery', 'Immune system', 'In Vitro', 'Informatics', 'Institutes', 'Institution', 'Internet', 'Java', 'Joints', 'Knowledge', 'Laboratories', 'Language', 'Life', 'Literature', 'Machine Learning', 'Mails', 'Malignant Neoplasms', 'Mammalian Cell', 'Manuals', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Metabolic', 'Metabolic Control', 'Metabolic Diseases', 'Metabolism', 'Methodology', 'Methods', 'Mission', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Multimedia', 'Nature', 'Noise', 'Online Systems', 'Ontology', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Personal Satisfaction', 'Phenotype', 'Phosphotransferases', 'Physics', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Prokaryotic Cells', 'Property', 'Protein Analysis', 'Protein Family', 'Proteins', 'Proteome', 'Publishing', 'RNA', 'Range', 'Rate', 'Reaction', 'Research', 'Research Activity', 'Research Personnel', 'Research Proposals', 'Resolution', 'Resources', 'Sampling', 'Semantics', 'Sequence Analysis', 'Services', 'Signal Transduction', 'Site', 'Software Engineering', 'Solutions', 'Source Code', 'Specific qualifier value', 'Specificity', 'Speed', 'Structural Protein', 'Structure', 'Structure of germinal center of lymph node', 'Students', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Transcriptional Regulation', 'United States National Institutes of Health', 'Universities', 'Validation', 'Virulence', 'Visual', 'Work', 'base', 'biocomputing', 'biomedical informatics', 'computer framework', 'computer studies', 'computerized tools', 'concept', 'data acquisition', 'data mining', 'data modeling', 'design', 'environmental change', 'experience', 'forging', 'hazard', 'improved', 'innovation', 'interest', 'interoperability', 'knowledge base', 'member', 'metabolomics', 'microbial', 'multidisciplinary', 'nervous system disorder', 'novel', 'pathogen', 'pathogenic bacteria', 'professor', 'programs', 'protein protein interaction', 'reconstruction', 'research study', 'response', 'simulation', 'size', 'software development', 'text searching', 'tool', 'transcription factor']",NIGMS,LOS ALAMOS NAT SECTY-LOS ALAMOS NAT LAB,R21,2008,220227,-0.01461623717429592
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7483692,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Endopeptidases', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2008,242920,-0.002276321716562226
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7502135,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2008,3570137,0.013756726476284814
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7458835,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2008,503603,-0.010463141183561286
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7688793,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2008,58299,-0.010463141183561286
"WormBase: a core data resource for C elegans and other nematodes    DESCRIPTION (provided by applicant):  Caenorhabditis elegans is a major model system for basic biological and biomedical research and the first animal for which there is a complete description of its genome, anatomy and development, and some information about each of its ~22,000 genes. Five years of funding is requested to maintain and expand WormBase, a Model Organism Database (MOD), with complete coverage of core genomic, genetic, anatomical and functional information about this and other nematodes. Such a database is necessary to allow the entire biomedical research community to make full use of nematode genomic sequences. The two top priorities will be intensive data curation and user interface improvement. WormBase will include up-to-date annotation of the genomic data, the current genetic and physical maps and many experimental data such as genome-scale datasets connected to the function and interactions of cells and genes, as well as development, physiology and behavior. Direct access to the sources of biological material, such as the strain collection of the Caenorhabditis Genetics Center and direct links to data sets maintained by others will be provided. Data will be recovered from the existing resources, from direct contribution of the individual laboratories, and from the literature. While WormBase will act as a central forum through which every laboratory will be able to contribute constructively to the global effort to fully comprehend this metazoan organism, WormBase professional curators will ensure detailed attribution of data sources and check consistency and integrity. To facilitate communication, WormBase will use technology, terminology and style concordant with other databases wherever possible. WormBase will maintain ontologies for nematode anatomy and phenotypes. WormBase will be Web-based and easy to use. Multiple relational databases will be used for data management; the object-based Acedb database system will be used for integration, and this integrated database plus ""slave"" relational databases will be used to drive the website. Coordination of the project and the main curation site will be at Caltech under the supervision of a C. elegans biologist. Curation and annotation of genomic sequence will take place at the centers - the Sanger Institute and Washington University - that generated the entire genome sequence. Oxford University will maintain genetic nomenclature.  Nematodes (roundworms) are major parasites of humans, livestock and crops, and extension of WormBase to broader coverage of nematode genomics will facilitate research into the diagnosis and treatment of nematode-based disease. Studies of C. elegans have informed us of basic principles of normal development and the molecular basis of aging, cancer, nicotine addiction, as well as a variety of fundamental biological processes such as cell migration, cell differentiation and cell death.              n/a",WormBase: a core data resource for C elegans and other nematodes,7502984,P41HG002223,"['Ablation', 'Age', 'Agriculture', 'Alleles', 'Anatomy', 'Animals', 'Antibodies', 'Architecture', 'Base Sequence', 'Behavior', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biomedical Research', 'Caenorhabditis', 'Caenorhabditis elegans', 'Cell Communication', 'Cell Death', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Chromosome Mapping', 'Code', 'Collection', 'Communication', 'Communities', 'Comparative Anatomy', 'Compatible', 'DNA Sequence', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Ensure', 'Expressed Sequence Tags', 'Funding', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Processes', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Institutes', 'Internet', 'Knock-out', 'Knowledge', 'Laboratories', 'Link', 'Literature', 'Livestock', 'Longevity', 'Malignant Neoplasms', 'Maps', 'Medical', 'Metabolic', 'Methods', 'Molecular', 'Molecular Genetics', 'Mutation', 'Names', 'Natural Language Processing', 'Nature', 'Nematoda', 'Nicotine Dependence', 'Nomenclature', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Parasites', 'Parasitic nematode', 'Pathway interactions', 'Phenotype', 'Physical Chromosome Mapping', 'Physiology', 'Pliability', 'Process', 'Proteins', 'Proteomics', 'RNA Interference', 'Reagent', 'Regulation', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Secure', 'Site', 'Slave', 'Source', 'Subcellular Anatomy', 'Supervision', 'System', 'Techniques', 'Technology', 'Terminology', 'Tertiary Protein Structure', 'Transcript', 'Transgenes', 'Transgenic Organisms', 'Universities', 'Variant', 'Washington', 'Yeasts', 'base', 'cell motility', 'chromatin immunoprecipitation', 'comparative', 'comparative genomic hybridization', 'data integration', 'data management', 'data modeling', 'design', 'experience', 'functional genomics', 'gene function', 'genetic analysis', 'genome sequencing', 'improved', 'interoperability', 'member', 'migration', 'model organisms databases', 'programs', 'research study', 'small molecule', 'tool', 'transcription factor', 'usability', 'web interface', 'yeast two hybrid system']",NHGRI,CALIFORNIA INSTITUTE OF TECHNOLOGY,P41,2008,2750000,-0.010315876045715463
"Semantics and Services enabled Problem Solving Environment for Trypanosoma cruzi    DESCRIPTION (provided by applicant): The study of complex biological systems increasingly depends on vast amounts of dynamic information from diverse sources. The scientific analysis of the parasite Trypanosoma cruzi (T.cruzi), the principal causative agent of human Chagas disease, is the driving biological application of this proposal. Approximately 18 million people, predominantly in Latin America, are infected with the T.cruzi parasite. As many as 40 percent of these are predicted eventually to suffer from Chagas disease, which is the leading cause of heart disease and sudden death in middle-aged adults in the region. Research on T. cruzi is therefore an important human disease related effort. It has reached a critical juncture with the quantities of experimental data being generated by labs around the world, due in large part to the publication of the T.cruzi genome in 2005. Although this research has the potential to improve human health significantly, the data being generated exist in independent heterogeneous databases with poor integration and accessibility. The scientific objectives of this research proposal are to develop and deploy a novel ontology-driven semantic problem-solving environment (PSE) for T.cruzi. This is in collaboration with the National Center for Biomedical Ontologies (NCBO) and will leverage its resources to achieve the objectives of this proposal as well as effectively to disseminate results to the broader life science community, including researchers in human pathogens. The PSE allows the dynamic integration of local and public data to answer biological questions at multiple levels of granularity. The PSE will utilize state-of- the-art semantic technologies for effective querying of multiple databases and, just as important, feature an intuitive and comprehensive set of interfaces for usability and easy adoption by biologists. Included in the multimodal datasets will be the genomic data and the associated bioinformatics predictions, functional information from metabolic pathways, experimental data from mass spectrometry and microarray experiments, and textual information from Pubmed. Researchers will be able to use and contribute to a rigorously curated T.cruzi knowledge base that will make it reusable and extensible. The resources developed as part of this proposal will be also useful to researchers in T.cruzi related kinetoplastids, Trypanosoma brucei and Leishmania major (among other pathogenic organisms), which use similar research protocols and face similar informatics challenges. PUBLIC HEALTH RELEVANCE: The scientific objective of this proposal is to develop and deploy a novel ontology-driven semantic problem-solving environment (PSE) for Trypanosoma cruzi, a parasite that infects approximately 18 million people, predominantly in Latin America. As many as 40 percent of those infected are predicted to eventually suffer from Chagas disease, the leading cause of heart disease and sudden death in middle-aged adults in the region. Facilitating T.cruzi research through the PSE, with the aim of identifying vaccine, diagnostic, and therapeutic targets, is an important human disease related endeavor.          n/a",Semantics and Services enabled Problem Solving Environment for Trypanosoma cruzi,7428761,R01HL087795,"['Acquired Immunodeficiency Syndrome', 'Address', 'Adherence', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Anatomy', 'Animal Model', 'Anti-Retroviral Agents', 'Architecture', 'Archives', 'Area', 'Arts', 'Automobile Driving', 'Beds', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biomedical Computing', 'Biomedical Research', 'Body of uterus', 'Buffaloes', 'California', 'Caring', 'Chagas Disease', 'Childhood', 'Chronic', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Computers', 'Controlled Vocabulary', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Doctor of Public Health', 'Drops', 'Drosophila genus', 'Educational Activities', 'Educational workshop', 'Electronics', 'Enrollment', 'Ensure', 'Environment', 'Evaluation', 'Evolution', 'Face', 'Feedback', 'Foundations', 'Future', 'Gene Mutation', 'Generations', 'Generic Drugs', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Geographic Locations', 'Goals', 'HIV', 'HIV Infections', 'Health', 'Heart Diseases', 'Homologous Gene', 'Human', 'Human Resources', 'Imagery', 'Immunologic Deficiency Syndromes', 'Immunology', 'Individual', 'Infection', 'Informatics', 'Information Management', 'Information Resources', 'Information Services', 'Information Technology', 'International', 'Internet', 'Interruption', 'Knowledge', 'Laboratories', 'Laboratory Organism', 'Language', 'Latin America', 'Lead', 'Learning', 'Leishmania major', 'Libraries', 'Link', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Medical Informatics', 'Medicine', 'Metabolic Pathway', 'Metadata', 'Methodology', 'Methods', 'Mind', 'Mining', 'Modeling', 'Mutation', 'Natural Language Processing', 'Nature', 'Online Mendelian Inheritance In Man', 'Online Systems', 'Ontology', 'Operative Surgical Procedures', 'Oregon', 'Organism', 'Orthologous Gene', 'Outcome', 'Parasites', 'Pathogenesis', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Philosophy', 'Physiology', 'Prevention strategy', 'Principal Investigator', 'Problem Solving', 'Process', 'Proteomics', 'Protocols documentation', 'PubMed', 'Public Health', 'Publications', 'Publishing', 'Purpose', 'Randomized Clinical Trials', 'Range', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'San Francisco', 'Science', 'Scientist', 'Semantics', 'Services', 'Site', 'Software Tools', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Structure', 'Study models', 'Sudden Death', 'Sum', 'System', 'TAF8 gene', 'Talents', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Thinking', 'Training', 'Treatment Protocols', 'Trypanosoma brucei brucei', 'Trypanosoma cruzi', 'USA Georgia', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Update', 'Vaccines', 'Vertical Disease Transmission', 'Victoria Austrailia', 'Virtual Library', 'Virus', 'Western Asia Georgia', 'Work', 'Zebrafish', 'abstracting', 'base', 'biocomputing', 'biomedical scientist', 'college', 'computer based Semantic Analysis', 'computer science', 'concept', 'data integration', 'design', 'desire', 'fundamental research', 'human disease', 'improved', 'indexing', 'innovative technologies', 'knowledge base', 'member', 'metabolomics', 'middle age', 'novel', 'novel strategies', 'open source', 'outreach', 'pandemic disease', 'pathogen', 'prevent', 'programs', 'protein protein interaction', 'repository', 'research and development', 'research study', 'syntax', 'theories', 'therapeutic target', 'tool', 'usability']",NHLBI,WRIGHT STATE UNIVERSITY,R01,2008,393930,-0.001265819815431592
"Computational Annotation of Orphan Metabolic Activities    DESCRIPTION (provided by applicant):  Even state-of-the-art homology methods cannot annotate metabolic genes with no or remote sequence identity to known enzymes. This presents a significant obstacle to network reconstruction, as about 30%- 40% (>1500) of known metabolic activities remain orphan, i.e. there are no known proteins catalyzing these activities in any organism. The scale of the orphan activities problem makes it arguably the single biggest challenge of modern biochemistry. We propose to develop, experimentally validate, and make available to the scientific community an efficient computational approach to fill the remaining gaps in metabolic networks. The main idea of the proposed method is to use genes assigned to the network neighbors of the remaining gaps as constraints in assigning genes for orphan activities. We demonstrate that this approach significantly outperforms simpler or existing methods. Our cross-validated results in model organisms demonstrate that the proposed method can predict the correct genes in more than 50% of the cases, without any sequence homology information. The calculations indicate that the prediction accuracy will also remain high in less studied organisms. Using the developed method we have already identified and validated a gene responsible for an E. coli metabolic activity which remained orphan for more than 25 years. There are four specific aims of the proposal: 1.) We will calculate the appropriate context-based descriptors of protein function for the majority of sequenced organisms. Many new functional descriptors will be developed and used for the predictions. 2.) We will investigate the ability of various machine learning approaches and fitness functions to integrate context-based descriptors. Based on the developed methodology we will make predictions for all orphan activities in sequenced organisms. 3.) The predictions will be available through a searchable and constantly updated Web server. We will also develop a method to detect functional misannotations and apply it to all public metabolic databases. 4.) In collaboration with the laboratories of Dr. Uwe Sauer (ETH Zurich) and Dr. George Church (Harvard) we will experimentally test at least 50 of the predicted genes without close sequence homologs in E. coli, B. subtilis, S. cerevisiae.           n/a",Computational Annotation of Orphan Metabolic Activities,7322388,R01GM079759,"['Animal Model', 'Arts', 'Base Sequence', 'Biochemical', 'Biochemical Genetics', 'Biochemical Pathway', 'Biochemistry', 'Biological Neural Networks', 'Church', 'Collaborations', 'Communities', 'Databases', 'Decision Trees', 'Descriptor', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Fusion', 'Genes', 'Genetic', 'Internet', 'Laboratories', 'Link', 'Machine Learning', 'Metabolic', 'Methodology', 'Methods', 'Numbers', 'Operon', 'Organism', 'Orphan', 'Pathway interactions', 'Performance', 'Positioning Attribute', 'Proteins', 'Range', 'Research Personnel', 'Saccharomyces cerevisiae', 'Sequence Homologs', 'Sequence Homology', 'Specific qualifier value', 'Structure', 'Testing', 'Update', 'Validation', 'base', 'computer based statistical methods', 'fitness', 'gene correction', 'gene function', 'genome sequencing', 'metabolomics', 'protein function', 'reconstruction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,364130,-0.014550063035094131
"Pathway Prediction and Assessment Integrating Multiple Evidence Types    DESCRIPTION (provided by applicant):    Metabolic pathway databases provide a biological framework in which relationships among an organism's genes may be revealed. This context can be exploited to boost the accuracy of genome annotation, to discover new targets for therapeutics, or to engineer metabolic pathways in bacteria to produce a historically expensive drug cheaply and quickly. But, knowledge of metabolism in ill-characterized species is limited and dependent on computational predictions of pathways. Our ultimate target is to develop methods for the prediction of novel metabolic pathways in any organism, coupled with robust assessment of the validity of any predicted pathway. We hypothesize that integrating evidence from multiple levels of an organism's metabolic network - from the fit of a pathway within the network to evolutionary relationships between pathways - will allow us to assess pathway validity and to predict novel metabolic pathways. We have successfully applied machine learning methods to the problem of identifying missing enzymes in metabolic pathways and believe similar methods will prove fruitful in this application. Our preliminary studies have identified several properties of predicted metabolic pathways that differ between sets of true positive pathway predictions (i.e., pathways known to occur in an organism) and sets of false positive pathway predictions. We will expand on these features and develop methods to address the following specific aims:      1) Identify features that are informative in distinguishing between correct and incorrect pathway predictions in computationally-generated pathway/genome databases based on predictions for highly-curated organisms (e.g., Escherichia coli and Arabidopsis thaliana).   2) Develop methods for computing the probability that a pathway is correctly predicted. Informative features identified in Specific Aim #1 will be integrated into a classifier that will compute the probability that a predicted pathway is correct given the associated evidence.   3) Extend the Pathologic program (the Pathway Tools algorithm used to infer the metabolic network of an organism) to predict alternate, previously unknown pathways in an organism. We will search the MetaCyc reaction space (comprising almost 6000 reactions) for novel subpathways, explicitly constraining our search using organism-specific evidence (i.e., homology, experimental evidence, etc.) at each step.          n/a",Pathway Prediction and Assessment Integrating Multiple Evidence Types,7301424,R01LM009651,"['Address', 'Algorithms', 'Antimalarials', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Coupled', 'Data', 'Data Set', 'Databases', 'Development', 'Engineering', 'Enzymes', 'Escherichia', 'Escherichia coli', 'Future', 'Gene Expression', 'Genes', 'Genome', 'Gold', 'Government', 'Knowledge', 'Laboratory Research', 'Left', 'Machine Learning', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Molecular Profiling', 'Mouse-ear Cress', 'Organism', 'Pathologic', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Probability', 'Prodrugs', 'Property', 'Proteins', 'Reaction', 'Relative (related person)', 'Research', 'Research Institute', 'Research Personnel', 'Scientist', 'Score', 'Series', 'Software Tools', 'Standards of Weights and Measures', 'Techniques', 'Training', 'Validation', 'Yeasts', 'base', 'design', 'genome database', 'metabolomics', 'novel', 'programs', 'reconstruction', 'therapeutic target', 'tool']",NLM,SRI INTERNATIONAL,R01,2007,173307,0.016028784102610667
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,7239477,R01GM074128,"['Address', 'Age', 'Algorithms', 'Amino Acids', 'Area', 'Automation', 'Binding', 'Biological', 'Biological Assay', 'Biological Process', 'Carbon', 'Cartoons', 'Cells', 'Chemicals', 'Class', 'Communities', 'Computer software', 'Data', 'Development', 'Disclosure', 'Disease', 'Expert Systems', 'Facility Construction Funding Category', 'Genomics', 'Glycoproteins', 'Goals', 'Graft Rejection', 'Human Genome', 'Isomerism', 'Knowledge', 'Learning', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Manuals', 'Mass Spectrum Analysis', 'Methods', 'Modification', 'Monosaccharides', 'Nature', 'Numbers', 'Occupations', 'Organism', 'Pathway interactions', 'Pattern', 'Peptides', 'Play', 'Polymers', 'Polysaccharides', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Range', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Score', 'Signal Transduction', 'Site', 'Specialist', 'Specific qualifier value', 'Spectrum Analysis', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Title', 'Training', 'Work', 'cancer cell', 'egg', 'enzyme activity', 'experience', 'glycosylation', 'glycosyltransferase', 'high throughput analysis', 'immune function', 'improved', 'novel', 'programs', 'prototype', 'sperm cell', 'sugar', 'tool']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2007,318904,-0.030082915348947005
"Cytokine Signaling Network Response to Smallpox Vaccine    DESCRIPTION (provided by applicant):  The identification of the molecular and cellular basis for adverse events observed in patients immunized against smallpox is of great public health interest. This is especially true today given efforts to defend the U.S. population and military against potential bioterrorism agents. We have shown recently that adverse vents following smallpox vaccination correlate with systemic cytokine patterns, suggesting a role for cytokines in the pathogenesis of adverse events. A challenge to further delineating the immunological mechanisms of adverse events is that cytokines rarely act in isolation to induce an immune response, but rather they work in a complex network to which immune system cells respond. Cytokines are small signaling proteins that integrate the activities of immune system cells. While it is often well understood how they act individually, the behavior of cytokines as part of a signaling network is less well known and likely depends on the nature of the infecting organism. We propose to develop and evaluate a comprehensive strategy to identify detailed kinetic cytokine network models associated with adverse events following smallpox vaccination. This strategy will be developed and evaluated using proteomic time-series data available from 103 volunteers that are part of an ongoing NIAID/NIH-sponsored trial to evaluate the Aventis Pasteur Smallpox Vaccine (APSV). We will develop software tools using machine learning algorithms to automatically discover cytokine signaling network models from observed time-series cytokine expression levels. Once the underlying cytokine network model has been estimated, our goal is to use the dynamic model as a simulation tool to suggest ways to create vaccines that minimize the risk of adverse events associated with vaccination. The software tools developed in this proposal will be generally applicable for biomedical research to understand the biochemical interactions in time-series data, and, thus, a useful and novel software package will be made available to the vaccine research community. The experience and knowledge gained during the collaboration on this important research problem in immunology coupled with the didactic and mentoring portions of the training program will create a firm foundation upon which I can develop and test significant hypotheses for future studies on the immunology of infectious diseases.             n/a",Cytokine Signaling Network Response to Smallpox Vaccine,7208003,K25AI064625,"['Address', 'Adverse event', 'Algorithms', 'Behavior', 'Biochemical', 'Biomedical Research', 'Bioterrorism', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Coupled', 'Coupling', 'Cytokine Network Pathway', 'Cytokine Signaling', 'Data', 'Engineering', 'Equation', 'Event', 'Feedback', 'Foundations', 'Future', 'Goals', 'Immune response', 'Immune system', 'Immunization', 'Immunologics', 'Immunology', 'Individual', 'Infectious Disease Immunology', 'Kinetics', 'Knowledge', 'Machine Learning', 'Mentors', 'Methods', 'Military Personnel', 'Modeling', 'Molecular', 'Nature', 'Organism', 'Pathogenesis', 'Patients', 'Pattern', 'Population', 'Proteins', 'Proteomics', 'Public Health', 'Research', 'Research Personnel', 'Risk', 'Role', 'Series', 'Serum', 'Signal Transduction', 'Signaling Protein', 'Simulate', 'Smallpox', 'Smallpox Vaccine', 'Software Tools', 'Systems Biology', 'Testing', 'Time', 'Today', 'Training Programs', 'Vaccination', 'Vaccine Research', 'Vaccines', 'Vent', 'Work', 'base', 'chemical reaction', 'cytokine', 'design', 'experience', 'interest', 'network models', 'novel', 'programs', 'protein expression', 'research study', 'response', 'simulation', 'software development', 'tool', 'volunteer']",NIAID,UNIVERSITY OF ALABAMA AT BIRMINGHAM,K25,2007,103762,-0.01195330514054726
"Experimental and Computational Studies of Concept Learning    DESCRIPTION (provided by applicant): This research is aimed at developing better understanding of how people bring their prior knowledge to the table when learning about new concepts. Both experimental studies and computational models of these processes will be used to further understanding of this fundamental aspect of human cognition. The proposal focuses on effects and interactions that show that memorized exemplars of a problem are involved with concept learning, on processes involved in unsupervised sorting without feedback, and on how these two processes interact with pre-existing concepts and relational knowledge. New computational models will incorporate exemplars and unsupervised learning into an existing model of knowledge and supervised learning, accounting for a variety of previously observed and newly predicted effects. Experiments involving human participants will investigate interactions of prior knowledge with frequency, exposure, and concept structure. Experiments are paired with the modeling so that new empirical discoveries will go hand-in-hand with theoretical development. If successful, this model will be the only one in the field that accounts for this range of phenomena, encompassing both statistical learning and use of prior knowledge in concept acquisition. Relevance to Public Health: Categorization and category learning are fundamental aspects of cognition, allowing people to intelligently respond to the world. As categorization can be impaired by neurological disorders such as Parkinson's disease, dementia, and amnesia, a rigorous understanding of the processes involved in normal populations aides the research and treatment of disorders in patients. This project will provide a detailed computational model of concept learning, which can then serve as a model to investigate what has gone wrong when the process is disrupted in clinical populations.           n/a",Experimental and Computational Studies of Concept Learning,7275769,F32MH076452,"['Accounting', 'Amnesia', 'Categories', 'Clinical', 'Cognition', 'Computer Simulation', 'Development', 'Disease', 'Feedback', 'Frequencies', 'Goals', 'Hand', 'Human', 'Individual', 'Intelligence', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Modeling', 'Parkinson&apos', 's Dementia', 'Participant', 'Patients', 'Population', 'Process', 'Public Health', 'Range', 'Research', 'Role', 'Sorting - Cell Movement', 'Structure', 'Testing', 'Thinking', 'base', 'computer studies', 'concept', 'experience', 'insight', 'nervous system disorder', 'research study', 'satisfaction', 'theories']",NIMH,NEW YORK UNIVERSITY,F32,2007,51278,0.009543027393898687
"Comparative Visualization and Analysis for GCxGC    DESCRIPTION (provided by applicant): Project Summary. This project will investigate and develop effective information technologies for comparative analysis and visualization of complex data generated by comprehensive two-dimensional gas chromatography (GCxGC). GCxGC is an emerging technology that provides an order-of-magnitude greater separation capacity, significantly better signal-to-noise ratio, and higher dimensional retention-structure relations than traditional GC. The principal challenge for utilization of GCxGC, in a wide range of public-health and other applications, is the difficulty of analyzing and interpreting the large, complex data it generates. The quantity and complexity of GCxGC data necessitates the investigation and development of new information technologies. This project will develop and demonstrate innovative methods and tools for comparative analysis of GCxGC datasets. The expected results of this research and development include a PCA-based method for chemical fingerprinting, decision trees with chemical constraints for sample classification, genetic programming for template and constraint-based matching and classification, and visualization methods for comparative GCxGC analyses. These methods will be implemented in commercial software that will support researchers and laboratory analysts in a wide range of commercial applications, including health care, environmental monitoring, and chemical processing. The power of GCxGC, supported by effective information technologies, will enable better understanding of chemical compositions and processes, a foundation for future scientific advances and discoveries. Relevance to Public Health. Today, a few advanced laboratories are pioneering GCxGC for a variety of applications such as environmental monitoring of exposure profiles in air, soil, food, and water; identification and quantification of toxic products in blood, urine, milk, and breath samples; and qualitative and quantitative metabolomics to provide a holistic view of the biochemical status or biochemical phenotype of an organism. Many analyses in these applications require detailed chemical comparisons of samples, e.g..monitoring changes, comparison to reference standards, chemical matching or ""fingerprinting"", and classification. GCxGC is a powerful new technology for such comparative analyses. This proposal will provide innovative information technologies to support users in these applications.           n/a",Comparative Visualization and Analysis for GCxGC,7270029,R44RR020256,"['Air', 'Archives', 'Biochemical', 'Blood', 'Chemicals', 'Classification', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Trees', 'Development', 'Emerging Technologies', 'Environmental Monitoring', 'Fingerprint', 'Food', 'Foundations', 'Future', 'Gas Chromatography', 'Genetic Programming', 'Goals', 'Healthcare', 'Image', 'Imagery', 'Information Technology', 'Investigation', 'Laboratories', 'Language', 'Machine Learning', 'Marketing', 'Methods', 'Milk', 'Monitor', 'Noise', 'Organism', 'Pattern', 'Phase', 'Phenotype', 'Principal Component Analysis', 'Process', 'Public Health', 'Range', 'Reference Standards', 'Reporting', 'Research Personnel', 'Sales', 'Sampling', 'Schedule', 'Scientific Advances and Accomplishments', 'Signal Transduction', 'Software Tools', 'Soil', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Today', 'Trademark', 'Urine', 'Water', 'base', 'chemical fingerprinting', 'commercial application', 'comparative', 'innovation', 'innovative technologies', 'instrument', 'metabolomics', 'new technology', 'research and development', 'tool', 'two-dimensional']",NCRR,"GC IMAGE, LLC",R44,2007,239373,0.004098345977014809
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7287965,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Facility Construction Funding Category', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Numbers', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Score', 'Software Tools', 'Source', 'Structure', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'models and simulation', 'open source', 'outreach', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2007,446875,-0.0077085149231498175
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7214148,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Compatible', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Information Systems', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Pliability', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'comparative', 'computer based statistical methods', 'concept', 'data integration', 'design', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface']",NIGMS,PRINCETON UNIVERSITY,R01,2007,240927,-0.001167308278623237
"Systems analysis of oxygen regulation in Halobacterium    DESCRIPTION (provided by applicant): To withstand environmental onslaught, biological systems mount global programs to coordinate the induction of protection and repair mechanisms. This proposal poses the hypothesis that the transcriptional networks underlying such responses to diverse stressors are interrelated. Halobacterium, a halophilic archaeon, has been chosen as a model for this study because it routinely negotiates an array of adverse conditions in its extreme environment, including anoxia, metal stress, and radiation damage. This proposal will investigate the inter-relationship of these responses using global approaches. Given that basal genetic information processing pathways in Halobacterium are mediated by eukaryotic-like proteins, findings from this study will have a direct impact on understanding how complex eukaryotic organisms elicit orthogonal responses in disease-perturbed or infection states. Specifically, I will (1) Characterize key transcriptional regulators responsible for mediating responses to fluctuating oxygen concentrations and identify regulons under their direct and indirect control; (2) Through statistical analysis of integrated datasets, evaluate the extent of cross-regulation of the anoxic response with other environmental perturbations; (3) Experimentally test new hypotheses generated by statistical analysis. These proposed experiments are expected to result in a transcriptional network model that addresses how organisms maintain homeostasis despite stress.           n/a",Systems analysis of oxygen regulation in Halobacterium,7261251,F32GM078980,"['Address', 'Aerobic', 'Algorithms', 'Anoxia', 'Archaea', 'Behavioral', 'Binding Sites', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Phenomena', 'Cells', 'Collection', 'Complex', 'Computer software', 'Condition', 'Couples', 'Data', 'Data Set', 'Defect', 'Disease', 'Electrophoretic Mobility Shift Assay', 'Environment', 'Equilibrium', 'Experimental Designs', 'Face', 'Facility Construction Funding Category', 'Fellowship', 'Gene Targeting', 'Genes', 'Genetic Information Processing Pathway', 'Genome', 'Goals', 'Growth', 'Halobacterium', 'Homeostasis', 'Hydrogen Peroxide', 'Individual', 'Infection', 'Information Systems', 'Knock-out', 'Laboratories', 'Learning', 'Light', 'Localized', 'Machine Learning', 'Manuscripts', 'Maps', 'Mediating', 'Mediation', 'Metals', 'Modeling', 'Molecular Biology', 'Mutate', 'Names', 'Organism', 'Oxidation-Reduction', 'Oxidative Stress', 'Oxygen', 'Oxygen measurement, partial pressure, arterial', 'Play', 'Preparation', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Radiation', 'Regulation', 'Regulator Genes', 'Regulon', 'Relative (related person)', 'Role', 'Stress', 'Study models', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Testing', 'Time', 'TimeLine', 'Training', 'Transcription Initiation Site', 'Transcriptional Regulation', 'Work', 'biological adaptation to stress', 'cell injury', 'chromatin immunoprecipitation', 'halobacteria', 'high throughput screening', 'in vivo', 'insight', 'metal poisoning', 'mutant', 'network models', 'novel', 'programs', 'repaired', 'research study', 'response', 'stressor', 'transcription factor']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,F32,2007,48796,-0.0017583929957973874
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7264516,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genome', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Numbers', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Rate', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'day', 'discount', 'drug discovery', 'fluorescence imaging', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2007,387827,-0.029107779443447324
"Robust computational framework for predictive ADME-Tox modeling    DESCRIPTION (provided by applicant):    This proposal seeks to establish a universally applicable and robust predictive ADME-Tox modeling framework based on rigorous Quantitative Structure Activity/Property Relationships (QSAR/QSPR) modeling. The framework has been refined in the course of many years of our research in the areas of QSPR methodology development and application to experimental datasets that led to novel analytical approaches, descriptors, model validation schemes, overall QSPR workflow design, and multiple end-point studies. This proposal focuses on the design of optimized QSPR protocols for the development of reliable predictors of critically important ADME-Tox properties. The ADME properties will include, but not limited to, water solubility, membrane permeability, P450 metabolism inhibition and induction, metabolic stability, human intestinal absorption, bioavailability, transporters and PK data; a variety of toxicological end-points vital to human health will be explored; they are available from recent initiatives on development and standardization of toxicity data, such as the US FDA, NIEHS, and EPA DSS-Tox and other database projects. The ultimate goal of this project is sharing both modeling software and specialized predictors with the research community via a web-based Predictive ADME-Tox Portal. The project objectives will be achieved via concurrent development of QSPR methodology (Specific Aim 1), building highly predictive, robust QSPR models of known ADME-Tox properties (Specific Aim 2), and the deployment of both modeling software and individual predictors via a specialized web-portal (Specific Aim 3). To achieve the goals of this project focusing on the development and delivery of specialized tools and rigorous predictors, we have assembled a research team of mostly senior investigators with complimentary skills and track records of accomplishment in the areas of computational drug discovery, experimental toxicology, statistical modeling, and software development and integration; two of the team members have had recent industrial experience before transitioning to academia. To the best of our knowledge, the results of this proposal will lead to the first publicly available in silico ADME-Tox modeling framework and predictors that can be used by the research community to analyze any set of chemicals (i.e., virtual and real compound sets). The framework will have a significant impact on compound prioritization, chemical library design, and candidate selection for preclinical and clinical development.            n/a",Robust computational framework for predictive ADME-Tox modeling,7244058,R21GM076059,"['Academia', 'Acute', 'Address', 'Area', 'Biological Availability', 'Cardiotoxicity', 'Cell Membrane Permeability', 'Chemicals', 'Chronic', 'Clinical', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Consensus', 'Cytochrome P450', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Drug Kinetics', 'End Point', 'Ensure', 'Environment', 'Goals', 'Health', 'Hepatotoxicity', 'Human', 'Individual', 'Internet', 'Intestinal Absorption', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Letters', 'Lung', 'Machine Learning', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Online Systems', 'Organ', 'Pharmacologic Substance', 'Postdoctoral Fellow', 'Property', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Scheme', 'Scientist', 'Screening procedure', 'Secure', 'Source', 'Specialist', 'Standardization', 'Standards of Weights and Measures', 'Statistical Models', 'Statistically Significant', 'Structure', 'Students', 'Techniques', 'Technology', 'Testing', 'Toxic effect', 'Toxicology', 'Training', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'carcinogenicity', 'career', 'cluster computing', 'combinatorial', 'computer framework', 'data mining', 'design', 'drug discovery', 'experience', 'genotoxicity', 'innovation', 'knowledge of results', 'member', 'method development', 'neurotoxicity', 'novel', 'open source', 'pre-clinical', 'programs', 'protocol development', 'reproductive', 'skills', 'small molecule libraries', 'software development', 'tool', 'virtual', 'water solubility']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2007,328325,0.003137805965175737
"Bayesian Methods and Experimental Design for Molecular Biology Experiments    DESCRIPTION (provided by applicant): The goal of this proposal is to provide a suite of software tools for bioinformatics and systems biology researchers who are using molecular biology (Omics) data to identify the best experimental design and to analyze the resulting experimental data using Bayesian tools. A common problem for most bioinformatics experiments is low power due to low replication. This problem can be alleviated economically when an increase in adoption and use of a specific platform leads to a decrease in associated costs, thereby enabling an increase in samples allocated per treatment. Yet, many bioinformatics experiments remain underpowered as researchers use the offsets of decreased costs to explore more complex questions. When designing an experiment, the allocation of samples to treatment regimens, and the choice of treatments to test, are traditionally the only variables to manipulate. Bayesian experimental design provides a framework to find the optimal design out of n possible designs subject to a utility function that can include such items as time and material costs.      Bayesian statistical methods have been gaining substantial favor in bioinformatics and systems biology as they provide a highly flexible framework for fitting and exploring complex models. Bayesian models also provides to domain experts such as biologists and physicians easily interpretable models through posterior probabilities which are more naturally understood than the traditional p-value. While a number of open source tools based on Bayesian models are available, most are applied best in the context of a specific research data analysis problem or model and are not integrated into a single, complete system for data analysis.      We propose to research and develop a statistical analysis software package S+OBAYES (for S-PLUS and R) with generalized tools for Bayesian design of experiments, empirical and fully Bayesian analysis, and modeling and simulation using modern commercial software development practices. These tools will provide functionality for finding the optimal choice and layout of experimental treatments for molecular biology experiments and for fitting Bayesian linear and non-linear models to a variety of data types including time series. We propose to validate the software in molecular biology research problems such as the detection of differential gene, protein, and metabolite abundance. The benefits of this work will be a commercial-quality software package with validated statistical methodology and interactive visualization tools that will appeal to molecular biologists and systems biology investigators. The results of the proposed work will expedite discoveries in basic science, early disease detection, and drug discovery and development.          n/a",Bayesian Methods and Experimental Design for Molecular Biology Experiments,7325828,R43GM083023,"['Address', 'Adoption', 'Algorithms', 'Animal Genetics', 'Arizona', 'Basic Science', 'Bayesian Analysis', 'Bayesian Method', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biological Sciences', 'Biometry', 'Biotechnology', 'Cations', 'Chromosome Mapping', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Department of Defense', 'Depth', 'Detection', 'Development', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Employment', 'Ensure', 'Experimental Designs', 'Exposure to', 'Factor Analysis', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Government', 'Government Agencies', 'Health', 'Imagery', 'Industry', 'Information Systems', 'Institution', 'Iowa', 'Libraries', 'Linear Models', 'Machine Learning', 'Manuals', 'Manuscripts', 'Maps', 'Marketing', 'Mass Spectrum Analysis', 'Measures', 'Medical Informatics', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Molecular', 'Molecular Biology', 'Non-linear Models', 'Numbers', 'Pathway interactions', 'Phase', 'Physicians', 'Population Study', 'Principal Investigator', 'Probability', 'Property', 'Proteome', 'Proteomics', 'Proxy', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Rice', 'Risk Factors', 'SNP genotyping', 'Sampling', 'Science', 'Scientist', 'Series', 'Services', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Tools', 'Software Validation', 'Solutions', 'Speed', 'Standards of Weights and Measures', 'Statistical Methods', 'Statistical Models', 'Systems Biology', 'Techniques', 'Telecommunications', 'Testing', 'Time', 'Time Series Analysis', 'Training', 'Treatment Protocols', 'Universities', 'Validation', 'Washington', 'Wisconsin', 'Work', 'animal breeding', 'base', 'cost', 'design', 'drug discovery', 'experience', 'human subject', 'improved', 'interest', 'lecturer', 'models and simulation', 'open source', 'professor', 'programs', 'protein metabolite', 'research and development', 'research study', 'skills', 'software development', 'statistics', 'success', 'theories', 'tool', 'treatment effect']",NIGMS,INSIGHTFUL CORPORATION,R43,2007,103995,0.009396819899586628
"Metabolomic Assessment of Estrogenic Endocrine Disruptor    DESCRIPTION (provided by applicant)     Estrogenic endocrine disruptors (EEDs) are a group of structurally diverse compounds that include pharmaceuticals, dietary supplements, industrial chemicals and environmental contaminants.  They can elicit a number of adverse health effects such as hormone dependent cancers, reproductive tract abnormalities, compromised reproductive fitness, and impaired cognitive abilities.  In order to fully assess the potential adverse effects of synthetic and natural EEDs, a more comprehensive understanding of their molecular, metabolic, and tissue level effects is required within the context of a whole organism.  This collaborative proposal will elucidate the pathways, networks and signaling cascades perturbed by EEDs using the complementary multidisciplinary expertise of its team members in the areas of toxicology, molecular biology, endocrinology, multinuclear NMR spectroscopy, data management and advanced data analysis.  The comparative effects of ethynyl estradiol (EE), genistein (GEN), and o, p'-dichlorodiphenyltrichloroethane (DDT) on metabolite levels will be assessed in urine, serum and liver extracts by multinuclear (i. e., 1H, 13C, 31P) NMR spectroscopy, and complemented with histopathology examination and gene expression data from ongoing microarray studies in both mouse and rat models.  All data will be stored and archived in dbZach, a MIAME-compliant toxicogenomic supportive database that facilitates data analysis, the integration of disparate data sets, the exchange of data between investigators, and the deposition of data into public repositories.  Advanced statistical approaches, modeling and data integration tools such as neural networks, data fusion, and Baysean inference will be used to fuse these disparate data sets in order to elucidate the conserved biological networks that are of importance in response to endogenous estrogens.  Moreover, EED perturbed pathways associated with elicited effects will be further defined.  Results from these studies will not only further define the physiologic and toxic mechanisms of action of estrogenic compounds but will also demonstrate the synergy of fusing complementary microarray, metabolomic and histopathology data into a comprehensive integrative computational model.  This approach will also demonstrate the ability to maximize knowledge extraction from all disparate data available within the proposed innovative data management system when used with the advanced information tools that will be developed.            n/a",Metabolomic Assessment of Estrogenic Endocrine Disruptor,7240459,R01ES013927,"['Adverse effects', 'Affect', 'Apical', 'Archives', 'Area', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Cell Proliferation', 'Chemicals', 'Class', 'Classification', 'Clinical Chemistry', 'Cognitive', 'Complement', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Deposition', 'Development', 'Disease Progression', 'Dose', 'Endocrine Disruptors', 'Endocrinology', 'Engineering', 'Environmental Pollution', 'Estradiol', 'Estrogens', 'Funding', 'Future', 'Gene Expression', 'Genistein', 'Health', 'Hepatic', 'Histopathology', 'Hormones', 'Knowledge Extraction', 'Lead', 'Link', 'Lipids', 'Liver Extract', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Metabolic', 'Metabolism', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Multinuclear NMR', 'Mus', 'NMR Spectroscopy', 'Numbers', 'Organ Weight', 'Outcome', 'Pathway interactions', 'Pattern Recognition', 'Pharmacologic Substance', 'Physiological', 'Principal Investigator', 'Process', 'Rattus', 'Reporting', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Assessment', 'Rodent', 'Sampling', 'Screening procedure', 'Serum', 'Signal Transduction', 'Spectrum Analysis', 'System', 'Techniques', 'Time', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Urine', 'Whole Organism', 'aqueous', 'comparative', 'data integration', 'data management', 'dichlorodiphenyltrichloroethane', 'dietary supplements', 'estrogenic endocrine disruptor', 'experience', 'fitness', 'innovation', 'member', 'metabolic abnormality assessment', 'metabolomics', 'multidisciplinary', 'programs', 'repository', 'reproductive', 'research study', 'response', 'tool']",NIEHS,MICHIGAN STATE UNIVERSITY,R01,2007,543226,0.010822388629976675
"Interrogation of systems level mechanisms controlling DNA repair processes    DESCRIPTION (provided by applicant): A comprehensive model of a complete biological system will enable prediction of phenotypic outcomes in face of novel genetic and environmental perturbations. Such predictive power for cellular systems, such as DMA repair, will have tremendous impacts on early detection and diagnosis of genetic disorders and, ultimately in designing preventive and/or curative treatments. However, the full understanding of eukaryotic DMA repair systems presents a daunting challenge due to their enormous complexity, especially given that systems approaches are not yet sufficiently mature to mathematically model such complex processes. At a molecular level, eukaryotic genetic information processing is mirrored in a simplified manner by their evolutionary ancestors, the archaea. In Halobacterium NRC-1 we have a simple yet powerful model system of -2400 genes in which the underlying generalized principles of a systems approach can be delineated. This halophilic archaeon routinely mitigates damage from high salinity, UV radiation and desiccation-rehydration cycles. We will use this model system to address the hypothesis that the decision making process governing cell fate after exposure to DMA damaging events such as UV irradiation is mediated by robust gene regulatory networks that simultaneously process information on spectral characteristics of the impinging radiation, the nature and extent of DMA damage and the potential preparative role of cellular entrainment to diurnal cycles. This hypothesis is motivated by two main observations: a. in systems analysis of UV response, although extraordinarily resistant, not all expected repair genes in this microbe responded to irradiation or damage; b. many of these damage-unresponsive repair genes did, however, respond to day-night entrainment. At a fundamental level this suggested that the resident state of the cell at time of irradiation may influence the type of response elicited. A systems approach is ideally suited to delinate the networks underlying this decision making process. Specifically, we will measure dynamic global changes (degree of damage, mRNA /protein levels, protein-protein and protein-DNA interactions) in wild type and mutant strains (defective in sensors, signal transducers, regulators and repair proteins) subjected to combinatorial changes in incident radiation, type of damage inflicted and resident state of the cell at the time of radiation. Through an integrated analysis of these diverse systems level data we will statistically learn perturbation-induced rewiring of a gene regulatory network that processes environmental perturbations (input) into phenotype (output), i.e. a predictive model for regulatory mechanisms for repair. This basic model will serve as a template for designing systems approaches to model higher complexities of eukaryotic repair processes.           n/a",Interrogation of systems level mechanisms controlling DNA repair processes,7317856,R01GM077398,"['Address', 'Algorithms', 'Animal Model', 'Archaea', 'Architecture', 'Behavior', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Candidate Disease Gene', 'Cell Cycle Progression', 'Cell Size', 'Cell Survival', 'Cell physiology', 'Cells', 'Characteristics', 'Chromosomes, Human, Pair 4', 'Circadian Rhythms', 'Complex', 'Computer information processing', 'Condition', 'Coupled', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Repair Gene', 'DNA Repair Pathway', 'DNA biosynthesis', 'DNA lesion', 'DNA repair protein', 'DNA-Protein Interaction', 'Data', 'Decision Making', 'Desiccation', 'Disease', 'Early Diagnosis', 'Elements', 'Engineering', 'Environment', 'Epitopes', 'Equilibrium', 'Event', 'Exogenous Factors', 'Exposure to', 'Face', 'Gene Proteins', 'Genes', 'Genetic', 'Genetic Information Processing Pathway', 'Genetic Transcription', 'Genome', 'Global Change', 'Halobacterium', 'Heart', 'Hour', 'Human', 'Lead', 'Learning', 'Life', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Messenger RNA', 'Metabolism', 'Microbe', 'Modeling', 'Molecular', 'Mutation', 'Nature', 'Nucleotide Excision Repair', 'Numbers', 'Operative Surgical Procedures', 'Organism', 'Outcome', 'Output', 'Oxidative Stress', 'Pathway interactions', 'Phenotype', 'Physiological Processes', 'Physiology', 'Preventive', 'Process', 'Protein Dynamics', 'Proteins', 'Radiation', 'Readiness', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Rehydrations', 'Resistance', 'Resources', 'Role', 'Signal Transduction', 'Skin Cancer', 'Source', 'Specific qualifier value', 'System', 'Systems Analysis', 'Systems Biology', 'Technology', 'Tertiary Protein Structure', 'Time', 'Transcript', 'Transducers', 'Translations', 'UV response', 'Ultraviolet Rays', 'biological research', 'cell type', 'combinatorial', 'coping', 'cryptochrome', 'day', 'design', 'gene repair', 'genetic disorder diagnosis', 'halobacteria', 'interest', 'irradiation', 'knockout gene', 'mathematical model', 'mutant', 'novel', 'predictive modeling', 'repaired', 'response', 'segregation', 'sensor', 'technology development', 'trait', 'ultraviolet damage', 'ultraviolet irradiation']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,R01,2007,335920,-0.024090090124445317
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7185305,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Biology, Other', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Computer information processing', 'Data', 'Databases', 'Depth', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Standards of Weights and Measures', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'functional genomics', 'genetic element', 'genome database', 'human disease', 'interest', 'model organisms databases', 'repository', 'size', 'tool']",NHGRI,JACKSON LABORATORY,P41,2007,3146180,0.0014636343646040118
"System-wide Study of Transcriptional Control of Metabolism    DESCRIPTION (provided by applicant): This proposal is in response to the NIH call for Exploratory Collaborations with National Centers for Biomedical Computing, PAR-06-223, and it will involve a collaboration between Columbia University's MAGNet NCBC and a team at Los Alamos National Laboratory. The aim of the proposal is a system-wide tudy of integrated transcriptional and metabolic networks in Eschericia coli K-12 strain, aiming at a similar analysis of a pathogen, Bacillus anthracis, at a later date. LANL hosts an experimental research program on bacterial metabolomics. Metabolites serve several functions. The most common one is being the precursors to various cellular components. They are also regulators of cellular functions by means of modulating metabolic reactions or binding to transcription factors and subsequently regulating gene expression. Conversely, the genes regulated by a transcription factor often encode enzymes, modulating the speed of metabolic reactions. Thus, to understand and ultimately predict the cellular response to an environmental change of interest (e.g., pathogen entry into its host environment), we must integrate the analysis of the transcriptome and metabolome. To address this need, we will work with the laboratories of Pat Unkefer and John Dunbar, which will produce data sets of about 300 joint metabolic/transcriptional profiles of E.coli under different steady-state growth conditions. The resources of MAGnet NCBC, specifically the algorithms within the geWorkbench bioinformatics platform produced by the center, will be leveraged to reconstruct cellular networks. Specifically, we expect that ARACNE, an algorithm originally developed by MAGNet for high-fidelity analysis of transcriptional networks in mammalian cells, is well positioned for reconstruction of metabolic networks from high throughput system-wide metabolic activity data, provide that appropriate modifications to deal with the specifics of the metabolic data are made. We will also adapt the algorithm to discover modulated interactions, that is, metabolic interactions that are conditional on the activity of a modulator gene (enzyme), or transcriptional interactions that require the presence of a metabolite to proceed. Such integrated genome/metabolome analysis has not been attempted yet. It will be a giant leap towards a complete understanding of cellular processes in an important organism. Because of the comparatively small size of bacterial genomes and metabolomes, it will be possible to perform system-wide analyses of interactions for the entire integrated genome and metabolome. While important in its own right, especially in view of the pathogenic nature of B. anthracis, this research would also represent an important test bed for a subsequent study of metabolic diseases in higher animals, including humans.           n/a",System-wide Study of Transcriptional Control of Metabolism,7234993,R21GM080216,"['Accounting', 'Address', 'Affect', 'Affinity', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Architecture', 'Autistic Disorder', 'Automobile Driving', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Bacillus anthracis', 'Bacterial Genome', 'Beds', 'Benchmarking', 'Binding', 'Biochemical', 'Biochemical Pathway', 'Biochemical Reaction', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Cadherins', 'Cell Adhesion Molecules', 'Cell Separation', 'Cell physiology', 'Cell-Cell Adhesion', 'Cells', 'Chemicals', 'Code', 'Collaborations', 'Commit', 'Communities', 'Complex', 'Computational Biology', 'Computational Technique', 'Computational algorithm', 'Computer Analysis', 'Computer Simulation', 'Computer software', 'Computers', 'Concentration measurement', 'Condition', 'Crystallography', 'DNA Binding', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Discipline', 'Disease', 'Dissection', 'Documentation', 'Drug Formulations', 'Drug Interactions', 'Educational workshop', 'Electrical Engineering', 'Engineering', 'Ensure', 'Environment', 'Enzyme Gene', 'Enzymes', 'Escherichia coli', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Proteins', 'Generations', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Health Sciences', 'Human', 'Imagery', 'Immune system', 'In Vitro', 'Informatics', 'Institutes', 'Institution', 'Internet', 'Java', 'Joints', 'Knowledge', 'Laboratories', 'Language', 'Life', 'Literature', 'Machine Learning', 'Mails', 'Malignant Neoplasms', 'Mammalian Cell', 'Manuals', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Metabolic', 'Metabolic Control', 'Metabolic Diseases', 'Metabolism', 'Methodology', 'Methods', 'Mission', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Multimedia', 'Nature', 'Noise', 'Online Systems', 'Ontology', 'Organism', 'Pathway Analysis', 'Pathway interactions', 'Performance', 'Personal Satisfaction', 'Phenotype', 'Phosphotransferases', 'Physics', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Prokaryotic Cells', 'Property', 'Protein Analysis', 'Protein Family', 'Proteins', 'Proteome', 'Publishing', 'RNA', 'Range', 'Rate', 'Reaction', 'Research', 'Research Activity', 'Research Personnel', 'Research Proposals', 'Resolution', 'Resources', 'Sampling', 'Semantics', 'Sequence Analysis', 'Services', 'Signal Transduction', 'Site', 'Software Engineering', 'Solutions', 'Source Code', 'Specific qualifier value', 'Specificity', 'Speed', 'Structural Protein', 'Structure', 'Structure of germinal center of lymph node', 'Students', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Transcriptional Regulation', 'United States National Institutes of Health', 'Universities', 'Validation', 'Virulence', 'Visual', 'Work', 'base', 'biocomputing', 'biomedical informatics', 'computer framework', 'computer studies', 'computerized tools', 'concept', 'data acquisition', 'data mining', 'data modeling', 'design', 'environmental change', 'experience', 'forging', 'hazard', 'improved', 'innovation', 'interest', 'interoperability', 'knowledge base', 'member', 'metabolomics', 'microbial', 'multidisciplinary', 'nervous system disorder', 'novel', 'pathogen', 'pathogenic bacteria', 'professor', 'programs', 'protein protein interaction', 'reconstruction', 'research study', 'response', 'simulation', 'size', 'software development', 'text searching', 'tool', 'transcription factor']",NIGMS,LOS ALAMOS NAT SECTY-LOS ALAMOS NAT LAB,R21,2007,257655,-0.01461623717429592
"Accelerating metabolic discovery using characterization data    DESCRIPTION (provided by applicant): The long term goal of this project is to develop methods that will allow researchers to gain insight into the metabolic networks of organisms for which we have little or no high-throughput data. Such metabolic networks can reveal aspects of the organism's metabolism that might make it vulnerable to new or existing therapies. A core data set using genomic and other omic data from data-rich bacteria that are related to the organisms of interest will be assembled. The statistical tools needed to integrate these data and to infer metabolic networks using these core data plus characterization (phenotypic) data will then be built. Using the statistical inference algorithms, the characterization data can be leveraged to reveal the metabolic networks of data-poor bacteria for which we have only characterization data. This approach can eliminate the need for genome sequencing, gene expression experiments and the like for thousands of Gram-negative facultative rod bacteria (GNF). There are five tasks in the project: (1) assemble the data sets from data-rich organisms that will be used to inform the inference algorithm. These data include (a) the genomic sequences and annotation information, (b) extant pathway data and (c) gene expression data. All these data contain some level of information about the connectivity within the metabolic network; (2) process the genomic data to enhance its predictive value; (3) develop a data integration algorithm; (4) investigate modeling frameworks to be used for Bayesian data fusion and network inference; (5) validate the metabolic networks. Deliverables from this project should include: (1) a set of pathway genome databases for 35 GNF, This group includes 20 strains classified as category A or B biothreat agents, (2) a core dataset that integrates all the information we have relevant to the metabolic pathways in the 35 sequenced GNF, (3) a probabilistic graphical modeling framework capable of integrating disparate types of data and inferring networks from the integrated data, (4) a method for using characterization data, along with deliverables 2 and 3, to infer metabolic networks for bacterial strains for which we have only characterization data. The ability to rapidly construct models of metabolic networks means researchers will be able to respond to emerging infectious agents or biothreats more quickly. Relevance The methods developed as part of this proposal will allow us to quickly make metabolic maps for thousands of bacteria. Such maps can guide researchers to promising new targets for therapeutic or preventative measures against pathogenic bacteria. The fight against well-known pathogens and biothreat agents, as well as against new, emerging pathogens will be greatly aided by these tools.              n/a",Accelerating metabolic discovery using characterization data,7267998,R21AI067543,"['Adopted', 'Algorithms', 'American Type Culture Collection', 'Artificial Intelligence', 'Bacteria', 'Bacteriology', 'Biochemical', 'Biochemical Pathway', 'Biological Models', 'Biology', 'Bypass', 'Categories', 'Cholera', 'Code', 'Data', 'Data Collection', 'Data Set', 'Depth', 'Disease', 'Electronics', 'Facility Construction Funding Category', 'Gammaproteobacteria', 'Gene Expression', 'Genomics', 'Goals', 'Gram&apos', 's stain', 'Infectious Agent', 'Information Networks', 'Manuals', 'Maps', 'Measures', 'Meta-Analysis', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Modeling', 'Nosocomial Infections', 'Numbers', 'Nutritional', 'Organism', 'Outcome', 'Oxygen', 'Pathway interactions', 'Plague', 'Predictive Value', 'Process', 'Prophylactic treatment', 'Proteomics', 'Research Personnel', 'Salmonella typhi', 'Shapes', 'Shigella', 'Shigella Infections', 'Signal Transduction', 'Source', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Typhoid Fever', 'Variant', 'Vibrio cholerae', 'Work', 'Writing', 'Yersinia pestis', 'biothreat', 'computerized data processing', 'data integration', 'design', 'falls', 'fight against', 'genome database', 'genome sequencing', 'gram negative facultative rods', 'innovation', 'insight', 'interest', 'network models', 'novel', 'pathogen', 'pathogenic bacteria', 'programs', 'research study', 'retinal rods', 'routine Bacterial stain', 'sound', 'success', 'therapeutic target', 'tool', 'transcriptomics']",NIAID,AMERICAN TYPE CULTURE COLLECTION,R21,2007,185677,-0.003095643667507924
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7286779,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2007,3638557,0.013756726476284814
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7287978,SC1GM081068,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Endopeptidases', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIGMS,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2007,247625,-0.002276321716562226
"Computational Models of Infectious Disease Threats DESCRIPTION (provided by applicant):  Microbial threats, including bioterrorism and naturally emerging infectious diseases, pose a serious challenge to national security in the United States and to health worldwide.  This proposal describes the creation of a center for computational modeling of infectious diseases at the Johns Hopkins Bloomberg School of Public Health, with the collaboration of key experts at the Brookings Institution, the National Aeronautic and Space Administration, the University of Maryland, and Imperial College (London).  The overarching aim of this project is to integrate the most advanced and powerful techniques of epidemiological data analysis with those of computer simulation (agent-based modeling) to produce a unified computational epidemiology that is scientifically sound, highly visual and user-friendly, and responsive to biosecurity and public health policy requirements.  Data analysis will be guided by the insight that epidemic patterns over space and time can be approached as nearly decomposable systems, in which frequency components of the incidence signal can be isolated and studied.  Wavelet transforms, and empiric mode decomposition using Hilbert-Huang Transforms, will be used to sift nonlinear, nonstationary epidemiological data, allowing frequency band patterns to be defined.  Isolated frequency modes will then be associated with external forcing (weather, social contact patterns) and internal dynamics (Kermack-McKendrick predator-prey models).  Results of the epidemiological data decomposition analysis, along with the knowledge of infectious disease experts, will instruct the creation and development of agent-based models.  Such models feature populations of mobile individuals in artificial societies that interact locally with other individuals.  Features of the basic model include variable social network structures, individual susceptibility and immunity, incubation periods, transmission rates, contact rates, and other selectable parameters.  After the agent-based model is calibrated to generate epidemic patterns consistent with real world epidemiology, preventive strategies including vaccination, contact tracing, isolation, quarantine, and other public health measures will be systematically introduced and their impact evaluated.  Methods will be developed for assessing the utility of individual models, and for making decisions based on combined results from more than one model.  Infectious diseases to be studied initially include smallpox, SARS, dengue, West Nile, and unknown but hypothetically plausible agents.  As part of a Cooperative Agreement, the Center will work with other research groups, a bioinformatics core group, and the NIGMS to develop data sets, software and methods, agent-based models, and visualization tools.  In an infectious disease epidemic emergency the Center will redirect its activities to serve the nation's security, as guided by the NIGMS. n/a",Computational Models of Infectious Disease Threats,7284239,U01GM070708,"['AIDS therapy', 'AIDS/HIV problem', 'Academy', 'Acquired Immunodeficiency Syndrome', 'Affect', 'Airborne Particulate Matter', 'Algorithms', 'American', 'Americas', 'Animal Experimentation', 'Appendix', 'Archives', 'Area', 'Arthropod Vectors', 'Award', 'Bacteria', 'Beds', 'Bioinformatics', 'Biological', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Books', 'Borrelia', 'Climate', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Condition', 'Contact Tracing', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Decision Theory', 'Demography', 'Dengue', 'Dengue Hemorrhagic Fever', 'Detection', 'Development', 'Dialysis procedure', 'Disease', 'Docking', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Ecology', 'Economics', 'Educational process of instructing', 'Ehrlichia', 'Emergency Situation', 'Emerging Communicable Diseases', 'Encephalitis', 'Engineering', 'Environmental Engineering technology', 'Environmental Health', 'Epidemic', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'Event', 'Evolution', 'Facility Construction Funding Category', 'Faculty', 'Foot-and-Mouth Disease', 'Frequencies', 'Game Theory', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Geography', 'Glass', 'Goals', 'HIV', 'Hantavirus', 'Head', 'Health', 'Health Policy', 'Healthcare', 'Hepatitis E', 'Human', 'Human Resources', 'Hygiene', 'Imagery', 'Immunity', 'Immunology', 'Incidence', 'Individual', 'Infectious Agent', 'Infectious Disease Epidemiology', 'Influenza', 'Informatics', 'Information Services', 'Institute of Medicine (U.S.)', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internal Medicine', 'International', 'Internet', 'Intervention', 'Joints', 'Journals', 'Knowledge', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Lead', 'Legal patent', 'Leptospira', 'Libraries', 'Location', 'London', 'Lung', 'Machine Learning', 'Maintenance', 'Malaria', 'Maryland', 'Master&apos', 's Degree', 'Mathematical Biology', 'Mathematics', 'Measles', 'Measures', 'Mechanics', 'Methods', 'Microbiology', 'Military Personnel', 'Modeling', 'Modified Smallpox', 'Molecular', 'National Institute of General Medical Sciences', 'National Security', 'New York', 'Nonlinear Dynamics', 'Nonparametric Statistics', 'Observational Study', 'Oceanography', 'Outcome', 'Paper', 'Pattern', 'Physical Dialysis', 'Play', 'Policies', 'Policy Maker', 'Population', 'Positioning Attribute', 'Predisposition', 'Pregnancy Outcome', 'Prevention strategy', 'Preventive', 'Principal Investigator', 'Prion Diseases', 'Procedures', 'Process', 'Provider', 'Proxy', 'Public Health', 'Public Health Schools', 'Public Policy', 'Publications', 'Publishing', 'Purpose', 'Quarantine', 'Rate', 'Recording of previous events', 'Reference Standards', 'Relative (related person)', 'Research', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Rickettsia', 'Risk Assessment', 'Rodent', 'Role', 'Route', 'Schedule', 'Schools', 'Science', 'Scientist', 'Screening procedure', 'Security', 'Series', 'Severe Acute Respiratory Syndrome', 'Signal Transduction', 'Simulate', 'Smallpox', 'Social Network', 'Social Sciences', 'Societies', 'Software Tools', 'Space Flight', 'Statistical Computing', 'Statistical Models', 'Structure', 'Students', 'System', 'Systems Analysis', 'Testing', 'Theoretical model', 'Time', 'Time Series Analysis', 'Training', 'Tropical Medicine', 'U-Series Cooperative Agreements', 'Uncertainty', 'United States', 'United States National Academy of Sciences', 'United States National Aeronautics and Space Administration', 'Universities', 'Vaccination', 'Variant', 'Vector-transmitted infectious disease', 'Violence', 'Viral', 'Viral Hemorrhagic Fevers', 'Virus', 'Virus Diseases', 'Visual', 'Weather', 'West Nile virus', 'Work', 'base', 'biosecurity', 'c new', 'college', 'computer science', 'concept', 'design', 'disease natural history', 'disease transmission', 'disorder prevention', 'disorder risk', 'editorial', 'experience', 'improved', 'indexing', 'infectious disease model', 'insight', 'interest', 'mathematical model', 'member', 'microbial', 'models and simulation', 'network models', 'pathogen', 'peer', 'predictive modeling', 'prevent', 'professor', 'programs', 'remote sensing', 'respiratory', 'simulation', 'skills', 'social', 'social organization', 'sound', 'theories', 'tool', 'transmission process', 'user-friendly', 'vaccination strategy']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,U01,2007,588968,-0.010463141183561286
"Systems Biology of Cell Decision Processes    DESCRIPTION (provided by applicant):  The remarkable complexity of biological systems demands a systematic approach to their analysis.  The goal of this proposal is to establish an MIT Center of Excellence in Cell Decision Processes (CDP) around an interdisciplinary team of cell biologists, computer scientists and microsystems engineers tackling the systems biology of protein networks and signal transduction in mammalian cells. The basic hypothesis of the CDP Center is that understanding cell decision processes requires the development of network models that combine quantitative rigor with molecular detail. These models will be hybrids containing highly specific representations of critical reactions and abstract representations of the system as a whole. Effective models will endure and capture the accumulation of knowledge over time in a rigorous and portable format.  The CDP Center will follow a research paradigm that links systematic experiments and numerical modeling in a four-step feedback loop of manipulation-measurement-mining and modeling. The biological focus of the Center will be the signaling events that control apoptosis. The measurement of protein concentrations, modification state and activity will be undertaken for signaling molecules at many points in the apoptotic network. The measurements will then be analyzed using several modeling approaches ranging from highly specified to highly abstract.  To collect sufficient data for systematic modeling, the CDP Center will automate and standardize biochemical methods, develop compact array-based assays and design novel microfabricated devices with integrated microfluidics and label-free sensors. To organize and systematize the data, informatic methods will be developed that support rigorous approaches to inference. Finally, physico-chemical, structure-systems and Bayesian models will be used to generate biological hypotheses for experimental verification.  The research activities of the CDP Center will be complemented by graduate and undergraduate education and by an outreach program targeted at the scientific community in general and minority-serving institutions in particular.         n/a",Systems Biology of Cell Decision Processes,7285298,P50GM068762,"['Accountability', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'Amino Acid Sequence', 'Animals', 'Annual Reports', 'Apoptosis', 'Apoptotic', 'Appendix', 'Area', 'Artificial Intelligence', 'Attention', 'Authorship', 'Automation', 'Award', 'BCL2L11 gene', 'Belief', 'Binding', 'Biochemical', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Phenomena', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Engineering', 'Boxing', 'Budgets', 'Cancer Center', 'Cell Extracts', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Cellular biology', 'Chemical Engineering', 'Chemical Structure', 'Chemicals', 'Child', 'Classification', 'Code', 'Collaborations', 'Color', 'Commit', 'Communities', 'Complement', 'Complex', 'Computational Biology', 'Computer software', 'Computers', 'Computing Methodologies', 'Core Facility', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Development', 'Devices', 'Discipline', 'Disputes', 'Doctor of Philosophy', 'Drug Formulations', 'Drug Industry', 'Education', 'Education and Outreach', 'Educational Curriculum', 'Educational process of instructing', 'Electrical Engineering', 'Electronics', 'Engineering', 'Ensure', 'Equilibrium', 'Equipment', 'Event', 'Evolution', 'Experimental Models', 'Facility Construction Funding Category', 'Faculty', 'Feedback', 'Figs - dietary', 'Foundations', 'Funding', 'Future', 'Gene Proteins', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome Components', 'Goals', 'Grant', 'Gray unit of radiation dose', 'Head', 'High Performance Computing', 'High Pressure Liquid Chromatography', 'Historically Black Colleges and Universities', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Individual', 'Informatics', 'Information Theory', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internet', 'Interruption', 'Investments', 'Joints', 'Knowledge', 'Label', 'Lead', 'Leadership', 'Learning', 'Letters', 'Life', 'Link', 'Mammalian Cell', 'Manuals', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical Device', 'Metabolic', 'Methods', 'Microfluidics', 'Microscopy', 'Mining', 'Minority-Serving Institution', 'Mission', 'Modeling', 'Modification', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Profiling', 'Molecular and Cellular Biology', 'Monitor', 'Mus', 'NCI Center for Cancer Research', 'Nature', 'Numbers', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Paper', 'Pathway Analysis', 'Pathway interactions', 'Peptide Sequence Determination', 'Performance', 'Phase', 'Phosphorylation', 'Play', 'Policies', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Productivity', 'Property', 'Protein Analysis', 'Proteins', 'Proteomics', 'Protons', 'Publications', 'Purpose', 'Range', 'Reaction', 'Reliance', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resource Allocation', 'Resources', 'Risk', 'Role', 'Route', 'Running', 'Schools', 'Science', 'Scientist', 'Seeds', 'Semiconductors', 'Series', 'Services', 'Signal Transduction', 'Signaling Molecule', 'Soaps', 'Source', 'Specific qualifier value', 'Students', 'Supervision', 'Support of Research', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'To specify', 'Training', 'Training Programs', 'Transgenic Organisms', 'Underrepresented Minority', 'United States National Institutes of Health', 'Visit', 'Work', 'abstracting', 'anticancer research', 'base', 'chemical reaction', 'college', 'computer based statistical methods', 'computer science', 'computerized data processing', 'concept', 'data mining', 'data modeling', 'design', 'desire', 'drug discovery', 'experience', 'fluid flow', 'forging', 'fundamental research', 'instrument', 'instrumentation', 'interest', 'intracellular protein transport', 'member', 'microsystems', 'molecular modeling', 'network models', 'novel', 'novel strategies', 'open source', 'outreach', 'outreach program', 'programs', 'protein transport', 'research facility', 'research study', 'response', 'sensor', 'size', 'success', 'systems research', 'technology development', 'tool', 'virtual']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,P50,2007,2952859,-0.011068728739709151
"Systems Biology of Cell Decision Processes The remarkable complexity of biological systems demands a systematic approach to their analysis. The goal of this proposal is to establish an MIT Center of Excellence in Cell Decision Processes (CDP) around an interdisciplinary team of cell biologists, computer scientists and microsystems engineers tackling the systems biology of protein networks and signal transduction in mammalian cells. The basic hypothesis of the CDP Center is that understanding cell decision processes requires the development of network models that combine quantitative rigor with molecular detail. These models will be hybrids containing highly specific representations of critical reactions and abstract representations of the system as a whole. Effective models will endure and capture the accumulation of knowledge over time in a rigorous and portable format.  The CDP Center will follow a research paradigm that links systematic experiments and numerical modeling in a four-step feedback loop of manipulation-measurement-mining and modeling. The biological focus of the Center will be the signaling events that control apoptosis. The measurement of protein concentrations, modification state and activity will be undertaken for signaling molecules at many points in the apoptotic network. The measurements will then be analyzed using several modeling approaches ranging from highly specified to highly abstract.  To collect sufficient data for systematic modeling, the CDP Center will automate and standardize biochemical methods, develop compact array-based assays and design novel microfabricated devices with integrated microfluidics and label-free sensors. To organize and systematize the data, inforrnatic methods will be developed that support rigorous approaches to inference. Finally, physico-chemical, structure-systems and Bayesian models will be used to generate biological hypothesis for experimental verification.  The research activities of the CDP Center will be complemented by graduate and undergraduate education and by an outreach program targeted at the scientific community in general and minority-serving institutions in particular n/a",Systems Biology of Cell Decision Processes,7479966,P50GM068762,"['Accountability', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'Amino Acid Sequence', 'Animals', 'Annual Reports', 'Apoptosis', 'Apoptotic', 'Appendix', 'Area', 'Artificial Intelligence', 'Attention', 'Authorship', 'Automation', 'Award', 'BCL2L11 gene', 'Belief', 'Binding', 'Biochemical', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Phenomena', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Engineering', 'Boxing', 'Budgets', 'Cancer Center', 'Cell Extracts', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Cellular biology', 'Chemical Engineering', 'Chemical Structure', 'Chemicals', 'Child', 'Classification', 'Code', 'Collaborations', 'Color', 'Commit', 'Communities', 'Complement', 'Complex', 'Computational Biology', 'Computer software', 'Computers', 'Computing Methodologies', 'Core Facility', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Development', 'Devices', 'Discipline', 'Disputes', 'Doctor of Philosophy', 'Drug Formulations', 'Drug Industry', 'Education', 'Education and Outreach', 'Educational Curriculum', 'Educational process of instructing', 'Electrical Engineering', 'Electronics', 'Engineering', 'Ensure', 'Equilibrium', 'Equipment', 'Event', 'Evolution', 'Experimental Models', 'Facility Construction Funding Category', 'Faculty', 'Feedback', 'Figs - dietary', 'Foundations', 'Funding', 'Future', 'Gene Proteins', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome Components', 'Goals', 'Grant', 'Gray unit of radiation dose', 'Head', 'High Performance Computing', 'High Pressure Liquid Chromatography', 'Historically Black Colleges and Universities', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Individual', 'Informatics', 'Information Theory', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internet', 'Interruption', 'Investments', 'Joints', 'Knowledge', 'Label', 'Lead', 'Leadership', 'Learning', 'Letters', 'Life', 'Link', 'Mammalian Cell', 'Manuals', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical Device', 'Metabolic', 'Methods', 'Microfluidics', 'Microscopy', 'Mining', 'Minority-Serving Institution', 'Mission', 'Modeling', 'Modification', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Profiling', 'Molecular and Cellular Biology', 'Monitor', 'Mus', 'NCI Center for Cancer Research', 'Nature', 'Numbers', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Paper', 'Pathway Analysis', 'Pathway interactions', 'Peptide Sequence Determination', 'Performance', 'Phase', 'Phosphorylation', 'Play', 'Policies', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Productivity', 'Property', 'Protein Analysis', 'Proteins', 'Proteomics', 'Protons', 'Publications', 'Purpose', 'Range', 'Reaction', 'Reliance', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resource Allocation', 'Resources', 'Risk', 'Role', 'Route', 'Running', 'Schools', 'Science', 'Scientist', 'Seeds', 'Semiconductors', 'Series', 'Services', 'Signal Transduction', 'Signaling Molecule', 'Soaps', 'Source', 'Specific qualifier value', 'Students', 'Supervision', 'Support of Research', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'To specify', 'Training', 'Training Programs', 'Transgenic Organisms', 'Underrepresented Minority', 'United States National Institutes of Health', 'Visit', 'Work', 'abstracting', 'anticancer research', 'base', 'chemical reaction', 'college', 'computer based statistical methods', 'computer science', 'computerized data processing', 'concept', 'data mining', 'data modeling', 'design', 'desire', 'drug discovery', 'experience', 'fluid flow', 'forging', 'fundamental research', 'instrument', 'instrumentation', 'interest', 'intracellular protein transport', 'member', 'microsystems', 'molecular modeling', 'network models', 'novel', 'novel strategies', 'open source', 'outreach', 'outreach program', 'programs', 'protein transport', 'research facility', 'research study', 'response', 'sensor', 'size', 'success', 'systems research', 'technology development', 'tool', 'virtual']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,P50,2007,48090,-0.012017921299689694
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,7071180,R01GM074128,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'chemical structure', 'chemical synthesis', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'glycosylation', 'high throughput technology', 'mass spectrometry', 'mathematics', 'matrix assisted laser desorption ionization', 'polysaccharides', 'structural biology', 'technology /technique development']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2006,324279,-0.030082915348947005
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,7107923,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2006,509027,-0.005980522135794032
"Genetic Network Inference with Combinational Phenotypes DESCRIPTION (provided by applicant): The reverse engineering of cellular genetic circuits from gene expression data is an important and scientifically challenging problem. When applied to system more complex than a yeast cell, however, most of the approaches for reverse engineering are limited by their reliance on a significant number of ad-hoc perturbation, such as gene knockout.  We propose to address these issues and to attempt to reconstruct the genetic circuitry of human B-cells by coupling three distinct components: 1) an information theoretic method for the inference of cellular networks from microarray profile data for a large number of distinct cellular and molecular phenotypes 2) A synthetic network simulation framework for the assessment of the performance of the reverse engineering under a variety of constraints and conditions, such as noise and network complexity. 3) An adaptive learning method that will iteratively apply optimal perturbations to the biological system, which will allow refining the cellular network model over time.  Furthermore, we propose to biologically validate this approach by elucidating the cellular networks of human B lymphocytes, from a variety of normal, tumor-derived, and experimentally manipulated B cell phenotypes, which are significant both from an oncological and immunological perspective. This will be accomplished by analyzing an existing set of over 340 high-quality microarray expression profiles.  Finally, we will create a software platform to reverse engineer any biological system for which adequate microarray data is available. The platform will also allow to design and perform virtual, in-silico gene perturbation experiments. n/a",Genetic Network Inference with Combinational Phenotypes,7082976,R01CA109755,"['B lymphocyte', 'artificial intelligence', 'cellular oncology', 'computer program /software', 'computer simulation', 'cytogenetics', 'functional /structural genomics', 'gene expression profiling', 'genetic models', 'human data', 'lymphoma', 'microarray technology', 'molecular biology information system', 'molecular genetics', 'molecular oncology', 'neoplasm /cancer genetics', 'nucleic acid structure', 'statistics /biometry']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,373483,-0.018502254000984833
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,7068069,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2006,19532,-0.01163597160134672
"The RPI Exploratory Center for Cheminformatics (RMI) The purpose of this Exploratory Center for Cheminformatics Research (ECCR) P20 planning grant is to develop a mechanism for bringing together and stimulating collaborative pilot projects among a constantly-evolving nucleus of experts in Cheminformatics-related fields ranging from methods of encoding and capturing molecular information, to machine learning and data mining techniques, to predictive model development, validation, interpretation and utilization. In addition to these research efforts, the Center will bring together a set of domain specialists and application scientists who will serve as both data generators and end users of the knowledge provided by the molecular property models and modeling methods developed during the course of the grant. This group will also test the new Cheminformatics software that will constitute a tangible, deliverable product from this work. Ten application project modules that exemplify possible interactions between various groups and areas of expertise within the Center are presented as part of this proposal. The unifying vision behind the proposed Center is that much of what is done in each of the subdisciplines represented here can be expressed in a Cheminformatics context: The many diverse project areas can be grouped into one or more overlapping categories: ""Data Generators"" (those who use either theoretical or experimental methods for creating or extracting knowledge), ""Machine Learning and Datamining"" groups (who perform model validation, feature selection, pattern recognition, generation of potentials of mean force and knowledge-based potential work), as well as ""Property-Prediction"" groups (who perform chemically-aware model building, molecular property descriptor generation, Quantitative Structure-Property Relationship modeling, validation, and interpretation), and ""Application"" groups who utilize the information made available using the new tools and methods that are developed as part of the Center. It is our strong belief that these areas of expertise can be brought together within this Planning Grant proposal to generate something larger than the sum of the parts. The Exploratory Center will seed new interdisciplinary projects and train graduate students in these areas.   Relevance: Advances in the generation, mining and analysis of chemical information is crucial to the development of new drug therapies, and to modern methods of bioinformatics and molecular medicine. n/a",The RPI Exploratory Center for Cheminformatics (RMI),7125575,P20HG003899,"['Internet', 'NIH Roadmap Initiative tag', 'bioinformatics', 'chemical models', 'cheminformatics', 'computer program /software', 'computers', 'data collection methodology /evaluation', 'data management', 'information retrieval', 'interdisciplinary collaboration', 'model design /development', 'molecular biology']",NHGRI,RENSSELAER POLYTECHNIC INSTITUTE,P20,2006,377226,0.004389960176241335
"Cytokine Signaling Network Response to Smallpox Vaccine    DESCRIPTION (provided by applicant):  The identification of the molecular and cellular basis for adverse events observed in patients immunized against smallpox is of great public health interest. This is especially true today given efforts to defend the U.S. population and military against potential bioterrorism agents. We have shown recently that adverse vents following smallpox vaccination correlate with systemic cytokine patterns, suggesting a role for cytokines in the pathogenesis of adverse events. A challenge to further delineating the immunological mechanisms of adverse events is that cytokines rarely act in isolation to induce an immune response, but rather they work in a complex network to which immune system cells respond. Cytokines are small signaling proteins that integrate the activities of immune system cells. While it is often well understood how they act individually, the behavior of cytokines as part of a signaling network is less well known and likely depends on the nature of the infecting organism. We propose to develop and evaluate a comprehensive strategy to identify detailed kinetic cytokine network models associated with adverse events following smallpox vaccination. This strategy will be developed and evaluated using proteomic time-series data available from 103 volunteers that are part of an ongoing NIAID/NIH-sponsored trial to evaluate the Aventis Pasteur Smallpox Vaccine (APSV). We will develop software tools using machine learning algorithms to automatically discover cytokine signaling network models from observed time-series cytokine expression levels. Once the underlying cytokine network model has been estimated, our goal is to use the dynamic model as a simulation tool to suggest ways to create vaccines that minimize the risk of adverse events associated with vaccination. The software tools developed in this proposal will be generally applicable for biomedical research to understand the biochemical interactions in time-series data, and, thus, a useful and novel software package will be made available to the vaccine research community. The experience and knowledge gained during the collaboration on this important research problem in immunology coupled with the didactic and mentoring portions of the training program will create a firm foundation upon which I can develop and test significant hypotheses for future studies on the immunology of infectious diseases.             n/a",Cytokine Signaling Network Response to Smallpox Vaccine,7099789,K25AI064625,"['Poxviridae disease', 'cytokine', 'model']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,K25,2006,27000,-0.01195330514054726
"Cytokine Signaling Network Response to Smallpox Vaccine    DESCRIPTION (provided by applicant):  The identification of the molecular and cellular basis for adverse events observed in patients immunized against smallpox is of great public health interest. This is especially true today given efforts to defend the U.S. population and military against potential bioterrorism agents. We have shown recently that adverse vents following smallpox vaccination correlate with systemic cytokine patterns, suggesting a role for cytokines in the pathogenesis of adverse events. A challenge to further delineating the immunological mechanisms of adverse events is that cytokines rarely act in isolation to induce an immune response, but rather they work in a complex network to which immune system cells respond. Cytokines are small signaling proteins that integrate the activities of immune system cells. While it is often well understood how they act individually, the behavior of cytokines as part of a signaling network is less well known and likely depends on the nature of the infecting organism. We propose to develop and evaluate a comprehensive strategy to identify detailed kinetic cytokine network models associated with adverse events following smallpox vaccination. This strategy will be developed and evaluated using proteomic time-series data available from 103 volunteers that are part of an ongoing NIAID/NIH-sponsored trial to evaluate the Aventis Pasteur Smallpox Vaccine (APSV). We will develop software tools using machine learning algorithms to automatically discover cytokine signaling network models from observed time-series cytokine expression levels. Once the underlying cytokine network model has been estimated, our goal is to use the dynamic model as a simulation tool to suggest ways to create vaccines that minimize the risk of adverse events associated with vaccination. The software tools developed in this proposal will be generally applicable for biomedical research to understand the biochemical interactions in time-series data, and, thus, a useful and novel software package will be made available to the vaccine research community. The experience and knowledge gained during the collaboration on this important research problem in immunology coupled with the didactic and mentoring portions of the training program will create a firm foundation upon which I can develop and test significant hypotheses for future studies on the immunology of infectious diseases.             n/a",Cytokine Signaling Network Response to Smallpox Vaccine,7389130,K25AI064625,[' '],NIAID,UNIVERSITY OF ALABAMA AT BIRMINGHAM,K25,2006,73818,-0.01195330514054726
"Nation Center: Multi-Scale Study- Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7126050,U54CA121852,"['NIH Roadmap Initiative tag', 'bioinformatics', 'cell biology', 'computational biology', 'cooperative study', 'genome']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2006,3747227,0.013763224125104676
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7125565,R01EB006200,"['NIH Roadmap Initiative tag', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'biotechnology', 'charge coupled device camera', 'computer program /software', 'computer system hardware', 'high throughput technology', 'image enhancement', 'robotics']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2006,399410,-0.029107779443447324
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,6916805,R01GM074128,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'chemical structure', 'chemical synthesis', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'glycosylation', 'high throughput technology', 'mass spectrometry', 'mathematics', 'matrix assisted laser desorption ionization', 'polysaccharides', 'structural biology', 'technology /technique development']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2005,353067,-0.030082915348947005
"BioMediator: Biologic Data Integration& Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration& Analysis System,6946761,R01HG002288,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'information retrieval', 'molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2005,100000,0.007298981059733793
"Neural network model of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using radial basis function neural network (RBFNN) that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The RBFNN model will be fed training data from our existing database (chinchilla) consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals. Once trained, the model will be able to predict the auditory consequences of exposure to any noise environment characterized by ten noise metrics and five biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/histological data are available (Year 2). The training period will be an iterative process in which the RBFNN will be modified as training proceeds. The prediction model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a RBFNN to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Neural network model of noise-induced hearing loss,6941215,R03OH008175,"['artificial intelligence', 'chinchilla', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'disease /disorder model', 'environmental exposure', 'model design /development', 'noise biological effect', 'noise induced deafness']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R03,2005,71735,-0.003526045960291434
"Shifting Conceptions of Human Identity DESCRIPTION (provided by applicant):  . One of the most important questions raised by the ongoing achievements of the Human Genome Project is how this new biological knowledge - and the powers it confers - will affect our identity and self-understanding as human beings. This book project focuses on one key aspect of this complex issue: exploring the extent to which human identity can be reconciled with deliberate design or partial redesign. The author proposes to shed new light on this question by comparing the debates surrounding two areas of scientific innovation that are not normally associated with each other, but that are in fact deeply related: the enterprise of human genetic intervention and the enterprise of building intelligent machines. Both these enterprises entail ""pushing the limits"" of traditional concepts of what it means to be human; and both ultimately confront their makers with the same core ""family"" of questions: What are the defining features of human personhood? To what extent can those features be modified or extended, before human personhood begins to break down? Can some (or all) of those features find embodiment in an entity other than a human being? These kinds of questions are no longer the sole province of science fiction writers, but have been taken up with increasing seriousness by mainstream scientists and technologists, as well as by a wide array of ""science watchers"" in academia, legislative circles, and the news media.   . Through documentary research and interviews, this project aims to deepen our understanding of the history and sociology of the debates surrounding these powerful new technologies, electro-mechanical and biological, that are perceived as destabilizing human identity. The intended audience for the book is a broad one: scientists and technological practitioners interested in the social and cultural reception of their research; legislators and other policymakers with a stake in the governance of science; general educated readers who are concerned about the role of science and technology in shaping our collective future. n/a",Shifting Conceptions of Human Identity,6915830,R03HG003298,"['adult human (21+)', 'artificial intelligence', 'behavioral /social science research tag', 'biotechnology', 'books', 'clinical research', 'ethics', 'genetic manipulation', 'history of life science', 'human subject', 'identity', 'interview', 'robotics', 'self concept', 'sociology /anthropology']",NHGRI,VANDERBILT UNIVERSITY,R03,2005,75833,-0.016732109900491423
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6923756,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,395905,-0.00048241606635071653
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6944266,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2005,523667,-0.005980522135794032
"Development of Bioinformatic Tools for Virtual Cloning  DESCRIPTION (provided by applicant): The elaboration of the sequences of the human genome and those of many cellular and viral parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease. It has also resulted in the formation of an entirely new field, bioinformatics, which promises to manage and analyze the vast amount of data being generated. Bioinformatics needs to supply tools for data analysis and tools for experimental design. Most of the scientific and corporate resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology. Essentially every experiment in biology now begins with cloning one or more pieces of DNA. Commercial software that facilitates virtual DNA cloning does exist, but it lacks any automation features and depends on primitive and/or fragmentary gene and vector databases. It is inadequate in planning the hundreds or thousands of clones necessary to address questions posed by the proteomics initiatives, because the lack of knowledge integration. In Phase I of this SBIR grant, we have built and tested a virtual cloning expert system, along with a very useful gene database and a uniquely annotated vector database that serve as a knowledge base for automated DNA manipulations. A collection of automated cloning modules and databases is now functional. In Phase II we will complete the virtual cloning expert system and develop a flexible platform for automated experimental design, data management and analysis. We will also construct a user database, improve the user interface and establish security protocols. The results will be a complete program suite as a stable and marketable product. n/a",Development of Bioinformatic Tools for Virtual Cloning,6908174,R44HG003506,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computer assisted sequence analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'experimental designs', 'expression cloning', 'genetic library', 'high throughput technology', 'molecular biology information system', 'molecular cloning']",NHGRI,"VIRMATICS, LLC",R44,2005,375000,-0.0049426864483583235
"Genetic Network Inference with Combinational Phenotypes DESCRIPTION (provided by applicant): The reverse engineering of cellular genetic circuits from gene expression data is an important and scientifically challenging problem. When applied to system more complex than a yeast cell, however, most of the approaches for reverse engineering are limited by their reliance on a significant number of ad-hoc perturbation, such as gene knockout.  We propose to address these issues and to attempt to reconstruct the genetic circuitry of human B-cells by coupling three distinct components: 1) an information theoretic method for the inference of cellular networks from microarray profile data for a large number of distinct cellular and molecular phenotypes 2) A synthetic network simulation framework for the assessment of the performance of the reverse engineering under a variety of constraints and conditions, such as noise and network complexity. 3) An adaptive learning method that will iteratively apply optimal perturbations to the biological system, which will allow refining the cellular network model over time.  Furthermore, we propose to biologically validate this approach by elucidating the cellular networks of human B lymphocytes, from a variety of normal, tumor-derived, and experimentally manipulated B cell phenotypes, which are significant both from an oncological and immunological perspective. This will be accomplished by analyzing an existing set of over 340 high-quality microarray expression profiles.  Finally, we will create a software platform to reverse engineer any biological system for which adequate microarray data is available. The platform will also allow to design and perform virtual, in-silico gene perturbation experiments. n/a",Genetic Network Inference with Combinational Phenotypes,6925178,R01CA109755,"['B lymphocyte', 'artificial intelligence', 'cellular oncology', 'computer program /software', 'computer simulation', 'cytogenetics', 'functional /structural genomics', 'gene expression profiling', 'genetic models', 'human data', 'lymphoma', 'microarray technology', 'molecular biology information system', 'molecular genetics', 'molecular oncology', 'neoplasm /cancer genetics', 'nucleic acid structure', 'statistics /biometry']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,387233,-0.018502254000984833
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,6937143,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2005,20000,-0.01163597160134672
"Model for prediction of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using a statistical learning machine (SLM), which includes an artificial neural network (ANN), a support vector machine (SVM), and a hybrid of ANN and SVM, that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The SLM model will be fed training data from our existing database consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals.  Once trained, the SLM model will be able to predict the auditory consequences of exposure to any noise environment characterized by the noise metrics and biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/ histological data are available (Year 2). The training period will be an iterative process in which the SLM will be modified as training proceeds. The predictions of the SLM model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a statistical learning machine to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Model for prediction of noise-induced hearing loss,6878561,R01OH007801,"['chinchilla', 'computational neuroscience', 'computer program /software', 'computer system design /evaluation', 'mathematical model', 'model design /development', 'noise induced deafness', 'noise pollution']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R01,2005,139799,-0.0035586987826211783
"The RPI Exploratory Center for Cheminformatics(RMI) The purpose of this Exploratory Center for Cheminformatics Research (ECCR) P20 planning grant is to develop a mechanism for bringing together and stimulating collaborative pilot projects among a constantly-evolving nucleus of experts in Cheminformatics-related fields ranging from methods of encoding and capturing molecular information, to machine learning and data mining techniques, to predictive model development, validation, interpretation and utilization. In addition to these research efforts, the Center will bring together a set of domain specialists and application scientists who will serve as both data generators and end users of the knowledge provided by the molecular property models and modeling methods developed during the course of the grant. This group will also test the new Cheminformatics software that will constitute a tangible, deliverable product from this work. Ten application project modules that exemplify possible interactions between various groups and areas of expertise within the Center are presented as part of this proposal. The unifying vision behind the proposed Center is that much of what is done in each of the subdisciplines represented here can be expressed in a Cheminformatics context: The many diverse project areas can be grouped into one or more overlapping categories: ""Data Generators"" (those who use either theoretical or experimental methods for creating or extracting knowledge), ""Machine Learning and Datamining"" groups (who perform model validation, feature selection, pattern recognition, generation of potentials of mean force and knowledge-based potential work), as well as ""Property-Prediction"" groups (who perform chemically-aware model building, molecular property descriptor generation, Quantitative Structure-Property Relationship modeling, validation, and interpretation), and ""Application"" groups who utilize the information made available using the new tools and methods that are developed as part of the Center. It is our strong belief that these areas of expertise can be brought together within this Planning Grant proposal to generate something larger than the sum of the parts. The Exploratory Center will seed new interdisciplinary projects and train graduate students in these areas.   Relevance: Advances in the generation, mining and analysis of chemical information is crucial to the development of new drug therapies, and to modern methods of bioinformatics and molecular medicine. n/a",The RPI Exploratory Center for Cheminformatics(RMI),7032113,P20HG003899,"['Internet', 'bioinformatics', 'chemical models', 'cheminformatics', 'computer program /software', 'computers', 'data collection methodology /evaluation', 'data management', 'information retrieval', 'interdisciplinary collaboration', 'model design /development', 'molecular biology']",NHGRI,RENSSELAER POLYTECHNIC INSTITUTE,P20,2005,375639,0.004389960176241335
"Computer cluster for computational biology DESCRIPTION (provided by applicant):    The present application aims to establish a computer Cluster for Computational Biology and Bioinformatic (CCBB). The cluster will consists of 256 dual nodes connected with Giganet switches to enable rapid communication between the processors. The cluster will enable the integration of the two approaches and make it possible to effectively address the highly demanding computational tasks of the field. It will serve a small group of investigators, supported by the NIH, and their close collaborators. The hardware needs of computational biology and bioinformatic applications, and of the team of investigators listed in this application can be summarized as follows:   1. Significant computer power for complex and expensive simulations.   2. Large storage capacity for the whole cluster (shared) and (separately) for the individual nodes.   3. Large and rapidly accessible memory for effective statistical analysis, application of machine learning techniques, and biological discovery.   4. Fast network for information updates across the network.   In addition CCBB will have high level of databases and software integration including   1. Updates of important ""mirrors"" of shared databases (such as NR, swissprot, human EST, human genome, protein databank, etc.)   2. Local installation and frequent upgrade of widely used software packages (e.g. BLAST, Pfam, CHARMm etc.)   3. Help in porting novel software for optimal use on the CCBB hardware platform.   The combined unification of optimal hardware and software for computational biology and bioinformatic will make the new cluster; an outstanding resource for NIH related research n/a",Computer cluster for computational biology,6877645,S10RR020889,"['bioinformatics', 'biomedical equipment purchase', 'computational biology', 'computer network', 'computer program /software', 'computer system hardware', 'computers']",NCRR,CORNELL UNIVERSITY ITHACA,S10,2005,500000,0.0028761805853869645
"Nation Center: Multi-Scale Study- Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7012104,U54CA121852,"['bioinformatics', 'cell biology', 'computational biology', 'cooperative study', 'genome']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2005,3758967,0.013763224125104676
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7012638,R01EB006200,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biotechnology', 'charge coupled device camera', 'computer program /software', 'computer system hardware', 'high throughput technology', 'image enhancement', 'robotics']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2005,363523,-0.029107779443447324
"Use of Microarray Test Data for Toxicogenomic Prediction    DESCRIPTION (provided by applicant):    This project bridges the understanding between physical and chemical principles and genomic/proteomic response by integrating three independent parallel toxicity prediction tools. Each uses computational neural networks (CNNs) and wavelets to rapidly and accurately make pharmaceutical/chemical toxicity predictions. A CNN-based Quantitative Structure-Activity Relationship (QSAR) module makes toxicological predictions based only on structure-activity analyses; a second CNN/wavelet module makes independent toxicogenomic predictions using microarray data; and a third CNN/wavelet module makes toxicogenomic predictions using Massively Parallel Signature Sequencing (MPSS) data. This multi-intelligent, three-module approach provides crosschecks to reduce false positives and false negatives while substantially increasing confidence in predictions relative to current computer-based toxicity prediction techniques. The resulting product could potentially become a primary tool used by (a) human health researchers, b) pharmaceutical companies for screening drugs early during development, c) companies designing/developing new chemicals and chemically treated materials, and (d) government organizations (e.g., military) for mission-related chemical deployments. Public benefits include reduced health and environmental risks (e.g., 4 out of 5 chemicals in use today have inadequate testing); reduced reliance on animal testing; and reduced time and cost required to bring new pharmaceuticals and chemicals into beneficial medical and commercial use.            n/a",Use of Microarray Test Data for Toxicogenomic Prediction,6743871,R41ES013321,"['computational neuroscience', 'computer data analysis', 'evaluation /testing', 'method development', 'microarray technology', 'polymerase chain reaction', 'toxicant screening', 'toxicology']",NIEHS,"YAHSGS, LLC",R41,2004,211770,-0.006746547666740202
"BioMediator: Biologic Data Integration& Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration& Analysis System,6805962,R01HG002288,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'information retrieval', 'molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2004,100000,0.007298981059733793
"Neural network model of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using radial basis function neural network (RBFNN) that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The RBFNN model will be fed training data from our existing database (chinchilla) consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals. Once trained, the model will be able to predict the auditory consequences of exposure to any noise environment characterized by ten noise metrics and five biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/histological data are available (Year 2). The training period will be an iterative process in which the RBFNN will be modified as training proceeds. The prediction model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a RBFNN to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Neural network model of noise-induced hearing loss,6820323,R03OH008175,"['artificial intelligence', 'chinchilla', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'disease /disorder model', 'environmental exposure', 'model design /development', 'noise biological effect', 'noise induced deafness']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R03,2004,71000,-0.003526045960291434
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6777028,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,341671,-0.00048241606635071653
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6784554,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2004,522252,-0.005980522135794032
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6936159,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,52940,-0.00048241606635071653
"Development of Bioinformatic Tools for Virtual Cloning  DESCRIPTION (provided by applicant): The elaboration of the sequences of the human genome and those of many cellular and viral parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease. It has also resulted in the formation of an entirely new field, bioinformatics, which promises to manage and analyze the vast amount of data being generated. Bioinformatics needs to supply tools for data analysis and tools for experimental design. Most of the scientific and corporate resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology. Essentially every experiment in biology now begins with cloning one or more pieces of DNA. Commercial software that facilitates virtual DNA cloning does exist, but it lacks any automation features and depends on primitive and/or fragmentary gene and vector databases. It is inadequate in planning the hundreds or thousands of clones necessary to address questions posed by the proteomics initiatives, because the lack of knowledge integration. In Phase I of this SBIR grant, we have built and tested a virtual cloning expert system, along with a very useful gene database and a uniquely annotated vector database that serve as a knowledge base for automated DNA manipulations. A collection of automated cloning modules and databases is now functional. In Phase II we will complete the virtual cloning expert system and develop a flexible platform for automated experimental design, data management and analysis. We will also construct a user database, improve the user interface and establish security protocols. The results will be a complete program suite as a stable and marketable product. n/a",Development of Bioinformatic Tools for Virtual Cloning,6788945,R44HG003506,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computer assisted sequence analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'experimental designs', 'expression cloning', 'genetic library', 'high throughput technology', 'molecular biology information system', 'molecular cloning']",NHGRI,"VIRMATICS, LLC",R44,2004,375000,-0.0049426864483583235
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6736326,U01GM061374,"['artificial intelligence', 'biomedical resource', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'computer system hardware', 'cooperative study', 'drug interactions', 'drug metabolism', 'gene expression', 'genetic polymorphism', 'informatics', 'information dissemination', 'interactive multimedia', 'molecular biology information system', 'online computer', 'pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2004,337653,0.00369993684790317
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,6803809,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2004,20000,-0.01163597160134672
"Attractors of Complex Signal Transduction Systems   DESCRIPTION (provided by the applicant): Biochemical signal transduction is a        critical basic cellular process by which information travels from the receptors      on the surface of a cell to the nucleus where responses to the signals are           generated. Originally thought to be a relatively simple system that merely           passed along signals, signal transduction has proven to be a highly complicated      system of molecules whose interactions have yet to be fully understood.              Furthermore, a number of disease states such as cancer, diabetes, and                neurological disorders have their origins in malfunctioning signal transduction      components. Until signal transduction is understood in its totality, rational        intervention of these diseases will be significantly hampered. While                 conventional laboratory methods have been used to study individual components        or pathways involved in signal transduction, they have less utility in studying      how signal transduction systems work as a whole and therefore do not detect          higher levels or organization and regulation that are known to exist in other        complex systems. In this application, it is proposed that signal transduction        systems be mathematically modeled and analyzed in order to determine the role        of complexity in the system. It is hypothesized that signal transduction             involves both the movement and processing of information in such a way as to         provide a cell the capacity for decision making, something every cell must           possess at some level. The most advanced techniques in the field of chaos            theory and neural networks (the basis of artificial intelligence) will be            applied to determine whether biochemical signal transduction systems have the        fundamental features of a complex system, how those features might be used for       cell level decision making, and how mutations in the system might affect the         higher level functions of the system. The elucidation of such higher levels of       function in signal transduction systems would greatly enhance our understanding      of this basic cellular function and make the rational design of therapy more         effective.                                                                                                                                                                n/a",Attractors of Complex Signal Transduction Systems,6745076,R01GM067272,"['biological information processing', 'biological signal transduction', 'computational neuroscience', 'computer simulation', 'mathematical model', 'mathematics', 'model design /development']",NIGMS,UNIVERSITY OF NEBRASKA OMAHA,R01,2004,314225,-0.020326080116183285
"Model for prediction of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using a statistical learning machine (SLM), which includes an artificial neural network (ANN), a support vector machine (SVM), and a hybrid of ANN and SVM, that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The SLM model will be fed training data from our existing database consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals.  Once trained, the SLM model will be able to predict the auditory consequences of exposure to any noise environment characterized by the noise metrics and biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/ histological data are available (Year 2). The training period will be an iterative process in which the SLM will be modified as training proceeds. The predictions of the SLM model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a statistical learning machine to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Model for prediction of noise-induced hearing loss,6753927,R01OH007801,"['chinchilla', 'computational neuroscience', 'computer program /software', 'computer system design /evaluation', 'mathematical model', 'model design /development', 'noise induced deafness', 'noise pollution']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R01,2004,138439,-0.0035586987826211783
"BioMediator: Biologic Data Integration & Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration & Analysis System,6681249,R01HG002288,"['artificial intelligence', ' bioengineering /biomedical engineering', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' information retrieval', ' molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2003,100000,0.007298981059733793
"Development of Bioinformatic Tools for Virtual Cloning    DESCRIPTION (provided by applicant): The ability to delineate (at least in theory) all the proteins encoded in the human genome and all of those encoded by the genomes of major human parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease.  However, the vast increase in biological knowledge that has resulted from the last decade of genomic DNA sequencing has led us to a a crisis in bioinformatics.  This crisis is two-fold: analysis of data and planning of experiments.  Most of the scientific resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology.  All modern experimental molecular biology (and, increasingly, structural biology) depends upon the availability of plasmid clones to address specific scientific questions.  Although software facilitating DNA manipulations exists, few programs advise users of optimal strategies and none automate the process of clone generation. Genomics initiatives identify proteins at the genome level and demand the generation of hundreds of expression clones for recombinant protein production in exogenous hosts such as E. coli.  Establishment of libraries of expression clones requires automation and optimization as well as effective means of data storage, archiving, annotation and query.  To address these needs, as well as to facilitate routine DNA manipulations in virtually any molecular biology laboratory, we propose (1) to test and build a task centered virtual cloning expert system that serves as a knowledge base for DNA manipulations, and (2) to test and build an information automaton for the construction of expression clone libraries in support of structural genomics initiatives and other high throughput experiments.         n/a",Development of Bioinformatic Tools for Virtual Cloning,6583437,R43GM067279,"['artificial intelligence', ' biomedical automation', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' expression cloning', ' gene expression', ' genetic library', ' genetic manipulation', ' informatics', ' molecular biology information system', ' transfection /expression vector']",NIGMS,"VIRMATICS, LLC",R43,2003,100000,-0.022628074215161373
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6694513,R01GM056529,"['artificial intelligence', ' biochemistry', ' computer program /software', ' computer system design /evaluation', ' dementia', ' enzyme mechanism', ' functional /structural genomics', ' information system analysis', ' mathematical model', ' molecular biology information system', ' molecular dynamics', ' physiology', ' protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2003,556670,-0.005980522135794032
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6685421,R01GM061372,"['Internet', ' artificial intelligence', ' automated data processing', ' biological signal transduction', ' biomedical automation', ' computer system design /evaluation', ' functional /structural genomics', ' high throughput technology', ' intermolecular interaction', ' method development', ' molecular biology information system', ' statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,323936,-0.00048241606635071653
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6636465,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2003,327818,0.00369993684790317
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6738628,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2003,159000,0.00369993684790317
"MCASE QSAR Expert System for Salmonella Mutagenicity   DESCRIPTION (provided by applicant): Computational expert systems provide an         inexpensive and fast alternative to short term genotoxicity assays such as the       Ames test. Validation studies show the predictive capability of the MCASE            system is about 85 percent. That is, 85 percent concordance is expected between      experiment and computational genotoxicity predictions for new chemicals. The         strong correlation between chemical structure and genotoxicity is particularly       useful for 'in silico' prescreening of new drugs in the pharmaceutical               industry.                                                                                                                                                                 The new Salmonella database modules being developed in this work will be made        available online to the public through the InfoTox web site                          (http://www.l-tox.com). Additionally, NIH grantees will be allowed unlimited         access to the Salmonella modules through InfoTox at no cost.                                                                                                              Collaboration will be sought with large drug companies, with mutual exchange of      data. Thus the databases will evolve and improve over time as new data are           submitted to form a centralized pool of mutagenicity data, that will provide a       resource for avoiding unneeded testing of chemicals structurally similarly to        those that are already thoroughly understood. Our collaborators at the FDA/CDER      will lead the effort to build this industrial consortium.                            PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                                                   n/a",MCASE QSAR Expert System for Salmonella Mutagenicity,6625981,R44CA090178,"['Salmonella typhimurium', ' alternatives to animals in research', ' artificial intelligence', ' chemical information system', ' chemical property', ' chemical structure function', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data collection', ' gene mutation', ' high throughput technology', ' informatics', ' mathematical model', ' mutagen testing', ' mutagens', ' physical property', ' statistics /biometry', ' toxicology']",NCI,"MULTICASE, INC.",R44,2003,278750,-0.018841175123361132
"Toxicological Evaluation Neuralnet Tools (TENT)  DESCRIPTION (provided by applicant):  YAHSGS' Toxicological Evaluation Neuralnet Tools (TEND is designed to advance the state-of-the-art in the prediction of toxicological end points for new or untested chemicals, drugs, and compounds. TENT deploys computational neural nets (CNN), innovative computational chemistry methods, and modem statistical regression methods into interactive modules that determine (a) a chemical's 3-D structure and physical chemistry properties, (b) Quantitative Structure Activity Relationships, (C) mechanistic modes leading to toxicological responses via microassay database analysis, and (d) a broad spectrum of toxicological properties via CNN 3-D structural similarity analyses. TENTs output includes physical chemistry properties, 3-D structure, predicted toxicological impacts, and confidence level associated with each. It is anticipated that TENT will become one of the primary tools used by (a) researchers in human health and toxicological fields, (b) pharmaceutical companies to screen out drugs early in the development process prior to expending hundreds of millions on clinical in vivo and in vitro testing, (C) by companies developing new chemicals, chemical compounds, and chemically treated materials to determine potential toxicological impacts including those caused by environmental changes during and after usage, (d) companies striving to show compliance with ISO 14000 for materials used in their products, and (e) federal and military organizations for chemicals and materials contemplated for use in their mission areas. Industry experts predict that the market for TENT-type tools and applications will reach $8 -$10 billion by 2006 and three times that amount by 2016. The benefits that the US should receive from TENT could include (a) a greatly enhanced understanding of potential toxicological impacts from pharmaceuticals, chemicals, and chemically treated materials (4 out of 5 chemicals in industrial use currently have not undergone adequate testing due to time and expense), (b) companies will avoid billions of dollars in clinical testing for chemicals and drugs that ultimately fail (the funds saved can be applied to the development of new and better materials that help mankind and the environment that might otherwise go unfunded), and (c) TENT can substantially reduce the number of laboratory animals used for clinical testing.   n/a",Toxicological Evaluation Neuralnet Tools (TENT),6550075,R43ES011918,"['alternatives to animals in research', ' chemical structure function', ' computational neuroscience', ' computer program /software', ' computer simulation', ' method development', ' microarray technology', ' molecular dynamics', ' neurotoxicology', ' statistics /biometry', ' three dimensional imaging /topography', ' toxicant screening']",NIEHS,"YAHSGS, LLC",R43,2003,84450,-0.006208835695318685
"Attractors of Complex Signal Transduction Systems   DESCRIPTION (provided by the applicant): Biochemical signal transduction is a        critical basic cellular process by which information travels from the receptors      on the surface of a cell to the nucleus where responses to the signals are           generated. Originally thought to be a relatively simple system that merely           passed along signals, signal transduction has proven to be a highly complicated      system of molecules whose interactions have yet to be fully understood.              Furthermore, a number of disease states such as cancer, diabetes, and                neurological disorders have their origins in malfunctioning signal transduction      components. Until signal transduction is understood in its totality, rational        intervention of these diseases will be significantly hampered. While                 conventional laboratory methods have been used to study individual components        or pathways involved in signal transduction, they have less utility in studying      how signal transduction systems work as a whole and therefore do not detect          higher levels or organization and regulation that are known to exist in other        complex systems. In this application, it is proposed that signal transduction        systems be mathematically modeled and analyzed in order to determine the role        of complexity in the system. It is hypothesized that signal transduction             involves both the movement and processing of information in such a way as to         provide a cell the capacity for decision making, something every cell must           possess at some level. The most advanced techniques in the field of chaos            theory and neural networks (the basis of artificial intelligence) will be            applied to determine whether biochemical signal transduction systems have the        fundamental features of a complex system, how those features might be used for       cell level decision making, and how mutations in the system might affect the         higher level functions of the system. The elucidation of such higher levels of       function in signal transduction systems would greatly enhance our understanding      of this basic cellular function and make the rational design of therapy more         effective.                                                                                                                                                                n/a",Attractors of Complex Signal Transduction Systems,6774537,R01GM067272,"['biological information processing', ' biological signal transduction', ' computational neuroscience', ' computer simulation', ' mathematical model', ' mathematics', ' model design /development']",NIGMS,UNIVERSITY OF NEBRASKA OMAHA,R01,2003,89424,-0.020326080116183285
"Attractors of Complex Signal Transduction Systems   DESCRIPTION (provided by the applicant): Biochemical signal transduction is a        critical basic cellular process by which information travels from the receptors      on the surface of a cell to the nucleus where responses to the signals are           generated. Originally thought to be a relatively simple system that merely           passed along signals, signal transduction has proven to be a highly complicated      system of molecules whose interactions have yet to be fully understood.              Furthermore, a number of disease states such as cancer, diabetes, and                neurological disorders have their origins in malfunctioning signal transduction      components. Until signal transduction is understood in its totality, rational        intervention of these diseases will be significantly hampered. While                 conventional laboratory methods have been used to study individual components        or pathways involved in signal transduction, they have less utility in studying      how signal transduction systems work as a whole and therefore do not detect          higher levels or organization and regulation that are known to exist in other        complex systems. In this application, it is proposed that signal transduction        systems be mathematically modeled and analyzed in order to determine the role        of complexity in the system. It is hypothesized that signal transduction             involves both the movement and processing of information in such a way as to         provide a cell the capacity for decision making, something every cell must           possess at some level. The most advanced techniques in the field of chaos            theory and neural networks (the basis of artificial intelligence) will be            applied to determine whether biochemical signal transduction systems have the        fundamental features of a complex system, how those features might be used for       cell level decision making, and how mutations in the system might affect the         higher level functions of the system. The elucidation of such higher levels of       function in signal transduction systems would greatly enhance our understanding      of this basic cellular function and make the rational design of therapy more         effective.                                                                                                                                                                n/a",Attractors of Complex Signal Transduction Systems,6640799,R01GM067272,"['biological information processing', ' biological signal transduction', ' computational neuroscience', ' computer simulation', ' mathematical model', ' mathematics', ' model design /development']",NIGMS,UNIVERSITY OF NEBRASKA OMAHA,R01,2003,208750,-0.020326080116183285
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6636516,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2003,374063,-0.0033244623413216166
"Improving Quantum Chemistry Calculations DESCRIPTION (provided by applicant): We propose to extend the functionality of our commercial quantum chemistry program, Q-Chem, to effectively treat molecules containing transition metals. This enhanced capability will provide Q-Chem's end-users with the ability to accurately model complex molecules such as proteins, enzymes, and catalysts of industrial importance. While remarkable progress has been made over the last several years in the accurate modeling of systems containing transition metals, current numerical methods for achieving SCF convergence in these systems are problematic at best, resulting in long execution times or, in some cases, complete failure to find a solution. However, a novel computational technique developed at Q-Chem has been shown to dramatically improve convergence for organic molecules with known SCF convergence problems. We propose to adapt this method for use with transition metals. Our goal is to achieve the same robust SCF convergence that is realized for most organic molecules, thereby greatly increasing productivity and extending the capability of scientists to study molecules such as enzymes and industrial catalysts. During Phase (I, our efforts will be to further extend Q-Chem's capability in the molecular biology arena. This proposal seeks to improve the quantum chemical treatment of molecular systems containing transition metals. Transition metal elements are essential to natural biological processes. The technology developed in this research will enable the computer modeling of those systems that are difficult to handle with the current methodologies and therefore increase of the applications of computational modeling. PROPOSED COMMERCIAL APPLICATION: Transition-metal elements play a vital role in biological systems.  The success of this project will improve the performance of modeling of transition-metal complexes and making the modelings possible for the systems that current algorithms fail.  The resulting work will be made available to researchers in health industry and universities through our commercial software Q-Chem. n/a",Improving Quantum Chemistry Calculations,6484828,R43GM065617,"['artificial intelligence', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' heavy metals', ' mathematical model', ' mathematics', ' model design /development', ' quantum chemistry']",NIGMS,"Q-CHEM, INC.",R43,2002,109642,-7.841326504973373e-05
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6520265,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2002,318270,0.00369993684790317
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6649647,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2002,232118,0.00369993684790317
"MCASE QSAR Expert System for Salmonella Mutagenicity   DESCRIPTION (provided by applicant): Computational expert systems provide an         inexpensive and fast alternative to short term genotoxicity assays such as the       Ames test. Validation studies show the predictive capability of the MCASE            system is about 85 percent. That is, 85 percent concordance is expected between      experiment and computational genotoxicity predictions for new chemicals. The         strong correlation between chemical structure and genotoxicity is particularly       useful for 'in silico' prescreening of new drugs in the pharmaceutical               industry.                                                                                                                                                                 The new Salmonella database modules being developed in this work will be made        available online to the public through the InfoTox web site                          (http://www.l-tox.com). Additionally, NIH grantees will be allowed unlimited         access to the Salmonella modules through InfoTox at no cost.                                                                                                              Collaboration will be sought with large drug companies, with mutual exchange of      data. Thus the databases will evolve and improve over time as new data are           submitted to form a centralized pool of mutagenicity data, that will provide a       resource for avoiding unneeded testing of chemicals structurally similarly to        those that are already thoroughly understood. Our collaborators at the FDA/CDER      will lead the effort to build this industrial consortium.                            PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                                                   n/a",MCASE QSAR Expert System for Salmonella Mutagenicity,6481789,R44CA090178,"['Salmonella typhimurium', ' alternatives to animals in research', ' artificial intelligence', ' chemical information system', ' chemical property', ' chemical structure function', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data collection', ' gene mutation', ' high throughput technology', ' informatics', ' mathematical model', ' mutagen testing', ' mutagens', ' physical property', ' statistics /biometry', ' toxicology']",NCI,"MULTICASE, INC.",R44,2002,359495,-0.018841175123361132
"Attractors of Complex Signal Transduction Systems   DESCRIPTION (provided by the applicant): Biochemical signal transduction is a        critical basic cellular process by which information travels from the receptors      on the surface of a cell to the nucleus where responses to the signals are           generated. Originally thought to be a relatively simple system that merely           passed along signals, signal transduction has proven to be a highly complicated      system of molecules whose interactions have yet to be fully understood.              Furthermore, a number of disease states such as cancer, diabetes, and                neurological disorders have their origins in malfunctioning signal transduction      components. Until signal transduction is understood in its totality, rational        intervention of these diseases will be significantly hampered. While                 conventional laboratory methods have been used to study individual components        or pathways involved in signal transduction, they have less utility in studying      how signal transduction systems work as a whole and therefore do not detect          higher levels or organization and regulation that are known to exist in other        complex systems. In this application, it is proposed that signal transduction        systems be mathematically modeled and analyzed in order to determine the role        of complexity in the system. It is hypothesized that signal transduction             involves both the movement and processing of information in such a way as to         provide a cell the capacity for decision making, something every cell must           possess at some level. The most advanced techniques in the field of chaos            theory and neural networks (the basis of artificial intelligence) will be            applied to determine whether biochemical signal transduction systems have the        fundamental features of a complex system, how those features might be used for       cell level decision making, and how mutations in the system might affect the         higher level functions of the system. The elucidation of such higher levels of       function in signal transduction systems would greatly enhance our understanding      of this basic cellular function and make the rational design of therapy more         effective.                                                                                                                                                                n/a",Attractors of Complex Signal Transduction Systems,6583980,R01GM067272,"['biological information processing', ' biological signal transduction', ' computational neuroscience', ' computer simulation', ' mathematical model', ' mathematics', ' model design /development']",NIGMS,UNIVERSITY OF NEBRASKA OMAHA,R01,2002,209000,-0.020326080116183285
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6520333,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2002,363261,-0.0033244623413216166
"Functional Genomics Software   DESCRIPTION (Applicant's abstract): A substantial commercial potential exists        for software tools that allow a biomedical research scientist to use genomic         data to form experimentally testable hypotheses. These will be used to exploit       genomic sequence data to understand the aetiology of disease, to improve             diagnostic tools, and to develop more effective therapies. The Master Catalog,       a commercial product developed jointly by EraGen Biosciences and the Benner          laboratory at the University of Florida, provides a convenient framework for         implementing heuristics that do this. The Master Catalog is a naturally              organized database that contains evolutionary trees, multiple sequence               alignments, and reconstructed evolutionary intermediates for all of the              proteins in the GenBank database. The Benner laboratory has developed and            anecdotally tested heuristics that date events in the molecular history,             provide evidence for and against functional recruitment within a protein             family, detect distant homologs, associate individual residues important for         functional changes with a crystal structure, find metabolic and regulatory           pathways, and correlate events in the molecular record with the history of life      on Earth. This Phase I proposal seeks to validate a set of these heuristics          more broadly to determine their suitability for database-wide application. In        Phase II, we will implement these within the Master Catalog, and launch a            commercial bioinformatics product to support functional analysis of genomic          databases.                                                                           PROPOSED COMMERCIAL APPLICATION:  In its present version, the Master Catalog is a successful commercial product within a  niche: ""best in class"" of bioinformatics databases.  Adding a validated set of heuristics  for extracting functional information from genome databases will make it the software  of choice for most functional genomics work, and be a central tool in the pharmaceutical/  biotechnology industries.  Academic versions and student versions will find markets in most  universities.                                                                                      n/a",Functional Genomics Software,6337786,R41HG002331,"['artificial intelligence', ' biochemical evolution', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' functional /structural genomics', ' informatics', ' molecular biology information system', ' nucleic acid sequence']",NHGRI,"ERAGEN BIOSCIENCES, INC.",R41,2001,96855,-0.023229541522340653
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6495900,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2001,35096,0.00369993684790317
BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN       n/a,BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN,6351629,R29LM006233,"['artificial intelligence', ' automated medical record system', ' behavioral /social science research tag', ' belief', ' computer assisted medical decision making', ' computer assisted patient care', ' computer system design /evaluation', ' health care facility information system', ' health services research tag', ' human data', ' patient care management']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R29,2001,106893,0.004279135244735239
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6387173,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2001,309000,0.00369993684790317
"PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS DESCRIPTION (Taken from application abstract):  Over the last decade             computational modeling has become central to neurobiology.  While much of        this work has focused on cellular and sub-cellular processes, the last few       years have seen increasing interest in systems level models and in               integrative accounts that span data from the subcellular to behavioral           levels.  Our proposal, in summary, is to extend existing work in parallel        discrete event simulation (PDES) and integrate it with existing work on          compartmental modeling environments, to produce a software environment which     has comprehensive support for modeling large scale, highly structured            networks of biophysically realistic cells; and which can efficiently exploit     the full range of parallel platforms, including the largest parallel             supercomputers, for simulation of these network models, which integrate          information about the nervous system from sub-cellular to the whole-brain        level.  Because of the scale of the models needed at this level of               integration, advanced parallel computing is required.  The critical              technical insight upon which this work rests is that neuronal modeling at        the systems level can often be reduced to a form of discrete event               simulation in which single cells are node functions and voltage spikes are       events.                                                                                                                                                           Three neuroscience modeling projects, will mold, test, and utilize these new     capabilities in investigations of system-level models of the nervous system      which integrate behavioral, anatomical and physiological data on a scale         that exceeds current simulation capabilities.  In collaboration with             computer scientists at Pittsburgh Supercomputing Center and UCLA,                neuroscientists at University of Virginia, the Born-Bunge Foundation,            Antwerp, and the Salk Institute, and developers of the NEURON and GENESIS        packages, these tools will be developed and made available to the                neuroscience community.  The software development aims include 1)                investigation of a portable, PDES system capable of running efficiently on       diverse parallel platforms, 2) development of interfaces to the PDES for         NEURON and GENESIS allowing models developed in those packages to be scaled      up, 3) investigation of a network specification language for neuronal            models, and associated a visualization interface, to facilitate                  investigation of systems-level models, 4) sufficiently robust and                well-documented software for download and installation at other sites.  The      three neuroscience projects will guide development of the software tools and     use the tools for investigation of large-scale models of cerebellum,             hippocampus and thalamocortical circuits.                                         n/a",PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS,6392266,R01MH057358,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biotechnology', ' cerebellar cortex', ' computational neuroscience', ' computer network', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' hippocampus', ' mathematical model', ' neural information processing', ' neurotransmitters', ' parallel processing', ' supercomputer', ' thalamocortical tract', ' vocabulary development for information system']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2001,232139,-0.007249730135289692
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6484619,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2001,337739,-0.0033244623413216166
BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN DESCRIPTION (Taken from application abstract):  Reminder systems are expert       n/a,BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN,6151393,R29LM006233,"['artificial intelligence', ' automated medical record system', ' behavioral /social science research tag', ' belief', ' computer assisted medical decision making', ' computer assisted patient care', ' computer system design /evaluation', ' health care facility information system', ' health services research tag', ' human data', ' patient care management']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R29,2000,103781,-0.036448030048291016
"PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS DESCRIPTION (Taken from application abstract):  Over the last decade             computational modeling has become central to neurobiology.  While much of        this work has focused on cellular and sub-cellular processes, the last few       years have seen increasing interest in systems level models and in               integrative accounts that span data from the subcellular to behavioral           levels.  Our proposal, in summary, is to extend existing work in parallel        discrete event simulation (PDES) and integrate it with existing work on          compartmental modeling environments, to produce a software environment which     has comprehensive support for modeling large scale, highly structured            networks of biophysically realistic cells; and which can efficiently exploit     the full range of parallel platforms, including the largest parallel             supercomputers, for simulation of these network models, which integrate          information about the nervous system from sub-cellular to the whole-brain        level.  Because of the scale of the models needed at this level of               integration, advanced parallel computing is required.  The critical              technical insight upon which this work rests is that neuronal modeling at        the systems level can often be reduced to a form of discrete event               simulation in which single cells are node functions and voltage spikes are       events.                                                                                                                                                           Three neuroscience modeling projects, will mold, test, and utilize these new     capabilities in investigations of system-level models of the nervous system      which integrate behavioral, anatomical and physiological data on a scale         that exceeds current simulation capabilities.  In collaboration with             computer scientists at Pittsburgh Supercomputing Center and UCLA,                neuroscientists at University of Virginia, the Born-Bunge Foundation,            Antwerp, and the Salk Institute, and developers of the NEURON and GENESIS        packages, these tools will be developed and made available to the                neuroscience community.  The software development aims include 1)                investigation of a portable, PDES system capable of running efficiently on       diverse parallel platforms, 2) development of interfaces to the PDES for         NEURON and GENESIS allowing models developed in those packages to be scaled      up, 3) investigation of a network specification language for neuronal            models, and associated a visualization interface, to facilitate                  investigation of systems-level models, 4) sufficiently robust and                well-documented software for download and installation at other sites.  The      three neuroscience projects will guide development of the software tools and     use the tools for investigation of large-scale models of cerebellum,             hippocampus and thalamocortical circuits.                                         n/a",PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS,6186179,R01MH057358,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biotechnology', ' cerebellar cortex', ' computational neuroscience', ' computer network', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' hippocampus', ' mathematical model', ' neural information processing', ' neurotransmitters', ' parallel processing', ' supercomputer', ' thalamocortical tract', ' vocabulary development for information system']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2000,234591,-0.007249730135289692
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6132622,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2000,300000,0.00369993684790317
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6323962,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2000,186611,0.00369993684790317
"THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE We propose to create the Stanford PharmacoGenetic Knowledge Base (PharmGKB), an integrated data resource to support the NIGMS Pharmacogenetic Research Network and Database Initiative.  This initiative will focus on how genetic variation contributes to variation in the response to drugs, and will produce data from a wide range of sources.  The PharmGKB will therefore interlink genomic, molecular, cellular and clinical information about gene systems important for modulating drug responses.  The PharmGKB is based on a powerful hierarchical data representation system that allows the data model to change as new knowledge is learned, while ensuring the security and stability of the data with a relational database foundation.  Our proposal defines an interactive process for defining a data model, creating automated systems for data submission, integrating the PharmGKB with other biological and clinical data resources, and creating a robust interface to the data and to the associated analytic tools. Finally, we outline a research plan that uses the PharmGKB to (1) address difficult data modeling challenges that arise in the course of building the resource, (2) study the user interface requirements of a database with such a wide range of information sources, and (3) model and analyze the structural variations of proteins to shed light on the molecular consequences of genetic variation.  The PharmGKB will respect the absolute confidentiality of genetic information from individuals.  n/a",THE STANFORD PHARMACOGENETICS KNOWLEDGE BASE,6344145,U01GM061374,"['artificial intelligence', ' biomedical resource', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' cooperative study', ' drug interactions', ' drug metabolism', ' gene expression', ' genetic polymorphism', ' informatics', ' information dissemination', ' interactive multimedia', ' molecular biology information system', ' online computer', ' pharmacogenetics']",NIGMS,STANFORD UNIVERSITY,U01,2000,141192,0.00369993684790317
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6193019,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN,R01,2000,478050,-0.0033244623413216166
"MegaPredict for predicting natural product uses and their drug interactions Project Summary The objective of ‘MegaPredict’ is to enable scientists to generate predictions for a natural product (or any molecule) and identify targets for efficacy assessment as well as identify any potential liabilities. We are building on our previous work which has compiled a comprehensive collection of datasets for structure-activity data for a broad variety of disease targets and other properties, in a form ready for model building. All of these models utilize the many sources of curated open data, including ChEMBL, ToxCast etc. We have developed a prototype of MegaPredict that utilizes Bayesian algorithm and ECFP6 fingerprints to output a list of prioritized ‘targets’. We realize that neither the algorithm or the descriptors may be optimal therefore we propose to address this as we validate MegaPredict and develop a product over this proposal. Our team is suitably qualified to develop the software needed and we will leverage our large collaborator network to assist us in validating the activity of compounds. We will initially create a script to take a natural product and score it against many thousands of machine learning models then rank the outputs to propose efficacy targets. We will use over 12,000 ChEMBL derived target-assay / bioactivity groups extracted from the ChEMBL v24 database, as well as EPA Tox21 measurements and other public datasets, using methodology that we have already partially developed. We can repeat this process for over 200 published compounds and access the outputs versus what is known. We intend to compare how the approach performs with synthetic drugs or drug-like compounds as well as natural products. We will assess whether other machine learning algorithms and molecular descriptors can improve predictions. As we generate machine learning models such as Linear Logistic Regression, AdaBoost Decision Tree, Random Forest, Support Vector Machine and deep neural networks (DNN) of varying depth we will assess the predictions for natural products and compare with the Bayesian approach. We will compare ECFP6 with other 2D, 3D descriptors and physicochemical properties in order to identify the optimal combination for generating predictions for natural products and compare how this differs for synthetic compounds. We will validate our predictions for natural product efficacy assessment. We will work closely with multiple academic groups to generate predictions for at least 20 natural products of interest against over 20 different targets or diseases. Our goal will be to identify potential targets that were previously unknown and then generate in vitro data inhouse or with academic collaborators. Develop a prototype user interface for input of a structure, processing an input molecule and output of prioritized targets and liabilities. We have developed multiple software prototypes (e. Assay Central, MegaTox, etc.) previously and will ensure a user-friendly interface and develop new visualization methods and algorithms for prioritizing potential predicted targets based on the outputs of thousands of machine learning models. In Phase I, we will use the software internally with collaborators to rapidly prototype it. In Phase II we will develop a commercial product, and greatly expand our validation by building a larger network of academic and industry partners that would help to prioritize features of most relevance. Using the machine learning models which we have for natural products is limited because ECFP6 fingerprints cannot distinguish between these very different classes of molecules. But this provides us with an opportunity by going for a ""pharmacophore"" style approach (ideally without using 3D conformations directly). We will therefore focus on developing a ‘3D shape-based fingerprint’ or developing a novel ‘2D fingerprint’ that captures the ‘3D shape’ for natural- and druglike molecules. Currently, the public datasets in ChEMBL and PubChem etc. are made up of mostly druglike molecules, but if we have fingerprints that can compare drug-like and natural product-like molecules then we can likely reliably use our MegaPredict models for natural products as well. We can also attempt to rank natural products with our ChEMBL models or we can look through catalogs of druglike compounds using models derived from natural products. That would be an important innovation. Additionally, in Phase II it would be important to see if we could find uses for natural products with any of the 7000 rare diseases. Developing software that predicts potential natural product drug interactions with various targets could be useful to regulatory organizations as well as the pharmaceutical industry and may broaden utility of being able to more effectively mix natural product and druglike compounds in models will have a profound effect on the value of cheminformatics in this arena. Project Narrative Natural products have long been a source of therapeutics for human healthcare. Yet, some of the challenges with developing natural product treatments are identifying potential human disease related targets and avoiding others that might lead to undesirable natural product-drug interactions. Now there is considerable data in the public domain for millions of molecules with thousands of targets and ADME/T related properties that it is possible to use a suite of machine learning models for prospective prediction and profiling of a molecule’s properties from structure alone. We aim to build on our preliminary efforts to date to create a prototype for MegaPredict using various machine learning models which will enable academic and industrial scientists to generate predictions for a natural product or any molecule of interest and identify potential targets for efficacy and toxicity liability assessment. We will experimentally validate these predictions in-house or through our network of collaborators.",MegaPredict for predicting natural product uses and their drug interactions,10055938,R43AT010585,"['3-Dimensional', 'Address', 'Algorithms', 'Bayesian Method', 'Bayesian learning', 'Biological Assay', 'Catalogs', 'Chemical Models', 'Chemistry', 'Collection', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Decision Trees', 'Descriptor', 'Disease', 'Drug Industry', 'Drug Interactions', 'Drug Targeting', 'Ensure', 'Fingerprint', 'G-Protein-Coupled Receptors', 'Goals', 'Healthcare', 'Human', 'In Vitro', 'Industrialization', 'Lead', 'Literature', 'Logistic Regressions', 'Machine Learning', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Natural Product Drug', 'Natural Products', 'Output', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Phosphotransferases', 'Process', 'Property', 'PubChem', 'Public Domains', 'Publishing', 'Rare Diseases', 'Running', 'Scientist', 'Shapes', 'Software Tools', 'Source', 'Structure', 'Testing', 'Therapeutic', 'Toxic effect', 'Validation', 'Viral', 'Visualization', 'Work', 'base', 'cheminformatics', 'commercial application', 'deep neural network', 'drug discovery', 'human disease', 'improved', 'in vivo', 'industry partner', 'innovation', 'interest', 'machine learning algorithm', 'machine learning method', 'model building', 'novel', 'open data', 'pharmacophore', 'predictive modeling', 'predictive tools', 'process repeatability', 'prospective', 'prototype', 'random forest', 'software development', 'statistics', 'support vector machine', 'symposium', 'synthetic drug', 'tool', 'user-friendly', 'web interface', 'web-based tool']",NCCIH,"COLLABORATIONS PHARMACEUTICALS, INC.",R43,2020,155686,-0.020567816531801533
"Machine learning approaches for improved accuracy and speed in sequence annotation Summary/Abstract Alignment of biological sequences is a key step in understanding their evolution, function, and patterns of activity. Here, we describe Machine Learning approaches to improve both accuracy and speed of highly- sensitive sequence alignment. To improve accuracy, we develop methods to reduce erroneous annotation caused by (1) the existence of low complexity and repetitive sequence and (2) the overextension of alignments of true homologs into unrelated sequence. We describe approaches based on both hidden Markov models and Artificial Neural Networks to dramatically reduce these sorts of sequence annotation error. We also address the issue of annotation speed, with development of a custom Deep Learning architecture designed to very quickly filter away large portions of candidate sequence comparisons prior to the relatively-slow sequence-alignment step. The results of these efforts will be incorporated into forks of the open source sequence alignment tools HMMER, MMSeqs, and (where appropriate) BLAST; we will also work with community developers of annotation pipelines, such as RepeatMasker and IMG/M, to incorporate these approaches. The development and incorporation into these widely used bioinformatics tools will lead to widespread impact on sequence annotation efforts. Narrative Modern molecular biology depends on effective methods for creating sequence alignments quickly and accurately. This proposal describes a plan to develop novel Machine Learning approaches that will dramatically increase the speed of highly-sensitive sequence alignment, and will also address two significant sources of erroneous sequence annotation, (i) the presence of repetitive sequence in biological sequences, and (ii) the tendency for sequence alignment algorithms to extend alignments beyond the boundaries of true homology. The proposed methods represent a mix of applications of hidden Markov models and Artificial Neural Networks, and build on prior success in applying such methods to the problem of sensitive sequence annotation.",Machine learning approaches for improved accuracy and speed in sequence annotation,10020995,R01GM132600,"['Address', 'Algorithms', 'Architecture', 'Bioinformatics', 'Biological', 'Classification', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Custom', 'DNA Transposable Elements', 'Data Set', 'Deletion Mutation', 'Descriptor', 'Development', 'Error Sources', 'Evolution', 'Foundations', 'Genome', 'Genomics', 'Hour', 'Human', 'Human Genome', 'Industry Standard', 'Insertion Mutation', 'Institutes', 'Intervention', 'Joints', 'Label', 'Letters', 'Licensing', 'Machine Learning', 'Manuals', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Molecular Biology', 'Network-based', 'Nucleotides', 'Pattern', 'Pilot Projects', 'Proteins', 'Repetitive Sequence', 'Sequence Alignment', 'Sequence Analysis', 'Source', 'Speed', 'Statistical Models', 'Takifugu', 'Work', 'annotation  system', 'artificial neural network', 'base', 'bioinformatics tool', 'computing resources', 'convolutional neural network', 'deep learning', 'density', 'design', 'genomic data', 'improved', 'markov model', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'software development', 'statistics', 'success', 'tool']",NIGMS,UNIVERSITY OF MONTANA,R01,2020,287504,-0.02923790451955877
"Opening the Black Box of Machine Learning Models Project Summary Biomedical data is vastly increasing in quantity, scope, and generality, expanding opportunities to discover novel biological processes and clinically translatable outcomes. Machine learning (ML), a key technology in modern biology that addresses these changing dynamics, aims to infer meaningful interactions among variables by learning their statistical relationships from data consisting of measurements on variables across samples. Accurate inference of such interactions from big biological data can lead to novel biological discoveries, therapeutic targets, and predictive models for patient outcomes. However, a greatly increased hypothesis space, complex dependencies among variables, and complex “black-box” ML models pose complex, open challenges. To meet these challenges, we have been developing innovative, rigorous, and principled ML techniques to infer reliable, accurate, and interpretable statistical relationships in various kinds of biological network inference problems, pushing the boundaries of both ML and biology. Fundamental limitations of current ML techniques leave many future opportunities to translate inferred statistical relationships into biological knowledge, as exemplified in a standard biomarker discovery problem – an extremely important problem for precision medicine. Biomarker discovery using high-throughput molecular data (e.g., gene expression data) has significantly advanced our knowledge of molecular biology and genetics. The current approach attempts to find a set of features (e.g., gene expression levels) that best predict a phenotype and use the selected features, or molecular markers, to determine the molecular basis for the phenotype. However, the low success rates of replication in independent data and of reaching clinical practice indicate three challenges posed by current ML approach. First, high-dimensionality, hidden variables, and feature correlations create a discrepancy between predictability (i.e., statistical associations) and true biological interactions; we need new feature selection criteria to make the model better explain rather than simply predict phenotypes. Second, complex models (e.g., deep learning or ensemble models) can more accurately describe intricate relationships between genes and phenotypes than simpler, linear models, but they lack interpretability. Third, analyzing observational data without conducting interventional experiments does not prove causal relations. To address these problems, we propose an integrated machine learning methodology for learning interpretable models from data that will: 1) select interpretable features likely to provide meaningful phenotype explanations, 2) make interpretable predictions by estimating the importance of each feature to a prediction, and 3) iteratively validate and refine predictions through interventional experiments. For each challenge, we will develop a generalizable ML framework that focuses on different aspects of model interpretability and will therefore be applicable to any formerly intractable, high-impact healthcare problems. We will also demonstrate the effectiveness of each ML framework for a wide range of topics, from basic science to disease biology to bedside applications. Project Narrative The development of effective computational methods that can extract meaningful and interpretable signals from noisy, big data has become an integral part of biomedical research, which aims to discover novel biological processes and clinically translatable outcomes. The proposed research seeks to radically shift the current paradigm in data-driven discovery from “learning a statistical model that best fits specific training data” to “learning an explainable model” for a wide range of topics, from basic science to disease biology to bedside applications. Successful completion of this project will result in novel biological discoveries, therapeutic targets, predictive models for patient outcomes, and powerful computational frameworks generalizable to critical problems in various diseases.",Opening the Black Box of Machine Learning Models,10020414,R35GM128638,"['Address', 'Basic Science', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Complex', 'Computing Methodologies', 'Data', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Future', 'Gene Expression', 'Genes', 'Healthcare', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Linear Models', 'Machine Learning', 'Measurement', 'Methodology', 'Modeling', 'Modernization', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Outcome', 'Patient-Focused Outcomes', 'Phenotype', 'Research', 'Sampling', 'Selection Criteria', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Technology', 'Training', 'Translating', 'biomarker discovery', 'clinical practice', 'clinically translatable', 'computer framework', 'deep learning', 'experimental study', 'feature selection', 'high dimensionality', 'innovation', 'inquiry-based learning', 'molecular marker', 'novel', 'precision medicine', 'predictive modeling', 'success', 'therapeutic target']",NIGMS,UNIVERSITY OF WASHINGTON,R35,2020,388750,0.006199432394427103
"Bayesian Machine Learning Tools for Analyzing Microbiome Dynamics The human microbiota plays an important role in health and disease, and its therapeutic manipulation is being actively investigated for a wide range of diseases that span every NIH institute. Our microbiota are inherently dynamic, and analyzing these time-dependent properties is key to robustly linking the microbiota to disease, and predicting the effects of therapies targeting the microbiota; indeed, longitudinal microbiome data is being acquired with increasing frequency, and is a major component of many NIH-funded projects. However, there is currently a dearth of computational tools for analyzing microbiome time-series data, which presents several special challenges including high measurement noise, irregular and sparse temporal sampling, and complex dependencies between variables. The objective of this proposal is to introduce new capabilities, improve on, and provide state-of-the-art implementations of tools for analyzing dynamics, or patterns of change in microbiome time-series data. The tools we develop will use Bayesian machine learning methods, which are well-recognized for their strong conceptual and practical advantages, particularly in biomedical domains. Tools will be rigorously tested and validated on synthetic and real human microbiome data, including publicly available datasets and those from collaborators providing 16S rRNA sequencing, metagenomic, and metabolomics data. We propose three specific aims. For Aim 1, we will develop integrated Bayesian machine learning tools for predicting population dynamics of the microbiome and its responses to perturbations. These tools will include a new model that simultaneously learns groups of microbes with similar interaction structure and predicts their behavior over time, and that incorporates prior phylogenetic information. The model will be further improved by incorporating stochastic microbial dynamics and errors in measurements throughout the model. For Aim 2, we will develop Bayesian machine learning tools to predict host status from microbiome dynamics. The tools will learn easily interpretable, human-readable rules that predict host status from microbiome time-series data, and will be further extended to handle a variety of longitudinal study designs. For Aim 3, we will engineer our microbiome dynamics analysis software tools for optimal performance, ease-of- use, maintainability, extensibility, and dissemination to the community. In total, the proposed work will yield a suite of contemporary software tools for analyzing microbiome dynamics, with expected broad use and major impact. The software will allow investigators to answer important scientific and translational questions about the microbiome, including discovering which microbial taxa or their metagenomes are affected over time by perturbations such as changes in diet or invasion by pathogens; predicting the effects of these perturbations over time, including changes in composition or stability of the gut microbiota; and finding temporal signatures in multi-‘omic microbiome data that predict disease risk in the human host. The human microbiota, or collection of micro-organisms living on and within us, plays an important role in health, and when disrupted or abnormal, may contribute to many types of diseases including infections, kidney diseases, bowel diseases, diabetes, heart diseases, arthritis, allergies, brain diseases, and cancer. Sophisticated computer-based tools are needed to make sense of human microbiota data, particularly time- series data, which can yield important insights into how our microbiomes change over time. This work will develop new and improved computer-based tools for analyzing microbiota time-series data, which will be made freely available and will enable scientists to increase our fundamental knowledge about how our microbiota affect us and ultimately to apply this knowledge to prevent and treat human illnesses.",Bayesian Machine Learning Tools for Analyzing Microbiome Dynamics,10015315,R01GM130777,"['16S ribosomal RNA sequencing', 'Affect', 'Algorithms', 'Antibiotics', 'Arthritis', 'Autoimmunity', 'Bayesian learning', 'Behavior', 'Biological Markers', 'Biological Models', 'Brain Diseases', 'Cardiovascular Diseases', 'Childhood', 'Clostridium difficile', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Set', 'Dependence', 'Diabetes Mellitus', 'Diet', 'Disease', 'Engineering', 'Environmental Exposure', 'Frequencies', 'Funding', 'Health', 'Heart Diseases', 'Human', 'Human Microbiome', 'Hypersensitivity', 'Infection', 'Institutes', 'Intervention', 'Intestines', 'Investigation', 'Kidney Diseases', 'Knowledge', 'Learning', 'Link', 'Longitudinal Studies', 'Malignant Neoplasms', 'Measurement', 'Medical', 'Metagenomics', 'Microbe', 'Modeling', 'Names', 'Noise', 'Oligosaccharides', 'Outcome', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Play', 'Population Dynamics', 'Property', 'Pythons', 'Readability', 'Research Design', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Series', 'Shotguns', 'Software Engineering', 'Software Tools', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Work', 'base', 'computerized tools', 'design', 'disorder risk', 'dynamic system', 'gut microbiota', 'human data', 'human microbiota', 'human subject', 'improved', 'insight', 'learning algorithm', 'machine learning method', 'man', 'metabolomics', 'metagenome', 'microbial', 'microbiome', 'microbiome analysis', 'microbiome sequencing', 'microbiota', 'microorganism', 'nervous system disorder', 'novel', 'open source', 'pathogen', 'predictive tools', 'prevent', 'recurrent infection', 'response', 'software development', 'targeted treatment', 'tool']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R01,2020,312939,0.015329395905026993
"A New Paradigm for Systems Physiology Modeling: Biomechanistic Learning Augmentation with Deep Differential Equation Representations (BLADDER) Many promising peripheral neuromodulation techniques have been proposed to treat lower urinary tract (LUT) dysfunction, but our lack of predictive models has forced the community (including the PI’s lab) to explore the vast parameter space of nerve targets, stimulation parameterizations, and electrode designs empirically in animal experiments by trial and error. This type of exploratory experimentation is the only current method of optimizing, personalizing, or discovering novel LUT neuromodulation techniques. Motivated by this clinical need, our long-term goal for this work is to predict the effects of neuromodulation on the LUT. To move toward this goal, we propose to develop a new modeling framework that integrates disparate biophysics models through machine learning, thereby emulating an entire organ system through a process we call Biomechanistic Learning Augmentation of Deep Differential Equation Representations (BLADDER). We will develop and use the general BLADDER framework to create an organ-level model of the normal healthy LUT throughout its filling and voiding cycles, including non-volitional neural reflex control over the bladder and urethra. Our focus on neural reflex control and organ-level scales ensures that, if successful, the BLADDER LUT model will be poised to predict effects of neuromodulation using computational studies, which so far has been impossible due to the complexity of the LUT. The BLADDER framework unites multiple individual mechanistic models (each accounting for a component function of an organ system) by using deep recurrent neural networks (RNN) to learn the appropriate coupling dynamics linking each component model. The combination of mechanistic and machine learning models under a single framework allows us to harness the advantages of both: mechanistic models excel at interpretability but suffer from a lack of scalability (becoming intractable at the level of organ systems), while machine learning models are excellent at scale but lack generalizability and insights for hypothesis generation. The BLADDER framework will scale up mechanistic models to the level of systems physiology by linking tractable model components together using a supervisory RNN, allowing the BLADDER framework to deliver both interpretability and scale. We will draw on existing SPARC datasets in the cat (e.g., Bruns and Gaunt), existing publicly available data in rat, and generate new data in the rat to construct a training dataset for the supervisory RNN. We will further draw from already published small-scale mechanistic models, validated on human and animal data, for the mechanistic components of the BLADDER LUT model. The formal process of identifying these models and datasets, and checking their validity and robustness, will clearly reveal the deficits and strengths in our theoretical and experimental understanding of the LUT in a straightforward and rational way. We will use the 10 Simple Rules to vet mechanistic models for inclusion in the BLADDER LUT model and compile a public inventory for the neurourology community. Major task 1 (Q1-2): Identify available datasets and candidate mechanistic models from published literature. Major deliverables are a public database and a whitepaper detailing the state of the field and prospects for modeling and experimental work. Major Task 2 (Q1-3): Demonstrate proof of concept of BLADDER framework. Major deliverables are a publicly available code linking two LUT component models via supervisory RNN and a report on suitable RNN architectures based on fully described dynamical systems. Major Task 3 (Q3-6): Create a multi-component BLADDER model. Major deliverables are code used to link separate mechanistic LUT models via the supervisory RNN, and an in vivo rat dataset to fill in critical measurables for the machine learning training set. Major Task 4 (Q6-8): Deploy the fully operational BLADDER model of the LUT, including autonomously predicted neural reflex control. Major deliverables are publicly available codes and datasets, and a hypothesis-driven computational experiment to predict simple interventions. n/a",A New Paradigm for Systems Physiology Modeling: Biomechanistic Learning Augmentation with Deep Differential Equation Representations (BLADDER),10206953,OT2OD030524,"['Accounting', 'Animal Experiments', 'Bladder', 'Clinical', 'Code', 'Communities', 'Coupling', 'Data', 'Data Set', 'Databases', 'Differential Equation', 'Electrodes', 'Ensure', 'Equipment and supply inventories', 'Felis catus', 'Functional disorder', 'Generations', 'Goals', 'Individual', 'Intervention', 'Learning', 'Link', 'Literature', 'Lower urinary tract', 'Machine Learning', 'Measurable', 'Methods', 'Modeling', 'Nerve', 'Organ', 'Peripheral', 'Physiology', 'Process', 'Publishing', 'Rattus', 'Reflex control', 'Reporting', 'System', 'Techniques', 'Training', 'Urethra', 'Work', 'animal data', 'base', 'biophysical model', 'body system', 'computer studies', 'design', 'dynamic system', 'experimental study', 'human data', 'in vivo', 'insight', 'neural network architecture', 'neuroregulation', 'novel', 'predictive modeling', 'recurrent neural network', 'relating to nervous system', 'scale up']",OD,FLORIDA INTERNATIONAL UNIVERSITY,OT2,2020,1025141,-0.016711510403571363
"The interaction of myosin and the thin filament: how mutations cause allosteric dysfunction and their connection to genetic cardiomyopathy Project Summary: The long-term goal of this research program is to develop a rigorously experimentally validated all-atom computational model of the cardiac thin filament (CTF) bound to myosin S1 which provides a unique and accessible platform to identify novel, high resolution disease mechanisms linked to Hypertrophic Cardiomyopathy (HCM). In the prior funding period, we refined and extended our existing CTF computational model and successfully employed it to identify unique and clinically relevant allosteric disease mechanisms including HCM mutation-induced changes in myofilament Ca2+ kinetics, mutation-specific molecular causes of differential cardiac remodeling and disease progression. This included an in vivo validation via the development of a novel transgenic mouse model of cTnT-linked dilated cardiomyopathy and a predictive algorithm to determine the pathogenicity of cTnT mutations that out-performed existing computational approaches in a preliminary test. The key to these advances has been the ability of the current model to precisely identify and locate allosteric changes caused by mutations throughout all components of the CTF followed by closely coupled experimental validation and eventual in vivo model correlation. We now propose to significantly expand the biological complexity of the model to include myosin S1, the molecular motor that drives contraction and the second most common genetic cause of HCM. This important and challenging advance will facilitate a deeper understanding of disease pathogenesis by, for the first time, incorporating the role of molecular allosteric mechanisms between myosin S1 and thin filament. This new computational – experimental platform will be used for both mechanistic insight (for example used for the identification of novel myofilament disease targets,) and the development of a comprehensive deep-learning predictive algorithm to assign pathogenicity to both myosin and thin filament HCM mutations. The latter represents the first use of high-resolution structure, dynamics and function to predict HCM disease allele pathogenicity, a central challenge in the clinical management of these complex patients. Both the training and testing components of the deep learning development will utilize data from the highly annotated and curated SHaRe HCM registry thus greatly improving translational power. Two Specific Aims will be pursued: Aim 1 will utilize state of the art rare event simulation methods developed in one of our groups and refinement of existing unstructured domains of the CTF via FRET to establish the new model. Aim 2 will employ an extensive program of computational analysis and subsequent in vitro validation using pathogenic, variants of unknown significance and non- pathogenic HCM alleles derived from SHaRe to provide inputs to the machine learning environment for algorithm development. Novel disease mechanisms for myosin and thin filament HCM that include crosstalk between the two components will also be explored. Elucidation of these mechanisms can be the basis for robust molecular approaches to disease. Precision medicine and “molecular” medicine are concepts that aim to employ a patient’s genetic structure to discern the best medical treatments for disease. Hypertrophic cardiomyopathy is a genetic disease that afflicts 1/500 people. This application translates our knowledge of the molecular level effects of cardiac tissue mutation to disease and will aim to lead to eventual treatment.",The interaction of myosin and the thin filament: how mutations cause allosteric dysfunction and their connection to genetic cardiomyopathy,10071638,R01HL107046,"['Address', 'Alleles', 'Anisotropy', 'Artificial Intelligence', 'Biological', 'Biological Assay', 'Biology', 'Biophysics', 'Breath Tests', 'C-terminal', 'Cardiac', 'Chemistry', 'Clinical Management', 'Complex', 'Computer Analysis', 'Computer Models', 'Contracts', 'Coupled', 'Data', 'Data Set', 'Descriptor', 'Development', 'Differential Scanning Calorimetry', 'Dilated Cardiomyopathy', 'Disease', 'Disease Progression', 'Distant', 'Engineering', 'Enzymes', 'Event', 'Fluorescence Anisotropy', 'Fluorescence Resonance Energy Transfer', 'Functional disorder', 'Funding', 'Generations', 'Genetic', 'Genetic Diseases', 'Genetic Structures', 'Goals', 'Grant', 'Hand', 'Human', 'Hypertrophic Cardiomyopathy', 'In Vitro', 'Individual', 'Induced Mutation', 'Kinetics', 'Knowledge', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Microfilaments', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Medicine', 'Molecular Motors', 'Motor', 'Mutation', 'Myosin ATPase', 'Pathogenesis', 'Pathogenicity', 'Patients', 'Perception', 'Physiological', 'Play', 'Protein Conformation', 'Protein Dynamics', 'Proteins', 'Registries', 'Research', 'Resolution', 'Resources', 'Role', 'Sampling', 'Sarcomeres', 'Site', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick Filament', 'Thin Filament', 'Thinness', 'Time', 'Tissues', 'Training', 'Transgenic Mice', 'Translating', 'Validation', 'Variant', 'Work', 'algorithm development', 'automated analysis', 'base', 'cell motility', 'clinically relevant', 'deep learning', 'educational atmosphere', 'experimental study', 'improved', 'in vivo', 'in vivo Model', 'inherited cardiomyopathy', 'insight', 'machine learning algorithm', 'mouse model', 'neural network', 'next generation', 'novel', 'phosphorescence', 'precision medicine', 'prediction algorithm', 'programs', 'quantum chemistry', 'response', 'simulation', 'stopped-flow fluorescence', 'success', 'variant of unknown significance']",NHLBI,UNIVERSITY OF ARIZONA,R01,2020,585711,-0.03134915455238982
"Incorporating molecular network knowledge into predictive data-driven models Modern computational techniques based on machine-learning (ML) and, more recently, deep-learning (DL) are playing a critical role in realizing the precision medicine initiative. However, there is a critical need to systematically combine these powerful data-driven techniques with prior molecular network knowledge to make more accurate predictive models while also satisfactorily explaining their predictions in terms of mechanisms underlying complex traits and diseases. I propose to use domain specific knowledge from biology and computing to tackle three outstanding problems: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? ​Network-constrained Deep Learning for Metadata Imputation: ​​Most multifactorial phenotypes are tissue dependent and manifest differently depending on age, sex, and ethnicity. However, a majority of publicly-available genomic data lack these labels. I will develop a network-guided approach to predict missing metadata of samples based on their expression profiles by designing novel data-driven models where the model architecture and/or structure of the input data are constrained by an underlying gene network. ​Network-guided Functional Analysis of Genomic Data: ​​High-throughput experiments often generate lists of genes of interest that are hard to interpret. Functional enrichment analysis (FEA) is a powerful tool that attaches functional meaning to an experimental set of genes by summarizing them into sets of pathways/processes. However, standard FEA analysis is limited by incomplete knowledge of gene function, lack of context of the underlying gene network, and noise in expression data. I will address these limitations by developing a network-guided approach that jointly captures genes, their interactions, and their known biological pathways/processes into a common, low-dimensional space that facilitates deriving biological meaning by comparing the distance between the experimental gene set and the pathway/process of interest. ​Joint Multi-Species Genomic Data Analysis and Knowledge Transfer: ​​In particular, finding the optimal model system to use in a follow-up study based on genetic signatures derived from human experiments is challenging because genetic networks can be quite different from species to species. I propose to use data-driven models to embed heterogeneous networks comprised of human genes and model species genes into a common, low-dimensional space to better compare genetic signatures between two (or even multiple) species. I will apply these methods to three specific tasks, but I emphasize that the results of this study will be transferable to any other biological problem where complex gene/protein interactions are a major component. I have surrounded myself with a great support team and developed a strong professional development plan. The freedom and support provided by the F32 fellowship will be instrumental in achieving my goal of becoming a professor with an independent research group. This proposal aims to develop novel computational approaches that systematically combine prior molecular network knowledge, powerful data-driven computational techniques, and large transcriptome data collections to answer three critical questions in biomedicine: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? The core goal of my fellowship is to achieve this by infusing prior-knowledge into state-of-the-art data-driven statistical/machine learning methods so that we can overcome two major hurdles in studying complex, multifactorial traits and diseases: a) complex genetic interactions underlie multi-factorial traits and diseases, and b) these traits and diseases often differ in how they manifest from patient to patient.",Incorporating molecular network knowledge into predictive data-driven models,10022122,F32GM134595,"['Accounting', 'Address', 'Age', 'Architecture', 'Back', 'Binding', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Cell physiology', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Collection', 'Development Plans', 'Dimensions', 'Disease', 'Engineering', 'Ethnic Origin', 'Expression Profiling', 'Fellowship', 'Follow-Up Studies', 'Freedom', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Human', 'Joints', 'Knowledge', 'Label', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Nature', 'Noise', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Process', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Source', 'Structure', 'Techniques', 'Tissues', 'Translating', 'base', 'data to knowledge', 'deep learning', 'design', 'disease phenotype', 'driving force', 'experimental study', 'functional genomics', 'gene function', 'genetic association', 'genetic signature', 'genomic data', 'genomic profiles', 'human data', 'interest', 'machine learning method', 'mathematical sciences', 'novel', 'predictive modeling', 'professor', 'sex', 'statistical and machine learning', 'tool', 'trait', 'transcriptome']",NIGMS,MICHIGAN STATE UNIVERSITY,F32,2020,67446,-0.00950025913806063
"Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data Big data is now ubiquitous in every field of modern scientific research. Many contemporary applications, such as the recent national microbiome initiative (NMI), greatly demand highly flexible statistical machine learning methods that can produce both interpretable and reproducible results. Thus, it is of paramount importance to identify crucial causal factors that are responsible for the response from a large number of available covariates, which can be statistically formulated as the false discovery rate (FDR) control in general high-dimensional nonlinear models. Despite the enormous applications of shotgun metagenomic studies, most existing investigations concentrate on the study of bacterial organisms. However, viruses and virus-host interactions play important roles in controlling the functions of the microbial communities. In addition, viruses have been shown to be associated with complex diseases. Yet, investigations into the roles of viruses in human diseases are significantly underdeveloped. The objective of this proposal is to develop mathematically rigorous and computationally efficient approaches to deal with highly complex big data and the applications of these approaches to solve fundamental and important biological and biomedical problems. There are four interrelated aims. In Aim 1, we will theoretically investigate the power of the recently proposed model-free knockoffs (MFK) procedure, which has been theoretically justified to control FDR in arbitrary models and arbitrary dimensions. We will also theoretically justify the robustness of MFK with respect to the misspecification of covariate distribution. These studies will lay the foundations for our developments in other aims. In Aim 2, we will develop deep learning approaches to predict viral contigs with higher accuracy, integrate our new algorithm with MFK to achieve FDR control for virus motif discovery, and investigate the power and robustness of our new procedure. In Aim 3, we will take into account the virus-host motif interactions and adapt our algorithms and theories in Aim 2 for predicting virus-host infectious interaction status. In Aim 4, we will apply the developed methods from the first three aims to analyze the shotgun metagenomics data sets in ExperimentHub to identify viruses and virus-host interactions associated with several diseases at some target FDR level. Both the algorithms and results will be disseminated through the web. The results from this study will be important for metagenomics studies under a variety of environments. Big data is ubiquitous in biological research. Identifying causal factors associated with complex diseases or traits from big data is highly important and challenging. New statistical and computational tools will be developed to control False Discovery Rate (FDR) for molecular sequence data based on the novel model-free knockoffs framework. They will be used to detect sequence motifs for viruses and motif-pairs for virus-host interactions, and to analyze multiple metagenomics data sets related to complex diseases.",Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data,9923688,R01GM131407,"['Address', 'Algorithms', 'Archaea', 'Attention', 'Bacteria', 'Big Data', 'Biological', 'Bypass', 'Cells', 'Colorectal Cancer', 'Complex', 'Computer software', 'Consult', 'Coupled', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Effectiveness', 'Environment', 'Foundations', 'Frequencies', 'Gaussian model', 'Genes', 'Genetic Materials', 'Genomics', 'Healthcare', 'Human', 'Internet', 'Investigation', 'Joints', 'Length', 'Linear Regressions', 'Literature', 'Liver Cirrhosis', 'Mathematics', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Sequence Data', 'Mutation', 'Neurosciences', 'Non-Insulin-Dependent Diabetes Mellitus', 'Non-linear Models', 'Obesity', 'Organism', 'Performance', 'Planet Earth', 'Play', 'Procedures', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Sampling Studies', 'Shotguns', 'Social Sciences', 'Testing', 'Theoretical Studies', 'Tissues', 'Training', 'Viral', 'Virus', 'Visualization software', 'Work', 'base', 'biological research', 'computerized tools', 'contig', 'dark matter', 'deep learning', 'deep learning algorithm', 'design', 'flexibility', 'high dimensionality', 'human disease', 'human tissue', 'improved', 'interest', 'learning strategy', 'machine learning method', 'metagenomic sequencing', 'microbial community', 'microbiome', 'microbiome research', 'model design', 'model development', 'new technology', 'novel', 'power analysis', 'response', 'simulation', 'statistical and machine learning', 'theories', 'trait', 'user-friendly', 'virus host interaction', 'virus identification']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,276700,0.0020086665593188288
"Using machine learning to predict odor characteristics from molecular structure PROJECT SUMMARY/ABSTRACT We cannot yet look at a chemical structure and predict if the molecule will have an odor, much less what character it will have. The goal of the proposed research is to apply machine learning to predict perceptual characteristics from chemical features of molecules. The specific aims of the proposal will determine (1) which molecules are odorous , and (2) what data are needed to model odor character. Building a highly predictive model requires two key ingredients: high-quality data and a sound modeling approach. High-quality data must be accurate (ratings are consistent and describe true odor properties) and detailed (ratings describe even small differences in odor properties). We have collected human psychophysical data on a diverse set of molecules and have trained a model to predict if a molecule has an odor, but pilot data identified odorous contaminants that limit model training and measurement of model accuracy. In Aim 1, I will apply my background in analytical chemistry to evaluate the accuracy of the data, using gas chromatography to identify and correct errors caused by chemical contaminants. In Aim 2, I will apply my experience in human sensory evaluation to measure and compare the consistency and the degree of detail in ratings that can be achieved with different sensory methods and subject training procedures. By executing my training plan, I will develop the skills in statistical programming and machine learning needed to employ a sound modeling approach to these problems. The model constructed in Aim 1 will enable prediction of odor classification (odor/odorless) for any molecule and thus define which molecules are perceptually relevant. Predicting odor character is a far more complex challenge – while a molecule can have only one of two odor classifications (odor or odorless) it may elicit any number of diverse odor character attributes (fruity, floral, musky, sweet, etc.). Descriptive Analysis (DA) is the gold standard method for generating accurate and detailed sensory profiles, but this method is time-consuming. We estimate that an odor character dataset will be large enough (“model-ready”) to predict odor character with approximately 10,000 molecules and that it would require more than 30,000 hours of human subject evaluation, or approximately 6 years for the typical trained panel, to produce this dataset using DA. Before we invest the time and resources, it is responsible to evaluate the relative data quality of more rapid sensory methods. The results of Aim 2 are expected to determine the best approach for generating a model-ready dataset by quantifying trade-offs in degree of detail (data resolution), rating consistency, and method speed of five candidate sensory methods. Together, these aims represent a significant step forward in linking chemical recipe to human odor perception, an advancement that supports the NIDCD goal of understanding normal olfactory function (how stimulus relates to percept) and has many potential applications in foods (what composition of molecules should be present to produce a target aroma percept). PROJECT NARRATIVE Currently, scientists cannot predict whether a molecule will have an odor and, if so, what odor characteristics it will have based on its chemical structure. The goal of this project is to develop predictive models linking chemical composition to odor characteristics. These models will advance our understanding of the human olfactory system and help design strategies for improving the aroma and palatability of healthy foods.",Using machine learning to predict odor characteristics from molecular structure,10142097,F32DC019030,"['Address', 'Analytical Chemistry', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Classification', 'Collection', 'Complex', 'Consumption', 'Data', 'Data Set', 'Descriptor', 'Development', 'Evaluation', 'Food', 'Fruit', 'Gas Chromatography', 'Goals', 'Gold', 'Health Food', 'Hour', 'Human', 'Human Resources', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Structure', 'National Institute on Deafness and Other Communication Disorders', 'Odors', 'Olfactory Pathways', 'Palate', 'Perception', 'Positioning Attribute', 'Procedures', 'Programmed Learning', 'Property', 'Protocols documentation', 'Psychophysics', 'Quality Control', 'Recipe', 'Research', 'Research Technics', 'Resolution', 'Resources', 'Sampling', 'Science', 'Scientist', 'Sensory', 'Smell Perception', 'Speed', 'Stimulus', 'Structure', 'Testing', 'Time', 'Training', 'Work', 'base', 'data quality', 'design', 'experience', 'food science', 'human subject', 'improved', 'machine learning algorithm', 'model building', 'predictive modeling', 'prevent', 'rapid technique', 'skills', 'sound']",NIDCD,MONELL CHEMICAL SENSES CENTER,F32,2020,67446,-0.0070563291160378955
"Using machine learning techniques to characterize the Metabolomics Workbench Dataset PROJECT SUMMARY/ABSTRACT  Mass spectrometry in combination with chromatography provides a powerful approach to characterize small molecules produced in cells, tissues and other biological systems. In essence, measured metabolites provide a functional readout of cellular state, allowing novel biological studies that advance our understanding of health and disease. Currently, the main bottleneck in metabolomics is determining the chemical identities associated with the spectral signatures of measured masses. Despite the growth of spectral databases and advances in annotation tools that recommend the chemical structure that best explains each signature, the large majority of measured masses cannot be assigned a chemical identity. There is now consensus that gleaning partial information regarding the measured spectra in terms of chemical substructure or chemical classification can inform biological studies. This consensus is reflected in the newly updated reporting standards for metabolite annotation as proposed by the Metabolite Identification Task Group of the Metabolomics Society. As we show in our Preliminary Results, spectral characterization results in “features” that can enhance performance in machine-learning tasks such as annotation.  This work aims to enhance the use and value of the metabolomics dataset in Metabolomics Workbench by: (1) developing machine-learning tools trained on this dataset to characterize unknown spectra, and (2) adding characterization information to the Metabolomics Workbench dataset. In Aim 1, we identify spectral patterns (motifs) that can represent chemically meaningful groupings of peaks within the spectra (e.g., peaks associated with aromatic substructures, loss of a substructure fragment, etc.). We utilize neural topic models that use variational inference to identify such motifs. We expect such models to offer computational speedups and to identify more chemically coherent motifs when compared to earlier implementations of topic modeling. We generate motifs across all spectra in the Metabolomics Workbench and provide annotations for each spectrum.  In Aim 2, we map spectral signatures to chemical ontology classes. As ontologies are hierarchical and as a molecule can be associated with multiple classes at different hierarchical levels of an ontology, we cast this mapping problem as a hierarchical multi-label classification problem and use neural networks to implement such a classifier. The classifier will be trained using the Metabolomics Workbench dataset. Learned motifs from Aim 1 will be used as additional input features to improve classification. We expect that the developed classifier can be used by others to elucidate measurements of unidentified molecules with chemical ontology classes, or to generate ontology terms that can be used as features in downstream machine-learning tasks. Relevance to Public Health The project proposes to investigate machine learning techniques to enhance the utility of a Common Fund data set hosted through the Metabolomics Workbench. This data set consists of biologically relevant molecules and information about their structural composition and their mass spectrometry signatures. We anticipate that our techniques will result in annotating and adding information to the data set, which in turn will advance discoveries in biomedical research and have direct benefits to human health.",Using machine learning techniques to characterize the Metabolomics Workbench Dataset,10111982,R03OD030601,"['Biochemical', 'Biological', 'Biomedical Research', 'Catalogs', 'Cells', 'Chemical Structure', 'Chemicals', 'Chromatography', 'Classification', 'Complement', 'Computational Technique', 'Computing Methodologies', 'Consensus', 'Consumption', 'Coupled', 'Data', 'Data Set', 'Databases', 'Disease', 'Funding', 'Gas Chromatography', 'Gene Expression', 'Glean', 'Goals', 'Grouping', 'Growth', 'Health', 'Histidine', 'Human', 'Ions', 'Label', 'Liquid Chromatography', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Modeling', 'Molecular', 'Molecular Structure', 'Nature', 'Ontology', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Public Health', 'Reporting', 'Research Personnel', 'Sampling', 'Societies', 'Structure', 'Taxonomy', 'Techniques', 'Time', 'Tissues', 'Training', 'Update', 'Validation', 'Variant', 'Vocabulary', 'Work', 'annotation  system', 'biological systems', 'biomarker discovery', 'cost', 'functional outcomes', 'improved', 'metabolomics', 'neural network', 'novel', 'protein expression', 'relating to nervous system', 'response', 'small molecule', 'tool']",OD,TUFTS UNIVERSITY MEDFORD,R03,2020,263120,0.003106236322484139
"National Resource for Network Biology (NRNB) OVERALL - PROJECT SUMMARY The mission of the National Resource for Network Biology (NRNB) is to advance the science of biological networks by creating leading-edge bioinformatic methods, software tools and infrastructure, and by engaging the scientific community in a portfolio of collaboration and training opportunities. Much of biomedical research is dependent on knowledge of biological networks of multiple types and scales, including molecular interactions among genes, proteins, metabolites and drugs; cell communication systems; relationships among genotypes and biological and clinical phenotypes; and patient and social networks. NRNB-supported platforms like Cytoscape are among the most widely used software tools in biology, with tens of thousands of active users, enabling researchers to apply network concepts and data to understand biological systems and how they are reprogrammed in disease.  NRNB’s three Technology Research and Development projects introduce innovative concepts with the potential to transform network biology, transitioning it from a static to a dynamic science (TR&D 1); from flat network diagrams to multi-scale hierarchies of biological structure and function (TR&D 2); and from descriptive interaction maps to predictive and interpretable machine learning models (TR&D 3). In previous funding periods our technology projects have produced novel and highly cited approaches, including network-based biomarkers for stratification of disease, data-driven gene ontologies assembled completely from network data, and deep learning models of cell structure and function built using biological networks as a scaffold.  During the next period of support, we introduce dynamic regulatory networks formulated from single-cell transcriptomics and advanced proteomics data (TR&D 1); substantially improved methodology for the study of hierarchical structure and pleiotropy in biological networks (TR&D 2); and procedures for using networks to seed machine learning models of drug response that are both mechanistically interpretable and transferable across biomedical contexts (TR&D 3). These efforts are developed and applied in close collaboration with outside investigators from 19 Driving Biomedical Projects who specialize in experimental generation of network data, disease biology (cancer, neuropsychiatric disorders, diabetes), single-cell developmental biology, and clinical trials. TR&Ds are also bolstered by 7 Technology Partnerships in which NRNB scientists coordinate technology development with leading resource-development groups in gene function prediction, mathematics and algorithm development, and biomedical databases. Beyond these driving collaborations, we continually support a broader portfolio of transient (non-driving) research collaborations; organize and lead international meetings including the popular Network Biology track of the Intelligent Systems for Molecular Biology conference; and deliver a rich set of training opportunities and network analysis protocols. OVERALL - PROJECT NARRATIVE We are all familiar with some of the components of biological systems – DNA, proteins, cells, organs, individuals – but understanding biological systems involves more than just cataloging its component parts. It is critical to understand the many interactions of these parts within systems, and how these systems give rise to biological functions and responses and determine states of health and disease. The National Resource for Network Biology provides the scientific community with a broad platform of computational tools for the study of biological networks and for incorporating network knowledge in biomedical research.",National Resource for Network Biology (NRNB),9937486,P41GM103504,"['Area', 'Automobile Driving', 'Beds', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Biomedical Technology', 'Cataloging', 'Catalogs', 'Cell Communication', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Conceptions', 'DNA', 'Data', 'Data Set', 'Databases', 'Developmental Cell Biology', 'Diabetes Mellitus', 'Disease', 'Disease stratification', 'Drug Modelings', 'Ecosystem', 'Educational workshop', 'Event', 'Expert Systems', 'Feedback', 'Funding', 'Gene Proteins', 'Generations', 'Genes', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Health', 'Individual', 'Infrastructure', 'International', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mentors', 'Methodological Studies', 'Methods', 'Mission', 'Modeling', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Network-based', 'Ontology', 'Organ', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Phase Transition', 'Phenotype', 'Positioning Attribute', 'Procedures', 'Proteins', 'Proteomics', 'Protocols documentation', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Running', 'Science', 'Scientist', 'Seeds', 'Services', 'Social Network', 'Software Tools', 'Structure', 'Students', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Visual', 'Visualization', 'Work', 'algorithm development', 'biological systems', 'clinical phenotype', 'cloud storage', 'computational platform', 'computerized tools', 'deep learning', 'gene function', 'genomics cloud', 'improved', 'innovation', 'interoperability', 'lens', 'mathematical algorithm', 'meetings', 'method development', 'multi-scale modeling', 'neuropsychiatric disorder', 'next generation', 'novel', 'pleiotropism', 'prediction algorithm', 'programs', 'protein metabolite', 'response', 'scaffold', 'single cell analysis', 'software infrastructure', 'symposium', 'technology development', 'technology research and development', 'tool', 'training opportunity', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P41,2020,1995376,0.015971022467112194
"Computational Techniques for Advancing Untargeted Metabolomics Analysis PROJECT SUMMARY/ABSTRACT Detecting and quantifying products of cellular metabolism using mass spectrometry (MS) has already shown great promise in biomarker discovery, nutritional analysis and other biomedical research fields. Despite recent advances in analysis techniques, our ability to interpret MS measurements remains limited. The biggest challenge in metabolomics is annotation, where measured compounds are assigned chemical identities. The annotation rates of current computational tools are low. For several surveyed metabolomics studies, less than 20% of all compounds are annotated. Another contributing factor to low annotation rates is the lack of systematic ways of designing a candidate set, a listing of putative chemical identities that can be used during annotation. Relying on exiting databases is problematic as considering the large combinatorial space of molecular arrangements, there are many biologically relevant compounds not catalogued in databases or documented in the literature. A secondary yet important challenge is interpreting the measurements to understand the metabolic activity of the sample under study. Current techniques are limited in utilizing complex information about the sample to elucidate metabolic activity. The goal of this project is to develop computational techniques to advance the interpretation of large-scale metabolomics measurements. To address current challenges, we propose to pursue three Aims: (1) Engineering candidate sets that enhance biological discovery. (2) Developing new techniques for annotation including using deep learning and incremental build out methods to recommend novel chemical structures that best explain the measurements. (3) Constructing probabilistic models to analyze metabolic activity. Each technique will be rigorously validated computationally and experimentally using chemical standards. Two detailed case studies on the intestinal microbiota will allow us to further validate our tools. Microbiota-derived metabolites have been detected in circulation and shown to engage host cellular pathways in organs and tissues beyond the digestive system. Identifying these metabolites is thus critical for understanding the metabolic function of the microbiota and elucidating their mechanisms. The complex test cases will challenge our techniques, provide feedback during development, and allow us to further disseminate our techniques. We will work closely with early adopters of our tools, as proposed in supporting letters, to further validate our tools and encourage wide adoption. All proposed tools will be open source and made accessible through the web. Our tools promise to change current practices in interpreting metabolomics data beyond what is currently possible with databases, current annotation tools, statistical and overrepresentation analysis, or combinations thereof. The use of machine learning and large data sets as proposed herein defines the most promising research direction in metabolomics analysis. PROJECT NARRATIVE  Untargeted Metabolomics is a recently developed technique that allows the measurement of thousands of molecules in a biological sample. This work proposes several novel computational techniques that address limitations of current metabolomics analysis tools. We anticipate that this work will advance discoveries in biomedical research and have direct benefits to human health.",Computational Techniques for Advancing Untargeted Metabolomics Analysis,10022125,R01GM132391,"['Address', 'Adoption', 'Biological', 'Biomedical Research', 'Blood Circulation', 'Case Study', 'Chemical Structure', 'Chemicals', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Engineering', 'Ensure', 'Feedback', 'Goals', 'Health', 'Human', 'Internet', 'Intestines', 'Label', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'MeSH Thesaurus', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Nutritional', 'Organ', 'Pathway interactions', 'Performance', 'Play', 'Probability', 'Property', 'PubChem', 'PubMed', 'Public Domains', 'Research', 'Research Personnel', 'Role', 'Running', 'Sampling', 'Statistical Models', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Uncertainty', 'Validation', 'Work', 'annotation  system', 'base', 'biomarker discovery', 'chemical standard', 'combinatorial', 'computerized tools', 'cost', 'dark matter', 'deep learning', 'design', 'drug development', 'drug discovery', 'experimental study', 'gastrointestinal system', 'gut microbiota', 'interest', 'large datasets', 'metabolome', 'metabolomics', 'microbiota', 'microbiota metabolites', 'neural network', 'novel', 'nutrition', 'open source', 'physical property', 'small molecule', 'tool']",NIGMS,TUFTS UNIVERSITY MEDFORD,R01,2020,378983,-0.014710457854306224
"Computational Techniques for Advancing Untargeted Metabolomics Analysis PROJECT SUMMARY/ABSTRACT Detecting and quantifying products of cellular metabolism using mass spectrometry (MS) has already shown great promise in biomarker discovery, nutritional analysis and other biomedical research fields. Despite recent advances in analysis techniques, our ability to interpret MS measurements remains limited. The biggest challenge in metabolomics is annotation, where measured compounds are assigned chemical identities. The annotation rates of current computational tools are low. For several surveyed metabolomics studies, less than 20% of all compounds are annotated. Another contributing factor to low annotation rates is the lack of systematic ways of designing a candidate set, a listing of putative chemical identities that can be used during annotation. Relying on exiting databases is problematic as considering the large combinatorial space of molecular arrangements, there are many biologically relevant compounds not catalogued in databases or documented in the literature. A secondary yet important challenge is interpreting the measurements to understand the metabolic activity of the sample under study. Current techniques are limited in utilizing complex information about the sample to elucidate metabolic activity. The goal of this project is to develop computational techniques to advance the interpretation of large-scale metabolomics measurements. To address current challenges, we propose to pursue three Aims: (1) Engineering candidate sets that enhance biological discovery. (2) Developing new techniques for annotation including using deep learning and incremental build out methods to recommend novel chemical structures that best explain the measurements. (3) Constructing probabilistic models to analyze metabolic activity. Each technique will be rigorously validated computationally and experimentally using chemical standards. Two detailed case studies on the intestinal microbiota will allow us to further validate our tools. Microbiota-derived metabolites have been detected in circulation and shown to engage host cellular pathways in organs and tissues beyond the digestive system. Identifying these metabolites is thus critical for understanding the metabolic function of the microbiota and elucidating their mechanisms. The complex test cases will challenge our techniques, provide feedback during development, and allow us to further disseminate our techniques. We will work closely with early adopters of our tools, as proposed in supporting letters, to further validate our tools and encourage wide adoption. All proposed tools will be open source and made accessible through the web. Our tools promise to change current practices in interpreting metabolomics data beyond what is currently possible with databases, current annotation tools, statistical and overrepresentation analysis, or combinations thereof. The use of machine learning and large data sets as proposed herein defines the most promising research direction in metabolomics analysis. PROJECT NARRATIVE  Untargeted Metabolomics is a recently developed technique that allows the measurement of thousands of molecules in a biological sample. This work proposes several novel computational techniques that address limitations of current metabolomics analysis tools. We anticipate that this work will advance discoveries in biomedical research and have direct benefits to human health.",Computational Techniques for Advancing Untargeted Metabolomics Analysis,10145183,R01GM132391,"['Address', 'Adoption', 'Biological', 'Biomedical Research', 'Blood Circulation', 'Case Study', 'Chemical Structure', 'Chemicals', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Engineering', 'Ensure', 'Feedback', 'Goals', 'Health', 'Human', 'Internet', 'Intestines', 'Label', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'MeSH Thesaurus', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Nutritional', 'Organ', 'Pathway interactions', 'Performance', 'Play', 'Probability', 'Property', 'PubChem', 'PubMed', 'Public Domains', 'Research', 'Research Personnel', 'Role', 'Running', 'Sampling', 'Statistical Models', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Uncertainty', 'Validation', 'Work', 'annotation  system', 'base', 'biomarker discovery', 'chemical standard', 'combinatorial', 'computerized tools', 'cost', 'dark matter', 'deep learning', 'design', 'drug development', 'drug discovery', 'experimental study', 'gastrointestinal system', 'gut microbiota', 'interest', 'large datasets', 'metabolome', 'metabolomics', 'microbiota', 'microbiota metabolites', 'neural network', 'novel', 'nutrition', 'open source', 'physical property', 'small molecule', 'tool']",NIGMS,TUFTS UNIVERSITY MEDFORD,R01,2020,10920,-0.014710457854306224
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9983144,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Information Retrieval', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structural Models', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'machine learning method', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'structured data', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,264232,-0.016037481156380606
"A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning SUMMARY Adaptive evolution (AE) is both a “force of good” as it can help to optimize biological processes in industry, but it is also a “force of frustration” when infectious diseases exploit AE to escape the host immune system or become resistant to drugs. It has long been assumed close to impossible to make predictions on AE due to the presumed predominating influences of random forces and events. However, the observation that evolutionary repeatability across traits and species is far more common than previously thought, suggests that AE, with the right data and approach, may become (partially) predictable. Indeed, we found through experiments with the bacterial pathogen Streptococcus pneumoniae on its response to antibiotics and the emergence of antimicrobial resistance, that in order to make AE predictable a detailed understanding of at least two aspects of the bacterial system are required: 1.) the genetic constraints of the system (i.e. the architecture of the organismal network); and 2.) where and how in the system stress is experienced and processed. We showed that by mapping out ~25% of the bacterium's network, determining phenotypic and transcriptional antibiotic responses, applying network analyses to capture and quantify the responses in a network context, and exploiting experimental evolution to pin-point adaptive mutations in the genome it becomes possible, by means of machine learning, to uncover hidden patterns in the data that make AE predictions feasible. This means that the network in interaction with the environment shapes the adaptive landscape, it limits available solutions and makes some solutions more likely than others, thereby driving repeatability and enabling predictability. In this proposal we build on these exciting developments with the goal to map out the constraints of S. pneumoniae's entire network and develop a machine learning model that can forecast adaptive evolution a priori, and on a genome-wide scale. To accomplish this, we combine in aim 1 parts of Tn-Seq, dTn-Seq and Drop-Seq to finalize a new tool Tn-Seq^2 (Tn-Seq squared) that is able to map genetic-interactions in high-throughput and genome-wide. We use Tn-Seq^2 to reconstruct the first genome-wide genetic interaction network for S. pneumoniae in the presence of 20 antibiotics. In aim 2 we create 85 HA-tagged Transcription factor induction (TFI) strains and: a) Determine with ChIP-Seq the DNA-binding sites for all 85 TFs in S. pneumoniae; b) By overexpressing each TFI strain followed by RNA- Seq we determine each TFs regulatory signature; c) Use a Transcriptional Regulator Induced Phenotype screen in the presence of 20 antibiotics to untangle environment specific links between genetic and transcriptional perturbations and their phenotypic outcomes. Lastly, in aim 3, we train and test a variety of machine learning approaches to design an optimal model that predicts which genes in the genome are most likely to adapt in the presence of a specific antibiotic. The development of this predictive AE model, will not only be useful in predicting the emergence of antibiotic resistance, but the strategy should be valuable for most any biological field for which adaptive changes are important, ranging from biological engineering to cancer. NARRATIVE Adaptive evolution (AE) is the driving force behind the emergence of antibiotic resistance and if it were possible to predict AE before it happens, it could help in preventing resistance. Here we use cutting-edge existing and newly designed genomics tools and analytical approaches to develop a machine learning model that can predict AE a priori, and on a genome-wide scale.",A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning,10049219,R01AI148470,"['Achievement', 'Affect', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Automobile Driving', 'Bacteria', 'Binding Sites', 'Biological', 'Biological Process', 'Biomass', 'ChIP-seq', 'Communicable Diseases', 'Complex', 'DNA Binding', 'Data', 'Development', 'Drug resistance', 'Engineering', 'Ensure', 'Environment', 'Escherichia coli', 'Event', 'Evolution', 'Exposure to', 'Fermentation', 'Frustration', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Immune system', 'Immunotherapeutic agent', 'Industry', 'Life', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Microfluidics', 'Modeling', 'Mutation', 'Organism', 'Outcome', 'Pathway Analysis', 'Pattern', 'Phenotype', 'Photosynthesis', 'Planet Earth', 'Process', 'Resistance', 'Shapes', 'Streptococcus pneumoniae', 'Stress', 'System', 'Testing', 'Time', 'Training', 'Yeasts', 'design', 'driving force', 'droplet sequencing', 'emerging antibiotic resistance', 'emerging antimicrobial resistance', 'experience', 'experimental study', 'genetic architecture', 'genome-wide', 'genomic tools', 'network architecture', 'novel', 'overexpression', 'pathogenic bacteria', 'predictive modeling', 'prevent', 'process optimization', 'programs', 'response', 'tool', 'trait', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transposon sequencing']",NIAID,BOSTON COLLEGE,R01,2020,391250,-0.03238444172232807
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,9874005,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2020,360227,-0.004678109880344061
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9989196,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'automated algorithm', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2020,222618,-0.006425567258379811
"Machine learning-based multi-omics modeling and CRISPR/Cas9-mediated gene editing in elucidating molecular transducer of physical activity ABSTRACT Regular exercise (physical activity) is the most effective intervention that promotes health and combats non- communicable disease (NCD). However, our understanding of the molecule(s) responsible for the superb benefits of exercise is obscure. The NIH Common Fund project “Molecular Transducers of Physical Activity Consortium (MoTrPAC)” is a large-scale discovery study designed to understand the molecular responses to exercise training, which has released the first batch of multi-omics data, including RNA-seq, Reduced Representation Bisulfite Sequencing, proteomics, phosphoproteomics, acetylproteomics, and targeted and untargeted metabolomics, from 5 tissues collected at different time points in rats following an acute bout of endurance exercise. These endeavors have laid a solid foundation for elucidation of the molecular transducer of physical activity. We have recently made significant progress in four areas, which poised us to explore these data and elucidate the mechanism(s) in an unprecedented manner. Specifically, 1) We have obtained similar time-course, transcriptomics data in 4 tissues in mice following acute and long-term endurance exercise and developed machine learning capability for mining the multi-omics data for identification of regulatory factors that mediate the exercise benefits; 2) We have perfected CRISPR/Cas9-mediated gene editing for generation of loss- of-function knock-in mice as well as techniques to generate tissue-specific, inducible gain-of-function transgenic mice; 3) We have established comprehensive phenotypic analysis in mice; and 4) We have had a successful experience in elucidating the regulation and function of extracellular superoxide dismutase (EcSOD), a humoral factor expressed in skeletal muscle and promoted by endurance exercise, in mediating the health benefits and protection against diseases. We hypothesize that endurance exercise promotes expression and release of one or more humoral factors from one or multiple tissues/organs, which is sufficient and necessary mediating the health benefits of exercise. To this end, we propose 1) Identify candidate molecular transducers of physical activity by machine learning-based multi-omics modeling. 2) Generate loss-of-function knock-in and tissue-specific, gain-of-function transgenic mice using CRISPR/Cas9- mediated gene editing and transgenesis. 3) Elucidate the role of the candidate molecular transducers of physical activity in health benefits of exercise. The experimental design and model systems are both conceptually and technically innovative. The findings will significantly improve the mechanistic understanding of exercise-induced adaptations with great potential impact on the future development of therapeutics for NCD. PROJECT NARRATIVE Since ancient times, physical activity has been well-known to improve health and prevents disease, but the understanding of biological molecule(s) responsible for the health benefits is still obscure. We formed a multi- disciplinary team to employ computational machine learning to explore the multi-omics data obtained from MoTrPAC to identify the potential molecule(s) followed by the state-of-the-art gene editing in mice to elucidate how this molecule(s) could transduce the health benefits of physical activity.",Machine learning-based multi-omics modeling and CRISPR/Cas9-mediated gene editing in elucidating molecular transducer of physical activity,10131449,U01AG070960,"['Acute', 'Animals', 'Area', 'Biological', 'Biological Models', 'Blood Circulation', 'Brain', 'CRISPR/Cas technology', 'Cardiac', 'Cardiovascular system', 'Cessation of life', 'Cognition', 'Consumption', 'Data', 'Development', 'Disease', 'Endocrine', 'Exercise', 'Experimental Designs', 'Experimental Models', 'Fatty acid glycerol esters', 'Fibrinogen', 'Foundations', 'Funding', 'Future', 'Gene Transfer Techniques', 'Generations', 'Genes', 'Health', 'Health Benefit', 'Health Promotion', 'Health protection', 'Heart', 'Hippocampus (Brain)', 'Human', 'Hypothalamic structure', 'Knock-in', 'Knock-in Mouse', 'Ligands', 'Liver', 'Liver Circulation', 'Longitudinal Studies', 'Machine Learning', 'Mediating', 'Metabolic', 'Metabolism', 'Metals', 'Mining', 'Modeling', 'Molecular', 'Multiomic Data', 'Mus', 'Muscle', 'Mutation', 'Neurodegenerative Disorders', 'Organ', 'Phenotype', 'Physical activity', 'Prevention', 'Proteins', 'Proteomics', 'Psyche structure', 'Rattus', 'Regulation', 'Regulator Genes', 'Research Design', 'Role', 'Site', 'Skeletal Muscle', 'Solid', 'Superoxide Dismutase', 'Techniques', 'Tetanus Helper Peptide', 'Time', 'Tissues', 'Transducers', 'Transgenes', 'Transgenic Mice', 'Treatment Efficacy', 'United States National Institutes of Health', 'autocrine', 'base', 'bisulfite sequencing', 'cognitive function', 'combat', 'design', 'effective intervention', 'endurance exercise', 'exercise capacity', 'exercise training', 'experience', 'extracellular', 'gain of function', 'improved', 'innovation', 'loss of function', 'mental function', 'metabolomics', 'multidisciplinary', 'multiple omics', 'paracrine', 'phenotypic data', 'phosphoproteomics', 'pre-clinical', 'prevent', 'programs', 'receptor', 'response', 'skeletal', 'therapeutic development', 'transcriptome sequencing', 'transcriptomics']",NIA,UNIVERSITY OF VIRGINIA,U01,2020,457208,-0.017729954058849983
"Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach Project Summary Biology is full of stunning examples of emergent behaviors – behaviors that arise from, but cannot be reduced to, the interactions of the constituent parts that make up the system under consideration. These behaviors span the full spectrum of length scales, from the emergence of distinct cell fates (e.g. neurons, muscle, etc.) due to the interactions of genes within cells, to the formation of complex ecological communities arising from the interactions of thousands of species. The overarching goal of my research is to develop new conceptual, theoretical, and computational tools to model such emergent, system-level behaviors in biology. To do so, we utilize an interdisciplinary approach that is grounded in Biological Physics, but draws heavily from Machine Learning, Information Theory, and Theoretical Ecology. Our work is unified and distinguished by our deep commitment to integrating theory with the vast amount of biological data now being generated by modern DNA sequencing-based techniques and quantitative microscopy. An important goal of the proposed research is to find common concepts and tools that transcend traditional biological sub-disciplines and models systems. The proposed research pursues four distinct but conceptually interrelated research directions: (1) understanding how distinct cell fates emerge from bimolecular interactions within mammalian cells (2) investigating how bimolecular networks within cells exploit energy consumption to improve computations, with applications to Synthetic Biology; (3) identifying the ecological principles governing community assembly in microbial communities and developing techniques for synthetically engineering ecological communities; and (4) developing new machine learning algorithms and techniques for biological data analysis. In addition to developing physics-based models for diverse biological phenomena, the proposed research will yield a series of practical important tools and algorithms which we will make publically available including: (1) a new linear-algebra based algorithm for assessing the fidelity of directed differentiation and cellular reprogramming protocols and visualizing reprogramming/differentiation dynamics and (2) improved algorithms for inferring microbial interactions in the human microbiome from high-throughput sequence data. These computational tools will allow scientists to realize the immense therapeutic potential of cellular reprogramming and microbial ecology-based techniques for studying and treating human disease. Project Narrative This project will develop new theoretical and computational tools that will allow scientists to realize the immense therapeutic potential of cellular reprogramming (the conversion of one cell type into another cell type) and microbial ecology-based techniques for studying and treating human diseases.",Modeling Emergent Behaviors in Systems Biology: A Biological Physics Approach,9963304,R35GM119461,"['Algorithms', 'Behavior', 'Biological', 'Biological Models', 'Biological Phenomena', 'Biology', 'Cells', 'Communities', 'Complex', 'Consumption', 'DNA sequencing', 'Data', 'Data Analyses', 'Discipline', 'Ecology', 'Engineering', 'Goals', 'Human Microbiome', 'Information Theory', 'Length', 'Linear Algebra', 'Machine Learning', 'Mammalian Cell', 'Modeling', 'Modernization', 'Muscle', 'Neurons', 'Physics', 'Protocols documentation', 'Quantitative Microscopy', 'Research', 'Scientist', 'Series', 'System', 'Systems Biology', 'Techniques', 'Therapeutic', 'Transcend', 'Work', 'base', 'cell type', 'computerized tools', 'gene interaction', 'human disease', 'improved', 'interdisciplinary approach', 'machine learning algorithm', 'microbial', 'microbial community', 'microorganism interaction', 'synthetic biology', 'theories', 'tool']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2020,330294,-0.011384054376679578
"Learning Dynamics of Biological Processes from Time Course Omics Datasets Complex biological processes, including organ development, immune response and disease progression, are inherently dynamic. Learning their regulatory architecture requires understanding how components of a large system dynamically interact with each other and give rise to emergent behavior. Recent experimental advances have made ii possible to investigate these biological systems in a data-driven fashion al high temporal resolution, allowing identification of new genes and their regulatory interactions. Longitudinal omics data sets are becoming increasingly common in clinical practice as well. Information on these collections of interacting genes can be integrated to gain systems-level insights into the roles of biological pathways and processes, including progression of diseases. Consequently, developing interpretable methods for learning functional relationships among genes, proteins or metabolites from high-dimensional time series data has become a timely research problem. The nature of these time-course data sets presents exciting opportunities and interesting challenges from a statistical perspective. Typical time-course omics data sets are challenging because of their high-dimensionality and non-linear relationships among system components. To tackle these challenges, one needs sophisticated dimension-reduction techniques that are biologically meaningful, computationally efficient and allow uncertainty quantification. Methods that incorporate prior biological information (e.g., pathway membership, protein-protein interactions) into the data analysis are good candidates for analyzing such high-dimensional systems using small samples. Here, we will develop three core methods to address the above challenges - (Aim 1): an empirical Bayes framework for clustering high-dimensional omics time-course data using prior biological knowledge; (Aim 2): a quantile-based Granger causality framework for learning interactions among genes or metabolites from their lead-lag relationships; and (Aim 3): a decision tree ensemble framework for searching cascades of interactions among genes from their temporal expression profiles. Our interdisciplinary team of statisticians and scientists will analyze time-course omics data from three research projects: (i) innate immune response systems in Drosophila, (ii) developmental process in mouse models, and (ii) longitudinal metabolite profiling of TB patients. These insights will be used to build and validate our methodology, which will be implemented in a publicly available software. This proposal is innovative in its incorporation of prior biological knowledge in the framework of novel dimension reduction techniques for interrogating high-dimensional time-course omics data. This research is significant in that it will impact basic sciences by elucidating data-driven, testable hypotheses on the regulatory architecture of biological processes, and clinical practice by monitoring disease progression and prognosis. n/a",Learning Dynamics of Biological Processes from Time Course Omics Datasets,10021429,R01GM135926,"['Address', 'Algorithms', 'Architecture', 'Basic Science', 'Behavior', 'Biological', 'Biological Process', 'Clinical', 'Collection', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Development', 'Developmental Process', 'Dimensions', 'Disease Progression', 'Drosophila genus', 'Etiology', 'Expression Profiling', 'Gene Proteins', 'Genes', 'Grouping', 'Immune System Diseases', 'Immune response', 'Innate Immune Response', 'Knowledge', 'Lead', 'Learning', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Pathway Analysis', 'Pathway interactions', 'Patients', 'Pattern', 'Process', 'Research', 'Research Project Grants', 'Role', 'Sampling', 'Scientist', 'Series', 'Silicon Dioxide', 'Structure', 'System', 'Techniques', 'Time', 'Uncertainty', 'Validation', 'Variant', 'base', 'biological systems', 'clinical practice', 'dynamic system', 'experimental study', 'high dimensionality', 'innovation', 'insight', 'learning algorithm', 'learning strategy', 'mouse model', 'novel', 'open source', 'organ growth', 'outcome forecast', 'protein protein interaction', 'random forest', 'temporal measurement']",NIGMS,CORNELL UNIVERSITY,R01,2020,344345,-0.004839555722562042
"Mechanism-Driven Virtual Adverse Outcome Pathway Modeling for Hepatotoxicity PROJECT SUMMARY/ABSTRACT  Experimental animal and clinical testing to evaluate hepatotoxicity demands extensive resources and long turnaround times. Utilization of computational models to directly predict the toxicity of new compounds is a promising strategy to reduce the cost of drug development and to screen the multitude of industrial chemicals and environmental contaminants currently lacking safety assessments. However, the current computational models for complex toxicity endpoints, such as hepatotoxicity, are not reliable for screening new compounds and face numerous challenges. Our recent studies have shown that traditional Quantitative Structure-Activity Relationship modeling is applicable for relatively simple properties or toxicity endpoints with a clear mechanism, but fails to address complex bioactivities such as hepatotoxicity. The primary objective of this proposal is to develop novel mechanism-driven Virtual Adverse Outcome Pathway (vAOP) models for the fast and accurate assessment of hepatotoxicity in a high-throughput manner The resulting vAOP models will be experimentally validated using a complement of in vitro and ex vivo testing. We have generated a preliminary vAOP model based on the antioxidant response element (ARE) pathway that has undergone initial validation and refinement using in vitro testing. To this end, our project will generate novel predictive models for hepatotoxicity by applying 1) a virtual cellular stress pathway model to mechanism profiling and assessment of new compounds; 2) computational predictions to fill in the missing data for specific targets within the pathway; 3) in vitro experimental validation with three complementary bioassays; and 4) ex vivo experimental validation with pooled primary human hepatocytes capable of biochemical transformation. The scientific approach of this study is to develop a universal modeling workflow that can take advantage of all available short-term testing information, obtained from both computational predictions using novel machine learning approaches and in vitro experiments, for target compounds of interest. We will validate and use our modeling workflow to directly evaluate the hepatotoxicity of new compounds and prioritize candidates for validation in pooled primary human hepatocytes. The resulting workflow will be disseminated via a web portal for public users around the world with internet access. Importantly, this study will pave the way for the next generation of chemical toxicity assessment by reconstructing the modeling process through a combination of big data, computational modeling, and low cost in vitro experiments. To the best of our knowledge, the implementation of this project will lead to the first publicly available mechanisms-driven modeling and web- based prediction framework for complex chemical toxicity based on publicly-accessible big data. These deliverables will have a significant public health impact by not only prioritizing compounds for safety testing or new chemical development, but also revealing toxicity mechanisms. PROJECT NARRATIVE Hepatotoxicity is a leading safety concern in the development of new chemicals. We will create virtual “Adverse Outcome Pathway” models that will directly evaluate the hepatotoxicity potentials of chemicals using massive public toxicity data. The primary deliverable of this project will be a publically-accessible, web-based search engine to evaluate new chemicals for risk of hepatotoxicity.",Mechanism-Driven Virtual Adverse Outcome Pathway Modeling for Hepatotoxicity,9864299,R01ES031080,"['Address', 'Animal Model', 'Animal Testing', 'Antioxidants', 'Big Data', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Cellular Stress', 'Chemical Injury', 'Chemical Structure', 'Chemicals', 'Clinical', 'Complement', 'Complex', 'Computer Models', 'Computer software', 'Computers', 'Cryopreservation', 'Custom', 'Data', 'Data Pooling', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Drug Costs', 'Ensure', 'Environment', 'Environmental Pollution', 'Evaluation', 'Face', 'Generations', 'Hepatocyte', 'Hepatotoxicity', 'Human', 'In Vitro', 'Industrialization', 'Injury', 'Internet', 'Libraries', 'Liver', 'Luciferases', 'Machine Learning', 'Marketing', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nutraceutical', 'Online Systems', 'Pathway interactions', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Population', 'Process', 'Property', 'Proteomics', 'PubChem', 'Public Health', 'Quantitative Structure-Activity Relationship', 'Research', 'Research Personnel', 'Resources', 'Response Elements', 'Risk', 'Safety', 'Signal Transduction', 'Source', 'Statutes and Laws', 'System', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Toxicology', 'Translating', 'Validation', 'Vertebrates', 'adverse outcome', 'base', 'candidate validation', 'cell injury', 'combat', 'computational toxicology', 'computer framework', 'computerized tools', 'cost', 'data mining', 'deep neural network', 'design', 'developmental toxicity', 'drug development', 'endoplasmic reticulum stress', 'experimental study', 'hepatocellular injury', 'improved', 'in vitro Assay', 'in vitro testing', 'in vivo', 'interest', 'knowledge base', 'large datasets', 'liver injury', 'next generation', 'novel', 'pre-clinical', 'predictive modeling', 'reproductive toxicity', 'research clinical testing', 'safety assessment', 'safety testing', 'screening', 'search engine', 'tool', 'toxicant', 'transcriptomics', 'virtual', 'web portal']",NIEHS,RUTGERS THE STATE UNIV OF NJ CAMDEN,R01,2020,465692,-0.005547917190259182
"An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics Immune-repertoire sequence, which consists of an individual's millions of unique antibody and T-cell receptor (TCR) genes, encodes a dynamic and highly personalized record of an individual's state of health. Our long- term goal is to develop the computational models and tools necessary to read this record, to one day be able diagnose diverse infections, autoimmune diseases, cancers, and other conditions directly from repertoire se- quence. The key problem is how to find patterns of specific diseases in repertoire sequence, when repertoires are so complex. Our hypothesis is that a combination of bottom-up (sequence-level) and top-down (systems- level) modeling can reveal these patterns, by encoding repertoires as simple but highly informative models that can be used to build highly sensitive and specific disease classifiers. In preliminary studies, we introduced two new modeling approaches for this purpose: (i) statistical biophysics (bottom-up) and (ii) functional diversity (top-down), and showed their ability to elucidate patterns related to vaccination status (97% accuracy), viral infection, and aging. Building on these studies, we will test our hypothesis through two specific aims: (1) We will develop models and classifiers based on the bottom-up approach, statistical biophysics; and (2) we will de- velop the top-down approach, functional diversity, to improve these classifiers. To achieve these aims, we will use our extensive collection of public immune-repertoire datasets, beginning with 391 antibody and TCR da- tasets we have characterized previously. Our team has deep and complementary expertise in developing computational tools for finding patterns in immune repertoires (Dr. Arnaout) and in the mathematics that under- lie these tools (Dr. Altschul), with additional advice available as needed regarding machine learning (Dr. AlQuraishi). This proposal is highly innovative for how our two new approaches address previous issues in the field. (i) Statistical biophysics uses a powerful machine-learning method called maximum-entropy modeling (MaxEnt), improving on past work by tailoring MaxEnt to learn patterns encoded in the biophysical properties (e.g. size and charge) of the amino acids that make up antibodies/TCRs; these properties ultimately determine what targets antibodies/TCRs can bind, and therefore which sequences are present in different diseases. (ii) Functional diversity fills a key gap in how immunological diversity has been measured thus far, by factoring in whether different antibodies/TCRs are likely to bind the same target. This proposal is highly significant for (i) developing an efficient, accurate, generative, and interpretable machine-learning method for finding diagnostic patterns in repertoire sequence; (ii) applying a robust mathematical framework to the measurement of immuno- logical diversity; (iii) impacting clinical diagnostics; and (iv) adding a valuable new tool for integrative/big-data medicine. The expected outcome of this proposal is an integrated pair of robust and well validated new tools/models for classifying specific disease exposures directly from repertoire sequence. This proposal in- cludes plans to make these tools widely available, to maximize their positive impact across medicine. The proposed research is relevant to public health because B cells/antibodies and T cells play vital roles across such a vast range of health conditions, from infection, to autoimmunity, to cancer, that the ability to de- code what they are doing would be an important step forward for diagnosing these conditions. The proposed research is relevant to the NIH's mission of fostering fundamental creative discoveries, innovative research strategies, and their applications as a basis for ultimately protecting and improving health, specifically relating to the diagnosis of human diseases.",An Integrated Multilevel Modeling Framework for Repertoire-Based Diagnostics,10050030,R01AI148747,"['Address', 'Affect', 'Aging', 'Amino Acid Motifs', 'Amino Acids', 'Antibodies', 'Autoimmune Diseases', 'Autoimmunity', 'B-Lymphocytes', 'Base Sequence', 'Big Data', 'Binding', 'Biophysics', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Code', 'Collection', 'Complex', 'Computer Models', 'Data Set', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Entropy', 'Fostering', 'Gene Frequency', 'Genes', 'Goals', 'Health', 'Human', 'Immune', 'Immunology', 'Individual', 'Infection', 'Influenza vaccination', 'Intuition', 'Learning', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mission', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Physics', 'Play', 'Population Heterogeneity', 'Privatization', 'Property', 'Public Health', 'Reading', 'Reporting', 'Research', 'Role', 'Sample Size', 'Sampling', 'Sampling Errors', 'Signs and Symptoms', 'Speed', 'Statistical Study', 'System', 'T-Cell Receptor', 'T-Cell Receptor Genes', 'T-Lymphocyte', 'Testing', 'United States National Institutes of Health', 'Vaccination', 'Virus Diseases', 'Work', 'base', 'biophysical properties', 'clinical diagnostics', 'computerized tools', 'diagnostic accuracy', 'human disease', 'immunological diversity', 'improved', 'information model', 'innovation', 'machine learning method', 'multidisciplinary', 'multilevel analysis', 'novel', 'novel strategies', 'tool']",NIAID,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2020,535171,-0.007057516385874076
"Computational Explorations of Unconventional Approaches to Control Noncovalent Interactions PROJECT SUMMARY The research interests of my group are rooted in explorations of new and useful conceptual models to improve the control and prediction of noncovalent interactions. Our research involves the use of a variety of computational quantum chemical tools, applications of density functional theory (DFT), cheminformatics, and machine-learning methods. A premise of our research is that aromaticity may be used to modulate many types of noncovalent interactions (such as hydrogen bonding, π-stacking, anion-π interactions). The reciprocal relationship we find, between “aromaticity” in molecules and the strengths of “noncovalent interactions,” is surprising especially since they are typically considered as largely separate ideas in chemistry. The innovation of this research is that it will enable use of intuitive “back-of-the-envelope” electron-counting rules (such as the 4n+2πe Hückel rule for aromaticity) to make predictions of experimental outcomes regarding the impact of noncovalent interactions. A five-year goal is to realize the use of our conceptual models in real synthetic examples prepared by our experimental collaborators. My research vision is to bridge discoveries of innovative concepts to their practical impacts for biomedical and biomolecular research. PROJECT NARRATIVE This research proposal includes four projects that are jointly motivated by the challenge to control and predict noncovalent interactions in organic and biomolecular systems. The proposed work involves applications of a variety of computational quantum chemical tools and synergistic investigations with experimental collaborators. We seek to identify new and useful concepts to guide experimental designs of novel “non-natural” molecular systems (e.g., receptors, biosensors, and hydrogels) that have potential biomedical applications.",Computational Explorations of Unconventional Approaches to Control Noncovalent Interactions,10016376,R35GM133548,"['Anions', 'Back', 'Biosensor', 'Chemicals', 'Chemistry', 'Electrons', 'Experimental Designs', 'Goals', 'Hydrogels', 'Hydrogen Bonding', 'Intuition', 'Investigation', 'Modeling', 'Molecular', 'Outcome', 'Plant Roots', 'Research', 'Research Project Summaries', 'Research Proposals', 'System', 'Vision', 'Work', 'cheminformatics', 'density', 'improved', 'innovation', 'interest', 'machine learning method', 'novel', 'quantum computing', 'receptor', 'theories', 'tool']",NIGMS,UNIVERSITY OF HOUSTON,R35,2020,377200,0.010728018099676492
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9889134,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,356625,-0.017877975374573828
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9872178,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'data analysis pipeline', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'programmed cell death protein 1', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2020,314000,-0.01053293752745621
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9981804,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Models', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in silico', 'in vivo', 'insight', 'intracranial artery', 'microSPECT', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'multiple omics', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'spatiotemporal', 'supervised learning', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2020,601275,-0.015410318001293041
"Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria Project Summary/Abstract Fungal and bacterial pathogens are a major threat to human health. Few therapeutics exist to treat fungal infections while bacteria are becoming increasingly resistant to existing therapeutics. Humans have been using natural products to treat infections for thousands of years, long before the causal agents of infection were understood. Natural products have continued to be used as therapeutics in the modern age of medicine. Rates of rediscovery of known natural products have increased in traditional sources of natural products, such as soil bacteria. Recently, symbiotic Actinobacteria from insect agricultural systems have been recognized as a promising source of bioactive compounds, especially antifungal agents. These bacteria often produce natural products that defend an insect’s fungal crop from pathogenic fungus. The work proposed here will use chemical biology approaches such as phenotypic interaction screens, genomics, and a new bioinformatics approach to systematically search for bioactive natural products produced by Actinobacteria symbionts and other organisms in insect agricultural systems. The first part of this proposal focuses on using existing techniques to identify new bioactive natural products. Phenotypic interaction screens can identify bioactive natural products by determining if a symbiotic bacteria produces a natural product that inhibits the growth of a fungal pathogen and vice-versa. We will then use genomic sequencing, bioinformatics, and heterologous expression to identify and characterize biosynthetic gene clusters (BGCs) that are not expressed in the phenotypic interaction screens. The second part of the proposed work involves the use of a new bioinformatics technique to identify interesting bioactive natural products. Existing bioinformatics techniques identify BGCs and predict the most likely chemical structure of the corresponding natural product. However, they do not conclude anything concerning the functional role that the natural product plays. The technique developed here will use machine learning to predict the function that the natural product fulfills in the ecological context of the organism. This algorithm will facilitate the identification of bioactive natural products with therapeutically relevant functions. Project Narrative Fungal infections are an underappreciated threat to human health with high mortality rates and few effective therapeutic agents for treatment. Symbiotic Actinobacteria from insect agricultural systems are a promising source of antifungal agents since they often produce natural products with antifungal activity protecting an insect’s fungal crop from pathogenic fungus. The work proposed here will use phenotypic interaction screens, genome sequencing, and the development of a novel bioinformatics method to systematically mine Actinobacteria for antifungal and antibacterial products – leading to the discovery of new bioactive small molecules along with a deeper understanding of how natural products mediate the interaction between species in insect agricultural systems.",Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria,9963295,F32GM128267,"['Actinobacteria class', 'Age', 'Agriculture', 'Algorithms', 'Anti-Bacterial Agents', 'Antibiotics', 'Antifungal Agents', 'Ants', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bioinformatics', 'Biological Assay', 'Biology', 'Breathing', 'Chemical Structure', 'Chemicals', 'Collaborations', 'Computational Biology', 'Computing Methodologies', 'Data Set', 'Development', 'Ecosystem', 'Gene Cluster', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Infection', 'Insecta', 'Learning', 'Life', 'Literature', 'Machine Learning', 'Mediating', 'Medicine', 'Methods', 'Mining', 'Modernization', 'Molecular Structure', 'Mycoses', 'Natural Products', 'Organism', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Public Health', 'Resistance', 'Role', 'Soil', 'Source', 'Structure', 'System', 'Techniques', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'Validation', 'Work', 'algorithm development', 'base', 'bioactive natural products', 'drug discovery', 'fungus', 'genetic information', 'genome sequencing', 'human disease', 'machine learning algorithm', 'mortality', 'novel', 'pathogen', 'pathogenic bacteria', 'pathogenic fungus', 'post-doctoral training', 'prediction algorithm', 'small molecule', 'symbiont']",NIGMS,HARVARD MEDICAL SCHOOL,F32,2020,65310,0.00023423470145451824
"Reactome: An Open Knowledgebase of Human Pathways Project Summary  We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated, open access biomolecular pathway database that can be freely used and redistributed by all members of the biological research community. It is used by clinicians, geneti- cists, genomics researchers, and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomic studies, and by systems biologists building predictive models of normal and disease variant pathways.  Our curators, PhD-level scientists with backgrounds in cell and molecular biology work closely with in- dependent investigators within the community to assemble machine-readable descriptions of human biological pathways. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated Reactome pathways currently cover 8930 protein- coding genes (44% of the translated portion of the genome) and ~150 RNA genes. We also offer a network of reliable ‘functional interactions’ (FIs) predicted by a conservative machine-learning approach, which covers an additional 3300 genes, for a combined coverage of roughly 60% of the known genome.  Over the next five years, we will: (1) curate new macromolecular entities, clinically significant protein sequence variants and isoforms, and drug-like molecules, and the complexes these entities form, into new reac- tions; (2) supplement normal pathways with alternative pathways targeted to significant diseases and devel- opmental biology; (3) expand and automate our tools for curation, management and community annotation; (4) integrate pathway modeling technologies using probabilistic graphical models and Boolean networks for pathway and network perturbation studies; (5) develop additional compelling software interfaces directed at both computational and lab biologist users; and (6) and improve outreach to bioinformaticians, molecular bi- ologists and clinical researchers. Project Narrative  Reactome represents one of a very small number of open access curated biological pathway databases. Its authoritative and detailed content has directly and indirectly supported basic and translational research studies with over-representation analysis and network-building tools to discover patterns in high-throughput data. The Reactome database and web site enable scientists, clinicians, researchers, students, and educators to find, organize, and utilize biological information to support data visualization, integration and analysis.",Reactome: An Open Knowledgebase of Human Pathways,9888390,U41HG003751,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Animal Model', 'Applications Grants', 'Back', 'Basic Science', 'Biological', 'Cellular biology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Development', 'Developmental Biology', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Event', 'Funding', 'Genes', 'Genome', 'Genomics', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Pathway interactions', 'Pattern', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'RNA', 'Reaction', 'Readability', 'Research Personnel', 'Scientist', 'Students', 'System', 'Technology', 'Translating', 'Translational Research', 'Variant', 'Work', 'biological research', 'clinically significant', 'data visualization', 'experimental study', 'improved', 'knowledge base', 'member', 'novel', 'outreach', 'predictive modeling', 'research study', 'tool', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2020,1932440,0.019443859235429715
"Imaging Molecular Level Details of Collagen Fibers by VSFG Microscopy In this proposed project, we plan to fill the knowledge gap of the relationships between microscopic self-assembled structures, collagen-molecule interactions and macroscopic fiber morphologies of type-I collagen, the primary component of most human tissues and a commonly used biomaterial for tissue engineering. By investigating collagen-water and collagen-protein interactions in in vitro systems that mimic basic aspects of physiologically relevant three- dimensional fibrillar tissue architectures, we aim to fill knowledge gaps in fundamental collagen research. We will achieve this goal by developing a hyperspectral imaging technique – vibrational sum frequency generation (VSFG) microscopy – at high repetition rates (400 kHz) and apply it to collagen. The long-term vision is to develop new biophysics methods to reveal molecular-level structures and interactions for pericellular space research and other complex biological environments, and eventually applying it to study various pericellular environment related diseases. In order to correlate spectral features to microscopic and macroscopic structures of type I collagen, we plan to apply machine-learning techniques to analyze our data and extract spectral signatures of collagen’s micro/macrostructures. We will two major scientific focuses: (A) understanding molecular signatures of microscopic self-assembly fibrils structures and its relationship to the macroscopic morphology (plan 1 and 2); and (B) investigating molecular level collagen-molecule interactions (plan 3 and 4). Specific plans include:  1. Obtaining hyperspectral VSFG images of collagen tissues to study their morphology in a  label free and non-invasive manner  2. Establishing molecular spectral signatures of self-assembled collagen fibril structures  3. Understanding collagen-water interaction in first solvation layer of collagen fibers.  4. Imaging spatial locations of chemicals and peptides that interact with collagens. If successful, the significance is that a label free, vibrational mode specific imaging technique specific for pericellular space will be available, which can reveal molecular level insights of collagen structures and its interactions with surrounding molecules, pertinent to fibrosis and cell— pericellular space interaction related diseases. This proposed project contributes to the scope of NIGMS by developing new technology to reveal fundamental molecular-level principle, mechanism and signatures related to morphology of collagen I at both micro- and macroscopic scales, and collagen-molecule interactions, laying foundations for biophysical/biochemical principles for future biomedical applications related to collagens. This proposed development of vibrational sum frequency generation microscopy, in the short term, will spatially resolve collagen tissues with chemical structure and molecular interaction information in a complicated environment. Machine learning and simulation approaches will be employed to build a data base to convert hyperspectral images of collagen into a spatial map with microscopic structures and molecular interaction information. In the long term, the fundamental biochemical knowledge learned from this development will lay foundations for rationally design biomedical approaches to monitor and control pericellular spaces and its interaction with cells, and further advance treatment to diseases related to it.",Imaging Molecular Level Details of Collagen Fibers by VSFG Microscopy,10028946,R35GM138092,"['3-Dimensional', 'Architecture', 'Binding', 'Biochemical', 'Biocompatible Materials', 'Biological', 'Biophysics', 'Cells', 'Chemical Structure', 'Chemicals', 'Collagen', 'Collagen Fiber', 'Collagen Fibril', 'Collagen Type I', 'Complex', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Fiber', 'Fibrosis', 'Foundations', 'Frequencies', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'In Vitro', 'Knowledge', 'Label', 'Location', 'Machine Learning', 'Maps', 'Microscopic', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Monitor', 'Morphology', 'National Institute of General Medical Sciences', 'Peptides', 'Physiological', 'Proteins', 'Research', 'Structure', 'Sum', 'System', 'Techniques', 'Tissue Engineering', 'Tissues', 'Vision', 'Water', 'biophysical techniques', 'design', 'human tissue', 'image reconstruction', 'insight', 'molecular imaging', 'new technology', 'self assembly', 'simulation', 'vibration']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R35,2020,393958,-0.019372075565055956
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,9968331,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computational pipelines', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'in silico', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2020,1024120,0.01469389239847055
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,10260964,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computational pipelines', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'in silico', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2020,152500,0.01469389239847055
"Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Summary: Viruses are ubiquitous in almost every ecological environment including the human body, water, soil, etc. They play important roles in the normal function of human microbiome. Many viruses have been shown to be associated with human diseases. However, our understanding of the roles of viruses in ecological communities is very limited. Recent technological and computational advances make it possible to have a deep understanding of the roles of viruses in public health and the environment. Metagenomics studies from various environments including the human microbiome projects (HMP), global ocean, and the earth microbiome projects have generated large amounts of short read data. Viruses are present in most of these metagenomic data sets and their hosts are unknown. In this proposal, the investigators will develop computational approaches for the identification of viral sequences from metagenomic data sets and for the study of virus-host interactions. For the identification of viral sequences from metagenomics samples, novel statistical measures using word patterns will first be developed. Second, a unified naïve Bayesian integrative approach by combining information from word patterns, gene directionality, and gene annotation will be studied. Third, the identified viral sequences from metagenomes will be further assembled to construct complete viral genomes using a novel binning approach to be developed by the investigators. Finally, the remaining reads will be assigned to the corresponding bins. For the study of virus- host interactions, computational methods to estimate the reliability of virus-host interactions from high-throughput experiments will first be developed. Then machine learning approaches will be developed to predict viruses infecting certain hosts. Finally, a network logistic regression approach will be developed to predict virus-host interactions. These computational approaches for the identification of viral sequences and for predicting virus-host interactions will be applied to a public liver cirrhosis and a unique metagenomics data set to understand how metagenomes change with health status, identify viruses and virus-host interactions associated with disease status and accurately predict disease status using bacteria, viruses and virus-host interactions. The developed computational methods will also be used to analyze metageomic data from various locations based on the TARA ocean data and a unique time series data to understand how environmental factors affect virus abundance and virus-host interactions. Some of the predictions will be experimentally validated. Software derived from the proposal will be developed and freely distributed to the scientific community. Project Narrative Viruses are abundant in many environments and are important to public health. New statistical and computational tools will be developed for the identification of viral sequences from metagenomics samples and for the prediction of virus-host interactions. These tools will be used to analyze microbial data sets related to liver cirrhosis and travelers’ diarrhea as well as marine metagenomics data sets from various geographic locations and time series.",Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications,9992596,R01GM120624,"['Affect', 'Bacteria', 'Biological', 'Body Water', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Environment', 'Environment and Public Health', 'Environmental Risk Factor', 'Functional disorder', 'Genes', 'Genome', 'Geographic Locations', 'Health', 'Health Status', 'Human', 'Human Microbiome', 'Human body', 'Liver Cirrhosis', 'Location', 'Logistic Regressions', 'Machine Learning', 'Measures', 'Metagenomics', 'Methods', 'Microbe', 'Network-based', 'Oceans', 'Organism', 'Pattern', 'Planet Earth', 'Play', 'Policies', 'Public Health', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Series', 'Soil', 'Technology', 'Time', 'Traveler&apos', 's diarrhea', 'Viral', 'Viral Genome', 'Virus', 'Virus Diseases', 'Visualization software', 'base', 'computer studies', 'computerized tools', 'contig', 'design', 'experimental study', 'gut metagenome', 'human disease', 'interest', 'metagenome', 'microbial', 'microbial community', 'microbiome', 'novel', 'particle', 'statistics', 'tool', 'user-friendly', 'virus host interaction']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,20899,0.02105506451195426
"Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications Summary: Viruses are ubiquitous in almost every ecological environment including the human body, water, soil, etc. They play important roles in the normal function of human microbiome. Many viruses have been shown to be associated with human diseases. However, our understanding of the roles of viruses in ecological communities is very limited. Recent technological and computational advances make it possible to have a deep understanding of the roles of viruses in public health and the environment. Metagenomics studies from various environments including the human microbiome projects (HMP), global ocean, and the earth microbiome projects have generated large amounts of short read data. Viruses are present in most of these metagenomic data sets and their hosts are unknown. In this proposal, the investigators will develop computational approaches for the identification of viral sequences from metagenomic data sets and for the study of virus-host interactions. For the identification of viral sequences from metagenomics samples, novel statistical measures using word patterns will first be developed. Second, a unified naïve Bayesian integrative approach by combining information from word patterns, gene directionality, and gene annotation will be studied. Third, the identified viral sequences from metagenomes will be further assembled to construct complete viral genomes using a novel binning approach to be developed by the investigators. Finally, the remaining reads will be assigned to the corresponding bins. For the study of virus- host interactions, computational methods to estimate the reliability of virus-host interactions from high-throughput experiments will first be developed. Then machine learning approaches will be developed to predict viruses infecting certain hosts. Finally, a network logistic regression approach will be developed to predict virus-host interactions. These computational approaches for the identification of viral sequences and for predicting virus-host interactions will be applied to a public liver cirrhosis and a unique metagenomics data set to understand how metagenomes change with health status, identify viruses and virus-host interactions associated with disease status and accurately predict disease status using bacteria, viruses and virus-host interactions. The developed computational methods will also be used to analyze metageomic data from various locations based on the TARA ocean data and a unique time series data to understand how environmental factors affect virus abundance and virus-host interactions. Some of the predictions will be experimentally validated. Software derived from the proposal will be developed and freely distributed to the scientific community. Project Narrative Viruses are abundant in many environments and are important to public health. New statistical and computational tools will be developed for the identification of viral sequences from metagenomics samples and for the prediction of virus-host interactions. These tools will be used to analyze microbial data sets related to liver cirrhosis and travelers’ diarrhea as well as marine metagenomics data sets from various geographic locations and time series.",Computational Studies of Virus-host Interactions Using Metagenomics Data and Applications,9899262,R01GM120624,"['Affect', 'Bacteria', 'Biological', 'Body Water', 'Cells', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Disease', 'Environment', 'Environment and Public Health', 'Environmental Risk Factor', 'Functional disorder', 'Genes', 'Genome', 'Geographic Locations', 'Health', 'Health Status', 'Human', 'Human Microbiome', 'Human body', 'Liver Cirrhosis', 'Location', 'Logistic Regressions', 'Machine Learning', 'Measures', 'Metagenomics', 'Methods', 'Microbe', 'Network-based', 'Oceans', 'Organism', 'Pattern', 'Planet Earth', 'Play', 'Policies', 'Public Health', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Series', 'Soil', 'Technology', 'Time', 'Traveler&apos', 's diarrhea', 'Viral', 'Viral Genome', 'Virus', 'Virus Diseases', 'Visualization software', 'base', 'computer studies', 'computerized tools', 'contig', 'design', 'experimental study', 'gut metagenome', 'human disease', 'interest', 'metagenome', 'microbial', 'microbial community', 'microbiome', 'novel', 'particle', 'statistics', 'tool', 'user-friendly', 'virus host interaction']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,430738,0.02105506451195426
"Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity Project Summary Antimicrobial resistance is an increasing problem, and current drug pipelines are not keeping pace with the rise of antimicrobial resistance. An alternative strategy is to boost host immunity. An often overlooked side-effect of the vitamin and mineral supplementation projects of the 1940s is that these supplements greatly reduced infectious disease burden. Recent work has shown that further gains may be possible, especially in adding phytochemicals back to highly processed diets typically consumed in the United States. However, we lack a fundamental understanding of how these components are processed by the microbiome, and how diet-derived molecules, microbiome and host immune system work together to resist infectious disease. A key barrier preventing us from making these discoveries is that each individual assay (microbiome, host gene expression metabolome, dietary compounds) is expensive and highly multivariate. Three key insights that enable the current project are the miniaturization of DNA and RNA sequencing assays on advanced nanoliter- scale liquid handling robots, greatly reducing the cost, the combination of untargeted and targeted mass spectrometry on the same samples in high throughput to enable discovery of a much greater chemical space, and the ability to use explicitly spatial maps on multiple scales to integrate the dataset throughout the body and enable both visual analytics and deep learning approaches based on spatial data. These breakthroughs will provide a fundamentally new understanding of how dietary metabolites promote disease resistance, and will allow us to develop a new infrastructure to integrate results from many investigators in different laboratories studying various aspects of these systems. Additionally, the results will allow us to choose biomaterials and biomarkers in human subjects that provide maximum information about internal nutritional and immune status. Results will be tested against the NHANES and American Gut cohorts. The results of this project will therefore be: 3D maps of mouse models showing how the microbiome, diet, and host gene expression produce immunity; an infrastructure for creating and sharing these maps; and a preliminary test of whether the results extend to large human populations. Project Narrative The public health relevance of this proposal is that it will provide an infrastructure for analyzing impacts of dietary components and microbiomes throughout the body. The analysis of these maps will help us identify dietary components that improve resistance to infectious disease.",Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity,10015205,DP1AT010885,"['3-Dimensional', 'American', 'Antimicrobial Resistance', 'Back', 'Biocompatible Materials', 'Biological Assay', 'Biological Markers', 'Chemicals', 'Communicable Diseases', 'Consumption', 'DNA sequencing', 'Data', 'Data Set', 'Diet', 'Dietary Component', 'Disease Resistance', 'Enhancers', 'Gene Expression', 'Human', 'Immune system', 'Immunity', 'Individual', 'Infrastructure', 'Laboratory Study', 'Liquid substance', 'Maps', 'Mass Spectrum Analysis', 'Metabolite Interaction', 'Microbe', 'Minerals', 'Miniaturization', 'National Health and Nutrition Examination Survey', 'Nutritional status', 'Pharmaceutical Preparations', 'Phytochemical', 'Population', 'Process', 'Research Personnel', 'Resistance', 'Robot', 'Sampling', 'Supplementation', 'System', 'Testing', 'United States', 'Visual', 'Vitamins', 'Work', 'base', 'burden of illness', 'cohort', 'cost', 'deep learning', 'human subject', 'immunological status', 'improved', 'insight', 'metabolome', 'microbiome', 'mouse model', 'nanolitre scale', 'prevent', 'public health relevance', 'side effect', 'transcriptome sequencing']",NCCIH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",DP1,2020,885000,-0.010643740948265314
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,10002192,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Infrastructure', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'data standards', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2020,427122,-0.014942555153853036
"Open Data-driven Infrastructure for Building Biomolecular Force Field for Predictive Biophysics and Drug Design PROJECT SUMMARY/ABSTRACT Molecular simulation is a powerful tool to predict the properties of biomolecules, interpret biophysical experiments, and design small molecules or biomolecules with therapeutic utility. However, a number of obstacles have impeded the development of quantitative, cloud-scale research workﬂows involving biomolecular simulation. Two main ob- stacles are the insufﬁcient accuracy of current atomistic models for biomolecules and small molecule therapeutics and the lack of interoperability in simulation toolchains used in both academic and industrial biomolecular research. Our original R01, “Open Data-driven Infrastructure for Building Biomolecular Force Fields for Predictive Bio- physics and Drug Design,” seeks to solve the ﬁrst problem. It helps fund our effort, the Open Force Field Initiative (https://openforceﬁeld.org) to develop open, extensible, and shared software and data infrastructure, implementing statistically robust methods of parameterizing force ﬁelds and choosing new force ﬁelds in a statistically sound manner. This work is designed to create not just a new generation of force ﬁelds, but an open technology to continue advancing force ﬁeld science. However, even with improved molecular models, putting together complete workﬂows of biomolecular simulations involves interfacing substantial numbers of different tools. However the majority of the existing molecular simulation workﬂows are mutually incompatible, with differing representations of the molecular models. The Open Force Field Initiative effort already includes the development of molecular data structures that we can ex- port into existing molecular simulation tools. We propose to extend the existing scope of our R01 to create an extensible common molecular simulation representation and translators to and from this representation. Such a set of tools will immediately make it signiﬁcantly easier to combine the disparate workﬂows developed for different sets of molecular simulation tools. Researchers will be able to set up and build the biophysical simulations using their usual tools, but run and analyze them with currently incompatible tools, enabling better matching of computational resources and methods to problems. It will help avoid trapping in a single software framework, and enable combinations of functionalities previously impossible without substantial developer time and effort. We will (Aim 1) work with partners to generalize our modular, extensible object model for representing parameterized biomolecular systems in a manner that accommodates the force ﬁeld terms currently supported by most popular biomolecular simulation packages. We will engineer it to be extensible to advanced interaction forms, such as polarizability and other multibody terms, and machine learning models for intermolecular forces. We will (Aim 2): enable easy conversion between components of molecular simulation workﬂows by allowing other molecular simulation packages to easily store their representations in this data model, developing converters that can import/export this object model to multiple popular ﬁle formats, focusing initially on OpenMM, AMBER, CHARMM, and GROMACS. We will demonstrate the utility of this interface in cloud-ready workﬂows. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life carry out their functions and to design new medications. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms. This supplement will make it much easier for molecular simulation workﬂows to interoperate with each other in large-scale workﬂows.",Open Data-driven Infrastructure for Building Biomolecular Force Field for Predictive Biophysics and Drug Design,10166314,R01GM132386,"['Affinity', 'Binding', 'Biophysics', 'COVID-19', 'Collaborations', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'DNA', 'Development', 'Drug Design', 'Ecosystem', 'Engineering', 'Funding', 'Generations', 'Human', 'Individual', 'Industrialization', 'Infrastructure', 'Language', 'Learning', 'Libraries', 'Life', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Motion', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Problem Solving', 'Property', 'Proteins', 'Pythons', 'RNA', 'Readability', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Scientist', 'Software Framework', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Work', 'Writing', 'biomaterial interface', 'computing resources', 'data infrastructure', 'data modeling', 'design', 'experimental study', 'file format', 'improved', 'interoperability', 'molecular modeling', 'open data', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'sound', 'structured data', 'tool']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,225000,1.739032843808696e-05
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9858390,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data infrastructure', 'data integration', 'data standards', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'large scale data', 'member', 'mouse genome', 'multiple data types', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2020,2000000,-0.02625320684986402
"Influenza host specific glycan motif identification through systems biology Project Summary Influenza A viruses (IAVs) have caused large losses of life around the world and continue to present a great public health challenge. IAVs can cause infections in birds, sea mammals, lower mammals (e.g., pigs, dogs, and horses), and humans. Previous studies have demonstrated that the structures of the carbohydrate receptors determine influenza host and tissue tropisms. Thus, it is necessary to understand the receptor- binding properties for IAVs and monitor changes to them, especially for IAVs at the animal–human interface. However, this understanding is hampered by our lack of detailed knowledge of IAV glycan substructures; most of our knowledge is limited to SA2,3Gal-like and SA2,6Gal-like structures. The goals of this project are to develop and validate a machine learning method to identify host-specific glycan substructures for IAVs by using glycan array data and to identify and validate the glycan motifs associated with the host tropisms of IAVs, including those for zoonotic IAVs. The study will focus on natural hosts of IAVs: humans, swine, canines, equines, and various avian species, including common domestic poultry species and wild bird species. We expect to identify structural determinants for receptor binding with human-, swine-, canine-, and avian-origin IAVs. Such knowledge will help us understand the factors that contribute to influenza infection and transmission and thereby facilitate development of an effective influenza vaccine to prevent virus infection and block virus transmission. This knowledge will also help us develop rapid assays for monitoring emerging influenza threats at the animal–human interface. We also expect to develop a computational method for identifying glycan motifs associated with influenza host tropisms; this method will be able to be adapted to determine functional glycan motifs for other proteins, lectins, antibodies, antisera, and microorganisms, including those of other infectious pathogens, by using glycan arrays. Project Narrative This project will develop and apply a computational tool to identify glycan motifs associated with influenza host tropisms, and the derived knowledge will help us develop effective strategies for influenza prevention and control.",Influenza host specific glycan motif identification through systems biology,9895377,R21AI144433,"['Affect', 'Animals', 'Antibodies', 'Area', 'Avian Influenza A Virus', 'Binding', 'Binding Sites', 'Biological', 'Biological Assay', 'Biosensor', 'Birds', 'Canis familiaris', 'Code', 'Complex', 'Computing Methodologies', 'Data', 'Data Set', 'Development', 'Domestic Fowls', 'Equus caballus', 'Family suidae', 'Goals', 'Growth', 'Hemagglutinin', 'Human', 'Immune Sera', 'Infection', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Knowledge', 'Learning', 'Lectin', 'Life', 'Link', 'Mammals', 'Methods', 'Molecular', 'Monitor', 'Mutation', 'National Institute of Allergy and Infectious Disease', 'Natural History', 'Pathogenesis', 'Performance', 'Play', 'Polysaccharides', 'Property', 'Proteins', 'Public Health', 'Research', 'Resources', 'Risk', 'Role', 'Sea', 'Sialic Acids', 'Signal Transduction', 'Slide', 'Strategic Planning', 'Streptavidin', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Tissues', 'Trees', 'Tropism', 'United States National Institutes of Health', 'Validation', 'Variant', 'Virus Diseases', 'Zoonoses', 'base', 'carbohydrate receptor', 'carbohydrate structure', 'computerized tools', 'design', 'experimental study', 'flu transmission', 'improved', 'in silico', 'influenza virus vaccine', 'influenzavirus', 'large datasets', 'learning strategy', 'machine learning method', 'microorganism', 'multi-task learning', 'multitask', 'novel', 'pathogen', 'prevent', 'protein profiling', 'receptor', 'receptor binding', 'respiratory', 'response', 'swine influenza', 'tissue tropism', 'tool', 'transmission process', 'universal influenza vaccine', 'viral transmission', 'wild bird']",NIAID,UNIVERSITY OF MISSOURI-COLUMBIA,R21,2020,239725,-0.007046093857799638
"Dissecting host-pathogen interactions through the lens of genomics Summary: Dissecting host-pathogen interactions through the lens of genomics Current investigation of mechanisms underlying many diseases relies on the acquisition of multi-dimensional genomics data. The utility of these data is, however, offset by the lag in development of tools and models to fully interrogate them. In the context of infectious diseases, such data contains molecular information including gene transcription, regulation, and variations from both the infecting pathogen and the host cell, providing a snapshot of the host and pathogen interactions (HPIs). These HPIs determine infection outcomes. For instance, when a pathogen evades, or evolves resistance to defensive host immunity via a multifaceted HPI, it can result in persisting infection, chronic inflammation, malignant transformation, and/or elevated mortality. Recent successes in overcoming immune-evasion of infected tumor cells with checkpoint inhibitors exemplifies the clinical gains that can be made by identifying and specifically targeting essential mechanisms of HPIs. Hence, precisely identifying new mode(s) of HPIs is critical for development of effective and personalized interventions. The molecular mechanisms of HPIs underpinning disease can be identified from genomics data. For example, information on whether a transcription factor (TF) regulates genes from either host or pathogen, or both, can be captured by chromatin immunoprecipitation (ChIP) sequencing of infected host cells. This means that integrative analysis of genome-scale data can provide a platform for large-scale and unbiased detection of often multi- dimensional and novel facets of HPIs in host cells. However, there is a lack of data mining tools and models to extract such information. More importantly, the available analysis tools typically focus on data from either the host or the pathogen and not on the interactions occurring between the two, excluding us from investigating the full HPI spectrum. Thus, novel methods to determine HPIs by simultaneously modeling both host and pathogen data are critical for understanding key cellular mechanisms and developing treatment strategies. My lab specializes in developing computational models to construct HPI maps and to experimentally validate them. As proof-of-principle, we produced a comprehensive HPI map from sequencing samples from large numbers of tumors caused by Epstein–Barr virus. This map delivered unprecedented insights, identifying novel viral integrations, mutations linked to viral reactivation and providing molecular classification of tumors expected to yield individualized cancer therapy. Therefore, my lab is uniquely positioned to uncover mechanistic insights from HPIs. Our program seeks to develop new models and machine learning tools to construct HPI maps in several diseases by focusing on the following major questions: 1) how do expression, integration, and mutational landscapes of host and pathogen affect pathogenesis of disease?; 2) what is the nature of physical HPIs and cross-regulation by major host and pathogen factors that modulate gene expression, such as TFs and RNA binding proteins?; 3) how do HPIs define molecular subtypes to guide personalized treatments? We expect to identify novel HPIs and provide systems-level understanding of mechanisms critical to cell biology. Narrative Understanding how host cells and pathogens interact is key to developing new and individualized therapeutics. Here, we will develop novel computational tools and models to analyze existing and newly generated high throughput data and construct multi-dimensional host pathogen interaction maps. These maps will provide detailed mechanisms underpinning multi-faceted interactions occurring between host and pathogen and will delineate molecular subtypes that can be utilized for novel and personalized treatment options.",Dissecting host-pathogen interactions through the lens of genomics,10028454,R35GM138283,"['Affect', 'Cells', 'Cellular biology', 'ChIP-seq', 'Chronic', 'Clinical', 'Communicable Diseases', 'Computer Models', 'Data', 'Detection', 'Development', 'Disease', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomics', 'Human Herpesvirus 4', 'Immune Evasion', 'Immune checkpoint inhibitor', 'Immunity', 'Infection', 'Inflammation', 'Investigation', 'Link', 'Machine Learning', 'Malignant - descriptor', 'Maps', 'Methods', 'Modeling', 'Molecular', 'Molecular Classification of Tumors', 'Mutation', 'Nature', 'Outcome', 'Pathogenesis', 'Positioning Attribute', 'RNA-Binding Proteins', 'Regulation', 'Resistance', 'Sampling', 'System', 'Therapeutic', 'Transcriptional Regulation', 'Variant', 'Viral', 'Virus Integration', 'computerized tools', 'data mining', 'effective intervention', 'genome analysis', 'genome-wide', 'genomic data', 'insight', 'lens', 'molecular subtypes', 'mortality', 'neoplastic cell', 'novel', 'pathogen', 'personalized cancer therapy', 'personalized intervention', 'personalized medicine', 'programs', 'success', 'tool', 'tool development', 'transcription factor', 'treatment strategy', 'tumor']",NIGMS,PURDUE UNIVERSITY,R35,2020,381824,-0.008237024864900114
"Simulation of Proton Translocation in Biomolecules PROJECT SUMMARY  The transport of protons in biomolecular systems is a phenomenon of fundamental importance to processes such as ATP synthesis, enzyme catalysis, the maintenance of pH gradients, proton pumping, viral infection, and substrate/ion transport across membranes via protein transporters, symporters, and antiporters. Modeling biomolecular proton translocation in silico is a significant challenge due to the complex chemical reactions involved in Grotthuss proton shutting between water molecules and with protonatable amino acids, as well as the complexity of the target biomolecular systems. In most cases, it is not only important to understand the mechanism of proton binding and transport, but also its coupling to other mechanistically relevant biomolecular processes, such as protein conformational changes, substrate binding, other protonation events, and dynamic hydration.  In this project the continued development and application of a powerful multiscale computer simulation methodology is described for the study of proton transport in several key classes of proton translocating biomolecular systems, including channels (influenza A and B M2 channels), antiporters/symporters (ClC Cl-/H+ antiporter and phosphate transporter, respectively), and transporters (proton-coupled oligopeptide transporter and EmrE multidrug transporter). The overall research plan is made possible by a novel reactive molecular dynamics simulation approach integrated with quantum mechanics/molecular mechanics (QM/MM) methods that allows for the study of explicit long-length and -time scale proton transport through water molecules and ionizable molecular groups in hydrogen-bonded networks, as well as by new innovations in enhanced free energy sampling methodology, machine learning, kinetic network theory, and coarse-graining. A primary goal in the research with this methodology in hand is to reveal the mechanisms of proton transport, as well as its coupling to hydration and conformational changes, in the above mentioned biomolecular systems. All of these studies will be carried out in collaboration with leading experimentalists, while continuing to add a new dimension to the field of biomolecular computer simulation as a whole. 1 PROJECT NARRATIVE  In this project, computer simulations will be used to study proton transport in several important biomolecular systems. Proton translocation is of fundamental significance throughout biology, as demonstrated by the pH-dependence of biomolecular structure and function and the central role of transmembrane proton gradients in bioenergy conversion. Moreover, understanding proton transport is of fundamental importance and direct relevance to numerous aspects of human health, including metabolism, aging, diabetes, neurodegeneration, retinal degeneration, antivral and anti-bacterial therapeutics, and homeostasis. 1",Simulation of Proton Translocation in Biomolecules,9934213,R01GM053148,"['ATP Synthesis Pathway', 'Achievement', 'Aging', 'Agreement', 'Amino Acids', 'Anions', 'Anti-Bacterial Agents', 'Area', 'Behavior', 'Binding', 'Biology', 'Carrier Proteins', 'Catalysis', 'Charge', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Consult', 'Coupled', 'Coupling', 'Data', 'Defect', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diffusion', 'Dimensions', 'Elements', 'Entropy', 'Enzymes', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Grain', 'Hand', 'Health', 'Homeostasis', 'Human', 'Hydration status', 'Hydrogen Bonding', 'Influenza', 'Influenza A virus', 'Influenza B Virus', 'Inorganic Phosphate Transporter', 'Ion Transport', 'Kinetics', 'Length', 'Letters', 'Machine Learning', 'Maintenance', 'Mechanics', 'Medical', 'Medicine', 'Membrane', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Motion', 'Mutation', 'Nerve Degeneration', 'Oligopeptides', 'Outcome', 'Pharmaceutical Preparations', 'Process', 'Progress Reports', 'Protein Conformation', 'Proteins', 'Proton Pump', 'Protons', 'Publishing', 'Quantum Mechanics', 'Reaction', 'Research', 'Research Personnel', 'Research Support', 'Retinal Degeneration', 'Role', 'Sampling', 'Sampling Biases', 'Specificity', 'Structure', 'System', 'Therapeutic', 'Time', 'Transport Process', 'Travel', 'United States National Institutes of Health', 'Virus Diseases', 'Water', 'Wisconsin', 'anti-influenza drug', 'antiporter', 'chemical bond', 'chemical reaction', 'experimental study', 'in silico', 'innovation', 'inorganic phosphate', 'insight', 'kinetic model', 'migration', 'molecular dynamics', 'molecular mechanics', 'multi drug transporter', 'novel', 'pH gradient', 'protonation', 'quantum', 'simulation', 'symporter', 'theories']",NIGMS,UNIVERSITY OF CHICAGO,R01,2020,310328,-0.021394193005354483
"Combining chemical and computational tools for predictive models of microbiome communities ABSTRACT The gut microbiome has a tremendous impact on health and disease, actively contributing to obesity, diabetes, inflammatory bowel disease, cardiovascular diseases, and several poorly understood neurological disorders. We do not yet have the necessary tools to precisely probe these microbial communities, though such tools could unlock extensive benefits to human health. Elucidating the contributions of individual species or consortia of bacteria would provide a rational basis for understanding microbiota-controlled disease and lead to novel therapies. To carry out the fundamental research planned in this proposal, we will tackle three major problems: First, we will build the first set of molecular tools that effectively and precisely modulate the microbiome bacteria; second, we will analyze the multiscale dynamics of microbial communities; and third, we will construct an ingestible biosensor for real-time monitoring of microbiome populations. Although antibiotics and fecal transplants can reconfigure microbial consortia, they do not precisely target individual bacteria. Conversely, antimicrobial peptides (AMPs) have evolved to selectively attack pathogenic bacteria but do not target microbiome bacteria, constituting desirable scaffolds for molecular engineering and potential sources of microbiome-targeting agents. We will develop a new computational peptide design methodology, based on classical and hybrid-quantum mechanical molecular dynamics (MD) simulations, to create a groundbreaking assessment of the dynamical and emergent properties of AMPs. Chemical synthesis and large-scale screening will confirm predicted selectivity against microbiome species, and a machine learning workflow will connect sequences of individual peptides to their dynamics and activity. We will then apply the synthetic AMPs to interrogate the human microbiome by selectively removing species during bacterial consortia experiments, to be carried out in bioreactors, under regular or anaerobic conditions. We will pair our experiments with whole-cell metabolic network models, providing a systems biology perspective to the analysis of inter-species interactions. An integrated ingestible biosensing device will be developed to monitor the microbiome by electrochemically sensing unique biomarkers from gut microbes. This will provide the first real-time measurements of microbiome composition and will be integrated to our bioreactors for testing, to ultimately be used for in vivo tests. This work will build the first set of molecular and computational tools for microbiome engineering and will lay the foundation to address critical gaps in our understanding of the gut micro-environment, and of the contributions of gut bacteria to the etiology of disease. Grounded in our demonstrated expertise in synthetic biology, computer science, microbiology, and electrical engineering, this project will provide a computational- experimental framework for developing a peptide encyclopedia for the gut microbiome, in line with NIH's public health mission and goals. PROJECT NARRATIVE  The gut microbiome plays roles in nutrition, immunity, metabolism, and several poorly understood neurological disorders. Suitable tools, however, do not yet exist for engineering the microbial communities that constitute the human microbiome. The proposed research introduces the first molecular tools to precisely understand the functions of microbiome communities in our health and disease in order to then delineate therapeutic interventions for diseases mediated by the gut microbiota, thereby addressing NIH's public health mission.",Combining chemical and computational tools for predictive models of microbiome communities,10029354,R35GM138201,"['Address', 'Anaerobic Bacteria', 'Antibiotics', 'Bacteria', 'Biochemical Pathway', 'Biological Markers', 'Bioreactors', 'Biosensing Techniques', 'Biosensor', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Communities', 'Devices', 'Diabetes Mellitus', 'Disease', 'Electrical Engineering', 'Encyclopedias', 'Engineering', 'Etiology', 'Foundations', 'Goals', 'Health', 'Human', 'Human Microbiome', 'Hybrids', 'Immunity', 'Individual', 'Inflammatory Bowel Diseases', 'Lead', 'Machine Learning', 'Mechanics', 'Mediating', 'Metabolism', 'Methodology', 'Microbiology', 'Mission', 'Molecular', 'Molecular Computations', 'Monitor', 'Obesity', 'Peptides', 'Play', 'Population', 'Property', 'Public Health', 'Research', 'Role', 'Source', 'Systems Biology', 'Testing', 'Therapeutic Intervention', 'United States National Institutes of Health', 'Work', 'antimicrobial peptide', 'base', 'chemical synthesis', 'computer science', 'computerized tools', 'design', 'experimental study', 'fecal transplantation', 'fundamental research', 'gut bacteria', 'gut microbes', 'gut microbiome', 'gut microbiota', 'in vivo evaluation', 'microbial community', 'microbiome', 'microbiome composition', 'microbiota', 'molecular dynamics', 'nervous system disorder', 'network models', 'novel therapeutics', 'nutrition', 'pathogenic bacteria', 'predictive modeling', 'quantum', 'real time monitoring', 'scaffold', 'screening', 'synthetic biology', 'targeted agent', 'temporal measurement', 'tool']",NIGMS,UNIVERSITY OF PENNSYLVANIA,R35,2020,342713,0.01673817298594209
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9982190,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Label', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'kinetic model', 'lead optimization', 'learning network', 'multidisciplinary', 'neural network', 'novel', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2020,1239304,-0.023328805200991107
"Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design PROJECT SUMMARY/ABSTRACT The study of biomolecular interactions and design of new therapeutics requires accurate physical models of the atomistic interactions between small molecules and biological macromolecules. Over the least few decades, molecular mechanics force ﬁelds have demonstrated the potential that physical models hold for quantitative biophysical modeling and predictive molecular design. However, a signiﬁcant technology gap exists in our ability to build force ﬁelds that achieve high accuracy, can be systematically improved in a statistically robust manner, be extended to new areas of chemistry, can model post-translational and covalent modiﬁcations, are able to quantify systematic errors in predictions, and can be broadly applied across a high-performance software packages. In this project, we willl bridge this technology gap to enable new generations of accurate quantitative biomolec- ular modeling and (bio)molecular design for chemical biology and drug discovery. In Aim 1, we will produce a modern, open infrastructure to enable practitioners to rapidly and conveniently construct and employ accurate and statistically robust physical force ﬁelds via automated machine learning methods. In Aim 2, we will construct open, machine-readable experimental and quantum chemical datasets that will accelerate next-generation force ﬁeld development. In Aim 3, we will develop statistically robust Bayesian inference techniques to enable the auto- mated construction of type assignment schemes that avoid overﬁtting and selection of physical functional forms statistically justﬁed by the data. This approach will also provide an estimate of the systematic error in predicted properties arising from uncertainty in parameters or functional form choices—generally the dominant source of error—to be quantiﬁed with little added expense. In Aim 4, we will integrate and apply this infrastructure to produce open, transferable, self-consistent force ﬁelds that achieve high accuracy and broad coverage for modeling small molecule interactions with biomolecules (including unnatural amino or nucleic acids and covalent modiﬁcations by organic molecules), with the ultimate goal of covering all major biomolecules. This research is signiﬁcant in that the technology developed in this project has the potential to radically transform the study of biomolecular phenomena by providing highly accurate force ﬁelds with exceptionally broad chemical coverage via fully consistent parameterization of organic (bio)molecules. In addition, we will produce new tools to automate force ﬁeld creation and tailoring to speciﬁc problem domains, quantify the systematic error in predictions, and identify new data for improving force ﬁeld accuracy. This will greatly improve our ability to study diverse biophysical processes at the molecular level, and to rationally design new small-molecule, protein, and nucleic acid therapeutics. This supplement to the original RO1 is to purchase a small GPU cluster to enable rapid prototyping of many of the approaches that are proposed in this project outlined in the four aims. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life carry out their functions and to design new medications. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms. This equipment supplement will provide computational resources for testing of new techniques throughout the duration of the grant.",Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design,10157034,R01GM132386,"['Address', 'Area', 'Automobile Driving', 'Award', 'Bayesian Analysis', 'Binding', 'Biological', 'Biology', 'Biophysical Process', 'Biophysics', 'Charge', 'Chemicals', 'Chemistry', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'Data', 'Data Set', 'Databases', 'Development', 'Drug Design', 'Electrostatics', 'Ensure', 'Equipment', 'Error Sources', 'Generations', 'Goals', 'Grant', 'Heart', 'Individual', 'Infrastructure', 'Investigation', 'Learning', 'Life', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Nucleic Acids', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Property', 'Proteins', 'RNA', 'Readability', 'Reproducibility', 'Research', 'Roentgen Rays', 'Scheme', 'Science', 'Scientist', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Therapeutic', 'Thermodynamics', 'Training', 'Uncertainty', 'Validation', 'Work', 'base', 'biophysical model', 'chemical synthesis', 'cheminformatics', 'computing resources', 'data infrastructure', 'design', 'drug discovery', 'experience', 'experimental study', 'improved', 'interest', 'machine learning method', 'macromolecule', 'models and simulation', 'molecular mechanics', 'multidisciplinary', 'new technology', 'next generation', 'novel therapeutics', 'nucleic acid-based therapeutics', 'open data', 'open source', 'physical model', 'physical property', 'prototype', 'quantum', 'simulation', 'simulation software', 'small molecule', 'software infrastructure', 'sound', 'tool', 'unnatural amino acids']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,96003,-0.01002121227747021
"Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design PROJECT SUMMARY/ABSTRACT The study of biomolecular interactions and design of new therapeutics requires accurate physical models of the atomistic interactions between small molecules and biological macromolecules. Over the least few decades, molecular mechanics force ﬁelds have demonstrated the potential that physical models hold for quantitative biophysical modeling and predictive molecular design. However, a signiﬁcant technology gap exists in our ability to build force ﬁelds that achieve high accuracy, can be systematically improved in a statistically robust manner, be extended to new areas of chemistry, can model post-translational and covalent modiﬁcations, are able to quantify systematic errors in predictions, and can be broadly applied across a high-performance software packages. In this project, we aim to bridge this technology gap to enable new generations of accurate quantitative biomolec- ular modeling and (bio)molecular design for chemical biology and drug discovery. In Aim 1, we will produce a modern, open infrastructure to enable practitioners to rapidly and conveniently construct and employ accurate and statistically robust physical force ﬁelds via automated machine learning methods. In Aim 2, we will construct open, machine-readable experimental and quantum chemical datasets that will accelerate next-generation force ﬁeld development. In Aim 3, we will develop statistically robust Bayesian inference techniques to enable the auto- mated construction of type assignment schemes that avoid overﬁtting and selection of physical functional forms statistically justﬁed by the data. This approach will also provide an estimate of the systematic error in predicted properties arising from uncertainty in parameters or functional form choices—generally the dominant source of error—to be quantiﬁed with little added expense. In Aim 4, we will integrate and apply this infrastructure to produce open, transferable, self-consistent force ﬁelds that achieve high accuracy and broad coverage for modeling small molecule interactions with biomolecules (including unnatural amino or nucleic acids and covalent modiﬁcations by organic molecules), with the ultimate goal of covering all major biomolecules. This research is signiﬁcant in that the technology developed in this project has the potential to radically transform the study of biomolecular phenomena by providing highly accurate force ﬁelds with exceptionally broad chemical coverage via fully consistent parameterization of organic (bio)molecules. In addition, we will produce new tools to automate force ﬁeld creation and tailoring to speciﬁc problem domains, quantify the systematic error in predictions, and identify new data for improving force ﬁeld accuracy. This will greatly improve our ability to study diverse biophysical processes at the molecular level, and to rationally design new small-molecule, protein, and nucleic acid therapeutics. This approach will bring statistical rigor to the ﬁeld of force ﬁeld construction and application by providing a means to make data-driven decisions, while enhancing reproducibility by enabling it to become a rigorous and reproducible science using a fully open infrastructure and datasets. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life do their jobs. They also use simulations to help design new medications – compounds that can bind and inﬂuence the behavior of these molecules of life, and thereby block diseases at the molecular level. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms.",Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design,9887804,R01GM132386,"['Address', 'Area', 'Automobile Driving', 'Bayesian Analysis', 'Binding', 'Biological', 'Biology', 'Biophysical Process', 'Biophysics', 'Charge', 'Chemicals', 'Chemistry', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Design', 'Electrostatics', 'Ensure', 'Error Sources', 'Generations', 'Goals', 'Heart', 'Individual', 'Infrastructure', 'Investigation', 'Learning', 'Life', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Nucleic Acids', 'Occupations', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Property', 'Proteins', 'RNA', 'Readability', 'Reproducibility', 'Research', 'Roentgen Rays', 'Scheme', 'Science', 'Scientist', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Technology', 'Temperature', 'Therapeutic', 'Thermodynamics', 'Training', 'Uncertainty', 'Validation', 'Work', 'base', 'behavior influence', 'biophysical model', 'chemical synthesis', 'cheminformatics', 'data infrastructure', 'design', 'drug discovery', 'experience', 'experimental study', 'improved', 'interest', 'machine learning method', 'macromolecule', 'models and simulation', 'molecular mechanics', 'multidisciplinary', 'new technology', 'next generation', 'novel therapeutics', 'nucleic acid-based therapeutics', 'open data', 'open source', 'physical model', 'physical property', 'quantum', 'simulation', 'simulation software', 'small molecule', 'software infrastructure', 'sound', 'tool', 'unnatural amino acids']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,675565,-0.008457298423724802
"Dietary and Microbial Reprogramming of Intestinal Microbiota-Produced Metabolites PROJECT SUMMARY The human colon houses a complex community of microbes, known as the gut microbiota, which possesses unmapped metabolic capabilities. Bacterial metabolic pathways process components of diet, like amino acids, and produce an array of ill-defined metabolites. Many of the metabolites produced by this microbial ecosystem are absorbed by the human host, modified by host enzymes, and ultimately excreted by the kidneys. When the kidneys fail, these solutes accumulate and comprise a significant portion of the ""uremic"" solutes found at very high levels in the plasma of patients maintained on dialysis. These compounds can vary widely between individual patients, yet are relatively stable over time within an individual, potentially reflecting inter-individual differences in gut microbiota composition. A few of these molecules have been investigated and linked to poor health outcomes in renal patients. For most of these compounds, however, neither the biochemical pathways responsible for their formation nor their biological effects on the host have been elucidated. This application is focused on the prevalent high concentration uremic solutes derived from tyrosine, 4- ethylphenylsulfate (4-EPS) and p-cresolsulfate (PCS), as well as 4-hydroxyphenylpropionic acid sulfate, a tyrosine metabolite not associated with uremia but important in understanding the tyrosine-utilization niche within the gut ecosystem. The goals of the research are to (i) determine the genes and species within the gut microbiota responsible for production of the microbial metabolites 4-ethylphenol and p-cresol that serve as precursors to 4-EPS and PCS; (ii) elucidate the effects of these molecules on aspects of host biology relevant to uremic illness; and (iii) investigate two distinct strategies for microbiota reprogramming with a goal of lowering uremic solute levels in a host. Aim 1 employs two approaches to predict microbial metabolic pathways, one using a computational/machine learning approach and a second method using comparative genomics combined with bacterial metabolomic phenotyping. Gene predictions will be genetically validated using gene deletion or heterologous expression. In Aim 2, gnotobiotic mice are used as a platform to investigate the conversion of microbial metabolites into circulating solutes, and how solute levels are affected by diet and other members of the microbiota. Isotopically labeled amino acids are used to trace dietary substrates to uremic solute products. Aim 3 leverages gnotobiotic mice colonized by WT versus mutant bacteria, which differ in the presence or absence of 4-EPS or PCS, to examine the effect of the metabolite on host biology. Changes in arterial thrombosis and cognitive function relevant to uremic illness will be assessed. The focus of Aim 4 is to reprogram the microbiota to reduce production of harmful uremic solutes. Single strain targeted reprogramming or complex consortium-based microbiota reconstitution using a diverse array of culturable bacteria will be tested as complementary strategies for lowering uremic solute levels in mice. Dietary modifications or antibiotic-based ablation of the microbiota will be used to augment the reprogramming therapies, respectively. PROJECT NARRATIVE A vast and diverse community of microbes known as the gut microbiota colonizes the human intestine. The microbiota is largely a beneficial community, but also produces some potentially toxic compounds that can accumulate to high levels in the circulation of dialysis patients. This proposal aims to define the bacterial species and genes that make these compounds and how the gut microbiota can be rationally altered to reduce the production of toxic substances.",Dietary and Microbial Reprogramming of Intestinal Microbiota-Produced Metabolites,9973004,R01DK101674,"['Ablation', 'Acids', 'Affect', 'Amino Acids', 'Anabolism', 'Anaerobic Bacteria', 'Animal Model', 'Antibiotics', 'Area', 'Bacteria', 'Behavioral', 'Biochemical Pathway', 'Biological', 'Biology', 'Blood Circulation', 'Colon', 'Communities', 'Complex', 'Cresol', 'Data', 'Data Set', 'Dialysis patients', 'Dialysis procedure', 'Diet', 'Diet Modification', 'Ecosystem', 'Enzymes', 'Foundations', 'Gene Deletion', 'Genes', 'Genetic', 'Gnotobiotic', 'Goals', 'Grant', 'Health', 'Human', 'Individual', 'Individual Differences', 'Individuality', 'Infrastructure', 'Intervention', 'Intestines', 'Investigation', 'Isotope Labeling', 'Kidney', 'Kidney Diseases', 'Knowledge', 'Libraries', 'Link', 'Machine Learning', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methods', 'Microbe', 'Molecular', 'Molecular Genetics', 'Mus', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Plasma', 'Poison', 'Process', 'Production', 'Renal function', 'Research', 'Research Design', 'Role', 'Series', 'Source', 'Sulfate', 'Taxonomy', 'Testing', 'Thrombosis', 'Time', 'Translations', 'Tyrosine', 'Uremia', 'Urine', 'Work', 'analysis pipeline', 'base', 'cognitive function', 'colon microbiota', 'comparative genomics', 'computerized tools', 'design', 'experimental study', 'frontier', 'gut microbiome', 'gut microbiota', 'human data', 'human subject', 'improved outcome', 'individual patient', 'member', 'metabolic phenotype', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiota', 'microbiota metabolites', 'mutant', 'novel', 'novel strategies', 'reconstitution', 'solute', 'tool', 'translation to humans']",NIDDK,STANFORD UNIVERSITY,R01,2020,690557,-0.0017078009001906301
"Systems biology frameworks to unravel mechanisms driving complex disorders Project Summary/Abstract This application proposes a training program to integrate the PI, Dr. Varadan's previous research efforts in informatics and machine learning into investigations pertaining to the etiology and progression of Barrett's Esophagus, a gastrointestinal disorder of significant public health interest. Much of Dr. Varadan's previous research has involved developing intelligent algorithms and informatics approaches to decode the interconnections within complex biological systems, with only a basic understanding of the clinical needs and complexities involved in translational research. The proposed project would provide a broad and in-depth mentored experience focused on clinical and biological aspects of Barrett's Esophagus, as well as added knowledge in the use of preclinical model systems to investigate biological mechanisms. The overall goal is to expand the PI's experience and training in the design and conduct of translational studies focused on gastrointestinal (GI) diseases. This objective will be achieved through a combination of didactic and research activities conducted under an exceptional mentoring team of translational researchers at Case Western Reserve University, spanning achievements across clinical management of GI disorders, molecular genetics and inflammatory processes associated with diseases of the gut. Accordingly, this proposal leverages Dr. Varadan's computational background to address an urgent and unmet need within the biomedical research community to develop reliable analytic approaches that can quantify signaling network activities in individual biological samples by integrating multi-omics measurements. We recently conceived a systems biology computational framework, InFlo, which integrates molecular profiling data to decode the functional states of cellular/molecular processes underpinning complex human diseases. Barrett's esophagus is one such complex disease gaining increasing importance to public health, as it is the known precursor to the deadly cancer, esophageal adenocarcinoma. Given that the mechanisms underlying the etiology and pathogenesis of Barrett's Esophagus remain elusive, a major objective of this proposal is to employ the InFlo framework combined molecular profiles derived from primary tissue cohorts, in vitro and in vivo model systems to establish the molecular roadmap of BE pathogenesis and disease recurrence, thus elucidating unifying mechanisms underlying this disease. This systems biology approach would enable the development of evidence-based, diagnostic/prognostic biomarkers for Barrett's esophagus and inform preventive strategies within at-risk populations. Project Narrative This proposal details a novel systems biology approach to enable seamless integration of patient molecular data to decipher the mechanisms underlying complex human diseases. Using this novel integrative analytics approach, we propose to resolve the molecular basis for the development and recurrence of Barrett's Esophagus, a disease with significant public health importance, since it is a known precursor to a lethal esophageal cancer and the mechanisms underpinning this disease remain largely unknown. The findings from our proposed research will enable the development of new diagnostic and prognostic biomarkers and will also inform preventive strategies in high-risk patient populations.",Systems biology frameworks to unravel mechanisms driving complex disorders,9888378,K25DK115904,"['3-Dimensional', 'Ablation', 'Achievement', 'Address', 'Automobile Driving', 'Award', 'Barrett Esophagus', 'Biological', 'Biological Models', 'Biomedical Research', 'Candidate Disease Gene', 'Cell Culture Techniques', 'Clinical', 'Clinical Management', 'Columnar Epithelium', 'Communities', 'Competence', 'Complex', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Electrical Engineering', 'Ephrins', 'Epithelial', 'Epithelium', 'Esophageal Adenocarcinoma', 'Esophageal Tissue', 'Esophagitis', 'Esophagus', 'Etiology', 'Event', 'Exhibits', 'Follow-Up Studies', 'Gastrointestinal Diseases', 'Gene Expression', 'Gland', 'Goals', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Informatics', 'Injury', 'Interleukin-1 beta', 'Investigation', 'Knowledge', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Maps', 'Measurement', 'Mentors', 'Modeling', 'Molecular', 'Molecular Abnormality', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mucous Membrane', 'Pathogenesis', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Populations at Risk', 'Pre-Clinical Model', 'Prevention strategy', 'Process', 'Prognostic Marker', 'Proliferating', 'Proteins', 'Public Health', 'Recurrence', 'Research', 'Research Activity', 'Risk', 'Risk Factors', 'Sampling', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Specificity', 'Squamous Epithelium', 'Stomach', 'System', 'Systems Analysis', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Training Programs', 'Transgenic Mice', 'Translational Research', 'Universities', 'Validation', 'base', 'candidate identification', 'candidate marker', 'career', 'cohort', 'complex biological systems', 'computer framework', 'design', 'diagnostic biomarker', 'evidence base', 'experience', 'genetic manipulation', 'genome-wide', 'high risk', 'human disease', 'in vivo Model', 'injury and repair', 'intelligent algorithm', 'interest', 'mouse model', 'multiple omics', 'network models', 'novel', 'novel diagnostics', 'patient population', 'prevent', 'resistance mechanism', 'standard of care', 'stem cells', 'success', 'therapeutic target', 'transcriptome', 'transcriptomics', 'translational scientist', 'translational study']",NIDDK,CASE WESTERN RESERVE UNIVERSITY,K25,2020,171720,0.0009292704546150253
"Successful Clinical Response In Pneumonia Therapy (SCRIPT) Systems Biology Center Modified Project Summary/Abstract Section  This innovative integrated systems biology application seeks to delineate the complex host/pathogen interactions occurring at the alveolar level that lead to unsuccessful response to therapy in serious pneumonia, including serious viral pneumonia. To achieve this objective, we will leverage our unique access to alveolar fluid collected as part of routine clinical care in mechanically ventilated patients with suspected pneumonia in our medical intensive care unit. Bronchoalveolar lavage fluid will be obtained serially from well characterized mechanically ventilated patients with serious viral or Pseudomonas or Acinetobacter bacterial pneumonias. Both of these CDC-designated serious hazard level bacterial pathogens have clinical failure rates as high as 50%. A robust clinical definition will allow comparison of both host and pathogen signatures associated with failure of therapy vs. success. These clinical specimens and extensive patient phenomics will anchor two mutually supportive and iterative research projects. Project One will deploy robust tools for flow sorting macrophage and lymphocyte subset populations, isolating RNA from these populations, and performing transcriptomic and epigenomic analysis to compare successful and unsuccessful host response. Project Two will focus on both specific pathogen genomic profiles associated with unsuccessful outcome and the differential microbiome response. Specific pathogen genomic profiles identified will be tested for causality in a unique humanized alveolar macrophage mouse model by the Technology Core. Changes in microbiome communities will be comprehensively assessed by shotgun deep sequencing to detect bacteriophage, other virus, and fungal DNA, in addition to bacterial. A Technical Core will perform cell sorting of BAL macrophage and lymphocyte subsets, RNA sequencing, and whole genome methylation, as well as perform the mouse pneumonia model studies. A Data Management and Bioinformatics Core will develop tools to reduce the dimensionality of these large comprehensive datasets, including the clinical phenomics, and provide them to the Modeling Core. The Modeling Core will then use an ecosystem-based approach to this complex adaptive system combined with unique machine learning tools and neural networks to generate biomarkers of host, pathogen and/or microbiome patterns predictive of successful pneumonia outcome. Predictive biomarkers developed in the Modeling Core will then be validated in a prospective confirmatory cohort of patients in whom analogous data will be generated. Biomarkers will also be tested for causality the mouse model. The Administrative Core will perform the outward- facing role of education and outreach to the community and sponsor, as well as regularly exchanging datasets, analytic tools, and specimens with NIH-sponsored/approved repository sites. Modified Public Health Relevance Section.   The Successful Clinical Response In Pneumonia Treatment (SCRIPT) systems biology center seeks to delineate the complex host/pathogen interactions occurring at the alveolar level that lead to unsuccessful response to therapy in serious pneumonia, including severe viral pneumonia. We will leverage our unique access to alveolar fluid collected as part of routine clinical care in mechanically ventilated patients to generate clinical phenomic, transcriptomic, epigenomic and metagenomic data that describe the host response, pathogen characteristics and microbiome of the alveolar space during pneumonia. We will then integrate this comprehensive phenotypic data into an ecosystem-based model to generate predictive biomarkers of pneumonia outcome for subsequent validation in a second cohort and tested for causality in a humanized alveolar macrophage mouse model.",Successful Clinical Response In Pneumonia Therapy (SCRIPT) Systems Biology Center,9843971,U19AI135964,"['Acinetobacter', 'Address', 'Alveolar', 'Alveolar Macrophages', 'Alveolus', 'Animal Model', 'Antibiotic Therapy', 'Bacteriophages', 'Bioinformatics', 'Biological Markers', 'Bronchoalveolar Lavage', 'Bronchoalveolar Lavage Fluid', 'Cause of Death', 'Cell Separation', 'Cells', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Microbiology', 'Clinical Trials', 'Collection', 'Communities', 'Complex', 'DNA Viruses', 'DNA sequencing', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Education and Outreach', 'Equilibrium', 'Etiology', 'Failure', 'Fungal DNA', 'Generations', 'Genes', 'Genetic', 'Goals', 'Human', 'Immune response', 'Infection', 'Intensive Care Units', 'Lead', 'Link', 'Liquid substance', 'Lymphocyte Subset', 'Lymphoid Cell', 'Machine Learning', 'Mechanics', 'Medical', 'Metagenomics', 'Methylation', 'Modeling', 'Multiomic Data', 'Myeloid Cells', 'Nosocomial Infections', 'Nosocomial pneumonia', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Pneumonia', 'Population', 'Preparation', 'Prospective cohort', 'Protocols documentation', 'Pseudomonas', 'Pseudomonas aeruginosa', 'Pseudomonas aeruginosa infection', 'RNA', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Sampling', 'Science', 'Secondary to', 'Shotguns', 'Site', 'Sorting - Cell Movement', 'Specimen', 'Standardization', 'Stream', 'System', 'Systems Biology', 'Technology', 'Testing', 'Treatment Failure', 'United States National Institutes of Health', 'Validation', 'Virulence', 'analytical tool', 'base', 'clinical care', 'cohort', 'data management', 'data pipeline', 'deep sequencing', 'epigenomics', 'experience', 'genomic data', 'genomic profiles', 'hazard', 'humanized mouse', 'improved', 'innovation', 'macrophage', 'microbiome', 'microbiome composition', 'mouse model', 'multiple omics', 'neural network', 'new therapeutic target', 'novel', 'pathogen', 'pathogen genomics', 'phenomics', 'phenotypic data', 'pneumonia model', 'predictive marker', 'predictive tools', 'prospective', 'repository', 'response', 'success', 'tool', 'transcriptome sequencing', 'transcriptomics', 'viral DNA', 'whole genome']",NIAID,NORTHWESTERN UNIVERSITY AT CHICAGO,U19,2020,2400000,-0.004409514129709333
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,9965942,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'in silico', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'personalized diagnostics', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2020,989602,-0.003855832141052464
"West Coast Metabolomics Center for Compound Identification Project Summary – Overall West Coast Metabolomics Center for Compound Identification (WCMC) The West Coast Metabolomics Center for Compound Identification (WCMC) is committed to the overall goals of the NIH Common Fund Metabolomics Initiative and specifically aims to largely improve small molecule identifications. Understanding metabolism is important to gain insight into biochemical processes and relevant to battle diseases such as cancer, obesity and diabetes. Compound identification in metabolomics is still a daunting task with many unknown compounds and false positive identifications. The major goal of the WCMC is therefore to develop processes and resources that accelerate and improve the accuracy of the compound identification workflow for experts and medical professionals. The WCMC for Compound Identification is structured in three different entities: the Administrative Core, the Computational Core and the Experimental Core. The Center is led by the Director Prof. Fiehn in close collaboration with quantum chemistry experts Prof. Wang and Prof. Tantillo, and metabolomics experts Dr. Barupal and Dr. Kind with broad support from mass spectrometry, computational metabolomics and programming experts. The Administrative Core will assist the Computational and Experimental Core to develop and validate large in-silico mass spectral libraries, retention time prediction models and innovative methods for constraining and ranking lists of isomers in an integrated process of cheminformatics tools and databases. The developed tools and databases will be made available to all Common Fund Metabolomics Consortium (CF-MC) members and professional working groups. The WCMC will also provide guidance for compound identification to the National Metabolomics Data Repository. The broad dissemination of developed compound identification protocols, training for compound identification workflows, databases and distribution of internal reference standard kits for metabolomic standardization will overall widely support the metabolomics community. Project Narrative – Overall West Coast Metabolomics Center for Compound Identification (WCMC) Understanding metabolism is relevant to find both markers and mechanisms of diseases and health phenotypes, including obesity, diabetes, and cancer. The West Coast Metabolomics Center for Compound Identification at UC Davis will use advanced experimental and computational mass spectrometry methods to significantly improve compound identification rates in metabolomics. Such identification will lead to breakthroughs in more precise diagnostics as well as finding the causes of diseases.",West Coast Metabolomics Center for Compound Identification,10258317,U2CES030158,"['Achievement', 'Amines', 'Benchmarking', 'Biochemical Process', 'Biodiversity', 'Biological Assay', 'Blinded', 'Chemicals', 'Chemistry', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Data Reporting', 'Databases', 'Deuterium', 'Diabetes Mellitus', 'Disease', 'Ensure', 'Enzymes', 'Finding by Cause', 'Funding', 'Goals', 'Guidelines', 'Health', 'Hybrids', 'Hydrogen', 'Isomerism', 'Leadership', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mass Chromatography', 'Mass Fragmentography', 'Mass Spectrum Analysis', 'Medical', 'Metabolism', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Monitor', 'North America', 'Obesity', 'Phenotype', 'Policies', 'Process', 'Protocols documentation', 'Reaction', 'Reference Standards', 'Research Design', 'Resolution', 'Resources', 'Software Tools', 'Solvents', 'Standardization', 'Structure', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Vendor', 'Vertebral column', 'base', 'chemical standard', 'cheminformatics', 'computing resources', 'data acquisition', 'data warehouse', 'database design', 'deep learning', 'heuristics', 'improved', 'in silico', 'innovation', 'insight', 'member', 'metabolomics', 'model building', 'molecular dynamics', 'novel', 'organizational structure', 'personalized diagnostics', 'predictive modeling', 'quantum chemistry', 'repository', 'small molecule', 'tool', 'training opportunity', 'working group']",NIEHS,UNIVERSITY OF CALIFORNIA AT DAVIS,U2C,2020,157500,-0.003855832141052464
"Dynamic regulatory network models of human response to influenza virus PROJECT SUMMARY The goal of this project is to build mathematical models of human innate immune responses to the global pathogen influenza virus A (IAV). To ensure successful replication, viral pathogens must simultaneously hijack several components of the host cell machinery while either evading or disabling innate cellular defenses. The host genetic background and subsequent viral and host signaling interactions dictate disease severity ranging from asymptomatic to mortality. Recent studies of IAV in genetically diverse murine models confirm the critical role of genotype in host response and outcome. Both molecular targets as well as key proteins involved in IAV pathogenesis could be therapeutically exploited to attenuate or prevent disease. Thus, we construct models of the molecular networks driving early innate IAV response that can be used to model genetic effects. Our experimental system is human lung epithelium, the first-line of defense against and target of IAV.  Aim 1. Genetic predictions from the gene regulatory network (GRN) governing human epithelial IAV response. GRNs describe the control of gene expression by transcription factors (TFs). We showed that integrating ATAC-seq with RNA-seq improves GRN accuracy. To construct a dynamic GRN in our heterogeneous lung tissue model, we propose scRNA-seq and scATAC-seq measurements of IAV infection and IFNβ stimulation time courses. Our group recently discovered new mechanisms by which the IAV protein Ns1 drives promoter-independent transcriptional “read-through” and alters 3D-chromatin architecture. Thus, for modeling, we also measure genomic transcription initiation and promoter-capture Hi-C. Following experimental testing and GRN refinement, we will use a deep-learning model trained on DNA sequence and epigenetic data to provide inputs that enable dynamic GRN simulations for thousands of human genotypes. We will identify genetic risk loci and molecular mechanisms driving difference in gene expression responses across individuals.  Aim 2. Model the protein-protein interactions (PPIs) and cellular signaling networks driving the innate immune response to IAV. We developed mutant influenza viruses, each encoding a FLAG-tagged viral protein, while maintaining virulence in vivo. We will use the mutant IAV to map host-virus PPIs in human lung epithelial cells and mouse lung in vivo. Integrating with diverse ‘omics datasets, we will construct a molecular network model connecting virus-host PPIs through cellular signaling pathways to IAV-dependent TFs. We will test pathway reconstruction with epistasis mapping.  Completion of both aims will lead to a GRN spanning virus-host PPIs and cellular signaling to TF control of gene expression in an innate-immune cell type. Our experimental-computational design is widely applicable. This model, and its future adaptation to other cells, will help identify the genetic and molecular mechanisms driving diverse human IAV responses and the network vulnerabilities to be exploited for IAV therapy. PROJECT NARRATIVE Human response to Influenza virus infection varies dramatically between individuals, from mildly symptomatic to death. We will systematically measure and model the innate immune response to IAV at the molecular network level: from host-virus protein-protein interactions through cellular signal transduction to changes in gene expression in human cells. The resulting mathematical model will help identify network vulnerabilities to be exploited for IAV therapy and help predict differences in IAV response in the human population.",Dynamic regulatory network models of human response to influenza virus,9950738,U01AI150748,"['3-Dimensional', 'ATAC-seq', 'Affinity Chromatography', 'Alleles', 'Architecture', 'Attenuated', 'Automobile Driving', 'Binding', 'Biological Models', 'Cells', 'Cessation of life', 'Chromatin', 'DNA Sequence', 'Data', 'Data Set', 'Differential Equation', 'Disease', 'Engineering', 'Ensure', 'Epigenetic Process', 'Epithelial', 'Epithelial Cells', 'Epithelium', 'Experimental Designs', 'Experimental Models', 'Flow Cytometry', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Models', 'Genetic Polymorphism', 'Genetic Risk', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Heterogeneity', 'Host Defense', 'Human', 'Immune', 'Immune response', 'Individual', 'Infection', 'Influenza A virus', 'Innate Immune Response', 'Interferon Type I', 'Interferon-beta', 'Joints', 'Knowledge', 'Learning', 'Lung', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Molecular', 'Molecular Target', 'Mouse Strains', 'Mus', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Pattern recognition receptor', 'Population', 'Prize', 'Proteins', 'Regulator Genes', 'Reporter', 'Role', 'Severity of illness', 'Signal Pathway', 'Signal Transduction', 'Signaling Molecule', 'Small Interfering RNA', 'Structure of parenchyma of lung', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissue Model', 'Tracheal Epithelium', 'Training', 'Transcription Elongation', 'Transcription Initiation', 'Untranslated RNA', 'Validation', 'Viral', 'Viral Proteins', 'Virulence', 'Virus', 'Virus Diseases', 'adaptive immune response', 'antimicrobial', 'base', 'cell behavior', 'cell type', 'cytokine', 'deep learning', 'design', 'experimental study', 'flu', 'forest', 'global health', 'high dimensionality', 'human disease', 'human model', 'human pathogen', 'improved', 'in vivo', 'influenzavirus', 'mathematical model', 'molecular modeling', 'mortality', 'mouse model', 'mutant', 'network models', 'pathogen', 'pathogenic virus', 'predictive modeling', 'prevent', 'promoter', 'protein protein interaction', 'reconstruction', 'response', 'risk variant', 'simulation', 'single-cell RNA sequencing', 'tool', 'transcription factor', 'transcription factor USF', 'transcription termination', 'transcriptome sequencing', 'virus genetics']",NIAID,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U01,2020,1202266,-0.03173563089863541
"A Proteogenomic Search Engine for Direct Mass Spectrometric Identification of Variant Proteins Using Genomic Data Project Summary / Abstract Mass spectrometry-based proteomics, used in conjunction with genomics, has been called proteogenomics. Recent exponential increases in variant identification by next-generation sequencing (NGS) is redefining the concept of the human genome/proteome. Our project is the commercialization of a first-to-market proteomic database search engine for mass spectrometry capable of directly reading NGS data for the identification of mutilations from individual samples or from curated resources. Such an offering has the potential to bring together these two fields, enabling validation of mutations at the protein-level. Mutated proteins have been shown to make ideal targets for drug therapies and diagnostics in cancer. Our software will provide an intuitive user experience, approachable by scientists who may not be expert both proteomic and genomic data analysis. Since the search engine is guided by prior knowledge, performance exceeds current practice. The software will come complete with a full array of post-processing validation, and visualization tools. Project Narrative The detection of protein variants, which differ from those predicted from the reference human genome sequence, can make ideal candidates for the development of targeted treatments and diagnostics for many clinical conditions such as cancer. This project proposes the development a first-of-its-kind “proteogenomics” search engine for the identification of protein variants by mass spectrometry, making direct use of genomic data and ever-growing public and private databases of genetic variation.",A Proteogenomic Search Engine for Direct Mass Spectrometric Identification of Variant Proteins Using Genomic Data,10082114,R44CA217432,"['Agreement', 'Cancer Vaccines', 'Clinical', 'Communities', 'Complement', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Databases', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Environment', 'Future', 'Gefitinib', 'Genetic Databases', 'Genetic Diseases', 'Genetic Variation', 'Genomics', 'Goals', 'Guidelines', 'Heterozygote', 'Human Genome', 'Individual', 'Informatics', 'Intuition', 'Ions', 'Isomerism', 'Knowledge', 'Licensing', 'Malignant Neoplasms', 'Marketing', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Modification', 'Monitor', 'Mutate', 'Mutation', 'Mutation Detection', 'Pathway interactions', 'Peptides', 'Performance', 'Phase', 'Post Translational Modification Analysis', 'Privatization', 'Probability', 'Protein Databases', 'Proteins', 'Proteome', 'Proteomics', 'Publications', 'Readability', 'Reading', 'Research', 'Resolution', 'Resources', 'Risk', 'Running', 'Sales', 'Sampling', 'Scientist', 'Services', 'Small Business Innovation Research Grant', 'Testing', 'Transcript', 'Validation', 'Variant', 'Visualization', 'Visualization software', 'Work', 'base', 'commercialization', 'cost', 'experience', 'genomic data', 'graphical user interface', 'human reference genome', 'improved', 'next generation sequencing', 'open source', 'protein expression', 'proteogenomics', 'prototype', 'repository', 'scaffold', 'search engine', 'support vector machine', 'targeted treatment', 'tool', 'transcriptome sequencing']",NCI,"SPECTRAGEN INFORMATICS, LLC",R44,2020,529294,-0.06004792073952256
"Rapid and Precise Molecular Pathway Modelling of the SARS-CoV-1 and SARS-CoV-2 Infection Cycle with Human Host Protein and Therapeutic Interactions Project Summary The Reactome Knowledgebase is a widely used and internationally recognized expert-curated, open-source resource of a broad array of human biological processes and their disease counterparts, coupled to powerful tools for data analysis and display, and integrated with diverse community genomics resources. The work proposed here will add molecular annotations of the COVID-19 infection process mediated by the SARS-CoV-2 coronavirus, interactions between viral components and human host proteins that mediate the severity of viral infection, and the effects of therapeutics and drug-like compounds on both viral and host proteins. The resulting SARS-CoV-2 pathway annotations will provide a framework for pathway- and network-based data analysis and visualization, which will be critical for the interpretation of numerous COVID-19 studies now and in the future. In collaboration with a team of community experts in virology, drug design, and infectious disease, we will assemble information in two stages. First, a draft annotation will associate relevant SARS-CoV-1 and SARS-CoV- 2 viral and host cell proteins with each stage of the infection process and the host response to it. These annotations will be immediately useful for identifying additional relevant interacting proteins, for assessing possible effects of variation in the host or viral proteins on specific steps of viral infection, and for identifying possible drug targets. In the second stage, the SARS-CoV-2 map will be annotated more extensively to fill in molecular details of each step in these processes and to highlight differences in the processes mediated by SARS- CoV-2 virus and related coronaviruses. This annotation process will continue for the duration of the project to incorporate newly validated molecular details as they are uncovered by the research community. All the data, code and tools developed by this project will be open source and open. Project Narrative Using long-established Reactome Knowledgebase standards for authorship, curation and peer-review of molecular pathway data from published and unpublished sources, we will annotate the molecular details of the processes by which SARS-CoV-2 and SARS-CoV-1 coronaviruses infect human cells. This will include the interactions among viral and host proteins, the expression of viral proteins likely to trigger innate and adaptive immunity, and an annotation of the molecular effects of drugs on these processes. Our strategy will allow rapid revision and extension of annotations as data accumulate, will support close integration with other community resources, and will generate a valuable resource for community analysis of experimental data sets relevant to COVID-19 disease.",Rapid and Precise Molecular Pathway Modelling of the SARS-CoV-1 and SARS-CoV-2 Infection Cycle with Human Host Protein and Therapeutic Interactions,10165320,U41HG003751,"['2019-nCoV', 'Authorship', 'Biological Process', 'COVID-19', 'Cells', 'Code', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer software', 'Consensus', 'Coronavirus', 'Coupled', 'Data', 'Data Analyses', 'Data Display', 'Data Set', 'Disease', 'Disease Pathway', 'Drug Design', 'Drug Targeting', 'Ensure', 'Future', 'Genomics', 'Human', 'Immune response', 'Infection', 'Innate Immune Response', 'Institutes', 'International', 'Link', 'Literature', 'Manuals', 'Maps', 'Mediating', 'Mining', 'Modeling', 'Molecular', 'Natural Immunity', 'Natural Language Processing', 'Network-based', 'Paper', 'Pathogenicity', 'Pathway interactions', 'Peer Review', 'Pharmaceutical Preparations', 'Process', 'Proteins', 'Proteome', 'Publishing', 'Reaction', 'Research', 'Resources', 'SARS coronavirus', 'Severities', 'Source', 'System', 'Systems Biology', 'Therapeutic', 'Therapeutic Effect', 'Therapeutic Monoclonal Antibodies', 'Variant', 'Viral', 'Viral Proteins', 'Virus', 'Virus Diseases', 'Work', 'adaptive immunity', 'data integration', 'data structure', 'data tools', 'data visualization', 'experimental analysis', 'knowledge base', 'open source', 'protein expression', 'small molecule', 'structured data', 'tool', 'virology']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2020,310292,-0.01484616981602171
"Tools for rapid and accurate structure elucidation of natural products Mapping the Secondary Metabolomes of Marine Cyanobacteria Bacteria are extraordinarily prolific sources of structurally unique and biologically active natural products that derive from a diversity of fascinating biochemical pathways. However, the complete structure elucidation of natural products is often the most time consuming and costly endeavor in natural product drug discovery programs. Compounding this, advancements in genome sequencing have accelerated the identification of unique modular biosynthetic gene clusters in prokaryotes and revealed a wealth of new compounds yet to be isolated and biologically and chemically characterized. Resultantly, there is an urgent and continuing need in this field to connect biosynthetic gene clusters to their respective MS fragmentation signatures in the MS2 molecular networks. The capacity to make such connections will accelerate new compound discovery as well as create associations between gene cluster and biosynthetic pathway, and aid in fast and accurate structure elucidations. Combined with this informatics approach, this proposed continuation project explores innovative methods by which to solve complex molecular structures by enhanced MS and NMR experiments, as well as the development of new algorithms by which to accelerate their analysis. Thus, the overarching goal of this grant is to develop efficient methods that facilitate automated structural classification, structural feature discovery and ultimately efficient structure elucidation of natural products (or any small molecule) and to build an infrastructure that interacts with data input from the community. We will achieve this with the following four specific aims: Aim 1. Integration of MS2 molecular networking with gene cluster networking to rapidly and efficiently locate natural products that have unique molecular architectures; Aim 2. To develop a suite of high sensitivity pulse sequences for natural product structure elucidation; Aim 3. To develop NMR based molecular networking strategies using Deep Convolutional Neural Networks (DCNNs) to facilitate the categorization and structure elucidation of organic compounds; Aim 4. To integrate NMR molecular networking and MS2-based molecular networking as an efficient structure characterization and elucidation strategy. By achieving these aims we will develop an innovative workflow for finding new compounds and for determining their structures, both quickly and accurately. The connection between gene cluster and molecule will shed light on stereochemistry and potential halogenations and methylations. This information can then be used in combination with more efficient NMR and MS methods to accurately determine structures. These tools will be widely shared, such as through the Global Natural Products Social (GNPS) Molecular Network, to enhance the overall capacity of the natural products and organic chemistry communities to solve complex molecular structures.   Natural products are compounds produced by natural sources and about 50 % of FDA approved drugs can trace their origin back to natural products. This proposal aims to use our data set of natural products produced by cyanobacteria for development of analytical tools that will speed- up and stream-line the discovery and structure elucidation of new compounds.  ",Tools for rapid and accurate structure elucidation of natural products,9921415,R01GM107550,"['Algae', 'Algorithms', 'Architecture', 'Back', 'Bacteria', 'Biochemical Pathway', 'Biological', 'Chemicals', 'Classification', 'Communities', 'Complex', 'Consumption', 'Cyanobacterium', 'Data', 'Data Set', 'Development', 'FDA approved', 'Family', 'Gene Cluster', 'Genomics', 'Goals', 'Grant', 'Informatics', 'Infrastructure', 'Light', 'Mass Spectrum Analysis', 'Methods', 'Methylation', 'Molecular', 'Molecular Structure', 'Natural Product Drug', 'Natural Products', 'Organic Chemistry', 'Pathway interactions', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Progress Reports', 'Prokaryotic Cells', 'Source', 'Speed', 'Stream', 'Structure', 'Techniques', 'Time', 'analog', 'analytical tool', 'base', 'convolutional neural network', 'cost', 'deep learning', 'drug discovery', 'experimental study', 'fascinate', 'genome sequencing', 'halogenation', 'innovation', 'metabolome', 'novel', 'programs', 'prototype', 'scaffold', 'small molecule', 'social', 'stereochemistry', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,514429,-0.022975238041999104
"Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence Abstract Enzyme functionality is a critical component of all life systems. Whereas advances in experimental methodology have enabled a better understanding of factors that control enzyme function, critical components of the reaction space such as highly unstable intermediates and transition states are best accessed for evaluation through computational simulations. Similarly, computational methodology continues to provide a key resource for probing excited-state processes such as bioluminescence. Combined ab initio quantum mechanical molecular mechanical (ai-QM/MM) simulations are, in principle, the preferred choice in the modeling of both processes. But ai-QM/MM modeling of enzymatic reactions is now severely limited by its computational cost, where a direct ai-QM/MM free energy simulation of an enzymatic reaction can take 500,000 or more CPU hours. Meanwhile, ai-QM/MM modeling of firefly bioluminescence is also hindered by the computational accuracy, where it has yet to produce quantitatively correct predictions for the bioluminescence spectral shift with site-directed mutagenesis. The goal of this proposal is to accelerate ai-QM/MM simulations of enzymatic reaction free energy and to improve the quality of ai-QM/MM-simulated bioluminescence spectra, so that ai-QM/MM simulations can be routinely performed by experimental groups. This will be achieved via a) using a lower-level (semi-empirical QM/MM) Hamiltonian for sampling; b) an enhancement to the similarity between the two Hamiltonians by calibrating the low-level Hamiltonian using the reaction pathway force matching approach, in conjunction with several other methods. The expected outcomes of this collaborative effort include: a) advanced methodologies for accelerated reaction free energy simulations and accurate bioluminescence spectra predictions, which will be released through multiple software platforms; b) a fundamental understanding of reactions such as Kemp elimination and polymerase-eta catalyzed DNA replication; c) a deeper insight into the role of macromolecular environment in the modulation of enzyme catalytic activities or bioluminescence wavelengths, which can further enhance our capability of designing new enzymes and bioluminescence probes. Narrative This project aims to develop quantum-mechanics-based computational methods to more quickly model enzymatic reactions and more accurately model bioluminescence spectra. It will lead to reliable and efficient computational tools for use by the general scientific community. It will facilitate the probe of enzymatic reaction mechanisms and the computer-aided design of new bioluminescence probes.",Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence,10021018,R01GM135392,"['Adopted', 'Biochemical Reaction', 'Bioluminescence', 'Calibration', 'Communities', 'Computer Simulation', 'Computer software', 'Computer-Aided Design', 'Computing Methodologies', 'DNA biosynthesis', 'DNA-Directed DNA Polymerase', 'Electrostatics', 'Environment', 'Enzymes', 'Evaluation', 'Fireflies', 'Free Energy', 'Freedom', 'Generations', 'Goals', 'Hour', 'Ions', 'Life', 'Machine Learning', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Multienzyme Complexes', 'Outcome', 'Pathway interactions', 'Polymerase', 'Process', 'Protocols documentation', 'Quantum Mechanics', 'Reaction', 'Resources', 'Role', 'Sampling', 'Site-Directed Mutagenesis', 'System', 'Temperature', 'Thermodynamics', 'Time', 'base', 'computerized tools', 'cost', 'design', 'experimental group', 'improved', 'innovation', 'insight', 'multi-scale modeling', 'mutant', 'quantum', 'simulation', 'theories']",NIGMS,UNIVERSITY OF OKLAHOMA NORMAN,R01,2020,255238,0.004757267089744818
"Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics Abstract Support is requested for a Keystone Symposia conference entitled Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics, organized by Drs. Jose M. Lora and Timothy K. Lu. The conference will be held in Breckenridge, Colorado from March 29- April 1, 2019. Synthetic Biology tools and principles have matured tremendously over the last decade and have reached extraordinary levels of sophistication, both in eukaryotic and prokaryotic systems. Synthetic biology as a therapeutic modality is starting to enter multiple clinical studies and has the potential to have a significant impact on medicine across a wide range of diseases (e.g., metabolic, immune-mediated, cancer, and neurologic diseases). This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine. While there are conferences that capture synthetic biology in only a few talks mixed in among other various topics, there is a paucity of conferences focused on synthetic biology as drugs to treat disease. However, due to the rapid pace of fundamental scientific advances along with an expanding number of biotechnology companies and emerging clinical studies with synthetic biology at their core, this conference will be highly relevant for a wide audience of scientists both from academia and industry. In addition, other meetings in this field have a highly technology-driven focus on synthetic biology techniques with relatively little attention given to biological and medical context. Ultimately, this Keystone Symposia conference should inspire researchers from diverse backgrounds to discuss synthetic biology via many new angles. PROJECT NARRATIVE Over the past two decades, tremendous advances have been made in the use of biological parts to engineer systems that can effectively direct living cells for a vast variety of purposes (a.k.a. synthetic biology). Synthetic biology is being used to construct more effective therapies in diseases such as cancer, but there are remaining obstacles to the clinical translation of these therapies. This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine.",Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics,9913772,R13EB029305,"['Academia', 'Address', 'Area', 'Attention', 'Biological', 'Biomedical Research', 'Biotechnology', 'Cells', 'Clinical Research', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Colorado', 'Computers', 'Disease', 'Educational workshop', 'Engineering', 'Future', 'Genetic Engineering', 'Genetic Screening', 'Human', 'Immune', 'Industrialization', 'Industry', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Medicine', 'Metabolic', 'Methodology', 'Modality', 'Neurologic', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Preventive', 'Process', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Scientific Advances and Accomplishments', 'Scientist', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Work', 'clinical application', 'clinical practice', 'clinical translation', 'combinatorial', 'design', 'effective therapy', 'graduate student', 'meetings', 'nervous system disorder', 'next generation', 'novel diagnostics', 'posters', 'symposium', 'synthetic biology', 'targeted treatment', 'tool']",NIBIB,KEYSTONE SYMPOSIA,R13,2020,10000,-0.0009530122357995637
"Automated Molecular Identity Disambiguator (AutoMID) PROJECT SUMMARY Small molecules are one of the most important classes of therapeutics alleviating suffering and in many cases death for hundreds of millions of people worldwide. Small molecules also serve as invaluable tools to study biology, often with the goal to validate novel targets for the development of future therapeutic drugs. Reproducibility of experimental results and the interoperability and reusability of resulting datasets depend on accurate descriptions of associated research objects, and most critically on correct representations of small molecules that are tested in biological assays. For example, it is not possible to develop predictive models of protein target - small molecule interactions if their chemical structure representations are not correct. Many factors contribute to errors in reported chemical structures in small molecule screening and omics reference databases, scientific publications, and many other web-based resources and documents. Because of the complexity of representing small molecules chemical structure graphs and the lack of thorough curation, errors are frequently introduced by non-experts and error propagation across different digital research assets is a pervasive problem. To address this challenging problem via a scalable approach, we propose the Automated Molecular Identity Disambiguator (AutoMID). AutoMID will be usable in batch mode at scale via an API, for example to assist chemical structure standardization and registration by maintainers of digital research assets, and also via interactive (UI) mode for everyday researchers to quickly and easily validate or correct their small molecule representations. AutoMID will leverage extensive highly standardized linked databases of chemical structures and associated information including names, synonyms, biological activity and physical properties and their sources / provenance and leverage expert rules and AI to enable reliable disambiguation of chemical structure identities at scale. PROJECT NARRATIVE Small molecules are one of the most important types of drugs. They also serve as invaluable tools to study biology. The complexity of representing chemical graphs and the lack of thorough curation leads to frequent small molecule structure errors, which propagate across digital research assets, impeding their interoperability and reusability. To address this challenging problem, we propose the Automated Molecular Identity Disambiguator (AutoMID). Built on expert knowledge and AI, AutoMID will enable researchers and maintainers of data repositories to reliably identify and resolve ambiguities in chemical structures at scale.",Automated Molecular Identity Disambiguator (AutoMID),9987129,R01LM013391,"['Address', 'Adoption', 'Biological', 'Biological Assay', 'Biology', 'Categories', 'Cessation of life', 'Chemical Structure', 'Chemicals', 'Classification', 'Complex', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Deposition', 'Detection', 'Development', 'FAIR principles', 'Future', 'Goals', 'Graph', 'Hand', 'Hybrids', 'In Vitro', 'Individual', 'Knowledge', 'Legal patent', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Metadata', 'Modeling', 'Molecular', 'Molecular Structure', 'Names', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Privatization', 'Property', 'Proteins', 'Publications', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Semantics', 'Source', 'Standardization', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Training', 'base', 'cheminformatics', 'data harmonization', 'data modeling', 'data warehouse', 'design', 'digital', 'high throughput screening', 'improved', 'in silico', 'in vivo', 'interoperability', 'knowledge curation', 'novel', 'online resource', 'physical property', 'predictive modeling', 'relational database', 'screening', 'small molecule', 'software systems', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2020,293345,-0.01584485909042799
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,9935719,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Asses', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2020,599090,-0.004772634944405319
"Bridging Statistical Inference and Mechanistic Network Models for HIV/AIDS Network models are used to investigate the spread of HIV/AIDS, but rather than assuming that the members of a population of interest are fully mixed, the network approach enables individual-level specification of contact patterns by considering the structure of connections among the members of the population. By representing individuals as nodes and contacts between pairs of individuals as edges, this network depiction enables identification of individuals who drive the epidemic, allows for accurate assessment of study power in cluster- randomized trials, and makes it possible to evaluate the impact of interventions on the individuals themselves, their partners, and the broader network. There are currently two major mathematical paradigms to the modeling of networks: the statistical approach and the mechanistic approach. In the statistical approach, one specifies a model that states the likelihood of observing a given network, whereas in the mechanistic approach one specifies a set of domain-specific mechanistic rules at the level of individual nodes, the actors in the network, that are used to evolve the network over time. Given that mechanistic models directly model individual-level behaviors – modification of which is the foundation of most prevention measures – they are a natural fit for infectious diseases. Another attractive feature of mechanistic models is their scalability as they can be implemented for networks consisting of thousands or even millions of nodes, making it possible to simulate population-wide implementation of interventions. Lack of statistical methods for calibrating these models to empirical data has however impeded their use in real-world settings, a limitation that stems from the fact that there are typically no closed-form likelihood functions available for these models due the exponential increase in the number of ways, as a function of network size, of arriving at a given observed network. We propose to overcome this gap by advancing inferential and model selection methods for mechanistic network models, and by developing a framework for investigating their similarities with statistical network models. We base our approach on approximate Bayesian computation (ABC), a family of methods developed specifically for settings where likelihood functions are intractable or unavailable. Our specific aims are the following. Aim 1: To develop a statistically principled framework for estimating parameter values and their uncertainty for mechanistic network models. Aim 2: To develop a statistically principled method for model choice between two competing mechanistic network models and estimating the uncertainty surrounding this choice. Aim 3: To establish a framework for mapping mechanistic network models to statistical models. We also propose to implement these methods in open source software, using a combination of Python and C/C++, to facilitate their dissemination and adoption. We believe that the research proposed here can help harness mechanistic network models – and with that leverage some of the insights developed in the network science community over the past decade and more – to help eradicate this disease. PROJECT NARRATIVE Network models are used to gain a more precise understanding of human behavioral factors associated with the spread of HIV/AIDS in order to develop more effective interventions to halt the epidemic. There are two main mathematical paradigms for modeling networks, the statistical approach and the mechanistic approach, and given that the latter directly models individual-level behaviors – modification of which is the foundation of most prevention measures – mechanistic models are a natural fit for infectious diseases. Lack of statistical methods for calibrating these models to empirical data has so far impeded their use in real-world settings, and we therefore propose to develop parameter inference and model selection methods for mechanistic network models in order to endow the biomedical community with these powerful tools.",Bridging Statistical Inference and Mechanistic Network Models for HIV/AIDS,9970407,R01AI138901,"['AIDS prevention', 'AIDS/HIV problem', 'Adoption', 'Automobile Driving', 'Bayesian Analysis', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Biological', 'Cluster randomized trial', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Development', 'Dimensions', 'Disease', 'Epidemic', 'Ethics', 'Evaluation', 'Evolution', 'Family', 'Foundations', 'Goals', 'HIV', 'Health Sciences', 'Human', 'Individual', 'Infection', 'Intervention', 'Learning', 'Likelihood Functions', 'Logistics', 'Machine Learning', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Pattern', 'Physics', 'Population', 'Prevention Measures', 'Prevention strategy', 'Probability', 'Process', 'Property', 'Public Health', 'Pythons', 'Research', 'Research Personnel', 'SET Domain', 'Science', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Structure', 'Time', 'Uncertainty', 'base', 'effective intervention', 'high dimensionality', 'indexing', 'innovation', 'insight', 'interest', 'member', 'network models', 'open source', 'pandemic disease', 'pathogen', 'pre-exposure prophylaxis', 'simulation', 'statistics', 'stem', 'tool', 'treatment adherence', 'treatment strategy']",NIAID,HARVARD SCHOOL OF PUBLIC HEALTH,R01,2020,453846,-0.013768338903354802
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9840897,U24DK112331,"['ATAC-seq', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Cost efficiency', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Infrastructure', 'Institutes', 'Knowledge', 'Lead', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'analysis pipeline', 'base', 'bisulfite sequencing', 'data exchange', 'data resource', 'epigenomics', 'exercise intervention', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'individual response', 'insight', 'machine learning algorithm', 'medical schools', 'methylome', 'mortality risk', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2020,4401725,-0.015560819001912658
"Integrative chemical-biological profiling to determine primary drivers of wildfire smoke-induced toxicity PROJECT SUMMARY  Wildfire occurrence, duration, and intensity have heightened in recent decades and continue to impact the health of millions of individuals worldwide. Smoke that is emitted from wildfires consists of a complex mixture of particulate matter and toxic gases. The chemical composition of wildfire smoke is dependent upon the type of biomass burn conditions and fuel type, which are heavily influenced by geographical region. The chemical mixtures within wildfire smoke that humans are exposed to can consequently cause variable health outcomes through potentially different biological mechanisms. Human exposure to wildfire smoke represents a growing concern in public health, and adequately characterizing health risks associated with biomass smoke across varying burn conditions and geographic areas is not possible with the data currently available.  The variabilities in toxicological responses across wildfire smoke exposure conditions have yet to be fully established and evaluated in the context of chemical composition. The growing threat of wildfires necessitates the elucidation of individual and/or co-occurring components of wildfire smoke that act as the primary drivers of toxicity. To address this important research issue, we expand upon a foundational study that has previously characterized the chemical constituents in various biomass burn scenarios and evaluated, in part, toxicological responses to these exposures in the mouse lung. Here, we leverage this extensive database and banked samples to: 1. characterize in vivo transcriptomic responses and pathway alterations associated with biomass smoke in the mouse lung; 2. integrate chemical-toxicity profiles using computational approaches to prioritize chemicals that are likely driving toxicity responses; and 3. further evaluate chemical drivers of biomass smoke toxicity responses using in vitro approaches.  This research will be carried out through a collaboration with laboratories at the University of North Carolina at Chapel Hill and the U.S. Environmental Protection Agency, allowing for a unique combination of expertise for studying the primary drivers of wildfire smoke-induced toxicity. This expertise includes skills in computational toxicology, exposure science, and molecular biology, coupled with experience studying adverse health effects and immune responses induced by exposure to air pollutants. PROJECT NARRATIVE Exposure to wildfire smoke continues to be a growing threat to public health, yet the primary drivers of toxicity and disease are not completely understood. This proposal represents an innovative approach to increase understanding on the health effects of wildfires by leveraging a robust dataset of chemical-biological profiles from mice exposed to biomass smoke condensate samples derived from variable conditions. New data will also be generated alongside additional in vitro testing to more comprehensively examine mechanisms of toxicity and identify the primary drivers of wildfire smoke-induced toxicity, resulting in improved abilities to predict region- specific health risks attributable to wildfires.",Integrative chemical-biological profiling to determine primary drivers of wildfire smoke-induced toxicity,9956440,R21ES031740,"['Address', 'Affect', 'Air', 'Air Pollutants', 'Analytical Chemistry', 'Automobile Driving', 'Biological', 'Biological Assay', 'Biomass', 'Cardiovascular Diseases', 'Cells', 'Cessation of life', 'Chemically Induced Toxicity', 'Chemicals', 'Collaborations', 'Complex', 'Complex Mixtures', 'Coupled', 'Critical Pathways', 'DNA Damage', 'Data', 'Data Set', 'Databases', 'Disease', 'Exposure to', 'Female', 'Foundations', 'Functional disorder', 'Gases', 'Gene Expression', 'Genes', 'Geographic Locations', 'Health', 'Human', 'Immune', 'Immune response', 'In Vitro', 'Individual', 'Inflammation', 'Inhalation', 'Inhalation Exposure', 'Laboratories', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Mus', 'North Carolina', 'Outcome', 'Particulate Matter', 'Pathway interactions', 'Phenotype', 'Population', 'Positioning Attribute', 'Proteins', 'Public Health', 'Research', 'Risk', 'Sampling', 'Science', 'Smoke', 'Structure of parenchyma of lung', 'System', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'United States Environmental Protection Agency', 'Universities', 'Variant', 'Wildfire', 'asthma exacerbation', 'base', 'biomass fuel', 'biomass smoke', 'computational toxicology', 'data integration', 'data reduction', 'data warehouse', 'experience', 'exposed human population', 'genotoxicity', 'improved', 'in vitro testing', 'in vivo', 'innovation', 'lung injury', 'male', 'novel', 'protein biomarkers', 'public health relevance', 'respiratory', 'response', 'skills', 'smoke inhalation', 'toxicant', 'transcriptomics']",NIEHS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2020,227277,0.0002203072388346535
"Harnessing ""omics"": A Systems Biology approach to discovery of biologicalpathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biologicalpathways in placental development and parturition",10243626,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'machine learning algorithm', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,UNIVERSITY OF FLORIDA,R01,2020,357022,-0.014120463052680436
"Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition PROJECT SUMMARY  Our  goal  in  this  proposal  is  to  identify  biological  networks  involved  in  synchronizing  placental  growth  and  maturity. To accomplish this goal, we have established a collaborative effort between the Center for Prevention  of  Preterm  Birth  at  Cincinnati  Children’s  Hospital  Medical  Center  (CCHMC)  and  the  Institute  for  Systems  Biology (ISB) in Seattle to conduct a systems level analysis of “omics” data. Perturbed growth and maturity can  lead  to  placental  insufficiency,  which  underlies  a  significant  proportion  of  adverse  pregnancy  outcomes,  such  as preterm birth.  A paucity of knowledge regarding normal placental development and maturity greatly hinders  any  study  of  placental  insufficiency.  Placental  growth  and  development  occurs  throughout  gestation  and  reaches maturity at term. Therefore, it is critical to identify the networks involved and to assess them over the  length of gestation. Our central hypothesis is that key biological networks vital to placental growth and  maturity  can  be  identified  through  the  intersection  of  transcriptomic,  proteomic,  and  metabolomics  data  from  term  and  preterm  placentae.  Furthermore,  utilizing  longitudinal  proteomics  and  metabolomics  data,  we  can  determine  how  those  pathways  change  over  gestation  and  differ  between  normal  and  preterm  placentae. We will test this hypothesis through the following aims:   Aim  1:  Identification  of  key  gene  and  metabolite  signatures  involved  in  placental  development  by  analyzing  longitudinal  “omics”  data.  Using  publically  available  transcriptomic  data,  we  will  generate  a  molecular profile of expressed genes in placental development throughout gestation.  We will also determine  the  placental  secretome  and  identify  biomarker  signatures  that  appear  in  maternal  urine  that  reflect  placental  maturation.   Aim  2:  Identification  of  molecular  pathways  associated  with  placental  maturity.  We  will  utilize  network  topology algorithms to identify changes in molecular pathways in preterm and term placentae. These data will  be  combined  with  publically  available  data  to  identify  molecular  pathways  and  genes  within  those  pathways  that differ between term and preterm placentae to provide insight into placental maturity.   Aim 3: Generation of a placenta-­specific transcriptional network for identifying regulatory mechanisms  involved  in  placental  maturity.  We  will  construct  genome-­scale,  tissue  specific  models  of  placental  transcriptional  regulatory  networks  using  our  newly-­developed  Transcriptional  Regulatory  Network  Analysis  (TRENA)  approach,  which  leverages  a  wealth  of  information  from  the  NIH’s  ENCODE  project.  We  will  characterize  which  transcriptional  regulators  are  most  likely  responsible  for  perturbed  gene  expression,  their  signaling pathways and downstream targets. Previously unknown or understudied networks or genes identified  targeted for further analyses in placental growth and maturity and future prospective clinical studies.        PROJECT NARRATIVE    The normal development of the placental is essential for optimal pregnancy outcomes, and understanding normal  and  pathological  placental  development  will  allow  new  opportunities  to  prevent  major  public  health  concerns  such as preterm birth, preeclampsia, and intrauterine growth restriction. This work will seek to develop new, non-­ invasive  strategies  to  monitor  human  placental  maturation,  reflecting  normal  development,  against  which  deviations can be determined earlier in pregnancy for more effective interventions.   ","Harnessing ""omics"": A Systems Biology approach to discovery of biological pathways in placental development and parturition",9855015,R01HD091527,"['Accounting', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological', 'Biological Assay', 'Biological Markers', 'Birth', 'Blood', 'Clinical Research', 'Data', 'Databases', 'Development', 'Ethics', 'Fetal Growth', 'Fetal Growth Retardation', 'First Pregnancy Trimester', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Growth and Development function', 'Human', 'Institutes', 'Knowledge', 'Lead', 'Length', 'Medical', 'Medical center', 'Methodology', 'Modeling', 'Molecular', 'Molecular Profiling', 'Monitor', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatric Hospitals', 'Peptides', 'Peripheral', 'Placenta', 'Placental Biology', 'Placental Insufficiency', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Pregnancy Outcome', 'Premature Birth', 'Prevention', 'Proteins', 'Proteomics', 'Public Health', 'Role', 'Sampling', 'Signal Pathway', 'Source', 'System', 'Systems Biology', 'Testing', 'Tissues', 'United States National Institutes of Health', 'Urine', 'Work', 'adverse pregnancy outcome', 'biomarker panel', 'database design', 'effective intervention', 'fetal', 'genome-wide', 'infant death', 'insight', 'longitudinal analysis', 'machine learning algorithm', 'maternal serum', 'metabolomics', 'premature', 'prevent', 'prospective', 'transcription factor', 'transcriptomics']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R01,2020,149117,-0.01134044728429158
"Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions Project Summary/Abstract DNA sequencing has spawned the “microbiome revolution” -- thousands of microbes and a dizzying number of microbial interactions that are associated with human health and disease. Unfortunately, most species in the microbiome are known only by a (partial) genome. The limited phenotypic data on newly discovered bacteria reveal species that behave unlike any of our model organisms. While genome-scale modeling plays an important role in understanding the microbiome, the paucity of phenotypic data for most species prevents detailed simulation of the microbial communities that affect our health. This project will develop an automated system for profiling, synthesizing, and modeling microbial communities. The center of our approach is Deep Phenotyping, an automated robotic platform that performs complex growth experiments on demand. Data from Deep Phenotyping will be used to train metabolic and statistical models of the oral pathogens Streptococcus mutans and Candida albicans to predict conditions that keep both microbes in a nonpathogenic state. Project Narrative The microbiome revolution has uncovered thousands of species of bacteria with roles in health and disease. This project automates the identification of interactions between environments, genes, and the microbes that live in and around us. Understanding these interactions is a critical step in re-engineering the microbiome to improve human health.","Automated, model-guided phenotyping to identify metabolite/gene/microbe interactions",9852330,R21EB027396,"['Affect', 'Animal Model', 'Antibiotics', 'Area', 'Bacteria', 'Biochemical Pathway', 'Bioinformatics', 'Biological', 'Biological Assay', 'Candida albicans', 'Carbon', 'Coculture Techniques', 'Collaborations', 'Combinatorics', 'Communities', 'Complex', 'Computer software', 'DNA sequencing', 'Data', 'Development', 'Disease', 'Engineering', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Future', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Human Microbiome', 'Hybrids', 'Image', 'Individual', 'Knock-out', 'Knowledge', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Metabolic', 'Methods', 'Microbe', 'Microbiology', 'Modeling', 'Oral', 'Oral candidiasis', 'Pathway interactions', 'Phenotype', 'Play', 'Positioning Attribute', 'Regulator Genes', 'Research Personnel', 'Robotics', 'Role', 'Shapes', 'Source', 'Statistical Models', 'Streptococcus mutans', 'Structure', 'System', 'Technology', 'Time', 'Training', 'Work', 'base', 'combinatorial', 'cost', 'design', 'dysbiosis', 'experience', 'experimental study', 'fitness', 'fungus', 'genome-wide', 'improved', 'instrumentation', 'large datasets', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microorganism interaction', 'network models', 'open source', 'oral pathogen', 'pathogenic fungus', 'phenotypic data', 'preference', 'prevent', 'screening', 'simulation', 'transcription factor', 'transcriptome sequencing', 'transposon sequencing']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,178949,-0.005299649305378121
"Center for Sub-Cellular Genomics A cell is a highly complex system with distributed molecular physiologies in structured sub- cellular compartments whose interplay with the nuclear genome determine the functional characteristics of the cell. A classic example of distributed genomic processes is found in neurons. Learning and memory requires modulation of individual synapses through RNA localization, localized translation, and localized metabolites such as those from dendritic mitochondria. Dendrites of neurons integrate distributed synaptic signals into both electrical and nuclear transcriptional response. Dysfunction of these distributed genomic functions in neurons can result in a broad spectrum of neuropsychiatric diseases such as bipolar and depressive disorders, autism, among others. Understanding complex genomic interactions within a single cell requires new technologies: we need nano-scale ability to make genome-wide measurements at highly localized compartments and to effect highly localized functional genomic manipulations, especially in live tissues. To address this need, we propose to establish a Center for Sub-Cellular Genomics using neurons as model systems. The center will develop new optical and nanotechnology approaches to isolate sub-cellular scale components for genomic, metabolomics, and lipidomic analyses. The center will also develop new mass spectrometry methods, molecular biology methods, and informatics models to create a platform technology for sub-cellular genomics. Many human diseases, especially neuropsychiatric diseases, can be traced to dysfunction of organelles and other sub-cellular components. This project will create novel technologies to study function and dysfunction of sub-cellular processes and apply them to study of neurons.",Center for Sub-Cellular Genomics,9973075,RM1HG010023,"['Address', 'Alzheimer&apos', 's Disease', 'Attention', 'Automobile Driving', 'Awareness', 'Biological Assay', 'Biological Models', 'Bipolar Disorder', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Cellular biology', 'Characteristics', 'Chromatin', 'Communities', 'Complex', 'Data', 'Dendrites', 'Depressive disorder', 'Devices', 'Disease', 'Education and Outreach', 'Educational workshop', 'Functional disorder', 'Genetic Transcription', 'Genome', 'Genomics', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Informatics', 'Institution', 'Investigation', 'Learning', 'Liquid substance', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Memory', 'Mental Depression', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Molecular Biology', 'Motivation', 'Nanotechnology', 'Neurodegenerative Disorders', 'Neurons', 'Nuclear', 'Optical Methods', 'Optics', 'Organelles', 'Output', 'Pathway interactions', 'Phenotype', 'Philadelphia', 'Physiology', 'Process', 'Proteins', 'RNA', 'Regulation', 'Research Project Grants', 'Resolution', 'Risk', 'Rodent', 'Role', 'Schizophrenia', 'Signal Transduction', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Traumatic Brain Injury', 'Variant', 'Work', 'autism spectrum disorder', 'base', 'deep learning', 'epigenomics', 'exosome', 'experience', 'flexibility', 'functional genomics', 'genome-wide', 'human disease', 'informatics tool', 'macromolecule', 'metabolomics', 'multimodality', 'nanoscale', 'neuropsychiatric disorder', 'new technology', 'novel', 'outreach', 'response', 'subcellular targeting', 'technology development', 'technology validation', 'transcriptome', 'welfare', 'whole genome']",NHGRI,UNIVERSITY OF PENNSYLVANIA,RM1,2020,500000,-0.022357379423709384
"Computational and Experimental Resources for Virome Analysis in Inflammatory Bowel Disease (CERVAID) SUMMARY  While the role of the bacterial microbiome in human health and disease is well established, few studies have evaluated the contribution of the virome. Recently, we demonstrated that alterations in the enteric virome in adulthood are associated with diseases such as inflammatory bowel disease (IBD) and AIDS. In a cross- sectional comparison of IBD cases and household controls, a significant expansion of the Caudovirales, an order of phages, and anelloviruses, a family of eukaryotic DNA viruses, was observed. Advancing understanding of the IBD virome beyond this finding is limited by: (1) A lack of well defined longitudinal human cohorts to enable discovery of temporal associations of the virome with health and disease; (2) The challenge of viral “dark matter”. Dark matter refers to the typically >50% of the sequences present in purified virus preparations cannot be classified due to a lack of statistically significant alignment to known reference sequences. Thus, current virome studies effectively assess < 50% of the virome, thereby compromising our ability to detect important associations between the virome and disease; (3) Inadequate experimental systems to manipulate the virome. Although sequencing has identified many novel eukaryotic viruses, there are only cell culture systems for a limited number of viruses; moreover, there are no small animal infection models for newly described viruses. In addition while a tremendous diversity of phage has been identified, only a tiny fraction have known hosts and an even smaller fraction has been cultured. Thus, there are significant barriers that must be overcome to be able to experimentally test the impact of either eukaryotic viruses or phages in murine IBD models. These barriers to understanding the role of the IBD virome will be addressed as follows: Aim 1 will define the enteric virome and bacterial microbiome in a longitudinal cohort of IBD patients and household controls and identify virome associations with IBD. In Aim 2 novel computational tools to identify and characterize viruses present in enteric viromes will be developed, including approaches to classify dark matter. In Aim 3 novel experimental systems for functional virome analysis, including novel cultures of both eukaryotic viruses and phages as well as animal infection models, will be developed with the end goal of evaluating causal roles for the viruses and phage in existing muring IBD models. Together, these Aims will not only address significant barriers in understanding of IBD, but will provide a wealth of tangible computational and experimental resources to advance the general field of virome studies.   NARRATIVE The overall goal of this project is to develop novel computational and experimental tools to address challenges in understanding the role of viruses in inflammatory bowel disease. These tools will facilitate studies of not only inflammatory bowel disease, but also broader studies of the relationship of the human virome to other diseases.  ",Computational and Experimental Resources for Virome Analysis in Inflammatory Bowel Disease (CERVAID),10019521,RC2DK116713,"['Acquired Immunodeficiency Syndrome', 'Address', 'Adult', 'Animal Model', 'Animals', 'Bacteria', 'Bacterial Infections', 'Bacteriophages', 'Bioinformatics', 'Biology', 'Caudovirales', 'Cell Culture System', 'Cell Culture Techniques', 'Chronic', 'Classification', 'Clinical', 'Communities', 'Computer Analysis', 'Computer software', 'DNA Viruses', 'Databases', 'Defect', 'Development', 'Digestive System Disorders', 'Disease', 'Disease model', 'Enteral', 'Family', 'Feces', 'Genome', 'Gnotobiotic', 'Goals', 'Health', 'High-Throughput Nucleotide Sequencing', 'Household', 'Human', 'Immune system', 'Infection', 'Inflammatory Bowel Diseases', 'Longitudinal cohort', 'Machine Learning', 'Metabolic Diseases', 'Metadata', 'Metagenomics', 'Modeling', 'Mus', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Norovirus', 'Open Reading Frames', 'Parasitic infection', 'Pathogenesis', 'Pathogenicity', 'Pathology', 'Patients', 'Play', 'Population', 'Preparation', 'Resource Development', 'Resources', 'Ribosomal RNA', 'Role', 'System', 'Taxonomy', 'Testing', 'Time', 'Viral', 'Viral Genes', 'Viral Genome', 'Virus', 'Virus Diseases', 'bacterial resistance', 'bacteriome', 'base', 'case control', 'cohort', 'computerized tools', 'contig', 'dark matter', 'early childhood', 'experimental analysis', 'genome annotation', 'gut microbiome', 'human virome', 'improved', 'metagenome', 'microbial', 'molecular sequence database', 'multidisciplinary', 'novel', 'phenomenological models', 'protein function', 'software development', 'stool sample', 'tool', 'virology', 'virome']",NIDDK,WASHINGTON UNIVERSITY,RC2,2020,1832307,-0.0014658066699308966
"Genetic neuroscience: How human genes and alleles shape neuronal phenotypes Genetic studies have identified many specific loci with significant associations to psychiatric disorders. However, unless we can develop useful approaches for systematically turning genetic information into neurobiological insights about brain disorders, there is a danger that costly and hard-won genetic findings will not be exploitable to understand pathophysiology and generate important therapeutic hypotheses. The goal of our collaborative, interdisciplinary effort is to develop powerful, generalizable approaches for discovering how risk variants for psychiatric disorders shape neurobiological processes at multiple levels of analysis, and to identify the processes whose dysregulation underlies disease. To do this, we propose to develop new experimental and inferential systems to bridge a longstanding gap between human genetics and experimental biology. We aim to identify biological causes and effects that span the genetic, molecular, and cellular levels of the nervous system. Our interdisciplinary team will develop new experimental systems that measure genetic influences across levels of analysis (RNA, proteins, and cellular function including physiology) in precise, scalable, well- controlled ways. We will make use of emerging cellular systems including three-dimensional cortical spheroids and organoids, and radically novel “population in a dish” experimental systems that collect data on cells from hundreds of donors in a shared environment, inferring donor identity at the time of phenotypic readout. The analysis of such systems in turn requires sophisticated inferential strategies and new ideas from computer science. We propose to develop and widely share experimental and computational resources, including cell lines, methods, datasets, and analytic tools. The successful completion of this work will identify key neurobiological processes for multiple psychiatric disorders, and fortify many other scientists in making such connections in their own work. We hope in so doing to create a new kind of interdisciplinary science that – by combining the strengths of data-driven, unbiased human genetics with the power of emerging experimental systems – transforms the rate at which human- genetic leads lead to insights about disease mechanisms. To better understand common, severe psychiatric illnesses and develop improved treatments for them, we need to understand what specific aspects of brain biology give rise to each disorder. Here a team of scientists with diverse areas of expertise – from neuroscience to computer science to psychiatry to human genetics to stem cell biology – come together to develop a set of next-generation scientific approaches to this important problem, and to generate new methods and data sets that we will widely share. Our team will work to understand how aspects of brain biology at many levels – genes, molecules, and cells – act upon one another to create vulnerability to psychiatric illness.",Genetic neuroscience: How human genes and alleles shape neuronal phenotypes,9989904,U01MH115727,"['3-Dimensional', 'Affect', 'Alleles', 'Architecture', 'Area', 'Awareness', 'Biological', 'Biological Assay', 'Biology', 'Brain', 'Brain Diseases', 'California', 'Cell Differentiation process', 'Cell Line', 'Cell physiology', 'Cells', 'Cellular biology', 'Communities', 'Computer Analysis', 'Data', 'Data Science', 'Data Set', 'Disease', 'Engineering', 'Environment', 'Experimental Models', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic study', 'Goals', 'Human', 'Human Genetics', 'Individual', 'Institutes', 'Investments', 'Ion Channel', 'Lead', 'Libraries', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Microglia', 'Molecular', 'Molecular Biology', 'Mutation', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Organoids', 'Penetrance', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Process', 'Property', 'Proteins', 'Psychiatry', 'RNA', 'Regenerative Medicine', 'Resources', 'Risk', 'Sampling', 'Science', 'Scientist', 'Shapes', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Time', 'Variant', 'Work', 'analytical tool', 'cell type', 'computer science', 'computing resources', 'cost', 'cytokine', 'excitatory neuron', 'experimental study', 'genetic information', 'human data', 'improved', 'induced pluripotent stem cell', 'inhibitory neuron', 'innovation', 'insight', 'loss of function mutation', 'multidimensional data', 'neurophysiology', 'next generation', 'novel', 'protein expression', 'protein function', 'rare variant', 'response', 'risk variant', 'stem cell biology', 'translational neuroscience', 'whole genome']",NIMH,"BROAD INSTITUTE, INC.",U01,2020,4125261,-0.01639504357277716
"Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration PROJECT SUMMARY The cell nucleus is a heterogeneous organelle that consists of nuclear bodies such as nuclear lamina, speckles, nucleoli and PML bodies. These structures continuously tether and tug chromatin at the small and large scales to synergistically orchestrate dynamic functions in distinct spatio-temporal compartments. A major obstacle to the production of navigable 4D reference maps and relating structure to function in the nucleus remains understanding how these different scales of organization influence each other. In particular, we have a poor understanding of the large-scale genome organization. Growing evidence suggests that such nuclear compartmentalization is causally connected with vital genome functions in human health and disease. However, the principles of this nuclear compartmentalization, its dynamics during changes in cell conditions, and its functional relevance are poorly understood. One lesson from Phase 1 4DN was the huge gap in throughput between imaging methods, that directly measure large-scale multi-landmark relationships, and genomic methods, that aim for whole genome high-resolution maps but are indirect measurements and provide limited information about large-scale compartments. For this 4DN UM1 Center application, we propose to meet these needs through the following Aims: (1) Generate multi-modal imaging and genomic datasets to reveal the structure, dynamics, and function of nuclear compartmentalization; (2) Develop and apply computational tools for data-driven genome structure modeling and integrative analysis of nuclear compartmentalization; (3) Develop an integrative analysis and visualization platform with navigable 4D reference maps of nuclear organization. The combined datasets and results of our proposed approaches will advance our understanding of nuclear compartmentalization, the interwoven connections among different nuclear components, and their functional significance. Our new integrative analysis tools and data-driven predictive models will produce more complete nuclear organization reference maps that integrate large-scale chromosome structure data from live and super-resolution microscopy with multi-modal genomic data including smaller scale chromatin interaction maps and predict functional relationships and dynamic responses. Our navigable reference maps will be publicly accessible through an analysis platform that provides interactive visualization of multiple data types, thus enabling investigators with diverse expertise to simultaneously explore their own data and related datasets/tools and promoting collaborations that will open new horizons into the role of the 4D nucleome in human health and disease. PROJECT NARRATIVE The proposed research is relevant to public health because it will enhance our understanding of nuclear genome organization and functions that are increasingly being linked to health and disease. Because we develop tools to disseminate this information and enable others to work with our data and their own data, we will also bring nuclear architecture to bear on a broad range of ongoing health related research. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration,10156141,UM1HG011593,"['Address', 'Architecture', 'Atlases', 'Binding', 'Biochemical', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Chromatin', 'Chromatin Loop', 'Chromatin Structure', 'Chromosome Structures', 'Chromosomes', 'Collaborations', 'Communities', 'Complement', 'Computing Methodologies', 'Cytology', 'DNA Replication Timing', 'Data', 'Data Set', 'Development', 'Disease', 'Formulation', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Interphase Chromosome', 'Intuition', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Methods', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nuclear', 'Nuclear Lamina', 'Nuclear Structure', 'Organelles', 'Outcome', 'Output', 'Phase', 'Population', 'Production', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Structural Models', 'Structure', 'Technology', 'Three-Dimensional Imaging', 'United States National Institutes of Health', 'Ursidae Family', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'cell cycle genetics', 'cell type', 'computer framework', 'computerized tools', 'data exploration', 'data integration', 'data tools', 'experimental study', 'genome-wide', 'genomic data', 'histone modification', 'imaging modality', 'improved', 'insight', 'machine learning algorithm', 'mental function', 'multimodal data', 'multimodality', 'multiple data types', 'multiscale data', 'predictive modeling', 'response', 'spatiotemporal', 'structured data', 'tool', 'transcription factor', 'transcriptome sequencing', 'user-friendly', 'whole genome']",NHGRI,CARNEGIE-MELLON UNIVERSITY,UM1,2020,2075409,-0.016338343094846112
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,10090262,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,38074,-0.02014861257209457
"Mechanisms of mechano-chemical rupture of blood clots and thrombi Mechanisms of mechano-chemical rupture of blood clots and thrombi Prashant K. Purohit, John L. Bassani, Valeri Barsegov and John W. Weisel The goal of this proposal is to explore and understand the fracture toughness of blood clots and thrombi, thus providing a mechanistic basis for life-threatening thrombotic embolization. A combination of experiments, theoretical modeling and computer simulations will reveal how mechanical stresses (due to blood flow) in synergy with enzymatic lysis induce structural damage from the molecular to continuum scales and affect the propensity of a clot to embolize. The specific aims of this proposal are: (1) Measure and model fracture toughness of fibrin gels in quasi-static conditions, (2) Investigate rate dependent dissipative effects on toughness of fibrin gels, and (3) Study the effects of blood cells, prothrombotic blood composition, and fibrinolysis on rupture of blood clots. In Specific Aim (SA) 1, we will measure toughness of fibrin clots and provide a structural basis for rupture at the micron and nanometer scales. In SA2, we will delve into the thermodynamics and rate-dependence of the fracture of fibrin gels, including fluid flow through pores and fluid drag on fibrin fibers to capture how energy dissipation increases toughness. In the translational SA3, we will investigate toughness of physiologically relevant clots with effects of platelets, red blood cells, and neutrophils in the absence and presence of the physiological fibrinolytic activator (tPA). We will also study the rupture of clots made from the blood of venous thromboembolism patients to explore the effects of (pro)thrombotic alterations of blood composition on clot mechanical stability. Our preliminary studies show that i) the toughness of cross-linked fibrin gels is in the range of those for synthetic hydrogels, ii) the addition of tPA to a crack tip reduces the loads for crack growth, iii) fibers are aligned and broken along the tensile direction at the crack tip, and iv) crack propagation results from the rupture of covalent and non-covalent bonds. We also developed v) dynamic force spectroscopy in silico to mechanically test fibrin fibers and fibrin networks using pulling simulations and vi) atomic stress approach to map the stress-strain fields using the output from simulations. We will use continuum and finite element models of swellable biopolymer hydrogels, and statistical mechanical models for the forced unfolding of fibrin molecules. We will employ multiscale computational modeling based on Molecular Dynamics simulations of atomic structures of fibrin fibers, and Langevin simulations of fibrin networks accelerated on Graphics Processing Units. The proposed experiments cover the whole gamut of macroscopic tensile tests, shear rheometry, electron microscopy and confocal microscopy to visualize and quantitate the structural alterations of ruptured blood clots. Our experiments and modeling will help us to understand the mechanisms of thrombotic embolization and will address the clinically important question: why is there a strong association between clot structure/mechanical properties and cardiovascular diseases? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering. Project Narrative The research objective of this proposal is to measure, model and predict the mechanisms of mechano-chemical rupture of blood clots and thrombi at the molecular and continuum length scales. Our experiments and modeling will help to understand the mechanisms of embolization and will address the clinically important question: why is there a strong correlation between clot structure/mechanical properties and cardiovascular disease? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering.",Mechanisms of mechano-chemical rupture of blood clots and thrombi,9970812,R01HL148227,"['Address', 'Affect', 'Biocompatible Materials', 'Biological', 'Biomedical Engineering', 'Biopolymers', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood coagulation', 'Blood flow', 'Cardiovascular Diseases', 'Cause of Death', 'Chemicals', 'Clinical', 'Clinical Medicine', 'Coagulation Process', 'Complex', 'Computer Models', 'Computer Simulation', 'Confocal Microscopy', 'Cytolysis', 'Dependence', 'Diagnosis', 'Disease', 'Electron Microscopy', 'Elements', 'Enzymes', 'Erythrocytes', 'Evolution', 'Fiber', 'Fibrin', 'Fibrinogen', 'Fibrinolysis', 'Fracture', 'Frustration', 'Gel', 'Glean', 'Goals', 'Growth', 'Hydrogels', 'Knowledge', 'Laws', 'Length', 'Life', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mechanical Stress', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Molecular Structure', 'Output', 'Patients', 'Physicians', 'Physiological', 'Plasma', 'Predisposition', 'Prevention', 'Process', 'Property', 'Prophylactic treatment', 'Proteins', 'Research', 'Research Proposals', 'Resistance', 'Resources', 'Rupture', 'Specimen', 'Spectrum Analysis', 'Stress', 'Structural Models', 'Structural defect', 'Structure', 'Testing', 'Theoretical Studies', 'Theoretical model', 'Therapeutic Embolization', 'Thermodynamics', 'Thick', 'Thrombin', 'Thromboembolism', 'Thrombosis', 'Thrombus', 'Traction', 'Work', 'base', 'crosslink', 'density', 'design', 'disability', 'experimental study', 'fiber cell', 'fluid flow', 'in silico', 'in vivo', 'insight', 'instrumentation', 'interdisciplinary approach', 'materials science', 'mechanical properties', 'models and simulation', 'molecular dynamics', 'molecular scale', 'multi-scale modeling', 'nanoscale', 'neutrophil', 'novel strategies', 'predictive modeling', 'prevent', 'response', 'simulation', 'synergism', 'theories', 'tool', 'venous thromboembolism', 'viscoelasticity']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2020,656886,-0.006638724762003724
"A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions Project summary There is a fundamental gap in our understanding of how mutations are preferentially targeted to the variable (V) regions of the Immunoglobulin (Ig) loci during somatic hypermutation (SHM). The persistence of this gap has limited our understanding of the mutagenic mechanisms involving activation-induced deaminase (AID) in the immune response and in the role of AID in mis-targeting mutations leading to B-cell lymphomas and other cancers. The long-term goal of the proposed research is to understand the global targeting of mutations in immunity that are required to protect us from infections. As high-throughput data from human antibody immune responses became available, it provided us with new opportunities to generate hypotheses to explain the underlying mechanisms of SHM. We now propose to generate further hypotheses using computational models applied to additional databases and to validate these hypotheses using cellular and animal experiments. Our objective is to understand what directs SHM across the many human Ig heavy chain V-regions. Our central hypothesis is that the V-region SHM process is highly dependent on a DNA sequence signature(s) that drives mutations in a largely deterministic fashion. This hypothesis is supported by our preliminary results using human in vivo data from a few human V region genes and has begun to be validated using independent databases and experiments in human B cell lines. The rationale is that evaluations of computational data based upon biological mechanisms, together with appropriate biological experiments, will reveal the key differences between IGHV regions (IGHV 3-23, 4-34, 1-18, 1-02, etc.) that lead to the dominance of each of those V regions in the responses to medically important antigens. Our hypothesis will be tested by pursuing two specific aims: 1) identify the extent to which a DNA signature determines the mutation process in four individual human IGHV genes that are important in disease responses; 2) examine the relationship between AID hotspots and Polη hotspots across all the other human V region genes, thus rigorously defining a mutation targeting signature. Both aims will also entail studying human V region genes and modifications of them in human cell lines and in mice expressing a human V region to further confirm the signature and identify molecular mechanisms in vivo. Our approach is innovative because the computational models we are proposing will be mechanistically motivated focusing on the interaction between AID and Polη hotspots, thus testing molecular mechanisms as opposed to classic statistical models using whole V region sequences that ignore the underlying biology. In addition, to focus on mechanisms we will leverage new high-throughput data from human V regions that have not undergone antigen selection. Our results will be highly relevant to human IgV repertoire analyses from immune responses that are currently hard to interpret and will help future vaccine and therapeutic antibody development, as well as help to understand mutations in human malignancies where AID plays a key role. Project narrative The proposed research is relevant to public health because understanding the targeting of AID-mediated mutations across many human heavy chain V-regions will make it possible to develop vaccines that will lead more rapidly to better and more broadly protective antibodies to infectious agents and reveal the risk factors in the development of B-cell malignancies and gastric and other solid tumors where AID is implicated.",A combined computational and experimental approach to the evolution and role of the DNA sequence environment in targeting mutations to antibody V regions,9882227,R01AI132507,"['Affect', 'Alleles', 'Animal Experiments', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Autoimmunity', 'B lymphoid malignancy', 'B-Cell Development', 'B-Cell Lymphomas', 'B-Lymphocytes', 'Biological', 'Biology', 'Cell Line', 'Chromatin', 'Complementarity Determining Regions', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Disease', 'Environment', 'Enzyme Activation', 'Evaluation', 'Event', 'Evolution', 'Family', 'Feedback', 'Frequencies', 'Future', 'GTP-Binding Protein alpha Subunits, Gs', 'Gene-Modified', 'Genes', 'Goals', 'HIV', 'Heavy-Chain Immunoglobulins', 'Human', 'Human Cell Line', 'Immune response', 'Immunity', 'Immunoglobulin Somatic Hypermutation', 'Immunoglobulins', 'Individual', 'Infection', 'Infectious Agent', 'Influenza', 'Influenza Hemagglutinin', 'Knock-in', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Medical', 'Mismatch Repair', 'Molecular', 'Mus', 'Mutate', 'Mutation', 'Outcome', 'Pattern', 'Play', 'Polymerase', 'Process', 'Public Health', 'Research', 'Risk Factors', 'Role', 'Site', 'Solid Neoplasm', 'Statistical Models', 'Stomach', 'Structure of germinal center of lymph node', 'Techniques', 'Testing', 'Therapeutic antibodies', 'Time', 'Transgenic Mice', 'Vaccines', 'Validation', 'Variant', 'activation-induced cytidine deaminase', 'base', 'chromatin modification', 'density', 'experimental study', 'genetic variant', 'human data', 'in vivo', 'in vivo Model', 'innovation', 'neutralizing antibody', 'recruit', 'repair enzyme', 'response', 'spatial relationship', 'vaccine response']",NIAID,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,591815,-0.02014861257209457
"Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties ABSTRACT Mesenchymal stem cells (MSCs) have broad-based potential in regenerative medicine cell therapies and can be isolated from a variety of different tissues. Though MSCs from different tissues are phenotypically similar, a barrier to their clinical use is the high variability of their trophic and regenerative properties. This variability suggests that inherent differences exist in the molecular machinery guiding MSC properties between different MSC populations, yet, to date, these differences are ill-defined. To this end, we have preliminary evidence that MSC phenotypes correlate to their regenerative outcomes. In this study, we aim to elucidate how the molecular and cellular properties of distinct MSC populations determine their regenerative properties. Our hypothesis is that MSCs from different tissues have different regenerative properties which correlate to specific molecular profiles defined by gene expression and transcriptional activity. To test this hypothesis, the project proposed has three Specific Aims (SAs). In SA1, we will determine how tissue-specificity dictates gene expression and dynamic transcription factor activity of distinct MSCs. SA2 will determine how differences in the cellular and molecular properties of MSCs correlate to MSC phenotype. Finally, in SA3, we will determine how the molecular profiles and cellular activities of MSCs dictate their regenerative properties. Findings of the proposed study will provide novel insights about how the distinct molecular profiles of MSCs dictate their biological and physiological properties. In a therapeutic context, this would enable the development of innovative screening technologies for MSC therapies to identify and enrich for the most appropriate MSC for the specific therapeutic application. PROPOSAL NARRATIVE Stem cell therapies are emerging as a new treatment approach to regenerate lost tissues, treat ischemic disorders, and treat chronic inflammatory conditions. Many of these approaches use stem cells from adults which are present in various regions throughout the body. Our research team is working to better understand how and why these adult stem cells behave the way they do so that we can better determine how to use them in different therapies to treat debilitating health conditions.",Redefining mesenchymal stem cells: using their cellular and molecular phenotypes to determine their regenerative and therapeutic properties,9954044,R01DE028657,"['Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Angiogenic Factor', 'Automobile Driving', 'Biological', 'Biological Process', 'Bone Marrow', 'Bone Regeneration', 'Bone Tissue', 'Cell Culture Techniques', 'Cell Separation', 'Cell Therapy', 'Cells', 'Chronic', 'Clinical', 'Clinical Trials', 'Computer Models', 'Data', 'Dental', 'Dental Pulp', 'Development', 'Disease', 'ENG gene', 'Emerging Technologies', 'Fatty acid glycerol esters', 'Funding Mechanisms', 'Gene Expression', 'Gene Expression Profile', 'Genetic Transcription', 'Gingiva', 'Health', 'Immunophenotyping', 'Inflammation', 'Inflammatory', 'Knowledge', 'Link', 'Maintenance', 'Mesenchymal Stem Cells', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Muscle', 'Natural regeneration', 'Operative Surgical Procedures', 'Oral', 'Osteogenesis', 'Outcome', 'Pathway interactions', 'Performance', 'Phenotype', 'Physiological', 'Population', 'Population Heterogeneity', 'Production', 'Property', 'Regenerative Medicine', 'Regulation', 'Reporting', 'Research', 'Rodent Model', 'Role', 'Signal Pathway', 'Sorting - Cell Movement', 'Specificity', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Tooth structure', 'United States National Institutes of Health', 'Work', 'adult stem cell', 'alveolar bone', 'angiogenesis', 'base', 'bone', 'clinical translation', 'healthy volunteer', 'in vivo', 'innovation', 'insight', 'interest', 'machine learning algorithm', 'molecular phenotype', 'next generation sequencing', 'novel', 'oral tissue', 'osteogenic', 'population based', 'regenerative', 'regenerative therapy', 'screening', 'self-renewal', 'stem cell differentiation', 'stem cell population', 'stem cell therapy', 'stem cells', 'stemness', 'transcription factor', 'transcriptome']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,405389,-0.03311920471056417
"Intestinal Homeostasis Induced by Commensals ABSTRACT While multidrug-resistance transporters including P-gp and MRP2 are generally studied for their role in exporting drugs and foreign compounds from the cell, our studies indicate that these efflux pumps expressed at the apical surface of intestinal epithelial cells provide a critical link in communication between sentinel functions of mucosal barriers and the immune system. Understanding how this P-gp/eCB anti-inflammatory arm is regulated will provide crucial insight into how dysfunction may promote intestinal inflammation and help identify potential new therapeutic targets. Because the resident microbiota is known to contribute to tolerance and homeostasis in the healthy intestine, the central hypothesis we aim to test is whether the normal microbiota actively drives the P-gp/eCB axis to prevent unnecessary inflammation. Our pilot studies indicate that the microbiota does influence P-gp expression and function, providing a unique foundation for further cause-effect studies. No data have previously demonstrated a link between the microbiota and eCBs or any other epithelial lipid signals, and may well provide great insight into a novel system. Bridging this gap could help explain how commensal bacteria can stabilize a state of tolerance and how genetic modification of specific pathway elements might predispose individuals to conditions of inflammatory bowel disease (IBD). To begin addressing these questions, in Aim 1 of this application will combine in vitro (including human colonoids) and in vivo murine model systems, as well as use healthy and UC patient stool, to more deeply understand the microbial consortia that collectively maximize P-gp expression and function. Aim 2 is designed to identify the microbial metabolites that drive activation of P-gp expression and eCB secretion to maintain an anti-inflammatory tone in the intestinal epithelium. Thus, transcriptomics and metabolite analyses will be performed to provide new information regarding microbial genes, gene clusters, and their metabolic products implicated in maintaining an anti- inflammatory tone in the intestinal epithelium through regulation of the P-gp/eCB axis. In Aim 3 we will employ novel computational methods will to uncover the inter-microbial network responses and the ecological structure of a stable community that is able to induce P-gp expression. Collectively, knowledge of the pathways that coordinate the maintenance of the P-gp/eCB axis will require a comprehensive understanding of distinct signals regulating intestinal homeostasis, how multiple signals are integrated in the complex intestinal environment, and pathways that modulate host-microbe interactions. Consequently, this proposal will directly advance novel biological principles with guidance of new therapeutic intervention strategies. Public Health Narrative Regulated recruitment and migration of acute inflammatory cells termed neutrophils (PMN) into the intestine and across the specialized epithelium that lines it is critical for host defense, yet dysregulation of this process is associated with disease. Because the resident microbiota is known to contribute to tolerance and homeostasis in the healthy intestine, the goal of this proposal will examine whether the normal microbiota actively drives the P-gp/eCB axis to maintain a homeostatic anti-inflammatory tone in the intestinal epithelium. Understanding this process could help explain how commensal bacteria can stabilize a state of tolerance and how genetic modification of specific pathway elements might predispose individuals to conditions of inflammatory bowel disease (IBD).",Intestinal Homeostasis Induced by Commensals,10029718,R01DK125407,"['ABCB1 gene', 'Acute', 'Address', 'Anti-Inflammatory Agents', 'Apical', 'Bile Acids', 'Biological', 'Biological Models', 'Cells', 'Colitis', 'Communication', 'Communities', 'Complex', 'Computing Methodologies', 'Cues', 'Data', 'Disease', 'Elements', 'Endocannabinoids', 'Environment', 'Epithelial', 'Epithelial Cells', 'Epithelium', 'Equilibrium', 'Ethanolamines', 'Eubacterium', 'Feces', 'Foundations', 'Functional disorder', 'Gene Cluster', 'Genes', 'Genetic', 'Genetic Transcription', 'Goals', 'Homeostasis', 'Host Defense', 'Human', 'Immune system', 'In Vitro', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Inflammatory Response', 'Injury', 'Intervention', 'Intestinal Mucosa', 'Intestines', 'Invaded', 'Knowledge', 'Lactobacillus', 'Link', 'Lipids', 'Machine Learning', 'Maintenance', 'Mediating', 'Metabolic', 'Modeling', 'Modification', 'Molecular', 'Mucous Membrane', 'Multi-Drug Resistance', 'Mus', 'Outcome', 'Output', 'P-Glycoprotein', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Play', 'Process', 'Public Health', 'Pump', 'Regulation', 'Research', 'Resolution', 'Role', 'Sentinel', 'Severities', 'Signal Transduction', 'Structure', 'Submucosa', 'Surface', 'System', 'Testing', 'Time', 'Toxin', 'Work', 'Xenobiotic Metabolism', 'arm', 'bacterial community', 'base', 'commensal bacteria', 'design', 'efflux pump', 'first responder', 'healing', 'host colonization', 'host-microbe interactions', 'in vivo', 'inflammatory disease of the intestine', 'innate immune mechanisms', 'insight', 'intestinal epithelium', 'intestinal homeostasis', 'mathematical model', 'microbial', 'microbiome', 'microbiota', 'microorganism', 'migration', 'mouse model', 'neutrophil', 'new therapeutic target', 'normal microbiota', 'novel', 'novel therapeutic intervention', 'nuclear factor 1', 'prevent', 'recruit', 'response', 'theories', 'transcriptomics']",NIDDK,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2020,560048,-0.02514570311636961
