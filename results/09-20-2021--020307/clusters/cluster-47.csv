text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,9739919,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Base Management', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistics', 'subchondral bone', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,588354,-0.007405342142125164
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,9976740,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Heterogeneity', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2019,299197,-0.00656123822083304
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9748523,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,195128,-0.020709508526604376
"AmplideX DeepNet, a new paradigm for deep learning analytical tools in the molecular diagnostic space Project Summary  An extensible analysis platform will be developed to accurately perform the automated genotyping of PCR/capillary electrophoresis (CE) traces for multiple disease-associated short tandem repeater (STR) assays. This study will evaluate the feasibility of developing generalizable and adaptive molecular analysis models, and will ultimately establish a new paradigm for deep learning analytical tools in the molecular diagnostic space.  Advanced machine learning strategies will be applied to interpret genotypes of inherited disorders caused by genetically unstable STR DNA sequences. STRs have traditionally been difficult to investigate due to their length (on the order of kilobases) and low sequence complexity, which elude detection by traditional and next- generation sequencing technologies. However, advances in PCR/CE technology have enabled the amplification and fragment sizing of STR DNA fragments, advancing clinical research and diagnostic test development for several neurodegenerative disorders, such as fragile X syndrome and amyotrophic lateral sclerosis. Despite these advances, the analysis of PCR/CE data from assays targeting STRs remains a manual, burdensome, and subjective process. There is a clear need to create a system that can scale with the development of new assays, and the proposed approach utilizes modern breakthroughs in artificial intelligence to fulfill that need.  This method will leverage recent advances in representation learning to establish a generalized and adaptive framework for automated PCR/CE annotation that can scale to new assays and improve automatically with the inclusion of new data. The project will benefit from Asuragen’s experience in optimizing repeat-primed chemistries to develop and commercialize multiple high performance assays including the AmplideX PCR/CE FMR1 kit. Importantly, the proposed modeling strategy will borrow-strength across multiple established PCR/CE assays and generalize to future PCR/CE assays for novel STR disease associated biomarkers. This system will be paramount to enabling a continuous learning platform wherein computationally-assisted annotation of PCR/CE assays can be continuously improved and integrated in to clinical research tools and diagnostics. Project Narrative  We are developing AmplideX DeepNet, an artificial intelligence-based analysis system that can accurately perform computationally-assisted analysis of molecular diagnostic assays. The proposed system will build upon recent breakthroughs in artificial intelligence to allow it to easily adapt to new assays and to continue to improve. The system will be applied to assays for several disorders, including fragile X syndrome, amyotrophic lateral sclerosis (ALS), myotonic dystrophy, and Huntington’s disease, and will provide a number of benefits over current analysis methods by reducing turn-around time for assay results and assuring reproducible reporting between operators and labs.","AmplideX DeepNet, a new paradigm for deep learning analytical tools in the molecular diagnostic space",9678895,R43GM128498,"['Alleles', 'American', 'Amyotrophic Lateral Sclerosis', 'Artificial Intelligence', 'Automated Annotation', 'Biological Assay', 'Biological Markers', 'C9ORF72', 'Capillary Electrophoresis', 'Chemistry', 'Clinical', 'Clinical Research', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnostic', 'Diagnostic tests', 'Disease', 'FMR1', 'FMR1 repeat', 'Fragile X Syndrome', 'Future', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Guidelines', 'Hand', 'Hereditary Disease', 'Heritability', 'Huntington Disease', 'Interruption', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical Genetics', 'Methods', 'Modeling', 'Modernization', 'Molecular Analysis', 'Myotonic Dystrophy', 'Neurodegenerative Disorders', 'Nucleotides', 'Pathogenicity', 'Performance', 'Phase', 'Process', 'Quality Control', 'Reagent', 'Reporting', 'Reproducibility', 'Running', 'Sampling', 'Short Tandem Repeat', 'System', 'Systems Analysis', 'Technology', 'Testing', 'Time', 'Training', 'analysis pipeline', 'analytical tool', 'automated analysis', 'base', 'clinical diagnostics', 'cohort', 'computer framework', 'deep learning', 'design', 'diagnostic assay', 'experience', 'frontotemporal lobar dementia-amyotrophic lateral sclerosis', 'heuristics', 'human-in-the-loop', 'improved', 'instrumentation', 'learning progression', 'learning strategy', 'medical schools', 'molecular diagnostics', 'nervous system disorder', 'next generation sequencing', 'novel', 'research and development', 'success', 'tool']",NIGMS,"ASURAGEN, INC.",R43,2019,269217,-0.0266688933469922
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9783816,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,438449,-0.02720637432496448
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9751222,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2019,373460,-0.04256328622548262
"Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment PROJECT SUMMARY We propose a study of radiomic texture analysis in terms of robustness assessment and classification utility. We will introduce novel robustness metrics geared towards assessment of radiomic features in comparison across two image conditions, and apply these metrics to study feature robustness across imaging parameters and patient biology. In addressing the utility of radiomic features in cancer risk assessment, we will identify and evaluate texture signatures from mammography and tomosynthesis datasets. The field of radiomics is evolving fast, and quantitative texture analysis is being applied to a growing number of applications in medical imaging. By performing a thorough investigation of the robustness of these radiomic features to dataset heterogeneities we aim to identify the strengths and weaknesses of commonly used features to guide their implementations on future applications.  Two clinical tasks will be studied under the proposed research: 1) risk assessment and cancer prediction and 2) malignancy evaluation. Multiple modalities including tomosynthesis, mammography and MRI will be involved in studies geared towards addressing these clinical questions. An evaluation of the robustness of commonly employed radiomic features will help guide the field of medical texture analysis and contribute to meaningful conclusions in future studies throughout the field of quantitative image analysis. The first aim of the proposed research involves the proposition and evaluation of novel robustness metrics for investigations lacking a classification task. The second aim will extend the study of radiomics to investigate the utility of robust features in classification tasks and identification of texture signatures relate to biomedical characteristics. The third aim will build upon the two previous aims and culminate in the application of cutting-edge technologies in machine learning and deep learning in further promoting image processing in the field of medical physics. PROJECT NARRATIVE The goal of the proposed research is to evaluate and improve the application of radiomic texture features in cancer risk assessment. We will accomplish this by evaluating the robustness of various radiomic metrics, testing the classification utility of texture features in clinical tasks, and extending current classification methods to include cutting-edge developments in machine learning technology. Careful preliminary studies have demonstrated methods for selection of robust texture features and improvement in classification tasks by emphasizing feature robustness in feature selection methodology and we therefore believe that a meticulous evaluation of the impact of imaging parameters on feature calculations will lead to overall improvement of computer-aided diagnosis and clinical translation to progress in cancer screening protocols.",Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment,9683697,F31CA228247,"['Address', 'Benign', 'Biological', 'Biology', 'Breast', 'Breast Cancer Risk Factor', 'Characteristics', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Effectiveness', 'Eligibility Determination', 'Emerging Technologies', 'Evaluation', 'Family', 'Future', 'Goals', 'Heterogeneity', 'Image', 'Image Analysis', 'Impact evaluation', 'Incidence', 'Intuition', 'Investigation', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammography', 'Maps', 'Mathematics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Output', 'Patients', 'Pattern', 'Performance', 'Physics', 'Protocols documentation', 'Psychological Transfer', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Screening for cancer', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Imaging', 'Time', 'Translations', 'Variant', 'Work', 'base', 'breast imaging', 'cancer risk', 'clinical translation', 'deep learning', 'expectation', 'high risk', 'image processing', 'image registration', 'imaging modality', 'imaging system', 'improved', 'innovation', 'molecular subtypes', 'multimodality', 'novel', 'outcome forecast', 'patient population', 'quantitative imaging', 'radiomics', 'response', 'tomosynthesis', 'tumor']",NCI,UNIVERSITY OF CHICAGO,F31,2019,24304,-0.03782783238949066
"Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images ABSTRACT Manual analysis of biomedical images by researchers and pathologists has the potential to introduce bias and error that compromise the reliability of research and clinical findings. These problems are significant barriers to delivering the most beneficial evidence-based medicine, developing effective medical treatments, and promoting confidence in scientific inquiry. Identification of biomarkers and cellular targets following microscopy requires manual analysis of biomedical images, which is time intensive, difficult, and prone to bias and errors. Unintentional bias and attentional limitations during analysis of biomarkers can underlie poor reproducibility of findings in biomedical research and potentially introduce error in clinical diagnostics. We recently developed a “beta” software package designed to improve automation and standardization of image analysis, called “PIPSQUEAK” (Perineuronal net Intensity Program for the Standardization and Quantification of Extracellular matrix Analysis Kit). Since its publication in 2016, PIPSQUEAK beta has amassed approximately 1,300 users worldwide who use it to quantify the intensity and number of perineuronal nets and other neural markers in the brain. This technology significantly increases data reliability between image raters and decreases the time required for analysis by more than 100-fold. However, PIPSQUEAK beta currently uses target detection algorithms that require high-contrast images to automatically identify neurons as clusters of bright pixels on dark backgrounds. A significant current limitation to PIPSQUEAK beta, and other available imaging programs, is that detection of biomarkers can be difficult unless image conditions are ideal. Suboptimal conditions, like high background staining, off-target structures, overlapping or clustered biomarkers, and atypical morphologies, can lead to artifacts and consequently to inaccurate results and erroneous conclusions. Here, we propose to develop a user-friendly artificial intelligence (AI) platform for the automated detection of targeted biomarkers in digital microscopy that reduces this error by learning to distinguish between true cellular biomarkers and artifacts. We propose to integrate AI capabilities into our PIPSQUEAK technology to produce an adaptive, high-throughput, biomedical image analysis platform that quickly and accurately identifies biomarker targets from bench to bedside. A key advantage is that this AI program will be user friendly and available online, making it highly accessible to basic researchers and to technicians and clinicians identifying human pathologies. Thus, successful development of our AI program has a high translational potential. The goal of this proposal is 1) to develop and validate a machine learning model that is capable of detecting common histological marker morphologies in digital microscopy, and 2) to test the feasibility of adapting our AI platform to new biomarker datasets with minimal additional supervised training. Our end goal is to advance the reliability and speed of research findings and clinical diagnoses by making this technology widely available to researchers and clinicians. PROJECT NARRATIVE Manual analysis of biomedical images by researchers and pathologists has the potential to introduces bias and error that compromise the reliability of research and clinical findings; problems which are significant barriers to delivering the most beneficial evidence-based medicine and developing effective medical treatments. Application of artificial intelligence for the detection of disease or cellular targets has the potential to improve the reliability of research findings and clinical diagnoses, while reducing waste, time, and expense. We propose a method to improve the quality of biomedical research reproducibility and clinical diagnoses by developing a high-throughput, adaptive artificial intelligence platform for automated analysis of cellular and disease targets in digital microscopy images, which will be made available to scientists and clinicians as a user-friendly analysis platform.",Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images,9845994,R43GM134789,"['Abbreviations', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Automation', 'Biological Markers', 'Biomedical Research', 'Brain', 'Cell Line', 'Cell model', 'Cellular Morphology', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Coupled', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Evidence Based Medicine', 'Extracellular Matrix', 'FOS gene', 'Fluorescence', 'Future', 'Glial Fibrillary Acidic Protein', 'Goals', 'Histologic', 'Histology', 'Human Pathology', 'Image', 'Image Analysis', 'Immunoassay', 'Immunohistochemistry', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Medical', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Neurons', 'Nuclear', 'Pathologist', 'Performance', 'Procedures', 'Psychological Transfer', 'Publications', 'Rattus', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Shapes', 'Speed', 'Stains', 'Standardization', 'Structure', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Banks', 'Tissue Model', 'Tissue imaging', 'Tissues', 'Training', 'Zebrafish', 'automated analysis', 'base', 'bench to bedside', 'bioimaging', 'biomarker identification', 'cell type', 'cellular targeting', 'clinical Diagnosis', 'clinical diagnostics', 'contrast imaging', 'design', 'digital', 'digital imaging', 'extracellular', 'histological specimens', 'histological stains', 'imaging biomarker', 'imaging program', 'improved', 'interest', 'lateral line', 'microscopic imaging', 'predictive marker', 'programs', 'relating to nervous system', 'software as a service', 'statistics', 'targeted biomarker', 'tool', 'user-friendly', 'wasting']",NIGMS,"REWIRE NEUROSCIENCE, LLC",R43,2019,224915,-0.01452233766550614
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9692717,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2019,695400,-0.011483251551786536
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9706921,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2019,381629,-0.028635669580790304
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9619075,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deaf', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'machine learning algorithm', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2019,318386,-0.0673611838610588
"Development and Evaluation of a Machine Learning Approach to Interpret Optical Coherence Tomography Images of the Middle Ear to Improve Antibiotic Management PROJECT SUMMARY Introduction: PhotoniCare, Inc. is a medical device company developing the TOMi Scope, a handheld, optical imaging device for improved diagnosis of middle ear health. The purpose of this proposal is to establish and evaluate a machine learning approach to interpret TOMi Scope depth-resolved images using a set of ear models with human middle ear effusion (MEE; fluid) to enable improved diagnostic accuracy and, ultimately, antibiotic stewardship for ear health. Significance: Ear infections affect 95% of all children, yet they are one of the most poorly diagnosed and managed diseases in all of medicine, resulting in high antibiotic over-prescription and antibiotic resistance development. Correctly identifying the absence or presence/type of MEE through the non-transparent eardrum is critical to accurate diagnosis, and the limited current diagnostic tools suffer poor diagnostic accuracy (50- 70%) due to inherent subjectivity and dependence on user experience. Therefore, objective image classification metrics to enable improved diagnostic accuracy is sorely needed to finally provide children afflicted by this disease with the correct treatment the first time. Hypothesis: Applying a machine learning approach to TOMi Scope image classification of a set of ear models with human MEE will facilitate detection of the presence or absence of effusion (≥90% accuracy), as well as classification by the type of effusion samples (≥80% accuracy), regardless of user experience. Specific Aims: (1) Collect robust datasets of ex vivo human MEE, sufficient for machine learning image analysis. (2) Develop a neural network model based on the MEE dataset and apply the model to a representative test clinical dataset to determine classification feasibility. Commercial Opportunity: The TOMi Scope will provide physicians with new, objective information, enabling better decision-making for antibiotic prescription and surgical intervention. This has the potential to impact the standard of care for ~1B children worldwide that experience ear infections, representing a multi-billion-dollar commercial opportunity. PROJECT NARRATIVE Ear infections (otitis media) are highly prevalent in the pediatric population and represent a significant clinical challenge due to the limitations of the gold-standard diagnostic tools, resulting in high antibiotic prescription but also antibiotic resistance development. Accurate detection and classification of effusion (fluid) in the middle ear is a critical element for this diagnosis, and for making informed medical treatment decisions, particularly regarding antibiotic stewardship. The long-term goal of this work is to reduce antibiotic resistance and healthcare costs through improving patient outcomes by addressing the low diagnostic accuracy and user experience dependence of current subjective methods, with a novel, non-invasive imaging tool capable of quantitative depth-resolved measurements to not only visualize the underlying infection behind the eardrum, but also, with automated machine learning image analysis algorithms, minimize user experience dependence and variability.",Development and Evaluation of a Machine Learning Approach to Interpret Optical Coherence Tomography Images of the Middle Ear to Improve Antibiotic Management,9847606,R43DC017422,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Biological', 'Biomechanics', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Childhood', 'Classification', 'Clinical', 'Collaborations', 'Controlled Environment', 'Data', 'Data Quality', 'Data Set', 'Decision Making', 'Dependence', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Elements', 'Evaluation', 'Family suidae', 'Goals', 'Gold', 'Health', 'Health Care Costs', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Infection', 'Intestines', 'Liquid substance', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Device', 'Medicine', 'Methods', 'Modeling', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Otitis Media', 'Otitis Media with Effusion', 'Otoscopy', 'Outcome', 'Pathologic', 'Patient observation', 'Patient-Focused Outcomes', 'Performance', 'Physicians', 'Population', 'Pythons', 'Resistance development', 'Safety', 'Sampling', 'Serous', 'Sterility', 'Surface', 'Technology', 'TensorFlow', 'Testing', 'Time', 'Tissues', 'Training', 'Tympanic membrane', 'Work', 'accurate diagnosis', 'base', 'convolutional neural network', 'deep learning', 'diagnostic accuracy', 'digital', 'ear infection', 'effusion', 'ex vivo imaging', 'experience', 'hearing impairment', 'improved', 'in vivo', 'middle ear', 'neural network', 'non-invasive imaging', 'novel', 'optical imaging', 'pediatric patients', 'standard of care', 'tool']",NIDCD,"PHOTONICARE, INC.",R43,2019,223899,-0.0025017572929621184
"Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis Project Summary Blood culture sensitivity in neonates is poor but is the “Gold Standard” for the diagnosis of sepsis. Universal genotyping of pathogen genomic sequences using High Resolution Melt (U-HRM) provides a simple, low cost, rapid, and modern alternative to blood culture testing. By measuring the fluorescence of an intercalating dye as PCR-amplified pathogen DNA fragments are heated and disassociate, sequence defined melt curves are generated with single-nucleotide resolution in a closed-tube reaction. We have advanced U- HRM into a digital PCR format (U-dHRM), where DNA sequences that are present in mixtures are individually amplified and identified as is needed for polymicrobial infections. We have also established unique signature melt curves for 37 bacterial species that commonly infect older children and adults and automatically identify them using machine learning technology. With the goal of creating an accurate and valid test for the timely diagnosis of neonatal sepsis, we will advance this technology to identify unique fungal, viral, and bacterial HRM signatures along with antibiotic resistance genes with an accuracy of 99-100% on minimal blood volume (1mL). Our aims are: Aim 1. Optimize and assess the U-dHRM platform for neonatal bacteremia diagnosis by expand our bacterial database (13 additional bacteria) to detect causes of >99% of neonatal bacterial infections, expand our antibiotic resistance gene database to include five clinically actionable genes, and assessing the performance of the system for bacteremia diagnosis in mock and clinical whole blood samples; Aim 2. Advance the U-dHRM platform for simultaneous detection of fungal and viral pathogens by upgrading our optical system to enable expansion to fungal and viral detection in a high-throughput format, multiplexing the assay to expand to viral and fungal pathogens causing >99% non-bacterial infections, and conducting analytical validation of the multiplexed platform using mock whole blood samples; and Aim 3. Advance the machine learning algorithm for detection of emerging pathogens by developing and integrating an anomaly detection algorithm for reporting emerging pathogens that are not included in our database and validating the algorithm using data generated in Aims 1 and 2. Thus, this proposal directly addresses the funding call by applying a multidisciplinary approach to overcome the biomedical challenge of rapidly diagnosis sepsis, a hidden public health disaster. Project Narrative Digital High Resolution Melting (dHRM) of DNA combined with machine learning creates unique “fingerprints"" for microbes and antibiotic resistance, allowing for faster and more precise detection and treatment of pathogen(s) causing sepsis. This project will advance and test the clinical performance of dHRM technology in the diagnosis of neonatal sepsis. Our goal is to rapidly and accurately identify pathogens and their resistance markers to facilitate accurate antimicrobial therapy, reducing antibiotic overuse in non-infected infants.",Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis,9693150,R01AI134982,"['Address', 'Adult', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Biological Assay', 'Birth Weight', 'Blood', 'Blood Volume', 'Blood specimen', 'Child', 'Clinical', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disasters', 'Dyes', 'Emerging Technologies', 'Exposure to', 'Fingerprint', 'Fluorescence', 'Funding', 'Genes', 'Genome', 'Genotype', 'Goals', 'Gold', 'Hour', 'Immune response', 'Individual', 'Infection', 'Machine Learning', 'Measures', 'Microbe', 'Modernization', 'Neonatal', 'Nucleotides', 'Optics', 'Organism', 'Patients', 'Performance', 'Predisposition', 'Public Health', 'RNA', 'Reaction', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Sampling', 'Sepsis', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tube', 'United States', 'Validation', 'Variant', 'Very Low Birth Weight Infant', 'Viral', 'Whole Blood', 'Woman', 'antimicrobial', 'base', 'circulating DNA', 'clinically actionable', 'clinically relevant', 'cost', 'diagnosis standard', 'digital', 'early onset', 'interdisciplinary approach', 'intrapartum', 'machine learning algorithm', 'melting', 'microbial', 'neonatal sepsis', 'neonate', 'overtreatment', 'pathogen', 'pathogen genome', 'pathogen genomics', 'pathogenic fungus', 'pathogenic virus', 'point of care', 'premature', 'rapid diagnosis', 'resistance gene', 'sample collection', 'septic', 'therapy resistant', 'viral detection']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,423601,-0.023811475882947547
"Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis Project Summary Blood culture sensitivity in neonates is poor but is the “Gold Standard” for the diagnosis of sepsis. Universal genotyping of pathogen genomic sequences using High Resolution Melt (U-HRM) provides a simple, low cost, rapid, and modern alternative to blood culture testing. By measuring the fluorescence of an intercalating dye as PCR-amplified pathogen DNA fragments are heated and disassociate, sequence defined melt curves are generated with single-nucleotide resolution in a closed-tube reaction. We have advanced U- HRM into a digital PCR format (U-dHRM), where DNA sequences that are present in mixtures are individually amplified and identified as is needed for polymicrobial infections. We have also established unique signature melt curves for 37 bacterial species that commonly infect older children and adults and automatically identify them using machine learning technology. With the goal of creating an accurate and valid test for the timely diagnosis of neonatal sepsis, we will advance this technology to identify unique fungal, viral, and bacterial HRM signatures along with antibiotic resistance genes with an accuracy of 99-100% on minimal blood volume (1mL). Our aims are: Aim 1. Optimize and assess the U-dHRM platform for neonatal bacteremia diagnosis by expand our bacterial database (13 additional bacteria) to detect causes of >99% of neonatal bacterial infections, expand our antibiotic resistance gene database to include five clinically actionable genes, and assessing the performance of the system for bacteremia diagnosis in mock and clinical whole blood samples; Aim 2. Advance the U-dHRM platform for simultaneous detection of fungal and viral pathogens by upgrading our optical system to enable expansion to fungal and viral detection in a high-throughput format, multiplexing the assay to expand to viral and fungal pathogens causing >99% non-bacterial infections, and conducting analytical validation of the multiplexed platform using mock whole blood samples; and Aim 3. Advance the machine learning algorithm for detection of emerging pathogens by developing and integrating an anomaly detection algorithm for reporting emerging pathogens that are not included in our database and validating the algorithm using data generated in Aims 1 and 2. Thus, this proposal directly addresses the funding call by applying a multidisciplinary approach to overcome the biomedical challenge of rapidly diagnosis sepsis, a hidden public health disaster. Project Narrative Digital High Resolution Melting (dHRM) of DNA combined with machine learning creates unique “fingerprints"" for microbes and antibiotic resistance, allowing for faster and more precise detection and treatment of pathogen(s) causing sepsis. This project will advance and test the clinical performance of dHRM technology in the diagnosis of neonatal sepsis. Our goal is to rapidly and accurately identify pathogens and their resistance markers to facilitate accurate antimicrobial therapy, reducing antibiotic overuse in non-infected infants.",Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis,9794293,R01AI134982,"['Address', 'Adult', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Biological Assay', 'Birth Weight', 'Blood', 'Blood Volume', 'Blood specimen', 'Child', 'Clinical', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disasters', 'Dyes', 'Emerging Technologies', 'Exposure to', 'Fingerprint', 'Fluorescence', 'Funding', 'Genes', 'Genome', 'Genotype', 'Goals', 'Gold', 'Hour', 'Immune response', 'Individual', 'Infection', 'Machine Learning', 'Measures', 'Microbe', 'Modernization', 'Neonatal', 'Nucleotides', 'Optics', 'Organism', 'Patients', 'Performance', 'Predisposition', 'Public Health', 'RNA', 'Reaction', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Sampling', 'Sepsis', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tube', 'United States', 'Validation', 'Variant', 'Very Low Birth Weight Infant', 'Viral', 'Whole Blood', 'Woman', 'antimicrobial', 'base', 'circulating DNA', 'clinically actionable', 'clinically relevant', 'cost', 'diagnosis standard', 'digital', 'early onset', 'interdisciplinary approach', 'intrapartum', 'machine learning algorithm', 'melting', 'microbial', 'neonatal sepsis', 'neonate', 'overtreatment', 'pathogen', 'pathogen genome', 'pathogen genomics', 'pathogenic fungus', 'pathogenic virus', 'point of care', 'premature', 'rapid diagnosis', 'resistance gene', 'sample collection', 'septic', 'therapy resistant', 'viral detection']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,58207,-0.023811475882947547
"Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques PROJECT SUMMARY Symptomatic urinary stone disease (USD) affects >8% of the United States population, resulting in an estimated annual medical cost exceeding $10 billion. Computed tomography (CT) is the established method for imaging urinary calculi and can provide accurate sub-millimeter details of the size and location of renal stones. However, in vivo characterization of more than just size and location is critical for quantifying stone characteristics important for optimal patient health management and essential for clinical research. A complete characterization of renal stones, including stone composition and fragility, is needed for safe and cost effective management of USD, as well as for phenotyping of research subjects. Our proposal meets these needs by developing methods to accurately and non-invasively characterize stones using low-dose, multi-energy CT. Our long-term goal is to use advanced CT methodologies to characterize urinary calculi for the purpose of directing clinical treatment and facilitating clinical investigation. Our objectives in this application are to develop and validate in vivo quantitative techniques for characterizing mixed and non-uric-acid stone types, as well as for predicting the likelihood of successful stone comminution, a novel concept we refer to as stone fragility. These image-based stone biometrics will enable evidence-based identification of treatment strategies that maximize effectiveness while minimizing risk, as well as accurate and non-invasive classification of research subjects to accelerate scientific advances in the understanding and treatment of USD. We will meet these objectives by accomplishing the following specific aims:  Specific Aim 1: Develop and validate CT techniques to characterize mixed and non-uric-acid  stone types.  Specific Aim 2: Develop and validate CT techniques to predict stone fragility. Current state-of-the-art stone imaging technology cannot accurately identify the composition of mixed and non- uric-acid stone types, nor can it provide quantitative indications of the likelihood of efficient comminution using the lowest risk technique. The innovation of this proposal lies in the use of newly developed statistical, deep learning and texture analysis techniques to quantitatively describe essential characteristics of urinary calculi, namely composition and fragility. The significance of this proposal is that the knowledge derived from using such techniques represents unique quantitative biomarkers that will allow physicians and researchers to more effectively manage and study USD. The developed methods respond to critical needs in the field of stone disease and will advance the ability of physicians to optimally direct patient therapy and scientists to phenotype research subjects. PROJECT NARRATIVE This proposal will develop imaging techniques that can determine urinary stone composition and fragility in patients. The significance of this is that these advanced CT imaging techniques will allow physicians to more efficiently direct patient therapy and perform clinical research, potentially avoiding procedures associated with higher risk or cost.","Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques",9798875,R01EB028591,"['Affect', 'Alkalies', 'Bilateral', 'Biological Markers', 'Biometry', 'Calcium Oxalate', 'Characteristics', 'Classification', 'Clinical Research', 'Clinical Treatment', 'Cost Effective Management', 'Coupled', 'Data', 'Disease', 'Dose', 'Economic Burden', 'Effectiveness', 'Excision', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Minerals', 'Morphology', 'Outcome', 'Patients', 'Percutaneous Nephrolithotomy', 'Phenotype', 'Physicians', 'Population', 'Prevalence', 'Procedures', 'Publishing', 'Recovery', 'Research', 'Research Personnel', 'Research Subjects', 'Resolution', 'Risk', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Shapes', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'United States', 'Ureteroscopy', 'Uric Acid', 'Urinary Calculi', 'Validation', 'X-Ray Computed Tomography', 'attenuation', 'base', 'calcium phosphate', 'clinical investigation', 'cost', 'deep learning', 'evidence base', 'health management', 'high risk', 'imaging modality', 'in vivo', 'innovation', 'learning strategy', 'novel', 'photon-counting detector', 'prevent', 'risk minimization', 'treatment strategy']",NIBIB,MAYO CLINIC ROCHESTER,R01,2019,357486,-0.029406737524538807
"Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1 Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at certain stages of the disease severity spectrum, specifically in the early stage and in advanced disease. These difficulties are due to a variety of causes that change over the course of the disease, including large between-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we build on our long-standing contribution to ocular imaging and propose novel and sensitive means to detect glaucoma and its progression that are optimized to the various stages of disease severity. We will use information gathered from visual fields (functional information) and a leading ocular imaging technology – optical coherence tomography (OCT; structural information) to map the capability of detecting changes across the entire disease severity spectrum to identify optimal parameters for each stage of the disease. Both commonly used parameters provided by the technologies and newly developed parameters with good diagnostic potential will be analyzed. We will use state-of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. We will also utilize a new imaging technology, the visible light OCT, to generate retinal images with outstanding resolution to extract information about the oxygen saturation of the tissue. This will provide in-vivo, real time, and noninvasive insight into tissue functionality. Taken together, this program will advance the use of structural and functional information with a substantial impact on the clinical management of subjects with glaucoma Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies that will substantially improve detection of glaucoma and its progression monitoring in order to prevent blindness.",Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1,9819321,R01EY013178,"['3-Dimensional', 'Blindness', 'Characteristics', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Data', 'Detection', 'Development', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Floor', 'Future', 'Glaucoma', 'Health', 'Human', 'Image', 'Imaging technology', 'Inner Plexiform Layer', 'Knowledge', 'Laboratories', 'Lead', 'Light', 'Machine Learning', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Oxygen Consumption', 'Oxygen saturation measurement', 'Pathology', 'Research Proposals', 'Resolution', 'Retinal', 'Retinal Diseases', 'Scanning', 'Severities', 'Severity of illness', 'Signal Transduction', 'Source', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Technology', 'Thick', 'Time', 'Tissue Extracts', 'Tissues', 'Translating', 'Visible Radiation', 'Vision', 'Visual Fields', 'Width', 'advanced disease', 'analytical method', 'base', 'clinical practice', 'cohort', 'computerized', 'deep learning', 'density', 'ganglion cell', 'improved', 'in vivo', 'innovation', 'innovative technologies', 'insight', 'instrument', 'invention', 'knowledge base', 'learning strategy', 'longitudinal dataset', 'macula', 'mathematical methods', 'new technology', 'novel', 'novel strategies', 'ocular imaging', 'preservation', 'prevent', 'programs', 'research study', 'retinal imaging', 'retinal nerve fiber layer', 'tissue oxygenation', 'tool']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,715489,-0.02374239093224695
"Functional and Structural Optical Coherence Tomography for Glaucoma PROJECT SUMMARY Glaucoma is a leading cause of blindness. Early diagnosis and close monitoring of glaucoma are important because the onset is insidious and the damage is irreversible. Advanced imaging modalities such as optical coherence tomography (OCT) have been used in the past 2 decades to improve the objective evaluation of glaucoma. OCT has higher axial spatial resolution than other posterior eye imaging modalities and can precisely measure neural structures. However, structural imaging alone has limited sensitivity for detecting early glaucoma and only moderate correlation with visual field (VF) loss. Using high-speed OCT systems, we have developed novel OCT angiography technologies to image vascular plexuses that supply the retinal nerve fibers and ganglion cells damaged by glaucoma. Our results showed that OCT angiographic parameters have better correlation with VF parameters. We have also found that measurement of focal and sectoral glaucoma damage using high-definition volumetric OCT angiographic and structural parameters improves diagnostic performance. The goal of the proposed project is to further improve the diagnosis and monitoring of glaucoma using ultrahigh-speed OCT and artificial intelligence machine learning techniques. The specific aims are: 1. Develop quantitative wide-field OCT angiography. We will develop a swept-source OCT prototype that  is 4 times faster than current commercial OCT systems. The higher speed will be used to fully sample the  neural structures and associated capillary plexuses damaged by glaucoma. 2. Simulate VF by combining structural and angiographic OCT. Preliminary results showed that both  structural and angiographic OCT parameters have high correlation with VF on a sector basis. It may be  possible to accurately simulate VF results by combining these parameters using an artificial neural  network. The simulated VF may be more precise and reliable than subjective VF testing. 3. Longitudinal clinical study in glaucoma diagnosis and monitoring. Our novel OCT structural and  angiographic parameters have high accuracy in diagnosing glaucoma. Neural network analysis of structural  and angiographic data from a larger clinical study could further improve diagnostic accuracy. Longitudinal  follow-up will assess if simulated VF could monitor disease progression as well as actual VF. 4. Clinical study to assess the effects of glaucoma treatments. Preliminary results suggest that OCT  angiography could detect the improvement in capillary density after glaucoma surgery and the effects of  drugs. These intriguing effects will be tested in before-and-after comparison studies. If successful, we will have an OCT diagnostic system that in minutes provides objective information on the location and severity of glaucoma damage. This approach could replace time-consuming and unreliable VF testing. Measuring the improvement in retinal circulation could be a quicker way to detect the benefit of glaucoma therapies that work through neuroprotection or regeneration, compared to monitoring VF. PROJECT NARRATIVE Optical coherence tomography is a high-resolution imaging technology that can non-invasively measure both the eye structures and small blood vessels that are damaged by glaucoma, a leading cause of blindness. The proposed research will further improve this technology so that it can provide detailed measurement over wider areas inside the eye, detect earlier stages of glaucoma, evaluate the location and severity of glaucoma damage, monitor disease progression, and provide more timely assessment of the effectiveness of therapy. A goal of this project is to determine if this objective imaging technology can provide information that is equivalent to or better than subjective visual field testing, which though time-consuming and poorly reliable, is the current gold standard for long-term monitoring and management of glaucoma.",Functional and Structural Optical Coherence Tomography for Glaucoma,9697824,R01EY023285,"['Abbreviations', 'Affect', 'Angiography', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Biomedical Engineering', 'Blindness', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Clinical', 'Clinical Research', 'Complex', 'Computer software', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Effectiveness', 'Evaluation', 'Eye', 'Eyedrops', 'Functional disorder', 'Future', 'Geography', 'Glaucoma', 'Glossary', 'Goals', 'Gold', 'Grant', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Lasers', 'Location', 'Longitudinal observational study', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Monitor', 'Natural regeneration', 'Nerve Fibers', 'Noise', 'Operative Surgical Procedures', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Pathway Analysis', 'Patients', 'Performance', 'Perfusion', 'Pharmaceutical Preparations', 'Physiologic Intraocular Pressure', 'Postoperative Period', 'Research', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Role', 'Safety', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Shunt Device', 'Signal Transduction', 'Source', 'Speed', 'Staging', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trabeculectomy', 'Variant', 'Vision', 'Visit', 'Visual Fields', 'Work', 'analytical tool', 'artificial neural network', 'base', 'bulk motion', 'cell injury', 'clinical practice', 'cost', 'density', 'diagnostic accuracy', 'fiber cell', 'field study', 'follow-up', 'ganglion cell', 'glaucoma surgery', 'high resolution imaging', 'high risk', 'imaging modality', 'improved', 'innovation', 'insight', 'macula', 'neural network', 'neuroprotection', 'new technology', 'novel', 'prototype', 'quantitative imaging', 'relating to nervous system', 'screening', 'tool', 'treatment effect', 'vascular factor', 'visual performance']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,564228,-0.013645371831079521
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9765316,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Endothelium', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Tissue Transplantation', 'Topical Corticosteroids', 'Translating', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2019,200104,-0.010091561410279209
"Automatic Rib Fracture Detection in Pediatric Radiography to Identify Non-Accidental Trauma ABSTRACT Automatic Rib Fracture Detection in Pediatric Radiography to Identify Non-Accidental Trauma PI: Adam M. Alessio Non-accidental trauma caused by physical abuse is a leading cause of death in children in the United States. Because rib fractures are highly predictive of child abuse and chest radiographs are commonly performed for multiple indications, pediatric chest radiographs can have a critical role in the identification of abuse. Detection of rib fractures on pediatric radiographs is challenging and a high percentage of fractures are missed, particularly in imaging centers with limited pediatric radiology experience. Currently, there are no viable computer assisted strategies for rib fracture detection on chest radiographs. The purpose of this proposal is to develop machine learning methodology to detect rib fractures on pediatric radiographs using images from a network of hospitals. These methods will rely on a two-stage approach including a thoracic cavity segmentation stage followed by a fracture detection stage. We will explore two fracture detection strategies using novel supervised learning approaches: a heterogeneous U-net and a multi-modal regional-convolutional neural network. These methods will be trained and tested with a large set of fracture-absent radiographs (N=1000) from Seattle Children's Hospital and a diverse set of labelled fracture-present radiographs (N=500) from collaborating sites. These methods will be developed with an intentionally diverse set of radiographs, representative of the variety of fracture presentations and image quality in clinical practice, in order to position this rib fracture detection method for rapid translation to clinical practice. The ultimate goal of this proposal is to provide a computer assisted rib fracture assessment tool that would be a rapid and widely-available add-on to all pediatric chest radiograph exams, improving detection of rib fractures and potentially leading to improved identification of child abuse. NARRATIVE Automatic Rib Fracture Detection in Pediatric Radiography to Identify Non-Accidental Trauma PI: Adam M. Alessio Child abuse is a leading cause of death in children and rates of abuse are increasing. Detection of rib fractures on commonly performed chest radiographs has the potential to identify unsuspected child abuse, but it is very challenging to see fractures on these exams. This work proposes a computer assisted strategy to help radiologists detect rib fractures on pediatric chest radiographs, which may lead to improved identification of child abuse.",Automatic Rib Fracture Detection in Pediatric Radiography to Identify Non-Accidental Trauma,9658063,R21HD097609,"['Assessment tool', 'Cause of Death', 'Cessation of life', 'Chest', 'Child', 'Child Abuse', 'Childhood', 'Clinical', 'Computer Assisted', 'Data', 'Detection', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Face', 'Fracture', 'Goals', 'Hospitals', 'Image', 'Image Analysis', 'Infant', 'Injury', 'Institutional Review Boards', 'Label', 'Lead', 'Lung', 'Machine Learning', 'Mediastinal', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Non-accidental', 'Outcome', 'Patient imaging', 'Pediatric Hospitals', 'Pediatric Radiology', 'Performance', 'Population', 'Positioning Attribute', 'Respiratory Diaphragm', 'Rib Fractures', 'Role', 'Sentinel', 'Site', 'Structure', 'Supervision', 'Testing', 'Thoracic cavity structure', 'Time', 'Training', 'Translations', 'Trauma', 'United States', 'Vendor', 'Work', 'bone', 'child physical abuse', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'detector', 'experience', 'follow-up', 'hands-on learning', 'imaging platform', 'imaging study', 'improved', 'learning strategy', 'mortality', 'multimodality', 'novel', 'patient population', 'physical abuse', 'radiologist', 'rapid technique', 'rib bone structure', 'soft tissue', 'supervised learning', 'tool']",NICHD,MICHIGAN STATE UNIVERSITY,R21,2019,223004,-0.03998557434485583
"Automated end-to-end retinal screening system with robotic image capture and deep learning analysis Abstract  In this SBIR project, we propose EyeScreenBot, an end-to-end automated retinal im- age capture and analysis system, comprising a self-driven, robotic fundus camera plat- form for automated image capture and a deep learning-based image analysis engine for generation of automated screening outcome. With the large, growing, and aging popula- tion and the increased prevalence of diabetes, a large number of people are at risk for vision loss due to several eye diseases including diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma. Although eye screening is effective in re- ducing vision loss, there are not enough clinical personnel and eye-care experts for pop- ulation-wide eye screening. Recent advances with automated image analysis are helping alleviate the situation, but they are still limited by the need for good quality images of the patients captured by trained technicians or expensive retinal cameras equipped for auto- mated capture. EyeScreenBot will be developed to provide a truly end-to-end screening solution that is cost-effective and suitable for deployment in primary care clinics or op- tometrist sites, addressing both automated capture and subsequent automated analysis, all without the need for trained technicians or eye experts at the point of care. When deployed and commercialized, this device will rapidly aid scaling of eye screening for the masses, thereby having an enormous impact in improving the quality and accessibility of eye care and helping reduce preventable vision loss. Narrative EyeScreenBot, an end-to-end automated screening system with intelligent image capture and analysis, will truly enable eye screening at massive scale, which is necessary and urgent since the population at risk for preventable vision loss due to retinal diseases (such as diabetic retinopathy) is growing at a staggering rate. Triaging and identification of at-risk patients will allow for timely intervention to prevent, slow, or even reverse the disease progression and loss of vision.",Automated end-to-end retinal screening system with robotic image capture and deep learning analysis,9847891,R43EY029652,"['Address', 'Age', 'Age related macular degeneration', 'Algorithms', 'Area', 'Blindness', 'California', 'Caring', 'Clinic', 'Clinical', 'Color', 'Computational algorithm', 'Computer Vision Systems', 'County', 'Coupled', 'Development', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease Progression', 'Evaluation', 'Eye', 'Eye diseases', 'Fundus', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Hand', 'Health', 'Health Services', 'Human', 'Human Resources', 'Image', 'Image Analysis', 'Institutes', 'Intelligence', 'Intervention', 'Intuition', 'Los Angeles', 'Manuals', 'Mass Screening', 'Measures', 'Medical', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Pilot Projects', 'Population', 'Populations at Risk', 'Prevalence', 'Primary Health Care', 'Process', 'Pupil', 'Retinal', 'Retinal Diseases', 'Risk', 'Robot', 'Robotics', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Software Engineering', 'Surveys', 'System', 'Systems Analysis', 'Testing', 'Time', 'Training', 'Triage', 'Universities', 'Validation', 'Visual impairment', 'Work', 'aging population', 'automated analysis', 'automated image analysis', 'base', 'cost effective', 'deep learning', 'deep learning algorithm', 'design', 'diabetic', 'digital imaging', 'experience', 'fundus imaging', 'improved', 'interest', 'macula', 'point of care', 'portability', 'prevent', 'professor', 'programs', 'retinal imaging', 'robot interface', 'robotic system', 'screening', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2019,218618,-0.004263609589963619
"Development of label-free computational flow cytometry for high-throughput micro-organism classification The purpose of flow cytometers is to enable the classification of cells or organisms at high throughput. Label-free optical flow cytometers not based on fluorescence are generally based on scattering. The most common of these compares the amount of forward (FS) versus side (SS) scattering. Such two-parameter information permits rudimentary classification based on size or granularity, but it misses more subtle features that can be critical in defining organism identity. Nevertheless, FS/SS flow cytometry remains popular, largely because of its simplicity and capacity for high throughput.  We propose to develop a label-free computational flow cytometer that preserves much of the simplicity and high-throughput capacity of FS/SS flow cytometry, but provides significantly enhanced information. Instead of characterizing organisms based on scattering direction (as does FS/SS flow cytometry), we will characterize based on scattering patterns. We will insert a reconfigurable diffractive element in the imaging optics of a flow cytometer to route user-defined basis patterns to independent detectors. The basis patterns will be optimally matched to specific sample features. The respective weights of these basis patterns will serve as signatures to identify organisms of interest. The basis patterns themselves will be determined by machine learning algorithms. Both the device and the learning algorithms will be developed from scratch.  We anticipate that our flow cytometer will be able to operate at flow rates on the order of meters per second, commensurate with state-of-the-art FS/SS flow cytometers, while providing significantly more information for improved classification capacity. While our technique should be advantageous for any label-free flow cytometry application requiring high throughput, we will test it here by demonstrating high-throughput classification of microbial communities. NARRATIVE Our goal is to improve the information extraction capacity of label-free flow cytometers, while maintaining high throughput capacity. As such, our device should have a broad range of applications.",Development of label-free computational flow cytometry for high-throughput micro-organism classification,9702053,R21GM128020,"['Address', 'Awareness', 'Bioinformatics', 'Biological', 'Biology', 'Categories', 'Cells', 'Classification', 'Communities', 'Custom', 'Detection', 'Development', 'Devices', 'Elements', 'Flow Cytometry', 'Fluorescence', 'Goals', 'Image', 'Image Compression', 'Label', 'Light', 'Machine Learning', 'Measurement', 'Microbe', 'Modernization', 'Optics', 'Organism', 'Pattern', 'Performance', 'Pupil', 'Resolution', 'Route', 'Sampling', 'Side', 'Signal Transduction', 'Specificity', 'Speed', 'Techniques', 'Testing', 'Traction', 'Validation', 'Weight', 'base', 'cellular imaging', 'cost', 'cost effective', 'design', 'detector', 'improved', 'interest', 'learning algorithm', 'machine learning algorithm', 'meter', 'microbial community', 'microorganism', 'microorganism classification', 'optical imaging', 'preservation', 'prototype', 'recruit']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2019,206250,-0.01575320245299879
"Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment Project Summary More than 20,000 hematopoietic stem cell transplants (including bone marrow transplants) are performed in the U.S. each year to cure a range of diseases ranging from leukemias to sickle cell anemia to autoimmune deficiencies in children. Unfortunately, most long-term non-relapse survivors will die of chronic graft-versus-host disease (cGVHD), which remains a disease of steadily increasing incidence and profound unmet need. A fundamental barrier in cGVHD management and research is a lack of sensitive and objective assessment tools that permit objective and reproducible measures of disease severity and progression. Skin is the most commonly affected organ in cGVHD and automated techniques capable of measuring precisely the surface area of involved skin in photographs may provide the tools necessary for effectively evaluating patient progress. We propose to (1) create the data set necessary to develop machine learning-based methods for the automatic analysis of cGVHD images, and (2) implement and evaluate these methods. Project Narrative  Chronic graft-versus-host disease (cGVHD) is a lethal disease that affects most long-term hematopoietic stem cell transplant (including bone marrow transplants) recipients. Skin images are used to assess disease severity and progression but the technology required to quantitatively and reproducibly analyze these images is lacking. This project aims at developing and evaluating this technology.",Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment,9648538,R21AR074589,"['3-Dimensional', 'Achievement', 'Affect', 'Agreement', 'Allogenic', 'Area', 'Assessment tool', 'Autoimmune Process', 'Body Surface', 'Bone Marrow Transplantation', 'Characteristics', 'Child', 'Circumscribed Lesion', 'Clinic', 'Clinical', 'Clinical Research', 'Cutaneous', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dermatologic', 'Dermatologist', 'Disease', 'Disease Management', 'Disease Progression', 'Documentation', 'Erythema', 'Exanthema', 'Future', 'Goals', 'Hematologic Neoplasms', 'Hematopoietic Stem Cell Transplantation', 'Hematopoietic System', 'Human', 'Image', 'Incidence', 'Industry', 'Institution', 'Label', 'Lead', 'Lesion', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methods', 'Morbidity - disease rate', 'Organ', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Population', 'Protocols documentation', 'Psoriasis', 'Reaction', 'Reproducibility', 'Research', 'Resources', 'Role', 'Scanning', 'Severities', 'Severity of illness', 'Sickle Cell Anemia', 'Site', 'Skin', 'Skin Cancer', 'Standardization', 'Surface', 'Survivors', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-dimensional analysis', 'Time', 'Transplant Recipients', 'Visit', 'Vitiligo', 'automated analysis', 'base', 'cancer imaging', 'chronic graft versus host disease', 'data warehouse', 'deep learning', 'deep neural network', 'digital', 'graft vs host disease', 'high risk', 'image processing', 'improved', 'interdisciplinary approach', 'learning strategy', 'leukemia', 'machine vision', 'mortality', 'network architecture', 'neural network architecture', 'novel therapeutics', 'patient subsets', 'prototype', 'repository', 'response', 'skin disorder', 'skin lesion', 'stereoscopic', 'success', 'tool']",NIAMS,VANDERBILT UNIVERSITY,R21,2019,179706,-0.02353828051142492
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user's location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user's location by recognizing standard informational signs present in the environment, tracking the user's trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9934891,R01EY029033,"['Adoption', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Environment', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Medical center', 'Process', 'Research', 'Schools', 'System', 'Tactile', 'Time', 'Travel', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'interest', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,105337,-0.03416532809363495
"NIDDK Extramural Digital Pathology Repository System In recent years, new technology and data processing capabilities have removed barriers to integration of molecular and histopathological data sets. Several clinical research networks across the National Institute of Diabetes, Digestive and Kidney Diseases extramural programs have put Digital Pathology Repositories (DPRs) into place with digital whole slide images (WSI) available to support standardization of classical diagnostic criteria across clinical sites. A developing line of investigation is the “mining” of these digital sets to identify features which correlate with disease. Computer assisted-image analysis for feature detection and feature recognition are key components of such investigation. The Centralized NIDDK Digital Pathology Repository will serve as an online repository to facilitate standardized archiving of WSI with the goal of providing controlled access for standardization, discovery and validation research efforts. n/a",NIDDK Extramural Digital Pathology Repository System,10032690,5N94019F00322,"['Archives', 'Artificial Intelligence', 'Clinical', 'Clinical Research', 'Computer-Assisted Image Analysis', 'Data Set', 'Diabetes Mellitus', 'Diagnostic', 'Digestive System Disorders', 'Disease', 'Extramural Activities', 'Future', 'Goals', 'Institutes', 'Investigation', 'Kidney Diseases', 'Machine Learning', 'Metadata', 'Mining', 'Molecular', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Research', 'Standardization', 'System', 'Validation', 'clinical research site', 'computerized data processing', 'digital', 'digital pathology', 'feature detection', 'new technology', 'online repository', 'programs', 'repository', 'whole slide imaging']",NICHD, ,N02,2019,95738,-0.00635920873026669
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9797689,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2019,748584,-0.0033822594314057448
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9663319,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,416374,-0.03416532809363495
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9618878,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Decubitus ulcer', 'Diabetic Foot Ulcer', 'Diabetic wound', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2019,401916,-0.020245141230480924
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,9666293,K99EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'learning strategy', 'mathematical model', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,K99,2019,146837,-0.017544901840021887
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9752019,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2019,991516,-0.012419495831713952
"Detecting Middle Ear Fluid Using Smartphones PROJECT SUMMARY Otitis media is one of the most common childhood diseases in developing countries; many of its complications are preventable if middle ear fluid is detected early. We propose an accessible and accurate smartphone-based screening tool that (i) sends a soft acoustic chirp into the ear canal using the smartphone speaker, (ii) detects reflected sound from the eardrum using the smartphone microphone, and (iii) employs a machine learning model to classify these reflections and predict middle ear fluid status in realtime. Given the ubiquity of smartphones and the inaccuracy of visual otoscopy, the system we propose has the potential to be the default screening tool used in developing countries by healthcare providers and caregivers at home. PROJECT NARRATIVE Otitis media is one of the most common childhood diseases in developing countries affecting over 1.23 billion people in 2013 and can lead to complications such as hearing loss, developmental delay, meningitis, mastoiditis, and death. Many of these complications are preventable if middle ear fluid is detected early. However, the absence of an accurate and accessible method to detect middle ear fluid has led to high misdiagnosis rates. The consequence is associated hearing and speech impairment rates greater than any other pediatric condition and growing microbial resistance as a result of antibiotic over-prescription. Currently, the technique of choice for detecting middle ear fluid by primary care providers is visual otoscopy, which has a diagnostic accuracy as low as 51%. Although more accurate methods like tympanometry and pneumatic otoscopy exist, they require significant expertise and referral to a specialist. Commercial acoustic reflectometers and smartphone-mounted otoscopes require specialized hardware. Thus, there is an urgent, unmet need for an accurate, rapid and easily accessible method for resource-limited healthcare providers and caregivers to detect middle ear fluid. This project aims to demonstrate the feasibility of using the speakers and microphones on existing smartphones to detect middle ear fluid by assessing eardrum mobility. Our proposed system would operate by (i) sending a soft acoustic chirp into the ear canal using the smartphone speaker, (ii) detecting reflected sound from the eardrum using the smartphone microphone, and (iii) employing a machine learning model to classify these reflections and predict middle ear fluid status. No additional attachments would be required beyond a paper funnel, which acts as a speculum to reduce waveform variability and can be constructed with printer paper, scissors, and tape. This technique is the first software-based screening tool for middle ear fluid detection that uses off-the-shelf smartphones which does not require hardware attachments or visual interpretation. Using data from our existing preliminary clinical study we aim to develop signal processing and machine learning algorithms to optimize sensitivity and specificity. We plan to develop a bench testing technique that enables previously unsupported smartphones to to run our test and prospectively validate our optimized algorithm clinically in parallel testing with an acoustic reflectometer. Further we aim to develop a user interface and improved funnel design. These new designs will undergo usability testing in physician and parent populations. Given the ubiquity of smartphones, our app has the potential to be the default screening tool used in developing countries by healthcare providers and caregivers at home.",Detecting Middle Ear Fluid Using Smartphones,9906782,R43DC018434,"['Acoustics', 'Affect', 'Agreement', 'Algorithms', 'Antibiotics', 'Caregivers', 'Cellular Phone', 'Cessation of life', 'Childhood', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Computer software', 'Data', 'Detection', 'Developing Countries', 'Development', 'Developmental Delay Disorders', 'Diagnosis', 'Disease', 'Ear', 'Earwax', 'Environment', 'External auditory canal', 'FDA approved', 'Feedback', 'Future', 'Galaxy', 'Health', 'Health Personnel', 'Hearing', 'Home environment', 'Impairment', 'Industry Standard', 'Lead', 'Liquid substance', 'Machine Learning', 'Mastoiditis', 'Measures', 'Meningitis', 'Methods', 'Modeling', 'Obstruction', 'Otitis Media', 'Otoscopes', 'Otoscopy', 'Outcome', 'Output', 'Paper', 'Parents', 'Patients', 'Performance', 'Peripheral', 'Phase', 'Physicians', 'Population', 'Preparation', 'Publishing', 'Research Personnel', 'Resistance', 'Resources', 'Running', 'Screening procedure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Specialist', 'Specificity', 'Speculums', 'Speech', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Tympanic membrane', 'Tympanometry', 'Visual', 'base', 'care providers', 'clinical care', 'clinical practice', 'design', 'diagnostic accuracy', 'experience', 'hearing impairment', 'improved', 'machine learning algorithm', 'meetings', 'microbial', 'microphone', 'middle ear', 'prospective', 'screening', 'signal processing', 'sound', 'telehealth', 'tool', 'urgent care', 'usability']",NIDCD,"WAVELY DIAGNOSTICS, INC.",R43,2019,157842,-0.01810659284213792
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",9640524,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Injury', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Receiver Operating Characteristics', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'disorder subtype', 'elastography', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,462750,-0.010381690364051658
"QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring Modern health monitoring devices at hospitals and wearable sensors in households generate a large amount of time series data at high rate, capturing the physiological status of patients in a real-lime fashion. The premise is that these technology advances enable a data-driven healthcare system that starts making fast, accurate, objective and inexpensive decisions based upon data, in addition to an individual physician's experience and preference. However, there is a significant gap in the mathematical theory and computational tools to promptly extract actionable information from multi-modal non-stationary time series data in a robust and tractable manner, which has become a serious roadblock to further utilize bigger data for better healthcare monitoring. The goal of this research program is to develop a mathematical framework for extracting time-frequency and geometric representations of multi-modal physiological data, in an online and robust manner, and use them to design machine learning algorithms to improve real-lime health monitoring. Specifically, we hypothesize that the development of time-series and geometric methods for large streaming multi-modal monitoring data will lead to more accurate diagnosis on various physiological monitoring applications, including detection and prediction of rare events such as seizure and arrhythmia, classification of sleep stages for newborns and children, and real-time artifact removal of physiological data. To achieve our goal, we plan to develop novel theoretical and computational tools for analyzing non-stationary multi-modal time series data with noise, corruption and missing data as well as real-time algorithms for filtering and event detection from such data. The tools and algorithms will be applied on clinical tasks at the Nationwide Children's Hospital. In addition, the real-time workflow will be implemented on Hadoop clusters with a mission of public sharing of both data and software. The development from the interdisciplinary team composed of mathematicians, biomedical informaticians as well as the hospital will not only transform the frontiers of mathematics knowledge, but also significantly impact clinical applications, data science education, and the development of the $11 O billion emerging market of wireless health. The goal of this project is to develop a series of novel computational theory and software to extract physiological information from the large multi-modal data streams generated by modern health monitoring devices. The tools will be applied to various clinical tasks such as detection and prediction of seizure and arrhythmia and classification of sleep stages for newborns and children, aiming for more accurate diagnosis.",QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring,9771321,R01EB025018,"['Address', 'Algorithms', 'Arrhythmia', 'Behavior', 'Big Data', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Science', 'Detection', 'Development', 'Diagnostic', 'Education', 'Environment', 'Event', 'Excision', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Household', 'Human body', 'Individual', 'Infant', 'Knowledge', 'Limes', 'Machine Learning', 'Mathematics', 'Measures', 'Methods', 'Mission', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Nature', 'Newborn Infant', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Pediatric Hospitals', 'Physicians', 'Physiologic Monitoring', 'Physiological', 'Property', 'Public Domains', 'Research', 'Resources', 'Seizures', 'Series', 'Sleep Stages', 'Stream', 'Techniques', 'Technology', 'Time', 'Universities', 'Validation', 'Wireless Technology', 'accurate diagnosis', 'base', 'biological systems', 'clinical application', 'clinical practice', 'computerized tools', 'design', 'diagnostic biomarker', 'education resources', 'experience', 'frontier', 'geometric methodologies', 'graduate student', 'heart rate variability', 'improved', 'insight', 'machine learning algorithm', 'mathematical theory', 'monitoring device', 'multimodal data', 'multimodality', 'novel', 'preference', 'programs', 'science education', 'signal processing', 'student training', 'theories', 'tool', 'wearable device']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2019,255543,-0.037946859914466856
"Innovations in cervical cancer diagnosis for low resource settings using advanced optical imaging and machine learning diagnostic algorithms. The broad goal of this project is to adapt a portable, low-cost, easy-to-use Pocket-sized Colposcope (developed under other funding) for use in a community setting, and develop automated algorithms that combine neovascularization, glycogen depletion and acetowhitening to provide comparable diagnosis to an expert. This work will be done in a collaboration between 3rd Stone Design, Inc, Duke University and Kenya Medical Research Institute. The specific aims of this proposal are:  Aim 1 (Phase I): Improve Pocket colposcope by designing continuous magnification mechanism and improving device workflow integration to eliminate between-use disinfection through the use of a disposable optically clear sterile sleeve. Provider feedback on our previously developed Pocket colposcope has unanimously suggested the addition of a slider mechanism to control coarse zoom and a sleeve consumable to the Pocket colposcope design.  Aim 2 (Phase I): Automated algorithms and software for cervical pre-cancer detection We will improve the specificity of VIA using a novel software application with embedded machine learning diagnostic algorithms for automated cervical cancer screening. We will apply and validate the individual algorithms for VIA and GIVI (green illumination vascular imaging) to existing images obtained from a 200-patient clinical study with the Pocket colposcope. We will then compare the performance of the algorithms to expert physician interpretation of the same images, with pathology serving as the gold standard.  Aim 3 (Phase II): Document user experience with Pocket colposcope in Kenya. We will develop a culturally relevant training package directly in the community healthcare setting. We will collect quantitative and qualitative data including surveys, in-depth interviews, and clinic observations from both naive providers and patients and use these findings to and use these findings to improve the introduction of the Pocket colposcope in Kenya and simultaneously, inform the clinical investigations in Aim 4.  Aim 4 (Phase II): Compare the performance of the Pocket colposcope to Visual Inspection with Acetic Acid for triage of HPV+ women in Kenya. We will carry out a cluster-randomized trial among 400 HPV+ women to compare the standard triage with that using the Pocket colposcope in Kisumu, Kenya. All HPV+ women will undergo biopsy to determine sensitivity, specificity and positive and negative predictive values of the different triage strategies. Data will be used to model the performance of the algorithm against that of expert colposcopists.  Aim 5 (Phase II): Assess the costs, incremental cost-effectiveness and population health impact of HPV-based cervical cancer screening programs with proposed triage strategies. We will determine the incremental cost-effectiveness ratio and the absolute and relative costs for four triage strategies by measuring the costs and model population health outcomes (cancer cases, deaths and disability adjusted life years). NARRATIVE The SBIR activities proposed by 3rd Stone Design and Duke University will advance the state of the art in cervical cancer imaging through the R&D of novel optics for a portable colposcope combined with automated algorithms for diagnosis. The project will confirm the benefits of these innovations through a clinical trial in Kenya conducted by the Kenya Medical Research Institutes. The innovations developed have tremendous potential to effect public health by increasing diagnostic acuity and decreasing costs of healthcare delivery which ultimately will reduce the impact of the deadly disease.",Innovations in cervical cancer diagnosis for low resource settings using advanced optical imaging and machine learning diagnostic algorithms.,9778122,R44CA240019,"['Acetic Acids', 'Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Ambulatory Care', 'American Society of Clinical Oncology', 'Back', 'Biopsy', 'Blood Vessels', 'Cancer Burden', 'Cervical', 'Cervical Cancer Screening', 'Cessation of life', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Cluster randomized trial', 'Collaborations', 'Colposcopes', 'Colposcopy', 'Community Health', 'Community Healthcare', 'Computer software', 'Cost Analysis', 'Cost Measures', 'Country', 'Coupled', 'Cytology', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Disinfection', 'Feedback', 'Fogs', 'Foundations', 'Funding', 'Glycogen', 'Goals', 'Gold', 'Guidelines', 'Health Care Costs', 'Healthcare', 'Human Papillomavirus', 'Image', 'Incidence', 'Individual', 'Infrastructure', 'International', 'Interview', 'Kenya', 'Lesion', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Medical Research', 'Modeling', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Phase', 'Physicians', 'Predictive Value', 'Prevention', 'Primary Health Care', 'Protocols documentation', 'Provider', 'Public Health', 'Research Institute', 'Resources', 'Rural', 'Sensitivity and Specificity', 'Site', 'Sledding', 'Small Business Innovation Research Grant', 'Specificity', 'Sterility', 'Surveys', 'Technology', 'Testing', 'Training', 'Triage', 'Universities', 'Vagina', 'Visual', 'Woman', 'Work', 'World Health Organization', 'base', 'burden of illness', 'cancer diagnosis', 'cancer imaging', 'clinical investigation', 'cohort', 'community setting', 'cost', 'cost effectiveness', 'cost-effectiveness ratio', 'design', 'disability-adjusted life years', 'experience', 'health care delivery', 'health care settings', 'improved', 'incremental cost-effectiveness', 'innovation', 'low and middle-income countries', 'mortality', 'neovascularization', 'novel', 'optical imaging', 'overtreatment', 'point of care', 'population health', 'portability', 'primary care setting', 'relative cost', 'research and development', 'screening', 'screening program']",NCI,CALLA HEALTH FOUNDATION,R44,2019,299992,-0.038714903526109436
"Improving Critical Congenital Heart Disease Screening and Detection of ""Secondary"" Targets PROJECT SUMMARY/ABSTRACT  We propose to develop an automated critical congenital heart disease (CCHD) screening algorithm using machine learning techniques to combine non-invasive measurements of perfusion and oxygenation. Oxygen saturation (SpO2)-based screening is the current standard for CCHD screening, however it fails to detect up to 50% of asymptomatic newborns with CCHD or nearly 900 newborns in the United States annually. The majority of newborns missed by SpO2 screening have defects with aortic obstruction, such as coarctation of the aorta (CoA), that do not result in deoxygenated blood entering circulation. Non-invasive measurements of perfusion such as perfusion index (PIx) and pulse oximetry waveform analysis is expected to improve the detection of newborns with defects such as CoA, which is currently the most commonly missed CCHD by SpO2 screening. Both PIx and pulse oximetry waveforms can be measured non-invasively and with the same equipment used for SpO2 screening.  Members of our team recently showed that the addition of PIx, a non-invasive measurement of pulsatile blood flow, has the potential to improve CCHD detection otherwise missed by SpO2 screening. However, variability of PIx over brief time periods (seconds) and human error in its interpretation limit its clinical capabilities. Additionally, human error in interpretation of the current SpO2 screening algorithm leads to missed diagnoses and inappropriate testing in healthy newborns. Therefore, an automated SpO2-PIx screening algorithm is needed to both simplify the screening process, and improve detection of defects that are missed with SpO2 screening. In order to achieve that, we will identify the optimal PIx waveforms to create a metric that discriminates between newborns with and without CCHD. We will perform pulse oximetry waveform analysis to identify other non-invasive components with discriminatory capacity for newborns with CCHD. Additionally, we will apply supervised machine learning techniques to automate the algorithm interpretation.  The proposed research is significant because an automated SpO2-PIx screening algorithm could save the lives of hundreds of newborns with CCHD that are not diagnosed by SpO2 screening. Additionally, this is innovative as it will be the first automatic interpretation of PIx measurement among newborns with CCHD and merging of automated PIx and SpO2, which will allow for easy implementation at later steps. Through collaboration with four pediatric cardiac centers, we will establish the infrastructure and necessary multidisciplinary relationships to conduct future multicenter studies to evaluate this novel combined SpO2-PIx algorithm on a large scale involving thousands of newborns. Improving the detection of CCHD will require a multidisciplinary approach among all the individuals involved in the care and screening of newborns with CCHD. Additionally, collaboration with engineering and computer sciences will be necessary to automate the SpO2-PIx CCHD screening algorithm. PROJECT NARRATIVE A screening approach that improves earlier detection of critical congenital heart defects with systemic obstruction is critically necessary. This application seeks to develop a screening algorithm that will combine the current screening standard, oxygen saturation, with non-invasive measurements of perfusion. This high risk, high reward approach is fundamentally different from other approaches as it will use machine learning techniques, and is expected to improve the detection of critical congenital heart defects with systemic obstruction and automate the interpretation of the screening results.","Improving Critical Congenital Heart Disease Screening and Detection of ""Secondary"" Targets",9805011,R21HD099239,"['Affect', 'Algorithms', 'American Heart Association', 'Aortic coarctation', 'Automatic Data Processing', 'Blood', 'Blood Circulation', 'Blood Pressure', 'Blood flow', 'California', 'Cardiac', 'Caring', 'Cessation of life', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Congenital Abnormality', 'Critical Congenital Heart Defects', 'Critical Illness', 'Data', 'Defect', 'Detection', 'Diagnosis', 'Early Diagnosis', 'Engineering', 'Equipment', 'Evaluation', 'Funding', 'Future', 'Goals', 'Individual', 'Infant', 'Infrastructure', 'Interruption', 'Intervention', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Morbidity - disease rate', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'National Institute of Child Health and Human Development', 'Neonatal Screening', 'New York', 'Newborn Infant', 'Obstruction', 'Oxygen', 'Perfusion', 'Physiologic pulse', 'Population', 'Process', 'Pulsatile Flow', 'Pulse Oximetry', 'Research', 'Savings', 'Screening Result', 'Screening procedure', 'Sensitivity and Specificity', 'Specificity', 'Techniques', 'Testing', 'Time', 'Ultrasonography', 'United States', 'Upper Extremity', 'Validation', 'aortic arch', 'base', 'clinical application', 'cohort', 'computer science', 'congenital heart disorder', 'high reward', 'high risk', 'human error', 'improved', 'indexing', 'infant death', 'innovation', 'interdisciplinary approach', 'member', 'mortality', 'multidisciplinary', 'neonatal period', 'novel', 'prenatal', 'prevent', 'screening', 'supervised learning']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2019,240804,-0.02269795818514229
"Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time Project Summary Lower limb assistive robotic devices, such as active prosthesis, orthoses, and exoskeletons have the potential to restore function for the millions of Americans who experience mobility challenges due to injury and disability. Since individuals with mobility challenges have an increased energetic cost of transport, the benefit of such assistive devices is commonly assessed via the reduction in the metabolic work rate of the individual who is using the device. Currently, metabolic work rate can only be obtained in a laboratory environment, using breath-by-breath measurements of respiratory gas analysis. To obtain a single steady state data point of metabolic work rate, multiple minutes of data must be collected, since the signals are noisy, sparsely sampled, and dynamically delayed. In addition, the user has to wear a mask and bulky equipment, further restricting the applicability of the method on a larger scale. We propose an improved way to obtain such estimates of metabolic work rate in real-time. Aim 1 will determine salient signal features and characterize the dynamics of sensing metabolic work rate from a variety of physiological sensor signals. Aim 2 will use advanced sensor fusion and machine learning techniques to accurately predict instantaneous energy cost in real-time from multiple physiological signals without relying on a metabolic mask. Aim 3 will use the obtained real-time estimates to optimize push-off timing for an active robotic prosthesis. The resulting methods will enable an automated and continuous evaluation of assistive robotic devices that can be realized outside the laboratory and with simple wearable sensors. This automated evaluation will enable devices, such as active prostheses, orthoses, or exoskeletons, that can self-monitor their performance, optimize their own behavior, and continuously adapt to changing circumstances. This will open up a radically new way of human-robot- interaction for assistive devices. It will greatly increase their clinical viability and enable novel advanced controllers and algorithms that can improve device performance on a subject specific basis. Project Narrative A common way of evaluating assistive robotic devices, such as active prostheses or exoskeletons, is by measuring the reduction in effort that they bring to an individual walking in them. The proposed project will develop ways to perform this evaluation automatically and in real-time by the device itself, which will be used in the future to develop prostheses and exoskeletons that automatically adapt themselves to their users. This project supports the NIH's stated mission of reducing disability by improving patient outcomes with new prosthetic and orthotic devices.",Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time,9668174,R03HD092639,"['Algorithms', 'American', 'Amputation', 'Amputees', 'Ankle', 'Behavior', 'Clinical', 'Data', 'Devices', 'Electromyography', 'Energy Metabolism', 'Environment', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Heart Rate', 'Indirect Calorimetry', 'Individual', 'Injury', 'Laboratories', 'Linear Regressions', 'Lower Extremity', 'Machine Learning', 'Masks', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Noise', 'Orthotic Devices', 'Patient-Focused Outcomes', 'Performance', 'Persons', 'Physiological', 'Population', 'Prosthesis', 'Reference Values', 'Robotics', 'Sampling', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'cost', 'disability', 'exoskeleton', 'experience', 'functional restoration', 'human-robot interaction', 'improved', 'light weight', 'neural network', 'novel', 'respiratory gas', 'robotic device', 'sensor', 'wearable device']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2019,78000,0.0019846899537696995
"Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology ABSTRACT Acute infections of the middle ear (acute otitis media - AOM), are the most commonly treated childhood disease. Treatment is fueled by concern for complications and effects on children's cognitive and language development. The financial burden of AOM is estimated at more than $5 billion per year. Because AOM is so common, a major societal problem is the over-diagnosis and over-treatment of this disease, as a result of two factors: First, accurately diagnosing AOM is difficult, even for experienced primary care or ear, nose, and throat (ENT) physicians. Second, with a growing shortage of primary care physicians in the US, more Nurse Practitioners and Physician Assistants serve as first-line clinicians in primary care settings, but lack extensive training in otoscopy (i.e. clinical examination of the eardrum). Consequently, practitioners often err on the side of making a diagnosis of AOM and prescribing oral antibiotics. Over 8 million unnecessary antibiotics are prescribed annually, contributing to the rise of antibiotic-resistant bacteria, and creating the largest number of pediatric medication-related adverse events. Many children with inaccurate diagnoses of AOM are referred to ENTs for surgical placement of ear tubes, and up to 70% of these cases are not indicated. Diagnosing AOM still depends on clinician subjectivity, based on a brief glimpse of the eardrum. This diagnostic subjectivity creates a critical barrier to progress in society's goal of decreasing healthcare costs and reducing over-diagnosis and over-treatment of AOM. According to the American Academy of Pediatrics in 2013, devices are needed to assist in more accurate, consistent, and objective diagnosis of AOM. A simple and objective method of analyzing an image of a patient's ear to diagnose or rule out AOM would drastically reduce over-treatment. This project will fill that gap, by developing computer-assisted image analysis (CAIA) software that provides objective information to a clinician by analyzing eardrum images collected using currently available hardware. Based on previous work in applying similar methods to improve clinician performance in radiology and surgical pathology, our overarching hypothesis is that the incremental implementation of enhanced images, automated identification of abnormalities, and retrieval of similar cases will result in improved clinician diagnostic accuracy. In our preliminary work, we developed software, called Auto-Scope, which labels eardrums as “normal” versus “abnormal.” In this study, we propose two Specific Aims to improve diagnostic performance: Specific Aim #1: Create an enhanced composite image of the eardrum. Specific Aim #2: Use machine learning approaches for clinical decision support. The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality and reducing inter-observer variability, which will ultimately enable more accurate diagnosis and personalized therapeutic approaches for ear abnormalities. Thus, the proposed research is relevant to NIH's mission pertaining to the application of novel strategies that may improve human health, and NIDCD's mission of improving diagnosis and treatment of ear diseases, particularly otitis media.",Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology,9790958,R21DC016972,"['Academy', 'Acute', 'Address', 'Adverse event', 'Affect', 'Algorithms', 'American', 'Antibiotics', 'Appearance', 'Awareness', 'Bacterial Antibiotic Resistance', 'Child', 'Childhood', 'Cholesteatoma', 'Clinic', 'Clinical', 'Clip', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cyst', 'Databases', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Ear Diseases', 'Financial Hardship', 'Goals', 'Guidelines', 'Hair', 'Hand', 'Health', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Interobserver Variability', 'Label', 'Language Delays', 'Language Development', 'Lighting', 'Liquid substance', 'Machine Learning', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nose', 'Nurse Practitioners', 'Operative Surgical Procedures', 'Oral', 'Otitis Media', 'Otitis Media with Effusion', 'Otolaryngologist', 'Otoscopes', 'Otoscopy', 'Pathology', 'Patients', 'Pediatrics', 'Perforation', 'Performance', 'Pharmaceutical Preparations', 'Pharyngeal structure', 'Physician Assistants', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resolution', 'Retrieval', 'Side', 'Skin', 'Societies', 'Surgical Pathology', 'System', 'Testing', 'Training', 'Tube', 'Tympanic membrane', 'United States National Institutes of Health', 'Waxes', 'Work', 'accurate diagnosis', 'acute infection', 'base', 'central database', 'clinical decision support', 'cognitive development', 'computerized', 'diagnostic accuracy', 'digital imaging', 'digital video recording', 'effusion', 'experience', 'hearing impairment', 'improved', 'middle ear', 'novel', 'novel strategies', 'overtreatment', 'personalized therapeutic', 'primary care setting', 'prototype', 'software development']",NIDCD,OHIO STATE UNIVERSITY,R21,2019,199142,-0.017866246754524636
"BlueBox: A Complete Code Blue Data Recorder, Phase II “Code blue” is the signal used in hospitals to call for an immediate cardiopulmonary resuscitation (CPR) following a cardiac or respiratory arrest. Reviewing the performance of the “code blue team” is a cornerstone for improving outcomes. The current standard of using handwritten records on a paper “code sheet” does not allow measurement of key quality indicators and is subject to human error. In the Phase I STTR project, we developed an electronic device for complete recording of code blue events, called BlueBox. The BlueBox is a small electronic recorder on an adhesive patch to be placed on the left chest next to the mid-sternum. The prototype we developed in Phase I was successfully tested on high fidelity mannequins and on pigs. In Phase II, our goal is to complete the product development and testing and prepare the BlueBox for regulatory clearance and market launch. To achieve this goal, we propose 3 Specific Aims. Aim 1 is to complete the product development of the BlueBox device and the software user interface (UI) for the “electronic code sheet.” We will turn the engineering prototype we developed in Phase I into a product ready for commercialization through rigorous product development processes. We will develop a mobile app for iPads with a software UI for the “electronic code sheet.” Aim 2 is to conduct human factors and usability engineering (HF/UE) testing and prepare for regulatory submission. The alpha prototype will undergo HF/UE testing in the Simulation Center. We will establish and maintain quality management records and conduct a pilot production run of 200 units of BlueBox. Aim 3 is to validate the BlueBox system in a clinical study of code blues in the hospital. We will first conduct a pilot study of 5 code blue patients in the CCU and Cath Lab. Once the pilot study is successful, we plan to conduct a full clinical study of 100 patients recruited from the Harbor-UCLA ICU/CCU and emergency departments. The objectives of the clinical study are: 1) to establish equivalence of the electronic code sheet to the current standard of paper code sheet; 2) to demonstrate the effectiveness of the electronic code sheet in identifying key CPR quality indicators. The criteria for successful development of the product will be that it passes all required regulatory testing and is validated in the clinical study for its equivalence and effectiveness in code blue recording. There will be two major milestones in this project: (1) finalizing product development with successful test production of 200 units; and (2) completing the clinical study and preparing for a 510(k) submission. Achieving the aims will result in a validated BlueBox system ready for submission to the FDA and commercialization. We intend to first introduce the BlueBox system to hospitals as a tool for staff training and quality improvement. We will continue the technology development with machine learning to provide instant feedback in the second generation BlueBox. Our ultimate goal is to minimize human error and improve patient outcomes through the BlueBox system's better documentation and continuous feedback mechanism. PROJECT NARRATIVE Debriefings and detailed reviews of the performance of the “code blue team” in cardiopulmonary resuscitation (CPR) can improve quality of care and patient outcomes. In Phase I, we developed and successfully tested an electronic device, the BlueBox, for recording all CPR events and enabling full displays of code blue resuscitations in an “electronic code sheet.” We will turn the engineering prototype into a product ready for regulatory submission and commercialization in the proposed Phase II project.","BlueBox: A Complete Code Blue Data Recorder, Phase II",9680137,R42GM113463,"['Accident and Emergency department', 'Adhesives', 'American Heart Association', 'Animals', 'Cardiac', 'Cardiopulmonary Resuscitation', 'Chest', 'Clinical', 'Clinical Research', 'Code', 'Code Blue', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Documentation', 'Effectiveness', 'Electric Countershock', 'Electronics', 'Emergency Situation', 'Engineering', 'Event', 'Family suidae', 'Feedback', 'Generations', 'Goals', 'Guidelines', 'Hospital Administrators', 'Hospitals', 'Human', 'Industrialization', 'Left', 'Machine Learning', 'Manikins', 'Measurement', 'Mechanics', 'Medical', 'Medical Errors', 'Miniaturization', 'Modeling', 'Outcome', 'Paper', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Pilot Projects', 'Preparation', 'Procedures', 'Process', 'Production', 'Quality Indicator', 'Quality of Care', 'Records', 'Resuscitation', 'Running', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specialist', 'Specific qualifier value', 'Sternum', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Validity and Reliability', 'base', 'care outcomes', 'commercialization', 'design', 'heart rhythm', 'human error', 'improved', 'improved outcome', 'machine learning algorithm', 'meetings', 'member', 'mobile application', 'patient safety', 'product development', 'prototype', 'respiratory', 'sensor', 'simulation', 'technology development', 'tool', 'usability', 'validation studies']",NIGMS,"NEOVATIVE, INC.",R42,2019,723986,-0.016256058912971653
"Integrated Microbial Screening and Antimicrobial Susceptibility Test on Microfluidic Digital Array for Diagnosis of Urinary Tract Infections Abstract COMBiNATi will work with Stanford University to bring the world’s first integrated ID+AST UTI diagnostic platform to the market by combining COMBiNATi’s “one-click” cost-effective dPCR platform with Stanford’s pathogen identification (ID) HRMA algorithm for broad detection, deep characterization and absolute quantification of UTI pathogens. By the end of the Phase 1 project, we will deliver the prototype instrument for ID and AST, scale-ready consumables for dPCR + HRM and culture + qPCR, machine-learning software algorithm for melt curve analysis, and prove the feasibility by identifying and quantifying the top two urinary tract infection bacteria. We will first develop two consumables: an 100k partition ID chip and a 32-lane, 10k partition per lane AST plate based on the micro-injection molding design rules established by COMBiNATi. An integrated system with thermal control and imaging capability will then be developed for HRM and qPCR processes. The prototype system will then be transferred to Stanford University where mock samples including both isolated bacteria and contrived urine samples will be tested on the platform for integrated pathogen ID and AST determination. Narrative Urinary Tract Infection (UTI) is one of the most common community-acquired bacterial infection. However, like other bacterial infections, standard culture-based diagnosis of UTI requires at least 2-3 days from sample acquisition to result reporting. Despite technological advancements, the process remains time- consuming and requires significant technical expertise. Automated instruments remain bulky and still require clonal isolation of the pathogens from the body fluid samples prior to AST. Additionally, the lack of definitive microbiological diagnosis that is rapid enough to achieve evidence-based treatment has driven the over- and misuse of broad-spectrum antibiotics. We believe the proposed integrated ID + AST platform has the potential to enable deep genetic analyses of clinical samples to provide rapid precision UTI triage and MIC determination in a timely and cost-efficient manner to positively impact patient care as well as promote the use of narrow spectrum antibiotics to favorably impact antibiotic resistance profiles.",Integrated Microbial Screening and Antimicrobial Susceptibility Test on Microfluidic Digital Array for Diagnosis of Urinary Tract Infections,9777415,R41AI145604,"['Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Ampicillin', 'Antibiotic Resistance', 'Antibiotic susceptibility', 'Antibiotics', 'Antimicrobial susceptibility', 'Bacteria', 'Bacterial Infections', 'Biological Assay', 'Body Fluids', 'Ceftriaxone', 'Cell Separation', 'Cells', 'Ciprofloxacin', 'Clinical', 'Communities', 'Computer software', 'Consumption', 'Data', 'Databases', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Escherichia coli', 'Evidence based treatment', 'Genomic DNA', 'Gentamicins', 'Growth', 'Individual', 'Injections', 'Klebsiella pneumonia bacterium', 'Laboratories', 'Liquid substance', 'Machine Learning', 'Methods', 'Microbiology', 'Microfluidics', 'Minimum Inhibitory Concentration measurement', 'Modality', 'Molds', 'Molecular', 'Patient Care', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Process', 'Protocols documentation', 'Reagent', 'Reporting', 'Resistance profile', 'Resolution', 'Sampling', 'Small Business Technology Transfer Research', 'System', 'Technical Expertise', 'Testing', 'Time', 'Triage', 'Trimethoprim-Sulfamethoxazole', 'Universities', 'Urinary tract infection', 'Urine', 'Uropathogen', 'Work', 'base', 'cost effective', 'cost efficient', 'design', 'digital', 'genetic analysis', 'imaging capabilities', 'instrument', 'melting', 'microbial', 'operation', 'pathogen', 'prototype', 'response', 'scale up', 'screening', 'success']",NIAID,"COMBINATI, INC.",R41,2019,224658,-0.015601096265231077
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",9746883,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'injured', 'innovation', 'learning strategy', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2019,824785,-0.030164361833195458
"An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis Project Summary  Improved methods for the bedside diagnosis and evaluation of neuromuscular disorders are needed. One technology that is finding increasing use for this purpose is electrical impedance myography (EIM). In EIM, a very weak, high frequency electrical current is passed through a muscle of interest and the resulting surface voltages are measured. Disease associated alterations in the composition and microstructural features of the muscle produce characteristic changes that can be used to help classify specific conditions and grade disease severity. To date, most studies using EIM analysis have utilized a fairly limited data set for disease assessment. While effective, this approach ignores a great deal of information locked within the impedance data, including those values that can assist in predicting specific muscle features (such as myofiber diameter) and the presence of pathological change (e.g., fat or connective tissue deposition). In addition, as it stands, the data set is challenging for the clinician to understand without a detailed knowledge of impedance theory. Myolex, Inc is a small business concern located in Boston, MA has as its main focus the development of EIM technologies for clinical use. Myolex recently completed a Phase 1 SBIR that demonstrated the potential capability of machine learning based classification algorithms to effectively discriminate healthy muscle from diseased and to discriminate one disease from another. In this proposed work, we will greatly advance this concept by embodying classification algorithms into a powerful new software suite for Myolex’s current EIM system, the mView. Our underlying hypothesis is that EIM data analysis can be automated to the point that classification systems can provide data on disease diagnosis as well as disease severity for improved ease-of-use. We propose to study this hypothesis via 2 specific aims. In Specific Aim 1, we will design a software suite capable of assisting with artifact-free data collection to be incorporated into our current EIM system, the mViewTM. Then using classification paradigms based on a prodigious amount of previous collected data, we will develop an automated data analysis tool to help provide data on disease category as well as microscopic features, muscle based on the impedance data alone using Microsoft’s Azure Cloud platform. In Specific Aim 2, we will test this developed software suite in a total of180 adult and pediatric neuromuscular disease patients and healthy participants evaluated at Ohio State University Wexner Medical Center (adults) and Boston Children’s Hospital (children). During this data collection period, the Ohio State and Boston Children’s researchers will have real- time access to Myolex staff to provide feedback and have questions/problems answered and addressed. The user interface will continue to be refined and classification algorithms improved. At the conclusion of this work, a new diagnostic tool will be developed for potential 510(k) FDA approval. It will serve as the basis for a continuously self-refining system as additional data sets are collected by end-users employing them in regular clinical use. Project Narrative  Electrical impedance myography (EIM) is a valuable technique to assist with the evaluation of a variety of conditions affecting nerve and muscle. However, to date, only simplistic EIM outcomes have been utilized to assess muscle condition. In this proposed work, we will develop a software platform using machine learning to be incorporated into current EIM technology to allow for automated diseased classification and characterization using the entire large EIM data set collected with each muscle measurement. This will serve as the basis for a new, powerful and convenient tool for neuromuscular diagnosis that will continue to advance over time.",An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis,9846955,R44NS113756,"['Address', 'Adult', 'Affect', 'Algorithmic Software', 'Amyotrophic Lateral Sclerosis', 'Area', 'Back Pain', 'Boston', 'Businesses', 'Caliber', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Classification', 'Clinical', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Set', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Duchenne muscular dystrophy', 'Effectiveness', 'Electrodes', 'Ensure', 'Evaluation', 'Fatty acid glycerol esters', 'Feedback', 'Fiber', 'Frequencies', 'Functional disorder', 'Health', 'Inclusion Body Myositis', 'Individual', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Medical Technology', 'Medical center', 'Methods', 'Microscopic', 'Morphologic artifacts', 'Muscle', 'Muscular Dystrophies', 'Myography', 'Myopathy', 'Myositis', 'Nerve', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Ohio', 'Outcome', 'Participant', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Provider', 'Radiculopathy', 'Research Personnel', 'Role', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Work', 'base', 'classification algorithm', 'cloud based', 'cloud platform', 'commercialization', 'data acquisition', 'design', 'diagnosis evaluation', 'disease classification', 'disease diagnosis', 'electric impedance', 'improved', 'indexing', 'interest', 'machine learning algorithm', 'method development', 'nerve injury', 'neuromuscular', 'novel diagnostics', 'pediatric patients', 'physical therapist', 'prototype', 'sarcopenia', 'software development', 'success', 'theories', 'tool', 'usability', 'user friendly software', 'user-friendly', 'voltage']",NINDS,"MYOLEX, INC.",R44,2019,621318,-0.013737642556120519
"Graphene-based Nanosensor Device for Rapid, Onsite Detection of Total Lead in Tap Water PROJECT SUMMARY Detrimental health impacts of lead are largely attributed to long-term exposures to undetected lead, which are particularly troublesome and problematic because of the neurological damage to children, a situation that should not be tolerated by an advanced society like the U.S. The Flint Water Crisis and many other water catastrophes could have been avoided if early warning can be made possible through timely detection of lead in drinking water at the point of use. Our extensive customer interviews unambiguously suggest that current options for lead detection are unsatisfactory for on-site testing, as they represent two extremes: one being accurate but expensive, slow, and hard to use; and the other being low-cost, fast, and easy to use but inaccurate. NanoAffix Science LLC (NAFX) proposes to address the above unmet need and niche market product gap by empowering water users (particularly those in economically disadvantaged communities) and water service providers with a low-cost, easy-to-use, and accurate handheld tester for rapid detection of total lead in the tap water, right from the kitchen sink. The handheld lead tester combines a novel proprietary micro-sized sensor chip embedded in a proprietary test cell with a portable digital meter for direct readout of testing results. The Phase I project has successfully established the feasibility for detection of soluble lead in the tap water using an earlier version of the prototype handheld tester. The Phase II project will continue to develop the handheld tester toward total lead detection, better device uniformity, pilot scale-up manufacturing, and accurate calibration. At the end of the Phase II project, NAFX plans to produce 20 beta units of the handheld lead tester meeting all performance specifications for field validation by 10 initial customers (e.g., schools/daycares, end water users, and well water drillers). Major innovations of the proposed approach include accurate prediction of the particulate lead through partial digestion based on lead digestion kinetics, and strategic and synergistic improvement of the ultimate sensor prediction accuracy by (1) improving the physical sensor device uniformity (both intra-wafer and inter-wafer) through innovative device configuration and rigorous quality control; and (2) improving the calibration accuracy through innovative theoretical equilibrium chemistry modeling and machine learning data analytics. The NAFX handheld lead tester is the first of its kind to (1) offer all three features sought by customers: accurate, cheap, and fast; and (2) to simultaneously report all three types of lead: total lead (indicative of overall toxicity), soluble lead (indicative of slow leaching of lead), and particulate lead (indicative of sporadic flaking of lead), which thus can not only alert customers to the lead hazard in their drinking water but also enable customers to identify possible causes and most effective solutions to mitigate the lead contamination. Therefore, the project will result in not only considerable economic impact but also immense societal impact. The regular use of NAFX handheld tester - even if intermittently - will virtually eliminate the chance of chronic exposure to undetected lead, thereby accruing significant and predictable public health impact, especially in locations with the highest risk. PROJECT NARRATIVE The NanoAffix Phase II project aims to continue the development of a handheld lead tester for accurate and low- cost onsite detection of total lead in tap water by untrained users, based on the success of the Phase I project. The project will contribute to enhancing the public health by offering an accessible tool for quantitative monitoring of all three types of lead: total lead (indicative of overall toxicity), soluble lead (indicative of slow leaching of lead), and particulate lead (indicative of sporadic flaking of lead) in tap water. The regular use of NanoAffix handheld tester - even if intermittently - will virtually eliminate the chance of chronic exposure to undetected lead, thereby accruing significant and predictable public health impact, especially in locations with the highest risk.","Graphene-based Nanosensor Device for Rapid, Onsite Detection of Total Lead in Tap Water",9847052,R44ES028656,"['Address', 'Algorithms', 'Calibration', 'Cations', 'Cells', 'Chemistry', 'Child', 'Chronic', 'Communication', 'Communities', 'Complex', 'Contracts', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Digestion', 'Disinfection', 'Economically Deprived Population', 'Equilibrium', 'Equipment', 'Exposure to', 'Goals', 'Gold', 'Health', 'International', 'Interview', 'Kinetics', 'Laboratories', 'Lead', 'Lead Poisoning', 'Location', 'Machine Learning', 'Measurement', 'Michigan', 'Modeling', 'Monitor', 'Nervous System Trauma', 'Paper', 'Particulate', 'Performance', 'Phase', 'Procedures', 'Process', 'Public Health', 'Quality Control', 'Reporting', 'Research', 'Schools', 'Science', 'Site', 'Societies', 'Specialist', 'System', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Validation', 'Variant', 'Water', 'Water Supply', 'Wireless Technology', 'aqueous', 'base', 'cost', 'digital', 'drinking water', 'economic impact', 'empowered', 'graphene', 'hazard', 'high risk', 'improved', 'innovation', 'lead concentration', 'lead contamination', 'manufacturing scale-up', 'meetings', 'meter', 'nanosensors', 'novel', 'operation', 'portability', 'prototype', 'rapid detection', 'real time monitoring', 'response', 'sample collection', 'sensor', 'service providers', 'success', 'tool', 'virtual', 'water quality', 'well water']",NIEHS,"NANOAFFIX SCIENCE, LLC",R44,2019,565059,0.0002683487443353725
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9746721,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Infrastructure', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'classification algorithm', 'clinical practice', 'community involvement', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,334204,-0.008726192549574291
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9750736,R01EB021396,"['3-Dimensional', 'Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'data pipeline', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'off-label use', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2019,434944,-0.008890819098621182
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,9735326,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Simulation', 'Cornea', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Image Analysis', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2019,396887,-0.0018601349040334799
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,9862231,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Comorbidity', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2019,450365,-0.0035776749329352363
"Microscopy-Based Antimicrobial Susceptibility Testing (MAST) Antibiotic resistance is compromising our ability to treat bacterial infections. Clinical microbiology laboratories guide appropriate treatment through antimicrobial susceptibility testing (AST) of patient bacterial isolates. However, increasingly, pathogens are developing resistance to a broad range of antimicrobials, requiring AST of less commonly used or recently introduced agents for which no commercially available or FDA-cleared testing methods exist. Agar and broth dilution are gold standard methods for AST that can be used to test any antimicrobial; however, labor and technical complexity precludes their use in hospital-based clinical laboratories. Therefore, bacterial isolates often must be sent to a reference laboratory with a 4-6 day delay in results. Furthermore, even standard methods require overnight incubation prior to readout. Therefore, there exists a significant AST testing gap in which current methodologies cannot adequately address the need for rapid results in the face of unpredictable susceptibility profiles. Our laboratory has recently verified inkjet printer-based digital dispensing technology as a novel platform to facilely perform reference AST for any antimicrobial at will. In this proposal, we aim to combine this methodology with advanced microscopy to leapfrog traditional AST capabilities through: (1) development of a method for microscopic imaging of bacterial replication on a solid-phase, 384-well microplate AST format, thereby allowing determination of susceptibility for any drug at will in 4 hours and (2) development and application of advanced image analysis for automated susceptibility calls. This new platform is designated MAST for microscopy-based antimicrobial susceptibility testing. The clinical diagnostic performance of the platform will be optimized against an AST reference method for accuracy and precision using a large panel of well-characterized clinical isolates. We anticipate establishing a prototype platform that will address the AST testing gap and thereby help our health system more effectively address the antimicrobial resistance threat. With the emergence of multi-drug resistant bacteria, it is no longer possible to accurately predict which antimicrobials will be effective against life-threatening bacterial illness. Testing bacteria directly for response available therapies may take several days. Therefore, a new technology platform called MAST is proposed to allow us to determine which antibiotics can treat a bacteria infection in a matter of hours and thereby address our current, clinically unacceptable antimicrobial testing gap.",Microscopy-Based Antimicrobial Susceptibility Testing (MAST),9697702,R21AI130434,"['Address', 'Agar', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Bacteria', 'Bacterial Infections', 'Clinical', 'Clinical Microbiology', 'Development', 'Diagnostic tests', 'Goals', 'Gold', 'Growth', 'Health system', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Laboratories', 'Life', 'Machine Learning', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Monitor', 'Multiple Bacterial Drug Resistance', 'Nutrient', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Predisposition', 'Printing', 'Regimen', 'Resistance', 'Resistance development', 'Solid', 'Surface', 'Technology', 'Test Result', 'Testing', 'antimicrobial', 'automated image analysis', 'base', 'biomaterial compatibility', 'clinical diagnostics', 'convolutional neural network', 'digital', 'direct application', 'microscopic imaging', 'new technology', 'next generation', 'novel', 'pathogen', 'performance tests', 'prototype', 'response', 'supervised learning']",NIAID,BETH ISRAEL DEACONESS MEDICAL CENTER,R21,2019,223354,-0.017254643553228664
" SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track) The overall objective of this Fast-Track SBIR contract project is to develop DigiBioMarCTM (Digital BioMarkers for Clinical Impact), a scalable and flexible cloud-based platform to capture and analyze wearable, implantable, or external device data. This platform also provides an informatics tool for automated data aggregation, integration, and machine learning algorithms. It is based on the scalable user-centered Medable platform, which implements standardization and normalization of patient-generated data to drive health insights. DigiBioMarCTM will compare and combine disparate data streams to understand contextualized patient physiology in real time in order to identify disease and/or detect changes in disease/health status. It also will support cohort and clinical studies, particularly those testing digital biomarkers from wearable sensor technologies. This Fast-Track project will focus on product development with an ultimate aim of a product that improves cancer research data and clinical trials, enhances clinical care, and that can be used to engage patients in preventive health behaviors and treatment adherence. The Phase I goal is to develop a data-agnostic DigiBioMarCTM prototype for validation in Phase II. The Phase 1 Go/No-Go decision point to proceed to Phase II will be a working prototype with specified features for further development and validation in Phase II. n/a", SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track),9952269,61201800010C,"['Biological Markers', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Computer software', 'Contracts', 'Data', 'Data Aggregation', 'Development', 'Devices', 'Disease', 'Documentation', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Patients', 'Phase', 'Physiology', 'Preventive', 'Publishing', 'Reporting', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Standardization', 'Stream', 'System', 'Testing', 'Time', 'Validation', 'anticancer research', 'base', 'behavioral adherence', 'clinical care', 'cloud based', 'digital', 'flexibility', 'graphical user interface', 'improved', 'informatics\xa0tool', 'insight', 'knowledge base', 'machine learning algorithm', 'product development', 'prototype', 'sensor', 'skills', 'tool', 'treatment adherence', 'wearable sensor technology']",NCI,"MEDABLE, INC.",N43,2019,1499800,0.0027825903994410273
"LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research PROJECT SUMMARY Imaging forms the backbone of living subjects research. Living subjects research is both essential to the progress of translational medicine and very expensive. The research community actively seeks to develop and validate new clinical endpoints to solve a range of etiology, natural history, diagnostic and prognostic problems. This project aims to develop and commercialize LATTICE, an Electronic Research Record, Image Management and Sharing Solution, and Deep Learning Platform. LATTICE is designed to increase the efficiency of imaging-driven biomedical research and clinical trials. This efficiency is accomplished first through a structured workflow that includes protocol management, subject scheduling, and records collection from multiple imaging modalities. Access to imaging and associated data within the same workflow simplifies the process for the research team. Structuring the data into a de-identified, privacy-managed Image Bank enables sharing for collaboration and re-use for retrospective research. Image processing algorithms connected to the Image Bank facilitate batch analysis, while the system also provides a platform for the development of new image-based outcome measures and clinical endpoints. A key objective of LATTICE is to enable investigators and collaborators to accelerate the translation of insights to the clinic with maximum efficiency. Successful translation requires structuring the workflow, record keeping, and protocols into a rigorous, transparent, reproducible and validated process. LATTICE is designed to reduce the friction in translating successful research projects to the clinic. Researchers in the Advanced Ocular Imaging Program (AOIP) at the Medical College of Wisconsin developed elements of LATTICE as separate technologies. The Specific Aims of this proposal are directed to an integrated workflow addressing a broader set of objectives. The AOIP LATTICE Electronic Research Record will be translated into a commercially managed repository and brought under regulatory Design Control. The current AOIP Image Bank containing 3,000,000 de- identified retinal images will be integrated into the LATTICE workflow. Critically, this integration will allow the sharing of the Image Bank with external researchers. Three retinal image process algorithms that operate on retinal images will integrate into this workflow. These algorithms include analysis of adaptive optics images of the fundus, analysis of the foveal avascular zone from optical coherence tomography angiography (OCTA), and model-based analysis of the fovea imaged with OCT. A computational deep learning workflow will also be prototyped using a cloud-based architecture. This final workflow will be constructed to demonstrate the feasibility of deploying a collaborative deep learning environment for the development of new clinical endpoints using shared, de-identified images. LATTICE will be a unique system for both prospective and retrospective translational research. LATTICE will make a profound impact on the cost of managing image-based research and add leverage to translational research expenditures for moving insights into the clinic. PROJECT NARRATIVE LATTICE is an innovative electronic research record and development platform for image-based ophthalmic research. LATTICE is designed to reduce the cost of translational research, promote the re- use of images, and simplify the development and application of new techniques to analyze medical images. LATTICE will integrate research workflow tools with a database of 3,000,000 retinal images and advanced image processing software to accelerate the process of translating eye research insights from the lab to the clinic.",LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research,9777970,R43EY030408,"['Address', 'Algorithmic Software', 'Algorithms', 'Angiography', 'Architecture', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnostic', 'Documentation', 'Elements', 'Etiology', 'Expenditure', 'Eye', 'Friction', 'Future', 'Health Insurance Portability and Accountability Act', 'Image', 'Libraries', 'Medical Imaging', 'Methods', 'Modeling', 'Morphology', 'Natural History', 'Optical Coherence Tomography', 'Outcome Measure', 'Output', 'Privacy', 'Process', 'Protocols documentation', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Scanning', 'Schedule', 'Secure', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Translational Research', 'Translations', 'Vertebral column', 'Wisconsin', 'Writing', 'adaptive optics', 'base', 'cloud based', 'cost', 'deep learning', 'design', 'educational atmosphere', 'fovea centralis', 'fundus imaging', 'image processing', 'imaging modality', 'imaging platform', 'imaging program', 'innovation', 'insight', 'medical schools', 'ocular imaging', 'operation', 'prognostic', 'programs', 'prospective', 'prototype', 'repository', 'retinal imaging', 'system architecture', 'tool', 'translational medicine', 'web services', 'wiki']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R43,2019,299999,-0.024109403150471314
"Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury ﻿    DESCRIPTION (provided by applicant): Throughout human pregnancy, the placenta is indispensable for embryonic development, fetal growth and tissue differentiation. The placenta also protects the fetus against diverse insults, while preserving maternal health. Placental dysfunction is commonly implicated in complications of pregnancy that challenge maternal physiology (e.g., preeclampsia) and fetal development (e.g., fetal death or fetal growth restriction) or that leads to preterm birth. Within the placenta, the trophoblast constitutes the outermost layer, which is directly bathed in maternal blood and therefore positioned to regulate maternal-fetal gas exchange, nutrient delivery, waste removal and the production of hormones, faithfully balancing fetal needs and maternal supply. Trophoblast damage, which is common in dysfunctional placentas, may interrupt the delicate maternal-fetal balance, cause clinical disease, and leave a lifelong mark on health. A fundamental challenge in perinatal medicine arises from our limited ability to diagnose placental disorders in real time and throughout pregnancy. However, the recent discovery, by ourselves and others, that (a) placental trophoblasts release distinctive micro- and nanovesicles into the maternal circulation and (b) these vesicles contain trophoblast-specific non-coding RNA cargo, created a new opportunity for assessing trophoblast health. These vesicles are actively released by trophoblasts throughout pregnancy, and thus serve as a venipuncture-accessible ""natural biopsy"" of trophoblasts, which can furnish information on trophoblast health in real time. Our established perinatal biology group at Magee- Womens Research Institute includes expertise in perinatal medicine and placental pathology, developmental and molecular biology, and bioinformatics. Inspired by these recent advances, we have partnered with an experienced group of bioengineers that includes experts from Carnegie Mellon University, MIT, and Penn State University, with unique skills in biophysics-based vesicle analytics, including microfluidics, nanomechanics, micro/nano fabrication and vesicle sorting using acoustic tweezers. Together, our new transdisciplinary group will use integrated molecular and biophysical methodologies to directly assess the use of trophoblast-derived extracellular vesicles from maternal plasma as revelatory of trophoblast health in real time and as a technique that may be employed throughout pregnancy. Our approach is comprehensive, centering on miRNAs as well as lncRNAs and circRNAs, analyzed in exosome nanovesicles, as well as microvesicles and apoptotic bodies. As each vesicle features a unique bimolecular and biophysical signature, we will deploy our machine learning- based training and testing pipeline to informatively integrate these distinct signals into an innovative diagnostic tool. Lastly, our deployment of affordable acoustic tweezers technology to sort trophoblastic vesicles will facilitate the translation of our advances into a new ""lab on a chip"" placental diagnostic technology, suitable for small blood volumes. This technology may not only denote trophoblast pathology, but has potential to identify those who may benefit from intervention and to monitor therapeutic success. PUBLIC HEALTH RELEVANCE: Although the placenta is critical for fetal development and pregnancy outcome, it is not currently accessible for real-time diagnostics throughout pregnancy. Having developed tools for isolation and analysis of placenta- specific extracellular from the maternal plasma, we will study molecular and biophysical properties of these vesicles as indicators of placental health and disease.",Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury,9701262,R01HD086325,"['Abruptio Placentae', 'Acoustics', 'Apoptotic', 'Arteries', 'Bioinformatics', 'Biological Assay', 'Biology', 'Biomedical Engineering', 'Biophysics', 'Biopsy', 'Blood', 'Blood Circulation', 'Blood Volume', 'Blood flow', 'Characteristics', 'Clinical', 'Communication', 'Data', 'Developmental Biology', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Dimensions', 'Disease', 'Embryonic Development', 'Endoglin', 'Equilibrium', 'Evaluation', 'Excision', 'Fetal Death', 'Fetal Development', 'Fetal Growth', 'Fetal Growth Retardation', 'Fetal Tissues', 'Fetal health', 'Fetus', 'Functional disorder', 'Future', 'Gases', 'Glean', 'Gold', 'Health', 'Histologic', 'Hormones', 'Human', 'Injury', 'Interruption', 'Intervention', 'Investigation', 'Knowledge', 'Lab-On-A-Chips', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maternal Health', 'Maternal Physiology', 'Methods', 'MicroRNAs', 'Microfluidics', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Needle biopsy procedure', 'Nutrient', 'PGF gene', 'Pathology', 'Perinatal', 'Placenta', 'Placenta Diseases', 'Placental Biology', 'Plasma', 'Plasma Proteins', 'Positioning Attribute', 'Postpartum Period', 'Pre-Eclampsia', 'Predictive Value', 'Pregnancy', 'Pregnancy Complications', 'Pregnancy Outcome', 'Pregnancy-Associated Plasma Protein-A', 'Premature Birth', 'Production', 'Property', 'Provider', 'Research Institute', 'Shapes', 'Signal Transduction', 'Sorting - Cell Movement', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissue Differentiation', 'Training', 'Translations', 'Ultrasonography', 'Universities', 'Untranslated RNA', 'Uterus', 'Venipunctures', 'Vesicle', 'Viscosity', 'Woman', 'adverse pregnancy outcome', 'base', 'biophysical properties', 'biophysical techniques', 'circular RNA', 'clinical care', 'clinical diagnostics', 'cost effective', 'design', 'exosome', 'experience', 'extracellular', 'extracellular vesicles', 'fetal', 'fitness', 'guided inquiry', 'improved', 'in vivo', 'injured', 'innovation', 'mechanical properties', 'microvesicles', 'multidimensional data', 'nanofabrication', 'nanomechanics', 'nanovesicle', 'novel', 'perinatal medicine', 'peripheral blood', 'pregnancy disorder', 'preservation', 'public health relevance', 'skills', 'stem', 'success', 'tomography', 'tool', 'transcriptome sequencing', 'trophoblast', 'viscoelasticity', 'wasting']",NICHD,MAGEE-WOMEN'S RES INST AND FOUNDATION,R01,2019,650539,-0.018838868350704436
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9761481,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2019,873369,-0.023799071585340458
"Acceleration techniques for SimSET SPECT simulations Abstract The Simulation System for Emission Tomography (SimSET) is one of the foundational tools for emission tomography research, used by hundreds of researchers worldwide for both positron emission tomography (PET) and single photon emission computed tomography (SPECT). It has proven to be accurate and efficient for both PET and low energy SPECT studies; because SimSET uses a geometric model for its SPECT collimation, it is less accurate for high energy isotopes. This application proposes to address this with the use of angular response functions (ARFs), a technique that has proven to accurately model SPECT collimation and detection for high-energy isotopes more efficiently than full photon-tracking simulations. In addition, we propose a novel ARF-based importance sampling method that will speed these simulations by a factor of >50. The generation of ARF tables is another consideration: it is extremely compute intensive and has caused ARF to be used only when a large number of simulations are needed using the same isotope/collimator/detector combination. For this reason, we also propose application of importance sampling to speed the generation of ARF tables by a factor 5, and the creation of a library of angular response functions for popular isotope/collimator/detector combinations. The former will lessen the computational cost of generating the tables, the latter will, for many users/uses, eliminate the need to generate ARF tables at all. This will greatly expand the potential applications of ARF-based simulations. Our first aim is to accelerate SimSET SPECT simulations without sacrificing accuracy. This will be accomplished by synergistically utilizing two tools: variance reduction and angular response function (ARF) tables. Variance reduction includes importance sampling and forced detection. We hypothesis that these techniques combined with information from our angular response function tables will improve SimSET simulation efficiency by >50 times of SPECT simulations of specific radioisotopes (e.g., I-123, Y-90, etc.). Our second aim is to accelerate ARF table generation. This will be accomplished by using importance sampling methods in the generation of ARFs. We further propose to use an adaptive stratification scheme that will simulate photons for a given table position only as long as required to determine its value to a user-specified precision. Our third aim is to create a library of pre-calculated ARF tables for popular vendor isotope/collimator/detector configurations. These ARF tables will then be made publically available for download through the SimSET website. With a registered user base of >500, we believe that these enhancements to SimSET will have far reaching impact on research projects throughout the world. Narrative The overall goal of this work is to develop methods to speed up the SimSET Monte Carlo-based simulation software for single photon computed tomography (SPECT) imaging systems by greater than 50-fold. This type of speed up with enable new research that was previously impractical due to the computation time required for simulation. In addition, all software tools and tables developed within this project will be made available via a web-based host.",Acceleration techniques for SimSET SPECT simulations,9751297,R03EB026800,"['90Y', 'Acceleration', 'Address', 'Algorithms', 'Collimator', 'Communities', 'Consumption', 'Crystallization', 'Data', 'Detection', 'Foundations', 'Future', 'Generations', 'Goals', 'Industrialization', 'Institution', 'Isotopes', 'Libraries', 'Location', 'Machine Learning', 'Medical Research', 'Methods', 'Modeling', 'Online Systems', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Probability', 'Radioisotopes', 'Research', 'Research Personnel', 'Research Project Grants', 'Running', 'Sampling', 'Scheme', 'Software Tools', 'Specific qualifier value', 'Speed', 'Stratification', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Vendor', 'Weight', 'Work', 'X-Ray Computed Tomography', 'base', 'cost', 'detector', 'imaging system', 'improved', 'interest', 'novel', 'response', 'simulation', 'simulation software', 'single photon emission computed tomography', 'synergism', 'thallium-doped sodium iodide', 'tomography', 'tool', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R03,2019,77750,-0.06387686466073446
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9740493,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Augmented Reality', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Imagery', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Visual', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'tool', 'trend', 'virtual reality', 'web services']",NIBIB,"KITWARE, INC.",R01,2019,508446,-0.01308682105336949
"Stasys Medical: A Rapid, Microfluidic Blood Test Sensitive to Platelet Dysfunction PROJECT SUMMARY/ABSTRACT Antiplatelet medications are a critical component to manage cardiovascular diseases (CVD), which is a prevalent affliction in the US. While monitoring platelet therapy is of increasing importance for the identification of hypo- or hyper-responsive patients, there is not a clear picture of the medical value of tailored antiplatelet therapy using currently available platelet function tests. Currently, US FDA cleared assays of platelet function designed to be near the patient measure platelet adhesion and aggregation. Stasys Medical is developing a system based on patented platelet contraction sensors to assay platelet contraction force as a biomarker for platelet dysfunction. In the current project, the Company will build on preliminary data to demonstrate that the force biomarker is sensitive to platelet inhibition via multiple pathways. Specifically, aims are designed to 1) correlate the platelet contractile force measurements to inhibition of platelet activation and adhesion pathways, and 2) benchmark the force assay to standard platelet function tests. The go/no-go criteria for moving to Phase II is demonstration that platelet force is sensitive to specific inhibitors and that the assay can identify platelet dysfunction currently missed by existing standard platelet function assays. In the Phase II project we will leverage data generated in the current project to develop an algorithm that can automatically identify antiplatelet medications. Clinically, this will be a valuable tool to identify medication non-responders. Taken together, the project will be used to support the Company’s 510(k) submission to FDA with claims directed at evaluating platelet function to assess clinical conditions, such as bleeding risk, associated with the use of antiplatelet drugs, and during and following cardiovascular surgery. PROJECT NARRATIVE Antiplatelet medications are a critical component to manage cardiovascular diseases (CVD), which is a prevalent affliction in the US. In the Phase I project, Stasys Medical will build on preliminary data to show that the platelet contraction force biomarker reflects platelet function as proof-of-concept that the force assay can identify platelet dysfunction missed by existing assays. The Phase II project will leverage Phase I results to develop an algorithm using machine learning techniques that can automatically identify antiplatelet medications to identify medication non-responders.","Stasys Medical: A Rapid, Microfluidic Blood Test Sensitive to Platelet Dysfunction",9681062,R43HL142318,"['Acute Coronary Event', 'Adhesions', 'Adverse event', 'Affect', 'Agonist', 'Algorithms', 'Antiplatelet Drugs', 'Aspirin', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Blood Platelets', 'Blood Tests', 'Blood Volume', 'Blood specimen', 'Cardiovascular Diseases', 'Cardiovascular Surgical Procedures', 'Cardiovascular system', 'Catheterization', 'Clinical', 'Clot retraction', 'Consensus', 'Coronary', 'Data', 'Devices', 'Functional disorder', 'Generations', 'Hemorrhage', 'Hemostatic function', 'Impairment', 'Integrins', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Microfluidics', 'Monitor', 'Myosin ATPase', 'Optical Instrument', 'Pathway interactions', 'Patient risk', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Platelet Activation', 'Platelet Function Tests', 'Population', 'Procedures', 'Randomized', 'Receiver Operating Characteristics', 'Risk', 'Shapes', 'Site', 'Stents', 'System', 'Techniques', 'Testing', 'Thromboxanes', 'Training', 'Validation', 'Whole Blood', 'base', 'design', 'flexibility', 'high risk population', 'inhibitor/antagonist', 'injured', 'nanonewton', 'off-patent', 'operation', 'patient response', 'platelet function', 'point of care', 'response', 'sensor', 'success', 'tool', 'wound']",NHLBI,STASYS MEDICAL CORPORATION,R43,2019,224945,-0.003882995015582432
"Personalizing Glaucoma Diagnosis by Disease Specific Patterns and Individual Eye Anatomy Project Summary/Abstract Glaucoma is a disease of the optic nerve which is accompanied by visual ﬁeld (VF) loss. While accurate VF loss diagnosis and the detection of its progression over time is of high relevance to clinical practitioners as it indicates the initiation of or change in ocular therapy, there is no consensus on objective measures for this purpose, and VF measurements are known to be often unreliable. The main objective of this project is to develop clinically applicable measures to improve the diagnosis of glaucomatous VF loss and of its progression by two approaches: First, the identiﬁcation of representative loss patterns and their progression, achieved by large-scale, customized bioinformatical procedures applied to data from glaucoma patients from nine clinical centers and second, the inclusion of eye and patient speciﬁc personalized parameters. In total, 480,486 VFs, are available for this project. One major aim is to develop novel diagnostic indices based on computationally identiﬁed evolution patterns of VF loss, particularly (1) an index that denotes the probability of glaucomatous vision loss and (2) an index that assigns probabilities to a VF that follow-up measurements will be in a certain defect class. The indices will be statistically evaluated on separate VF samples and compared to existing approaches. Routinely available patient speciﬁc parameters which are candidates to impact glaucomatous vision loss are patient ethnicity, type of glaucoma, spherical equivalent (SE) of refractive error and the location of the blind spot relative to ﬁxation. The effect of these parameters on the vision loss patterns will be systematically studied. The impact of their inclusion in the novel diagnostic indices and their potential improvement on glaucoma diagnosis will be quantiﬁed on a separate data set. A further aim is the calculation of a spatial map speciﬁc to a measured VF that represents the preferred VF locations of future defects as well as their reliability as an aid to event-based progression diagnosis. A second major objective is the investigation of the relationship of VF loss and individual parameters related to retinal structure, based on retinal nerve ﬁber layer thickness (RNFLT) measurements around the optic disc. The inter-relationship of representative patterns of RNFLT and its decrease over time with trajectories of major retinal arteries, SE, and blind spot location is systematically studied, and the impact on patterns of VF loss is quantitatively analyzed with the goal to improve the interpretation of existing VF loss and to predict future glaucomatous vision loss. Main contributions of the project with relevance to clinical practice are publicly available open-source software implementations of new diagnostic indices and maps, enhanced by individual functional and structural parameters, and a detailed and personalized model for the relationship between retinal structure and glaucomatous vision loss. Project Narrative Glaucoma is an ocular disease accompanied by vision loss which may progress over time up to total blindness, but the assessment of glaucomatous vision loss is noisy, and it is often hard for clinical practitioners to decide whether changes over time reﬂect true changes of functional vision or are the result of normal measurement variations or artifacts. This project contributes directly and immediately to public health by exploring the impact of individual anatomical parameters on the spatial patterns of glaucomatous vision loss in order to improve the diagnosis of vision loss and of its progression. Main objective of the project is the development of new quantitative diagnostic indices, implemented as publicly available software.",Personalizing Glaucoma Diagnosis by Disease Specific Patterns and Individual Eye Anatomy,9802123,R01EY030575,"['Anatomy', 'Atrophic', 'Axon', 'Bioinformatics', 'Blindness', 'Clinical', 'Cluster Analysis', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Ethnic Origin', 'Event', 'Evolution', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Hemorrhage', 'Impairment', 'Individual', 'Investigation', 'Length', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Modeling', 'Morphologic artifacts', 'Nerve Fibers', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Probability', 'Procedures', 'Public Health', 'Refractive Errors', 'Retinal', 'Retinal Defect', 'Retinal Ganglion Cells', 'Retinal blind spot', 'Sampling', 'Structure', 'Structure-Activity Relationship', 'System', 'Thick', 'Time', 'Variant', 'Vision', 'Visual Fields', 'Work', 'base', 'central retinal artery', 'clinical application', 'clinical practice', 'disease diagnosis', 'follow-up', 'fovea centralis', 'improved', 'indexing', 'multidisciplinary', 'neglect', 'novel diagnostics', 'open source', 'optic nerve disorder', 'outcome forecast', 'retinal nerve fiber layer', 'sample fixation', 'sex']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,R01,2019,534037,-0.01495925015325111
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9750520,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Personal Satisfaction', 'Persons', 'Phase', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'manufacturability', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2019,507856,-0.004842374225596441
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9653180,R01EY025332,"['3-Dimensional', 'Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,416574,-0.00383990527954784
"Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms Project Summary This project will create and assess new optical imaging and computational technologies with the goal of improving the detection rates of precancerous, non-polypoid lesions during colonoscopy screening. Identifying and removing these subtle lesions is critical to improving the protective value of colonoscopy in reducing mortality from colorectal cancer. However, current approaches to non-polypoid lesion detection are largely unsuccessful because they are time-consuming and require specialized training (chromoendoscopy), or they start with poor image contrast (software analysis of conventional video). This project focuses on developing a novel technique, called quantitative topographic endoscopy (QTE), that optically measures colon surface properties via a modified commercial colonoscope. The key innovation in this proposal is to utilize structured illumination and build on concepts from computer vision and optical engineering to acquire high-resolution 3D images of the colon surface through a custom endoscope. The project will be implemented through three specific aims: (1) develop a miniaturized, quantitative, high-resolution topography system, (2) implement QTE in a modified commercial colonoscope ready for clinical testing, and (3) determine the validity of QTE in a phantom model and its clinical feasibility in a pilot human study. QTE systems developed in this project will be tested in tissue-mimicking phantoms with a goal of achieving better than 1-mm height sensitivity, in ex-vivo resected colon samples with a goal of accurately reconstructing surface shapes from a complex tissue, and in a pilot human study with the goal of obtaining surface topography non-polypoid lesions. Beyond increasing non-polypoid lesion detection rates, QTE has the potential to address other limitations of colonoscopy, including preventing missed polypoid lesions, classifying lesions for resect-and-discard strategies, and improving colonoscopy quality metrics. Additionally, the development of a QTE system that is approved for human studies will serve as a platform for future clinical assessment of other optical techniques such as spatial frequency domain imaging and speckle imaging in a variety of gastroenterology applications. Project Narrative Colorectal cancer is the second leading cause of cancer death in the United States. Screening colonoscopy can significantly reduce mortality from colorectal cancer but is limited by high miss rates for precancerous non- polypoid lesions. This project will develop new imaging and computational techniques for improving the detection rates of these lesions during colonoscopy screening.",Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms,9769725,R21EB024700,"['3-Dimensional', 'Address', 'Adult', 'Algorithms', 'American', 'Area', 'Biopsy', 'Caliber', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical assessments', 'Colon', 'Colonoscopes', 'Colonoscopy', 'Color', 'Colorectal', 'Colorectal Cancer', 'Colorectal Neoplasms', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Custom', 'Data', 'Detection', 'Development', 'Dyes', 'Effectiveness', 'Elements', 'Endoscopes', 'Endoscopy', 'Engineering', 'Foundations', 'Frequencies', 'Future', 'Gastroenterology', 'Goals', 'Height', 'Human', 'Hybrids', 'Image', 'Imaging Techniques', 'Interobserver Variability', 'Knowledge', 'Large Intestine', 'Lesion', 'Light', 'Lighting', 'Malignant - descriptor', 'Maps', 'Measurement', 'Measures', 'Morphology', 'Motion', 'Mucous Membrane', 'Optics', 'Patients', 'Pilot Projects', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Premalignant', 'Procedures', 'Research', 'Research Proposals', 'Resected', 'Resolution', 'Sampling', 'Shapes', 'Source', 'Spatial\xa0Frequency\xa0Domain\xa0Imaging', 'Structure', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Image', 'Time', 'Tissues', 'Training', 'United States', 'adenoma', 'base', 'chromoscopy', 'colorectal cancer risk', 'computer aided detection', 'contrast imaging', 'human study', 'imaging system', 'improved', 'innovation', 'miniaturize', 'mortality', 'mortality risk', 'novel', 'optical imaging', 'phantom model', 'prevent', 'research clinical testing', 'routine screening', 'screening', 'vector']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,327488,-0.03922957784936334
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9787575,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2019,291536,-0.02225070204084334
"Automated Diagnosis and Progression Rate of IPF Using HRCT Project Summary: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. Diagnosis and stratification of disease phenotypes are important in order to decipher the effects of novel therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individuals. Few computerized diagnostic tools have been developed for IPF that correlate with visual and surgical lung biopsy; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good predictive models with localized region exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use as a derivative dataset the anonymized clinical data and source images on 234 patients with IPF and 266 patients with IPF suspected, but not IPF based on HRCT and the surgical biopsy who have participated in multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for high through-put quantitative image analysis, we will train a classifier with features of anatomic distribution and reproducible imaging features expressed with a quantitative lung fibrosis (QLF) score, testing on separate data from in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitial Lung Disease Program. Furthermore, the second aim is to develop a rate of progression at local region and to aggregate predictive models using Cox proportional regression models, which will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that diagnose and anticipate disease course in patients with IPF and subdividing patients into more homogeneous groups prior to the development of significant respiratory impairment. We anticipate that models can be used clinically at the individual patient level to enable more informed and timely management decisions to define more homogeneous cohorts for purposes of testing new targeted therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. Relevance to Public Health: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rate of progression is highly variables, which hampers timely decisions about referral for lung transplantation or treatments using new drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to diagnose and predict disease course robustly in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with IPF and non-IPF with reducing chance of lung biopsy and predict slowly versus rapidly progressive disease, leading to more time to treat patients and timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Automated Diagnosis and Progression Rate of IPF Using HRCT,9765383,R21HL140465,"['Acute', 'Air', 'Algorithms', 'Anatomy', 'Archives', 'Automation', 'Biological', 'Biopsy', 'Categories', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease stratification', 'Elderly', 'Etiology', 'Exhibits', 'General Population', 'Glass', 'Goals', 'Growth', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Informatics', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Laboratories', 'Lobar', 'Lobe', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathology', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Prevalence', 'Probability', 'Progression-Free Survivals', 'Progressive Disease', 'Public Health', 'Pulmonary Fibrosis', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Spatial Distribution', 'Stable Disease', 'Standardization', 'Testing', 'Texture', 'Time', 'Time Management', 'Training', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinically relevant', 'cohort', 'computerized', 'data archive', 'digital imaging', 'disease natural history', 'disease phenotype', 'functional decline', 'idiopathic pulmonary fibrosis', 'image processing', 'imaging biomarker', 'improved', 'individual patient', 'individualized medicine', 'new therapeutic target', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'success', 'survival prediction', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2019,113241,-0.060763813743633696
"Adaptive & Individualized AAC The heterogeneity of the more than 1.3% of Americans who suffer from severe physical impairments (SPIs) preclude the use of common augmentative or alternative communication (AAC) solutions such as manual signs, gestures or dexterous interaction with a touchscreen for communication. While efforts to develop alternative access methods through eye or head tracking have provided some communication advancements for these individuals, all current technologies suffer from the same fundamental limitation: existing AAC devices require patients to conform to generic communication access methods and interfaces rather than the device conforming to the user. Consequently, AAC users are forced to settle for interventions that require excessive training and cognitive workload only to deliver extremely slow information transfer rates (ITRs) and recurrent communication errors that ultimately deprive them of the fundamental human right of communication. To meet this health need, we propose the first smart-AAC system designed using individually adaptive access methods and AAC interfaces to accommodate the unique manifestations of motor impairments specific to each user. Preliminary research by our team of speech researchers at Madonna Rehabilitation Hospital (Communication Center Lab) and Boston University (STEPP Lab), utilizing wearable sensors developed by our group (Altec, Inc) have already demonstrated that metrics based on surface electromyographic (sEMG) and accelerometer measures of muscle activity and movement for head-mediated control can be combined with optimizable AAC interfaces to improve ITRs when compared with traditional unoptimized AAC devices. Leveraging this pilot work, our team is now proposing a Phase I project to demonstrate the proof-of-concept that a single sEMG/IMU hybrid sensor worn on the forehead can provide improvements in ITR and communication accuracy when integrated with an AAC interface that is optimized through machine learning algorithms. The prototype system will be tested and compared to a conventional (non-adaptable) interface in subjects with SPI at a collaborative clinical site. Assistance by our speech and expert-AAC collaborators will ensure that all phases of technology development are patient-centric and usable in the context of clinical care. In Phase II we will build upon this proof-of-concept to design a smart-AAC system with automated optimization software that achieves dynamic learning which adapts to intra-individual changes in function through disease progression or training as well as inter-individual differences in motor impairments for a diverse set of users with spinal cord injury, traumatic brain injury, cerebral palsy, ALS, and other SPIs. The innovation is the first and only AAC technology that combines advancements in wearable-sensor access with interfaces that are autonomously optimized to the user, thereby reducing the resources and training needed to achieve effective person-centric communication in SPI, through improved HMI performance and reduced workload. This project addresses the fundamental mission of NIDCD (National Institute for Deafness and Communication Disorders) to provide a direct means of assisting communication for people with severe physical impairments caused by stroke, high level spinal cord injury, neural degeneration, or neuromuscular disease. Leveraging wearable access technology (which has barely been explored for AAC users), we will develop a first-of-its-kind adaptive tablet interface tailored to individual users through advanced movement classification algorithms. Through these efforts, we aim to provide an improved Human Machine Interface (HMI) that is able to accommodate varying degrees of inter- and intra-subject residual motor function and context dependent impairments to provide individuals with SPI the opportunity for improved societal integration and quality of life.",Adaptive & Individualized AAC,9907832,R43DC018437,"['Accelerometer', 'Address', 'American', 'Boston', 'Cerebral Palsy', 'Child', 'Cognitive', 'Communication', 'Communication Methods', 'Communication impairment', 'Computer software', 'Custom', 'Development', 'Devices', 'Diagnosis', 'Disease Progression', 'Ensure', 'Eye', 'Facial Muscles', 'Fatigue', 'Forehead', 'Gestures', 'Goals', 'Head', 'Head Movements', 'Health', 'Heterogeneity', 'Hospitals', 'Human Rights', 'Hybrids', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Individual Differences', 'Institutes', 'Intervention', 'Intuition', 'Learning', 'Linguistics', 'Manuals', 'Measures', 'Mediating', 'Methods', 'Mission', 'Motor', 'Motor Manifestations', 'Movement', 'Muscle', 'National Institute on Deafness and Other Communication Disorders', 'Nerve Degeneration', 'Neuromuscular Diseases', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Population Heterogeneity', 'Quality of life', 'Recurrence', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Resources', 'Series', 'Signal Transduction', 'Speech', 'Spinal cord injury', 'Stroke', 'Surface', 'System', 'Tablets', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Traumatic Brain Injury', 'United States National Aeronautics and Space Administration', 'Universities', 'User-Computer Interface', 'Variant', 'Work', 'Workload', 'alternative communication', 'base', 'classification algorithm', 'clinical care', 'clinical research site', 'communication device', 'deafness', 'design', 'experimental study', 'improved', 'innovation', 'kinematics', 'machine learning algorithm', 'mathematical model', 'motor impairment', 'novel', 'prototype', 'rehabilitation engineering', 'rehabilitation science', 'sensor', 'sensor technology', 'signal processing', 'technology development', 'touchscreen', 'two-dimensional', 'wearable device']",NIDCD,"ALTEC, INC.",R43,2019,224701,-0.04818259779906877
"ACTIVE: Abilities Captured Through Interactive Video Evaluation (DDT COA 000032) Project Summary/Abstract Technology has the potential to accelerate clinical research and reduce the burden of participation in rare diseases such as Duchenne Muscular Dystrophy (DMD). DMD is an x-linked genetic disorder that results in progressive muscle weakness with loss of ambulation by 10-12 years of age, progression of arm weakness resulting in difficulty with self-feeding and other self-care activities in adolescence, and death resulting from cardiopulmonary insufficiency by age 30 years. Studies in rare diseases are inherently difficult due to a small recruitment pool and a limited number of sites that possess the experience and resources to participate as a study site. An outcome measure that quantifies change in both ambulant and non-ambulant individuals with minimal evaluator training could enable more efficient data collection in multi-site clinical trials. Our upcoming submission, DDT COA 0032, Abilities Captured Through Interactive Video Evaluation (ACTIVE), has the potential to meet this need. ACTIVE is a 65-second game utilizing a skeletal-tracking algorithm to quantify workspace volume (WSV) elicited through maximal arm reaching overhead, side-to-side, and forward while also encouraging trunk lean in each direction. Our studies have shown that ACTIVE is valid and reliable in quantifying WSV in persons with DMD across the span of age and abilities. However, to increase access and portability of a tool for use across trial sites, it is critical that tool has sound scientific and technological construction. ACTIVE WSV was originally built upon the Microsoft Kinect and Kinect One for Xbox platforms. The skeletal tracking algorithm developed by Microsoft vastly exceeds all other programs as it had the full backing of the Microsoft machine. Unfortunately, the Kinect, in its additional sense, has been abandoned for more current artificial intelligence applications. The Microsoft Kinect Azure will soon be released with higher resolution and programming capabilities. Our full DDT submission has been delayed as each new camera release has required reprogramming of our software to ensure valid and reliable results. Our team has recently expanded to include software development partners, The Plan Works (thePlan), who have the technological expertise to alter our current codebase to ensure transfer of ACTIVE across camera sensor platforms is more efficient and reliable as we expect ongoing technological advances to provide opportunities for continued advances. To this end, our current application seeks support to verify the technology of the ACTIVE WSV system to 1) confirm the use of unique code that can be ported across platforms over time and 2) improving the ease of use and limit training needed at a growing number of inexperienced centers. Project Narrative Our upcoming submission, DDT COA 0032, Abilities Captured Through Interactive Video Evaluation (ACTIVE), is a 65-second outcome assessment that quantifies a person’s workspace volume and has the potential to expand the enrollment pool by measuring both ambulant and non-ambulant subjects. While the scientific construction of the tool is sound, ongoing technological advances and changes have made it challenging to port our software across camera platforms. Our proposal seeks funding to support final software updates to ensure changes in technology components (i.e. camera sensor systems) or coding instability will not interfere with clinical trial data collection and allow us to complete our final submission package.",ACTIVE: Abilities Captured Through Interactive Video Evaluation (DDT COA 000032),9989528,U01FD006883,[' '],FDA,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,U01,2019,215170,-1.563124347548547e-05
"CANNABIS IMPAIRMENT DETECTION APPLICATION (CIDA) (T163). SBIR PHASE II. POP: 9/20/2019-9/19/2021. N44DA-19-1218. Under this Small Business Innovation Research (SBIR) Phase I project, Research Topic 163, the Contractor will develop a portable, easily applied system incorporating a neuropsychological test protocol to detect cannabis impairment. n/a",CANNABIS IMPAIRMENT DETECTION APPLICATION (CIDA) (T163). SBIR PHASE II. POP: 9/20/2019-9/19/2021. N44DA-19-1218.,10044153,5N95019C00052,"['Algorithm Design', 'Apple', 'Biological Markers', 'Cannabis', 'Clinical Research', 'Contractor', 'Data', 'Databases', 'Detection', 'Goals', 'Health Technology', 'Impairment', 'Law Enforcement', 'Neuropsychological Tests', 'Phase', 'Procedures', 'Protocols documentation', 'Research', 'Small Business Innovation Research Grant', 'Study Subject', 'System', 'digital', 'human subject', 'machine learning algorithm', 'novel', 'novel therapeutics', 'portability', 'potential biomarker']",NIDA,"ADVANCED BRAIN MONITORING, INC.",N44,2019,1499722,0.003110398566410588
"Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. Annually, malaria affects more than 200 million people and claims the lives of over 440,000 people worldwide, mostly African children. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM and incorrect treatment. An accurate means to confirm the presence of CM or to investigate for a non-malarial illness is critically needed to improve outcomes. Since Malarial retinopathy (MR) is greater than 90% specific and sensitive to the presence of CM once clinically diagnosed, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. VisionQuest Biomedical and its collaborators have assembled a team of inter-disciplinary scientists with considerable experience in automated retinal image analysis, clinical ophthalmology with specialized research in malarial retinopathy (MR), and cerebral malaria diagnosis (CM). This team will develop and test ASPIRE, a system for detection of MR consisting of automated MR detection software integrated with a low-cost and portable retinal camera. Our proposed ASPIRE system will augment, not replace, the current CM diagnostic standard; increasing the accuracy of CM diagnoses, leading to a smaller number of false positive outcomes. In Phases I and II, the research team at VisionQuest Biomedical developed the automated MR detection software and interfaced it with a handheld retinal camera. The resulting clinical prototype of ASPIRE was tested onsite in a health-clinic in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In Phase II-B, the MR detection system will be refined, productized, and the resulting commercial prototype will be validated on prospective datasets. We will accomplish this through three specific aims. In the first aim, the software system for MR detection will be adapted and improved to work with low-cost and portable iNview camera. In the second aim, we will refine iNview’s driver-software and integrate the camera with MR detection software to produce the first commercial prototype. The third aim will focus on collecting the retinal image data for algorithm testing as well as for validating the commercial prototype in an observational clinical study to be conducted at nine clinical sites in Malawi, Uganda, and Zambia in Africa. Narrative Cerebral malaria is a life-threatening clinical syndrome associated with malarial infection, which affects about 200 million people annually and claims the lives of over 440,000 people worldwide, mostly African children. The presence of malarial retinopathy can provide additional insight and improve the diagnostic accuracy of CM. This project proposes the development of a fully-automated malaria retinopathy detection system consisting of a low-cost retinal camera and automatic malaria retinopathy detection software.",Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria,9680179,R44AI112164,"['5 year old', 'Address', 'Affect', 'Africa', 'African', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Cellular Phone', 'Cerebral Malaria', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Country', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Enrollment', 'Expert Systems', 'Foundations', 'Goals', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Image Analysis', 'Incidence', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Medicine', 'Ophthalmologist', 'Ophthalmology', 'Ophthalmoscopy', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Poison', 'Predictive Value', 'Price', 'Reporting', 'Research', 'Retinal', 'Retinal Diseases', 'Safety', 'Scientist', 'Seasons', 'Series', 'Site', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Test Result', 'Testing', 'Uganda', 'Validation', 'Work', 'Zambia', 'base', 'clinical Diagnosis', 'clinical research site', 'cost', 'cost effectiveness', 'design', 'diagnostic accuracy', 'experience', 'imaging capabilities', 'improved', 'improved outcome', 'innovation', 'insight', 'malaria infection', 'mortality', 'performance site', 'portability', 'programs', 'prospective', 'prototype', 'research study', 'response', 'retinal imaging', 'screening', 'smartphone Application', 'software development', 'software systems', 'success', 'usability']",NIAID,"VISIONQUEST BIOMEDICAL, LLC",R44,2019,587952,-0.012128422093540652
"Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. Annually, malaria affects more than 200 million people and claims the lives of over 440,000 people worldwide, mostly African children. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM and incorrect treatment. An accurate means to confirm the presence of CM or to investigate for a non-malarial illness is critically needed to improve outcomes. Since Malarial retinopathy (MR) is greater than 90% specific and sensitive to the presence of CM once clinically diagnosed, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. VisionQuest Biomedical and its collaborators have assembled a team of inter-disciplinary scientists with considerable experience in automated retinal image analysis, clinical ophthalmology with specialized research in malarial retinopathy (MR), and cerebral malaria diagnosis (CM). This team will develop and test ASPIRE, a system for detection of MR consisting of automated MR detection software integrated with a low-cost and portable retinal camera. Our proposed ASPIRE system will augment, not replace, the current CM diagnostic standard; increasing the accuracy of CM diagnoses, leading to a smaller number of false positive outcomes. In Phases I and II, the research team at VisionQuest Biomedical developed the automated MR detection software and interfaced it with a handheld retinal camera. The resulting clinical prototype of ASPIRE was tested onsite in a health-clinic in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In Phase II-B, the MR detection system will be refined, productized, and the resulting commercial prototype will be validated on prospective datasets. We will accomplish this through three specific aims. In the first aim, the software system for MR detection will be adapted and improved to work with low-cost and portable iNview camera. In the second aim, we will refine iNview’s driver-software and integrate the camera with MR detection software to produce the first commercial prototype. The third aim will focus on collecting the retinal image data for algorithm testing as well as for validating the commercial prototype in an observational clinical study to be conducted at nine clinical sites in Malawi, Uganda, and Zambia in Africa. Narrative Cerebral malaria is a life-threatening clinical syndrome associated with malarial infection, which affects about 200 million people annually and claims the lives of over 440,000 people worldwide, mostly African children. The presence of malarial retinopathy can provide additional insight and improve the diagnostic accuracy of CM. This project proposes the development of a fully-automated malaria retinopathy detection system consisting of a low-cost retinal camera and automatic malaria retinopathy detection software.",Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria,10002542,R44AI112164,"['5 year old', 'Address', 'Affect', 'Africa', 'African', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Cellular Phone', 'Cerebral Malaria', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Country', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Enrollment', 'Expert Systems', 'Foundations', 'Goals', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Image Analysis', 'Incidence', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Medicine', 'Ophthalmologist', 'Ophthalmology', 'Ophthalmoscopy', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Poison', 'Predictive Value', 'Price', 'Reporting', 'Research', 'Retinal', 'Retinal Diseases', 'Safety', 'Scientist', 'Seasons', 'Series', 'Site', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Test Result', 'Testing', 'Uganda', 'Validation', 'Work', 'Zambia', 'base', 'clinical Diagnosis', 'clinical research site', 'cost', 'cost effectiveness', 'design', 'diagnostic accuracy', 'experience', 'imaging capabilities', 'improved', 'improved outcome', 'innovation', 'insight', 'malaria infection', 'mortality', 'performance site', 'portability', 'programs', 'prospective', 'prototype', 'research study', 'response', 'retinal imaging', 'screening', 'smartphone Application', 'software development', 'software systems', 'success', 'usability']",NIAID,VISIONQUEST BIOMEDICAL INC,R44,2019,412048,-0.012128422093540652
"Medical Image Perception Society XVIII Conference MIPS XVIII brings together an international community of experts including radiologists, pathologists, other image-based clinicians, psychologists, statisticians, physicists, engineers, and computer scientists investigating the extraction of diagnostic information from medical images. The meeting forges research and learning opportunities for new students and young researchers in a dedicated forum unmatched by other meetings. MIPS XVIII is being organized by the Medical Image Perception Society (a US-based society; Elizabeth Krupinski, PhD President) in conjunction with local hosts Trafton Drew, PhD (University of Utah Psychology) and William Auffermann, MD, PhD (University of Utah Radiology); and committee Lauren Williams (University of Utah) trainee member, David Alonso trainee member (University of Utah). It will run July 14-17, 2019 at the University of Utah Guest House & Conference Center located near the University of Utah campus. Nine topic areas have been selected for MIPS XVIII, reflecting important dimensions of medical image interpretation. This year’s special focus theme is addressing other image-based specialties outside radiology. Studying how clinicians extract diagnostic information from images identifies the causes of missed diagnoses and ways to eliminate these errors. Careful design and evaluation of imaging systems are critical in view of their enormous costs. With the current emphasis in the practice of medicine on “meaningful use” and “accountable care” to improve the quality, safety, and efficiency of care, the role the clinician as decision-maker cannot be ignored. Medical image perception research develops and applies modern methods to the evaluation of observer performance in diagnostic imaging tasks. Understanding basic aspects of the perception of medical images can reduce diagnostic error and improve medical decision-making quality. This grant will support 10 students to attend and present their research at MIPS XVIII. To date, 115 students have been awarded scholarships. The primary goal in supporting these students is to create opportunities and offer supportive mentoring at this formative stage in the trainee’s career to enhance their research potential and likelihood of success. The meeting brings together researchers investigating the process of extracting diagnostic information from medical images to render accurate and efficient diagnostic decisions. Opportunities for advanced, interdisciplinary training of young scientists interested in medical image perception research and its relevance to disease prevention and treatment are often quite limited at the university level. Since 1997, 115 students have been awarded MIPS scholarships, having a significant impact on the field by creating opportunities and offering supportive mentoring at this formative stage in the trainee’s career to enhance their research potential and likelihood of success as independent basic science and clinician-scientist researchers.",Medical Image Perception Society XVIII Conference,9833051,R13EB028683,"['3-Dimensional', 'Acquired Immunodeficiency Syndrome', 'Address', 'American', 'Area', 'Attention', 'Award', 'Basic Science', 'Behavior', 'Caring', 'Clinical', 'Clinical Trials', 'Cognition', 'Cognitive', 'Color', 'Communities', 'Computers', 'Data Set', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Diagnostic radiologic examination', 'Dimensions', 'Discrimination', 'Doctor of Philosophy', 'Engineering', 'Evaluation', 'Failure', 'Fatigue', 'Frequencies', 'Goals', 'Grant', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institute of Medicine (U.S.)', 'International', 'Judgment', 'Knowledge', 'Lead', 'Learning', 'Malpractice', 'Medical', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Modern Medicine', 'Modernization', 'Ophthalmology', 'Pathologist', 'Patients', 'Pattern', 'Perception', 'Performance', 'Physician&apos', 's Role', 'Physicians', 'Population', 'Prevention', 'Process', 'Psychologist', 'Psychology', 'Psychophysics', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Running', 'Safety', 'Scholarship', 'Scientist', 'Societies', 'Students', 'Technology', 'Telemedicine', 'Training', 'United States National Institutes of Health', 'Universities', 'Utah', 'Work', 'automobile accident', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'design', 'disorder prevention', 'health care quality', 'image processing', 'imaging system', 'improved', 'interest', 'malignant breast neoplasm', 'medical specialties', 'meetings', 'member', 'outcome forecast', 'prognostic', 'radiologist', 'statistics', 'success', 'symposium', 'whole slide imaging']",NIBIB,EMORY UNIVERSITY,R13,2019,10000,0.0034430880166031654
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9784742,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data pipeline', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2019,533529,-0.013680033293577303
"Lightweight optoimpedance sensors enabling early detection of the physiological response to injury and illness Abstract Early detection of ongoing hemorrhage (OH) before onset of shock is a universally acknowledged great unmet need, and particularly important after trauma. Delays in the detection of OH are associated with a “failure to rescue” and a dramatic deterioration in prognosis once the onset of clinically frank shock has occurred. While uniplex noninvasive technologies have failed to detect or diagnose complex disease states, we have demonstrated the superiority of multiplex approaches in silico. The goal of this STTR project is to develop a commercially viable optoimpedance sensor-based system that combines state-of-the-art noninvasive sensing technologies and advanced multivariable statistical algorithms. Phase I will involve three Aims: 1) D​esign, Fabricate and Test Opto-Impedance oPiic sensors, 2) Develop of Mobile App, Data and ML Pipeline on Secure Cloud, and 3) Evaluate oPiics on an Unanesthetized Upright Porcine Hemorrhage Model. By derisking the hardware challenges, we will be well-positioned for a Phase II application to optimize oPiic design and manufacturing, fold-in predictive algorithms under current development with DOD support, and validate with a clinical trial in critical care setting. Project Narrative We have demonstrated that a multiplex approach is superior to predicting shock compared to single clinical devices alone. During a mass-casualty event, a predictive tool would need to be deployed widely, since only a fraction of individuals will have ongoing hemorrhage that will progress to decompensated shock. Optical and bioimpedance signals are critical indicators of muscle hemodynamics and electrolyte balance likely to be modified in the period leading up to shock. No commercial device exists that provides continuous, low-power, low-cost monitoring of these signals with characteristics suitable for integration with the multiplexing approach. This STTR application seeks Phase I funding to commercialize an opto-impedance sensor, called the ‘oPiic’, that will address this unmet need.",Lightweight optoimpedance sensors enabling early detection of the physiological response to injury and illness,9909081,R41EB029284,"['Address', 'Adhesives', 'Algorithms', 'Animals', 'Back', 'Benchmarking', 'Cardiovascular Physiology', 'Caring', 'Characteristics', 'Classification', 'Clinical', 'Clinical Trials', 'Complex', 'Computer Simulation', 'Computer software', 'Conscious', 'Critical Care', 'Data', 'Data Set', 'Detection', 'Deterioration', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'Disasters', 'Disease', 'Early Diagnosis', 'Electrolyte Balance', 'Event', 'Faculty', 'Failure', 'Family suidae', 'Fiber Optics', 'Funding', 'General anesthetic drugs', 'Goals', 'Hemorrhage', 'Human', 'Hydration status', 'Individual', 'Injury', 'Intensive Care', 'Learning', 'Life', 'Location', 'Measurement', 'Medical', 'Medical Device', 'Metabolism', 'Military Personnel', 'Modality', 'Modeling', 'Monitor', 'Muscle', 'Noise', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Patients', 'Phase', 'Physiological', 'Positioning Attribute', 'Postoperative Care', 'Protocols documentation', 'Resolution', 'Risk', 'Sampling', 'Secure', 'Shock', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specialist', 'Spectrum Analysis', 'Statistical Algorithm', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'Triage', 'Trust', 'Validation', 'Vertebrates', 'analog', 'base', 'clinical development', 'clinically relevant', 'college', 'cost', 'deep learning', 'design', 'effective intervention', 'electric impedance', 'electrical property', 'hemodynamics', 'instrument', 'light weight', 'mass casualty', 'member', 'miniaturize', 'mobile application', 'optical sensor', 'optimal treatments', 'outcome forecast', 'performance tests', 'portability', 'prediction algorithm', 'predictive tools', 'preservation', 'programs', 'response', 'response to injury', 'sensor', 'sensor technology', 'tissue oxygenation', 'wearable device']",NIBIB,"MULTIVARIATE SYSTEMS, INC.",R41,2019,155282,-0.0067448274986409845
"A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions Abstract. Melanoma is the third most common form of skin cancer with estimated 87,110 new cases diagnosed in the United States in the year 2017. Current routine diagnostic approaches utilize microscopic evaluation of thinly sectioned patient biopsies, but in certain cases diagnosis can be contentious even among experts. The overall goal of this multi-phase SBIR project is to develop, validate, and commercialize MelanoMap™, Frontier Diagnostics' patented assay for the diagnosis of melanoma using a matrix-assisted laser desorption/ionization imaging mass spectrometry (MALDI IMS) platform—and to have this assay available to pathologists in the U.S. as a laboratory developed test. MALDI IMS is a state-of-the-art technology that generates molecular images of tens to thousands of biomolecules from tissue sections in a single analysis. The assay uses formalin-fixed paraffin embedded (FFPE) biopsies used in routine histopathological diagnosis. The proposed assay has pathologists select regions of skin biopsies for analysis via a remote web interface. The acquired IMS data from those regions unambiguously identifies malignant melanoma or benign nevus.  Phase I of this proposal will demonstrate the feasibility of this technology platform to achieve cost-effective diagnosis of melanoma from patient skin biopsies at sample volumes acceptable for a clinical laboratory. Specific Aim 1 focuses on the development of a scalable and robust analytical protocol in both sample preparation and informatics to accurately diagnose melanoma with MALDI IMS. In specific aim 2, we will test the methodology developed in Specific Aim 1 on a cohort of melanocytic lesions with known clinical outcome and subsequently validate the classification accuracy of the proposed test  In Phase II, the protocols developed in Phase I will be integrated into a diagnostic service workflow. This phase will focus on quality control measures, client facing cloud software, clinical diagnostic reporting, and completing the analysis of a 500-patient sample set for final assay validation. Specific Aim 3 of this proposal (initial aim of Phase II) will establish and implement test tissues into standard workflows that will provide performance metrics for standard operation of a test meeting Clinical Laboratory Improvement Amendments (CLIA) standards. Protocols will be developed to monitor reagents, the reproducibility of sample preparation, and mass spectrometer performance on daily basis. Specific Aim 4 will expand software capabilities to include a secure web interface for clients ordering the test and the laboratory performing the test. The software will meet regulatory compliance, perform statistical analysis, and generate and communicate reports of the MALDI IMS analysis. Specific Aim 5 proposes to expand the sample set used in the initial assay from Specific Aim 2 to include a set of 300 patient samples from our clinical collaborators with 5 or more years follow-up data. The test will be independently validated by an additional 200 patient samples with definitive diagnoses. Project Narrative This multi-phase Fast Track SBIR project will develop and validate a new laboratory developed test to differentiate malignant melanocytic tumors from benign nevi and complete development of an imaging mass spectrometry-based diagnostic service platform for a clinical laboratory. The clinical assay developed under this proposal augments current practice by providing molecular measurements that are used as objective criteria in the diagnosis of melanoma. Successful completion of this Fast Track project will result in a fully documented and validated assay ready for launch as a laboratory developed test.",A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions,9905050,R44CA228897,"['Amendment', 'Antigens', 'Area', 'Benign', 'Biological Assay', 'Biopsy', 'Caliber', 'Cells', 'Classification', 'Client', 'Clinical', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Services', 'Digestion', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Formalin', 'Goals', 'Gold', 'Image', 'Incentives', 'Informatics', 'Laboratories', 'Legal patent', 'Lesion', 'Malignant - descriptor', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Melanocytic Neoplasm', 'Metadata', 'Methodology', 'Microscopic', 'Microtomy', 'Molecular', 'Monitor', 'Nevus', 'Outcome', 'Paraffin Embedding', 'Pathologist', 'Pathology Report', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Physical shape', 'Physicians', 'Preparation', 'Procedures', 'Proteins', 'Protocols documentation', 'Quality Control', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Retrieval', 'Sampling', 'Secure', 'Security', 'Sensitivity and Specificity', 'Side', 'Skin', 'Skin Cancer', 'Small Business Innovation Research Grant', 'Software Tools', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Standardization', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Treatment Cost', 'United States', 'Validation', 'accurate diagnosis', 'analytical method', 'base', 'clinical diagnostics', 'cloud software', 'cohort', 'cost', 'cost effective', 'data acquisition', 'diagnosis standard', 'diagnostic assay', 'disease classification', 'follow-up', 'frontier', 'histopathological examination', 'instrumentation', 'interest', 'machine learning algorithm', 'mass spectrometer', 'meetings', 'melanoma', 'molecular diagnostics', 'molecular imaging', 'mortality risk', 'off-patent', 'operation', 'prototype', 'quality assurance', 'skin lesion', 'tissue preparation', 'web interface']",NCI,"FRONTIER DIAGNOSTICS, LLC",R44,2019,998671,-0.002354929443162657
"UC Davis Alzheimer's Core Center PROJECT SUMMARY/ABSTRACT As reflected in recent budget increases in the National Institutes of Health, and in line with the National Alzheimer’s Project Act, there is a need to enhance and leverage resources to decrease dementia disparities and change the trajectory of Alzheimer’s disease and related dementias. To fill this gap, we seek to enhance the University of California Davis Alzheimer’s Disease Center (UCD ADC), which contains a diverse ethnoracial cohort (having Hispanic, Black, and non-Hispanic White decedents), through implementation of digital pathology within our Neuropathology Core. This implementation will allow for rapid transmission of pathological data for consultation and collaborations, distribution of materials for educational purposes, tissue specimen archiving, and image analysis. In addition, by having a digital pathology with immunofluorescent capabilities will allow for viewing of the distribution (including overlap) of multiple proteins at one time within a tissue specimen. This can enhance biological studies by providing spatial relationships of proteins resulting in a deeper phenotype of disease. This supplement application is designed to support equipment and leverage and enhance infrastructure to allow the UCD ADC the ability to 1) purchase a whole slide image system to digitize existing and future histologically stained samples 2) leverage and enhance current servers and database systems to allow for storage and rapid retrieval of digital images and their data and 3) leverage and enhance hardware to develop and deploy pipelines for quantitative computational methodologies for pathologies found within a diverse ethnoracial cohort of Alzheimer’s disease brains. The UCD ADC continues to excel and expand in its research initiatives to collect and provide brain specimens and pathological data on a diverse population of individuals at various stages of cognitive ability and dementia risk. This supplement will further enable suitable infrastructure for enhancement of current collaborations and facilitate emerging collaborations by providing a means to share and analysis pathology on digitized whole slide images. PROJECT NARRATIVE Digital microscopy paired with machine learning algorithms has aided in diagnosis and provide more quantitative pathology data to unlock the secrets of diseases. These technologies are needed within the dementia field, specifically in diverse cohorts, as disease presentations may differ. By implementing state of the art imaging systems and analysis, the goals of this supplement are to enhance the ADC’s ability to provide greater access to high quality pathological data for educational, consultation and collaborative purposes, infrastructure to pursue digital solutions for more quantitative analysis, and safe secure storage of histologic specimens.",UC Davis Alzheimer's Core Center,9852188,P30AG010129,"['Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Archives', 'Autopsy', 'Back', 'Basic Science', 'Biological', 'Brain', 'Brain Diseases', 'Budgets', 'California', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Consultations', 'Data', 'Database Management Systems', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Educational Materials', 'Equipment', 'Extramural Activities', 'Future', 'Generations', 'Genetic', 'Genetic Variation', 'Glass', 'Glean', 'Goals', 'Grant', 'Heterogeneity', 'Hispanics', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Individual', 'Infrastructure', 'Infusion procedures', 'Knowledge', 'Measurement', 'Measures', 'Medical Genetics', 'Methods', 'Microscope', 'Microscopy', 'Modernization', 'Neurodegenerative Disorders', 'Not Hispanic or Latino', 'Outcome', 'Paper', 'Pathologic', 'Pathologist', 'Pathology', 'Phenotype', 'Population Heterogeneity', 'Proteins', 'Publishing', 'Research', 'Research Infrastructure', 'Resources', 'Retrieval', 'Sampling', 'Scientist', 'Secure', 'Senile Plaques', 'Slide', 'Specimen', 'Stains', 'Structure', 'Systems Analysis', 'Technology', 'Thioflavin S', 'Time', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Work', 'analysis pipeline', 'base', 'beta pleated sheet', 'cognitive ability', 'cohort', 'cost effective', 'data resource', 'data sharing', 'dementia risk', 'design', 'digital', 'digital imaging', 'digital pathology', 'disease phenotype', 'histological specimens', 'histological stains', 'human tissue', 'imaging system', 'machine learning algorithm', 'neuropathology', 'novel therapeutic intervention', 'spatial relationship', 'synergism', 'transmission process', 'whole slide imaging']",NIA,UNIVERSITY OF CALIFORNIA AT DAVIS,P30,2019,289154,-0.050475856324029955
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9600285,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biological Neural Networks', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2018,194115,-0.020709508526604376
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9521289,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2018,471965,-0.02720637432496448
"Machine Learning Methods for Detecting Disease-related Functional and Structural Change in Glaucoma PROJECT SUMMARY This project aims to apply novel machine learning techniques to recently developed optical imaging measurement to improve the accurate prediction and detection of glaucomatous progression. Complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and advanced pattern recognition/machine learning-based analysis techniques can find and use that hidden information. We will use mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1,800 patient and healthy eyes, available as the result of long-term NIH funding. We also will investigate deep learning and novel statistical techniques for this purpose. The required longitudinal measurements from several newly developed optical imaging techniques were not available to our previously funded NEI- supported work. The proposed work potentially can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care by informing clinical decision-making based on mathematically based, externally validated methods. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs. PROJECT NARRATIVE The proposed project will improve machine learning techniques for predicting and detecting glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments and will make use of a very large amount of data, obtained using previously awarded NIH funds, to do so. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neuro- degeneration within the visual pathways at structural and functional levels. The development of a clinically useful novel, empirical system for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and on the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.",Machine Learning Methods for Detecting Disease-related Functional and Structural Change in Glaucoma,9517942,R21EY027945,"['Address', 'Algorithms', 'Anatomy', 'Award', 'Caring', 'Classification', 'Clinical', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Defect', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Environment', 'Eye', 'Frequencies', 'Funding', 'Future', 'Gaussian model', 'Generations', 'Glaucoma', 'Goals', 'Health Personnel', 'Image', 'Imaging Device', 'Imaging Techniques', 'Instruction', 'Laboratories', 'Lasers', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perimetry', 'Physiologic Intraocular Pressure', 'Reporting', 'Research', 'Scanning', 'Science', 'Series', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Variant', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'care providers', 'clinical care', 'clinical decision-making', 'cost', 'deep learning', 'expectation', 'glaucoma test', 'high dimensionality', 'improved', 'independent component analysis', 'instrument', 'learning strategy', 'markov model', 'mathematical model', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'recruit', 'retinal nerve fiber layer', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2018,193750,-0.010658825606696825
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9507909,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Grain', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'cognitive development', 'computerized', 'cost', 'deep learning', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'sensor technology', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2018,203125,-0.0224299567649409
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9523267,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2018,385011,-0.04256328622548262
"Left Ventricular Distribution Patterns of the Regionally varying Ischemic Myocardial Contractile Substrates Associated with Ischemic Mitral Regurgitation PROJECT SUMMARY - ABSTRACT  The loss of mitral leaflet coaptation surface area caused by restrictive chordal tethering to dysfunctional myocardial wall segments is the well-recognized mechanism of ischemic mitral regurgitation (MR). An accurate characterization of the left ventricular (LV) distribution pattern, magnitude, and reversibility of the contractile injury substrates that predispose to the occurrence of ischemic MR may improve the accuracy of therapeutic intervention. Only recently have high-resolution LV regional contractile metrics become clinically available to map myocardial ischemic substrates (hibernating, infarcted) across patient-specific LV geometry. Application of MRI-based multiparametric strain analysis in our pilot ischemic MR study group suggested that high-resolution 3D topographical mapping of LV contractile injury may reveal a more complex array of associated regional contractile injury than is discernible from echocardiography. This initial study identified a “sentinel” LV region (basilar and mid subregions of the posterior and posterolateral LV regions) in which the presence of severe contractile injury clearly predisposes to the development of ischemic MR.  We will enroll ischemic coronary artery disease patients with (≥3+ MR; n=90) and without (≤1+ MR; n=90) ischemic MR who are scheduled for standardized surgery (ACC/AHA Clinical Guidelines). Preoperative MRI- based multiparametric strain analysis will provide high-resolution 3D LV topographical maps of regional contractile injury to statistically correlate to occurrence of ischemic MR and to postoperative studies obtained at 3-months and yearly. An independent core laboratory will catalogue all echocardiography-based metrics of ischemic MR for inclusion in Support Vector Machine analyses, along with all other identified clinical variables.  MRI-based LV displacement datasets are obtained in <30 minutes using Navigator-gated Spiral Displacement ENcoding with Stimulated Echoes (DENSE). Patient-specific LV strain fields are calculated using the recently developed Radial Point Interpolation Method (RPIM). Regional contractile function is “normalized” by comparing multiple patient-specific strain metric values (at each of 11,520 LV grid points) to their respective average +/- SD values from our normal human strain database, with z- score (SD) calculation (total computer analysis <20 seconds). Support Vector Machine analyses will search all metric variables (multiparametric strain, echo-based metrics, and all clinical variables) for patterns that predict ischemic MR recurrence.  We will use high-resolution 3D topographical mapping of “normalized” LV contractile function to characterize the distribution, magnitude, and reversibility of the regional contractile injury substrates (hibernating; infarcted) associated with ischemic MR. We will then test the hypothesis that the novel application of machine learning Support Vector Machine analyses can identify hybrid combinations of both regional contractile injury patterns and clinical variables that accurately predict post-repair recurrence of ischemic MR. PROJECT NARRATIVE  Since the loss of mitral leaflet coaptation surface area caused by restrictive chordal tethering to dysfunctional myocardial wall segments is the well-recognized mechanism of ischemic mitral regurgitation, an accurate characterization of the left ventricular distribution pattern, magnitude, and reversibility of the contractile injury substrates (hibernating/infarcted) that predispose to the occurrence of ischemic mitral regurgitation may improve the accuracy of therapeutic intervention. Only recently have high-resolution LV regional contractile metrics become clinically available to map these myocardial ischemic substrates across patient-specific LV geometry. We will test the hypothesis that in patients with ischemic CAD, the ischemic status of a 4-subregion “sentinel” zone (basilar/mid subregions of posterior/posterolateral regions) is the primary determinant of the presence of significant ischemic MR and that three defining ischemic substrate (infarcted, hibernating) characteristics (location, magnitude, and reversibility) can be used in a hybrid model to predict recurrence of ischemic MR.",Left Ventricular Distribution Patterns of the Regionally varying Ischemic Myocardial Contractile Substrates Associated with Ischemic Mitral Regurgitation,9769299,R56HL136619,"['Angiography', 'Anterolateral', 'Area', 'Cardiac', 'Catalogs', 'Characteristics', 'Clinical', 'Complex', 'Computer Analysis', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Vessels', 'Correlation Studies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dyskinetic syndrome', 'Echocardiography', 'Electrocardiogram', 'Enrollment', 'Geometry', 'Guidelines', 'Hibernation', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Infarction', 'Injury', 'Laboratories', 'Left', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Methodology', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Myocardial', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Postoperative Period', 'Radial', 'Recovery', 'Recurrence', 'Resolution', 'Schedule', 'Sentinel', 'Severities', 'Standardization', 'Surface', 'Testing', 'Therapeutic Intervention', 'Time', 'Troponin', 'Ventricular', 'base', 'improved', 'mathematical model', 'novel', 'papillary muscle', 'prognostic', 'repaired', 'response']",NHLBI,WASHINGTON UNIVERSITY,R56,2018,389375,-0.02753441601463865
"Extracting rich information from biological images Project Summary  Most laboratories studying biological processes and human disease use microscopes to image samples. Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.  The principal investigator envisions bringing transformative image analysis and machine learning algorithms and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in 3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­ scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image analysis into complex workflows with other software for microscope control, cloud computing, and data mining.  The PI will also pioneer novel algorithms and approaches changing the way images are used in biology, including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines. Public Health Relevance/Narrative Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering computational techniques and software that will change the way microscopy images are used in biology. Biologists will use the resulting software to tackle fundamentally new problems using quantitative image analysis, including detecting changes in the appearance of cells that are overlooked by human vision and studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the context of dozens of projects addressing important fundamental biological questions and world health problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source image analysis software, CellProfiler.",Extracting rich information from biological images,9708392,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,128747,-0.01249165721945016
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9474630,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,695400,-0.011483251551786536
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9402599,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2018,318898,-0.0673611838610588
"Functional and Structural Optical Coherence Tomography for Glaucoma PROJECT SUMMARY Glaucoma is a leading cause of blindness. Early diagnosis and close monitoring of glaucoma are important because the onset is insidious and the damage is irreversible. Advanced imaging modalities such as optical coherence tomography (OCT) have been used in the past 2 decades to improve the objective evaluation of glaucoma. OCT has higher axial spatial resolution than other posterior eye imaging modalities and can precisely measure neural structures. However, structural imaging alone has limited sensitivity for detecting early glaucoma and only moderate correlation with visual field (VF) loss. Using high-speed OCT systems, we have developed novel OCT angiography technologies to image vascular plexuses that supply the retinal nerve fibers and ganglion cells damaged by glaucoma. Our results showed that OCT angiographic parameters have better correlation with VF parameters. We have also found that measurement of focal and sectoral glaucoma damage using high-definition volumetric OCT angiographic and structural parameters improves diagnostic performance. The goal of the proposed project is to further improve the diagnosis and monitoring of glaucoma using ultrahigh-speed OCT and artificial intelligence machine learning techniques. The specific aims are: 1. Develop quantitative wide-field OCT angiography. We will develop a swept-source OCT prototype that  is 4 times faster than current commercial OCT systems. The higher speed will be used to fully sample the  neural structures and associated capillary plexuses damaged by glaucoma. 2. Simulate VF by combining structural and angiographic OCT. Preliminary results showed that both  structural and angiographic OCT parameters have high correlation with VF on a sector basis. It may be  possible to accurately simulate VF results by combining these parameters using an artificial neural  network. The simulated VF may be more precise and reliable than subjective VF testing. 3. Longitudinal clinical study in glaucoma diagnosis and monitoring. Our novel OCT structural and  angiographic parameters have high accuracy in diagnosing glaucoma. Neural network analysis of structural  and angiographic data from a larger clinical study could further improve diagnostic accuracy. Longitudinal  follow-up will assess if simulated VF could monitor disease progression as well as actual VF. 4. Clinical study to assess the effects of glaucoma treatments. Preliminary results suggest that OCT  angiography could detect the improvement in capillary density after glaucoma surgery and the effects of  drugs. These intriguing effects will be tested in before-and-after comparison studies. If successful, we will have an OCT diagnostic system that in minutes provides objective information on the location and severity of glaucoma damage. This approach could replace time-consuming and unreliable VF testing. Measuring the improvement in retinal circulation could be a quicker way to detect the benefit of glaucoma therapies that work through neuroprotection or regeneration, compared to monitoring VF. PROJECT NARRATIVE Optical coherence tomography is a high-resolution imaging technology that can non-invasively measure both the eye structures and small blood vessels that are damaged by glaucoma, a leading cause of blindness. The proposed research will further improve this technology so that it can provide detailed measurement over wider areas inside the eye, detect earlier stages of glaucoma, evaluate the location and severity of glaucoma damage, monitor disease progression, and provide more timely assessment of the effectiveness of therapy. A goal of this project is to determine if this objective imaging technology can provide information that is equivalent to or better than subjective visual field testing, which though time-consuming and poorly reliable, is the current gold standard for long-term monitoring and management of glaucoma.",Functional and Structural Optical Coherence Tomography for Glaucoma,9564111,R01EY023285,"['Abbreviations', 'Affect', 'Angiography', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Biological Neural Networks', 'Biomedical Engineering', 'Blindness', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Clinical', 'Clinical Research', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Effectiveness', 'Evaluation', 'Eye', 'Eyedrops', 'Functional disorder', 'Future', 'Geography', 'Glaucoma', 'Glossary', 'Goals', 'Gold', 'Grant', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Lasers', 'Location', 'Longitudinal observational study', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Monitor', 'Natural regeneration', 'Nerve Fibers', 'Noise', 'Operative Surgical Procedures', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Pathway Analysis', 'Patients', 'Performance', 'Perfusion', 'Pharmaceutical Preparations', 'Physiologic Intraocular Pressure', 'Postoperative Period', 'Research', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Role', 'Safety', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Shunt Device', 'Signal Transduction', 'Source', 'Speed', 'Staging', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trabeculectomy', 'Variant', 'Vision', 'Visit', 'Visual Fields', 'Work', 'analytical tool', 'artificial neural network', 'base', 'bulk motion', 'cell injury', 'clinical practice', 'cost', 'density', 'diagnostic accuracy', 'fiber cell', 'field study', 'follow-up', 'ganglion cell', 'glaucoma surgery', 'high resolution imaging', 'high risk', 'imaging modality', 'improved', 'innovation', 'insight', 'macula', 'neuroprotection', 'new technology', 'novel', 'prototype', 'quantitative imaging', 'relating to nervous system', 'screening', 'tool', 'treatment effect', 'vascular factor', 'visual performance']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,564228,-0.013645371831079521
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9518217,R01HL142036,"['Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Simulation', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2018,392932,-0.028635669580790304
"Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis Project Summary Blood culture sensitivity in neonates is poor but is the “Gold Standard” for the diagnosis of sepsis. Universal genotyping of pathogen genomic sequences using High Resolution Melt (U-HRM) provides a simple, low cost, rapid, and modern alternative to blood culture testing. By measuring the fluorescence of an intercalating dye as PCR-amplified pathogen DNA fragments are heated and disassociate, sequence defined melt curves are generated with single-nucleotide resolution in a closed-tube reaction. We have advanced U- HRM into a digital PCR format (U-dHRM), where DNA sequences that are present in mixtures are individually amplified and identified as is needed for polymicrobial infections. We have also established unique signature melt curves for 37 bacterial species that commonly infect older children and adults and automatically identify them using machine learning technology. With the goal of creating an accurate and valid test for the timely diagnosis of neonatal sepsis, we will advance this technology to identify unique fungal, viral, and bacterial HRM signatures along with antibiotic resistance genes with an accuracy of 99-100% on minimal blood volume (1mL). Our aims are: Aim 1. Optimize and assess the U-dHRM platform for neonatal bacteremia diagnosis by expand our bacterial database (13 additional bacteria) to detect causes of >99% of neonatal bacterial infections, expand our antibiotic resistance gene database to include five clinically actionable genes, and assessing the performance of the system for bacteremia diagnosis in mock and clinical whole blood samples; Aim 2. Advance the U-dHRM platform for simultaneous detection of fungal and viral pathogens by upgrading our optical system to enable expansion to fungal and viral detection in a high-throughput format, multiplexing the assay to expand to viral and fungal pathogens causing >99% non-bacterial infections, and conducting analytical validation of the multiplexed platform using mock whole blood samples; and Aim 3. Advance the machine learning algorithm for detection of emerging pathogens by developing and integrating an anomaly detection algorithm for reporting emerging pathogens that are not included in our database and validating the algorithm using data generated in Aims 1 and 2. Thus, this proposal directly addresses the funding call by applying a multidisciplinary approach to overcome the biomedical challenge of rapidly diagnosis sepsis, a hidden public health disaster. Project Narrative Digital High Resolution Melting (dHRM) of DNA combined with machine learning creates unique “fingerprints"" for microbes and antibiotic resistance, allowing for faster and more precise detection and treatment of pathogen(s) causing sepsis. This project will advance and test the clinical performance of dHRM technology in the diagnosis of neonatal sepsis. Our goal is to rapidly and accurately identify pathogens and their resistance markers to facilitate accurate antimicrobial therapy, reducing antibiotic overuse in non-infected infants.",Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis,9596299,R01AI134982,"['Address', 'Adult', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Biological Assay', 'Birth Weight', 'Blood', 'Blood Volume', 'Blood specimen', 'Child', 'Clinical', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disasters', 'Dyes', 'Emerging Technologies', 'Exposure to', 'Fingerprint', 'Fluorescence', 'Funding', 'Genes', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Hour', 'Immune response', 'Individual', 'Infant', 'Infection', 'Machine Learning', 'Measures', 'Microbe', 'Modernization', 'Neonatal', 'Nucleotides', 'Optics', 'Organism', 'Patients', 'Performance', 'Predisposition', 'Public Health', 'RNA', 'Reaction', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Sampling', 'Sepsis', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tube', 'United States', 'Validation', 'Variant', 'Very Low Birth Weight Infant', 'Viral', 'Whole Blood', 'Woman', 'antimicrobial', 'base', 'circulating DNA', 'clinically actionable', 'clinically relevant', 'cost', 'diagnosis standard', 'digital', 'early onset', 'interdisciplinary approach', 'intrapartum', 'melting', 'microbial', 'neonatal sepsis', 'neonate', 'overtreatment', 'pathogen', 'pathogen genome', 'point of care', 'premature', 'rapid diagnosis', 'resistance gene', 'sample collection', 'septic', 'therapy resistant', 'viral detection']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2018,437420,-0.023811475882947547
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9592472,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Topical Corticosteroids', 'Translating', 'Transplantation', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2018,240000,-0.010091561410279209
"Automating Real-Time Localization of Target Sites in Catheter Ablation of Ventricular Tachycardia Project Summary Ventricular tachycardia (VT) is an important cause of mortality and morbidity in patients with heart diseases. The majority of life-threatening VT episodes are caused by an electrical ""short circuit” that travels through narrow strands of surviving tissue inside myocardial scar. Catheter ablation treats scar-related VT by “blocking” the surviving channel that forms the circuit, commonly at the site the circuit exits from the scar. To localize a VT exit, however, remains a significant challenge. A common approach, known as pace-mapping, utilizes the principle that the VT exit serves as the origin of ventricular activation and determines the QRS morphology on 12-lead electrocardiograms (ECGs). It thus involves repetitive electrical simulation at various sites of the heart, until locating the site that reproduces the QRS of the VT on all 12 ECG leads. While the principle behind pace- mapping is time tested, the current practice is of a ""trial-and-error"" nature and requires rapid qualitative interpretation of the ECG by clinicians, which can be time-consuming and inaccurate. This research proposes to leverage modern machine learning techniques to reform the way the principle behind pace-mapping is used. It aims to learn the relationship between the origin of ventricular activation and ECG morphology, and then use it to directly predict the exit of a VT from its ECG data. To this end, this project will include the following activities: 1) to develop a population-based model to provide pre-procedural initial localizations of VT exits using standard 12-lead ECG; 2) to integrate the population-based model with a patient-specific model in clinically-usable software to provide intra-procedural real-time guidance for localizing the exit site of a clinical VT; and 3) to assess the ability of the proposed software to improve the efficiency and accuracy of pace- mapping in a prospective clinical study. This project will be carried out by a multidisciplinary team of computational and clinical scientists with a fruitful record of collaboration. The software delivered by this project will provide real-time assistance to clinicians for narrowing down a VT exit with a minimum amount of time and localization errors. This will substantially reduce the workload for ablating multiple VTs, potentially allowing clinicians to ablate more or even all VTs seen in a procedure. This may reduce the duration of an ablation procedure while improving its outcome. The development and deployment of the software also adds minimal cost or distractions to routine workflow. With a low barrier to clinical implementation, it will have a real potential to challenge and improve the standard practice of catheter ablation. Project Narrative Catheter ablation treats ventricular arrhythmia by destroying the culprit tissue responsible for the arrhythmia. To localize the culprit tissue, however, remains a tedious process with limited success in current practice. This project will develop inexpensive software to guide clinicians towards the culprit tissue in real time during the procedure, helping narrow down the ablation target with a minimum amount of time and localization errors.",Automating Real-Time Localization of Target Sites in Catheter Ablation of Ventricular Tachycardia,9590857,R15HL140500,"['Ablation', 'Arrhythmia', 'Attention', 'Cardiac ablation', 'Cicatrix', 'Clinical', 'Clinical Research', 'Collaborations', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Data Set', 'Development', 'EKG QRS Complex', 'Electrocardiogram', 'Encapsulated', 'Goals', 'Heart', 'Heart Diseases', 'Hybrids', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Morphology', 'Myocardial', 'Nature', 'Outcome', 'Patients', 'Population Database', 'Procedures', 'Process', 'Recurrence', 'Research', 'Scientist', 'Site', 'Techniques', 'Testing', 'Time', 'Tissues', 'Travel', 'Variant', 'Ventricular', 'Ventricular Arrhythmia', 'Ventricular Tachycardia', 'Workload', 'clinical implementation', 'cost', 'deep learning', 'design', 'distraction', 'improved', 'interest', 'mortality', 'multidisciplinary', 'novel', 'population based', 'prevent', 'prospective', 'simulation', 'software development', 'success', 'sudden cardiac death', 'usability']",NHLBI,ROCHESTER INSTITUTE OF TECHNOLOGY,R15,2018,419810,-0.019611865018155858
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. Narrative There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9680657,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'professional atmosphere', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2018,449918,-0.0034448416022718627
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9499823,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Research Infrastructure', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radiofrequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2018,416374,-0.03416532809363495
"IGF::OT::IGF SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track) The overall objective of this Fast-Track SBIR contract project is to develop DigiBioMarCTM (Digital BioMarkers for Clinical Impact), a scalable and flexible cloud-based platform to capture and analyze wearable, implantable, or external device data. This platform also provides an informatics tool for automated data aggregation, integration, and machine learning algorithms. It is based on the scalable user-centered Medable platform, which implements standardization and normalization of patient-generated data to drive health insights. DigiBioMarCTM will compare and combine disparate data streams to understand contextualized patient physiology in real time in order to identify disease and/or detect changes in disease/health status. It also will support cohort and clinical studies, particularly those testing digital biomarkers from wearable sensor technologies. This Fast-Track project will focus on product development with an ultimate aim of a product that improves cancer research data and clinical trials, enhances clinical care, and that can be used to engage patients in preventive health behaviors and treatment adherence. The Phase I goal is to develop a data-agnostic DigiBioMarCTM prototype for validation in Phase II. The Phase 1 Go/No-Go decision point to proceed to Phase II will be a working prototype with specified features for further development and validation in Phase II. n/a",IGF::OT::IGF SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track),9788845,61201800010C,"['Algorithms', 'Biological Markers', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Computer software', 'Contracts', 'Data', 'Data Aggregation', 'Development', 'Devices', 'Disease', 'Documentation', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Informatics', 'Machine Learning', 'Patients', 'Phase', 'Physiology', 'Preventive', 'Publishing', 'Reporting', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Standardization', 'Stream', 'System', 'Testing', 'Time', 'Validation', 'anticancer research', 'base', 'clinical care', 'cloud based', 'digital', 'flexibility', 'graphical user interface', 'improved', 'insight', 'knowledge base', 'product development', 'prototype', 'sensor', 'skills', 'tool', 'treatment adherence', 'wearable sensor technology']",NCI,"MEDABLE, INC.",N01,2018,224294,0.0027825903994410273
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9496652,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Decubitus ulcer', 'Diabetic Foot Ulcer', 'Diabetic wound', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2018,425994,-0.020245141230480924
"Development of label-free computational flow cytometry for high-throughput micro-organism classification The purpose of flow cytometers is to enable the classification of cells or organisms at high throughput. Label-free optical flow cytometers not based on fluorescence are generally based on scattering. The most common of these compares the amount of forward (FS) versus side (SS) scattering. Such two-parameter information permits rudimentary classification based on size or granularity, but it misses more subtle features that can be critical in defining organism identity. Nevertheless, FS/SS flow cytometry remains popular, largely because of its simplicity and capacity for high throughput.  We propose to develop a label-free computational flow cytometer that preserves much of the simplicity and high-throughput capacity of FS/SS flow cytometry, but provides significantly enhanced information. Instead of characterizing organisms based on scattering direction (as does FS/SS flow cytometry), we will characterize based on scattering patterns. We will insert a reconfigurable diffractive element in the imaging optics of a flow cytometer to route user-defined basis patterns to independent detectors. The basis patterns will be optimally matched to specific sample features. The respective weights of these basis patterns will serve as signatures to identify organisms of interest. The basis patterns themselves will be determined by machine learning algorithms. Both the device and the learning algorithms will be developed from scratch.  We anticipate that our flow cytometer will be able to operate at flow rates on the order of meters per second, commensurate with state-of-the-art FS/SS flow cytometers, while providing significantly more information for improved classification capacity. While our technique should be advantageous for any label-free flow cytometry application requiring high throughput, we will test it here by demonstrating high-throughput classification of microbial communities. NARRATIVE Our goal is to improve the information extraction capacity of label-free flow cytometers, while maintaining high throughput capacity. As such, our device should have a broad range of applications.",Development of label-free computational flow cytometry for high-throughput micro-organism classification,9510096,R21GM128020,"['Address', 'Algorithms', 'Awareness', 'Bioinformatics', 'Biological', 'Biology', 'Categories', 'Cells', 'Classification', 'Communities', 'Custom', 'Detection', 'Development', 'Devices', 'Elements', 'Flow Cytometry', 'Fluorescence', 'Goals', 'Image', 'Image Compression', 'Label', 'Learning', 'Light', 'Machine Learning', 'Measurement', 'Microbe', 'Modernization', 'Optics', 'Organism', 'Pattern', 'Performance', 'Pupil', 'Resolution', 'Route', 'Sampling', 'Side', 'Signal Transduction', 'Specificity', 'Speed', 'Techniques', 'Testing', 'Traction', 'Validation', 'Weight', 'base', 'cellular imaging', 'cost', 'cost effective', 'design', 'detector', 'improved', 'interest', 'meter', 'microbial community', 'microorganism', 'microorganism classification', 'optical imaging', 'prototype', 'recruit']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2018,239527,-0.01575320245299879
"A Customizable Real-Time Biosensor for Continuous Monitoring of Water Contaminants Ensuring access to clean water for generations to come will involve developing novel ap- proaches to determining the safety and composition of potable water that are practical and afford- able. Arsenic, mercury, and cadmium are three of the top priorities among hazardous substances commonly found at Superfund sites, as they are linked to health problems in people exposed to them in drinking water, yet the current real-time monitoring methods for these and other contam- inants are either extremely costly or nonexistent, making it difﬁcult to monitor water quality with high spatial or temporal resolution. QBiSci is developing a biosensor that uses synthetic micro- bial sensor strains that ﬂuoresce in response to speciﬁc toxins to continuously monitor water for contamination. The platform will substantially improve upon currently available technologies for toxin detection, making monitoring more affordable, continuous, and ﬁeld-deployable. Speciﬁc Aim 1: To fully characterize three synthetic E. coli strains that speciﬁcally detect ar- senic, mercury, and cadmium in a continuous water stream. For a real-time sensor to be maxi- mally effective, it must be able to report accurate toxin concentrations in real-time. Focusing on three of the highest priority contaminants as a proof of feasibility, comprehensive data will be acquired to train a machine learning algorithm to be able classify real-world samples in real-time. Speciﬁc Aim 2: To develop and train a classiﬁcation algorithm to recognize the type and amount of each contaminant present in a continuous water stream. The ability to analyze and interpret data in real-time from a constantly ﬂuctuating water source will require an extensive classiﬁcation train- ing effort. QBiSci's existing machine learning framework will be trained and tested using many contamination induction scenarios, ranging from sudden pulses to subtly varying concentrations. Speciﬁc Aim 3: To develop a microﬂuidic cartridge system that reduces device complexity and enables sensor deployment with minimal intervention. QBiSci will develop a swappable car- tridge system using devices that are pre-loaded with biologically-stable strains and can simply be “plugged in” to the sensor platform to achieve repeatable results in a user-friendly manner. The development of a method for thermoplastic device fabrication will enable the more precise connections required for a cartridge clamping system that will require little operational expertise.  A successful outcome of this proposal will lead to a biosensor capable of real-time quantiﬁca- tion of arsenic, mercury, and cadmium in a continuous water input. A future Phase II proposal would focus on real-world performance evaluations of our sensors via deployment in areas of con- cern and comparison of our results to standard techniques as well as an expansion of the platform to detect other contaminants quantitatively and continuously. 1 Access to clean, reliable water supplies is critical to our quality of life and our economy, yet across the country over 100,000 hazardous waste sites are so heavily contaminated that the un- derlying groundwater doesn't meet drinking water standards. While there is a wide range of toxins found at these sites, arsenic, mercury, and cadmium are among the most common offend- ers, all of which have been linked to a variety of health problems ranging from cancer to dia- betes as well as behavior and neurological disorders. We are developing a customizable real-time biosensor that will enable contamination monitoring to become more affordable, continuous, and ﬁeld-deployable and will facilitate improved management decisions aimed at reducing toxin con- centrations in the environment, tracking the progression of contamination plums, and targeting investments in remediation efforts. 1",A Customizable Real-Time Biosensor for Continuous Monitoring of Water Contaminants,9467134,R43ES028993,"['Algorithms', 'Area', 'Arsenic', 'Behavior Disorders', 'Biological', 'Biosensor', 'Cadmium', 'Classification', 'Closure by clamp', 'Country', 'Data', 'Detection', 'Development', 'Devices', 'Diabetes Mellitus', 'Ensure', 'Environment', 'Escherichia coli', 'Evaluation', 'Exposure to', 'Fluorescence', 'Future', 'Generations', 'Goals', 'Hazardous Substances', 'Hazardous Waste Sites', 'Health', 'Intervention', 'Investments', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mercury', 'Methods', 'Microfluidics', 'Monitor', 'Outcome', 'Performance', 'Phase', 'Physiologic pulse', 'Plug-in', 'Plum', 'Quality of life', 'Reporting', 'Research', 'Research Infrastructure', 'Risk', 'Safety', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Water', 'Water Supply', 'contaminated water', 'cost', 'drinking water', 'ground water', 'improved', 'innovation', 'microbial', 'nervous system disorder', 'novel', 'novel strategies', 'operation', 'real time monitoring', 'remediation', 'response', 'sensor', 'simulation', 'superfund site', 'temporal measurement', 'user-friendly', 'water quality']",NIEHS,"QUANTITATIVE BIOSCIENCES, INC.",R43,2018,162205,-0.005811962514171044
"A computational approach to early sepsis detection Abstract Significance: In this SBIR project, we propose to improve the performance of InSight, a machine-learning- based sepsis screening system, in situations of limited training data from the target clinical site. The proposed work will make possible prospective clinical deployments to sites which are smaller or lack clinical data repositories, by significantly reducing the amount of training data necessary down to a few weeks of clinical observation. Classically, a machine-learning-based system like InSight requires complete retraining for each new clinical setting, in turn requiring a new and large collection of data from each target deployment site. We will circumvent this requirement via transfer learning techniques, which transfer knowledge acquired previously in a source clinical setting to a new, target setting. Research Questions: Which transfer learning methods and paired classification algorithms are most suitable for use with InSight, requiring minimal target-site training data while maintaining strong performance? Are these methods and algorithms robust across the several common sepsis-spectrum definitions? Prior Work: We have developed InSight using the MIMIC-III retrospective data set, on which it attains an area under the receiver operating characteristic curve (AUROC) of 0.88 for sepsis detection, and 0.74 for 4-hour early sepsis prediction. We have also conducted pilot transfer learning  ≥ experiments in a different clinical task, mortality forecasting, in which transfer learning yields a 10-fold reduction in the amount of target-site training data required to achieve AUROC 0.80. Specific Aims: Aim 1 - to implement and assess side-by-side four diverse transfer learning methods for a retrospective clinical sepsis prediction task, where the source data set is MIMIC-III and the simulated clinical target is a data set drawn from UCSF. Aim 2 - to determine which among the best methods from Aim 1 also provide robust performance when applied to two additional sepsis-spectrum gold standards. Methods: We will prepare implementations of transfer learning methods which use instance transfer, residual learning and/or feature augmentation, kernel length scale transfer, and feature transfer. We will test these methods with applicable classifiers on subsets of the UCSF set, using cross-validation and quantifying discrimination performance in terms of AUROC. The best method/classifier pairs will require no more than 30 examples of septic patients from the target set and attain AUROC superiorities of 0.05 in 0- and 4-hour pre-onset sepsis prediction/detection, relative to the best tested alternative screening systems (Aim 1). The top three pairs will then be tested for robustness to gold standard choice, using septic shock (0- and 4-hour) and SIRS-based sepsis (0-hour) gold standards; in these tests, at least one pair must again attain 0.05 margin of superiority in AUROC versus the alternative screening systems (Aim 2). Future Directions: The results of these experiments will enable InSight to be robustly deployed to diverse clinical sites, yielding high performance without the need for extensive target-site data acquisition. Narrative Clinical decision support (CDS) systems present critical information to medical professionals by examining patient data and providing relevant information. Machine learning is a powerful method for creating CDS tools, but accessing its full strength requires re-training with retrospective data from each target clinical site. We will use transfer learning techniques to dramatically reduce the amount of target-site training data required by InSight, our machine-learning-based CDS tool for sepsis prediction, and empirically evaluate several such methods on a patient data set, using three different sepsis-related gold standards.",A computational approach to early sepsis detection,9557664,R43TR002221,"['Address', 'Age', 'Algorithms', 'Area', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Collection', 'Custom', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Discrimination', 'Drops', 'Early Diagnosis', 'Early Intervention', 'Future', 'Gold', 'Healthcare', 'Healthcare Systems', 'Hour', 'Image', 'Immune response', 'Institution', 'Knowledge', 'Learning', 'Length', 'Machine Learning', 'Medical', 'Methods', 'Multicenter Studies', 'Nature', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Psychological Transfer', 'Receiver Operating Characteristics', 'Research', 'Residual state', 'Risk', 'SCAP2 gene', 'Sensitivity and Specificity', 'Sepsis', 'Septic Shock', 'Severities', 'Side', 'Site', 'Small Business Innovation Research Grant', 'Source', 'Survival Rate', 'System', 'Techniques', 'Testing', 'Training', 'Validation', 'Work', 'base', 'clinical data warehouse', 'clinical decision support', 'clinical research site', 'cost', 'data acquisition', 'experimental study', 'improved', 'insight', 'learning strategy', 'mortality', 'performance site', 'portability', 'prospective', 'screening', 'septic', 'septic patients', 'success', 'support tools']",NCATS,"DASCENA, INC.",R43,2018,310782,-0.010421919655723224
"Quantifying NETosis via Automated High Content Imaging Convolutional Neural Networks PROJECT SUMMARY NETosis was identified as a distinct mode of cell death in neutrophils more than a decade ago. Dysregulation of NETosis has been implicated in the etiology of human pathologies such as preeclampsia, sickle cell disease, systemic lupus erythematosus, multiple sclerosis, rheumatoid arthritis, sepsis, cystic fibrosis, lupus nephritis, and coagulopathies that include cancer-associated thrombosis. The literature consistently cites the lack of a standardized methodology for quantitation of NETosis as an impediment to basic and translational research. Thus, the premise is that there is a compelling, unmet need for a standardized, quantitative and automated method for the measurement of NETosis to accelerate neutrophil and inflammation-based research and facilitate the discovery and development of therapeutic compounds. The scope of this STTR project is to develop a high-throughput image analysis and quantitation method by using high content imaging and the revolutionary technology of convolutional neural networks (CNN) for the identification and quantitation of NETosis in human neutrophils. The target readout is based on the primary morphological difference between NETotic and non-NETotic nuclei--the decondensation of chromatin. This image-based quantitative method will be observer-independent and will enable robust and rapid evaluation of a large number of samples that would exceed any attempts at manual assessment. In Phase I we will complete the following Specific Aims: Aim 1: Optimize and standardize the high- throughput platform for quantitation of NETosis in adherent human neutrophils. This includes standard assay optimization procedures, training the CNN to identify and quantitate NETotic neutrophil, and demonstrating that the CNN reliably distinguishes between necrosis and NETosis, whose phenotypes appear similar to the human eye. Aim 2: Validate the NETosis assay biochemically and clinically. This includes concentration-response assays with NETosis agonists, assessment of NETosis inhibitors, and evaluation of the NETotic status of Sickle Cell Disease patient samples (a disease in which aberrant NETosis has been implicated). The expected outcome of this Phase I effort is to demonstrate proof-of-concept for this automated high- throughput NETosis assay. Further, we expect to provide insight into the utility of the assay for assessment of inhibitors of NETosis as therapeutic agents. Upon completion of our Phase I aims, our Phase II program will focus on further optimizing and validating this NETosis assay and preparing it for commercialization.   PROJECT NARRATIVE Aberrant NETosis has been implicated in the etiology of several inflammatory and autoimmune diseases. The lack of a standardized, quantitative and automated method for the measurement of NETosis is impeding basic and translational research. We have developed a high-throughput assay using convolutional neural networks to quantify NETosis in human neutrophils. This assay will accelerate neutrophil and inflammation-based research and facilitate the discovery and development of compounds with therapeutic potential.",Quantifying NETosis via Automated High Content Imaging Convolutional Neural Networks,9465292,R41AI131840,"['Agonist', 'Apoptosis', 'Autoimmune Diseases', 'Basic Science', 'Benchmarking', 'Biochemical', 'Biochemical Pathway', 'Biological Assay', 'Biological Neural Networks', 'Blood Coagulation Disorders', 'Caymans', 'Cell Death', 'Cell Death Process', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Clinical', 'Cystic Fibrosis', 'DNA', 'Data', 'Development', 'Diagnostic', 'Diagnostic tests', 'Diagnostics Research', 'Disease', 'Drug Screening', 'Ensure', 'Enzymes', 'Etiology', 'Evaluation', 'Eye', 'Histones', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Impairment', 'Infection', 'Inflammation', 'Inflammatory', 'Innate Immune Response', 'Letters', 'Literature', 'Lupus Nephritis', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Morphology', 'Multiple Sclerosis', 'Nature', 'Necrosis', 'Nuclear', 'Opportunistic Infections', 'Outcome', 'Pathway interactions', 'Patients', 'Peptide Hydrolases', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physical condensation', 'Population', 'Pre-Eclampsia', 'Predisposition', 'Procedures', 'Process', 'Publishing', 'Reproducibility', 'Research', 'Rheumatoid Arthritis', 'Sampling', 'Sepsis', 'Severity of illness', 'Sickle Cell Anemia', 'Side', 'Small Business Technology Transfer Research', 'Specificity', 'Stains', 'Standardization', 'Systemic Lupus Erythematosus', 'Technology', 'Therapeutic', 'Therapeutic Agents', 'Thrombosis', 'Training', 'Translational Research', 'antimicrobial', 'antimicrobial peptide', 'base', 'commercial application', 'commercialization', 'extracellular', 'high throughput screening', 'inhibitor/antagonist', 'innovation', 'insight', 'neutrophil', 'novel', 'patient population', 'predictive test', 'programs', 'response', 'suicidal', 'symptom management', 'therapeutic development', 'tool']",NIAID,"EPICYPHER, INC.",R41,2018,299751,-0.015613751990258534
"Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology ABSTRACT Acute infections of the middle ear (acute otitis media - AOM), are the most commonly treated childhood disease. Treatment is fueled by concern for complications and effects on children's cognitive and language development. The financial burden of AOM is estimated at more than $5 billion per year. Because AOM is so common, a major societal problem is the over-diagnosis and over-treatment of this disease, as a result of two factors: First, accurately diagnosing AOM is difficult, even for experienced primary care or ear, nose, and throat (ENT) physicians. Second, with a growing shortage of primary care physicians in the US, more Nurse Practitioners and Physician Assistants serve as first-line clinicians in primary care settings, but lack extensive training in otoscopy (i.e. clinical examination of the eardrum). Consequently, practitioners often err on the side of making a diagnosis of AOM and prescribing oral antibiotics. Over 8 million unnecessary antibiotics are prescribed annually, contributing to the rise of antibiotic-resistant bacteria, and creating the largest number of pediatric medication-related adverse events. Many children with inaccurate diagnoses of AOM are referred to ENTs for surgical placement of ear tubes, and up to 70% of these cases are not indicated. Diagnosing AOM still depends on clinician subjectivity, based on a brief glimpse of the eardrum. This diagnostic subjectivity creates a critical barrier to progress in society's goal of decreasing healthcare costs and reducing over-diagnosis and over-treatment of AOM. According to the American Academy of Pediatrics in 2013, devices are needed to assist in more accurate, consistent, and objective diagnosis of AOM. A simple and objective method of analyzing an image of a patient's ear to diagnose or rule out AOM would drastically reduce over-treatment. This project will fill that gap, by developing computer-assisted image analysis (CAIA) software that provides objective information to a clinician by analyzing eardrum images collected using currently available hardware. Based on previous work in applying similar methods to improve clinician performance in radiology and surgical pathology, our overarching hypothesis is that the incremental implementation of enhanced images, automated identification of abnormalities, and retrieval of similar cases will result in improved clinician diagnostic accuracy. In our preliminary work, we developed software, called Auto-Scope, which labels eardrums as “normal” versus “abnormal.” In this study, we propose two Specific Aims to improve diagnostic performance: Specific Aim #1: Create an enhanced composite image of the eardrum. Specific Aim #2: Use machine learning approaches for clinical decision support. The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality and reducing inter-observer variability, which will ultimately enable more accurate diagnosis and personalized therapeutic approaches for ear abnormalities. Thus, the proposed research is relevant to NIH's mission pertaining to the application of novel strategies that may improve human health, and NIDCD's mission of improving diagnosis and treatment of ear diseases, particularly otitis media.",Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology,9669491,R21DC016972,"['Academy', 'Acute', 'Address', 'Adverse event', 'Affect', 'Algorithms', 'American', 'Antibiotics', 'Appearance', 'Awareness', 'Bacterial Antibiotic Resistance', 'Child', 'Childhood', 'Cholesteatoma', 'Clinic', 'Clinical', 'Clip', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cyst', 'Databases', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Ear Diseases', 'Goals', 'Guidelines', 'Hair', 'Hand', 'Health', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Interobserver Variability', 'Label', 'Language Delays', 'Language Development', 'Lighting', 'Liquid substance', 'Machine Learning', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nose', 'Nurse Practitioners', 'Operative Surgical Procedures', 'Oral', 'Otitis Media', 'Otitis Media with Effusion', 'Otolaryngologist', 'Otoscopes', 'Otoscopy', 'Pathology', 'Patients', 'Pediatrics', 'Perforation', 'Performance', 'Pharmaceutical Preparations', 'Pharyngeal structure', 'Physician Assistants', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resolution', 'Retrieval', 'Side', 'Skin', 'Societies', 'Surgical Pathology', 'System', 'Testing', 'Training', 'Tube', 'Tympanic membrane', 'United States National Institutes of Health', 'Waxes', 'Work', 'accurate diagnosis', 'acute infection', 'base', 'clinical decision support', 'cognitive development', 'computerized', 'diagnostic accuracy', 'digital imaging', 'digital video recording', 'effusion', 'experience', 'hearing impairment', 'improved', 'middle ear', 'novel', 'novel strategies', 'overtreatment', 'personalized therapeutic', 'primary care setting', 'prototype', 'software development']",NIDCD,OHIO STATE UNIVERSITY,R21,2018,252169,-0.017866246754524636
"Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time Project Summary Lower limb assistive robotic devices, such as active prosthesis, orthoses, and exoskeletons have the potential to restore function for the millions of Americans who experience mobility challenges due to injury and disability. Since individuals with mobility challenges have an increased energetic cost of transport, the benefit of such assistive devices is commonly assessed via the reduction in the metabolic work rate of the individual who is using the device. Currently, metabolic work rate can only be obtained in a laboratory environment, using breath-by-breath measurements of respiratory gas analysis. To obtain a single steady state data point of metabolic work rate, multiple minutes of data must be collected, since the signals are noisy, sparsely sampled, and dynamically delayed. In addition, the user has to wear a mask and bulky equipment, further restricting the applicability of the method on a larger scale. We propose an improved way to obtain such estimates of metabolic work rate in real-time. Aim 1 will determine salient signal features and characterize the dynamics of sensing metabolic work rate from a variety of physiological sensor signals. Aim 2 will use advanced sensor fusion and machine learning techniques to accurately predict instantaneous energy cost in real-time from multiple physiological signals without relying on a metabolic mask. Aim 3 will use the obtained real-time estimates to optimize push-off timing for an active robotic prosthesis. The resulting methods will enable an automated and continuous evaluation of assistive robotic devices that can be realized outside the laboratory and with simple wearable sensors. This automated evaluation will enable devices, such as active prostheses, orthoses, or exoskeletons, that can self-monitor their performance, optimize their own behavior, and continuously adapt to changing circumstances. This will open up a radically new way of human-robot- interaction for assistive devices. It will greatly increase their clinical viability and enable novel advanced controllers and algorithms that can improve device performance on a subject specific basis. Project Narrative A common way of evaluating assistive robotic devices, such as active prostheses or exoskeletons, is by measuring the reduction in effort that they bring to an individual walking in them. The proposed project will develop ways to perform this evaluation automatically and in real-time by the device itself, which will be used in the future to develop prostheses and exoskeletons that automatically adapt themselves to their users. This project supports the NIH's stated mission of reducing disability by improving patient outcomes with new prosthetic and orthotic devices.",Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time,9529742,R03HD092639,"['Algorithms', 'American', 'Amputation', 'Amputees', 'Ankle', 'Behavior', 'Biological Neural Networks', 'Clinical', 'Data', 'Devices', 'Electromyography', 'Energy Metabolism', 'Environment', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Gray unit of radiation dose', 'Heart Rate', 'Indirect Calorimetry', 'Individual', 'Injury', 'Laboratories', 'Linear Regressions', 'Lower Extremity', 'Machine Learning', 'Masks', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Noise', 'Orthotic Devices', 'Patient-Focused Outcomes', 'Performance', 'Persons', 'Physiological', 'Population', 'Prosthesis', 'Reference Values', 'Robotics', 'Sampling', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'cost', 'disability', 'exoskeleton', 'experience', 'functional restoration', 'human-robot interaction', 'improved', 'light weight', 'novel', 'respiratory gas', 'robotic device', 'sensor', 'wearable device']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2018,77959,0.0019846899537696995
"QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring Modern health monitoring devices at hospitals and wearable sensors in households generate a large amount of time series data at high rate, capturing the physiological status of patients in a real-lime fashion. The premise is that these technology advances enable a data-driven healthcare system that starts making fast, accurate, objective and inexpensive decisions based upon data, in addition to an individual physician's experience and preference. However, there is a significant gap in the mathematical theory and computational tools to promptly extract actionable information from multi-modal non-stationary time series data in a robust and tractable manner, which has become a serious roadblock to further utilize bigger data for better healthcare monitoring. The goal of this research program is to develop a mathematical framework for extracting time-frequency and geometric representations of multi-modal physiological data, in an online and robust manner, and use them to design machine learning algorithms to improve real-lime health monitoring. Specifically, we hypothesize that the development of time-series and geometric methods for large streaming multi-modal monitoring data will lead to more accurate diagnosis on various physiological monitoring applications, including detection and prediction of rare events such as seizure and arrhythmia, classification of sleep stages for newborns and children, and real-time artifact removal of physiological data. To achieve our goal, we plan to develop novel theoretical and computational tools for analyzing non-stationary multi-modal time series data with noise, corruption and missing data as well as real-time algorithms for filtering and event detection from such data. The tools and algorithms will be applied on clinical tasks at the Nationwide Children's Hospital. In addition, the real-time workflow will be implemented on Hadoop clusters with a mission of public sharing of both data and software. The development from the interdisciplinary team composed of mathematicians, biomedical informaticians as well as the hospital will not only transform the frontiers of mathematics knowledge, but also significantly impact clinical applications, data science education, and the development of the $11 O billion emerging market of wireless health. The goal of this project is to develop a series of novel computational theory and software to extract physiological information from the large multi-modal data streams generated by modern health monitoring devices. The tools will be applied to various clinical tasks such as detection and prediction of seizure and arrhythmia and classification of sleep stages for newborns and children, aiming for more accurate diagnosis.",QuBBD: Geometric Time-Frequency Methods for Multi-modal Physiological Monitoring,9568758,R01EB025018,"['Address', 'Algorithms', 'Arrhythmia', 'Behavior', 'Big Data', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Science', 'Detection', 'Development', 'Diagnostic', 'Education', 'Environment', 'Event', 'Excision', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Household', 'Human body', 'Individual', 'Infant', 'Knowledge', 'Limes', 'Machine Learning', 'Mathematics', 'Measures', 'Methods', 'Mission', 'Modality', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Nature', 'Newborn Infant', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Pediatric Hospitals', 'Physicians', 'Physiologic Monitoring', 'Physiological', 'Property', 'Public Domains', 'Research', 'Resources', 'Seizures', 'Series', 'Sleep Stages', 'Stream', 'Techniques', 'Technology', 'Time', 'Universities', 'Validation', 'Wireless Technology', 'accurate diagnosis', 'base', 'biological systems', 'clinical application', 'clinical practice', 'computerized tools', 'design', 'diagnostic biomarker', 'experience', 'frontier', 'geometric methodologies', 'graduate student', 'heart rate variability', 'improved', 'insight', 'mathematical theory', 'monitoring device', 'multimodality', 'novel', 'preference', 'programs', 'science education', 'signal processing', 'student training', 'theories', 'tool', 'wearable device']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2018,258070,-0.037946859914466856
"Non-invasive device to assist selecting the level-of-amputation in patients with peripheral arterial disease 1 Abstract  2  3 This is a Phase I SBIR proposal to develop a non-contact and non-invasive imaging device for assisting clinicians  4 in selecting the appropriate level-of-amputation (LOA) in limbs with peripheral arterial disease (PAD). Surgeons  5 prefer to salvage as much limb tissue as possible during amputation to increase patient mobility while decreasing  6 morbidity and mortality. However, clinicians must balance this preference against the likelihood of primary wound  7 healing at a given level of amputation (LOA), which decreases with more distal amputations. There are no gold-  8 standard tests to aid clinicians in selecting the LOA in patients with PAD, therefore reported rates of re-  9 amputation in current practice are substantial. Up to 20% percent of above-the-knee amputations to 35% of 10 foot amputations require revision to a more proximal level. Furthermore, physician awareness of the risk for 11 re-amputation may lead to overly aggressive selection of LOA to more proximal levels in some cases. Indeed, 12 certain patients may receive amputations at a level more proximal than is necessary because their surgeon could 13 not confidently predict a high likelihood of healing at a more distal level. 14 15 In current practice, selection of LOA is determined qualitatively by clinical judgment of the surgeon using patient 16 history and physical exam. Others have developed quantitative tests that assess local microcirculation. These 17 technologies have not superseded clinical judgement. To address this critical problem, SpectralMD is 18 developing an imaging device that integrates multispectral imaging with a machine learning algorithm 19 to provide a quantitative assessment of the healing potential of a selected LOA whereas current clinical 20 practice is only capable of qualitative assessment. 21 22 We have proof-of-concept of our technology’s ability to characterize microvascular blood flow changes in a 23 patient with critical limb ischemia. In this proposal, we intend to establish the utility of our device for predicting 24 the healing potential of a clinician selected LOA by demonstrating the effectiveness of DeepView assessment 25 on a large set of pre-amputation images. To this end we will conduct a Phase I pilot study for the use of our 26 device in predicting the healing potential of a clinician selected LOA. This clinical study will develop a data set 27 for training the algorithm, and deliver a clear demonstration of feasibility for completing the development on an 28 algorithm that has high accuracy in predicting the healing potential of the proposed amputation site. Following 29 this work, we will apply for a Phase II proposal intended to finalize algorithm training, validate the algorithm 30 developed in Phase I, and establish a successful regulatory and commercialization pathway. Narrative In patients with peripheral arterial disease, reported rates of re-amputation due to non-healing of a primary amputation are very significant—approximately 20% of below-the-knee amputations require eventual revision, with even higher rates established for amputations at the level of the foot. There are no gold-standard tests for selection of level of amputation (LOA) to aid clinical judgment. To address this critical problem, SpectralMD is developing the DeepView-Gen2 imaging device that integrates multispectral imaging and a machine learning algorithm to quantitatively measure microvascular blood flow and tissue healing potential to assist in the clinical selection of LOA and minimize the incidence of re-amputation and its associated morbidity and mortality.",Non-invasive device to assist selecting the level-of-amputation in patients with peripheral arterial disease,9622035,R43HL142428,"['Address', 'Algorithms', 'Amputation', 'Ankle', 'Architecture', 'Awareness', 'Blood flow', 'Clinical', 'Clinical Data', 'Clinical Research', 'Contracts', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Devices', 'Distal', 'Effectiveness', 'Elements', 'Equilibrium', 'Goals', 'Gold', 'Image', 'Imaging Device', 'Incidence', 'Investigation', 'Ischemia', 'Judgment', 'Knee', 'Lead', 'Limb structure', 'Lower Extremity', 'Machine Learning', 'Measures', 'Medical History', 'Microcirculation', 'Morbidity - disease rate', 'Pathway interactions', 'Patients', 'Peripheral arterial disease', 'Phase', 'Physicians', 'Pilot Projects', 'Postoperative Period', 'Practice Guidelines', 'Quality of life', 'Recording of previous events', 'Reporting', 'Risk', 'Sample Size', 'Secondary to', 'Site', 'Skin Tissue', 'Small Business Innovation Research Grant', 'Specificity', 'Standardization', 'Surgeon', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'Wound Healing', 'base', 'clinical practice', 'clinical risk', 'commercialization', 'design', 'foot', 'healing', 'indexing', 'mortality', 'non-invasive imaging', 'patient mobility', 'phase 1 study', 'preference', 'standard of care', 'success', 'wound']",NHLBI,"SPECTRAL MD, INC.",R43,2018,196561,-0.009963439639517908
"Assay Classifier Engine (ACE) for enhancing splice sensor assay performance SUMMARY:  The goal of this proposal is to improve the sensitivity and specificity of the Spinach-based splice sensor platform by developing a novel multiprobe (MP) assay design and a companion machine learning-based classification algorithm called assay classifier engine (ACE). Improvement in sensitivity and specificity of the splice sensor platform enables its application to detect endogenous RNA isoforms with low copy number and distinguish alternative RNA isoforms that share high degree of sequence similarities.  The aim of any assay development effort is to achieve excellent assay specificity and sensitivity. However, this is often a futile endeavor since specificity and sensitivity are two inversely correlated factors. The underlying reason for poor sensitivity or specificity is due to the off-target signals generated by competing molecules present in the sample. In the field of diagnostics, one of the ways these issues are addressed is to perform multiple single probe testing instead of one single probe testing. While individual singe probe assays might have poor specificity and sensitivity, when combined, these assays synergistically improve the sensitivity and specificity of the ultimate diagnostic determination. In the field of research and drug discovery, researchers have employed a multitude of strategies (e.g. signal amplification, reaction cascades, or sample enrichment) to improve sensitivity and MP design or strand displacement strategies to improve specificity. Some of the PCR- based methods have combined both enzyme-based signal amplification and MP strategies to improve assay determination. However, when it comes to detecting targets that are highly similar to their competitors, such as detecting single nucleotide polymorphism, DNA methylation, RNA modification and alternative splicing, there is still an unmet need for more sensitive and specific analytical methods.  In the past few years, Lucerna has developed Spinach-based sensors to detect intractable metabolites and biomolecules. One such sensor is the splice sensor, which is a Spinach-based sensor that can generate fluorescence signal based on the alternative RNA isoform of interest. One of the challenges encountered during splice sensor assay development is the lack of sensitivity toward low copy number RNA isoforms and low specificity when distinguishing two splice isoforms that share a high sequence similarity. To overcome this challenge in this proposal, we will develop a MP assay panel comprised of splice sensor variants that recognize the target RNA and the competitor with varying binding affinities and differing signal responses. We will use data sets generated from the MP assay to train a ML-based ACE algorithm to make target determination in test samples. Further, we will develop a quantitative MP data set and re-train the ACE algorithm to classify the assay signals into various categories based on target concentrations in the test sample. This new ACE algorithm will then be tested against conventional single probe assays to determine specificity and sensitivity improvement of the MP assay platform. PROJECT NARRATIVE: Improved specificity and sensitivity are highly sought-after features in assays where there are high similarity between the target and its competitors or when the target exists naturally in very low abundance. To address this unmet need, we will develop a fluorescence sensor-based multiprobe assay approach and a companion machine learning-based assay classifier engine (ACE). The ACE algorithm will integrate the multiprobe assay data and classify them based on trained machine learning models to make sample determination with enhanced specificity, sensitivity, and dynamic range than possible with conventional single probe assays.",Assay Classifier Engine (ACE) for enhancing splice sensor assay performance,9622514,R43GM130258,"['Address', 'Adopted', 'Affinity', 'Algorithms', 'Alternative Splicing', 'Area Under Curve', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Assay', 'Categories', 'Cells', 'Characteristics', 'Classification', 'Companions', 'Custom', 'DNA Methylation', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Enzyme-Linked Immunosorbent Assay', 'Enzymes', 'Evaluation', 'Exhibits', 'Fluorescence', 'Goals', 'Individual', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Nerve Degeneration', 'Nucleotides', 'Output', 'Pattern', 'Performance', 'Process', 'Protein Isoforms', 'RNA', 'RNA Splicing', 'Reaction', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Series', 'Side', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Specificity', 'Spinach - dietary', 'Technology', 'Testing', 'Time', 'Titrations', 'Training', 'Variant', 'analytical method', 'aptamer', 'assay development', 'base', 'cost', 'design', 'drug discovery', 'experience', 'improved', 'interest', 'novel', 'outcome forecast', 'predictive modeling', 'response', 'sensor', 'targeted biomarker']",NIGMS,"LUCERNA, INC.",R43,2018,224925,-0.05585438384878539
"2018 Image Science Gordon Research Conference & Gordon Research Seminar Project Summary: The proposal requests support for early-career investigators to attend the 2018 Gordon Research Conference on Image Science. The unique feature of this conference in its third offering compared with others in medical imaging is the bringing together of renown speakers from disparate application areas, including astronomy, biology, medicine, remote sensing, and security and defense industries, in a forum that encourages each to describe their greatest challenges and most promising solutions. All speakers are invited based on their leadership in their field and their willingness to debate fundamental issues shared by everyone developing, evaluating, and applying imaging in medicine and biology. We believe the GRC format placed in the context of a small-college venue promotes the type of innovative interdisciplinary thinking that leads to breakthroughs. An environment where leading senior scientists debate core issues is valuable to young investigators trying to build successful independent careers in medical imaging in industry and academia. All attendees are invited to present a poster describing their research in poster sessions that are a key element of the Gordon Conference format. The June 17-22, 2018 GRC conference theme is “Image Science: Creating Knowledge from Information,” which is focused on appropriate acquisition and efficient uses of the massive volume of imaging information now collected from patients. Speakers give 40 minutes presentations in a single-track format with 20 minute discussions following each presentation that are led by experts in the field. Topic range from “Imaging in Brain Science Discovery” to “Advanced Machine Learning” and “Computational Imaging.” At the center of each presentation is a discussion of the core challenges shared by image scientists and novel techniques for acquiring and displaying information in a manner that maximizes decision performance. Given the success of the previous meeting, we will hold the first-ever, student-run Gordon Research Seminars (GRS) on Image Science June 16, 17, 2018. Our aim is to build Image Science as an independent field of study through detailed interdisciplinary discussions and by fostering the success of a new generation of image scientists. Project Narrative: Solutions to very difficult problems often emerge from discussions among experts in different fields of study being challenged by the same core problems. The 2018 GRC on Imaging Science strives to build a community of problem solvers by creating an environment for detailed discussions among senior investigators that involves young investigators at a time when they are building careers. This is a proposal to fund young investigators to attend the conference.",2018 Image Science Gordon Research Conference & Gordon Research Seminar,9461211,R13EB025662,"['Academia', 'Area', 'Astronomy', 'Big Data', 'Biology', 'Brain', 'Collaborations', 'Communities', 'Computational Science', 'Data', 'Data Analytics', 'Development', 'Disabled Persons', 'Discipline', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Fees', 'Female', 'Financial Support', 'Fostering', 'Funding', 'Housing', 'Human', 'Image', 'Industry', 'Information Sciences', 'Interdisciplinary Study', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Minority', 'Modeling', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Recruitment Activity', 'Request for Proposals', 'Research', 'Research Personnel', 'Resource Development', 'Risk-Taking', 'Role', 'Running', 'Science', 'Scientist', 'Security', 'Senior Scientist', 'Series', 'Societies', 'Source', 'Statistical Models', 'Students', 'Systems Development', 'Techniques', 'Thinking', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'career', 'college', 'cost', 'design', 'disabled students', 'educational atmosphere', 'field study', 'frontier', 'graduate student', 'image reconstruction', 'imaging scientist', 'imaging system', 'information display', 'innovation', 'instrument', 'meetings', 'minority student', 'multidisciplinary', 'next generation', 'novel', 'posters', 'preference', 'remote sensing', 'skills', 'success', 'symposium', 'training opportunity', 'virtual', 'willingness']",NIBIB,GORDON RESEARCH CONFERENCES,R13,2018,10000,-0.021816852835962408
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment Project Summary NIH is increasing its investment in large mutli-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several open-source software systems. For example, the NIH NIAAA and BD2K funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements that called for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for multi-site QC workflows as that would require a unified platform, design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that supports simplified creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific findings findable, accessible, interoperable, and reusable.  Specifically, our multi-site open-source software platform for Medical Image Quality Assurance (mIQa) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system, machine learning to aid in QC process, and an interactive electronic notebook platform. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automating notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, mIQa is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop multi-site, open-source software for Medical Image Quality Assurance (mIQa) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. mIQa will enable efficient and accurate QC processing by levering open-source, state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive review and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment,9622218,R43MH119022,"['Active Learning', 'Address', 'Adolescence', 'Alcohols', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Data Sources', 'Development', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Environment', 'Evaluation', 'FAIR principles', 'Four-dimensional', 'Funding', 'Geography', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'International', 'Internet', 'Investments', 'Label', 'Libraries', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical', 'Medical Imaging', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'System', 'Techniques', 'Technology', 'Time', 'United States National Institutes of Health', 'Visual', 'Work', 'Writing', 'application programming interface', 'base', 'cohesion', 'cost', 'dashboard', 'data access', 'data management', 'design', 'experience', 'flexibility', 'image archival system', 'imaging study', 'improved', 'innovation', 'member', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'prototype', 'quality assurance', 'research study', 'software systems', 'success', 'tool', 'web interface', 'web-enabled']",NIMH,"KITWARE, INC.",R43,2018,225001,-0.005531258054772107
"An integrated neural network analysis and video microscopy platform for fully automated particle tracking Project Summary/Abstract  Particle tracking (PT) is a biophysical tool for elucidating molecular interactions, transport phenomena of diverse species, and rheological properties of complex materials. PT experiments involve first obtaining high resolution videos that capture time-resolved increments of particles, followed by extraction of traces of entities of interest from videos in the form of spatial locations over time, a process we refer to as path conversion. Finally, quantitative analysis of the traces will yield diffusivities, viscoelasticity, etc.  Lung diseases, such as cystic fibrosis and COPD, are characterized by a highly viscoelastic mucus layer that is incapable of being cleared by mucociliary clearance. Not surprisingly, the viscoelasticity of mucus often directly reflects disease progression. A variety of mucolytics are being investigated, but due to the variable composition and properties of mucus between patients, effective mucolytics treatment will likely be different between individuals; too little/inappropriate mucolytics will not be effective in restoring mucus clearance, whereas too much may result in bronchorrhea. Although microbeads-based rheology has been performed on a variety of mucus specimens in basic research, the capacity for high throughput characterization of rheological properties of biological specimens in a clinical setting is currently not available. This limitation can be attributed to inefficiencies of path conversion: current PT software requires extensive human supervision/intervention to achieve accurate path conversion, not only resulting in poor reproducibility and throughput but also restricting its use to only expert labs. Our vision is to make PT as objective and easy to use as a simple plate reader that can be readily utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening), and research professionals. Towards this goal, we have created a neural network tracker (NNT) that automatically determines the location of all particles in each frame with zero user-input (i.e. no parameter for users to change), and retains the identity of all particles from frame to frame. The innovation is that NNT can robustly, reproducibly, and accurately track a wide range of 2D/3D videos with virtually no need for human intervention, achieving unparalleled time savings. We have already successfully deployed NNT over the Google cloud, which offers exceptional scalability. Nevertheless, for time-sensitive applications, such as an automated PT rheometer, the transfer of large video data files is likely prohibitive. Therefore, in this Phase I STTR, we seek to enable real-time NNT-based PT analysis on the local machine while video microscopy data is being acquired by the microscope, and allow data from PT analysis to drive the operation of the microscope. In Aim 1, we will integrate our NNT with a single objective fluorescence microscope system called Monoptes. Aim 2 will evaluate the performance of our NNT- Monoptes system. If successful, our technology would form the basis of a fully automated PT system capable of measuring rheological properties of fluids/materials or distribution of particle sizes in a 96-well plate format. Project Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately, its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a software that can consistently provide superior and truly automated tracking performance compared to current alternatives. In this proposal, we will integrate this latest advance with sophisticated instrumentation to develop a microscope system capable of fully automated particle tracking microscopy in a 96-well plate format. If successful, the instrument will likely be utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening of patients), and research professionals.",An integrated neural network analysis and video microscopy platform for fully automated particle tracking,9620574,R41GM130202,"['Acceleration', 'Adopted', 'Antibodies', 'Artificial Intelligence', 'Basic Science', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Trials', 'Code', 'Complex', 'Computer software', 'Cystic Fibrosis', 'Data', 'Data Files', 'Decision Making', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease Progression', 'Drug Carriers', 'Drug Screening', 'Effectiveness', 'Elasticity', 'Engineering', 'Gaussian model', 'Goals', 'HIV Infections', 'Heterogeneity', 'Human', 'Image', 'Individual', 'Intervention', 'Liquid substance', 'Location', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Microspheres', 'Motion', 'Mucociliary Clearance', 'Mucolytics', 'Mucous body substance', 'Output', 'Particle Size', 'Particulate', 'Pathway Analysis', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Positioning Attribute', 'Process', 'Property', 'Radial', 'Reader', 'Reproducibility', 'Research', 'Resolution', 'Respiratory physiology', 'Rheology', 'Risk', 'Running', 'Sampling', 'Savings', 'Series', 'Small Business Technology Transfer Research', 'Software Tools', 'Specimen', 'Spottings', 'Supervision', 'System', 'Technology', 'TensorFlow', 'Time', 'Video Microscopy', 'Viscosity', 'Vision', 'Woman', 'base', 'biophysical tools', 'cloud based', 'drug development', 'experimental study', 'fluorescence microscope', 'innovation', 'instrument', 'instrumentation', 'interest', 'movie', 'novel', 'operation', 'particle', 'patient screening', 'physical science', 'pre-clinical', 'submicron', 'virtual', 'viscoelasticity']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2018,224894,-0.00415856122359801
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9465330,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,503162,-0.0338065581510193
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9698505,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,50000,-0.0338065581510193
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9535994,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2018,444363,-0.008890819098621182
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research PROJECT SUMMARY This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0™ that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud™ Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb’s DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently. PROJECT NARRATIVE PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9741597,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Communications Media', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Internet of Things', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Modernization', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'Transact', 'United States National Institutes of Health', 'analytical tool', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'experimental study', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'service learning', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2018,99999,0.0016424984275952572
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9536759,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2018,619539,-0.017907793153206546
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9525950,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,333515,-0.008726192549574291
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,9427452,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Simulation', 'Cornea', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Image Analysis', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patient risk', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2018,400000,-0.0018601349040334799
"2018 In Vivo Magnetic Resonance Gordon Research Conference & Gordon Research Seminar PROJECT SUMMARY  The field of magnetic resonance (MR) is in the midst of a revolution. Disruptive external forces, such as the advent of powerful new Artificial Intelligence methods, coupled with a recent creative ferment in method development within the field, is changing the way we think about the acquisition, the reconstruction, and the interpretation of MR data. Meanwhile, MR has long been an indispensable tool not only for basic discovery but also for medical diagnostics, but the value proposition of clinical MR imaging is also changing, against the backdrop of a shifting healthcare landscape.  There is a palpable need to explore the full scope of these changes, in a forum that enables deep dives and focused discussion, without losing the necessary breath of perspective. While large meetings such as the annual scientific meeting of the International Society for Magnetic Resonance in Medicine (ISMRM) have the necessary breath, the sheer size and pace of such meetings work against the requisite focus. On the other hand, short focused workshops are better suited to the evaluation of progress in well-defined subfields.  The goal of this grant application is to support a high-impact conference with a time-tested format which is ideally suited to assess recent changes in the field of in vivo MR. The tenth Gordon Research Conference (GRC) on In Vivo Magnetic Resonance will be held July 15 to 20, 2018, at Proctor Academy, in Andover, NH. Our GRC will also be associated with the first-ever trainee-organized and trainee-focused Gordon Research Seminar (GRS) on In Vivo Magnetic Resonance, which will take place on the weekend before the GRC (July 14-15, 2018). The trainee seminar meshes well with our goal of preparing young scientists for a changing field and a changing world. We request funding to support graduate students and postdoctoral fellows attending these meetings, which will focus explicitly on the shifting role of MR in a rapidly changing world.  The GRC, subtitled “Challenging assumptions about MR technology and applications in a changing world,” will be led by Chair Daniel K. Sodickson, MD, PhD, and Vice Chair Jeff F. Dunn, PhD, and will build upon a rich history of In Vivo MR GRCs. The GRS, subtitled “The Changing World of Magnetic Resonance: Old Physics, New Techniques,” will be led by Chair Scott Beeman, PhD, and Vice Chair Carson Hoffman, BSc, and will further enhance the experience of trainees with tailored opportunities for mentorship, networking, and scientific exchange.  Specific aims of our 2018 GRC and GRS on In Vivo MR are as follows:  1. Explore disruptive forces and marshal disruptive innovation in the field of in vivo MR  2. Foster connections between MR and surrounding disciplines  3. Prepare young scientists to make a difference in a rapidly changing world PROJECT NARRATIVE Support is requested for graduate students and postdoctoral fellows to attend the tenth Gordon Research Conference (GRC) on In Vivo Magnetic Resonance, scheduled for July 15-20, 2018, and the inaugural trainee- focused Gordon Research Seminar (GRS) to precede the conference on July 14-15, 2018. The GRC will be focused on “Challenging assumptions about MR technology and applications in a changing world,” with the goal of taking the measure of disruptive forces such as Artificial Intelligence, and marshaling disruptive innovations in the acquisition, reconstruction, and interpretation of MR data. The companion GRS will have a related focus on “The changing world of magnetic resonance: old physics, new techniques,” and will provide trainees (who will attend the GRC as well) with opportunities for presentation of their work to peers and thought leaders, discussion of emerging areas of MR, and focused networking and mentorship.",2018 In Vivo Magnetic Resonance Gordon Research Conference & Gordon Research Seminar,9608839,R13EB026933,"['Academy', 'Address', 'Anniversary', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Awareness', 'Biological', 'Biological Neural Networks', 'Books', 'Characteristics', 'Clinical', 'Companions', 'Complex', 'Coupled', 'Data', 'Development', 'Diagnostic', 'Discipline', 'Doctor of Philosophy', 'Educational workshop', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Goals', 'Healthcare', 'Human', 'Imaging technology', 'International', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Marshal', 'Measures', 'Medical', 'Medicine', 'Mentorship', 'Methods', 'Modernization', 'Palpable', 'Physics', 'Postdoctoral Fellow', 'Recording of previous events', 'Research', 'Role', 'Schedule', 'Science', 'Scientist', 'Signal Transduction', 'Societies', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Work', 'biophysical model', 'c new', 'commune', 'comparative', 'computer science', 'design', 'experience', 'graduate student', 'in vivo', 'innovation', 'insight', 'interest', 'magnetic field', 'meetings', 'method development', 'peer', 'posters', 'programs', 'reconstruction', 'symposium', 'tool']",NIBIB,GORDON RESEARCH CONFERENCES,R13,2018,5000,-0.021417342557447157
"Advancing a novel portable detection method for cannabis intoxication Intoxication from marijuana (MJ) impairs psychomotor performance and at least doubles the risk of motor vehicle accidents. The ongoing wave of legalization of MJ has brought increasing prevalence of driving while intoxicated with MJ. However, there is no quantitative biologic test that can accurately determine whether an individual is acutely impaired from MJ intoxication. Assays of the primary intoxicating substance in MJ, THC, in body fluids has a high false negative rate as THC is cleared from blood within 15 minutes, long before impairment is resolved. And assays of THC metabolites yield a high false positive rate because clearance of these metabolites can take weeks. Thus there is now no nor is there likely to ever be a test of blood, breath or body fluids that can accurately detect MJ intoxication. In response to this significant knowledge gap, this project aims to develop an accurate, portable method for detection of impairment due to MJ intoxication using functional near-infrared spectroscopy (fNIRS). fNIRS is a non-invasive, safe brain imaging technique that capitalizes on differences in the light absorption spectra of deoxygenated and oxygenated hemoglobin (Hb), that allows the measurement of relative changes in Hb concentration that reflect brain activity. fNIRS can be performed in natural environments at low cost, and thus can be used in real-world settings. In Phase I, we will develop an algorithm for individual-level detection of impairment from THC using fNIRS measurements. To do so, we will assess the effect of oral THC (or placebo) on fNIRS measurements, self-reported intoxication, and impairment as defined by the gold standard field sobriety test conducted by a Drug Recognition Expert (DRE) in 40 healthy MJ users. fNIRS assessments will examine (1) the effect of THC exposure on resting state and task-based activation in the prefrontal cortex, (2) the extent to which impairment in psychomotor functioning with THC administration correlates with THC-induced change in hemodynamic responses detected with fNIRS, and (3) the sensitivity and specificity and area under the ROC curve of fNIRS measurements and field sobriety test determinants of impairment. Milestone: Should machine learning applications to the data generate an algorithm that predicts impairment with >80% accuracy compared with a gold standard field sobriety test, we will proceed to Phase II. In Phase II, we will conduct fNIRS testing in 150 individuals under THC/placebo as in Phase I and in 50 individuals in a THC plus alcohol/placebo condition in order to further refine the algorithm for MJ impairment detection such that fNIRS detection concurs with field sobriety testing with >90% specificity. It is anticipated that this level of specificity could be used in legal definitions of impairment. This will warrant commercialization, which will be followed by prototype development and field testing. An accurate, quantitative, biological test that is user-friendly and enables law enforcement to detect impairment from MJ has the potential to dramatically change practice of law enforcement across the country and the world and thus has enormous commercial potential, as outlined in the Commercialization Plan and in accompanying letters of support. The goal of this project is to develop, test, and refine a method to accurately and reliably detect marijuana (MJ) impairment using a portable, user-friendly, non-invasive, brain-based modality. MJ doubles the chance of motor vehicle accidents, yet, there now exists no valid, biologically based method to detect whether an individual is acutely impaired from MJ. The development of a reliable, quantitative biological marker that enables law enforcement officers to screen individuals whom they suspect are impaired from MJ will have highly significant public health importance and enormous commercial potential.",Advancing a novel portable detection method for cannabis intoxication,9541180,R42DA043977,"['Acute', 'Adult', 'Age', 'Alcohols', 'Algorithms', 'Area', 'Base of the Brain', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Blood', 'Blood Circulation', 'Blood Tests', 'Body Fluids', 'Brain', 'Brain imaging', 'Cannabis', 'Collaborations', 'Comorbidity', 'Country', 'Cross-Over Trials', 'Data', 'Detection', 'Development', 'Devices', 'Dose', 'Double-Blind Method', 'Driving While Intoxicated', 'Drug Kinetics', 'Ensure', 'Environment', 'Equipment', 'Evaluation', 'Formulation', 'Future', 'Goals', 'Gold', 'Hemoglobin', 'Hour', 'Human Resources', 'Imaging Techniques', 'Impairment', 'Individual', 'Intoxication', 'Knowledge', 'Law Enforcement', 'Law Enforcement Officers', 'Legal', 'Letters', 'Licensing', 'Light', 'Machine Learning', 'Marijuana', 'Measurement', 'Methods', 'Modality', 'Near-Infrared Spectroscopy', 'Oral', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Placebos', 'Population', 'Prefrontal Cortex', 'Prevalence', 'Property', 'Psychomotor Impairments', 'Psychomotor Performance', 'Public Health', 'ROC Curve', 'Randomized', 'Readiness', 'Rest', 'Risk', 'Sensitivity and Specificity', 'Source', 'Specificity', 'System', 'THC exposure', 'Testing', 'Tetrahydrocannabinol', 'United States', 'Urine', 'Vendor', 'absorption', 'alcohol exposure', 'base', 'behavior test', 'commercialization', 'cost', 'density', 'detector', 'driving under influence', 'drug testing', 'field sobriety tests', 'field study', 'functional disability', 'hemodynamics', 'interest', 'marijuana legalization', 'marijuana use', 'marijuana user', 'novel', 'novel strategies', 'portability', 'prediction algorithm', 'prototype', 'response', 'spectroscopic imaging', 'tool', 'user-friendly', 'vehicular accident']",NIDA,"HIGHLIGHTI, INC",R42,2018,731789,-0.0028860362679124754
"Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury ﻿    DESCRIPTION (provided by applicant): Throughout human pregnancy, the placenta is indispensable for embryonic development, fetal growth and tissue differentiation. The placenta also protects the fetus against diverse insults, while preserving maternal health. Placental dysfunction is commonly implicated in complications of pregnancy that challenge maternal physiology (e.g., preeclampsia) and fetal development (e.g., fetal death or fetal growth restriction) or that leads to preterm birth. Within the placenta, the trophoblast constitutes the outermost layer, which is directly bathed in maternal blood and therefore positioned to regulate maternal-fetal gas exchange, nutrient delivery, waste removal and the production of hormones, faithfully balancing fetal needs and maternal supply. Trophoblast damage, which is common in dysfunctional placentas, may interrupt the delicate maternal-fetal balance, cause clinical disease, and leave a lifelong mark on health. A fundamental challenge in perinatal medicine arises from our limited ability to diagnose placental disorders in real time and throughout pregnancy. However, the recent discovery, by ourselves and others, that (a) placental trophoblasts release distinctive micro- and nanovesicles into the maternal circulation and (b) these vesicles contain trophoblast-specific non-coding RNA cargo, created a new opportunity for assessing trophoblast health. These vesicles are actively released by trophoblasts throughout pregnancy, and thus serve as a venipuncture-accessible ""natural biopsy"" of trophoblasts, which can furnish information on trophoblast health in real time. Our established perinatal biology group at Magee- Womens Research Institute includes expertise in perinatal medicine and placental pathology, developmental and molecular biology, and bioinformatics. Inspired by these recent advances, we have partnered with an experienced group of bioengineers that includes experts from Carnegie Mellon University, MIT, and Penn State University, with unique skills in biophysics-based vesicle analytics, including microfluidics, nanomechanics, micro/nano fabrication and vesicle sorting using acoustic tweezers. Together, our new transdisciplinary group will use integrated molecular and biophysical methodologies to directly assess the use of trophoblast-derived extracellular vesicles from maternal plasma as revelatory of trophoblast health in real time and as a technique that may be employed throughout pregnancy. Our approach is comprehensive, centering on miRNAs as well as lncRNAs and circRNAs, analyzed in exosome nanovesicles, as well as microvesicles and apoptotic bodies. As each vesicle features a unique bimolecular and biophysical signature, we will deploy our machine learning- based training and testing pipeline to informatively integrate these distinct signals into an innovative diagnostic tool. Lastly, our deployment of affordable acoustic tweezers technology to sort trophoblastic vesicles will facilitate the translation of our advances into a new ""lab on a chip"" placental diagnostic technology, suitable for small blood volumes. This technology may not only denote trophoblast pathology, but has potential to identify those who may benefit from intervention and to monitor therapeutic success. PUBLIC HEALTH RELEVANCE: Although the placenta is critical for fetal development and pregnancy outcome, it is not currently accessible for real-time diagnostics throughout pregnancy. Having developed tools for isolation and analysis of placenta- specific extracellular from the maternal plasma, we will study molecular and biophysical properties of these vesicles as indicators of placental health and disease.",Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury,9503015,R01HD086325,"['Abruptio Placentae', 'Acoustics', 'Apoptotic', 'Arteries', 'Bioinformatics', 'Biological Assay', 'Biology', 'Biomedical Engineering', 'Biophysics', 'Biopsy', 'Blood', 'Blood Circulation', 'Blood Volume', 'Blood flow', 'Characteristics', 'Clinical', 'Communication', 'Data', 'Developmental Biology', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Dimensions', 'Disease', 'Embryonic Development', 'Endoglin', 'Equilibrium', 'Evaluation', 'Excision', 'Fetal Death', 'Fetal Development', 'Fetal Growth', 'Fetal Growth Retardation', 'Fetal Tissues', 'Fetal health', 'Fetus', 'Functional disorder', 'Future', 'Gases', 'Glean', 'Gold', 'Health', 'Histologic', 'Hormones', 'Human', 'Injury', 'Interruption', 'Intervention', 'Investigation', 'Knowledge', 'Lab-On-A-Chips', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maternal Health', 'Maternal Physiology', 'Methods', 'MicroRNAs', 'Microfluidics', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Needle biopsy procedure', 'Nutrient', 'PGF gene', 'Pathology', 'Perinatal', 'Placenta', 'Placenta Diseases', 'Placental Biology', 'Plasma', 'Plasma Proteins', 'Positioning Attribute', 'Postpartum Period', 'Pre-Eclampsia', 'Predictive Value', 'Pregnancy', 'Pregnancy Complications', 'Pregnancy Outcome', 'Pregnancy-Associated Plasma Protein-A', 'Premature Birth', 'Production', 'Property', 'Provider', 'Research Institute', 'Shapes', 'Signal Transduction', 'Sorting - Cell Movement', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissue Differentiation', 'Training', 'Translations', 'Ultrasonography', 'Universities', 'Untranslated RNA', 'Venipunctures', 'Vesicle', 'Viscosity', 'Woman', 'adverse pregnancy outcome', 'base', 'biophysical properties', 'biophysical techniques', 'circular RNA', 'clinical care', 'clinical diagnostics', 'cost effective', 'design', 'exosome', 'experience', 'extracellular', 'extracellular vesicles', 'fetal', 'fitness', 'guided inquiry', 'high dimensionality', 'improved', 'in vivo', 'injured', 'innovation', 'mechanical properties', 'microvesicles', 'nanofabrication', 'nanomechanics', 'nanovesicle', 'novel', 'perinatal medicine', 'peripheral blood', 'pregnancy disorder', 'public health relevance', 'skills', 'stem', 'success', 'tomography', 'tool', 'transcriptome sequencing', 'trophoblast', 'viscoelasticity', 'wasting']",NICHD,MAGEE-WOMEN'S RES INST AND FOUNDATION,R01,2018,664486,-0.018838868350704436
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9622047,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Biological Neural Networks', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2018,1057846,-0.023799071585340458
"Acceleration techniques for SimSET SPECT simulations Abstract The Simulation System for Emission Tomography (SimSET) is one of the foundational tools for emission tomography research, used by hundreds of researchers worldwide for both positron emission tomography (PET) and single photon emission computed tomography (SPECT). It has proven to be accurate and efficient for both PET and low energy SPECT studies; because SimSET uses a geometric model for its SPECT collimation, it is less accurate for high energy isotopes. This application proposes to address this with the use of angular response functions (ARFs), a technique that has proven to accurately model SPECT collimation and detection for high-energy isotopes more efficiently than full photon-tracking simulations. In addition, we propose a novel ARF-based importance sampling method that will speed these simulations by a factor of >50. The generation of ARF tables is another consideration: it is extremely compute intensive and has caused ARF to be used only when a large number of simulations are needed using the same isotope/collimator/detector combination. For this reason, we also propose application of importance sampling to speed the generation of ARF tables by a factor 5, and the creation of a library of angular response functions for popular isotope/collimator/detector combinations. The former will lessen the computational cost of generating the tables, the latter will, for many users/uses, eliminate the need to generate ARF tables at all. This will greatly expand the potential applications of ARF-based simulations. Our first aim is to accelerate SimSET SPECT simulations without sacrificing accuracy. This will be accomplished by synergistically utilizing two tools: variance reduction and angular response function (ARF) tables. Variance reduction includes importance sampling and forced detection. We hypothesis that these techniques combined with information from our angular response function tables will improve SimSET simulation efficiency by >50 times of SPECT simulations of specific radioisotopes (e.g., I-123, Y-90, etc.). Our second aim is to accelerate ARF table generation. This will be accomplished by using importance sampling methods in the generation of ARFs. We further propose to use an adaptive stratification scheme that will simulate photons for a given table position only as long as required to determine its value to a user-specified precision. Our third aim is to create a library of pre-calculated ARF tables for popular vendor isotope/collimator/detector configurations. These ARF tables will then be made publically available for download through the SimSET website. With a registered user base of >500, we believe that these enhancements to SimSET will have far reaching impact on research projects throughout the world. Narrative The overall goal of this work is to develop methods to speed up the SimSET Monte Carlo-based simulation software for single photon computed tomography (SPECT) imaging systems by greater than 50-fold. This type of speed up with enable new research that was previously impractical due to the computation time required for simulation. In addition, all software tools and tables developed within this project will be made available via a web-based host.",Acceleration techniques for SimSET SPECT simulations,9583854,R03EB026800,"['90Y', 'Acceleration', 'Address', 'Algorithms', 'Collimator', 'Communities', 'Crystallization', 'Data', 'Detection', 'Foundations', 'Future', 'Generations', 'Goals', 'Industrialization', 'Institution', 'Isotopes', 'Libraries', 'Location', 'Machine Learning', 'Medical Research', 'Methods', 'Modeling', 'Online Systems', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Probability', 'Radioisotopes', 'Research', 'Research Personnel', 'Research Project Grants', 'Running', 'Sampling', 'Scheme', 'Software Tools', 'Specific qualifier value', 'Speed', 'Stratification', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Vendor', 'Weight', 'Work', 'X-Ray Computed Tomography', 'base', 'cost', 'detector', 'imaging system', 'improved', 'interest', 'novel', 'response', 'simulation', 'simulation software', 'single photon emission computed tomography', 'synergism', 'thallium-doped sodium iodide', 'tomography', 'tool', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R03,2018,74515,-0.06387686466073446
"Microscopy-Based Antimicrobial Susceptibility Testing (MAST) Antibiotic resistance is compromising our ability to treat bacterial infections. Clinical microbiology laboratories guide appropriate treatment through antimicrobial susceptibility testing (AST) of patient bacterial isolates. However, increasingly, pathogens are developing resistance to a broad range of antimicrobials, requiring AST of less commonly used or recently introduced agents for which no commercially available or FDA-cleared testing methods exist. Agar and broth dilution are gold standard methods for AST that can be used to test any antimicrobial; however, labor and technical complexity precludes their use in hospital-based clinical laboratories. Therefore, bacterial isolates often must be sent to a reference laboratory with a 4-6 day delay in results. Furthermore, even standard methods require overnight incubation prior to readout. Therefore, there exists a significant AST testing gap in which current methodologies cannot adequately address the need for rapid results in the face of unpredictable susceptibility profiles. Our laboratory has recently verified inkjet printer-based digital dispensing technology as a novel platform to facilely perform reference AST for any antimicrobial at will. In this proposal, we aim to combine this methodology with advanced microscopy to leapfrog traditional AST capabilities through: (1) development of a method for microscopic imaging of bacterial replication on a solid-phase, 384-well microplate AST format, thereby allowing determination of susceptibility for any drug at will in 4 hours and (2) development and application of advanced image analysis for automated susceptibility calls. This new platform is designated MAST for microscopy-based antimicrobial susceptibility testing. The clinical diagnostic performance of the platform will be optimized against an AST reference method for accuracy and precision using a large panel of well-characterized clinical isolates. We anticipate establishing a prototype platform that will address the AST testing gap and thereby help our health system more effectively address the antimicrobial resistance threat. With the emergence of multi-drug resistant bacteria, it is no longer possible to accurately predict which antimicrobials will be effective against life-threatening bacterial illness. Testing bacteria directly for response available therapies may take several days. Therefore, a new technology platform called MAST is proposed to allow us to determine which antibiotics can treat a bacteria infection in a matter of hours and thereby address our current, clinically unacceptable antimicrobial testing gap.",Microscopy-Based Antimicrobial Susceptibility Testing (MAST),9455026,R21AI130434,"['Address', 'Agar', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Bacteria', 'Bacterial Infections', 'Biological Neural Networks', 'Clinical', 'Clinical Microbiology', 'Development', 'Diagnostic tests', 'Goals', 'Gold', 'Growth', 'Health system', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Infection', 'Laboratories', 'Life', 'Machine Learning', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Monitor', 'Multiple Bacterial Drug Resistance', 'Nutrient', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Predisposition', 'Printing', 'Regimen', 'Resistance', 'Resistance development', 'Solid', 'Supervision', 'Surface', 'Technology', 'Test Result', 'Testing', 'antimicrobial', 'base', 'biomaterial compatibility', 'clinical diagnostics', 'digital', 'direct application', 'microscopic imaging', 'new technology', 'next generation', 'novel', 'pathogen', 'performance tests', 'prototype', 'response']",NIAID,BETH ISRAEL DEACONESS MEDICAL CENTER,R21,2018,263805,-0.017254643553228664
"Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II Project Summary Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Clinical performance assessment emphasizes learner evaluation over learner development, lacks rigor and utility for developmental purposes, and clinical teachers have expressed particular difficulty with diagnosing reasoning deficits for remediation purposes. Further, medical students' diagnostic reasoning does not improve over the course of clinical training and senior medical students have highly variable diagnostic performance that is often rated below expectations according to theory-based and validated scoring criteria. Independent practice does not necessarily enhance the context for clinical reasoning; the majority of physicians' medical errors are thought to be diagnostic in nature. We propose to improve undergraduate medical education to minimize the time to clinical competency for first year residents through targeted diagnostic reasoning skill development that (1) integrates basic science and clinical instruction; (2) provides deliberate practice with structured, case-based learning opportunities; and (3) enables anytime/anywhere learning that fits with the demanding schedules of most medical students. Southern Illinois University School of Medicine (SIUSOM) is a recognized leader in using performance-based clinical competency exams to enhance reasoning skill acquisition among medical students. These exams feature clinical scenarios with standardized patients followed by diagnostic justification essays which require students to explicitly describe the thought process used to reach a final diagnosis. These essays are the most reliable method of assessing diagnostic strategies but are not in use in the majority of medical schools, though interest in improving diagnostic reasoning instruction and assessment during undergraduate medical education is widespread. Barriers to the widespread adoption of this approach are 1) the time-consuming need to hand score each essay; and 2) the difficulty in accurately and consistently identifying the causes of strategy failures. This project will develop an application to provide automated scoring of diagnostic justification essays, identification of the underlying causes of failure when students perform poorly, and feedback with instructional strategies for remediation specific to each deficit. We propose these specific aims: 1) Improve reliability of human scoring of DXJ essays. 2) Extend the automated scoring algorithms. 3) Automated reasoning failure categorization and remediation. 4) Complete the software development required for delivering the commercial product. 5) Evaluate predictive validity of automatically scored DXJ essays. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine. Project Narrative Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Better preparation during undergraduate medical education can shorten the time to competency of first year residents, improving patient outcomes. We propose to develop and test a technology-enabled, deliberate-practice approach to training diagnostic strategy that includes automated scoring of diagnostic justification essays, identification of specific diagnostic strategy failures and targeted remediation. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine.","Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II",9537633,R42GM108104,"['Address', 'Adopted', 'Adoption', 'Algorithms', 'Basic Science', 'Caring', 'Case Based Learning', 'Case Study', 'Charge', 'Classification', 'Clinical', 'Clinical Competence', 'Community Health Education', 'Competence', 'Consult', 'Custom', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Education', 'Educational Technology', 'Educational process of instructing', 'Ensure', 'Environment', 'Equation', 'Evaluation', 'Faculty', 'Failure', 'Feedback', 'Future', 'Goals', 'Hand', 'Hospitals', 'Human', 'Illinois', 'Incubators', 'Instruction', 'Leadership', 'Learning', 'Letters', 'Machine Learning', 'Measures', 'Medical', 'Medical Education', 'Medical Errors', 'Medical Students', 'Medicine', 'Methods', 'Modeling', 'Nature', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Preparation', 'Process', 'Recommendation', 'Role', 'Sales', 'Schedule', 'Semantics', 'Standardization', 'Structure', 'Students', 'Suggestion', 'Supervision', 'System', 'Taxonomy', 'Teaching Method', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validity and Reliability', 'Variant', 'base', 'educational atmosphere', 'essays', 'evidence base', 'expectation', 'improved', 'innovation', 'interest', 'medical schools', 'prototype', 'remediation', 'research and development', 'skill acquisition', 'skills', 'software development', 'teacher', 'theories', 'tool', 'undergraduate medical education', 'undergraduate student', 'virtual']",NIGMS,"PARALLEL CONSULTING, LLC",R42,2018,489952,-0.012855912526268786
"MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention Project Summary The Medical Image Computing and Computer Assisted Intervention (MICCAI) society is dedicated to the promotion, preservation, facilitation of research and education in the fields of medical image computing (MIC) and computer assisted interventions (CAI) including biomedical imaging and robotics; this is achieved through the organization and operation of regular international conferences of highest quality and publications which promote and foster the exchange and dissemination of advanced knowledge, expertise and experience in the field produced by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their roots and origin in three separate but related conferences beginning in early 1990s, the Visualization in Biomedical Computing (VBC), Computer Vision and Virtual Reality in Robotics and Medicine (CVRMed), and Medical Robotics and Computer Assisted Surgery (MRCAS), which merged into a single annual conference in 1998. MICCAI Conferences have defined a new scientific discipline over the years and have become the premier conference in the field with their proceedings having an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & image processing for medical imaging, computer-aided diagnosis, computer-assisted intervention & surgery, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, specific imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry. The main MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance) and several presented papers becoming landmark publications over the years reaching up to 2,000 citations. The conference series includes community-driven software challenges, workshops and tutorials just before and/or after the main conference. These satellite events focus in detail on the current status and advances in topics relevant to MICCAI and are very highly attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendance typically includes more than 45 countries, with strong student representation (~40%). The MICCAI 2018 Conference will be held in Granada, Spain in September 16th-20th, 2018. An innovative aspect of MICCAI 2018 is the initiation of a “Mentoring Program” to connect students and young investigators with established mentors from academia and industry. Along with the mission of “Women in MICCAI” committee, this proposal requests funds to initiate and ultimately sustain student travel awards to specifically enhance diversity in conference attendance, including women, underrepresented minorities, students with disabilities, and students from disadvantaged backgrounds, to present their work, providing them with a unique opportunity to reach an international audience for career development and collaborations. Project Narrative The MICCAI 2018 Conference will be held in Granada, Spain during September 16th-20th, 2018. The MICCAI conferences are the premier meeting in the medical image computing (MIC) and computer assisted intervention (CAI) communities, having introduced several landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students, focusing on enhancing diversity by supporting the participation of women, underrepresented minorities, students with disabilities, and from disadvantaged backgrounds, to present their work, providing them with an opportunity for visibility in an established international audience, foster professional development and collaborations.",MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention,9617533,R13CA225202,"['Academia', 'Address', 'American', 'Area', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Climate', 'Clinic', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Country', 'Development', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Grant', 'Imagery', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority', 'Mission', 'Occupations', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Physicians', 'Physiology', 'Plant Roots', 'Policies', 'Psychiatry', 'Publications', 'Publishing', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Support', 'Robotics', 'Scientist', 'Series', 'Sex Bias', 'Societies', 'Spain', 'Students', 'System', 'Translations', 'Travel', 'United States National Institutes of Health', 'Woman', 'Work', 'Writing', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'computer science', 'design', 'digital imaging', 'disabled students', 'disadvantaged student', 'experience', 'image processing', 'imaging system', 'improved', 'innovation', 'lecture notes', 'meetings', 'new technology', 'oncology', 'operation', 'peer', 'posters', 'preservation', 'programs', 'prototype', 'racial and ethnic', 'research and development', 'social', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NCI,UNIVERSITY OF PENNSYLVANIA,R13,2018,5000,-0.01424367848019158
"How Does Automated Record Linkage Affect Inferences about Population Health? ABSTRACT  Our broad research objective is to create the Longitudinal Intergenerational Family Electronic Micro-dataset (LIFE-M) spanning the late 19th and 20th century United States. Using automated record linkage technology, the LIFE-M project combines millions of vital records to reconstruct how and why individuals' health has changed across time. This multi-generational, longitudinal micro-database aims to transform research on health and longevity, on childbearing and family structure, and on the long-run health effects of early-life circumstances and exposures.  In creating LIFE-M, however, we have encountered serious deficits in knowledge about the performance of automated record linkage technology. The proposed project seeks to evaluate the performance of the most popular and cutting-edge automated linking techniques for the purposes of creating longitudinal health data. Our specific aims are to (1) produce systematic evidence regarding the performance of automated record linking algorithms in terms of match rates, representativeness of the linked sample, erroneous matches (type I errors), and systematic measurement error; (2) examine how phonetic name-cleaning methods affect quality metrics; and (3) examine how record quality metrics vary for different underrepresented subgroups (including women, racial/ethnic minorities, and immigrants) and to determine how linking methods affect representativeness and inferences. To achieve these aims, we have developed new partnerships with record linking experts allowing us to incorporate the most cutting-edge methods in record linking. We will also rely on new “ground truth” generated by LIFE-M project's independent, double-blind human review process.  This project will contribute significantly to existing knowledge about the use of automated linking methods for creating longitudinal and intergenerational health data. It will also increase knowledge about potential sources of bias in health studies. Both contributions should greatly enhance the quality of descriptive and causal inferences about population health and aging and disparities in these outcomes. PROJECT NARRATIVE  This project contributes to public health knowledge by advancing record linking methodology for creating longitudinal and intergenerational health datasets. It will also increase knowledge about potential sources of bias in public health and aging studies using linked records. Both contributions should significantly improve the quality of inferences about public and population health and health disparities.",How Does Automated Record Linkage Affect Inferences about Population Health?,9565480,R21AG056912,"['Affect', 'Aging', 'Algorithms', 'American', 'Benchmarking', 'Big Data', 'Birth', 'Birth Certificates', 'Birth Records', 'Censuses', 'Child', 'Computers', 'Data', 'Data Linkages', 'Data Set', 'Databases', 'Double-Blind Method', 'Economics', 'Family', 'Foundations', 'Four-dimensional', 'Funding', 'Genealogy', 'Generations', 'Genetic Transcription', 'Goals', 'Graph', 'Hand', 'Health', 'Heterogeneity', 'Human', 'Immigrant', 'Incidence', 'Individual', 'Infant', 'Joints', 'Knowledge', 'Life', 'Link', 'Longevity', 'Machine Learning', 'Maiden Name', 'Marriage', 'Measurement', 'Measures', 'Medicare', 'Methodology', 'Methods', 'Minnesota', 'Minor', 'Names', 'Outcome', 'Performance', 'Pilot Projects', 'Politics', 'Population', 'Process', 'Public Health', 'Records', 'Research', 'Research Infrastructure', 'Running', 'Sample Size', 'Sampling', 'Science', 'Scientist', 'Source', 'Speed', 'Subgroup', 'Techniques', 'Technology', 'Time', 'United States', 'United States National Institutes of Health', 'Universities', 'Variant', 'Veterans', 'Woman', 'aging population', 'child bearing', 'cost effective', 'ethnic minority population', 'family structure', 'health data', 'health disparity', 'health knowledge', 'improved', 'innovation', 'intergenerational', 'longitudinal database', 'population health', 'racial and ethnic', 'repository', 'social', 'vector']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2018,194895,-0.02019359656715778
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions Project Summary/Abstract People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. Project Narrative People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9644103,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Personal Satisfaction', 'Persons', 'Phase', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'manufacturability', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2018,519349,-0.004496569635851818
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9542210,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting', 'whole slide imaging']",NIAMS,UNIVERSITY OF FLORIDA,R01,2018,377571,0.008571007325155543
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9517057,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'International', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Radiology Specialty', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Screening procedure', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging study', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'perfusion imaging', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'single photon emission computed tomography', 'skills', 'success', 'validation studies', 'virtual', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2018,169609,-0.050597533241239105
"Partelligence Abstract Halo Labs proposes to develop “Partelligence” a particle ID technique that enables accurate and rapid identification of contaminating particles in biopharmaceutical formulations. Protein therapeutics currently represent between 15 and 30% of the overall pharmaceutical market. The primary concern for this class of therapeutics is that they can elicit an immune response from patients who develop anti- drug antibodies. The drug’s effect is therefore eliminated between 1 and 10 percent of patients who return to their original disease state. The presence of particulate matter in these therapeutics (e.g. shed glass from a syringe or a protein aggregate) can enhance this immune response and, due to the patient safety risk the FDA regulates the amount of particles that can be present. There are always some number of particles in each injected sample, and although their presence can be detected, they don’t know what the particles actually are. A QC tool that can identify the particles would help manufactures trace them back to their source (e.g. a bad lot of syringes) and eliminate them. Partelligence aims to make particle identification routine in biopharma QC. The technology builds off our current instrument, Horizon, which was launched in mid-2017 and already sold to some of the world’s largest pharmaceutical companies. The technique works by analyzing several combinatorial features including size, morphology, optical contrast, and intrinsic fluorescence, and in this proposal we will test which features are key to enable the most accurate and rapid particle recognition. To date, we have performed feasibility experiments validating our ability to identify a few commonly found particles in biopharma solutions. Given this, our goals in Phase I are to expand on these studies by building a comprehensive training set and by testing a number of different algorithms. We will first start with reference samples, and then move to real biopharmaceutical samples provided by our pharma collaborators. At the end of the study, we will do a feasibility analysis to determine if the throughput, specificity and reliability meets the needs of the industry. Narrative We propose to evaluate a particle recognition technique to enable accurate and rapid identification of unwanted contaminating particles in biopharmaceutical formulations. Successful development of this analytical technique would improve bioprocess control by identifying dangers early on in development and throughout the manufacturing process, resulting in safer protein drugs, reduced recalls and shortened time to market.",Partelligence,9679781,R43GM132995,"['Adverse effects', 'Algorithmic Analysis', 'Algorithms', 'Allergic Reaction', 'Alpha Particles', 'Anaphylaxis', 'Antibodies', 'Back', 'Biological Neural Networks', 'Biological Products', 'Cessation of life', 'Classification', 'Clinic', 'Dangerousness', 'Data', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Event', 'Failure', 'Fluorescence', 'Forensic Medicine', 'Formulation', 'Generations', 'Glass', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immune', 'Immune response', 'Industrialization', 'Industry', 'Investigation', 'Label', 'Learning', 'Letters', 'Machine Learning', 'Membrane', 'Morphology', 'Optics', 'Particulate', 'Particulate Matter', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Process', 'Proteins', 'Raman Spectrum Analysis', 'Regulation', 'Resistance development', 'Risk', 'Rubber', 'Sampling', 'Scientist', 'Shapes', 'Source', 'Specificity', 'Spectroscopy, Fourier Transform Infrared', 'Syringes', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Work', 'base', 'bioprocess', 'combinatorial', 'experience', 'experimental study', 'fluorescence imaging', 'forest', 'imaging modality', 'immunogenicity', 'improved', 'instrument', 'manufacturing process', 'microscopic imaging', 'particle', 'patient response', 'patient safety', 'predictive modeling', 'pressure', 'protein aggregate', 'small molecule', 'therapeutic protein', 'tool', 'trend']",NIGMS,"OPTOFLUIDICS, INC.",R43,2018,203830,-0.04782002100029418
"Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms Project Summary This project will create and assess new optical imaging and computational technologies with the goal of improving the detection rates of precancerous, non-polypoid lesions during colonoscopy screening. Identifying and removing these subtle lesions is critical to improving the protective value of colonoscopy in reducing mortality from colorectal cancer. However, current approaches to non-polypoid lesion detection are largely unsuccessful because they are time-consuming and require specialized training (chromoendoscopy), or they start with poor image contrast (software analysis of conventional video). This project focuses on developing a novel technique, called quantitative topographic endoscopy (QTE), that optically measures colon surface properties via a modified commercial colonoscope. The key innovation in this proposal is to utilize structured illumination and build on concepts from computer vision and optical engineering to acquire high-resolution 3D images of the colon surface through a custom endoscope. The project will be implemented through three specific aims: (1) develop a miniaturized, quantitative, high-resolution topography system, (2) implement QTE in a modified commercial colonoscope ready for clinical testing, and (3) determine the validity of QTE in a phantom model and its clinical feasibility in a pilot human study. QTE systems developed in this project will be tested in tissue-mimicking phantoms with a goal of achieving better than 1-mm height sensitivity, in ex-vivo resected colon samples with a goal of accurately reconstructing surface shapes from a complex tissue, and in a pilot human study with the goal of obtaining surface topography non-polypoid lesions. Beyond increasing non-polypoid lesion detection rates, QTE has the potential to address other limitations of colonoscopy, including preventing missed polypoid lesions, classifying lesions for resect-and-discard strategies, and improving colonoscopy quality metrics. Additionally, the development of a QTE system that is approved for human studies will serve as a platform for future clinical assessment of other optical techniques such as spatial frequency domain imaging and speckle imaging in a variety of gastroenterology applications. Project Narrative Colorectal cancer is the second leading cause of cancer death in the United States. Screening colonoscopy can significantly reduce mortality from colorectal cancer but is limited by high miss rates for precancerous non- polypoid lesions. This project will develop new imaging and computational techniques for improving the detection rates of these lesions during colonoscopy screening.",Quantitative topographic endoscopy for improved screening of non-polypoid colorectal neoplasms,9456285,R21EB024700,"['Address', 'Adult', 'Algorithms', 'American', 'Area', 'Biopsy', 'Caliber', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical assessments', 'Colon', 'Colonoscopes', 'Colonoscopy', 'Color', 'Colorectal', 'Colorectal Cancer', 'Colorectal Neoplasms', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Custom', 'Data', 'Detection', 'Development', 'Dyes', 'Effectiveness', 'Elements', 'Endoscopes', 'Endoscopy', 'Engineering', 'Foundations', 'Frequencies', 'Future', 'Gastroenterology', 'Goals', 'Height', 'Human', 'Hybrids', 'Image', 'Imaging Techniques', 'Interobserver Variability', 'Knowledge', 'Large Intestine', 'Lesion', 'Light', 'Lighting', 'Malignant - descriptor', 'Maps', 'Measurement', 'Measures', 'Morphology', 'Motion', 'Mucous Membrane', 'Optics', 'Patients', 'Pilot Projects', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Premalignant', 'Procedures', 'Research', 'Research Proposals', 'Resected', 'Resolution', 'Sampling', 'Shapes', 'Source', 'Spatial\xa0Frequency\xa0Domain\xa0Imaging', 'Structure', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Image', 'Time', 'Tissues', 'Training', 'United States', 'adenoma', 'base', 'chromoscopy', 'colorectal cancer risk', 'computer aided detection', 'contrast imaging', 'human study', 'imaging system', 'improved', 'innovation', 'miniaturize', 'mortality', 'novel', 'optical imaging', 'phantom model', 'prevent', 'research clinical testing', 'routine screening', 'screening', 'vector']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2018,295916,-0.03922957784936334
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9438535,R01EY025332,"['Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2018,416574,-0.00383990527954784
SCH: INT: A Context-aware Cuff-less Wearable Ambulatory Blood Pressure Monitor using a Bio-Impedance Sensor Array  n/a,SCH: INT: A Context-aware Cuff-less Wearable Ambulatory Blood Pressure Monitor using a Bio-Impedance Sensor Array,9756906,R01EB028106,"['Address', 'Adult', 'Affect', 'Aging', 'Algorithms', 'Ambulatory Blood Pressure Monitoring', 'American', 'American Heart Association', 'Arteries', 'Awareness', 'Biological Markers', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood Vessels', 'Calibration', 'Cardiology', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Caring', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Frequencies', 'Funding', 'Grain', 'Guidelines', 'Health Sciences', 'Home environment', 'Hour', 'Human Resources', 'Hypertension', 'Institutes', 'Institution', 'International', 'Intervention Trial', 'Investigation', 'Laboratories', 'Left ventricular structure', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Phenotype', 'Physicians', 'Physiologic pulse', 'Physiological', 'Play', 'Positioning Attribute', 'Posture', 'Preventive Intervention', 'Reading', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Site', 'Skin', 'Source', 'Specific qualifier value', 'Speed', 'Sphygmomanometers', 'System', 'Technology', 'Testing', 'Texas', 'Time', 'Tissues', 'Travel', 'United States National Institutes of Health', 'Universities', 'Validation', 'Wearable Computer', 'Wrist', 'base', 'blood perfusion', 'cardiovascular disorder risk', 'clinical practice', 'cohesion', 'college', 'cost', 'design', 'disability-adjusted life years', 'disorder prevention', 'electric impedance', 'health disparity', 'hypertension control', 'learning strategy', 'minority health', 'novel', 'novel strategies', 'patient population', 'sensor', 'signal processing', 'therapy development', 'validation studies', 'wearable device']",NIBIB,TEXAS ENGINEERING EXPERIMENT STATION,R01,2018,299998,-0.033036667882830294
"Fast and Robust Low-Dose X-Ray CT Image Reconstruction Abstract:  The use of CT scans has recently increased, for example, in virtual colonoscopy, CT cardiac screening, screening of the lung in smokers, whole-body CT in asymptomatic patients, and CT imaging of children. Shortening of the scanning time to around 1 second, eliminating the strict need for the subject to remain still or be sedated, is one of the main reasons for the large increase in the pediatric population. CT scans of children have been estimated to produce non-negligible increases in the probability of lifetime cancer mortality, leading to calls for the use of reduced current settings for CT scans of children. For these reasons, the CT industry has put in a lot of effort to develop low-dose CT. One active area of research is methods to reduce the radiation counts by applying adaptive collimation to block unnecessary x-ray photons. Another active area of research is the development of more robust image reconstruction algorithms that are less sensitive to noise for low-count data.  This grant proposal is focused on the second approach — development of fast and robust reconstruction algorithms. It is known that some iterative image reconstruction algorithms outperform the analytical filtered backprojection (FBP) algorithm in terms of producing less-noisy images with the same data set. One disadvantage of these iterative algorithms is their long computation time, making them impractical in a real- world CT reconstruction tasks. For this reason, the FBP algorithm is still the main work horse for CT applications.  The main goal of the proposed research is to develop fast and robust iterative-algorithms so that their computation time is at the same order of an analytic FBP algorithm, using experimental low-dose phantom, cadaver data, and low-dose cancer screen chest CT patient data to perform comparison studies. We will answer the question: When the fast and robust algorithms are used, how much can the CT dose be reduced while retaining the image quality of a standard-dose CT produced by the conventional FBP?  This R15 project provides Weber State University (WSU) computer engineering and computer science students with hands-on opportunities and experiences of performing real-world research in the field of healthcare. It will stimulate the interests of students so that they consider a career in biomedical and bioengineering field/industry. Narrative:  CT dose is currently a major concern for the general public. Low-dose CT is under development. The proposed research will focus on developing fast, robust and practical image reconstruction methods that are able to produce a standard CT image using a lower CT dose.",Fast and Robust Low-Dose X-Ray CT Image Reconstruction,9440734,R15EB024283,"['Algorithms', 'Applications Grants', 'Area', 'Biomedical Engineering', 'Cadaver', 'Cancer Patient', 'Cardiac', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Collimator', 'Computed Tomographic Colonography', 'Computer Hardware', 'Computer Simulation', 'Computers', 'Contracts', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Dimensions', 'Disadvantaged', 'Disease', 'Dose', 'Engineering', 'Environment', 'Equilibrium', 'Equus caballus', 'Evaluation', 'General Population', 'Goals', 'Healthcare', 'Human', 'Image', 'Industry', 'Inferior', 'Internships', 'Investigation', 'Learning', 'Lesion', 'Liver Cirrhosis', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Morphologic artifacts', 'Noise', 'Patients', 'Performance', 'Photons', 'Population', 'Preparation', 'Probability', 'Radiation', 'Radiation exposure', 'Research', 'Resolution', 'Roentgen Rays', 'Running', 'Scanning', 'Screening for cancer', 'Smoker', 'Structure', 'Students', 'Supervision', 'Time', 'Training', 'Universities', 'Utah', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'career', 'chest computed tomography', 'clinical application', 'computer science', 'data acquisition', 'design', 'digital imaging', 'experience', 'high risk', 'image reconstruction', 'improved', 'interest', 'low-dose spiral CT', 'lung cancer screening', 'mortality', 'parallel computer', 'professor', 'radiologist', 'reconstruction', 'screening', 'tomography', 'university student']",NIBIB,WEBER STATE UNIVERSITY,R15,2018,88321,-0.03331181365272441
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9679722,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Autistic Disorder', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2018,303226,-0.02225070204084334
"A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions Abstract. Melanoma is the third most common form of skin cancer with estimated 87,110 new cases diagnosed in the United States in the year 2017. Current routine diagnostic approaches utilize microscopic evaluation of thinly sectioned patient biopsies, but in certain cases diagnosis can be contentious even among experts. The overall goal of this multi-phase SBIR project is to develop, validate, and commercialize MelanoMapTM, Frontier Diagnostics' patented assay for the diagnosis of melanoma using a matrix-assisted laser desorption/ionization imaging mass spectrometry (MALDI IMS) platform—and to have this assay available to pathologists in the U.S. as a laboratory developed test. MALDI IMS is a state-of-the-art technology that generates molecular images of tens to thousands of biomolecules from tissue sections in a single analysis. The assay uses formalin-fixed paraffin embedded (FFPE) biopsies used in routine histopathological diagnosis. The proposed assay has pathologists select regions of skin biopsies for analysis via a remote web interface. The acquired IMS data from those regions unambiguously identifies malignant melanoma or benign nevus.  Phase I of this proposal will demonstrate the feasibility of this technology platform to achieve cost-effective diagnosis of melanoma from patient skin biopsies at sample volumes acceptable for a clinical laboratory. Specific Aim 1 focuses on the development of a scalable and robust analytical protocol in both sample preparation and informatics to accurately diagnose melanoma with MALDI IMS. In specific aim 2, we will test the methodology developed in Specific Aim 1 on a cohort of melanocytic lesions with known clinical outcome and subsequently validate the classification accuracy of the proposed test  In Phase II, the protocols developed in Phase I will be integrated into a diagnostic service workflow. This phase will focus on quality control measures, client facing cloud software, clinical diagnostic reporting, and completing the analysis of a 500-patient sample set for final assay validation. Specific Aim 3 of this proposal (initial aim of Phase II) will establish and implement test tissues into standard workflows that will provide performance metrics for standard operation of a test meeting Clinical Laboratory Improvement Amendments (CLIA) standards. Protocols will be developed to monitor reagents, the reproducibility of sample preparation, and mass spectrometer performance on daily basis. Specific Aim 4 will expand software capabilities to include a secure web interface for clients ordering the test and the laboratory performing the test. The software will meet regulatory compliance, perform statistical analysis, and generate and communicate reports of the MALDI IMS analysis. Specific Aim 5 proposes to expand the sample set used in the initial assay from Specific Aim 2 to include a set of 300 patient samples from our clinical collaborators with 5 or more years follow-up data. The test will be independently validated by an additional 200 patient samples with definitive diagnoses. Project Narrative This multi-phase Fast Track SBIR project will develop and validate a new laboratory developed test to differentiate malignant melanocytic tumors from benign nevi and complete development of an imaging mass spectrometry-based diagnostic service platform for a clinical laboratory. The clinical assay developed under this proposal augments current practice by providing molecular measurements that are used as objective criteria in the diagnosis of melanoma. Successful completion of this Fast Track project will result in a fully documented and validated assay ready for launch as a laboratory developed test.",A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions,9557356,R44CA228897,"['Algorithms', 'Amendment', 'Antigens', 'Area', 'Benign', 'Biological Assay', 'Biopsy', 'Caliber', 'Cells', 'Cessation of life', 'Classification', 'Client', 'Clinical', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Services', 'Digestion', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Formalin', 'Goals', 'Gold', 'Image', 'Incentives', 'Informatics', 'Laboratories', 'Legal patent', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Melanocytic Neoplasm', 'Metadata', 'Methodology', 'Microscopic', 'Microtomy', 'Molecular', 'Monitor', 'Nevus', 'Outcome', 'Paraffin Embedding', 'Pathologist', 'Pathology Report', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Physical shape', 'Physicians', 'Preparation', 'Procedures', 'Proteins', 'Protocols documentation', 'Quality Control', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Retrieval', 'Risk', 'Sampling', 'Secure', 'Security', 'Sensitivity and Specificity', 'Side', 'Skin', 'Skin Cancer', 'Small Business Innovation Research Grant', 'Software Tools', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Standardization', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Treatment Cost', 'United States', 'Validation', 'accurate diagnosis', 'analytical method', 'base', 'clinical diagnostics', 'cloud software', 'cohort', 'cost', 'cost effective', 'data acquisition', 'diagnosis standard', 'diagnostic assay', 'disease classification', 'follow-up', 'frontier', 'histopathological examination', 'instrumentation', 'interest', 'mass spectrometer', 'meetings', 'melanoma', 'molecular diagnostics', 'molecular imaging', 'operation', 'prototype', 'quality assurance', 'skin lesion', 'tissue preparation', 'web interface']",NCI,"FRONTIER DIAGNOSTICS, LLC",R44,2018,299244,-0.002354929443162657
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9483579,R00AG046911,"['Address', 'Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Drug Screening', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'imaging modality', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'public health relevance', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2018,249000,-0.020638281682895318
"Automated Diagnosis and Progression Rate of IPF Using HRCT Project Summary: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. Diagnosis and stratification of disease phenotypes are important in order to decipher the effects of novel therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individuals. Few computerized diagnostic tools have been developed for IPF that correlate with visual and surgical lung biopsy; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good predictive models with localized region exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use as a derivative dataset the anonymized clinical data and source images on 234 patients with IPF and 266 patients with IPF suspected, but not IPF based on HRCT and the surgical biopsy who have participated in multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for high through-put quantitative image analysis, we will train a classifier with features of anatomic distribution and reproducible imaging features expressed with a quantitative lung fibrosis (QLF) score, testing on separate data from in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitial Lung Disease Program. Furthermore, the second aim is to develop a rate of progression at local region and to aggregate predictive models using Cox proportional regression models, which will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that diagnose and anticipate disease course in patients with IPF and subdividing patients into more homogeneous groups prior to the development of significant respiratory impairment. We anticipate that models can be used clinically at the individual patient level to enable more informed and timely management decisions to define more homogeneous cohorts for purposes of testing new targeted therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. Relevance to Public Health: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rate of progression is highly variables, which hampers timely decisions about referral for lung transplantation or treatments using new drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to diagnose and predict disease course robustly in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with IPF and non-IPF with reducing chance of lung biopsy and predict slowly versus rapidly progressive disease, leading to more time to treat patients and timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Automated Diagnosis and Progression Rate of IPF Using HRCT,9592308,R21HL140465,"['Acute', 'Air', 'Algorithms', 'Anatomy', 'Archives', 'Automation', 'Biological', 'Biopsy', 'Categories', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease stratification', 'Elderly', 'Etiology', 'Exhibits', 'General Population', 'Glass', 'Goals', 'Growth', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Informatics', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Laboratories', 'Lobar', 'Lobe', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathology', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Prevalence', 'Probability', 'Progression-Free Survivals', 'Progressive Disease', 'Public Health', 'Pulmonary Fibrosis', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Spatial Distribution', 'Stable Disease', 'Standardization', 'Testing', 'Texture', 'Time', 'Time Management', 'Training', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinically relevant', 'cohort', 'computerized', 'data archive', 'digital imaging', 'disease natural history', 'disease phenotype', 'functional decline', 'idiopathic pulmonary fibrosis', 'image processing', 'imaging biomarker', 'improved', 'individual patient', 'individualized medicine', 'new therapeutic target', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'success', 'survival prediction', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2018,113241,-0.060763813743633696
"Detecting biochemical changes in the pregnant mouse cervix by Raman spectroscopy DESCRIPTION (provided by applicant): Our understanding of cervical remodeling during pregnancy and labor is incomplete, partly due to the lack of in vivo studies on the biochemical changes that occur in the cervix over the course of pregnancy. Elucidation of the mechanisms for cervical ripening could be used to predict the onset of preterm labor. Until recently, in vivo research methods were too invasive to be used as discovery tools, particularly in women who present with preterm labor. This proposal will use in vivo Raman spectroscopy, an optical technique that is sensitive to collagen content, collagen structure, hydration, lipids, proteins, ad other biomolecules to non-invasively investigate the biochemistry of the cervix throughout pregnancy. Using fiber optic in vivo Raman spectroscopy, we recently found significant differences in Raman spectra in at least four important peaks during the course of pregnancy in mice, including discrete signatures for lipids, collagen, amide bonds, and enriched amino acids (proline, tyrosine). Computational analysis of these spectra yielded predictive algorithms with 94% classification accuracy for stage of pregnancy. Studies performed in 2-hour windows at the end of pregnancy identified spectra predictive for the timing of parturition. This approach provides a detailed real-time biomolecular map of cervical ripening that is currently unavailable by other means. In this proposal, we hypothesize that the different mechanisms of premature cervical ripening have unique Raman spectral signatures that correspond to underlying biochemical and mechanical changes that precede preterm birth, which can be detected in vivo. Two Specific Aims are proposed: 1) Determine spectral changes in the cervix of mice with normal and abnormal pregnancy and parturition; 2) Identify specific mediators of cervical remodeling by comparing Raman spectra to mechanical and biochemical changes in the ex vivo cervix during normal and abnormal parturition. Raman spectroscopy has primarily been used for detection of disease. Collaboration between our reproductive biology and bioengineering groups will capitalize on our expertise in Raman analysis of cervical tissues to study dynamic changes in cervix composition during pregnancy. Key elements in cervical biochemistry will be identified. In vivo Raman spectroscopy will be combined with biomechanical studies and imaging mass spectrometry, a powerful tool for in situ proteomic analysis, to examine mice with premature or delayed cervical remodeling. Together, these highly innovative approaches will generate in-depth profiles of cervical biology that will translate into novel non-invasive methods to detect impending premature birth in women. PUBLIC HEALTH RELEVANCE: This proposal will use Raman Spectroscopy, a non-invasive, optical scattering technique, to investigate the composition of the cervix throughout pregnancy and provide detailed real-time information on cervical ripening. These studies will identify spectral differences in the cervix during normal and abnormal cervical maturation; optical and biochemical markers will be identified to help monitor pregnancy non-invasively, as the fiber optic probe only requires brief contact with the external surface of the cervix to obtain measurements. Elucidating the mechanisms that initiate cervical ripening will provide a critical step for early detection and treatment of preterm birth, which is the leading cause of infant morbidity and mortality.",Detecting biochemical changes in the pregnant mouse cervix by Raman spectroscopy,9505946,R01HD081121,"['Address', 'Algorithms', 'Alprostadil', 'Amides', 'Amino Acids', 'Applications Grants', 'Biochemical', 'Biochemical Markers', 'Biochemistry', 'Biological', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biomechanics', 'Biomedical Engineering', 'Birth', 'Cervical', 'Cervical Ripening', 'Cervix Uteri', 'Classification', 'Clinical', 'Collaborations', 'Collagen', 'Computational algorithm', 'Computer Analysis', 'Data', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Elements', 'Emerging Technologies', 'Etiology', 'Fetal Development', 'Fiber Optics', 'Foundations', 'Generations', 'Goals', 'Health', 'High-Risk Pregnancy', 'Hormonal', 'Hour', 'Hydration status', 'Image', 'Immunohistochemistry', 'Impairment', 'In Situ', 'In Situ Hybridization', 'Interdisciplinary Study', 'Laboratories', 'Lead', 'Link', 'Lipids', 'Machine Learning', 'Maintenance', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mechanics', 'Mediator of activation protein', 'Medical', 'Methods', 'Mifepristone', 'Modality', 'Molecular', 'Molecular Profiling', 'Monitor', 'Mus', 'Optics', 'Periodicity', 'Phenotype', 'Physiological', 'Pregnancy', 'Premature Birth', 'Premature Labor', 'Prevention', 'Process', 'Proline', 'Property', 'Proteins', 'Proteomics', 'Raman Spectrum Analysis', 'Reproductive Biology', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Spectrum Analysis', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Tyrosine', 'Woman', 'base', 'clinical application', 'in vivo', 'infant morbidity/mortality', 'innovation', 'insight', 'learning strategy', 'mouse model', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'physical science', 'prediction algorithm', 'predictive modeling', 'pregnant', 'premature', 'public health relevance', 'response', 'tool']",NICHD,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,387714,-0.018641968652398668
"A Real-Time Computational System for Detecting ARDS Using Ventilator Waveform Data No abstract available Project Narrative: Acute respiratory distress syndrome (ARDS) is a highly lethal disease contracted by over 100,000 Americans each year. We seek to address whether we can create automated technologies to detect onset and change in severity of ARDS in critically ill patients using widely available ventilator waveform data. With these automated diagnostic testing technologies, doctors can promptly deliver necessary treatments for ARDS before the disease worsens.",A Real-Time Computational System for Detecting ARDS Using Ventilator Waveform Data,9612053,F31HL144028,"['Acute', 'Acute respiratory failure', 'Address', 'Adult Respiratory Distress Syndrome', 'Affect', 'Airway Resistance', 'Algorithms', 'American', 'Automation', 'Berlin', 'Chest', 'Classification', 'Clinical', 'Complex', 'Computational algorithm', 'Contracts', 'Critical Illness', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Model', 'Detection', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Discipline', 'Disease', 'Electronic Health Record', 'Hospital Mortality', 'Hour', 'Hypoxemia', 'Intensive Care Units', 'Intervention', 'Learning', 'Life', 'Lung', 'Machine Learning', 'Mechanical ventilation', 'Medical History', 'Modeling', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Physiological', 'Physiology', 'Provider', 'Recording of previous events', 'Reporting', 'Reproducibility', 'Research', 'Respiratory Failure', 'Sampling', 'Savings', 'Scanning', 'Series', 'Severities', 'Specific qualifier value', 'Statistical Methods', 'System', 'Techniques', 'Technology', 'Time', 'United States', 'Ventilator', 'Work', 'adjudicate', 'base', 'clinical decision support', 'clinical predictors', 'clinical translation', 'cohort', 'computer science', 'deep learning', 'high dimensionality', 'high risk', 'improved', 'improved outcome', 'innovation', 'insight', 'markov model', 'model development', 'mortality', 'novel', 'predictive modeling', 'predictive tools', 'prevent', 'prognostic', 'recurrent neural network', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA AT DAVIS,F31,2018,36701,-0.04612746464498848
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9449456,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Analysis', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Modality', 'Modernization', 'Morphology', 'Multimodal Imaging', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Pharmacology', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Reproducibility', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Time', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'clinical imaging', 'disease diagnosis', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'imaging study', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2018,64155,-0.020942997562971757
"A Direct Reading Video Assessment Instrument for Repetitive Motion Stress Project Summary/ Abstract This research studies if computer vision can more effectively evaluate worker exposure and assess the associated risk for work related injuries than conventional methods. Current methods involve either observations or measurements using instruments attached to a worker's hands or arms. Observation is often considered too subjective or inaccurate, and instruments too invasive or time consuming for routine applications in industry. Automated job analysis potentially offers a more objective, accurate, repeatable, and efficient exposure assessment tool than observational analysis. Computer vision uses less resources than instruments attached to workers and does not interfere with production; can quantify more exposure variables and interactions; is suitable for long-term, direct reading exposure assessment; and offers animated data visualizations synchronized with video for identifying aspects of jobs needing interventions. This research leverages the research from coordinated multi-institutional prospective studies of upper limb work related MSD conducted between 2001 and 2010 that studied production and service workers from a variety of US industries, and used rigorous case-criteria and individual-level exposure assessments prospectively, including recording detailed videos of the work. Our study partners from the National Institute for Occupational Safety and Health, the Washington State Labor & Industries Safety & Health Assessment & Research for Prevention program and the University of California-San Francisco will provide task-level videos, associated exposure variable data, and prospective health outcomes for 1,649 workers. Exposure properties directly measured from videos of jobs and corresponding health outcomes from the prospective study database will establish dose-response relationships to translate into a prototype automated job analysis instrument. We build on our previous success in developing video marker-less hand motion algorithms for estimating the ACGIH hand activity level, and reliable video processing methods for hand tracking under challenging viewing conditions. This proposal will refine and develop additional video algorithms, and analyze the videos to extract exposure measures for repetition, posture, exertions, and their interactions. The video extracted exposure measures will be compared against conventional observational exposure measures made by our collaborators. Video and corresponding observational data will be merged with the prospective health outcomes data to evaluate dose-response and to develop and validate parsimonious exposure risk models for an automated direct reading repetitive motion instrument. We will test if automation has better predictive capability than observation and also consider the accuracy and utility of computer vision analysis against conventional job analysis for selected industrial jobs. This proposal addresses the NIOSH cross-sector programs in Musculoskeletal Disorders as well as in Exposure Assessment. This translational research is in concurrence with the Research to Practice (r2P) initiative by developing technology to disseminate knowledge from recent NIOSH sponsored prospective studies on MSDs. Project Narrative  Upper extremity musculoskeletal injuries are common in hand intensive work involving highly repetitive motions  and exertions and impose a significant socioeconomic burden and substantial personal toll on health,  prosperity and wellbeing.  This proposal investigates a practical approach for exposure assessment of jobs that  can be implemented non-­invasively in the workplace and provide direct reading quantitative measures for  evaluation, prevention and control.   ",A Direct Reading Video Assessment Instrument for Repetitive Motion Stress,9515581,R01OH011024,[' '],NIOSH,UNIVERSITY OF WISCONSIN-MADISON,R01,2018,465109,-0.017937667088144826
"Innovative text-mining tools to accelerate citation screening: comparative efficiency and impact on conclusions Project Summary Systematic reviews (SRs) synthesize and critically assess bodies of evidence to produce a comprehensive unbiased assessment of what is known. As such, SRs are vital for evidence-based decision-making. However, given the pace of new research, the process of developing an SR remains too slow. One particularly time-consuming step in the process is citation screening, which requires manual review of thousands of abstracts to identify only a small number of relevant studies. Screening such large numbers of studies is necessary because systematic reviewers place a high priority on identifying all relevant studies to avoid bias. Innovative citation screening tools, which utilize text-mining and new sophisticated machine learning methods, represent one potential solution. Abstrackr (Brown University) and EPPI-Reviewer (University College London) are off- the-shelf, web-based citation screening tools designed to improve screening efficiency. Both programs utilize machine- learning techniques to semi-automate the screening process by modeling the probability that each citation will meet criteria for inclusion. This allows efficiency gains through screening prioritization and screening truncation. With screening prioritization, citations are organized for screening from highest to lowest likelihood of inclusion. This allows earlier retrieval of full-text articles and facilitates workflow planning. Organizing citations by likelihood of inclusion also allows reviewers the option of truncating the screening process when remaining citations fall below a certain threshold. While promising, existing studies have predominantly been performed by computer scientists testing individual tools or comparing different modeling algorithms (e.g., various classifiers). To date, no studies have performed a direct comparison of citation screening tools. Similarly, although automatically excluding citations that fall below particular thresholds could substantively improve efficiency, adoption has been low due to concerns that relevant studies could be missed. However, how often studies would be missed and how important such omissions would be remains unknown. To address these knowledge gaps, this project will (1) Compare screening efficiency for two citation-screening tools, Abstrackr and EPPI-reviewer, and (2) Characterize the potential impact of using thresholds to exclude low probability studies automatically. To address aim 1, using citations from 3 large and 6 small completed evidence reports, we will compare Abstrackr to EPPI-Reviewer for citation screening. Using screening prioritization, we will assess what proportion of articles must be screened to identify all included studies (e.g., to achieve 100% sensitivity). For Aim 2, we will explore the potential impact of excluding all citations that fall below particular thresholds during the screening process. We will also assess to what extent missing these studies would alter report conclusions. By characterizing potential efficiency gains from new, innovative, and widely accessible tools, this project can facilitate wider adoption by evidence based practice centers seeking to speed systematic review production. Project Narrative Systematic reviews provide a comprehensive, unbiased assessment of a body of literature and are vital for timely, evidence-based decision-making. However, development of systematic reviews remains too slow, with one particularly time-consuming step being citation screening, in which thousands of research abstracts are manually reviewed to identify a small number of relevant studies. By testing potential gains in citation screening efficiency offered by two innovative, widely-accessible machine- learning tools (Abstrackr and EPPI–Reviewer), and determining if automatically excluding studies to improve speed compromises report conclusions, we hope to enable more rapid production of systematic reviews to inform clinicians and policy-makers and promote high quality, evidence-based patient care.",Innovative text-mining tools to accelerate citation screening: comparative efficiency and impact on conclusions,9435231,R03HS025859,[' '],AHRQ,ECRI INSTITUTE,R03,2018,95324,-0.014360483540340523
"Fully-automated lesion characterization in ultrawide-field retinal images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-automated lesion characterization in ultrawide-field retinal images,9559582,R43EY028081,"['Agreement', 'Algorithms', 'Anti-HIV Agents', 'Applications Grants', 'Architecture', 'Area', 'Biological', 'Blindness', 'Cataract', 'Categories', 'Characteristics', 'Clinical', 'Cloud Computing', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Engineering', 'Ensure', 'Exposure to', 'Exudate', 'Eye', 'Eye diseases', 'Eyelash', 'Gold', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Lasers', 'Lesion', 'Light', 'Manuals', 'Measures', 'Microaneurysm', 'Modality', 'Morphologic artifacts', 'Normalcy', 'Ophthalmoscopy', 'Output', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Receiver Operating Characteristics', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Spottings', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Vision', 'Work', 'base', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fovea centralis', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'operation', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'software development', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2018,216440,-0.005886451255257697
"RetiVue DR, a point and shoot, non-mydriatic, widefield retinal camera for diabetic eye screening Project Summary Over the past two decades, diabetic retinopathy (DR) has become the leading cause of adult blindness in the US, affecting 40% of all diabetic patients and resulting in $500 million a year in direct medical costs. Vision loss due to DR is largely preventable and can be reduced by up to 90% with appropriate eye screening. However, in the US, less than 50% of diabetic patients receive a recommended yearly eye exam due to many factors that include lack of access to eye care professionals. Distributed tele-ophthalmic screening thru primary care clinics can potentially provide all diabetic patients cost- effective, yearly evaluations to detect DR and prevent vision loss. However, gold-standard sensitive detection of DR using standard retinal photography is complex and cumbersome process requiring up to 7 images per eye. This screening process cannot for all practical purposes be achieved without having highly trained ophthalmic photographers. RetiVue proposes to develop the RetiVue DR in collaboration with Olympus, to create the first handheld, non- mydriatic, 160 field of view, widefield DR screening camera. It will allow single photo capture of an area up to ten times greater than conventional fundus cameras, allowing sensitive detection of DR at its earliest time points. Full integration of RetiVue and Olympus hardware will enable the most advanced and highest image quality handheld retina camera on the market. Use of automated alignment, auto laser focus, and auto image capture will allow complex imaging of the retina to be performed simply by positioning the iris, requiring no user knowledge of retinal anatomy. We have established clinical proof of concept with our patented technology, but require several additional innovations in optical design, automated image recognition, and retinal image processing to enable a commercial device. We will for this proposal optimize our alignment system and laser based focusing system for widefield imaging, allowing automated alignment and focus to image the retina before eye movement occurs. We will develop a new method of widefield, non-mydriatic peripheral retinal imaging using multiple LED slit-beam projectors to allow rapid, segmental, sequential image capture of 90°, 120°, and 160° FOV on diabetic patients. Finally, we will create the most advanced retinal image processing algorithms to remove Purkinje haze which prevents conventional cameras from imaging beyond 45° FOV and enable seamless stitching of segmental peripheral retina images into a single widefield image. Project Narrative Diabetic retinopathy is a blinding eye disease that affects millions of people with diabetes and costs the US $500 million a year in medical costs. Loss of vision can be prevented if diabetic patients undergo yearly eye screening that examines the retina to detect this disease, but currently less than 50% of diabetics do so. At Re- tiVue LLC, we are designing the first easy to use handheld eye camera to allow primary care doctors to take DSLR quality pictures of the eye to look for diabetic retinopathy. Our eye camera will see 5 times more of the retina than any other handheld camera, ensuring that we find diabetic retinopathy when it first occurs. Earlier detection of diabetic retinopathy will give diabetic patients the best chance to keep their vision long term, and avoid unnecessary blindness.","RetiVue DR, a point and shoot, non-mydriatic, widefield retinal camera for diabetic eye screening",9564677,R44EY028484,"['Adult', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Americas', 'Anatomy', 'Animals', 'Area', 'Blindness', 'Caring', 'Clinic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Color', 'Complex', 'Custom', 'Detection', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Diagnostic Imaging', 'Direct Costs', 'Disease', 'Early Diagnosis', 'Electronics', 'Ensure', 'Evaluation', 'Eye', 'Eye Movements', 'Eye diseases', 'Fundus photography', 'Generations', 'Gold', 'Human', 'Image', 'Imagery', 'Imaging technology', 'Iris', 'Knowledge', 'Lasers', 'Legal patent', 'Light', 'Lighting', 'Masks', 'Medical Care Costs', 'Methods', 'Modeling', 'Movement', 'Ophthalmic examination and evaluation', 'Optics', 'Patients', 'Peripheral', 'Phase', 'Photography', 'Physicians', 'Positioning Attribute', 'Predictive Value', 'Primary Health Care', 'Procedures', 'Process', 'Pupil', 'Resolution', 'Retina', 'Retinal', 'Sensitivity and Specificity', 'Specificity', 'Speed', 'Surface', 'System', 'TNFRSF10B gene', 'Technology', 'Time', 'Training', 'Ultraviolet Rays', 'Validation', 'Visible Radiation', 'Vision', 'base', 'compliance behavior', 'cost', 'cost effective', 'deep learning', 'design', 'detector', 'diabetic', 'diabetic patient', 'image processing', 'imager', 'improved', 'innovation', 'laptop', 'lens', 'novel', 'point of care', 'prevent', 'prototype', 'retinal imaging', 'sample fixation', 'screening', 'seal', 'sensor', 'success']",NEI,RETIVUE,R44,2018,847697,-0.013872625964596638
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9548627,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2018,573677,-0.013680033293577303
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning. PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,9133939,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Awareness', 'Behavior', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Conscious', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Foundations', 'GTP-Binding Protein alpha Subunits, Gs', 'Hand functions', 'Head', 'Head Movements', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Research', 'Robot', 'Robotics', 'Subconscious', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'public health relevance', 'robot control', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2017,133916,-0.02441447613380641
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,9215686,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cells', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Education', 'Educational Curriculum', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'faculty research', 'graduate student', 'lecturer', 'lectures', 'personalized approach', 'programs', 'public health relevance', 'quantitative imaging', 'student training', 'teaching assistant', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2017,59383,0.0002179212586463577
"Artificial neural networks for high performance, fully automated particle tracking analysis even at low signal-to-noise regimes Abstract: Particle tracking (PT) is a powerful biophysical tool for elucidating molecular interactions, transport phenomena and rheological properties in complex biological environments. Unfortunately, PT remains a niche tool in life and physical sciences with a limited user base, in large part due to significant time and technical constraints in extracting accurate time-variant positional data from recorded movies. These constraints are exacerbated in experiments with low signal-to-noise ratios or substantial heterogeneity, as frequently encountered with nanoparticles and pathogens in biological fluids. Currently available software that attempts to automate the movie analysis process rely almost exclusively on assigning static image filters based on specific intensity, pixel size and signal-to-noise ratio thresholds. Unfortunately, when applied to actual experimental data with substantial spatial and temporal heterogeneity, the current software generally produces substantial numbers of false positives (i.e. tracking artifacts) or false negatives (i.e. missing actual traces), and frequently both. Frequent user intervention is thus required to ensure accurate tracking even when using sophisticated tracking software, markedly reducing experimental throughput and resulting in substantial user- to-user variations in analyzed data. The time required for accurate particle tracking analysis makes PT experiments exceedingly expensive compared to other commonly used experimental techniques in life sciences. These same tracking analysis limitations have effectively precluded investigators from undertaking more sophisticated 3D PT, even though the microscopy capability to obtain such movies is readily available and critical scientific insights can be gained from 3D PT. To circumvent the challenges with currently available particle tracking software, we have developed a new approach for particle identification and tracking, based on machine learning and convolutional neural networks (CNN). CNN is a type of feed-forward artificial neural network designed to process information in a layered network of connections that mimics the organization of real neural networks in the mammalian retina and visual cortex. Unlike most CNN imaging models that are trained to make predictions on static images, we have trained our CNN to input adjacent frames so that each prediction includes information from the past and future, thus effectively performing convolutions in both space and time to infer particle locations. Similar principles of image analysis are now being harnessed by developers of autonomous vehicle technologies to distinguish the motions of different objects on the road. We have applied our CNN tracking algorithm to a wide range of 2D movies capturing dynamic motions of nanoparticles, viruses and highly motile bacteria, achieving at least 30-fold time savings with virtually no need for human intervention while maintaining robust tracking performance (i.e. low false positive and low false negative rates). In this STTR proposal, we seek to focus on further optimization and testing of our neural network tracking platform for 2D PT, including the use of cloud computing (Aim 1), and extending our neural network tracker to enable accurate 3D PT (Aim 2). Our vision is to popularize PT as a research tool among researchers by minimizing the time and labor costs associated with PT analysis. Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a computational neural network that can recognize objects in much the same way as the human eye, and which consistently provided superior and truly automated tracking performance compared to current alternatives. This STTR will establish the feasibility of using our computational neural network for robust 2D and 3D particle tracking analysis.","Artificial neural networks for high performance, fully automated particle tracking analysis even at low signal-to-noise regimes",9347679,R41GM123897,"['Adopted', 'Advanced Development', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Bacteria', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Classification', 'Cloud Computing', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diffuse', 'Ensure', 'Environment', 'Eye', 'Future', 'Gaussian model', 'Generations', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Life', 'Link', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Performance', 'Phase', 'Photobleaching', 'Process', 'Property', 'Radial', 'Research', 'Research Personnel', 'Retina', 'Savings', 'Scientist', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Software Tools', 'Spottings', 'Students', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'Virus', 'Vision', 'Visual Cortex', 'Work', 'base', 'biophysical tools', 'cell motility', 'cloud based', 'cost', 'design', 'experimental study', 'feeding', 'field study', 'graduate student', 'improved', 'insight', 'interest', 'macromolecule', 'movie', 'nanoparticle', 'novel strategies', 'particle', 'pathogen', 'physical science', 'response', 'spatiotemporal', 'submicron', 'terabyte', 'tool', 'virtual']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2017,224997,-0.019657770268676055
"Machine Learning Methods for Detecting Disease-related Functional and Structural Change in Glaucoma PROJECT SUMMARY This project aims to apply novel machine learning techniques to recently developed optical imaging measurement to improve the accurate prediction and detection of glaucomatous progression. Complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and advanced pattern recognition/machine learning-based analysis techniques can find and use that hidden information. We will use mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1,800 patient and healthy eyes, available as the result of long-term NIH funding. We also will investigate deep learning and novel statistical techniques for this purpose. The required longitudinal measurements from several newly developed optical imaging techniques were not available to our previously funded NEI- supported work. The proposed work potentially can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care by informing clinical decision-making based on mathematically based, externally validated methods. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs. PROJECT NARRATIVE The proposed project will improve machine learning techniques for predicting and detecting glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments and will make use of a very large amount of data, obtained using previously awarded NIH funds, to do so. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neuro- degeneration within the visual pathways at structural and functional levels. The development of a clinically useful novel, empirical system for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and on the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.",Machine Learning Methods for Detecting Disease-related Functional and Structural Change in Glaucoma,9298423,R21EY027945,"['Address', 'Algorithms', 'Anatomy', 'Award', 'Caring', 'Classification', 'Clinical', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Defect', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Environment', 'Eye', 'Frequencies', 'Funding', 'Future', 'Gaussian model', 'Generations', 'Glaucoma', 'Goals', 'Health Personnel', 'Image', 'Imaging Device', 'Imaging Techniques', 'Instruction', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perimetry', 'Physiologic Intraocular Pressure', 'Provider', 'Recruitment Activity', 'Reporting', 'Research', 'Scanning', 'Science', 'Series', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Variant', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'clinical care', 'clinical decision-making', 'cost', 'expectation', 'glaucoma test', 'high dimensionality', 'improved', 'independent component analysis', 'instrument', 'learning strategy', 'markov model', 'mathematical model', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'retinal nerve fiber layer', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2017,232500,-0.010658825606696825
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9373088,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Cereals', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Darkness', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Technology', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'behavioral study', 'cognitive development', 'computerized', 'cost', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2017,243750,-0.0224299567649409
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9322408,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,30900,-0.04256328622548262
"IGF::OT::IGF Semantic Bibliometric System for Improving Healthcare Research (Topic 162) (Period of Performance: September 15, 2017 - March 14, 2018). BASE AWARD N43DA-17-1217 BCL will expand the current bibliometric methods by developing a Semantic Bibliometric System using machine learning that will examine research publications, rank the publications by quality, and identify research-productive scientific teams. Used in conjunction with current methods this Semantic Bibliometric System will have the dual use of improving the impact of Government Research and improving semantic search on the web and in ecommerce. n/a","IGF::OT::IGF Semantic Bibliometric System for Improving Healthcare Research (Topic 162) (Period of Performance: September 15, 2017 - March 14, 2018). BASE AWARD N43DA-17-1217",9576638,71201700054C,"['Award', 'BCL1 Oncogene', 'Bibliometrics', 'Data', 'Effectiveness', 'Evaluation', 'Feasibility Studies', 'Government', 'Health Care Research', 'Internet', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Performance', 'Procedures', 'Publications', 'Research', 'Semantics', 'System', 'Text', 'improved']",NIDA,"BCL TECHNOLOGIES, INC.",N43,2017,225000,-0.015951544086893
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9199411,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Controlled Study', 'Databases', 'Detection', 'Devices', 'Dimensions', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2017,319382,-0.0673611838610588
"Functional and Structural Optical Coherence Tomography for Glaucoma PROJECT SUMMARY Glaucoma is a leading cause of blindness. Early diagnosis and close monitoring of glaucoma are important because the onset is insidious and the damage is irreversible. Advanced imaging modalities such as optical coherence tomography (OCT) have been used in the past 2 decades to improve the objective evaluation of glaucoma. OCT has higher axial spatial resolution than other posterior eye imaging modalities and can precisely measure neural structures. However, structural imaging alone has limited sensitivity for detecting early glaucoma and only moderate correlation with visual field (VF) loss. Using high-speed OCT systems, we have developed novel OCT angiography technologies to image vascular plexuses that supply the retinal nerve fibers and ganglion cells damaged by glaucoma. Our results showed that OCT angiographic parameters have better correlation with VF parameters. We have also found that measurement of focal and sectoral glaucoma damage using high-definition volumetric OCT angiographic and structural parameters improves diagnostic performance. The goal of the proposed project is to further improve the diagnosis and monitoring of glaucoma using ultrahigh-speed OCT and artificial intelligence machine learning techniques. The specific aims are: 1. Develop quantitative wide-field OCT angiography. We will develop a swept-source OCT prototype that  is 4 times faster than current commercial OCT systems. The higher speed will be used to fully sample the  neural structures and associated capillary plexuses damaged by glaucoma. 2. Simulate VF by combining structural and angiographic OCT. Preliminary results showed that both  structural and angiographic OCT parameters have high correlation with VF on a sector basis. It may be  possible to accurately simulate VF results by combining these parameters using an artificial neural  network. The simulated VF may be more precise and reliable than subjective VF testing. 3. Longitudinal clinical study in glaucoma diagnosis and monitoring. Our novel OCT structural and  angiographic parameters have high accuracy in diagnosing glaucoma. Neural network analysis of structural  and angiographic data from a larger clinical study could further improve diagnostic accuracy. Longitudinal  follow-up will assess if simulated VF could monitor disease progression as well as actual VF. 4. Clinical study to assess the effects of glaucoma treatments. Preliminary results suggest that OCT  angiography could detect the improvement in capillary density after glaucoma surgery and the effects of  drugs. These intriguing effects will be tested in before-and-after comparison studies. If successful, we will have an OCT diagnostic system that in minutes provides objective information on the location and severity of glaucoma damage. This approach could replace time-consuming and unreliable VF testing. Measuring the improvement in retinal circulation could be a quicker way to detect the benefit of glaucoma therapies that work through neuroprotection or regeneration, compared to monitoring VF. PROJECT NARRATIVE Optical coherence tomography is a high-resolution imaging technology that can non-invasively measure both the eye structures and small blood vessels that are damaged by glaucoma, a leading cause of blindness. The proposed research will further improve this technology so that it can provide detailed measurement over wider areas inside the eye, detect earlier stages of glaucoma, evaluate the location and severity of glaucoma damage, monitor disease progression, and provide more timely assessment of the effectiveness of therapy. A goal of this project is to determine if this objective imaging technology can provide information that is equivalent to or better than subjective visual field testing, which though time-consuming and poorly reliable, is the current gold standard for long-term monitoring and management of glaucoma.",Functional and Structural Optical Coherence Tomography for Glaucoma,9390382,R01EY023285,"['Abbreviations', 'Affect', 'Angiography', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Biological Neural Networks', 'Biomedical Engineering', 'Blindness', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Clinical', 'Clinical Research', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Effectiveness', 'Evaluation', 'Eye', 'Eyedrops', 'Functional disorder', 'Future', 'Geography', 'Glaucoma', 'Glossary', 'Goals', 'Gold', 'Grant', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Lasers', 'Location', 'Longitudinal observational study', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Monitor', 'Natural regeneration', 'Nerve Fibers', 'Noise', 'Operative Surgical Procedures', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Pathway Analysis', 'Patients', 'Performance', 'Perfusion', 'Pharmaceutical Preparations', 'Physiologic Intraocular Pressure', 'Postoperative Period', 'Research', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Role', 'Safety', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Shunt Device', 'Signal Transduction', 'Source', 'Speed', 'Staging', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trabeculectomy', 'Variant', 'Vision', 'Visit', 'Visual Fields', 'Work', 'analytical tool', 'base', 'bulk motion', 'capillary', 'cell injury', 'clinical practice', 'cost', 'density', 'diagnostic accuracy', 'fiber cell', 'field study', 'follow-up', 'ganglion cell', 'glaucoma surgery', 'high resolution imaging', 'high risk', 'imaging modality', 'improved', 'innovation', 'insight', 'macula', 'neuroprotection', 'new technology', 'novel', 'prototype', 'quantitative imaging', 'relating to nervous system', 'screening', 'tool', 'treatment effect', 'vascular factor', 'visual performance']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,559269,-0.013645371831079521
"Extracting rich information from biological images Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Extracting rich information from biological images,9276910,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Learning', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2017,513030,-0.01249165721945016
"A high-throughput imaging and classification system for fruit flies PROJECT SUMMARY / ABSTRACT In this Phase I SBIR application, FlySorter proposes to development a high throughput imaging and classification system to aid research with fruit flies, a widely-used model organism relevant to both basic science as well as studies in human health. The use of animal model systems is essential for research in almost all aspects of biology: genetics, development, neuroscience, disease, physiology, and beyond. The fruit fly – Drosophila melanogaster – is small and easy to care for, but is complex enough an organism to provide a wealth of information that directly relates to human biology and health. Over 75% of human diseases with a genetic basis (including depression, alcoholism, certain forms of cancer, and many more) are either present or have an analog in Drosophila. Modern genetic tools, such as CRISPR/cas9, allow the creation of transgenic flies that provide the opportunity to study diseases, pathways and systems that don’t exist naturally in Drosophila. With these advances, fruit flies are becoming more frequently subjects for drugs screens. For all the advances in the biological tools and techniques applicable to flies, however, the limiting factor in many experiments is the manual labor involved in a few common tasks: moving flies from vial to vial or other lab equipment; classifying and sorting flies by sex, eye color and other phenotypes; and collecting virgin female flies before they mate so that they can be used in controlled crosses, etc. FlySorter’s patent-pending fly dispensing mechanism can reliably deliver a single organism from a vial containing hundreds of awake flies, and our novel FlyPlate system allows storage of individual flies in custom 96 well plates. FlySorter’s robotic fly handling system, co-developed with the de Bivort Lab at Harvard, is capable of manipulating and transporting those individual flies between vial, 96 well plate, and experimental apparatus. The next piece of the automation puzzle to solve is high throughput imaging and classification. To accomplish this goal, FlySorter will: 1) complete a prototype automated image capture hardware system; 2) adapt state-of-the-art computer vision and machine learning algorithms for use on Drosophila; and 3) build a module that can physically sort the classified flies into different vials. Once integrated into the existing FlySorter product ecosystem, this imaging and classification module will greatly expand the kinds of experiments and screens that can be automated, allowing for the study of larger populations or a wider variety of flies, reducing the impact of human error, and freeing up valuable time for researchers. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are one of the most widely used model organisms in biology, for research in genetics, development, neuroscience, disease, and much more. One of the most common tasks in Drosophila labs is sorting flies by various markers and phenotypes using a microscope and paintbrush. FlySorter aims to build an automated system for sorting flies using high resolution digital cameras and modern computer vision algorithms, which will obviate the need for such tedious manual labor.",A high-throughput imaging and classification system for fruit flies,9408980,R43OD023302,"['Air', 'Alcoholism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animal Model', 'Animals', 'Appearance', 'Automation', 'Basic Science', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Neural Networks', 'Biology', 'CRISPR/Cas technology', 'Caring', 'Classification', 'Code', 'Complex', 'Computer Vision Systems', 'Custom', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Pathway', 'Dorsal', 'Drosophila genus', 'Drosophila melanogaster', 'Ecosystem', 'Ensure', 'Eye', 'Eye Color', 'Female', 'Floor', 'Genes', 'Genetic', 'Genetic Screening', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Head', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Legal patent', 'Lighting', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mechanics', 'Mental Depression', 'Methodology', 'Microscope', 'Modernization', 'Motor', 'Mutation', 'Names', 'Neurosciences', 'Obesity', 'Optics', 'Organism', 'Partner in relationship', 'Phase', 'Phenotype', 'Physiology', 'Population', 'Preclinical Drug Evaluation', 'Pump', 'Research', 'Research Personnel', 'Resolution', 'Robot', 'Robotics', 'Sampling', 'Sclera', 'Shapes', 'Small Business Innovation Research Grant', 'Sorting - Cell Movement', 'Standardization', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transgenic Organisms', 'Universities', 'Vial device', 'Walking', 'Work', 'analog', 'awake', 'base', 'depression model', 'digital', 'digital imaging', 'experimental study', 'fly', 'genetic strain', 'human disease', 'improved', 'interest', 'laboratory equipment', 'male', 'meter', 'novel', 'phenotypic biomarker', 'prevent', 'prototype', 'sex', 'tool', 'virtual']",OD,"FLYSORTER, LLC",R43,2017,225000,-0.022603295456316428
"IGF::OT::IGF Constructed Environments for Successfully Sustaining Abstinence Through Immersive and On-Demand Treatment. Period of Performance: September 22, 2017 - March 21, 2018. N43DA-17-5583.   Charles River Analytics and our partners at Massachusetts General Hospital and Virtual Reality Medical Center propose to design and demonstrate Constructed Environments for Successfully Sustaining Abstinence Through Immersive and On-Demand Treatment (CESSATION). We will build VR environments using our in-house game engine and content (cues) that are diverse, realistic, and well-placed, bolstering traditional psychological therapy delivery, and use research-based principles of narrative and game design to produce immersive and engaging content to motivate continued use. We will use probabilistic models (e.g., Bayesian networks) and machine-learning (e.g., neural nets) to learn from patient data and clinician input to assist in selecting and combining therapies in a way that is tailored to the individual patient. Finally, CESSATION will communicate information to clinicians in a manner that is understandable, and gives them enough meta-information to foster appropriate trust in the system. The anticipated results of the proposed Phase I work are: (1) an initial domain analysis; (2) initial VR content; (3) initial motivational content; (4) prototype sensor capabilities; (5) a prototype Intervention Tailoring Component; (6) a prototype Clinician User Interface and Remote Patient Data Server; and (7) an initial Phase I CESSATION prototype demonstration and evaluation. n/a","IGF::OT::IGF Constructed Environments for Successfully Sustaining Abstinence Through Immersive and On-Demand Treatment. Period of Performance: September 22, 2017 - March 21, 2018. N43DA-17-5583.  ",9582496,71201700022C,"['Abstinence', 'Algorithms', 'Contractor', 'Cues', 'Data', 'Effectiveness', 'Elements', 'Ensure', 'Environment', 'Evaluation', 'Exposure to', 'Feedback', 'Fostering', 'Future', 'General Hospitals', 'Health Insurance Portability and Accountability Act', 'Immersion Investigative Technique', 'Intervention', 'Learning', 'Machine Learning', 'Massachusetts', 'Mathematics', 'Measures', 'Medical center', 'Motivation', 'Output', 'Patients', 'Performance', 'Phase', 'Quick Test for Liver Function', 'Recommendation', 'Regulation', 'Reporting', 'Research', 'Rivers', 'Secure', 'Statistical Models', 'Stimulus', 'Summary Reports', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Trust', 'Visit', 'Work', 'base', 'commercialization', 'computer based statistical methods', 'design', 'graphical user interface', 'individual patient', 'lens', 'prototype', 'psychologic', 'relating to nervous system', 'response', 'sensor', 'simulation', 'smoking cessation', 'therapy design', 'virtual reality']",NIDA,"CHARLES RIVER ANALYTICS, INC.",N43,2017,149987,-0.014075202259570976
"User-driven fitting of hearing aids and other assistive hearing devices Hearing aids are the principal tool today for ameliorating age-related hearing loss and its significant social, cognitive and functional costs to patients and society at large. However, many individuals who are prescribed hearing aids do not use them at all, or use them only occasionally. Most reasons behind the “hearing aid in the drawer” phenomenon relate to the characteristics of the sound produced, and could, in theory, be addressed with the correct signal processing strategy. The problem persists despite the increased complexity and power of new devices, for three reasons: (a) The hearing aid parameters, as set in the clinic, introduce distortion or render audible many sounds that the hearing impaired user had become accustomed to not hearing. The novelty is often so uncomfortable for the user as to discard the device. (b) The optimum parameters vary depending on the listening task and environment. Under some conditions, a device with parameters designed for a different condition will perform worse than no device at all. (c) The clinical fitting is derived from a non-ideal way to assess auditory function (the pure- tone audiogram). The optimum parameters for the actual impairment may be different from those of the prescribed fitting. Although it is true that the physiological mechanisms make it impossible to process sound so as to completely reverse the effect of sensorineural hearing loss, a device that delivers some benefit at all times is likely to be used all the time. The goal is to develop a hearing aid that can adaptively change its parameters to address the problems above, and will be accomplished with a novel fitting approach that rapidly presents a number of parameter settings to the user and lets the user guide the system toward the optimal settings for each listening situation. This requires the development of machine-learning algorithms to effectively search the parameter space and user interface devices and instructions that are easy for the patient to use. The focus of this Phase I proposal is the development of the algorithms and the adaptive user-driven fitting program, and to compare the proposed fitting with the traditional audiogram-based fitting across measures of functional hearing (ability to recognize speech in noise) and subjective preference. A hearing aid user is often dissatisfied with the sound quality of their device, despite its sophistication and adjustment by a trained audiologist. The problem can be mitigated by letting the user fine-tune the device for maximum comfort in everyday use. We will apply modern machine learning methods to develop a program for efficient user-driven fitting of hearing assistive devices.",User-driven fitting of hearing aids and other assistive hearing devices,9409910,R43DC016251,"['Address', 'Algorithms', 'Audiometry', 'Auditory', 'Back', 'Books', 'Cellular Phone', 'Characteristics', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Computer software', 'Development', 'Devices', 'Environment', 'Future', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Impairment', 'Individual', 'Instruction', 'Intuition', 'Knowledge', 'Likelihood Functions', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Music', 'Noise', 'Outcome', 'Patients', 'Performance', 'Phase', 'Physiological', 'Presbycusis', 'Process', 'Protocols documentation', 'Psychology', 'Psychophysics', 'Relaxation', 'Reproducibility', 'Self-Help Devices', 'Sensorineural Hearing Loss', 'Societies', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Time', 'Training', 'Update', 'base', 'cohort', 'cost', 'design', 'hearing impairment', 'improved', 'learning strategy', 'models and simulation', 'novel', 'performance tests', 'preference', 'programs', 'response', 'signal processing', 'simulation', 'social', 'sound', 'success', 'theories', 'tool', 'vector']",NIDCD,"CARAWAY SOFTWARE, INC.",R43,2017,224966,-0.004977096362166266
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9315808,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Computing', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'image guided', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'public health relevance', 'quantitative imaging', 'response', 'task analysis', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2017,413289,-0.001909854043550959
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris�n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris�n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9264531,R01EY023279,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Categories', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Morphology', 'Nerve Fibers', 'Ophthalmoscopes', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2017,339750,-0.013550615368157388
"Web Software to develop an RDoC-Compatible Adaptive Diagnostic Nosology, the SID-5 n psychiatry, clinical judgment has been the predominant method of diagnosis. The `gold standard” for clinical research is the Structured Clinical Interview for DSM-5 (SCID-5). The SCID-5 promotes reliability, but its validity is questionable. There is growing recognition that biomarkers can be used to identify more homogeneous patient populations, but there is substantial phenotypic discordance for schizophrenia even in identical twins. In the absence of symptom data, biomarkers alone are unlikely to yield a clinical diagnosis.  In a past SBIR project, TeleSage Inc. successfully converted the paper SCID into a web-based software program. The NetSCID-5 is now widely used in research. Nevertheless, in order to achieve the goal of “turning clinical care networks into centers for research” (Insel, Director's Blog, 2012) and furthering the RDoC initiative, we need a means of gathering rigorous diagnostic data in routine clinical care. This software must (a) require minimal clinician time, (b) allow clinics to bill according to the current DSM-5 categories, and (c) be able to gather the large amount of data necessary to inform a broad research agenda including machine learning techniques. TeleSage proposes to develop a self-report diagnostic assessment that satisfies both immediate clinical needs and broader research goals: the “Screening Interview for Diagnosis” or SID.  TeleSage has worked with an expert panel including Dr. Michael First, the primary author of the SCID- 5, iteratively developing and testing self-report items. Based on expert panel review and cognitive interviewing, we identified a final set of 661 unique self-report, Likert-scale items covering all of the individual sub-symptoms described within each of the SCID criteria. TeleSage has also created a behavioral health PORTAL that includes the NetSCID-5, IRT/CAT item administration, randomization, and longitudinal reporting capabilities. The PORTAL exchanges data and reports with several EHRs including the NetSmart EHR system.  This Direct-to-Phase II application aims to create the SID, which will (a) reside on our existing secure web PORTAL, (b) administer simple Likert-scale self-report items, (c) generate DSM-5 and ICD-10 diagnoses for billing, (d) use minimal clinician time, (e) pull pre-defined data fields from the EHR (e.g. family history, demographic, and biomarker data), (f) be able to add new self-report items for exploration, (g) integrate with machine learning tools, and (h) send raw data and interpretive reports to EHR systems. Because of these features, we believe that the SID has the potential to be used widely by both clinicians and researchers.  The SID is intended to help transcend DSM-5 and to support RDoC. The SID product must be commercially successful and useful both in routine clinical care and research. The SID is intended to facilitate the development and evolution of a new behavioral health nosology based on the aggregation of biomarker and symptom data, a nosology that is more analogous to those found in other fields of medicine. The Structured Clinical Interview for DSM-5 (SCID-5) represents the current diagnostic gold standard in behavioral health and yields much more reliable diagnoses than the unstructured patient interviews that predominate in clinical settings; however, the full SCID-5 is a lengthy and complex paper-and-pencil instrument that takes approximately 90 minutes to administer and is thus seldom used outside of clinical research settings. We want to create a new, self-report software tool that will save clinicians time relative to the paper SCID, significantly reduce diagnostic error rates, greatly increase the reliability of diagnoses in routine clinical care, and integrate seamlessly into Electronic Health Record (EHR) systems: the Screening Inventory for Diagnosis (SID). The SID is a self-report, computer-adaptive diagnostic assessment, based on easy-to- understand, five-point Likert-scale items. The SID is intended to help transcend DSM-5, support RDoC, and facilitate the development and evolution of a new behavioral health nosology based on the aggregation of biomarker and symptom data.","Web Software to develop an RDoC-Compatible Adaptive Diagnostic Nosology, the SID-5",9255772,R44MH108177,"['Adult', 'Algorithms', 'Alleles', 'Area', 'Behavioral', 'Biological Markers', 'Blood Chemical Analysis', 'Brain scan', 'Categories', 'Clinic', 'Clinical', 'Clinical Research', 'Cognitive', 'Complex', 'Computer software', 'Computers', 'DSM-IV', 'DSM-V', 'Data', 'Data Reporting', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Differential Diagnosis', 'Electronic Health Record', 'Ensure', 'Equipment and supply inventories', 'Evolution', 'Family', 'Future', 'Gene Frequency', 'Genes', 'Goals', 'Gold', 'Healthcare', 'Hour', 'Individual', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Internet', 'Intervention', 'Interview', 'Judgment', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medicine', 'Mental Health', 'Methodology', 'Methods', 'Monozygotic twins', 'Online Systems', 'Paper', 'Participant', 'Patient Self-Report', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Pilot Projects', 'Population', 'Psyche structure', 'Psychiatry', 'Public Sector', 'Publishing', 'Questionnaires', 'Randomized', 'Recording of previous events', 'Reporting', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Sampling', 'Savings', 'Schedule', 'Schizophrenia', 'Secure', 'Severities', 'Small Business Innovation Research Grant', 'Software Tools', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Transcend', 'Update', 'Work', 'base', 'behavioral health', 'clinical Diagnosis', 'clinical care', 'data exchange', 'disease classification', 'epigenetic marker', 'follow-up', 'health care service', 'instrument', 'mental health center', 'patient population', 'personalized medicine', 'programs', 'satisfaction', 'screening', 'specific biomarkers', 'symptom cluster', 'tool', 'usability', 'web portal']",NIMH,"TELESAGE, INC.",R44,2017,433630,-0.027720566828621666
"Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination Project Summary / Abstract Between 1.6 and 3.8 million people each year suffer a mild TBI in the US alone. Reliable diagnosis and prompt treatments are vital to managing the often-serious short and long-term sequelae resulting from mild TBI. However, a reliable objective and accurate method for mild TBI diagnosis outside of a hospital setting, and in particular for determining RTP readiness, has eluded the clinical community. Current diagnosis and RTP assessments are based on patient symptoms, neurocognitive evaluations, and / or physical performance testing. Use of symptom scales are problematic for several reasons including subjectivity and reliability. Neurocognitive evaluations and physical tests (such as balance tests), although less subjective, require pre- injury baseline testing of subjects due to inherently large subject-to-subject variations in evaluation performances. Due to these reasons, current mild TBI diagnostic methods have limited applications and are not suitable for a significant majority of patients who suffer mild TBI. This project is aimed at developing an objective diagnosis of mild traumatic brain injury (mild TBI) based on physiologic changes in a patient after injury and providing a platform capable of RTP guidance. The method is based on quantification of well-known physiologic changes after a concussion, i.e. the impairment of autonomic function and altered cerebral blood flow (CBF) as measured with transcranial Doppler (TCD). The novelty of the proposed approach is the use of a recently-developed analytical machine learning framework for the analysis of the CBF velocity (CBFV) waveforms. In contrast to previous methods used before, the proposed approach utilizes the entire shape of the complex CBFV waveform, thus obtaining subtle changes in blood flow that are lost in other analysis methods. Additionally, comprehensive verification between our platform and MRI will be performed following injury resulting in the first scientific experiments of this kind. The ultimate goal of this Phase II SBIR is to commercialize an objective and accurate software algorithm for reliable diagnosis and management of sports concussions which does not currently exist. The outcome will be a software suite integrated into existing TCD and will be marketed to emergency departments, neurology clinics, and other healthcare providers involved in mild TBI diagnosis and RTP management. Project Narrative Traumatic brain injury (TBI) is a serious public health problem in the United States contributing to a substantial number of deaths and cases of permanent disability. Mild TBI concussions account for over 80% of all TBIs sustained and a major problem is the high rate of mis-diagnosis due to lack of objective measures and delayed onset of symptoms. This project aims to develop the first objective concussion evaluation method using a novel analysis platform that can obtain subtle, physiologic changes in cerebral hemodynamics. Successful completion of this project will result in a portable diagnostic device suitable for use in many scenarios where concussion diagnosis is inaccurate or unavailable today.",Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination,9323604,R44NS092209,"['Accident and Emergency department', 'Acute', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Area Under Curve', 'Assessment tool', 'Blood flow', 'Brain Concussion', 'Cerebrovascular Circulation', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Controlled Study', 'Core-Binding Factor', 'Data', 'Data Analytics', 'Data Collection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Evaluation', 'Functional disorder', 'Future', 'Goals', 'Gold', 'Guidelines', 'Health Personnel', 'Hospitals', 'Image', 'Impairment', 'Injury', 'Letters', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Neurocognitive', 'Neurologist', 'Neurology', 'Outcome', 'Patients', 'Pediatric Neurology', 'Performance', 'Persons', 'Phase', 'Physical Performance', 'Physicians', 'Physiological', 'Play', 'Public Health', 'Publications', 'Readiness', 'Recovery', 'Research', 'Resolution', 'Risk', 'Severities', 'Shapes', 'Site', 'Small Business Innovation Research Grant', 'Spin Labels', 'Sports', 'Sports Medicine', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Traumatic Brain Injury', 'Ultrasonography', 'United States', 'Variant', 'balance testing', 'base', 'brain health', 'cerebral hemodynamics', 'clinical Diagnosis', 'diagnostic accuracy', 'disability', 'experimental study', 'hemodynamics', 'high school', 'injured', 'innovation', 'mild traumatic brain injury', 'novel', 'pediatric department', 'performance tests', 'portability', 'prevent', 'programs', 'relating to nervous system', 'success', 'tool']",NINDS,"NEURAL ANALYTICS, INC.",R44,2017,1500000,-0.0010653819909360114
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability. PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.",Capti Screen Reading Assistant for Goal Directed Web Browsing,9199231,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2017,500000,-0.019790163863038588
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9544350,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,56360,-0.008890819098621182
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9355633,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,454865,-0.008890819098621182
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research ﻿    DESCRIPTION (provided by applicant): This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0(tm) that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud(tm) Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb's DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently. PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9354497,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Communications Media', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Internet of Things', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Modernization', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'Transact', 'United States National Institutes of Health', 'analytical tool', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'experimental study', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'service learning', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2017,739402,0.0020486661259758697
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9315773,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Darkness', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2017,619539,-0.017907793153206546
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9150601,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2017,326571,-0.008726192549574291
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle. PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9355100,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Intuition', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Morphology', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscle function', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2017,391844,-0.018544473855587988
"Advancing a novel portable detection method for cannabis intoxication Intoxication from marijuana (MJ) impairs psychomotor performance and at least doubles the risk of motor vehicle accidents. The ongoing wave of legalization of MJ has brought increasing prevalence of driving while intoxicated with MJ. However, there is no quantitative biologic test that can accurately determine whether an individual is acutely impaired from MJ intoxication. Assays of the primary intoxicating substance in MJ, THC, in body fluids has a high false negative rate as THC is cleared from blood within 15 minutes, long before impairment is resolved. And assays of THC metabolites yield a high false positive rate because clearance of these metabolites can take weeks. Thus there is now no nor is there likely to ever be a test of blood, breath or body fluids that can accurately detect MJ intoxication. In response to this significant knowledge gap, this project aims to develop an accurate, portable method for detection of impairment due to MJ intoxication using functional near-infrared spectroscopy (fNIRS). fNIRS is a non-invasive, safe brain imaging technique that capitalizes on differences in the light absorption spectra of deoxygenated and oxygenated hemoglobin (Hb), that allows the measurement of relative changes in Hb concentration that reflect brain activity. fNIRS can be performed in natural environments at low cost, and thus can be used in real-world settings. In Phase I, we will develop an algorithm for individual-level detection of impairment from THC using fNIRS measurements. To do so, we will assess the effect of oral THC (or placebo) on fNIRS measurements, self-reported intoxication, and impairment as defined by the gold standard field sobriety test conducted by a Drug Recognition Expert (DRE) in 40 healthy MJ users. fNIRS assessments will examine (1) the effect of THC exposure on resting state and task-based activation in the prefrontal cortex, (2) the extent to which impairment in psychomotor functioning with THC administration correlates with THC-induced change in hemodynamic responses detected with fNIRS, and (3) the sensitivity and specificity and area under the ROC curve of fNIRS measurements and field sobriety test determinants of impairment. Milestone: Should machine learning applications to the data generate an algorithm that predicts impairment with >80% accuracy compared with a gold standard field sobriety test, we will proceed to Phase II. In Phase II, we will conduct fNIRS testing in 150 individuals under THC/placebo as in Phase I and in 50 individuals in a THC plus alcohol/placebo condition in order to further refine the algorithm for MJ impairment detection such that fNIRS detection concurs with field sobriety testing with >90% specificity. It is anticipated that this level of specificity could be used in legal definitions of impairment. This will warrant commercialization, which will be followed by prototype development and field testing. An accurate, quantitative, biological test that is user-friendly and enables law enforcement to detect impairment from MJ has the potential to dramatically change practice of law enforcement across the country and the world and thus has enormous commercial potential, as outlined in the Commercialization Plan and in accompanying letters of support. The goal of this project is to develop, test, and refine a method to accurately and reliably detect marijuana (MJ) impairment using a portable, user-friendly, non-invasive, brain-based modality. MJ doubles the chance of motor vehicle accidents, yet, there now exists no valid, biologically based method to detect whether an individual is acutely impaired from MJ. The development of a reliable, quantitative biological marker that enables law enforcement officers to screen individuals whom they suspect are impaired from MJ will have highly significant public health importance and enormous commercial potential.",Advancing a novel portable detection method for cannabis intoxication,9334516,R42DA043977,"['Acute', 'Adult', 'Age', 'Alcohols', 'Algorithms', 'Area', 'Base of the Brain', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Blood', 'Blood Circulation', 'Blood Tests', 'Body Fluids', 'Brain', 'Brain imaging', 'Breath Tests', 'Cannabis', 'Collaborations', 'Comorbidity', 'Country', 'Cross-Over Trials', 'Data', 'Detection', 'Development', 'Devices', 'Dose', 'Double-Blind Method', 'Driving While Intoxicated', 'Drug Kinetics', 'Ensure', 'Environment', 'Equipment', 'Evaluation', 'Formulation', 'Future', 'Goals', 'Gold', 'Hemoglobin', 'Hour', 'Human Resources', 'Imaging Techniques', 'Impairment', 'Individual', 'Intoxication', 'Knowledge', 'Law Enforcement', 'Law Enforcement Officers', 'Legal', 'Letters', 'Licensing', 'Light', 'Machine Learning', 'Marijuana', 'Measurement', 'Methods', 'Modality', 'Near-Infrared Spectroscopy', 'Oral', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Placebo Control', 'Placebos', 'Population', 'Prefrontal Cortex', 'Prevalence', 'Property', 'Psychomotor Impairments', 'Psychomotor Performance', 'Public Health', 'ROC Curve', 'Randomized', 'Readiness', 'Rest', 'Risk', 'Sensitivity and Specificity', 'Source', 'Specificity', 'System', 'THC exposure', 'Testing', 'Tetrahydrocannabinol', 'United States', 'Urine', 'Vendor', 'absorption', 'alcohol exposure', 'base', 'behavior test', 'commercialization', 'cost', 'density', 'detector', 'driving under influence', 'drug testing', 'field sobriety tests', 'field study', 'functional disability', 'hemodynamics', 'interest', 'marijuana legalization', 'marijuana use', 'marijuana user', 'novel', 'novel strategies', 'portability', 'prediction algorithm', 'prototype', 'response', 'spectroscopic imaging', 'tool', 'user-friendly', 'vehicular accident']",NIDA,"HIGHLIGHTI, INC",R42,2017,224973,-0.0028860362679124754
"Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury ﻿    DESCRIPTION (provided by applicant): Throughout human pregnancy, the placenta is indispensable for embryonic development, fetal growth and tissue differentiation. The placenta also protects the fetus against diverse insults, while preserving maternal health. Placental dysfunction is commonly implicated in complications of pregnancy that challenge maternal physiology (e.g., preeclampsia) and fetal development (e.g., fetal death or fetal growth restriction) or that leads to preterm birth. Within the placenta, the trophoblast constitutes the outermost layer, which is directly bathed in maternal blood and therefore positioned to regulate maternal-fetal gas exchange, nutrient delivery, waste removal and the production of hormones, faithfully balancing fetal needs and maternal supply. Trophoblast damage, which is common in dysfunctional placentas, may interrupt the delicate maternal-fetal balance, cause clinical disease, and leave a lifelong mark on health. A fundamental challenge in perinatal medicine arises from our limited ability to diagnose placental disorders in real time and throughout pregnancy. However, the recent discovery, by ourselves and others, that (a) placental trophoblasts release distinctive micro- and nanovesicles into the maternal circulation and (b) these vesicles contain trophoblast-specific non-coding RNA cargo, created a new opportunity for assessing trophoblast health. These vesicles are actively released by trophoblasts throughout pregnancy, and thus serve as a venipuncture-accessible ""natural biopsy"" of trophoblasts, which can furnish information on trophoblast health in real time. Our established perinatal biology group at Magee- Womens Research Institute includes expertise in perinatal medicine and placental pathology, developmental and molecular biology, and bioinformatics. Inspired by these recent advances, we have partnered with an experienced group of bioengineers that includes experts from Carnegie Mellon University, MIT, and Penn State University, with unique skills in biophysics-based vesicle analytics, including microfluidics, nanomechanics, micro/nano fabrication and vesicle sorting using acoustic tweezers. Together, our new transdisciplinary group will use integrated molecular and biophysical methodologies to directly assess the use of trophoblast-derived extracellular vesicles from maternal plasma as revelatory of trophoblast health in real time and as a technique that may be employed throughout pregnancy. Our approach is comprehensive, centering on miRNAs as well as lncRNAs and circRNAs, analyzed in exosome nanovesicles, as well as microvesicles and apoptotic bodies. As each vesicle features a unique bimolecular and biophysical signature, we will deploy our machine learning- based training and testing pipeline to informatively integrate these distinct signals into an innovative diagnostic tool. Lastly, our deployment of affordable acoustic tweezers technology to sort trophoblastic vesicles will facilitate the translation of our advances into a new ""lab on a chip"" placental diagnostic technology, suitable for small blood volumes. This technology may not only denote trophoblast pathology, but has potential to identify those who may benefit from intervention and to monitor therapeutic success. PUBLIC HEALTH RELEVANCE: Although the placenta is critical for fetal development and pregnancy outcome, it is not currently accessible for real-time diagnostics throughout pregnancy. Having developed tools for isolation and analysis of placenta- specific extracellular from the maternal plasma, we will study molecular and biophysical properties of these vesicles as indicators of placental health and disease.",Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury,9269122,R01HD086325,"['Abruptio Placentae', 'Acoustics', 'Apoptotic', 'Arteries', 'Bioinformatics', 'Biological Assay', 'Biology', 'Biomedical Engineering', 'Biophysics', 'Biopsy', 'Blood', 'Blood Circulation', 'Blood Volume', 'Blood flow', 'Characteristics', 'Clinical', 'Communication', 'Data', 'Developmental Biology', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Dimensions', 'Disease', 'Embryonic Development', 'Endoglin', 'Equilibrium', 'Evaluation', 'Excision', 'Fetal Death', 'Fetal Development', 'Fetal Growth', 'Fetal Growth Retardation', 'Fetal Tissues', 'Fetus', 'Functional disorder', 'Future', 'Gases', 'Glean', 'Gold', 'Health', 'Histologic', 'Hormones', 'Human', 'Injury', 'Interruption', 'Intervention', 'Investigation', 'Knowledge', 'Lab-On-A-Chips', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maternal Health', 'Maternal Physiology', 'Methods', 'MicroRNAs', 'Microfluidics', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Needle biopsy procedure', 'Nutrient', 'PGF gene', 'Pathology', 'Perinatal', 'Placenta', 'Placenta Diseases', 'Placental Biology', 'Plasma', 'Plasma Proteins', 'Positioning Attribute', 'Postpartum Period', 'Pre-Eclampsia', 'Predictive Value', 'Pregnancy', 'Pregnancy Complications', 'Pregnancy Outcome', 'Pregnancy-Associated Plasma Protein-A', 'Premature Birth', 'Production', 'Property', 'Provider', 'Research Institute', 'Shapes', 'Signal Transduction', 'Sorting - Cell Movement', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissue Differentiation', 'Training', 'Translations', 'Ultrasonography', 'Universities', 'Untranslated RNA', 'Venipunctures', 'Vesicle', 'Viscosity', 'Woman', 'adverse pregnancy outcome', 'base', 'biophysical properties', 'biophysical techniques', 'circular RNA', 'clinical care', 'clinical diagnostics', 'cost effective', 'design', 'exosome', 'experience', 'extracellular', 'extracellular vesicles', 'fetal', 'fitness', 'guided inquiry', 'high dimensionality', 'improved', 'in vivo', 'injured', 'innovation', 'mechanical properties', 'microvesicles', 'nanofabrication', 'nanomechanics', 'nanovesicle', 'novel', 'perinatal medicine', 'peripheral blood', 'pregnancy disorder', 'public health relevance', 'skills', 'stem', 'success', 'tomography', 'tool', 'transcriptome sequencing', 'trophoblast', 'viscoelasticity', 'wasting']",NICHD,MAGEE-WOMEN'S RES INST AND FOUNDATION,R01,2017,725442,-0.018838868350704436
"Software for OCT Analysis of Vascular Stents Software for OCT Analysis of Vascular Stents PI: Ronny Shalev, PhD, Dyad Medical Summary Dyad Medical, Inc. will create intravascular OCT (IVOCT) software for clinical, live time determination of stent apposition (OCTivat-live, the live time OCT image visualization and analysis tool) and for offline analysis of stent implantation (OCTivat-stent). Every year, 100s of thousands of patients in the US are treated with intra- vascular stents creating an opportunity for both solutions. Although advancements such as drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent design parameters include drug, material (bioresorbable vs metal), polymer composition, coatings to stimulate cell coverage, etc. To opti- mize designs, sensitive, in vivo assessments are needed for preclinical and clinical evaluations. Intravascular OCT (IVOCT) is the lone imaging modality with the resolution and contrast to meet this challenge. The Core Lab at CWRU is the premiere site in the world for manual analysis of IVOCT image data. A cardiologist analyst takes 6-16 hrs to analyze manually a single stent, and despite training and quality assurance measures, inter- analyst variability can limit the power to determine changes between stent designs. Building upon work at CWRU, we will develop advanced, highly automated software to greatly speed analysis, improve reproducibil- ity, increase accuracy, and harmonize analysis. Software will reduce costs by decreasing manual labor, and with improved reproducibility, possibly enable the use of historical data, eliminating cost of a control arm. Re- garding live time analysis, rather than manually reviewing >500 images in a pullback, with fast software, it will be possible to present the number and location of malapposed struts in 3D, providing instant feedback to phy- sicians on the need for additional dilatation with a larger balloon or higher pressure. In addition, we will auto- matically determine stent and vessel area along the length of the pullback, allowing us to compute stent ex- pansion and eccentricity, quantitative measures related to successful stent deployment, the most important de- terminant of outcome. IVOCT could also play a role at patient follow up. If a stent is well covered, then long- term anti-platelet therapy might be unnecessary, minimizing bleeding risk. If a stent has many uncovered struts, a therapeutic might prevent stent thrombosis or stimulate healing. Project Narrative: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies and improved deployment for improved treatment of vascular dis- ease.",Software for OCT Analysis of Vascular Stents,9407267,R43HL137500,"['Agreement', 'Algorithms', 'Area', 'Blinded', 'Blood Vessels', 'Cells', 'Classification', 'Clinical', 'Clinical Trials', 'Code', 'Computer software', 'Data', 'Detection', 'Devices', 'Dilatation - action', 'Doctor of Philosophy', 'Feedback', 'Follow-Up Studies', 'Heart', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Implant', 'Institutes', 'International', 'Ions', 'Laboratories', 'Length', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Metals', 'Methods', 'Myocardial Ischemia', 'Needs Assessment', 'Outcome', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Play', 'Polymers', 'Process', 'Reproducibility', 'Research Personnel', 'Resolution', 'Risk', 'Role', 'Services', 'Site', 'Speed', 'Stents', 'Surrogate Markers', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Variant', 'Vascular Diseases', 'Work', 'arm', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'image visualization', 'imaging modality', 'implantation', 'improved', 'in vivo', 'personalized diagnostics', 'preclinical evaluation', 'pressure', 'prevent', 'prototype', 'quality assurance', 'research clinical testing', 'restenosis', 'statistics', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,"DYAD MEDICAL, INC.",R43,2017,224744,0.001823760840226637
"Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II Project Summary Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Clinical performance assessment emphasizes learner evaluation over learner development, lacks rigor and utility for developmental purposes, and clinical teachers have expressed particular difficulty with diagnosing reasoning deficits for remediation purposes. Further, medical students' diagnostic reasoning does not improve over the course of clinical training and senior medical students have highly variable diagnostic performance that is often rated below expectations according to theory-based and validated scoring criteria. Independent practice does not necessarily enhance the context for clinical reasoning; the majority of physicians' medical errors are thought to be diagnostic in nature. We propose to improve undergraduate medical education to minimize the time to clinical competency for first year residents through targeted diagnostic reasoning skill development that (1) integrates basic science and clinical instruction; (2) provides deliberate practice with structured, case-based learning opportunities; and (3) enables anytime/anywhere learning that fits with the demanding schedules of most medical students. Southern Illinois University School of Medicine (SIUSOM) is a recognized leader in using performance-based clinical competency exams to enhance reasoning skill acquisition among medical students. These exams feature clinical scenarios with standardized patients followed by diagnostic justification essays which require students to explicitly describe the thought process used to reach a final diagnosis. These essays are the most reliable method of assessing diagnostic strategies but are not in use in the majority of medical schools, though interest in improving diagnostic reasoning instruction and assessment during undergraduate medical education is widespread. Barriers to the widespread adoption of this approach are 1) the time-consuming need to hand score each essay; and 2) the difficulty in accurately and consistently identifying the causes of strategy failures. This project will develop an application to provide automated scoring of diagnostic justification essays, identification of the underlying causes of failure when students perform poorly, and feedback with instructional strategies for remediation specific to each deficit. We propose these specific aims: 1) Improve reliability of human scoring of DXJ essays. 2) Extend the automated scoring algorithms. 3) Automated reasoning failure categorization and remediation. 4) Complete the software development required for delivering the commercial product. 5) Evaluate predictive validity of automatically scored DXJ essays. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine. Project Narrative Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Better preparation during undergraduate medical education can shorten the time to competency of first year residents, improving patient outcomes. We propose to develop and test a technology-enabled, deliberate-practice approach to training diagnostic strategy that includes automated scoring of diagnostic justification essays, identification of specific diagnostic strategy failures and targeted remediation. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine.","Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II",9339455,R42GM108104,"['Address', 'Adopted', 'Adoption', 'Algorithms', 'Basic Science', 'Caring', 'Case Based Learning', 'Case Study', 'Charge', 'Classification', 'Clinical', 'Clinical Competence', 'Community Health Education', 'Competence', 'Consult', 'Custom', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Education', 'Educational Technology', 'Educational process of instructing', 'Ensure', 'Environment', 'Equation', 'Evaluation', 'Faculty', 'Failure', 'Feedback', 'Future', 'Goals', 'Hand', 'Hospitals', 'Human', 'Illinois', 'Incubators', 'Instruction', 'Leadership', 'Learning', 'Letters', 'Machine Learning', 'Measures', 'Medical', 'Medical Education', 'Medical Errors', 'Medical Students', 'Medicine', 'Methods', 'Modeling', 'Nature', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Preparation', 'Process', 'Recommendation', 'Role', 'Sales', 'Schedule', 'Semantics', 'Standardization', 'Structure', 'Students', 'Suggestion', 'Supervision', 'System', 'Taxonomy', 'Teaching Method', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validity and Reliability', 'Variant', 'base', 'educational atmosphere', 'essays', 'evidence base', 'expectation', 'improved', 'innovation', 'interest', 'medical schools', 'prototype', 'remediation', 'research and development', 'skill acquisition', 'skills', 'software development', 'teacher', 'theories', 'tool', 'undergraduate medical education', 'undergraduate student', 'virtual']",NIGMS,"PARALLEL CONSULTING, LLC",R42,2017,500000,-0.012855912526268786
"How Does Automated Record Linkage Affect Inferences about Population Health? ABSTRACT  Our broad research objective is to create the Longitudinal Intergenerational Family Electronic Micro-dataset (LIFE-M) spanning the late 19th and 20th century United States. Using automated record linkage technology, the LIFE-M project combines millions of vital records to reconstruct how and why individuals' health has changed across time. This multi-generational, longitudinal micro-database aims to transform research on health and longevity, on childbearing and family structure, and on the long-run health effects of early-life circumstances and exposures.  In creating LIFE-M, however, we have encountered serious deficits in knowledge about the performance of automated record linkage technology. The proposed project seeks to evaluate the performance of the most popular and cutting-edge automated linking techniques for the purposes of creating longitudinal health data. Our specific aims are to (1) produce systematic evidence regarding the performance of automated record linking algorithms in terms of match rates, representativeness of the linked sample, erroneous matches (type I errors), and systematic measurement error; (2) examine how phonetic name-cleaning methods affect quality metrics; and (3) examine how record quality metrics vary for different underrepresented subgroups (including women, racial/ethnic minorities, and immigrants) and to determine how linking methods affect representativeness and inferences. To achieve these aims, we have developed new partnerships with record linking experts allowing us to incorporate the most cutting-edge methods in record linking. We will also rely on new “ground truth” generated by LIFE-M project's independent, double-blind human review process.  This project will contribute significantly to existing knowledge about the use of automated linking methods for creating longitudinal and intergenerational health data. It will also increase knowledge about potential sources of bias in health studies. Both contributions should greatly enhance the quality of descriptive and causal inferences about population health and aging and disparities in these outcomes. PROJECT NARRATIVE  This project contributes to public health knowledge by advancing record linking methodology for creating longitudinal and intergenerational health datasets. It will also increase knowledge about potential sources of bias in public health and aging studies using linked records. Both contributions should significantly improve the quality of inferences about public and population health and health disparities.",How Does Automated Record Linkage Affect Inferences about Population Health?,9372797,R21AG056912,"['Affect', 'Aging', 'Algorithms', 'American', 'Benchmarking', 'Big Data', 'Birth', 'Birth Certificates', 'Birth Records', 'Censuses', 'Child', 'Computers', 'Data', 'Data Linkages', 'Data Set', 'Databases', 'Double-Blind Method', 'Economics', 'Family', 'Foundations', 'Four-dimensional', 'Funding', 'Genealogy', 'Generations', 'Genetic Transcription', 'Goals', 'Graph', 'Hand', 'Health', 'Heterogeneity', 'Human', 'Immigrant', 'Incidence', 'Individual', 'Infant', 'Joints', 'Knowledge', 'Life', 'Link', 'Longevity', 'Machine Learning', 'Maiden Name', 'Marriage', 'Measurement', 'Measures', 'Medicare', 'Methodology', 'Methods', 'Minnesota', 'Minor', 'Names', 'Outcome', 'Performance', 'Pilot Projects', 'Politics', 'Population', 'Process', 'Public Health', 'Records', 'Research', 'Research Infrastructure', 'Running', 'Sample Size', 'Sampling', 'Science', 'Scientist', 'Source', 'Speed', 'Subgroup', 'Techniques', 'Technology', 'Time', 'United States', 'United States National Institutes of Health', 'Universities', 'Variant', 'Veterans', 'Woman', 'aging population', 'child bearing', 'cost effective', 'ethnic minority population', 'family structure', 'health data', 'health disparity', 'health knowledge', 'improved', 'innovation', 'intergenerational', 'longitudinal database', 'population health', 'racial and ethnic', 'repository', 'social', 'vector']",NIA,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2017,232500,-0.02019359656715778
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions Project Summary/Abstract People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. Project Narrative People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9407137,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Persons', 'Phase', 'Phonation', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2017,159267,-0.004496569635851818
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9316507,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2017,379732,0.008571007325155543
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers. PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9330810,UH2CA203710,"['Algorithms', 'Artificial Intelligence', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Classification', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Image Analysis', 'Institutes', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Nonprofit Organizations', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Specificity', 'Statistical Models', 'Students', 'Technology', 'Territoriality', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'fine art', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'virtual', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2017,320900,-0.00715569728525761
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9300962,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'International', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging study', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'perfusion imaging', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'success', 'tool', 'validation studies', 'virtual', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2017,169609,-0.050597533241239105
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9238777,R01EY025332,"['Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2017,416574,-0.00383990527954784
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,9194390,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Internet', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'analytical method', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'digital media', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'pedagogy', 'public health relevance', 'sample fixation', 'screening', 'tool', 'transmission process', 'virtual']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,611703,-0.0153089236203433
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,9212187,R01HL121226,"['Acute', 'Anatomy', 'Autopsy', 'Bayesian Modeling', 'Biomechanics', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Heart Ventricle', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Pharmacology', 'Phase', 'Physiology', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'perfusion imaging', 'public health relevance', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2017,768639,-0.003940875315746374
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9303234,R00AG046911,"['Address', 'Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'imaging modality', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'public health relevance', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2017,249000,-0.020638281682895318
"Detecting biochemical changes in the pregnant mouse cervix by Raman spectroscopy DESCRIPTION (provided by applicant): Our understanding of cervical remodeling during pregnancy and labor is incomplete, partly due to the lack of in vivo studies on the biochemical changes that occur in the cervix over the course of pregnancy. Elucidation of the mechanisms for cervical ripening could be used to predict the onset of preterm labor. Until recently, in vivo research methods were too invasive to be used as discovery tools, particularly in women who present with preterm labor. This proposal will use in vivo Raman spectroscopy, an optical technique that is sensitive to collagen content, collagen structure, hydration, lipids, proteins, ad other biomolecules to non-invasively investigate the biochemistry of the cervix throughout pregnancy. Using fiber optic in vivo Raman spectroscopy, we recently found significant differences in Raman spectra in at least four important peaks during the course of pregnancy in mice, including discrete signatures for lipids, collagen, amide bonds, and enriched amino acids (proline, tyrosine). Computational analysis of these spectra yielded predictive algorithms with 94% classification accuracy for stage of pregnancy. Studies performed in 2-hour windows at the end of pregnancy identified spectra predictive for the timing of parturition. This approach provides a detailed real-time biomolecular map of cervical ripening that is currently unavailable by other means. In this proposal, we hypothesize that the different mechanisms of premature cervical ripening have unique Raman spectral signatures that correspond to underlying biochemical and mechanical changes that precede preterm birth, which can be detected in vivo. Two Specific Aims are proposed: 1) Determine spectral changes in the cervix of mice with normal and abnormal pregnancy and parturition; 2) Identify specific mediators of cervical remodeling by comparing Raman spectra to mechanical and biochemical changes in the ex vivo cervix during normal and abnormal parturition. Raman spectroscopy has primarily been used for detection of disease. Collaboration between our reproductive biology and bioengineering groups will capitalize on our expertise in Raman analysis of cervical tissues to study dynamic changes in cervix composition during pregnancy. Key elements in cervical biochemistry will be identified. In vivo Raman spectroscopy will be combined with biomechanical studies and imaging mass spectrometry, a powerful tool for in situ proteomic analysis, to examine mice with premature or delayed cervical remodeling. Together, these highly innovative approaches will generate in-depth profiles of cervical biology that will translate into novel non-invasive methods to detect impending premature birth in women. PUBLIC HEALTH RELEVANCE: This proposal will use Raman Spectroscopy, a non-invasive, optical scattering technique, to investigate the composition of the cervix throughout pregnancy and provide detailed real-time information on cervical ripening. These studies will identify spectral differences in the cervix during normal and abnormal cervical maturation; optical and biochemical markers will be identified to help monitor pregnancy non-invasively, as the fiber optic probe only requires brief contact with the external surface of the cervix to obtain measurements. Elucidating the mechanisms that initiate cervical ripening will provide a critical step for early detection and treatment of preterm birth, which is the leading cause of infant morbidity and mortality.",Detecting biochemical changes in the pregnant mouse cervix by Raman spectroscopy,9443649,R01HD081121,"['Address', 'Algorithms', 'Alprostadil', 'Amides', 'Amino Acids', 'Applications Grants', 'Biochemical', 'Biochemical Markers', 'Biochemistry', 'Biological', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biomechanics', 'Biomedical Engineering', 'Birth', 'Cervical', 'Cervical Ripening', 'Cervix Uteri', 'Classification', 'Clinical', 'Collaborations', 'Collagen', 'Computational algorithm', 'Computer Analysis', 'Data', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Elements', 'Emerging Technologies', 'Etiology', 'Fetal Development', 'Fiber Optics', 'Foundations', 'Generations', 'Goals', 'Health', 'High-Risk Pregnancy', 'Hormonal', 'Hour', 'Hydration status', 'Image', 'Immunohistochemistry', 'Impairment', 'In Situ', 'In Situ Hybridization', 'Infant Mortality', 'Interdisciplinary Study', 'Laboratories', 'Lead', 'Link', 'Lipids', 'Machine Learning', 'Maintenance', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mechanics', 'Mediator of activation protein', 'Medical', 'Methods', 'Mifepristone', 'Modality', 'Molecular', 'Molecular Profiling', 'Monitor', 'Mus', 'Optics', 'Periodicity', 'Phenotype', 'Physiological', 'Pregnancy', 'Premature Birth', 'Premature Labor', 'Prevention', 'Process', 'Proline', 'Property', 'Proteins', 'Proteomics', 'Raman Spectrum Analysis', 'Reproductive Biology', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Spectrum Analysis', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Tyrosine', 'Woman', 'base', 'clinical application', 'in vivo', 'infant morbidity', 'innovation', 'insight', 'learning strategy', 'mouse model', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'physical science', 'prediction algorithm', 'predictive modeling', 'pregnant', 'premature', 'public health relevance', 'response', 'tool']",NICHD,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,376620,-0.018641968652398668
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9244841,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Analysis', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Modality', 'Modernization', 'Morphology', 'Multimodal Imaging', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Pharmacology', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Reproducibility', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Time', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'clinical imaging', 'disease diagnosis', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'imaging study', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2017,63883,-0.020942997562971757
"A Direct Reading Video Assessment Instrument for Repetitive Motion Stress Project Summary/ Abstract This research studies if computer vision can more effectively evaluate worker exposure and assess the associated risk for work related injuries than conventional methods. Current methods involve either observations or measurements using instruments attached to a worker's hands or arms. Observation is often considered too subjective or inaccurate, and instruments too invasive or time consuming for routine applications in industry. Automated job analysis potentially offers a more objective, accurate, repeatable, and efficient exposure assessment tool than observational analysis. Computer vision uses less resources than instruments attached to workers and does not interfere with production; can quantify more exposure variables and interactions; is suitable for long-term, direct reading exposure assessment; and offers animated data visualizations synchronized with video for identifying aspects of jobs needing interventions. This research leverages the research from coordinated multi-institutional prospective studies of upper limb work related MSD conducted between 2001 and 2010 that studied production and service workers from a variety of US industries, and used rigorous case-criteria and individual-level exposure assessments prospectively, including recording detailed videos of the work. Our study partners from the National Institute for Occupational Safety and Health, the Washington State Labor & Industries Safety & Health Assessment & Research for Prevention program and the University of California-San Francisco will provide task-level videos, associated exposure variable data, and prospective health outcomes for 1,649 workers. Exposure properties directly measured from videos of jobs and corresponding health outcomes from the prospective study database will establish dose-response relationships to translate into a prototype automated job analysis instrument. We build on our previous success in developing video marker-less hand motion algorithms for estimating the ACGIH hand activity level, and reliable video processing methods for hand tracking under challenging viewing conditions. This proposal will refine and develop additional video algorithms, and analyze the videos to extract exposure measures for repetition, posture, exertions, and their interactions. The video extracted exposure measures will be compared against conventional observational exposure measures made by our collaborators. Video and corresponding observational data will be merged with the prospective health outcomes data to evaluate dose-response and to develop and validate parsimonious exposure risk models for an automated direct reading repetitive motion instrument. We will test if automation has better predictive capability than observation and also consider the accuracy and utility of computer vision analysis against conventional job analysis for selected industrial jobs. This proposal addresses the NIOSH cross-sector programs in Musculoskeletal Disorders as well as in Exposure Assessment. This translational research is in concurrence with the Research to Practice (r2P) initiative by developing technology to disseminate knowledge from recent NIOSH sponsored prospective studies on MSDs. Project Narrative  Upper extremity musculoskeletal injuries are common in hand intensive work involving highly repetitive motions  and exertions and impose a significant socioeconomic burden and substantial personal toll on health,  prosperity and wellbeing.  This proposal investigates a practical approach for exposure assessment of jobs that  can be implemented non-­invasively in the workplace and provide direct reading quantitative measures for  evaluation, prevention and control.   ",A Direct Reading Video Assessment Instrument for Repetitive Motion Stress,9357554,R01OH011024,[' '],NIOSH,UNIVERSITY OF WISCONSIN-MADISON,R01,2017,452168,-0.017937667088144826
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study No abstract available Project Narrative This study will use computer image analysis techniques to improve our understanding of the causes of diagnostic errors during the interpretation of skin biopsy specimens, as well as seek ways to reduce such errors. As skin biopsies are one of the most common medical procedures performed in the U.S., the results of this study have important implications for patients as these tests are frequently used to guide important treatment recommendations for melanoma and surveillance recommendations for dysplastic nevi.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9666656,R01CA200690,[' '],NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2017,283866,-0.007239806898708864
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9341177,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2017,579791,-0.013680033293577303
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,9021663,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Health', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'exercise program', 'faculty research', 'graduate student', 'lecturer', 'lectures', 'personalized approach', 'programs', 'quantitative imaging', 'student training', 'teaching assistant', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2016,59383,0.0002179212586463577
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9174605,R01CA200690,"['Adult', 'Algorithms', 'Architecture', 'Area', 'Association Learning', 'Behavior', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Characteristics', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Event', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Property', 'Reference Standards', 'Research', 'Scanning', 'Skin', 'Slide', 'Specimen', 'Staging', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'visual tracking']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,408063,-0.04256328622548262
"Automated Facial Expression Analysis for Research and Clinical Use DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use. The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.",Automated Facial Expression Analysis for Research and Clinical Use,9029353,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2016,452541,-0.008017016733972005
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand.         PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.            ",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9054574,R01DC014498,"['Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Controlled Study', 'Databases', 'Detection', 'Devices', 'Educational process of instructing', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Intervention', 'Joints', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deafness', 'design', 'experience', 'face perception', 'innovation', 'instructor', 'interest', 'prevent', 'public health relevance', 'reconstruction', 'research study', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2016,331310,-0.0673611838610588
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing. PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8998947,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'improved outcome', 'neovascular', 'novel', 'programs', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2016,180061,0.008204512731335252
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9111923,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,539886,-0.01737242766066417
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9324484,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,175692,-0.01737242766066417
"A Clinical 3D Movement Analysis System for Assessing Lower Extremity Injury Risk and Recovery in Athletes ﻿    DESCRIPTION (provided by applicant):  The mission of Bioniks is to develop and commercialize accurate, low-cost movement analysis systems for clinicians, ergonomists, athletic trainers, and other professionals interested in quantifying human movement. Our initial focus is on developing computer enhancements for inexpensive 3D cameras like the Microsoft Kinect. These enhancements surpass the accuracy limitations of state-of-the-art ""skeleton"" by combining established marker-based measurement protocols and advanced computer vision techniques, to generate clinical-quality 3D human motion data.  Difficult to obtain outside a laboratory setting, these kinematic data are inherently valuable for several NIH priority areas: 1) assessment of function and fatigability in older adults (NIA); 2) measurement of gait and posture biomechanics to monitor patients (NIAMS); 3) tools to enable mobile health and telemedicine by providing a means to monitor, evaluate, manage, track, train, and treat patients in underserved community settings and rural and remote locations (NIMHD, NINR); 4) tools for health informatics for clinical and translational research (NCATS); and 5) measurement of occupational health stressors in the workplace (NIOSH).  For this Phase I STTR, Bioniks' goal is to provide therapists with an affordable and easy-to-use 3D movement analysis system that quantifies an athlete's risk for, or recovery from, lower extremity injury. Our first aim is to show that the movement analysis system will not only be accurate and reliable (Aim 1), but also be practical and easy to use (Aim 2). We hypothesize that: 1) our kinematic measurements will agree with those from a gold-standard laboratory-based motion capture system (Vicon); and 2) that therapists will judge our system to be more useful and usable than current clinical tools, including traditional 2D video analyses. To test these hypotheses, we will conduct a validation study with healthy volunteers at the UCSF Human Performance Center as well as a pilot usability study with therapists and healthy volunteers and patients with history of ACL injury at the SF Sports and Spine Physical Therapy Clinic.         PUBLIC HEALTH RELEVANCE:  Because of the high cost and perceived ineffectiveness of traditional musculoskeletal care, there is growing pressure on health care professionals to provide more cost- effective treatments as well as to validate treatment effectiveness. Bioniks has the opportunity to be the first clinic-based tool that quantitatively and objectively assesses musculoskeletal function of patients over the course of treatment and rehabilitation. This STTR proposal focuses on quantification of an athlete's risk for, and recovery from, lower extremity injury.                ",A Clinical 3D Movement Analysis System for Assessing Lower Extremity Injury Risk and Recovery in Athletes,9046038,R41AR068202,"['Adoption', 'Adult', 'Algorithms', 'Ankle', 'Anterior Cruciate Ligament', 'Area', 'Athletic', 'Biomechanics', 'Boxing', 'Caring', 'Clinic', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Collection', 'Data Set', 'Drops', 'Dyskinetic syndrome', 'Elderly', 'Environment', 'Evaluation', 'Feasibility Studies', 'Feedback', 'Functional disorder', 'Gait', 'Goals', 'Gold', 'Health Professional', 'Human', 'Individual', 'Injury', 'Joints', 'Kinetics', 'Knee', 'Knee Injuries', 'Laboratories', 'Leg', 'Length', 'Limb structure', 'Location', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Mission', 'Monitor', 'Motion', 'Movement', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Nature', 'Occupational Health', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physical therapy', 'Positioning Attribute', 'Posture', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recording of previous events', 'Recovery', 'Rehabilitation therapy', 'Research', 'Risk', 'Risk Factors', 'Rural', 'Series', 'Site', 'Skeleton', 'Small Business Technology Transfer Research', 'Sports', 'System', 'Techniques', 'Technology', 'Telemedicine', 'Testing', 'Time', 'Training', 'Translational Research', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Validation', 'Vertebral column', 'Video Games', 'Workplace', 'anterior cruciate ligament rupture', 'base', 'clinical practice', 'clinical research site', 'commercialization', 'community setting', 'cost', 'cost effective', 'design', 'healthy volunteer', 'interest', 'kinematics', 'ligament injury', 'mHealth', 'meetings', 'modifiable risk', 'movement analysis', 'neuromuscular function', 'physical therapist', 'pressure', 'public health relevance', 'research clinical testing', 'stressor', 'tool', 'usability', 'validation studies', 'volunteer']",NIAMS,"BIONIKS, INC.",R41,2016,215600,-0.027160634210258442
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9110984,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2016,412881,-0.001909854043550959
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9050682,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2016,339750,-0.013550615368157388
"IGF::OT::IGF ARTIFICIAL INTELLIGENCE IN MEDICINE INC: HHSN261201500033I- TASK ORDER 2; POP 9/26/2016-9/25/2017 The purpose of this acquisition is to 1) maintain and update the existing Surveillance Epidemiology and End Results (SEER) ePath network; 2) expand the SEER network to additional pathology laboratories; 3) expand electronic data capture to include electronic reports from diagnostic imaging, and 4) install cancer data forwarding module in previously installed ePath laboratories n/a",IGF::OT::IGF ARTIFICIAL INTELLIGENCE IN MEDICINE INC: HHSN261201500033I- TASK ORDER 2; POP 9/26/2016-9/25/2017,9361217,61201500033I,"['Artificial Intelligence', 'Data', 'Diagnostic Imaging', 'Electronics', 'Laboratories', 'Malignant Neoplasms', 'Medical Surveillance', 'Medicine', 'Pathology', 'Reporting', 'Update', 'electronic data']",NCI,"ARTIFICIAL INTELLIGENCE IN MEDICINE, INC",N03,2016,1999910,-0.026832380307720574
"Micromachined microphones with in-plane and out-of-plane directivity Project Summary We aim to introduce to the hearing-assistive device industry directional microphones with high signal-to-noise ratio, and the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or “window” of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired “rocking” style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. We aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete  -axis pressure gradient sensor. Project Narrative Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the “cocktail party” effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified – making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.",Micromachined microphones with in-plane and out-of-plane directivity,9098683,R44DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Hearing', 'Hearing Aids', 'Industry', 'Laboratories', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R44,2016,490980,-0.015073773946173305
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9176982,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Shapes', 'Slice', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Translations', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'abstracting', 'aging population', 'base', 'catalyst', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2016,677628,-0.008890819098621182
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability.         PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.        ",Capti Screen Reading Assistant for Goal Directed Web Browsing,9048176,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Learning', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'empowered', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2016,500000,-0.019790163863038588
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research ﻿    DESCRIPTION (provided by applicant): This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0(tm) that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud(tm) Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb's DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently.         PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.        ",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9138555,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'United States National Institutes of Health', 'Work', 'analytical tool', 'animal data', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'meetings', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'research study', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2016,750063,0.0020486661259758697
"Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination Project Summary / Abstract Between 1.6 and 3.8 million people each year suffer a mild TBI in the US alone. Reliable diagnosis and prompt treatments are vital to managing the often-serious short and long-term sequelae resulting from mild TBI. However, a reliable objective and accurate method for mild TBI diagnosis outside of a hospital setting, and in particular for determining RTP readiness, has eluded the clinical community. Current diagnosis and RTP assessments are based on patient symptoms, neurocognitive evaluations, and / or physical performance testing. Use of symptom scales are problematic for several reasons including subjectivity and reliability. Neurocognitive evaluations and physical tests (such as balance tests), although less subjective, require pre- injury baseline testing of subjects due to inherently large subject-to-subject variations in evaluation performances. Due to these reasons, current mild TBI diagnostic methods have limited applications and are not suitable for a significant majority of patients who suffer mild TBI. This project is aimed at developing an objective diagnosis of mild traumatic brain injury (mild TBI) based on physiologic changes in a patient after injury and providing a platform capable of RTP guidance. The method is based on quantification of well-known physiologic changes after a concussion, i.e. the impairment of autonomic function and altered cerebral blood flow (CBF) as measured with transcranial Doppler (TCD). The novelty of the proposed approach is the use of a recently-developed analytical machine learning framework for the analysis of the CBF velocity (CBFV) waveforms. In contrast to previous methods used before, the proposed approach utilizes the entire shape of the complex CBFV waveform, thus obtaining subtle changes in blood flow that are lost in other analysis methods. Additionally, comprehensive verification between our platform and MRI will be performed following injury resulting in the first scientific experiments of this kind. The ultimate goal of this Phase II SBIR is to commercialize an objective and accurate software algorithm for reliable diagnosis and management of sports concussions which does not currently exist. The outcome will be a software suite integrated into existing TCD and will be marketed to emergency departments, neurology clinics, and other healthcare providers involved in mild TBI diagnosis and RTP management. Project Narrative Traumatic brain injury (TBI) is a serious public health problem in the United States contributing to a substantial number of deaths and cases of permanent disability. Mild TBI concussions account for over 80% of all TBIs sustained and a major problem is the high rate of mis-diagnosis due to lack of objective measures and delayed onset of symptoms. This project aims to develop the first objective concussion evaluation method using a novel analysis platform that can obtain subtle, physiologic changes in cerebral hemodynamics. Successful completion of this project will result in a portable diagnostic device suitable for use in many scenarios where concussion diagnosis is inaccurate or unavailable today.",Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination,9202982,R44NS092209,"['Accident and Emergency department', 'Accounting', 'Acute', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Area Under Curve', 'Assessment tool', 'Blood Flow Velocity', 'Blood flow', 'Brain Concussion', 'Cerebrovascular Circulation', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Controlled Study', 'Core-Binding Factor', 'Data', 'Data Analytics', 'Data Collection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Evaluation', 'Functional disorder', 'Future', 'Goals', 'Gold', 'Guidelines', 'Health Personnel', 'Hospitals', 'Image', 'Impairment', 'Injury', 'Letters', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Marketing', 'Measures', 'Methods', 'Modeling', 'Neurocognitive', 'Neurologist', 'Neurology', 'Outcome', 'Patients', 'Pediatric Neurology', 'Performance', 'Persons', 'Phase', 'Physical Performance', 'Physicians', 'Physiological', 'Play', 'Public Health', 'Publications', 'Readiness', 'Recovery', 'Research', 'Resolution', 'Risk', 'Severities', 'Shapes', 'Site', 'Small Business Innovation Research Grant', 'Spin Labels', 'Sports', 'Sports Medicine', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Traumatic Brain Injury', 'Ultrasonography', 'United States', 'Variant', 'abstracting', 'balance testing', 'base', 'brain health', 'cerebral hemodynamics', 'clinical Diagnosis', 'diagnostic accuracy', 'disability', 'hemodynamics', 'high school', 'injured', 'innovation', 'mild traumatic brain injury', 'novel', 'performance tests', 'prevent', 'programs', 'relating to nervous system', 'research study', 'success', 'tool']",NINDS,"NEURAL ANALYTICS, INC.",R44,2016,1500000,-0.0010653819909360114
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9108343,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Health', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2016,618809,-0.017907793153206546
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering. PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,9336584,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Health', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'rehabilitation engineering', 'robot rehabilitation', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2016,28000,-0.017004345984384068
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle.           PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.              ",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9047634,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Genetic', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'quantitative imaging', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2016,609726,-0.018544473855587988
"NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired PROJECT SUMMARY (See instructions): The objective of the proposed research is to develop new technology for a Wearable Robotic Object Manipulation Aid (W-ROMA) for the visually impaired. The W-ROMA is a hand-worn assistive device that provides assistance to a visually impaired individual in effectively grasping an object. Thanks to the onboard computer vision methods, the W-ROMA is capable of detecting a target object, determining the hand-object misalignment, and conveying to the wearer, via natural human-device interfaces, the desired hand motion for hand-object alignment. The W-ROMA will contribute to the independent lives of the visually impaired in twofold: First, it helps the visually impaired with independent travel by enabling them to identify a movable obstacle and manipulate the obstacle to make a passage. Second, it assists the visually impaired in effectively grasping an object for non-navigational purpose. The PIs will involve graduate, undergraduate and high school students in the project and use the proposed project activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision and human-robot interaction methods that support accurate and effective object grasping for the visually impaired for their independent daily lives. These methods include: (1) a new real-time object recognition method; (2) an innovative hand-object alignment mechanism; (3) a novel hybrid tactile display system for object shape rendering; and (4) a computationally efficient device localization method. The proposed solutions can be encapsulated in a hand-worn robotic device. The W-ROMA will provide new co-robotic functions for the visually impaired. The PIs have performed proof of concept studies for the computer vision and tactile display methods and the results are promising. The broader impacts include: (1) the research will positively impact the large visually impaired community; (2) the proposed methods can be applied to other small robotic systems that have a wide range of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the PI's university and train graduate and undergraduate students for their future careers in science and engineering. RELEVANCE (See instructions): The project addresses a growing public health care issue--visual impairment. The research fits well into the NEI's Low Vision and Blindness Rehabilitation program that supports development of new technologies for minimizing the impact of visual impairment. The project addresses the NEI's mission by developing new assistive technology that will help the visually impaired to maintain a higher quality of life.",NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired,9136188,R01EY026275,"['Address', 'Blindness', 'Canes', 'Code', 'Communities', 'Companions', 'Computer Vision Systems', 'Data', 'Detection', 'Development', 'Devices', 'Encapsulated', 'Engineering', 'Environment', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'Hand', 'Healthcare', 'High School Student', 'Human', 'Hybrids', 'Image', 'Independent Living', 'Individual', 'Instruction', 'Law Enforcement', 'Maps', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'Motion', 'Movement', 'National Institute of Biomedical Imaging and Bioengineering', 'Performance', 'Persons', 'Polymers', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robotics', 'Rotation', 'Scheme', 'Science', 'Self-Help Devices', 'Solid', 'Speech', 'Speed', 'Students', 'System', 'Tactile', 'Testing', 'Thumb structure', 'Time', 'Training', 'Translations', 'Travel', 'United States National Institutes of Health', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'base', 'blind', 'career', 'design', 'experience', 'graduate student', 'grasp', 'human-robot interaction', 'improved', 'innovation', 'new technology', 'novel', 'object recognition', 'object shape', 'programs', 'research study', 'robotic device', 'tactile display', 'undergraduate student']",NEI,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2016,274076,-0.02537273980067714
"Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition ﻿    DESCRIPTION (provided by applicant): Non-invasive medical devices are fast emerging as powerful tools in providing quantitative, simple to parse data in assessing the health and wellness of users. These devices can provide information feedback to users on their state of health, and can potentially provide valuable real-time insight to doctors on the links between user consumption and activity on their respective health. Recently described epidermal electronics / multifunctional tattoos introduced from our lab and others have demonstrated sensing of biopressure, bioelectricity, analyte concentration, bacteria, and more. These structures potentially represent the evolution of wearable devices as they possess a negligible form factor and conform to any surface (such as skin or teeth), minimizing user impact. These devices also bypass more traditional, ""wearable"" gadgets that often require bulky mechanical fixtures or straps, require complex microfluidic systems or integrated electronics, cannot provide dynamic readout, and cannot be disposed of easily. Dielectric sensors are a class of structures that are able to probe the composition of a biofluid via their impedance spectrum, and can be configured for remote sensing via radio waves. These devices can be composed of isolated, thin film circuits, and are directly amenable to epidermal or tattoo formats. This measurement methodology is inherently tremendously powerful, as it can potentially measure multiple analytes at once by probing multiple resonance peaks, and can potentially be piggybacked onto existing RFID infrastructure for data readout. However, these capabilities have not yet been demonstrated, and under real-world applications dielectric sensors have often proven difficult to use. This is often due to simplistic readout (devices will directly correlate a single metric such s the real value of the impedance at a frequency to a biomarker) and are thus can be sensitive from user to user or to environmental conditions. Herein, the applicant will leverage the expertise and knowledge of the labs of Dr. Omenetto and colleagues to bring practical usability to these dielectric antennas, bridging the gap between laboratory measurement and real-time, and real-world health monitoring applications. The end-goal is to generate disposable, skin and teeth-mounted, dielectric sensors to remotely probe the presence of biomarkers in sweat, saliva, and potentially blood to draw definitive links between user nutrition and their health.         PUBLIC HEALTH RELEVANCE: This proposal seeks to create non-invasive, wireless sensor tattoos to be tagged onto the human body for probing the composition of saliva, sweat, or blood. These wireless sensors would present negligible impediment to the user, and would require next to no upkeep to maintain, potentially facilitating an unprecedented level of subject data collection and dissemination. Such data could yield conclusive links between diet, activity, biomarkers, and public health.            ","Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition",9148070,F32EB021159,"['Architecture', 'Bacteria', 'Behavior', 'Biocompatible Materials', 'Biological', 'Biological Markers', 'Blood', 'Bypass', 'Cells', 'Characteristics', 'Classification', 'Complex', 'Consumption', 'Data', 'Data Analyses', 'Data Collection', 'Detection', 'Development', 'Devices', 'Diet', 'Electronics', 'Evolution', 'Feedback', 'Film', 'Fingerprint', 'Frequencies', 'Goals', 'Health', 'Human body', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medical Device', 'Methodology', 'Microfluidics', 'Monitor', 'Nafion', 'Pattern', 'Performance', 'Principal Component Analysis', 'Public Health', 'Radio', 'Radio Waves', 'Reader', 'Research Infrastructure', 'Running', 'Saliva', 'Silk', 'Skin', 'Sodium', 'Stimulus', 'Structure', 'Surface', 'Sweat', 'Sweating', 'System', 'Tattooing', 'Testing', 'Time', 'Tooth structure', 'Training', 'Urea', 'Validation', 'Wireless Technology', 'World Health', 'bioelectricity', 'design', 'electric impedance', 'enzyme activity', 'flexibility', 'glucose monitor', 'improved', 'insight', 'non-invasive monitor', 'nutrition', 'public health relevance', 'real world application', 'remote sensing', 'response', 'saliva composition', 'sensor', 'tool', 'usability']",NIBIB,TUFTS UNIVERSITY MEDFORD,F32,2016,47190,0.007388618258767766
"Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury ﻿    DESCRIPTION (provided by applicant): Throughout human pregnancy, the placenta is indispensable for embryonic development, fetal growth and tissue differentiation. The placenta also protects the fetus against diverse insults, while preserving maternal health. Placental dysfunction is commonly implicated in complications of pregnancy that challenge maternal physiology (e.g., preeclampsia) and fetal development (e.g., fetal death or fetal growth restriction) or that leads to preterm birth. Within the placenta, the trophoblast constitutes the outermost layer, which is directly bathed in maternal blood and therefore positioned to regulate maternal-fetal gas exchange, nutrient delivery, waste removal and the production of hormones, faithfully balancing fetal needs and maternal supply. Trophoblast damage, which is common in dysfunctional placentas, may interrupt the delicate maternal-fetal balance, cause clinical disease, and leave a lifelong mark on health. A fundamental challenge in perinatal medicine arises from our limited ability to diagnose placental disorders in real time and throughout pregnancy. However, the recent discovery, by ourselves and others, that (a) placental trophoblasts release distinctive micro- and nanovesicles into the maternal circulation and (b) these vesicles contain trophoblast-specific non-coding RNA cargo, created a new opportunity for assessing trophoblast health. These vesicles are actively released by trophoblasts throughout pregnancy, and thus serve as a venipuncture-accessible ""natural biopsy"" of trophoblasts, which can furnish information on trophoblast health in real time. Our established perinatal biology group at Magee- Womens Research Institute includes expertise in perinatal medicine and placental pathology, developmental and molecular biology, and bioinformatics. Inspired by these recent advances, we have partnered with an experienced group of bioengineers that includes experts from Carnegie Mellon University, MIT, and Penn State University, with unique skills in biophysics-based vesicle analytics, including microfluidics, nanomechanics, micro/nano fabrication and vesicle sorting using acoustic tweezers. Together, our new transdisciplinary group will use integrated molecular and biophysical methodologies to directly assess the use of trophoblast-derived extracellular vesicles from maternal plasma as revelatory of trophoblast health in real time and as a technique that may be employed throughout pregnancy. Our approach is comprehensive, centering on miRNAs as well as lncRNAs and circRNAs, analyzed in exosome nanovesicles, as well as microvesicles and apoptotic bodies. As each vesicle features a unique bimolecular and biophysical signature, we will deploy our machine learning- based training and testing pipeline to informatively integrate these distinct signals into an innovative diagnostic tool. Lastly, our deployment of affordable acoustic tweezers technology to sort trophoblastic vesicles will facilitate the translation of our advances into a new ""lab on a chip"" placental diagnostic technology, suitable for small blood volumes. This technology may not only denote trophoblast pathology, but has potential to identify those who may benefit from intervention and to monitor therapeutic success. PUBLIC HEALTH RELEVANCE: Although the placenta is critical for fetal development and pregnancy outcome, it is not currently accessible for real-time diagnostics throughout pregnancy. Having developed tools for isolation and analysis of placenta- specific extracellular from the maternal plasma, we will study molecular and biophysical properties of these vesicles as indicators of placental health and disease.",Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury,9145745,R01HD086325,"['Abruptio Placentae', 'Acoustics', 'Apoptotic', 'Arteries', 'Bathing', 'Bioinformatics', 'Biological Assay', 'Biology', 'Biomedical Engineering', 'Biophysics', 'Biopsy', 'Blood', 'Blood Circulation', 'Blood Volume', 'Blood flow', 'Characteristics', 'Clinical', 'Communication', 'Data', 'Developmental Biology', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Dimensions', 'Disease', 'Embryonic Development', 'Endoglin', 'Equilibrium', 'Evaluation', 'Excision', 'Fetal Death', 'Fetal Development', 'Fetal Growth', 'Fetal Growth Retardation', 'Fetal Tissues', 'Fetus', 'Functional disorder', 'Future', 'Gases', 'Glean', 'Gold', 'Health', 'Histologic', 'Hormones', 'Human', 'Injury', 'Intervention', 'Investigation', 'Knowledge', 'Left', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maternal Health', 'Maternal Physiology', 'Mechanics', 'Methods', 'MicroRNAs', 'Microfluidics', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Needle biopsy procedure', 'Nutrient', 'PGF gene', 'Pathology', 'Perinatal', 'Placenta', 'Placenta Diseases', 'Plasma', 'Plasma Proteins', 'Positioning Attribute', 'Postpartum Period', 'Pre-Eclampsia', 'Predictive Value', 'Pregnancy', 'Pregnancy Complications', 'Pregnancy Outcome', 'Pregnancy-Associated Plasma Protein-A', 'Premature Birth', 'Production', 'Property', 'Provider', 'Research Institute', 'Shapes', 'Signal Transduction', 'Sorting - Cell Movement', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissue Differentiation', 'Training', 'Translations', 'Ultrasonography', 'Universities', 'Untranslated RNA', 'Venipunctures', 'Vesicle', 'Viscosity', 'Woman', 'adverse pregnancy outcome', 'base', 'biophysical properties', 'biophysical techniques', 'circular RNA', 'clinical care', 'cost effective', 'design', 'exosome', 'experience', 'extracellular', 'extracellular vesicles', 'fetal', 'fitness', 'guided inquiry', 'improved', 'in vivo', 'injured', 'innovation', 'micro-total analysis system', 'microvesicles', 'nanofabrication', 'nanomechanics', 'nanovesicle', 'novel', 'perinatal medicine', 'peripheral blood', 'pregnancy disorder', 'skills', 'stem', 'success', 'tomography', 'tool', 'transcriptome sequencing', 'trophoblast', 'viscoelasticity', 'wasting']",NICHD,MAGEE-WOMEN'S RES INST AND FOUNDATION,R01,2016,727321,-0.018838868350704436
"Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle,9282051,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'muscular system', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,58482,0.008289876721385451
"Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings ﻿    DESCRIPTION (provided by applicant): ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the cost  of  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resoure  settings.  We propose to advance our previously developed low-cost, handheld device capable of automatically measuring the optical properties of the eye based on the technique of wavefront aberrometry.  The  proposed  work  will  specifically  focus  on  the development of optical and software systems will extend the device's measurement  range  to  work  on  a  larger  range  of  refractive  errors.  First,  optical  systems  with  no  moving  parts  will  be  developed  which  enable  the  device  to  work  on  subjects  with  severe  myopia  or  hyperopia  (<-­-6  diopters or  >6  diopters  of  refractive  error).  Second,  algorithms  that  make  the  device  easy  and  intuitive  to  use  will  be  implemented.  Third,  a  handheld  prototype  incorporating  these  improvements  will  be  constructed  and  validated  in  model  eye  systems.  The  output  of  this  project  will  be  a  functional,  extended-range  prototype  that  will  facilitate  the  fild-testing  and  commercialization  of  a  low-cost,  easy-to-use  device  to  dispense  eyeglass  prescriptions. PUBLIC HEALTH RELEVANCE: ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the  cost  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resource  settings.  Specifically,  optical  and  software  systems  will  be  developed  that  will  extend  the  measurement  range  of  a  low-cost  device  that  automatically  prescribes  eyeglasses  for patients with a large range of refractive errors.","Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings",9349858,R43EY025452,"['Adoption', 'Algorithms', 'Brazil', 'Caring', 'China', 'Client satisfaction', 'Clinical Trials', 'Communities', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Ensure', 'Eye', 'Eyeglasses', 'Feedback', 'Goals', 'Health', 'Hospitals', 'Human', 'Human Resources', 'Hyperopia', 'Image', 'India', 'Laser In Situ Keratomileusis', 'Letters', 'Licensing', 'Lighting', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Myopia', 'New England', 'Nurses', 'Operative Surgical Procedures', 'Optics', 'Optometrist', 'Optometry', 'Output', 'Patients', 'Performance', 'Pharmacists', 'Phase', 'Population', 'Positioning Attribute', 'Productivity', 'Property', 'Protocols documentation', 'Provider', 'Pupil', 'Quality of life', 'Refractive Errors', 'Resources', 'Rest', 'Retina', 'Source', 'Spottings', 'System', 'Target Populations', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Vision', 'Visual Acuity', 'Work', 'base', 'college', 'commercialization', 'cost', 'design', 'digital', 'disability', 'field study', 'handheld equipment', 'improved', 'lens', 'meetings', 'prototype', 'software systems', 'standard of care', 'success', 'usability']",NEI,"PLENOPTIKA, INC.",R43,2016,25000,-0.0011959401361176425
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9126405,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,316467,0.008571007325155543
"Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography ﻿    DESCRIPTION (provided by applicant):  We propose a tonometry based solution to the problem of inexpensive, unencumbering and non- invasive measurement of blood pressure. The proposed solution will be useful in clinical as well as ambulatory blood pressure measurements. Specifically, we propose to develop a large (1cm x 5cm) two-dimensional array of pressure sensors with 0.2mm spacing (24x128 pressure-sensing elements), together with robust signal processing algorithms with a feedback controlled band-tightening mechanism in order to measure blood pressure at the wrist. The pressure sensor array together with a photoplethysmogram (PPG) sensor will be embedded in a band, and will provide signals through a multiplexed circuit designed. Signal conditioning techniques will be used to get the large amount of data in the form that can be efficiently processed on a microcontroller. The proposed two-dimensional array of pressure sensors will be built using flexible plastic and micro-fabrication techniques. The increased size of the sensor array will ensure proper contact and pressure application with arteries in the wrist for tonometric measurement of BP. The signals generated from the sensor array will be processed through advanced signal processing and optimization techniques to handle the huge amount of data and to mitigate noise. The PPG signals will be used at the wrist to improve the efficiency and accuracy of the system. The sensor array system will be embodied in the form of a band, which will be integrated in a wearable device such as smartwatch. The capabilities of the smartwatch will be used for data processing and analytics. a) Design, develop, and test a two-dimensional pressure sensor array on a polyimide flexible substrate b) Process large amount of analog data from sensor array using signal conditioning and processing techniques  to generate blood pressure estimates c) Design a user friendly prototype form factor, and perform a clinical trial to validate device performance  The engineering members of our multidisciplinary team have specialized in cardiac instrumentation, signal and image processing for medical applications, pressure and touch sensors, signal processing and robust optimization. The team members with clinical expertise have been engaged in blood pressure trials in US, and have been working with leading institutions in India engaged in cardiovascular research. This proposal brings together their unique expertise and experience to innovatively address this challenging problem through a joint effort. PUBLIC HEALTH RELEVANCE: Unmanaged hypertension is a major problem, and its management based on occasional measurement is known to be suboptimal. The ability to measure blood pressure using non- invasive techniques in an ambulatory setting has many significant benefits. We propose to research and develop a large (1cm x 5cm) two-dimensional array of pressure sensors based device together with robust signal processing algorithms with a feedback controlled to measure blood pressure at the wrist. The device will be test in a clinical trial based on the European Society of Hypertension International Protocol.",Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography,9145739,U01EB020589,"['Address', 'Algorithms', 'Area', 'Arteries', 'Blood Pressure', 'Blood Pressure Monitors', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Engineering', 'Clinical Trials', 'Data', 'Data Analytics', 'Devices', 'Elements', 'Engineering', 'Ensure', 'Environment', 'European', 'Fatigue', 'Feedback', 'Generations', 'Goals', 'Health', 'Hypertension', 'India', 'Institution', 'International', 'Joints', 'Lead', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Noise', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Photoplethysmography', 'Process', 'Protocols documentation', 'Research', 'Signal Transduction', 'Societies', 'Somatotype', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Touch sensation', 'Training', 'Untrained Personnel', 'Work', 'Wrist', 'analog', 'arterial tonometry', 'base', 'computerized data processing', 'conditioning', 'design', 'experience', 'field study', 'flexibility', 'image processing', 'improved', 'instrumentation', 'member', 'multidisciplinary', 'pressure', 'process optimization', 'prototype', 'rural area', 'sensor', 'signal processing', 'tonometry', 'two-dimensional', 'user-friendly']",NIBIB,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2016,355735,0.005235743769055306
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9132242,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Health', 'Heart', 'Hybrids', 'Image', 'Individual', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Marketing', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'prevent', 'programs', 'prospective', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'skills training', 'success', 'tool', 'validation studies', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2016,169609,-0.050597533241239105
"Enabling access to printed text for blind people via assisted mobile OCR DESCRIPTION (provided by applicant): This application proposes new technology development and user studies aiming to facilitate the use of mobile Optical Character Recognition (OCR) for blind people. Mobile OCR systems, implemented as smartphones apps, have recently appeared on the market. This technology unleashes the power of modern computer vision algorithms to enable a blind person to hear (via synthetic speech) the content of printed text imaged by the smartphone's camera. Unlike traditional OCR, that requires scanning of a document with a flatbed scanner, mobile OCR apps enable access to text anywhere, anytime. Using their own smartphones, blind people can read store receipts, menus, flyers, business cards, utility bills, and many other printed documents of the type normally encountered in everyday life. Unfortunately, current mobile OCR systems suffer from a chicken-and-egg problem, which limits their usability. They require the user to take a well-framed snapshot of the document to be scanned, with the full text in view, and at a close enough distance that each character can be well resolved and thus readable by the machine. However, taking a good picture of a document is difficult without sight, and thus without the ability to look at the scene being imaged by the camera through the smartphone's screen. Anecdotal evidence, supported by results of preliminary studies conducted by the principal investigator's group, confirms that acquisition of an OCR-readable image of a document can indeed by very challenging for some blind users. We plan to address this problem by developing and testing a new technique of assisted mobile OCR. As the user aims the camera at the document, the system analyzes in real time the stream of images acquired by the camera, and determines how the camera position and orientation should be adjusted so that an OCR-readable image of the document can be acquired. This information is conveyed to the user via a specially designed acoustic signal. This acoustic feedback allows users to quickly adjust and reorient the camera or the document, resulting in reduced access time and in more satisfactory user experience. Multiple user studies with blind participants are planned with the purpose of selecting an appropriate acoustic interface and of evaluating the effectiveness of the proposed assisted mobile OCR modality. PUBLIC HEALTH RELEVANCE: This application is concerned with the development of new technology designed to facilitate use of mobile Optical Character Recognition (OCR) systems to access printed text without sight. Specifically, this exploratory research will develop and test a novel system that, by means of a specially designed acoustic interface, will help a blind person take a well-framed, well-resolved image of a document for OCR processing using a smartphone or wearable camera. If successful, this novel approach to assisted mobile OCR will reduce access time and improve user experience of blind mobile OCR users.",Enabling access to printed text for blind people via assisted mobile OCR,8989105,R21EY025077,"['Acoustics', 'Address', 'Algorithms', 'Augmented Reality', 'Businesses', 'Cellular Phone', 'Chest', 'Chickens', 'Clothing', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Education', 'Effectiveness', 'Employment', 'Environment', 'Eyeglasses', 'Feedback', 'Goals', 'Hand', 'Health', 'Hearing', 'Image', 'Knowledge', 'Life', 'Light', 'Location', 'Marketing', 'Modality', 'Monitor', 'Participant', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Printing', 'Process', 'Quality of life', 'Reading', 'Report (document)', 'Research', 'Resolution', 'Restaurants', 'Scanning', 'Series', 'Signal Transduction', 'Speech', 'Stream', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Development Study', 'Testing', 'Text', 'Time', 'Translating', 'Travel', 'Vision', 'Visual', 'Visually Impaired Persons', 'blind', 'design', 'egg', 'experience', 'handicapping condition', 'improved', 'new technology', 'novel', 'novel strategies', 'object recognition', 'optical character recognition', 'research study', 'technology development', 'usability', 'way finding']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2016,230563,-0.006195371149724713
"In vivo Characterization of Stents using Intravascular OCT Imaging DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel. PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,9097737,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Health', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shapes', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Surrogate Markers', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'preclinical trial', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2016,447440,-0.01280152991897046
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software.         PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.                ",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9030162,R01EY025332,"['3D Print', 'Access to Information', 'Adoption', 'Algorithms', 'American', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image', 'Information Systems', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'research study', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2016,416574,-0.00383990527954784
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,9002898,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Health', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2016,776460,-0.003940875315746374
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8970690,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'digital media', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'pedagogy', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,624643,-0.0153089236203433
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma ABSTRACT  This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Comptutational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans. PROJECT NARRATIVE  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,8989994,R00EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Imaging Device', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'mathematical sciences', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'spectrograph', 'symposium', 'time use']",NEI,UNIVERSITY OF MEMPHIS,R00,2016,230028,-0.023610168687745306
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9213710,R00AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2016,249000,-0.020638281682895318
"Computer-aided detection of focal cortical dysplasias ﻿    DESCRIPTION (provided by applicant): This project proposes to build computer-aided detection (CAD) software for use in identifying cortical malformations known as focal cortical dysplasia's (FCDs), which are a common cause of epileptic seizures. The intent is for the software, used by a neuroradiologist at a clinical workstation, to decrease the time- intensive nature of the visual search for cortical dysplasia's, while simultaneously increasing sensitivity o dysplasia identification, thus reducing the number of missed lesions and making neuroradiologists more effective and more efficient.  Epilepsy is a common neurological disorder, characterized by recurrent unprovoked seizures, that exacts a large toll upon society in terms of both quality of life and health care costs. Malformations of cortical development (MCD) are the most common cause of seizures in children and the second most common cause in adults. Focal cortical dysplasia is a common form of MCD that is responsible for the vast majority of treatment resistant epilepsy in patients with MCD, and when anti-epileptic medication is ineffective, detection of FCD becomes critical to the ability of the epilepsy team to offer surgery which is often these patient's last hope for seizure freedom.  Unfortunately, the radiological diagnosis of FCD is exceedingly difficult in a large percentage of cases due to their focal and subtle nature. Thus, while resection of these dysplasias can often cure seizures, they can be missed for years or decades, resulting in increased neurological damage and degradation of quality of life due to chronic seizures. In principle high resolution MRI can be used to increase diagnostic accuracy. While this is becoming more common in clinical practice, the need for high patient throughput, lack of clinical information and inexperience often results i these lesions being missed on routine clinical reads by neuroradiologists.  The project will build upon a foundation of existing technology for the generation of quantitative measures of the human brain based on MRI imaging, known in the neuroimaging research domain as FreeSurfer. The project will make use of an MRI dataset of 100 subjects with histologically-confirmed FCD to be labeled by four neuroradiologists, and control subjects with epilepsy that is not due to FCD. The project has three aims: gathering the dataset and expansion of the detection algorithms tested in Phase I to include additional MRI biomarkers; development of an MRI scanner slice prescription component to ensure imaging of an FCD at the optimal visualization plane; and an aim to submit a commercialized version of FreeSurfer for FDA 510(k) clearance. The latter aim is important for the long-term project goal of advancing the state of other clinical detection methods through the building of additional CAD tools making use of FreeSurfer's brain measures, including diseases as varied as Huntington's disease, Alzheimer's disease, tumor monitoring and hydrocephalus. PUBLIC HEALTH RELEVANCE: The proposal is to build software for computer-aided detection of focal cortical dysplasias (FCDs), a malformation of brain development that is a common cause of epileptic seizures in children and adults. The proposed software will offer a neuroradiologist a faster and more accurate detection method compared to visual inspection only. By identifying abnormalities otherwise missed, the ensuing surgical removal of an abnormality can often stop seizures.",Computer-aided detection of focal cortical dysplasias,9061843,R44NS083101,"['Adult', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Antiepileptic Agents', 'Back', 'Base of the Brain', 'Biological Markers', 'Brain', 'Brain region', 'Child', 'Chronic', 'Classification', 'Clinical', 'Code', 'Computer software', 'Cortical Dysplasia', 'Cortical Malformation', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Documentation', 'Dysplasia', 'Ensure', 'Epilepsy', 'Equipment', 'Excision', 'Formulation', 'Foundations', 'Freedom', 'Generations', 'Goals', 'Gray unit of radiation dose', 'Health', 'Health Care Costs', 'Histologic', 'Human', 'Huntington Disease', 'Hydrocephalus', 'Image', 'Imagery', 'Label', 'Lesion', 'Letters', 'Licensing', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Markov chain Monte Carlo methodology', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nervous System Trauma', 'Neurologic', 'Operative Surgical Procedures', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Prevalence', 'Procedures', 'Property', 'Quality of life', 'Reading', 'Recurrence', 'Refractory', 'Research', 'Resistance', 'Resolution', 'Scanning', 'Seizures', 'Slice', 'Societies', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'United States', 'Vendor', 'Visual', 'Work', 'base', 'brain malformation', 'clinical practice', 'computer aided detection', 'design', 'diagnostic accuracy', 'gray matter', 'interest', 'migration', 'nervous system disorder', 'neuroimaging', 'radiologist', 'screening', 'success', 'tool', 'tumor', 'vector', 'visual search', 'white matter']",NINDS,"CORTICOMETRICS, LLC",R44,2016,750677,-0.07942493518543355
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9044803,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithms', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Health', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Morphology', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2016,63620,-0.020942997562971757
"Prediction of IPF Progression Using Imaging Patterns ﻿    DESCRIPTION (provided by applicant): Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. These designations of natural history assume great importance at a time when insights from preclinical studies are beginning to translate into therapies targeted at specific key pathways of fibrosis. Stratification of disease phenotypes is important in order to decipher the effects of newly approved therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individual patients.  Various prognostic tools have been developed for IPF that correlate with overall survival; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good early predictive models exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use the anonymized clinical data and source images on 234 patients with IPF from multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for quantitative image analysis, we will train a classifier on scans annotated manually by an expert radiologist, analyzing in separate aims static image features present on baseline scans and transitional (difference) morphologic features on sequential scans that herald progressive disease. Features of anatomic distribution will be explored and reproducible imaging features will be expressed with a quantitative lung fibrosis (QLF) score. Aggregate prognostic models using Cox proportional regression models will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Finally, we will externally validate our models in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitia Lung Disease Program.  Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that anticipate disease course in patients with IPF. We anticipate that these models can be used clinically at the individual patient level to enable more informed and timely management decisions for the choice in treatment as well as future research to define more homogeneous cohorts for testing new safe and effective therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. PUBLIC HEALTH RELEVANCE: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rates of progression are highly variable, which hampers timely decisions about referral for lung transplantation or treatments using newer drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to predict disease course in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with slowly versus rapidly progressive disease, leading to more timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Prediction of IPF Progression Using Imaging Patterns,9122467,R21HL123477,"['Acute', 'Algorithms', 'Anatomy', 'Archives', 'Behavior', 'Biopsy', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Decision Making', 'Derivation procedure', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease model', 'Elderly', 'Etiology', 'Exhibits', 'Fibrosis', 'Functional disorder', 'General Population', 'Goals', 'Hamman-Rich syndrome', 'Health', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Individual', 'Institution', 'Interobserver Variability', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Investigation', 'Laboratories', 'Lung Transplantation', 'Lung diseases', 'Measures', 'Mining', 'Modeling', 'Morphology', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Play', 'Prevalence', 'Progression-Free Survivals', 'Progressive Disease', 'Pulmonary Fibrosis', 'Pulmonary function tests', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Stable Disease', 'Stratification', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'cohort', 'data archive', 'digital imaging', 'disease classification', 'disease natural history', 'disease phenotype', 'effective therapy', 'functional decline', 'image processing', 'imaging biomarker', 'individual patient', 'insight', 'interstitial', 'novel', 'novel therapeutics', 'preclinical study', 'predictive modeling', 'prognostic', 'prognostic tool', 'programs', 'pulmonary function', 'quantitative imaging', 'radiologist', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2016,107290,-0.03332890577158033
"Detection of Glaucoma Progression with Macular OCT Imaging DESCRIPTION (provided by applicant): This application is a formal request for a career development award (K23) for an academic glaucoma specialist with a serious interest in the role of imaging in glaucoma using optical coherence tomography (OCT). This will allow the candidate to establish a clinical research program with the main goal of improving detection of glaucoma progression through macular imaging with spectral-domain OCT. By the time the proposed research is accomplished, the candidate will have preliminary data for continuing his research as an independent investigator and will have collected longitudinal structural and functional data in a group of advanced glaucoma patients that will serve as a platform for further improving detection of glaucoma progression with macular OCT imaging. The data will help the candidate provide preliminary results for a subsequent R01 that would potentially allow the PI to continue follow-up of the patients enrolled in the K23 award period.  I have a Master's of Science degree in Clinical Investigation under my belt and intend to deepen my skills in the field of imaging and biostatistics (to be used for enhancing and handling OCT images and for analyzing longitudinal data) by completing the proposed didactic program. By the end of the award period, I expect that I will have gained additional experience, knowledge, and mentorship required to prosper as an independent clinician-scientist in the field of glaucoma. My long-term goal is to carry out longitudinal studies of glaucoma patients where current and upcoming imaging and functional tests can be applied and their utility for detection of glaucoma progression can be investigated. I am confident that the combined skills and experience of my mentors will lead to a successful outcome for the proposed K award. I also envisage myself mentoring candidates like myself in future so that our collective knowledge and wisdom can be passed along to the next generation of aspiring clinician-scientists.  My objectives during the award period are as follows: 1) To develop an individual research program in glaucoma diagnostic imaging; 2) to successfully complete credited coursework in biomathematics, advanced biostatistics, computer vision (image processing), epidemiology, and ethical issues in research.  The main goal of the research component of this proposal is to better delineate the role of macular SD- OCT imaging for detection of glaucoma progression in advanced glaucoma. The specific aims through which this goal will be accomplished are as follows:  (1) To compare the performance of various global and regional macular measures to detect glaucoma.  The potential factors influencing the performance of various macular outcome measures will be explored. Such covariates include age, race, axial length, disc size, central corneal thickness,  OCT signal strength, and outer retinal thickness among others. I hypothesize that the thickness  of the outer retina (outer nuclear layer to retinal pigment epithelium-Bruch's membrane  complex) may be the most important factor explaining the measurement variability of the inner  retinal layer thickness (GCC or ganglion cell/inner plexiform layers).  (2) To determine and compare the utility of the candidate macular measures, detected through the first  aim, for detection of glaucoma progression in moderately advanced to severe glaucoma.  Moderately advanced to severe glaucoma will be defined as eyes with visual field mean  deviation worse than -6 dB or eyes with involvement of the central 10 degrees on the 24-2  visual field. It is widely accepted that measurement of the optic nerve head or RNFL parameters  in advanced glaucoma does not provide clinicians with much useful information. In contrast, the  central macular ganglion cells are the last to die in glaucoma. Macular imaging in advanced  glaucoma is directed towards this area where detection of change may still be possible. I  hypothesize that macular OCT parameters are valid structural outcome measures (biomarkers)  that can be used to follow the course of the disease in advanced glaucoma and that such  measures are significantly correlated with changes in the central visual field. Changes in the  macular measures over time will be first correlated with the corresponding visual field change  (functional progression) over time in eyes with moderately advanced to severe glaucoma. The  utility of the best candidate macular measures for predicting subsequent glaucoma progression  will also be explored and compared. I hypothesize that there may be a lag period between  progressive loss of macular ganglion cells and subsequent visual field progression in advanced  glaucoma, and therefore, detection of worsening in one or more macular outcome measures  can be used as a proxy for subsequent visual field progression.  Collectively, these studies will provide a solid foundation for better understanding and integration of macular OCT imaging in the care of glaucoma patients. Timely detection of glaucoma progression in the later stages can significantly reduce visual disability and blindness through earlier aggressive treatment and will potentially reduce glaucoma's financial burden to society. Detection of glaucoma progression remains a challenging task in eyes demonstrating significant damage. Even small amounts of progression in advanced glaucoma can have important consequences with regard to patient's visual function and quality of life. The results of the proposed study will potentially lead to more effective and earlier detection of glaucoma progression and will allow ophthalmologists to step up treatment in a timely manner. This will in turn result in less visual morbidity and reduced blindness from glaucoma, which is projected to cause more than 10 million cases of legal blindness around the world in 2020.",Detection of Glaucoma Progression with Macular OCT Imaging,9084580,K23EY022659,"['Age', 'Area', 'Award', 'Biological Markers', 'Biometry', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Caring', 'Clinical Research', 'Complement', 'Complex', 'Computer Vision Systems', 'Cornea', 'Data', 'Detection', 'Diagnosis', 'Diagnostic Imaging', 'Disease', 'Early Diagnosis', 'Enrollment', 'Epidemiology', 'Ethical Issues', 'Evaluation', 'Eye', 'Foundations', 'Functional Imaging', 'Future', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inner Plexiform Layer', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal Blindness', 'Length', 'Longitudinal Studies', 'Master of Science', 'Measurement', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Morbidity - disease rate', 'Nerve Fibers', 'Noise', 'Ophthalmologist', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Outcome Measure', 'Patients', 'Performance', 'Process', 'Proxy', 'Quality of life', 'Race', 'Research', 'Research Personnel', 'Retinal', 'Role', 'Scientist', 'Signal Transduction', 'Societies', 'Solid', 'Specialist', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Thick', 'Time', 'Vision', 'Visual', 'Visual Fields', 'advanced disease', 'biomathematics', 'central visual field', 'clinical investigation', 'disability', 'experience', 'field study', 'follow-up', 'ganglion cell', 'image processing', 'improved', 'interest', 'macula', 'next generation', 'programs', 'retina outer nuclear layer', 'retinal nerve fiber layer', 'skills']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,K23,2016,229139,-0.046552258895507174
"A Direct Reading Video Assessment Instrument for Repetitive Motion Stress Project Summary/ Abstract This research studies if computer vision can more effectively evaluate worker exposure and assess the associated risk for work related injuries than conventional methods. Current methods involve either observations or measurements using instruments attached to a worker's hands or arms. Observation is often considered too subjective or inaccurate, and instruments too invasive or time consuming for routine applications in industry. Automated job analysis potentially offers a more objective, accurate, repeatable, and efficient exposure assessment tool than observational analysis. Computer vision uses less resources than instruments attached to workers and does not interfere with production; can quantify more exposure variables and interactions; is suitable for long-term, direct reading exposure assessment; and offers animated data visualizations synchronized with video for identifying aspects of jobs needing interventions. This research leverages the research from coordinated multi-institutional prospective studies of upper limb work related MSD conducted between 2001 and 2010 that studied production and service workers from a variety of US industries, and used rigorous case-criteria and individual-level exposure assessments prospectively, including recording detailed videos of the work. Our study partners from the National Institute for Occupational Safety and Health, the Washington State Labor & Industries Safety & Health Assessment & Research for Prevention program and the University of California-San Francisco will provide task-level videos, associated exposure variable data, and prospective health outcomes for 1,649 workers. Exposure properties directly measured from videos of jobs and corresponding health outcomes from the prospective study database will establish dose-response relationships to translate into a prototype automated job analysis instrument. We build on our previous success in developing video marker-less hand motion algorithms for estimating the ACGIH hand activity level, and reliable video processing methods for hand tracking under challenging viewing conditions. This proposal will refine and develop additional video algorithms, and analyze the videos to extract exposure measures for repetition, posture, exertions, and their interactions. The video extracted exposure measures will be compared against conventional observational exposure measures made by our collaborators. Video and corresponding observational data will be merged with the prospective health outcomes data to evaluate dose-response and to develop and validate parsimonious exposure risk models for an automated direct reading repetitive motion instrument. We will test if automation has better predictive capability than observation and also consider the accuracy and utility of computer vision analysis against conventional job analysis for selected industrial jobs. This proposal addresses the NIOSH cross-sector programs in Musculoskeletal Disorders as well as in Exposure Assessment. This translational research is in concurrence with the Research to Practice (r2P) initiative by developing technology to disseminate knowledge from recent NIOSH sponsored prospective studies on MSDs. Project Narrative  Upper extremity musculoskeletal injuries are common in hand intensive work involving highly repetitive motions  and exertions and impose a significant socioeconomic burden and substantial personal toll on health,  prosperity and wellbeing.  This proposal investigates a practical approach for exposure assessment of jobs that  can be implemented non-­invasively in the workplace and provide direct reading quantitative measures for  evaluation, prevention and control.   ",A Direct Reading Video Assessment Instrument for Repetitive Motion Stress,9174992,R01OH011024,[' '],NIOSH,UNIVERSITY OF WISCONSIN-MADISON,R01,2016,475542,-0.017937667088144826
"Improving Accuracy and Accessibility of Early Autism Screening DESCRIPTION (provided by applicant): Autism is prevalent (1 in 50 children) and impairing but early intervention has been shown to improve outcomes prompting recommendations for screening at both two year and 18 month health check-ups. Detection of autism early is crucial but accurate screening tools have been elusive. In Phase II, a practical method of improving accuracy of M-CHAT, the most widely used autism screen, was created by adapting the validated and recommended follow up interview, M-CHAT F/Ui (F/U), for efficient use during the visit. In the case of a positive screen, the primary care provider (PCP) can use CHADIS, a web-based questionnaire delivery, decision support and post-visit engagement system, to conduct F/U rather than requiring a visit with another professional. Phase II data showed F/U results by a PCP were equivalent to the autism center. Phase-II data on the M-CHAT plus F/U via CHADIS replicated findings of the F/U authors in showing both excellent positive predictive value (PPV) 0.96 for children >20 months (thus effective for 24 month olds) and also low PPV 0.54 for <20 months. Promisingly, Phase II exploratory analyses using a decision tree including supplementary data from a routinely used standard language screen (ASQ communication scale) and an item from a language measure (MCDI) plus the standard autism screen (M-CHAT plus F/U) reached PPV of 0.95 in the <20 month group. This screen completion could be done efficiently online by parents. Phase IIB plans a replication of this screening procedure which promises to be accurate for 18 month olds and comparison to alternatives using the community network of >400 Maryland doctors where >22,000 autism screens have been done using the CHADIS system. A more accurate screening test is of less value if it is not universally used. In Phase II, an approach was developed that reduces disparities in access to screening using a ""talking"" tablet kiosk that was preferred by parents to alternatives, but further workflow issues will be addressed in Phase IIB. To improve screen completion, we will program an automated reminder/completion confirmation text/email system in CHADIS with coupons as incentives for parents. In Phase II, CHADIS was adapted to capture both patient input and doctor decision-making and Maintenance of Certification (MOC) accreditation was awarded by the American Board of Pediatrics for this program and earned by 140 pediatricians. This monthly doctor quality improvement program will be extended to a daily continuous quality improvement process for the whole office team to further assure patient participation in screening while providing other clinical and financial analytics of value to the office. The Phase-IIB goal is to develop and test an innovative ""screening system"" not just a new test. PUBLIC HEALTH RELEVANCE: Autism is prevalent (1 in 50 children) and impairing but early intervention has been shown to improve outcomes prompting recommendations for screening at both two year and 18 month health check-ups. In Phase I, a standard screening procedure was adapted so that doctors could efficiently identify autistic children at two years of age but the screen did not prove accurate at 18 months. Phase II data showed that a novel method combining supplemental information and a new computerized scoring pathway promised accurate detection at the critical 18 month age. This Phase 2B proposal is aimed at replicating this unique approach to early autism identification in a community sample, comparing it with alternatives plus developing innovative strategies to assure that all children are screened by automating reminders and completion confirmation and by supporting continuous quality improvement in office implementation using automated reporting analytics.",Improving Accuracy and Accessibility of Early Autism Screening,9070770,R44MH085399,"['Academy', 'Accreditation', 'Address', 'Age-Months', 'Age-Years', 'Algorithms', 'American', 'Autistic Disorder', 'Award', 'Certification', 'Child', 'Child Care', 'Child health care', 'Clinical', 'Communication', 'Communities', 'Community Networks', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Decision Making', 'Decision Trees', 'Detection', 'Development', 'Diagnostic tests', 'Early Diagnosis', 'Early Intervention', 'Electronic Mail', 'Evaluation', 'Evidence based intervention', 'Family', 'Feedback', 'Goals', 'Health', 'Improve Access', 'Incentives', 'Interview', 'Language', 'Lead', 'Licensing', 'Maintenance', 'Maryland', 'Measures', 'Methods', 'Motivation', 'Online Systems', 'Outcome', 'Parents', 'Pathway interactions', 'Patient Participation', 'Patients', 'Pediatrics', 'Phase', 'Predictive Value', 'Primary Health Care', 'Procedures', 'Process', 'Provider', 'Public Health', 'Questionnaires', 'Recommendation', 'Reminder Systems', 'Reporting', 'Research', 'Running', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Symptoms', 'System', 'Tablets', 'Testing', 'Text', 'Toddler', 'Training', 'Visit', 'autistic children', 'base', 'checkup examination', 'computerized', 'disparity reduction', 'follow-up', 'improved', 'improved outcome', 'indexing', 'innovation', 'meetings', 'novel', 'pediatrician', 'programs', 'public health priorities', 'screening', 'tool']",NIMH,"TOTAL CHILD HEALTH, INC.",R44,2016,796080,-0.041479816597200375
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers.         PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1        ",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9076876,UH2CA203710,"['Algorithms', 'Arts', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Code', 'Collaborations', 'Color', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Institutes', 'Intelligence', 'Lead', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Statistical Models', 'Students', 'Technology', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2016,320900,-0.00715569728525761
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9145647,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2016,605366,-0.013680033293577303
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning. PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,8914675,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Behavior', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Glass', 'Hand', 'Head', 'Head Movements', 'Health', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Research', 'Robot', 'Robotics', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2015,136355,-0.02441447613380641
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,8813596,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Health', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'quantitative imaging', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2015,59383,0.0002179212586463577
"Face De-Identification for Research and Clinical Use DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis. PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.",Face De-Identification for Research and Clinical Use,8908047,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Health', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'sex', 'social stigma', 'targeted imaging', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2015,193512,-0.030066785574825387
"Automated Facial Expression Analysis for Research and Clinical Use DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use. The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.",Automated Facial Expression Analysis for Research and Clinical Use,8816133,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2015,452541,-0.008017016733972005
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications DESCRIPTION (provided by applicant): In this small business innovations research (SBIR) project we present EyeArt, a retinal image analysis tool for automated diabetic retinopathy (DR) screenings with high diag- nostic efficacy. With its interface to EyePACS, a license-free, scalable telemedicine plat- form, EyeArt will aid the expansion of DR screening and help bridge the exponentially growing disparity between the number of diabetic patients and the number of eye-care providers. Research suggests that the Latino population in general are genetically predisposed to develop diabetes. Their vulnerability to vision loss due to diabetic retinopathy is further compounded by factors such as lack of access to ophthalmology clinicians, lack of insurance, and lack of education. According to the Department of Health Services (DHS) in Los Angeles County (LAC) the situation for diabetics is particularly grim, with current wait times upwards of 6-9 months for retinal examinations for retinopathy screening. This can lead to treatment delays and progression towards irreversible vision loss. To help reduce risk of vision loss in this diabetic population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritizatin of ophthalmologist appointments, and aid in triage of high-risk patients. Our phase I prototype automatic DR screening tool has already shown great potential by beating current academic and commercial DR screening ap- proaches on large public retinal datasets. Going forward, we will build on our approach and further develop innovative, customized algorithms for critical low-level image processing steps, while leveraging on recent advances in computer vision, and machine learning areas for high-level, inference steps to produce a clinical grade DR screening tool. Our lesion localization and screening engine will be functionally integrated with EyePACS to further drive the expansion of screening, particularly benefiting under- resourced screening programs like the LAC-DHS safety net and its large Hispanic diabetic population. PUBLIC HEALTH RELEVANCE: EyeArt - an automated retinal image analysis tool will help in triaging patients in need of expert care and thus reduce the cost of diabetic retinopathy (DR) screening, while leading to an expansion of screening in primary care centers through its easily accessible telemedicine interface. This increased access to DR care will help prevent vision loss due to diabetes complications in vulnerable disparity populations such as Latinos who do not get screened due to socio-economic factors. To make an immediate impact we are collaborating with Los Angeles County Department of Health Services (LAC-DHS) to deploy our system, following clinical validation, in their under-resourced safety net teleretinal screening setup whic caters to large disparity populations of LA County.",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8891422,R44EB013585,"['Adult', 'Age', 'Agreement', 'Algorithms', 'Appointment', 'Area', 'Background Diabetic Retinopathy', 'Blindness', 'California', 'Caring', 'Clinic', 'Clinical', 'Clinical effectiveness', 'Color', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Consult', 'County', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Dimensions', 'Economic Factors', 'Economically Deprived Population', 'Education', 'Engineering', 'Evaluation', 'Eye', 'Faculty', 'Fundus', 'Goals', 'Gold', 'Health', 'Health Services', 'Hispanics', 'Image', 'Image Analysis', 'Industry', 'Institutes', 'Insurance', 'International', 'Latino', 'Lead', 'Learning', 'Lesion', 'Licensing', 'Los Angeles', 'Machine Learning', 'Marketing', 'Measures', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patient Triage', 'Patients', 'Pattern Recognition', 'Phase', 'Population', 'Predictive Value', 'Primary Health Care', 'Process', 'Protocols documentation', 'Provider', 'ROC Curve', 'Reader', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Project Grants', 'Resolution', 'Retinal', 'Retinal Diseases', 'Risk', 'Sensitivity and Specificity', 'Severities', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Engineering', 'Software Tools', 'Surveys', 'System', 'Telemedicine', 'Testing', 'Texture', 'Time', 'Training', 'Triage', 'Universities', 'Validation', 'Work', 'base', 'bioimaging', 'clinical care', 'cloud based', 'computerized', 'cost', 'design', 'diabetic', 'diabetic patient', 'experience', 'high risk', 'image processing', 'innovation', 'prevent', 'programs', 'prototype', 'safety net', 'screening', 'socioeconomics', 'success', 'tool', 'usability']",NIBIB,"EYENUK, INC.",R44,2015,394177,-0.019210707421439408
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing.         PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.                ",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8826350,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Outcome', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'neovascular', 'novel', 'programs', 'public health relevance', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2015,215393,0.008204512731335252
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,8910751,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,589523,-0.01737242766066417
"Image analysis for high-throughput C. elegans infection and metabolism assays DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute. PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8786567,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression Profile', 'Gene Expression Profiling', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'imaging platform', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,309263,-0.0018136090362642293
"Automatically Creating and Updating Meta-Studies of Randomized Controlled Trials ﻿    DESCRIPTION (provided by applicant):  A ""meta-study"" (or ""meta-analysis"") collects and analyzes many studies on the same topic to understand if there is a meaningful, overall result. Meta-studies can support (or refute) interventions, spur new investigations, and lead to novel clinical guidelines. However, constructing meta-studies is a time intensive process of searching the literature, compiling the results, and performing the statistical analysis. Due to the time commitment that is required, many topics are unexplored, and many meta-studies are not kept up-to-date with the latest published results. Finally, a number of (unknown) biases, via subjective choices during the meta-study, may influence the results. Our long-term goal is to automate, as much as possible, the meta-study process. This should decrease subjective bias; increase the dissemination of evidence, especially for diseases and interventions that receive less attention; and allow for the automatic updating of meta-studies as new results are published. We propose a computer system that uses statistical machine learning to gather and group studies focused on similar interventions and outcomes; extract the necessary results from the text; and analyze the results using standard meta-analysis techniques. The final output will be presented in a spreadsheet-like Web-interface where users can explore and even change the data and meta-analyses. Our team uniquely blends technical expertise in machine learning with leadership in publishing meta-studies about Inflammatory Bowel Disease (IBD), our disease of focus for our Phase I feasibility study. We are therefore qualified technically and able to ensure that the techniques generate valid and accurate meta-studies. Our Phase I results will define the current state-of-the-art for this novel task. Further, although we will initially focus n IBD, our Phase I results will demonstrate that our approach can generalize to other diseases, eventually applying to any intervention and any disease. The feasibility shown by our Phase I results will motivate our Phase II effort where we will focus on dramatically improving the approach, yielding broad coverage of all medical literature and generating human-quality meta-studies. We note that by the end of Phase I we should have a viable end-to-end prototype, focused on IBD, which we can begin taking to market. The final product should significantly benefit our target markets given the Phase II emphasis to improve the technology, user experience, and scope of covered diseases. PUBLIC HEALTH RELEVANCE:  A meta-analysis collects and analyzes the results from multiple studies that are all focused on the same topic, and it can confirm (or refute) the overall effect across the studies, lead to changes in clinical guidelines, or spur new directions for research. However, generating a meta-analysis is an extremely time-consuming process, so many diseases are not covered, and most meta-analyses are not updated to reflect the latest published studies. This work begins to automate the process of creating meta-analyses, overcoming these difficulties in order to make the results published in the medical literature more accessible.",Automatically Creating and Updating Meta-Studies of Randomized Controlled Trials,8977531,R43LM012210,"['Adverse event', 'Algorithms', 'Attention', 'Clinical', 'Computer Systems', 'Computer software', 'Data', 'Data Aggregation', 'Diabetes Mellitus', 'Disease', 'Disease remission', 'Dourine', 'Ensure', 'Evidence Based Medicine', 'Feasibility Studies', 'Goals', 'Grouping', 'Guidelines', 'Hand', 'Health', 'Human', 'Inflammatory Bowel Diseases', 'Intervention', 'Intervention Studies', 'Investigation', 'Lead', 'Leadership', 'Literature', 'Lupus', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Meta-Analysis', 'Modeling', 'Odds Ratio', 'Outcome', 'Outcome Study', 'Output', 'Pattern', 'Performance', 'Phase', 'Placebos', 'Population Sizes', 'Process', 'Publishing', 'Qualifying', 'Randomized Controlled Trials', 'Research', 'Research Personnel', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Text', 'Time', 'Update', 'Work', 'abstracting', 'base', 'experience', 'falls', 'improved', 'novel', 'primary outcome', 'programs', 'prototype', 'software development', 'text searching', 'web interface']",NLM,INFERLINK CORPORATION,R43,2015,150000,-0.003950443913661858
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,8902139,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2015,405249,-0.001909854043550959
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8842639,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2015,332955,-0.013550615368157388
"Micromachined microphones with in-plane and out-of-plane directivity Project Summary We aim to introduce to the hearing-assistive device industry directional microphones with high signal-to-noise ratio, and the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or “window” of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired “rocking” style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. We aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete  -axis pressure gradient sensor. Project Narrative Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the “cocktail party” effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified – making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.",Micromachined microphones with in-plane and out-of-plane directivity,8981015,R44DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Hearing', 'Hearing Aids', 'Industry', 'Laboratories', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R44,2015,508997,-0.015073773946173305
"Development of real-time, automated 3D ultrasound tools for the study of placental invasion and morphology ﻿    DESCRIPTION (provided by applicant) Among the most intractable pregnancy pathologies are those related to aberrant trophoblast invasion and the subsequent remodeling of maternal vasculature at the utero-placental interface (UPI). These include preeclampsia (PE), intrauterine growth restriction (IUGR) and abnormally invasive placenta (AIP, aka placenta accreta). Despite this, tools to measure placental structure and function in the crucial late first to early second trimester period have yet to be developed that can be translated from the research environment to routine clinical use. We are now constructing 3D power Doppler ultrasound technologies that provide real-time, quantitative assessment of placental structural and vascular development. We have developed novel semi- automated methods for calculation of placental volume (PlaV) and new methods to measure gross placental morphology (GPM; dimensions, surface area etc.) and to assess the vasculature at the UPI (Fractional Moving Blood Volume, FMBV). We propose four Aims intended to move the field towards routine imaging of placental structure and function in real time and to generate clinically useful tests for monitoring significant placental pathologies. In Aim 1, using machine learning techniques and an extant database of ~2800 1st trimester placental scans, we will fully automate the novel tools developed for measurement of PlaV into a real-time analytical package. Aim 2 will focus on 3D ultrasound techniques to interrogate the vasculature at the UPI through refinement of our new method for determining FMBV, a quantitative measure of vascularity. This will lead to a tool that can assess the entire UPI, a major site of pathology in PE, IUGR and AIP. We also aim to develop 3D power Doppler ultrasound tools for the examination of the size and distribution of the spiral artery jets feeding the intervillous space, enabling us to explore normal and pathological development of the intervillous supply in real-time. Aims 3 and 4 are prospective validation studies designed to test the utility of the tools described above. Aim 3 extends our recently published study of over-invasion of the maternal vasculature to the 1 /2 trimester. The presence and severity of AIP is assessed using Acon, the largest area of standard 3D power Doppler signal at the UPI. Under-invasion will be addressed via analysis of prospectively collected 11-13 week 3D-PD scans in women who develop PE. We will compare PlaV, GPM, FMBV and spiral artery jets in normotensive and preeclamptic pregnancies. The prospective study in Aim 4 will address the environmental impact of smoking by comparing structural and vascular parameters between smokers and non-smokers at weekly intervals from 8-18 wks. These powerful longitudinal studies will map the development of morphologic and vascular features in smokers and non-smokers and provide new insights into the factors responsible for smoking-induced growth restriction. The strong investigative team, composed of bioengineers, maternal-fetal medicine specialists and placental biologists, is delivering these new tools in the research setting and is poised to generate new methods for clinical measurement of placental structure and vascular function in real-time.          PUBLIC HEALTH RELEVANCE: If the placenta does not develop normally, complications like poor fetal growth and preeclampsia in the mother occur. We are developing new ultrasound techniques to measure the placenta early in pregnancy. This could permit early detection of problems that occur months later in the pregnancy. This would allow doctors to monitor the pregnancy and to prevent or treat problems quickly, before they have serious effects on the fetus.        ","Development of real-time, automated 3D ultrasound tools for the study of placental invasion and morphology",9076751,U01HD087209,"['Address', 'Area', 'Biomedical Engineering', 'Blood Vessels', 'Blood Volume', 'Clinical', 'Data', 'Databases', 'Decidua', 'Dependence', 'Development', 'Dimensions', 'Doppler Ultrasound', 'Early Diagnosis', 'Environment', 'Environmental Impact', 'Fetal Growth', 'Fetal Growth Retardation', 'Fetus', 'Generations', 'Goals', 'Gold', 'Growth', 'Growth and Development function', 'Hand', 'Image', 'Lead', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Mothers', 'Pathology', 'Placenta', 'Placenta Accreta', 'Placentation', 'Plant Roots', 'Pre-Eclampsia', 'Pregnancy', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Research', 'Research Design', 'Resources', 'Scanning', 'Second Pregnancy Trimester', 'Severities', 'Shapes', 'Signal Transduction', 'Site', 'Smoker', 'Smoking', 'Specialist', 'Spiral Artery of the Endometrium', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Validation', 'Vascularization', 'Woman', 'feeding', 'fetal', 'fetal medicine', 'implantation', 'in vivo', 'indexing', 'insight', 'model development', 'myometrium', 'non-smoker', 'normotensive', 'novel', 'prevent', 'prospective', 'public health relevance', 'screening', 'tool', 'trophoblast', 'validation studies']",NICHD,HACKENSACK UNIVERSITY MEDICAL CENTER,U01,2015,3271021,-0.008437704644564904
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact).         PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.            ",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,8946754,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2015,658985,-0.017907793153206546
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8852613,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,213115,-0.017791644547600474
"Cloud-computer-aided diagnostic imaging decision support system DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer. Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.",Cloud-computer-aided diagnostic imaging decision support system,8848046,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'accurate diagnosis', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2015,361050,-0.05384166339727857
"Cloud-computer-aided diagnostic imaging decision support system DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer. Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.",Cloud-computer-aided diagnostic imaging decision support system,9050240,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'accurate diagnosis', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2015,227070,-0.05384166339727857
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics.         PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.            ",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9072725,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disadvantaged', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Population', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'Solutions', 'Staging', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2015,299984,-0.008726192549574291
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering. PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8920573,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Health', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'rehabilitation engineering', 'robot rehabilitation', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2015,3412,-0.017004345984384068
"NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired PROJECT SUMMARY (See instructions): The objective of the proposed research is to develop new technology for a Wearable Robotic Object Manipulation Aid (W-ROMA) for the visually impaired. The W-ROMA is a hand-worn assistive device that provides assistance to a visually impaired individual in effectively grasping an object. Thanks to the onboard computer vision methods, the W-ROMA is capable of detecting a target object, determining the hand-object misalignment, and conveying to the wearer, via natural human-device interfaces, the desired hand motion for hand-object alignment. The W-ROMA will contribute to the independent lives of the visually impaired in twofold: First, it helps the visually impaired with independent travel by enabling them to identify a movable obstacle and manipulate the obstacle to make a passage. Second, it assists the visually impaired in effectively grasping an object for non-navigational purpose. The PIs will involve graduate, undergraduate and high school students in the project and use the proposed project activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision and human-robot interaction methods that support accurate and effective object grasping for the visually impaired for their independent daily lives. These methods include: (1) a new real-time object recognition method; (2) an innovative hand-object alignment mechanism; (3) a novel hybrid tactile display system for object shape rendering; and (4) a computationally efficient device localization method. The proposed solutions can be encapsulated in a hand-worn robotic device. The W-ROMA will provide new co-robotic functions for the visually impaired. The PIs have performed proof of concept studies for the computer vision and tactile display methods and the results are promising. The broader impacts include: (1) the research will positively impact the large visually impaired community; (2) the proposed methods can be applied to other small robotic systems that have a wide range of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the PI's university and train graduate and undergraduate students for their future careers in science and engineering. RELEVANCE (See instructions): The project addresses a growing public health care issue--visual impairment. The research fits well into the NEI's Low Vision and Blindness Rehabilitation program that supports development of new technologies for minimizing the impact of visual impairment. The project addresses the NEI's mission by developing new assistive technology that will help the visually impaired to maintain a higher quality of life.",NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired,9050942,R01EY026275,"['Address', 'Blindness', 'Canes', 'Code', 'Communities', 'Companions', 'Computer Vision Systems', 'Data', 'Detection', 'Development', 'Devices', 'Encapsulated', 'Engineering', 'Environment', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'Hand', 'Healthcare', 'High School Student', 'Human', 'Hybrids', 'Image', 'Independent Living', 'Individual', 'Instruction', 'Law Enforcement', 'Maps', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'Motion', 'Movement', 'National Institute of Biomedical Imaging and Bioengineering', 'Performance', 'Persons', 'Polymers', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Rotation', 'Scheme', 'Science', 'Self-Help Devices', 'Solid', 'Solutions', 'Speech', 'Speed', 'Students', 'System', 'Tactile', 'Testing', 'Thumb structure', 'Time', 'Training', 'Translations', 'Travel', 'United States National Institutes of Health', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'base', 'blind', 'career', 'design', 'experience', 'graduate student', 'grasp', 'improved', 'innovation', 'new technology', 'novel', 'object recognition', 'object shape', 'programs', 'research study', 'robotic device', 'tactile display', 'undergraduate student']",NEI,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2015,280721,-0.02537273980067714
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics. n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8792208,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2015,248295,-0.0032919402465584704
"Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury ﻿    DESCRIPTION (provided by applicant): Throughout human pregnancy, the placenta is indispensable for embryonic development, fetal growth and tissue differentiation. The placenta also protects the fetus against diverse insults, while preserving maternal health. Placental dysfunction is commonly implicated in complications of pregnancy that challenge maternal physiology (e.g., preeclampsia) and fetal development (e.g., fetal death or fetal growth restriction) or that leads to preterm birth. Within the placenta, the trophoblast constitutes the outermost layer, which is directly bathed in maternal blood and therefore positioned to regulate maternal-fetal gas exchange, nutrient delivery, waste removal and the production of hormones, faithfully balancing fetal needs and maternal supply. Trophoblast damage, which is common in dysfunctional placentas, may interrupt the delicate maternal-fetal balance, cause clinical disease, and leave a lifelong mark on health. A fundamental challenge in perinatal medicine arises from our limited ability to diagnose placental disorders in real time and throughout pregnancy. However, the recent discovery, by ourselves and others, that (a) placental trophoblasts release distinctive micro- and nanovesicles into the maternal circulation and (b) these vesicles contain trophoblast-specific non-coding RNA cargo, created a new opportunity for assessing trophoblast health. These vesicles are actively released by trophoblasts throughout pregnancy, and thus serve as a venipuncture-accessible ""natural biopsy"" of trophoblasts, which can furnish information on trophoblast health in real time. Our established perinatal biology group at Magee- Womens Research Institute includes expertise in perinatal medicine and placental pathology, developmental and molecular biology, and bioinformatics. Inspired by these recent advances, we have partnered with an experienced group of bioengineers that includes experts from Carnegie Mellon University, MIT, and Penn State University, with unique skills in biophysics-based vesicle analytics, including microfluidics, nanomechanics, micro/nano fabrication and vesicle sorting using acoustic tweezers. Together, our new transdisciplinary group will use integrated molecular and biophysical methodologies to directly assess the use of trophoblast-derived extracellular vesicles from maternal plasma as revelatory of trophoblast health in real time and as a technique that may be employed throughout pregnancy. Our approach is comprehensive, centering on miRNAs as well as lncRNAs and circRNAs, analyzed in exosome nanovesicles, as well as microvesicles and apoptotic bodies. As each vesicle features a unique bimolecular and biophysical signature, we will deploy our machine learning- based training and testing pipeline to informatively integrate these distinct signals into an innovative diagnostic tool. Lastly, our deployment of affordable acoustic tweezers technology to sort trophoblastic vesicles will facilitate the translation of our advances into a new ""lab on a chip"" placental diagnostic technology, suitable for small blood volumes. This technology may not only denote trophoblast pathology, but has potential to identify those who may benefit from intervention and to monitor therapeutic success.         PUBLIC HEALTH RELEVANCE: Although the placenta is critical for fetal development and pregnancy outcome, it is not currently accessible for real-time diagnostics throughout pregnancy. Having developed tools for isolation and analysis of placenta- specific extracellular from the maternal plasma, we will study molecular and biophysical properties of these vesicles as indicators of placental health and disease.            ",Extracellular vesicles and their ncRNA cargo as markers of trophoblast injury,9019135,R01HD086325,"['Abruptio Placentae', 'Acoustics', 'Apoptotic', 'Arteries', 'Bathing', 'Bioinformatics', 'Biological Assay', 'Biology', 'Biomedical Engineering', 'Biophysics', 'Biopsy', 'Blood', 'Blood Circulation', 'Blood Volume', 'Blood flow', 'Characteristics', 'Clinical', 'Communication', 'Data', 'Developmental Biology', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Dimensions', 'Disease', 'Embryonic Development', 'Endoglin', 'Equilibrium', 'Evaluation', 'Excision', 'Fetal Death', 'Fetal Development', 'Fetal Growth', 'Fetal Growth Retardation', 'Fetal Tissues', 'Fetus', 'Functional disorder', 'Future', 'Gases', 'Glean', 'Gold', 'Health', 'Histologic', 'Hormones', 'Human', 'Injury', 'Intervention', 'Investigation', 'Knowledge', 'Left', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maternal Health', 'Maternal Physiology', 'Mechanics', 'Medicine', 'Methods', 'MicroRNAs', 'Microfluidics', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Monitor', 'Needle biopsy procedure', 'Nutrient', 'PGF gene', 'Pathology', 'Perinatal', 'Placenta', 'Placenta Diseases', 'Plasma', 'Plasma Proteins', 'Positioning Attribute', 'Pre-Eclampsia', 'Predictive Value', 'Pregnancy', 'Pregnancy Complications', 'Pregnancy Outcome', 'Pregnancy-Associated Plasma Protein-A', 'Premature Birth', 'Production', 'Property', 'Provider', 'Research Institute', 'Shapes', 'Signal Transduction', 'Sorting - Cell Movement', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissue Differentiation', 'Training', 'Translations', 'Ultrasonography', 'Universities', 'Untranslated RNA', 'Venipunctures', 'Vesicle', 'Viscosity', 'Woman', 'base', 'biophysical properties', 'biophysical techniques', 'circular RNA', 'clinical care', 'cost effective', 'design', 'experience', 'extracellular', 'fetal', 'fitness', 'improved', 'in vivo', 'injured', 'innovation', 'micro-total analysis system', 'nanofabrication', 'nanomechanics', 'nanovesicle', 'novel', 'peripheral blood', 'pregnancy disorder', 'public health relevance', 'skills', 'stem', 'success', 'tomography', 'tool', 'transcriptome sequencing', 'trophoblast', 'viscoelasticity', 'wasting']",NICHD,MAGEE-WOMEN'S RES INST AND FOUNDATION,R01,2015,804679,-0.018838868350704436
"Providing Access to Appliance Displays for Visually Impaired Users DESCRIPTION (provided by applicant):  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays.  This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment.  No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents.  Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image.  For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast.  These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view.  Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users.  Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures.  The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.",Providing Access to Appliance Displays for Visually Impaired Users,8916115,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Health', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'contrast enhanced', 'contrast imaging', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2015,368560,-0.0013180693053153614
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8922953,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2015,314327,0.008571007325155543
"Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings ﻿    DESCRIPTION (provided by applicant): ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the cost  of  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resoure  settings.  We propose to advance our previously developed low-cost, handheld device capable of automatically measuring the optical properties of the eye based on the technique of wavefront aberrometry.  The  proposed  work  will  specifically  focus  on  the development of optical and software systems will extend the device's measurement  range  to  work  on  a  larger  range  of  refractive  errors.  First,  optical  systems  with  no  moving  parts  will  be  developed  which  enable  the  device  to  work  on  subjects  with  severe  myopia  or  hyperopia  (<-­-6  diopters or  >6  diopters  of  refractive  error).  Second,  algorithms  that  make  the  device  easy  and  intuitive  to  use  will  be  implemented.  Third,  a  handheld  prototype  incorporating  these  improvements  will  be  constructed  and  validated  in  model  eye  systems.  The  output  of  this  project  will  be  a  functional,  extended-range  prototype  that  will  facilitate  the  fild-testing  and  commercialization  of  a  low-cost,  easy-to-use  device  to  dispense  eyeglass  prescriptions.                 PUBLIC HEALTH RELEVANCE: ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the  cost  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resource  settings.  Specifically,  optical  and  software  systems  will  be  developed  that  will  extend  the  measurement  range  of  a  low-cost  device  that  automatically  prescribes  eyeglasses  for patients with a large range of refractive errors.             ","Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings",8981552,R43EY025452,"['Adoption', 'Algorithms', 'Brazil', 'Caring', 'China', 'Client satisfaction', 'Clinical Trials', 'Communities', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Ensure', 'Eye', 'Eyeglasses', 'Feedback', 'Goals', 'Health', 'Hospitals', 'Human', 'Human Resources', 'Hyperopia', 'Image', 'India', 'Laser In Situ Keratomileusis', 'Letters', 'Licensing', 'Lighting', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Myopia', 'New England', 'Nurses', 'Operative Surgical Procedures', 'Optics', 'Optometrist', 'Optometry', 'Output', 'Patients', 'Performance', 'Pharmacists', 'Phase', 'Population', 'Positioning Attribute', 'Productivity', 'Property', 'Protocols documentation', 'Provider', 'Pupil', 'Quality of life', 'Refractive Errors', 'Resources', 'Rest', 'Retina', 'Source', 'Spottings', 'System', 'Target Populations', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Vision', 'Visual Acuity', 'Work', 'base', 'college', 'commercialization', 'cost', 'design', 'digital', 'disability', 'improved', 'lens', 'meetings', 'prototype', 'software systems', 'success', 'usability']",NEI,"PLENOPTIKA, INC.",R43,2015,149265,-0.0011959401361176425
"Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition ﻿    DESCRIPTION (provided by applicant): Non-invasive medical devices are fast emerging as powerful tools in providing quantitative, simple to parse data in assessing the health and wellness of users. These devices can provide information feedback to users on their state of health, and can potentially provide valuable real-time insight to doctors on the links between user consumption and activity on their respective health. Recently described epidermal electronics / multifunctional tattoos introduced from our lab and others have demonstrated sensing of biopressure, bioelectricity, analyte concentration, bacteria, and more. These structures potentially represent the evolution of wearable devices as they possess a negligible form factor and conform to any surface (such as skin or teeth), minimizing user impact. These devices also bypass more traditional, ""wearable"" gadgets that often require bulky mechanical fixtures or straps, require complex microfluidic systems or integrated electronics, cannot provide dynamic readout, and cannot be disposed of easily. Dielectric sensors are a class of structures that are able to probe the composition of a biofluid via their impedance spectrum, and can be configured for remote sensing via radio waves. These devices can be composed of isolated, thin film circuits, and are directly amenable to epidermal or tattoo formats. This measurement methodology is inherently tremendously powerful, as it can potentially measure multiple analytes at once by probing multiple resonance peaks, and can potentially be piggybacked onto existing RFID infrastructure for data readout. However, these capabilities have not yet been demonstrated, and under real-world applications dielectric sensors have often proven difficult to use. This is often due to simplistic readout (devices will directly correlate a single metric such s the real value of the impedance at a frequency to a biomarker) and are thus can be sensitive from user to user or to environmental conditions. Herein, the applicant will leverage the expertise and knowledge of the labs of Dr. Omenetto and colleagues to bring practical usability to these dielectric antennas, bridging the gap between laboratory measurement and real-time, and real-world health monitoring applications. The end-goal is to generate disposable, skin and teeth-mounted, dielectric sensors to remotely probe the presence of biomarkers in sweat, saliva, and potentially blood to draw definitive links between user nutrition and their health.         PUBLIC HEALTH RELEVANCE: This proposal seeks to create non-invasive, wireless sensor tattoos to be tagged onto the human body for probing the composition of saliva, sweat, or blood. These wireless sensors would present negligible impediment to the user, and would require next to no upkeep to maintain, potentially facilitating an unprecedented level of subject data collection and dissemination. Such data could yield conclusive links between diet, activity, biomarkers, and public health.            ","Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition",8980210,F32EB021159,"['Architecture', 'Bacteria', 'Behavior', 'Biocompatible Materials', 'Biological', 'Biological Markers', 'Blood', 'Bypass', 'Cells', 'Characteristics', 'Classification', 'Complex', 'Consumption', 'Data', 'Data Analyses', 'Data Collection', 'Detection', 'Development', 'Devices', 'Diet', 'Electronics', 'Evolution', 'Feedback', 'Film', 'Fingerprint', 'Frequencies', 'Goals', 'Health', 'Human body', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medical Device', 'Methodology', 'Microfluidics', 'Monitor', 'Nafion', 'Pattern', 'Performance', 'Principal Component Analysis', 'Public Health', 'Radio', 'Radio Waves', 'Reader', 'Research Infrastructure', 'Running', 'Saliva', 'Silk', 'Skin', 'Sodium', 'Solutions', 'Stimulus', 'Structure', 'Surface', 'Sweat', 'Sweating', 'System', 'Tattooing', 'Testing', 'Time', 'Tooth structure', 'Training', 'Urea', 'Validation', 'Wireless Technology', 'World Health', 'bioelectricity', 'design', 'electric impedance', 'enzyme activity', 'flexibility', 'glucose monitor', 'improved', 'insight', 'non-invasive monitor', 'nutrition', 'public health relevance', 'real world application', 'remote sensing', 'response', 'saliva composition', 'sensor', 'tool', 'usability']",NIBIB,TUFTS UNIVERSITY MEDFORD,F32,2015,56042,0.007388618258767766
"Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography ﻿    DESCRIPTION (provided by applicant):  We propose a tonometry based solution to the problem of inexpensive, unencumbering and non- invasive measurement of blood pressure. The proposed solution will be useful in clinical as well as ambulatory blood pressure measurements. Specifically, we propose to develop a large (1cm x 5cm) two-dimensional array of pressure sensors with 0.2mm spacing (24x128 pressure-sensing elements), together with robust signal processing algorithms with a feedback controlled band-tightening mechanism in order to measure blood pressure at the wrist. The pressure sensor array together with a photoplethysmogram (PPG) sensor will be embedded in a band, and will provide signals through a multiplexed circuit designed. Signal conditioning techniques will be used to get the large amount of data in the form that can be efficiently processed on a microcontroller. The proposed two-dimensional array of pressure sensors will be built using flexible plastic and micro-fabrication techniques. The increased size of the sensor array will ensure proper contact and pressure application with arteries in the wrist for tonometric measurement of BP. The signals generated from the sensor array will be processed through advanced signal processing and optimization techniques to handle the huge amount of data and to mitigate noise. The PPG signals will be used at the wrist to improve the efficiency and accuracy of the system. The sensor array system will be embodied in the form of a band, which will be integrated in a wearable device such as smartwatch. The capabilities of the smartwatch will be used for data processing and analytics. a) Design, develop, and test a two-dimensional pressure sensor array on a polyimide flexible substrate b) Process large amount of analog data from sensor array using signal conditioning and processing techniques  to generate blood pressure estimates c) Design a user friendly prototype form factor, and perform a clinical trial to validate device performance  The engineering members of our multidisciplinary team have specialized in cardiac instrumentation, signal and image processing for medical applications, pressure and touch sensors, signal processing and robust optimization. The team members with clinical expertise have been engaged in blood pressure trials in US, and have been working with leading institutions in India engaged in cardiovascular research. This proposal brings together their unique expertise and experience to innovatively address this challenging problem through a joint effort.         PUBLIC HEALTH RELEVANCE: Unmanaged hypertension is a major problem, and its management based on occasional measurement is known to be suboptimal. The ability to measure blood pressure using non- invasive techniques in an ambulatory setting has many significant benefits. We propose to research and develop a large (1cm x 5cm) two-dimensional array of pressure sensors based device together with robust signal processing algorithms with a feedback controlled to measure blood pressure at the wrist. The device will be test in a clinical trial based on the European Society of Hypertension International Protocol.                ",Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography,8936340,U01EB020589,"['Address', 'Algorithms', 'Area', 'Arteries', 'Blood Pressure', 'Blood Pressure Monitors', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Engineering', 'Clinical Trials', 'Data', 'Devices', 'Elements', 'Engineering', 'Ensure', 'Environment', 'European', 'Fatigue', 'Feedback', 'Generations', 'Goals', 'Hypertension', 'India', 'Institution', 'International', 'Joints', 'Lead', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Noise', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Photoplethysmography', 'Plastics', 'Process', 'Protocols documentation', 'Research', 'Signal Transduction', 'Societies', 'Solutions', 'Somatotype', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Touch sensation', 'Training', 'Untrained Personnel', 'Work', 'Wrist', 'analog', 'arterial tonometry', 'base', 'computerized data processing', 'conditioning', 'design', 'experience', 'flexibility', 'image processing', 'improved', 'instrumentation', 'member', 'multidisciplinary', 'pressure', 'process optimization', 'prototype', 'public health relevance', 'rural area', 'sensor', 'signal processing', 'tonometry', 'two-dimensional', 'user-friendly']",NIBIB,NORTHWESTERN UNIVERSITY,U01,2015,362070,0.005235743769055306
"Low-Cost, Compact, and Portable Robot for Autonomous Intravenous Access using Nea DESCRIPTION (provided by applicant): Peripheral venous access is pivotal to a wide range of clinical interventions and is consequently the leading cause of medical injury in the U.S. Complications associated with the procedure are exacerbated in difficult settings, where the rate of success depends heavily on the patient's physiology and the practitioner's experience. My dissertation thesis pertains to the development of imaging and robotic technologies to improve the accuracy and speed of blood draws and IV's. The core technology is an image-guided robotic device that accurately and autonomously introduces a cannula for venous access. The device operates by mapping in real-time the 3D structure of peripheral veins in order to robotically direct a needle into a selected vein. A working prototype has been developed and validated in several studies, the results of which are described in two journal publications. The device combines a 3D near-infrared vein imager, a robot, and computer vision software; these three components form the basis of the three Specific Aims described in this proposal. The Aims fit into the overall dissertation by 1) incorporating the current imaging hardware into a standalone, handheld imaging device; 2) introducing software for the imaging device that assists in selecting suitable cannulation sites; and 3) integrating the imaging device and software with a miniaturized version of the current robot. The outcome of this work will be a compact and low-cost system that is suited for beta-stage development. PUBLIC HEALTH RELEVANCE: Blood draws and IV therapies are one of the most commonly performed medical routines in hospitals and clinics. Injuries to doctors and patients happen frequently because of how difficult it can be to find veins and accurately insert the needle. We are developing a portable and lightweight medical robot to perform the procedure in situations where the doctor is unable to successfully access the veins. This device may greatly improve the safety and accuracy of venous access, and has wide applications in many clinical areas.","Low-Cost, Compact, and Portable Robot for Autonomous Intravenous Access using Nea",8832591,F31EB018191,"['Algorithms', 'Anatomy', 'Area', 'Benchmarking', 'Blood', 'Cannulas', 'Cannulations', 'Catheters', 'Childhood', 'Clinical', 'Clinics and Hospitals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cues', 'Custom', 'Development', 'Device Safety', 'Devices', 'Emergency Care', 'Evaluation', 'Failure', 'Goals', 'Graph', 'Health', 'Healthcare Systems', 'Human', 'Image', 'Imaging Device', 'In Vitro', 'Injury', 'Institutional Review Boards', 'Intervention', 'Intravenous', 'Journals', 'Knowledge', 'Literature', 'Location', 'Maps', 'Medical', 'Motivation', 'Needles', 'Neonatal', 'Outcome', 'Patients', 'Peripheral', 'Physiology', 'Pilot Projects', 'Population', 'Population Sizes', 'Positioning Attribute', 'Procedures', 'Publications', 'Reporting', 'Robot', 'Robotics', 'Safety', 'Site', 'Speed', 'Sprague-Dawley Rats', 'Staging', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Veins', 'Venous', 'Visual', 'Weight', 'Work', 'arm', 'base', 'cost', 'design', 'experience', 'image guided', 'imaging software', 'imaging system', 'improved', 'in vivo', 'meetings', 'miniaturize', 'pre-clinical', 'prototype', 'robotic device', 'skeletal', 'success', 'three dimensional structure', 'three-dimensional modeling', 'tissue phantom', 'visual motor']",NIBIB,"RUTGERS, THE STATE UNIV OF N.J.",F31,2015,32250,0.0013583452864512821
"Computational Analysis of Microtubule Dynamics for Personalized Cancer Therapy DESCRIPTION (provided by applicant): Optimized optics and feedback-controlled microscope hardware permit efficient acquisition of large, high- quality image datasets. Computer-based analyses deliver fast processing of high volume of image data which manually cannot be accomplished. The most exciting contribution that computer vision systems can make to translational cancer research, however, is to give access to image-based information that is inaccessible by eye. Computer vision programs can be directly coupled to mathematical models that describe the relation between hidden, invisible processes and measurable image events. Changes in the behavior of hidden processes are thus detectable as changes in the image. This study envisages the use of such algorithms to obtain statistically representative results for the differential effects of each of the three FDA-approved taxanes on the microtubule cytoskeleton in prostate cancer (PC) cell lines. My previous work in basic research has demonstrated the ability of computer-based analysis of the microtubule (MT) cytoskeleton to distinguish between weak disease phenotypes and establish links to MT dynamics in renal cell carcinoma. Therefore, the proposed translational research project can impact clinical decision-making by equipping physicians for the first time with a computer-aided tool allowing the design of an effective personalized MT-targeting chemotherapy of metastatic PC patients. Metastatic PC is treated primarily by means of taxane-based chemotherapy with one of the three FDA- approved taxanes (paclitaxel, docetaxel and cabazitaxel). However, currently there is no way of selecting the taxane for chemotherapy based on the particular pattern of dynamic behavior of the MT cytoskeleton in individual patients. In addition, recent data have indicated that AR binds MTs in order to traffic to the nucleus and that there are several clinically relevant AR splice variants i metastatic PC patients. To date, there is no information available on the potential effects of wild type or variant AR on MT dynamics and consequently no information on differential metastatic PC cell response to taxane treatment as a function of cellular AR content. Based on preliminary research, we hypothesize that there are inherent differences in tumor MT dynamics among individual PC patients, and that the presence of AR variants affects specific parameters of MT polymerization dynamics. If correct, this hypothesis has very significant implications for PC treatment. Because different microtubule-targeting drugs (even from within the same class like the taxanes) affect distinct parameters of MT dynamics, it is conceivable that we can match each drug with an individual tumor-specific ""MT-dynamics signature"" for maximum therapeutic efficacy. PUBLIC HEALTH RELEVANCE: We envision that a systematic characterization of microtubule dynamics and their response to taxanes will allow chemotherapy customization and prolong survival of castrate-resistant prostate cancer patient. The proposed study has the potential to impact clinical decision-making by equipping physicians with a computer- aided tool allowing the design of an effective personalized medical treatment. In addition, it will bring insight into the mechanisms of inherent and acquired resistance to microtubule-targeting drugs.",Computational Analysis of Microtubule Dynamics for Personalized Cancer Therapy,8837582,F32CA177104,"['Affect', 'Algorithms', 'Androgen Receptor', 'Basic Science', 'Behavior', 'Binding', 'Biological Markers', 'Biology', 'Cancer Etiology', 'Cancer Patient', 'Cell Nucleus', 'Cell physiology', 'Cessation of life', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Computers', 'Coupled', 'Cytoskeleton', 'Data', 'Data Set', 'Dependency', 'Diagnosis', 'Disease', 'Drug Targeting', 'Dynein ATPase', 'Event', 'Eye', 'FDA approved', 'Feedback', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Health', 'Homeostasis', 'Image', 'Image Analysis', 'In Vitro', 'Individual', 'Label', 'Link', 'Malignant neoplasm of prostate', 'Measurable', 'Measures', 'Medical', 'Metastatic Prostate Cancer', 'Microscope', 'Microtubule Polymerization', 'Microtubule Stabilization', 'Microtubules', 'Modeling', 'Motor', 'Nuclear', 'Optics', 'Outcome', 'Paclitaxel', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Polymers', 'Process', 'Property', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Renal Cell Carcinoma', 'Research', 'Research Project Grants', 'Resistance', 'Scheme', 'Second Primary Neoplasms', 'Taxane Compound', 'Testing', 'Therapeutic', 'Time', 'Transcriptional Regulation', 'Translational Research', 'Treatment Efficacy', 'Tubulin', 'Variant', 'Work', 'anticancer research', 'base', 'behavior test', 'cancer cell', 'cancer therapy', 'cellular targeting', 'chemotherapy', 'clinical decision-making', 'clinically relevant', 'design', 'disease phenotype', 'docetaxel', 'in vivo', 'inhibitor/antagonist', 'insight', 'male', 'mathematical model', 'novel', 'personalized cancer therapy', 'programs', 'prostate cancer cell', 'prostate cancer cell line', 'receptor binding', 'response', 'taxane', 'tool', 'trafficking', 'transcription factor', 'transcriptome sequencing', 'tumor']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2015,59966,-0.05675449351260568
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging.         PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.                ",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,8968015,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Marketing', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'skills training', 'success', 'tool', 'validation studies', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2015,169609,-0.050597533241239105
"Predicting and Detecting Glaucomatous Progression Using Pattern Recognition DESCRIPTION (provided by applicant): This project aims to improve glaucoma management by applying novel pattern recognition techniques to improve the accurate prediction and detection of glaucomatous progression. The premise is that complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and that advanced pattern recognition techniques can find and use that hidden information. The primary goals involve the use of mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1800 glaucomatous and healthy eyes, available as the result of long-term NIH funding. With the interdisciplinary team of glaucoma and pattern recognition experts we have assembled, with our extensive NIH-supported database of eyes, and with the knowledge we have acquired in the optimal use of pattern recognition methods from previous NIH support, we believe the proposed work can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs. The proposed project will develop and demonstrate the usefulness of pattern recognition techniques for predicting and detecting patterns of glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neurodegeneration within the visual pathways at structural and functional levels. The development/use of novel, empirical techniques for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.",Predicting and Detecting Glaucomatous Progression Using Pattern Recognition,8792219,R01EY022039,"['Address', 'Algorithm Design', 'California', 'Caring', 'Clinic', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Databases', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Image', 'Imaging Device', 'Informatics', 'Knowledge', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Noise', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Perimetry', 'Physiologic Intraocular Pressure', 'Physiological', 'Provider', 'Scanning', 'Science', 'Series', 'Signal Transduction', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Translational Research', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'clinical care', 'cost', 'heuristics', 'improved', 'independent component analysis', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'retinal nerve fiber layer', 'skills']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2015,379750,-0.016529535501047837
"Enabling access to printed text for blind people via assisted mobile OCR     DESCRIPTION (provided by applicant): This application proposes new technology development and user studies aiming to facilitate the use of mobile Optical Character Recognition (OCR) for blind people. Mobile OCR systems, implemented as smartphones apps, have recently appeared on the market. This technology unleashes the power of modern computer vision algorithms to enable a blind person to hear (via synthetic speech) the content of printed text imaged by the smartphone's camera. Unlike traditional OCR, that requires scanning of a document with a flatbed scanner, mobile OCR apps enable access to text anywhere, anytime. Using their own smartphones, blind people can read store receipts, menus, flyers, business cards, utility bills, and many other printed documents of the type normally encountered in everyday life. Unfortunately, current mobile OCR systems suffer from a chicken-and-egg problem, which limits their usability. They require the user to take a well-framed snapshot of the document to be scanned, with the full text in view, and at a close enough distance that each character can be well resolved and thus readable by the machine. However, taking a good picture of a document is difficult without sight, and thus without the ability to look at the scene being imaged by the camera through the smartphone's screen. Anecdotal evidence, supported by results of preliminary studies conducted by the principal investigator's group, confirms that acquisition of an OCR-readable image of a document can indeed by very challenging for some blind users. We plan to address this problem by developing and testing a new technique of assisted mobile OCR. As the user aims the camera at the document, the system analyzes in real time the stream of images acquired by the camera, and determines how the camera position and orientation should be adjusted so that an OCR-readable image of the document can be acquired. This information is conveyed to the user via a specially designed acoustic signal. This acoustic feedback allows users to quickly adjust and reorient the camera or the document, resulting in reduced access time and in more satisfactory user experience. Multiple user studies with blind participants are planned with the purpose of selecting an appropriate acoustic interface and of evaluating the effectiveness of the proposed assisted mobile OCR modality.         PUBLIC HEALTH RELEVANCE: This application is concerned with the development of new technology designed to facilitate use of mobile Optical Character Recognition (OCR) systems to access printed text without sight. Specifically, this exploratory research will develop and test a novel system that, by means of a specially designed acoustic interface, will help a blind person take a well-framed, well-resolved image of a document for OCR processing using a smartphone or wearable camera. If successful, this novel approach to assisted mobile OCR will reduce access time and improve user experience of blind mobile OCR users.                ",Enabling access to printed text for blind people via assisted mobile OCR,8812658,R21EY025077,"['Acoustics', 'Address', 'Algorithms', 'Businesses', 'Cellular Phone', 'Chest', 'Chickens', 'Clothing', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Education', 'Effectiveness', 'Employment', 'Environment', 'Eyeglasses', 'Feedback', 'Goals', 'Hand', 'Hearing', 'Image', 'Knowledge', 'Life', 'Light', 'Location', 'Marketing', 'Modality', 'Monitor', 'Participant', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Printing', 'Process', 'Quality of life', 'Reading', 'Report (document)', 'Research', 'Resolution', 'Restaurants', 'Scanning', 'Series', 'Signal Transduction', 'Solutions', 'Speech', 'Stream', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Development Study', 'Testing', 'Text', 'Time', 'Translating', 'Travel', 'Vision', 'Visual', 'Visually Impaired Persons', 'blind', 'design', 'egg', 'experience', 'handicapping condition', 'improved', 'new technology', 'novel', 'novel strategies', 'object recognition', 'optical character recognition', 'public health relevance', 'research study', 'technology development', 'usability', 'way finding']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2015,191510,-0.006195371149724713
"In vivo Characterization of Stents using Intravascular OCT Imaging DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel. PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,8885879,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Health', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'stent thrombosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2015,457216,-0.01280152991897046
IGF::OT::IGF TASK ORDER 1 - CORE & ADMINISTRATION; MAINTENANCE & INSTALLATION FOR THE SURVEILLANCE EPIDEMIOLOGY AND END RESULTS (SEER) ELECTRONIC DATA CAPTURE SOFTWARE SUPPORT AND INSTALLATIONS. Surveillance Epidemiology and End Results (SEER) Electronic Data Capture Software Support and Installations. n/a,IGF::OT::IGF TASK ORDER 1 - CORE & ADMINISTRATION; MAINTENANCE & INSTALLATION FOR THE SURVEILLANCE EPIDEMIOLOGY AND END RESULTS (SEER) ELECTRONIC DATA CAPTURE SOFTWARE SUPPORT AND INSTALLATIONS.,9162089,61201500033I,"['Artificial Intelligence', 'Award', 'Computer software', 'Contracts', 'Data', 'Diagnostic Imaging', 'Electronics', 'Hour', 'Laboratories', 'Maintenance', 'Malignant Neoplasms', 'Medical Surveillance', 'Medicine', 'Pathology', 'Reporting', 'Update', 'electronic data']",NCI,"ARTIFICIAL INTELLIGENCE IN MEDICINE, INC",N03,2015,1135265,-0.02329385544924903
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8771432,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,639475,-0.0153089236203433
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,8807942,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Health', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2015,767996,-0.003940875315746374
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma ABSTRACT  This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Comptutational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans. PROJECT NARRATIVE  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,8798661,R00EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'mathematical sciences', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'spectrograph', 'symposium', 'time use']",NEI,UNIVERSITY OF MEMPHIS,R00,2015,228148,-0.023610168687745306
"Advanced retinal image analysis for AMD screening ﻿    DESCRIPTION (provided by applicant): In this grant application we propose to develop a screening tool for Age-related macular degeneration (AMD) - the single largest cause for legal blindness among aged Americans. A robust screening test that can be performed by a primary care physician or an optometrist, who can then refer the patient to an ophthalmologist, will be a useful first step in casting a wider net and helping reduce the toll of severe vision loss with timely intervention and patient education.  Large, multi-center studies Age Related Eye Disease Study (AREDS) and AREDS2 have shown that vitamin supplements along with minerals and antioxidants slow progression of the disease in patients with intermediate AMD, and those with late AMD in one eye. Identifying the at-risk population for advanced AMD who might benefit from the supplements in a timely manner is a growing problem with the aging baby boomers. The proposed tool, EyeSeeAMD, will analyze color retinal fundus images from a patient, automatically detect the various pathologies associated with AMD, quantify them and recommend if the patient needs to be referred to an expert for further evaluation. We have promising preliminary results in drusen detection, detailed plans for developing the envisioned device, and excellent clinical, research, and engineering teams to guarantee success of the project.         PUBLIC HEALTH RELEVANCE: The proposed tool, EyeSeeAMD, will help in triaging age-related macular degeneration (AMD) patients who are at higher risk to progress to late AMD by providing an automated method for screening the growing aged-population in a non-invasive manner. Timely intervention will help slow the progression of AMD in such patients. Easy quantification of AMD pathological indicators will spur clinical research and drug discovery process by facilitating early and reliable measurement of efficacy of novel treatment methods.            ",Advanced retinal image analysis for AMD screening,8981869,R43EY025984,"['Address', 'Age related macular degeneration', 'Aging', 'Algorithms', 'American', 'Antioxidants', 'Applications Grants', 'Architecture', 'Area Under Curve', 'Blindness', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Cloud Computing', 'Collaborations', 'Color', 'Computer software', 'County', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic Imaging', 'Disease Progression', 'Drug Formulations', 'Drusen', 'Elderly', 'Engineering', 'Evaluation', 'Eye', 'Eye diseases', 'Face', 'Fundus', 'Gold', 'Health Services', 'Hour', 'Image', 'Image Analysis', 'Industry', 'Institutes', 'Intake', 'Intervention', 'Joints', 'Legal Blindness', 'Lesion', 'Los Angeles', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Methods', 'Minerals', 'Monitor', 'Multicenter Studies', 'Ophthalmologist', 'Optometrist', 'Pathology', 'Patient Education', 'Patients', 'Pattern Recognition', 'Phase', 'Physician Executives', 'Pigments', 'Population', 'Populations at Risk', 'Primary Care Physician', 'Process', 'Progressive Disease', 'Quality of life', 'Reader', 'Reading', 'Recommendation', 'Research', 'Research Project Grants', 'Retina', 'Retinal', 'Retinal Diseases', 'Risk', 'Scientist', 'Small Business Innovation Research Grant', 'Software Engineering', 'Specialist', 'Specificity', 'Staging', 'Surveys', 'System', 'Techniques', 'Testing', 'Triage', 'United States', 'Vision', 'Visual impairment', 'Vitamins', 'Work', 'age related', 'aged', 'aging population', 'base', 'clinical care', 'design', 'detector', 'dietary supplements', 'disorder of macula of retina', 'drug discovery', 'experience', 'geographic atrophy', 'high risk', 'image processing', 'image registration', 'improved', 'neovascularization', 'novel', 'operation', 'programs', 'public health relevance', 'screening', 'software development', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2015,224999,-0.013157622150071685
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2).          PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.                 ",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,8854343,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithms', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Morphology', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Tissues', 'Underrepresented Minority', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2015,63363,-0.020942997562971757
"Prediction of IPF Progression Using Imaging Patterns ﻿    DESCRIPTION (provided by applicant): Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. These designations of natural history assume great importance at a time when insights from preclinical studies are beginning to translate into therapies targeted at specific key pathways of fibrosis. Stratification of disease phenotypes is important in order to decipher the effects of newly approved therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individual patients.  Various prognostic tools have been developed for IPF that correlate with overall survival; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good early predictive models exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use the anonymized clinical data and source images on 234 patients with IPF from multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for quantitative image analysis, we will train a classifier on scans annotated manually by an expert radiologist, analyzing in separate aims static image features present on baseline scans and transitional (difference) morphologic features on sequential scans that herald progressive disease. Features of anatomic distribution will be explored and reproducible imaging features will be expressed with a quantitative lung fibrosis (QLF) score. Aggregate prognostic models using Cox proportional regression models will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Finally, we will externally validate our models in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitia Lung Disease Program.  Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that anticipate disease course in patients with IPF. We anticipate that these models can be used clinically at the individual patient level to enable more informed and timely management decisions for the choice in treatment as well as future research to define more homogeneous cohorts for testing new safe and effective therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression.         PUBLIC HEALTH RELEVANCE: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rates of progression are highly variable, which hampers timely decisions about referral for lung transplantation or treatments using newer drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to predict disease course in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with slowly versus rapidly progressive disease, leading to more timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.            ",Prediction of IPF Progression Using Imaging Patterns,8956609,R21HL123477,"['Acute', 'Algorithms', 'Anatomy', 'Archives', 'Behavior', 'Biopsy', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Decision Making', 'Derivation procedure', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease model', 'Elderly', 'Etiology', 'Exhibits', 'Fibrosis', 'Functional disorder', 'General Population', 'Goals', 'Hamman-Rich syndrome', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Individual', 'Institution', 'Interobserver Variability', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Investigation', 'Laboratories', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measures', 'Mining', 'Modeling', 'Morphology', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Play', 'Prevalence', 'Progression-Free Survivals', 'Progressive Disease', 'Pulmonary function tests', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Stable Disease', 'Stratification', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'cohort', 'digital imaging', 'disease classification', 'disease natural history', 'disease phenotype', 'effective therapy', 'functional decline', 'image processing', 'imaging biomarker', 'insight', 'interstitial', 'novel', 'preclinical study', 'predictive modeling', 'prognostic', 'prognostic tool', 'programs', 'public health relevance', 'pulmonary function', 'quantitative imaging', 'radiologist', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2015,107290,-0.03332890577158033
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,8775624,K99AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,GEORGIA INSTITUTE OF TECHNOLOGY,K99,2015,90000,-0.020638281682895318
"Detecting biochemical changes in the pregnant mouse cervix by Raman spectroscopy DESCRIPTION (provided by applicant): Our understanding of cervical remodeling during pregnancy and labor is incomplete, partly due to the lack of in vivo studies on the biochemical changes that occur in the cervix over the course of pregnancy. Elucidation of the mechanisms for cervical ripening could be used to predict the onset of preterm labor. Until recently, in vivo research methods were too invasive to be used as discovery tools, particularly in women who present with preterm labor. This proposal will use in vivo Raman spectroscopy, an optical technique that is sensitive to collagen content, collagen structure, hydration, lipids, proteins, ad other biomolecules to non-invasively investigate the biochemistry of the cervix throughout pregnancy. Using fiber optic in vivo Raman spectroscopy, we recently found significant differences in Raman spectra in at least four important peaks during the course of pregnancy in mice, including discrete signatures for lipids, collagen, amide bonds, and enriched amino acids (proline, tyrosine). Computational analysis of these spectra yielded predictive algorithms with 94% classification accuracy for stage of pregnancy. Studies performed in 2-hour windows at the end of pregnancy identified spectra predictive for the timing of parturition. This approach provides a detailed real-time biomolecular map of cervical ripening that is currently unavailable by other means. In this proposal, we hypothesize that the different mechanisms of premature cervical ripening have unique Raman spectral signatures that correspond to underlying biochemical and mechanical changes that precede preterm birth, which can be detected in vivo. Two Specific Aims are proposed: 1) Determine spectral changes in the cervix of mice with normal and abnormal pregnancy and parturition; 2) Identify specific mediators of cervical remodeling by comparing Raman spectra to mechanical and biochemical changes in the ex vivo cervix during normal and abnormal parturition. Raman spectroscopy has primarily been used for detection of disease. Collaboration between our reproductive biology and bioengineering groups will capitalize on our expertise in Raman analysis of cervical tissues to study dynamic changes in cervix composition during pregnancy. Key elements in cervical biochemistry will be identified. In vivo Raman spectroscopy will be combined with biomechanical studies and imaging mass spectrometry, a powerful tool for in situ proteomic analysis, to examine mice with premature or delayed cervical remodeling. Together, these highly innovative approaches will generate in-depth profiles of cervical biology that will translate into novel non-invasive methods to detect impending premature birth in women. PUBLIC HEALTH RELEVANCE: This proposal will use Raman Spectroscopy, a non-invasive, optical scattering technique, to investigate the composition of the cervix throughout pregnancy and provide detailed real-time information on cervical ripening. These studies will identify spectral differences in the cervix during normal and abnormal cervical maturation; optical and biochemical markers will be identified to help monitor pregnancy non-invasively, as the fiber optic probe only requires brief contact with the external surface of the cervix to obtain measurements. Elucidating the mechanisms that initiate cervical ripening will provide a critical step for early detection and treatment of preterm birth, which is the leading cause of infant morbidity and mortality.",Detecting biochemical changes in the pregnant mouse cervix by Raman spectroscopy,8925122,R01HD081121,"['Address', 'Algorithms', 'Alprostadil', 'Amides', 'Amino Acids', 'Applications Grants', 'Biochemical', 'Biochemical Markers', 'Biochemistry', 'Biological', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biomechanics', 'Biomedical Engineering', 'Birth', 'Cervical', 'Cervical Ripening', 'Cervix Uteri', 'Classification', 'Clinical', 'Collaborations', 'Collagen', 'Computational algorithm', 'Computer Analysis', 'Data', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Emerging Technologies', 'Etiology', 'Fetal Development', 'Fiber Optics', 'Foundations', 'Generations', 'Goals', 'Health', 'High-Risk Pregnancy', 'Hormonal', 'Hour', 'Hydration status', 'Image', 'Immunohistochemistry', 'In Situ', 'In Situ Hybridization', 'Indium', 'Interdisciplinary Study', 'Laboratories', 'Lead', 'Link', 'Lipids', 'Machine Learning', 'Maintenance', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mechanics', 'Mediator of activation protein', 'Medical', 'Methods', 'Mifepristone', 'Modality', 'Molecular', 'Molecular Profiling', 'Monitor', 'Mus', 'Optics', 'Phenotype', 'Physiological', 'Pregnancy', 'Premature Birth', 'Premature Labor', 'Prevention', 'Process', 'Proline', 'Property', 'Proteins', 'Proteomics', 'RU-486', 'Raman Spectrum Analysis', 'Reproductive Biology', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Spectrum Analysis', 'Staging', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Tyrosine', 'Woman', 'base', 'clinical application', 'in vivo', 'infant morbidity/mortality', 'innovation', 'insight', 'mouse model', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'physical science', 'predictive modeling', 'pregnant', 'premature', 'response', 'tool']",NICHD,VANDERBILT UNIVERSITY,R01,2015,362979,-0.018641968652398668
"Computer-aided detection of focal cortical dysplasias ﻿    DESCRIPTION (provided by applicant): This project proposes to build computer-aided detection (CAD) software for use in identifying cortical malformations known as focal cortical dysplasia's (FCDs), which are a common cause of epileptic seizures. The intent is for the software, used by a neuroradiologist at a clinical workstation, to decrease the time- intensive nature of the visual search for cortical dysplasia's, while simultaneously increasing sensitivity o dysplasia identification, thus reducing the number of missed lesions and making neuroradiologists more effective and more efficient.  Epilepsy is a common neurological disorder, characterized by recurrent unprovoked seizures, that exacts a large toll upon society in terms of both quality of life and health care costs. Malformations of cortical development (MCD) are the most common cause of seizures in children and the second most common cause in adults. Focal cortical dysplasia is a common form of MCD that is responsible for the vast majority of treatment resistant epilepsy in patients with MCD, and when anti-epileptic medication is ineffective, detection of FCD becomes critical to the ability of the epilepsy team to offer surgery which is often these patient's last hope for seizure freedom.  Unfortunately, the radiological diagnosis of FCD is exceedingly difficult in a large percentage of cases due to their focal and subtle nature. Thus, while resection of these dysplasias can often cure seizures, they can be missed for years or decades, resulting in increased neurological damage and degradation of quality of life due to chronic seizures. In principle high resolution MRI can be used to increase diagnostic accuracy. While this is becoming more common in clinical practice, the need for high patient throughput, lack of clinical information and inexperience often results i these lesions being missed on routine clinical reads by neuroradiologists.  The project will build upon a foundation of existing technology for the generation of quantitative measures of the human brain based on MRI imaging, known in the neuroimaging research domain as FreeSurfer. The project will make use of an MRI dataset of 100 subjects with histologically-confirmed FCD to be labeled by four neuroradiologists, and control subjects with epilepsy that is not due to FCD. The project has three aims: gathering the dataset and expansion of the detection algorithms tested in Phase I to include additional MRI biomarkers; development of an MRI scanner slice prescription component to ensure imaging of an FCD at the optimal visualization plane; and an aim to submit a commercialized version of FreeSurfer for FDA 510(k) clearance. The latter aim is important for the long-term project goal of advancing the state of other clinical detection methods through the building of additional CAD tools making use of FreeSurfer's brain measures, including diseases as varied as Huntington's disease, Alzheimer's disease, tumor monitoring and hydrocephalus.         PUBLIC HEALTH RELEVANCE: The proposal is to build software for computer-aided detection of focal cortical dysplasias (FCDs), a malformation of brain development that is a common cause of epileptic seizures in children and adults. The proposed software will offer a neuroradiologist a faster and more accurate detection method compared to visual inspection only. By identifying abnormalities otherwise missed, the ensuing surgical removal of an abnormality can often stop seizures.            ",Computer-aided detection of focal cortical dysplasias,8903251,R44NS083101,"['Adult', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Antiepileptic Agents', 'Back', 'Base of the Brain', 'Biological Markers', 'Brain', 'Brain region', 'Child', 'Chronic', 'Classification', 'Clinical', 'Code', 'Computer software', 'Cortical Dysplasia', 'Cortical Malformation', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Documentation', 'Drug Formulations', 'Dysplasia', 'Ensure', 'Epilepsy', 'Equipment', 'Excision', 'Foundations', 'Freedom', 'Generations', 'Goals', 'Gray unit of radiation dose', 'Health Care Costs', 'Histologic', 'Human', 'Huntington Disease', 'Hydrocephalus', 'Image', 'Imagery', 'Label', 'Lesion', 'Letters', 'Licensing', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Markov chain Monte Carlo methodology', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nervous System Trauma', 'Neurologic', 'Operative Surgical Procedures', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Prevalence', 'Procedures', 'Property', 'Quality of life', 'Reading', 'Recurrence', 'Refractory', 'Research', 'Resistance', 'Resolution', 'Scanning', 'Seizures', 'Slice', 'Societies', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'United States', 'Vendor', 'Visual', 'Work', 'base', 'brain malformation', 'clinical practice', 'computer aided detection', 'design', 'diagnostic accuracy', 'gray matter', 'interest', 'migration', 'nervous system disorder', 'neuroimaging', 'public health relevance', 'radiologist', 'screening', 'success', 'tool', 'tumor', 'vector', 'visual search', 'white matter']",NINDS,"CORTICOMETRICS, LLC",R44,2015,750677,-0.07942493518543355
"Detection of Glaucoma Progression with Macular OCT Imaging DESCRIPTION (provided by applicant): This application is a formal request for a career development award (K23) for an academic glaucoma specialist with a serious interest in the role of imaging in glaucoma using optical coherence tomography (OCT). This will allow the candidate to establish a clinical research program with the main goal of improving detection of glaucoma progression through macular imaging with spectral-domain OCT. By the time the proposed research is accomplished, the candidate will have preliminary data for continuing his research as an independent investigator and will have collected longitudinal structural and functional data in a group of advanced glaucoma patients that will serve as a platform for further improving detection of glaucoma progression with macular OCT imaging. The data will help the candidate provide preliminary results for a subsequent R01 that would potentially allow the PI to continue follow-up of the patients enrolled in the K23 award period.  I have a Master's of Science degree in Clinical Investigation under my belt and intend to deepen my skills in the field of imaging and biostatistics (to be used for enhancing and handling OCT images and for analyzing longitudinal data) by completing the proposed didactic program. By the end of the award period, I expect that I will have gained additional experience, knowledge, and mentorship required to prosper as an independent clinician-scientist in the field of glaucoma. My long-term goal is to carry out longitudinal studies of glaucoma patients where current and upcoming imaging and functional tests can be applied and their utility for detection of glaucoma progression can be investigated. I am confident that the combined skills and experience of my mentors will lead to a successful outcome for the proposed K award. I also envisage myself mentoring candidates like myself in future so that our collective knowledge and wisdom can be passed along to the next generation of aspiring clinician-scientists.  My objectives during the award period are as follows: 1) To develop an individual research program in glaucoma diagnostic imaging; 2) to successfully complete credited coursework in biomathematics, advanced biostatistics, computer vision (image processing), epidemiology, and ethical issues in research.  The main goal of the research component of this proposal is to better delineate the role of macular SD- OCT imaging for detection of glaucoma progression in advanced glaucoma. The specific aims through which this goal will be accomplished are as follows:  (1) To compare the performance of various global and regional macular measures to detect glaucoma.  The potential factors influencing the performance of various macular outcome measures will be explored. Such covariates include age, race, axial length, disc size, central corneal thickness,  OCT signal strength, and outer retinal thickness among others. I hypothesize that the thickness  of the outer retina (outer nuclear layer to retinal pigment epithelium-Bruch's membrane  complex) may be the most important factor explaining the measurement variability of the inner  retinal layer thickness (GCC or ganglion cell/inner plexiform layers).  (2) To determine and compare the utility of the candidate macular measures, detected through the first  aim, for detection of glaucoma progression in moderately advanced to severe glaucoma.  Moderately advanced to severe glaucoma will be defined as eyes with visual field mean  deviation worse than -6 dB or eyes with involvement of the central 10 degrees on the 24-2  visual field. It is widely accepted that measurement of the optic nerve head or RNFL parameters  in advanced glaucoma does not provide clinicians with much useful information. In contrast, the  central macular ganglion cells are the last to die in glaucoma. Macular imaging in advanced  glaucoma is directed towards this area where detection of change may still be possible. I  hypothesize that macular OCT parameters are valid structural outcome measures (biomarkers)  that can be used to follow the course of the disease in advanced glaucoma and that such  measures are significantly correlated with changes in the central visual field. Changes in the  macular measures over time will be first correlated with the corresponding visual field change  (functional progression) over time in eyes with moderately advanced to severe glaucoma. The  utility of the best candidate macular measures for predicting subsequent glaucoma progression  will also be explored and compared. I hypothesize that there may be a lag period between  progressive loss of macular ganglion cells and subsequent visual field progression in advanced  glaucoma, and therefore, detection of worsening in one or more macular outcome measures  can be used as a proxy for subsequent visual field progression.  Collectively, these studies will provide a solid foundation for better understanding and integration of macular OCT imaging in the care of glaucoma patients. Timely detection of glaucoma progression in the later stages can significantly reduce visual disability and blindness through earlier aggressive treatment and will potentially reduce glaucoma's financial burden to society. Detection of glaucoma progression remains a challenging task in eyes demonstrating significant damage. Even small amounts of progression in advanced glaucoma can have important consequences with regard to patient's visual function and quality of life. The results of the proposed study will potentially lead to more effective and earlier detection of glaucoma progression and will allow ophthalmologists to step up treatment in a timely manner. This will in turn result in less visual morbidity and reduced blindness from glaucoma, which is projected to cause more than 10 million cases of legal blindness around the world in 2020.",Detection of Glaucoma Progression with Macular OCT Imaging,8866409,K23EY022659,"['Age', 'Area', 'Award', 'Biological Markers', 'Biometry', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Caring', 'Clinical Research', 'Complement', 'Complex', 'Computer Vision Systems', 'Cornea', 'Data', 'Detection', 'Diagnosis', 'Diagnostic Imaging', 'Disease', 'Early Diagnosis', 'Enrollment', 'Epidemiology', 'Ethical Issues', 'Evaluation', 'Eye', 'Foundations', 'Functional Imaging', 'Future', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inner Plexiform Layer', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal Blindness', 'Length', 'Longitudinal Studies', 'Master of Science', 'Measurement', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Morbidity - disease rate', 'Nerve Fibers', 'Noise', 'Ophthalmologist', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Outcome Measure', 'Patients', 'Performance', 'Process', 'Proxy', 'Quality of life', 'Race', 'Research', 'Research Personnel', 'Retinal', 'Role', 'Scientist', 'Signal Transduction', 'Societies', 'Solid', 'Specialist', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Thick', 'Time', 'Vision', 'Visual', 'Visual Fields', 'advanced disease', 'biomathematics', 'central visual field', 'clinical investigation', 'disability', 'experience', 'follow-up', 'ganglion cell', 'image processing', 'improved', 'interest', 'macula', 'next generation', 'programs', 'retina outer nuclear layer', 'retinal nerve fiber layer', 'skills']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,K23,2015,229139,-0.046552258895507174
"Context Understanding Technology to improve internet accessibility for users with DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization. PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.",Context Understanding Technology to improve internet accessibility for users with,8795182,R44EY020082,"['Advertisements', 'Area', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Government', 'Grouping', 'Health', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Persons', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2015,195445,0.005817824137930364
"Improving Accuracy and Accessibility of Early Autism Screening DESCRIPTION (provided by applicant): Autism is prevalent (1 in 50 children) and impairing but early intervention has been shown to improve outcomes prompting recommendations for screening at both two year and 18 month health check-ups. Detection of autism early is crucial but accurate screening tools have been elusive. In Phase II, a practical method of improving accuracy of M-CHAT, the most widely used autism screen, was created by adapting the validated and recommended follow up interview, M-CHAT F/Ui (F/U), for efficient use during the visit. In the case of a positive screen, the primary care provider (PCP) can use CHADIS, a web-based questionnaire delivery, decision support and post-visit engagement system, to conduct F/U rather than requiring a visit with another professional. Phase II data showed F/U results by a PCP were equivalent to the autism center. Phase-II data on the M-CHAT plus F/U via CHADIS replicated findings of the F/U authors in showing both excellent positive predictive value (PPV) 0.96 for children >20 months (thus effective for 24 month olds) and also low PPV 0.54 for <20 months. Promisingly, Phase II exploratory analyses using a decision tree including supplementary data from a routinely used standard language screen (ASQ communication scale) and an item from a language measure (MCDI) plus the standard autism screen (M-CHAT plus F/U) reached PPV of 0.95 in the <20 month group. This screen completion could be done efficiently online by parents. Phase IIB plans a replication of this screening procedure which promises to be accurate for 18 month olds and comparison to alternatives using the community network of >400 Maryland doctors where >22,000 autism screens have been done using the CHADIS system. A more accurate screening test is of less value if it is not universally used. In Phase II, an approach was developed that reduces disparities in access to screening using a ""talking"" tablet kiosk that was preferred by parents to alternatives, but further workflow issues will be addressed in Phase IIB. To improve screen completion, we will program an automated reminder/completion confirmation text/email system in CHADIS with coupons as incentives for parents. In Phase II, CHADIS was adapted to capture both patient input and doctor decision-making and Maintenance of Certification (MOC) accreditation was awarded by the American Board of Pediatrics for this program and earned by 140 pediatricians. This monthly doctor quality improvement program will be extended to a daily continuous quality improvement process for the whole office team to further assure patient participation in screening while providing other clinical and financial analytics of value to the office. The Phase-IIB goal is to develop and test an innovative ""screening system"" not just a new test. PUBLIC HEALTH RELEVANCE: Autism is prevalent (1 in 50 children) and impairing but early intervention has been shown to improve outcomes prompting recommendations for screening at both two year and 18 month health check-ups. In Phase I, a standard screening procedure was adapted so that doctors could efficiently identify autistic children at two years of age but the screen did not prove accurate at 18 months. Phase II data showed that a novel method combining supplemental information and a new computerized scoring pathway promised accurate detection at the critical 18 month age. This Phase 2B proposal is aimed at replicating this unique approach to early autism identification in a community sample, comparing it with alternatives plus developing innovative strategies to assure that all children are screened by automating reminders and completion confirmation and by supporting continuous quality improvement in office implementation using automated reporting analytics.",Improving Accuracy and Accessibility of Early Autism Screening,8894598,R44MH085399,"['Academy', 'Accreditation', 'Address', 'Age-Months', 'Age-Years', 'Algorithms', 'American', 'Autistic Disorder', 'Award', 'Certification', 'Child', 'Child Care', 'Child health care', 'Clinical', 'Communication', 'Communities', 'Community Networks', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Decision Making', 'Decision Trees', 'Detection', 'Development', 'Diagnostic tests', 'Early Diagnosis', 'Early Intervention', 'Electronic Mail', 'Evaluation', 'Evidence based intervention', 'Family', 'Feedback', 'Goals', 'Health', 'Improve Access', 'Incentives', 'Interview', 'Language', 'Lead', 'Licensing', 'Maintenance', 'Maryland', 'Measures', 'Methods', 'Motivation', 'Online Systems', 'Outcome', 'Parents', 'Pathway interactions', 'Patient Participation', 'Patients', 'Pediatrics', 'Phase', 'Predictive Value', 'Primary Health Care', 'Procedures', 'Process', 'Provider', 'Public Health', 'Questionnaires', 'Recommendation', 'Reminder Systems', 'Reporting', 'Research', 'Running', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Symptoms', 'System', 'Tablets', 'Testing', 'Text', 'Toddler', 'Training', 'Visit', 'autistic children', 'base', 'checkup examination', 'computerized', 'follow-up', 'improved', 'indexing', 'innovation', 'meetings', 'novel', 'pediatrician', 'programs', 'public health priorities', 'screening', 'tool']",NIMH,"TOTAL CHILD HEALTH, INC.",R44,2015,796060,-0.041479816597200375
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8919113,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'imaging software', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'targeted imaging', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,341788,0.0005736579585363054
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities.         PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.                ","Pathology Image Informatics Platform for visualization, analysis and management",8970326,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2015,606305,-0.013680033293577303
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair     DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning.          PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.             ",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,8838311,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Behavior', 'Build-it', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Glass', 'Hand', 'Head', 'Head Movements', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Reliance', 'Research', 'Robot', 'Robotics', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'public health relevance', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2014,155663,-0.02441447613380641
"Computational Image Analysis for Cellular and Developmental Biology     DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. !         PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.             ",Computational Image Analysis for Cellular and Developmental Biology,8628140,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'public health relevance', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2014,59383,0.0002179212586463577
"Face De-Identification for Research and Clinical Use     DESCRIPTION (provided by applicant): This application addresses NIH's call to promote data sharing and patient privacy. A major obstacle to sharing of recorded video has been the need to protect participants' identity. Similarly, concern about stigma is a reason that many people in need of mental health services (e.g., in the military) fail to do so. We propose a system to de-identify patients and research participants in video. Face de-identification transfers facial expression automatically from source face images, which are confidential, to target face images, which are not. The system safeguards face anonymity while preserving the facial expression of the original source video. The target video then can communicate the emotion, communicative intent, pain, and neurological or physiological status of the source person without displaying the source person's face. Face de-identification would enable video archive sharing among researchers and clinicians without compromising privacy or confidentiality. Moreover, a version of this system could potentially be used to preserve privacy and anonymity in internet-based interviews. Innovation. The project has four innovations. The approach (1) Removes identity information while retaining facial dynamics; thus preserving the information value of the face to communicate emotion, pain, and related states. (2) Accommodates subtle and spontaneous facial actions, rather than imitating only some predefined molar expressions (e.g., happy or sad). (3) Requires no training steps by target persons. (4) And requires no hand annotation of video. The system is entirely automatic. Approach. The software will take as input a video with the face of a subject (source) and automatically generate or output a video with the face de-identified. The project will use new machine learning and computer vision algorithms for transferring subtle facial expression from a source subject (original video) to a target subject, using only one frontal image of the target subject. A major novelty of the approach is to make the process completely automatic. The algorithm will be validated using commercially available software for face recognition and custom software for facial expression analysis.         PUBLIC HEALTH RELEVANCE: Sharing of video recordings for research and clinical uses would significantly contribute to scientific discovery and patient diagnosis, treatment, and evaluation. We will develop and validate a fully automatic system that preserves facial expression in video while fully protecting face identity.            ",Face De-Identification for Research and Clinical Use,8772435,R21MH099487,"['Address', 'Age', 'Algorithms', 'Archives', 'Behavioral Sciences', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Vision Systems', 'Computer software', 'Confidentiality', 'Custom', 'Data Set', 'Detection', 'Diagnosis', 'Education', 'Emotions', 'Evaluation', 'Face', 'Facial Expression', 'Facial Expression Recognition', 'Goals', 'Gold', 'Hand', 'Human', 'Image', 'Informed Consent', 'Intention', 'Internet', 'Interview', 'Judgment', 'Machine Learning', 'Maps', 'Measurement', 'Mental Health Services', 'Methods', 'Military Personnel', 'Modeling', 'Neurologic', 'Output', 'Pain', 'Participant', 'Patients', 'Perception', 'Personal Computers', 'Persons', 'Physiological', 'Privacy', 'Process', 'Research', 'Research Personnel', 'Running', 'Source', 'Step training', 'System', 'Testing', 'Training', 'Twin Multiple Birth', 'Video Recording', 'base', 'clinical practice', 'data sharing', 'graphical user interface', 'innovation', 'middle age', 'patient privacy', 'public health relevance', 'sex', 'social stigma', 'user-friendly', 'young adult']",NIMH,CARNEGIE-MELLON UNIVERSITY,R21,2014,194915,-0.030066785574825387
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8699686,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'E-learning', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2014,142837,-0.004378159456758402
"Automated retinopathy of prematurity classification using machine learning     DESCRIPTION (provided by applicant): The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH-funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi-disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing.         PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.",Automated retinopathy of prematurity classification using machine learning,8723225,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2014,198905,-0.011064785088650513
"Automated Facial Expression Analysis for Research and Clinical Use     DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use.          The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.            ",Automated Facial Expression Analysis for Research and Clinical Use,8633060,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2014,452541,-0.008017016733972005
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications  Abstract In this small business innovations research (SBIR) project we present EyeArt, a retinal image analysis tool for automated diabetic retinopathy (DR) screenings with high diag- nostic efficacy. With its interface to EyePACS, a license-free, scalable telemedicine plat- form, EyeArt will aid the expansion of DR screening and help bridge the exponentially growing disparity between the number of diabetic patients and the number of eye-care providers. Research suggests that the Latino population in general are genetically predisposed to develop diabetes. Their vulnerability to vision loss due to diabetic retinopathy is further compounded by factors such as lack of access to ophthalmology clinicians, lack of in- surance, and lack of education. According to the Department of Health Services (DHS) in Los Angeles County (LAC) the situation for diabetics is particularly grim, with current wait times upwards of 6-9 months for retinal examinations for retinopathy screening. This can lead to treatment delays and progression towards irreversible vision loss. To help reduce risk of vision loss in this diabetic population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and aid in triage of high-risk patients. Our phase I prototype automatic DR screening tool has already shown great potential by beating current academic and commercial DR screening ap- proaches on large public retinal datasets. Going forward, we will build on our approach and further develop innovative, customized algorithms for critical low-level image pro- cessing steps, while leveraging on recent advances in computer vision, and machine learning areas for high-level, inference steps to produce a clinical grade DR screening tool. Our lesion localization and screening engine will be functionally integrated with EyePACS to further drive the expansion of screening, particularly benefiting under- resourced screening programs like the LAC-DHS safety net and its large Hispanic dia- betic population. PUBLIC HEALTH RELEVANCE: EyeArt - an automated retinal image analysis tool will help in triaging patients in need of expert care and thus reduce the cost of diabetic retinopathy (DR) screening, while leading to an expansion of screening in primary care centers through its easily accessible telemedicine interface. This increased access to DR care will help prevent vision loss due to diabetes complications in vulnerable disparity populations such as Latinos who do not get screened due to socio-economic factors. To make an immediate impact we are collaborating with Los Angeles County Department of Health Services (LAC-DHS) to deploy our system, following clinical validation, in their under-resourced safety net teleretinal screening setup whic caters to large disparity populations of LA County.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8740363,R44EB013585,"['Adult', 'Age', 'Agreement', 'Algorithms', 'Appointment', 'Area', 'Background Diabetic Retinopathy', 'Blindness', 'California', 'Caring', 'Clinic', 'Clinical', 'Clinical effectiveness', 'Color', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Consult', 'County', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Dimensions', 'Economic Factors', 'Economically Deprived Population', 'Education', 'Engineering', 'Evaluation', 'Eye', 'Faculty', 'Fundus', 'Goals', 'Gold', 'Health', 'Health Services', 'Hispanics', 'Image', 'Image Analysis', 'Industry', 'Institutes', 'Insurance', 'International', 'Latino', 'Lead', 'Learning', 'Lesion', 'Licensing', 'Los Angeles', 'Machine Learning', 'Marketing', 'Measures', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patient Triage', 'Patients', 'Pattern Recognition', 'Phase', 'Population', 'Predictive Value', 'Primary Health Care', 'Process', 'Protocols documentation', 'Provider', 'ROC Curve', 'Reader', 'Receiver Operating Characteristics', 'Reporting', 'Research', 'Research Project Grants', 'Resolution', 'Retinal', 'Retinal Diseases', 'Risk', 'Sensitivity and Specificity', 'Severities', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Engineering', 'Software Tools', 'Surveys', 'System', 'Telemedicine', 'Testing', 'Texture', 'Time', 'Training', 'Triage', 'Universities', 'Validation', 'Work', 'base', 'bioimaging', 'clinical care', 'cloud based', 'computerized', 'cost', 'design', 'diabetic', 'diabetic patient', 'experience', 'high risk', 'image processing', 'innovation', 'prevent', 'programs', 'prototype', 'public health relevance', 'safety net', 'screening', 'socioeconomics', 'success', 'tool', 'usability']",NIBIB,"EYENUK, INC.",R44,2014,394542,-0.020148925683030484
"Continued Development of CellProfiler Cell Image Analysis Software     DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology.         PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.            ",Continued Development of CellProfiler Cell Image Analysis Software,8761195,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'public health relevance', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,522488,-0.01737242766066417
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8600293,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,310129,-0.0018136090362642293
"Graph-Based Medical Image Segmentation in 3D and 4D     DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care.         PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.            ",Graph-Based Medical Image Segmentation in 3D and 4D,8759436,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'public health relevance', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2014,395708,-0.001909854043550959
"A Software Platform for Sensor-based Movement Disorder Recognition     DESCRIPTION (provided by applicant): The overall objective of this SBIR project is to develop a pre-commercial prototype system capable of continuously monitoring involuntary movement disorders from a wide spectrum of neurological conditions. The impact of this innovation will enhance the availability of advanced brain and behavior research tools [PA- 11-134] by providing a continuous means of tracking the presence and severity of movement disorders during normal daily activities. This project will transform our unique movement disorder recognition algorithms into custom software that analyzes movement disorders for specific neurological conditions. The information obtained from body worn sensors will provide an accurate and objective means for assessing the complex and changeable nature of movement disorders. This goal cannot by realized using the current method of self-report questionnaires.  The research strategy for Phase I will establish the merit and feasibility of this effort by developing an Application Generation (AG) software platform using a framework of configurable signal processing modules to generate custom applications for movement disorder analysis (Aim 1). This approach reduces the effort and enhances the flexibility of designing and testing software solutions for these applications. The AG Platform will be developed using C++ software to implement signal processing and machine-learning software modules that operate within a knowledge-based framework that we have previously developed. In Aim 2 we will utilize the AG platform to generate movement disorder analysis software to evaluate a challenging test-case application: freezing-of-gait in Parkinson's disease (PD). The goal is to attain performance metrics for freezing that are comparable to those we have achieved for tremor and dyskinesia in previous efforts.  Phase II will refine the capabilities of the AG platform developed in Phase I. We will augment it with the means to automatically design and train the machine learning algorithms, improve the user-interface, and provide options for viewing and summarizing the results. The improved AG platform will be used to develop customized disorder-analysis software that encompasses the full complement of movement disorders associated with PD (e.g. dystonia, bradykinesia, Parkinsonian gait, tremor, dyskinesia), as well as for other neurological condition, such as Essential Tremor (ET). Firmware will be developed for each custom application to efficiently integrate the analytic software with our existing Trigno wireless sensor data acquisition hardware, which needs to be streamlined for this application. This combined system will be evaluated under research use-case scenarios in Neurology. Phase II will deliver an ambulatory Movement Disorder Monitoring system that not only succeeds in providing state-of-the-art monitoring solutions for PD and Essential Tremor, but has proven technology to develop monitoring solutions for a wide variety of neurological conditions. Future development will transfer this technology to a clinical version of this system.         PUBLIC HEALTH RELEVANCE: The project is intended to improve the accuracy and reduce the burden of researchers and clinicians when assessing motor outcomes for patients with involuntary movement disorders. The proposed technology will provide a means for evaluating new treatment options, and expedite the delivery of care. The attainment of these goals should increase the effectiveness of research, the time required for these research advancements to reach the consumer, and help control the rising costs of clinical care among the estimated 45 million Americans who have neurological disorders resulting in involuntary movements. The resulting improvements in motor function will ultimately lead to greater independence and productivity for this growing segment of the population.            ",A Software Platform for Sensor-based Movement Disorder Recognition,8734495,R43NS083098,"['Affect', 'Algorithms', 'American', 'Bradykinesia', 'Clinical', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Custom', 'Data', 'Development', 'Disease', 'Dyskinetic syndrome', 'Dystonia', 'Early Diagnosis', 'Essential Tremor', 'Freezing', 'Future', 'Gait', 'Generations', 'Goals', 'Health Care Sector', 'Health Professional', 'Home environment', 'Involuntary Movements', 'Lead', 'Learning Module', 'Left', 'Lower Extremity', 'Machine Learning', 'Methods', 'Metric', 'Miniaturization', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Neurologic', 'Neurology', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Process', 'Productivity', 'Quality of life', 'Questionnaires', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training', 'Tremor', 'Video Recording', 'Wireless Technology', 'Work', 'Writing', 'advanced system', 'base', 'brain behavior', 'care delivery', 'clinical care', 'cost', 'data acquisition', 'design', 'disorder control', 'effectiveness research', 'flexibility', 'handheld mobile device', 'human subject', 'improved', 'innovation', 'knowledge base', 'motor disorder', 'nervous system disorder', 'novel therapeutics', 'prototype', 'public health relevance', 'research study', 'response', 'sensor', 'signal processing', 'software development', 'tool']",NINDS,"ALTEC, INC.",R43,2014,417876,-0.02095127407060901
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8652462,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2014,332955,-0.013550615368157388
"Micromachined microphones with in-plane and out-of-plane directivity  Project Summary We aim to introduce to the hearing-assistive device industry the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or ""window"" of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired ""rocking"" style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. In Phase II, we aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete 3-axis pressure gradient sensor. PUBLIC HEALTH RELEVANCE: Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the ""cocktail party"" effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified - making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.            ",Micromachined microphones with in-plane and out-of-plane directivity,8648777,R43DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Goals', 'Hearing', 'Hearing Aids', 'Industry', 'Investigation', 'Laboratories', 'Microfabrication', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Phase', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Structure', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'public health relevance', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R43,2014,149828,-0.012287586041213272
"Mobile App for Diabetic Retinopathy Screening using Cellphone Retinal Camera     DESCRIPTION (provided by applicant): In this SBIR project, we present EyeApp, a smartphone-based end-to-end point-of- care diabetic retinopathy diagnostic device comprising of a smartphone-attachable retinal imaging camera and validated software application enabling fully-automated screening of diabetic retinopathy (DR). DR is the leading cause of new-onset blindness in working-age adults in the industrialized world today. Studies show that in 90% of the cases vision loss can be prevented if DR is diagnosed at an early stage.  Recommended annual screening is expected to significantly improve outcome for diabetic patients, but even in the developed world, majority of the diabetics do not regularly have the annual screening due to several limiting factors. To make things worse, the current cost of screening all diabetics to detect those with early DR is very high because: (a) most patients will have normal exams (thus, causing inefficient use of specialist's time), (b) retinal imaging equipment is very expensive, and (c) trained technicians must operate the imaging equipment. In this project we address these critical limitations by employing cellphone retinal camera attachment, the Ocular CellScope, developed by our collaborators at UCB/UCSF, which simply attaches to an iPhone, doesn't need a trained technician to operate, will obtain wide-field images, and will cost several orders of mag- nitude less than the current tabletop retinal imaging cameras. Diabetic patients can attach the camera to their smartphones and with some assistance (untrained friend, spouse, or nurse) obtain retinal video for each eye using an app residing on the same phone. This app guides the image capture to ensure that best quality frames are obtained, and also ensure all areas of the eye are imaged enabling wide-field imaging. EyeApp's validated algorithms output a near-instant DR screening recommendation score. EyeApp is con- ceptualized as a culmination of over three years of research and development at Eyenuk (on computerized DR screening) and at UCB/UCSF (on smartphone retinal camera) that has already produced functional prototypes of critical technology modules. This phase I project focusses on seamless integration of these proven modules (the camera hardware and the diagnostic software) via several novel ideas.         PUBLIC HEALTH RELEVANCE: EyeApp, a smartphone-based end-to-end point-of-care diabetic retinopathy diagnostic device, will truly enable diabetic retinopathy screening at massive scale, which is necessary and urgent - since the world diabetic population is estimated to be a staggering 371 million, and is projected to grow to over half a billion by 2030. EyeApp will operate in and end-to-end fashion, from retinal imaging to diagnostic screening, all without needing a trained operator. It will cost orders of magnitude less than conventional retinal cameras, and will simply attach to a smartphone, thus greatly reducing the cost and expanding the availability of screening to vast underserved population in the US and the world.            ",Mobile App for Diabetic Retinopathy Screening using Cellphone Retinal Camera,8782362,R43EY024848,"['Address', 'Adult', 'Age', 'Agreement', 'Algorithms', 'Architecture', 'Area', 'Back', 'Biomedical Engineering', 'Blindness', 'Chairperson', 'Color', 'Computer Vision Systems', 'Computer software', 'Descriptor', 'Detection', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Elements', 'Ensure', 'Equipment', 'Eye', 'Foundations', 'Friends', 'Fundus', 'Goals', 'Gold', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Leadership', 'Lesion', 'Machine Learning', 'Marketing', 'Measures', 'Monitor', 'Nurses', 'Ophthalmology', 'Optics', 'Outcome', 'Output', 'Patients', 'Pattern Recognition', 'Phase', 'Population', 'Process', 'Public Health', 'ROC Curve', 'Recommendation', 'Research', 'Resolution', 'Retinal', 'Retinal Diseases', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Engineering', 'Software Tools', 'Solid', 'Specialist', 'Spouses', 'Staging', 'Surveys', 'System', 'Technology', 'Telephone', 'Testing', 'Time', 'Training', 'Underserved Population', 'Universities', 'Washington', 'Work', 'base', 'clinical care', 'cloud based', 'cluster computing', 'commercialization', 'computerized', 'cost', 'design', 'diabetic', 'diabetic patient', 'experience', 'glucose monitor', 'image processing', 'improved', 'interest', 'longitudinal analysis', 'member', 'mobile application', 'novel', 'point of care', 'prevent', 'professor', 'prototype', 'public health relevance', 'research and development', 'screening', 'statistics', 'success', 'tool']",NEI,"EYENUK, INC.",R43,2014,217002,-0.021715209840432674
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8664845,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,214609,-0.017791644547600474
"Cloud-computer-aided diagnostic imaging decision support system     DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer.          Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                ",Cloud-computer-aided diagnostic imaging decision support system,8657936,R01CA166816,"['Adoption', 'American Cancer Society', 'Bayesian Modeling', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Cloud Computing', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'handheld mobile device', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2014,350219,-0.05384166339727857
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired     DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering.         PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8704450,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'public health relevance', 'rehabilitation engineering', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2014,51689,-0.017004345984384068
"Sign Finding and Reading SFAR on GPU Accelerated Mobile Devices     DESCRIPTION (provided by applicant): The inability to access information on printed signs directly impacts the mobility independence of the over 1.2 million blind persons in the U.S. Many previously proposed technological solutions to this problem either required physical modifications to the environment (talking signs or the placement of coded markers) or required the user to carry around specialized computational equipment, which can be stigmatizing. A recently pursued strategy is to utilize the computational capabilities of smart phones and techniques from computer vision to allow blind persons to read signs at a distance using commercially available, non-stigmatizing, smart- phones. However, despite the fact that sophisticated algorithms exist to recognize and extract sign text from cluttered video input (as evidenced, for example, by mapping services such as Google Maps automatically locating and blurring out only license plate text in street-view maps) current mobile solutions for reading sign text at a distance perform relatively poorly. This poor performance is largely because until recently, smart-phone processors have simply not been able to execute state-of-the-art computer vision text extraction and recognition algorithms at real-time rates, which forced previous mobile sign readers to utilize older, simplistic, less effective algorithms. Next-generation smart-phones run on fundamentally different, hybrid processor architectures (such as the Tegra 4, Snapdragon 800, both released in 2013) with dedicated embedded graphical processing units (GPUs) and multi-core CPUs, which make them ideal for high-performance, vision-heavy computation. In this study, we propose to develop a smart-phone-based system for finding and reading signs at a distance which significantly outperforms previous such readers by implementing state-of-the-art text extraction algorithms on modern smart-phone hybrid GPU/CPU processor architectures. In Phase I, the proposed system will be developed and tested with blind users. In Phase II, feedback from user testing will be integrated into system design and the performance will be improved to permit operation in extremely challenging (such as low light) environments.         PUBLIC HEALTH RELEVANCE: Over 1.2 million people in the US are blind, and lack of safe and independent mobility substantially impacts the quality of life of this population. Printed textual signs, which are ubiquitously used in sighted navigation, are inaccessible to visually impaired persons, and this lack of access to environmental information contributes significantly to the mobility problem. This research would help develop a system whereby blind persons could use commercially available smart-phones to locate and read sign text at a distance.            ",Sign Finding and Reading SFAR on GPU Accelerated Mobile Devices,8779810,R43EY024800,"['Acceleration', 'Access to Information', 'Algorithms', 'Antirrhinum', 'Architecture', 'Back', 'Code', 'Computer Vision Systems', 'Distant', 'Environment', 'Equipment', 'Eye', 'Feedback', 'Hybrids', 'Licensing', 'Light', 'Literature', 'Maps', 'Modification', 'Performance', 'Phase', 'Population', 'Printing', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Research Institute', 'Risk', 'Running', 'SKI gene', 'Self-Help Devices', 'Services', 'Solutions', 'System', 'Techniques', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Vision', 'Visually Impaired Persons', 'assistive device/technology', 'authority', 'base', 'blind', 'design', 'experience', 'handheld mobile device', 'improved', 'next generation', 'operation', 'phase 1 study', 'public health relevance', 'volunteer']",NEI,"LYNNTECH, INC.",R43,2014,229742,-0.02965432795108861
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8631080,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2014,250003,-0.0032919402465584704
"Automating Directly Observed Therapy as a Platform Technology     DESCRIPTION (provided by applicant): Introduction: Ai Cure Technologies LLC was established in 2009 to develop automated medication adherence monitoring solutions using computer vision technology. This SBIR Phase II will allow Ai Cure Technologies to test the accuracy and validity of its flagship product, AiView"". The SBIR Phase I demonstrated that the AiView"" platform was technically feasible and capable of confirming medication administration. Significance: Poor medication adherence is a huge burden on clinical research and clinical practice. The inability to accurately measure or improve adherence significantly compounds the problem. Clinical trials depend on people taking the drug being tested. The problem of medication adherence has been addressed - determinants of adherence are being studied and new monitoring methods developed - but no solution has been able to accurately confirm real-time medication adherence while also being affordable, flexible, and likable. The Product: Ai Cure Technologies will provide an automated DOT (Directly Observed Therapy) software platform, AiView"", for use in clinical trials which uses sophisticated computer vision technology on webcam- enabled smart phones or tablets to visually confirm medication administration. AiView"" will visually track and confirm medication administration without human supervision. Long-Term Goal: The AiView"" system will combine sophisticated computer vision technology with the best attributes of DOT for 1/400th of the cost. Automating and standardizing the way medication adherence is captured will help clinical trials better define their subjects' rates of compliance and allow them to intervene immediately in case of non-compliance. Phase II hypothesis: AiView"" can be used to accurately measure and improve medication adherence across different patient populations, and positively impact self-perception and clinical outcomes. Specific Aim #1: To demonstrate that the AiView"" system can accurately measure and improve medication adherence in a depression and a stroke patient population. Specific Aim #2: To demonstrate that the AiView"" system can improve self-perception and improve clinical outcomes in the AiView"" intervention groups Expected Outcome: The patients in the AiView"" intervention groups (depression and stroke) are expected to have statistically significant higher adherence rates than those in the pill counting groups.         PUBLIC HEALTH RELEVANCE: Poor medication adherence is a huge burden on clinical research and clinical practice with the inability to accurately measure or improve adherence significantly compounding the problem. In accordance with this SBIR Phase II grant, Ai Cure Technologies will continue development and testing of its Automated DOTSM (Directly Observed Therapy) software platform, AiView"", for use in clinical trials which uses sophisticated computer vision technology on webcam-enabled smart phones or tablets to visually confirm medication administration. Automating and standardizing the way medication adherence is captured will help clinical trials better define their subjects' rates of compliance and allow tria administrators to intervene immediately in case of non-compliance, thus improving the accuracy of clinical trials the overall safety of the drug development process.            ",Automating Directly Observed Therapy as a Platform Technology,8670794,R44TR000873,"['Address', 'Adherence', 'Administrator', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communication', 'Computer Vision Systems', 'Computer software', 'Control Groups', 'Controlled Environment', 'Data', 'Data Quality', 'Development', 'Directly Observed Therapy', 'Disease Management', 'Drug Prescriptions', 'Electronics', 'Ensure', 'Event', 'Goals', 'Grant', 'Health', 'Health Insurance Portability and Accountability Act', 'Human', 'Intervention', 'Libraries', 'Marketing', 'Measures', 'Mental Depression', 'Methods', 'Monitor', 'Oral cavity', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phase III Clinical Trials', 'Phase IV Clinical Trials', 'Population', 'Process', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Risk', 'Running', 'Safety', 'Secure', 'Self Perception', 'Small Business Innovation Research Grant', 'Solutions', 'Speed', 'Stroke', 'Supervision', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Time', 'Travel', 'base', 'clinical application', 'clinical practice', 'commercial application', 'compliance behavior', 'cost', 'design', 'drug development', 'flexibility', 'group intervention', 'improved', 'medication compliance', 'meetings', 'non-compliance', 'patient population', 'pill', 'public health relevance', 'tool', 'usability']",NCATS,"AI CURE TECHNOLOGIES, LLC",R44,2014,888295,-0.014487511785556828
"HHSN261201400054C; TOPIC 308 AUTOMATED COLLECTION, STORAGE, ANALYSIS, AND REPORTING SYSTEMS FOR DIETARY IMAGES 'TITLE: THE MOBILE FOOD INTAKE PHOTO STORAGE & ANALYSIS SYSTEM. PERFORMANCE PERIOD 09/16/ This proposal describes enhancements to Viocare’s Mobile Food Intake Visual and Voice Recognizer (FIVR)  System, a novel combination of innovative technologies including computer vision and speech recognition to  measure dietary intake using a mobile phone. FIVR uses a mobile phone’s camera to capture a short video  of foods to be consumed, which is then verbally-annotated on the mobile phone by the user. These video  and audio files are processed through a real-time backend server speech and image recognition engine for  food recognition and portion size measurement. This project will extend FIVR’s capabilities to analyze more  foods, enhance the analysis and reporting tools, expand system support tools, and develop interfaces to a  diverse set of clinical and research systems. A final evaluation of the FIVR system will be conducted at The  Ohio State University to assess the usability and accuracy of food intake tracking with a group of 100 freeliving  subjects, comparing 4 days of FIVR food intake data to 4 days of 24 hour recalls collected using  ASA24 data. The resulting FIVR product will be a unique food intake tracker that combines selfadministration,  automation (vision), and backend coding to collect food intake records to generate a detailed  nutritional analysis. n/a","HHSN261201400054C; TOPIC 308 AUTOMATED COLLECTION, STORAGE, ANALYSIS, AND REPORTING SYSTEMS FOR DIETARY IMAGES 'TITLE: THE MOBILE FOOD INTAKE PHOTO STORAGE & ANALYSIS SYSTEM. PERFORMANCE PERIOD 09/16/",8947304,61201400054C,"['Architecture', 'Automation', 'Car Phone', 'Clinical Research', 'Code', 'Collection', 'Computer Vision Systems', 'Computerized Medical Record', 'Data', 'Databases', 'Diet', 'Dietary intake', 'Eating', 'Evaluation', 'Food', 'Health', 'Hour', 'Image', 'Individual', 'Location', 'Measurement', 'Measures', 'Methods', 'Nutritional', 'Ohio', 'Output', 'Patients', 'Performance', 'Procedures', 'Process', 'Records', 'Reporting', 'Research Personnel', 'Speech', 'Support System', 'System', 'Systems Analysis', 'Time', 'Universities', 'Vision', 'Visual', 'Voice', 'innovative technologies', 'mobile application', 'novel', 'speech recognition', 'tool', 'usability']",NCI,"VIOCARE, INC.",N44,2014,1000000,-0.050759521537956244
"Providing Access to Appliance Displays for Visually Impaired Users     DESCRIPTION (provided by applicant):  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays.  This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment.  No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents.  Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image.  For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast.  These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view.  Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users.  Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures.  The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software.         PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.",Providing Access to Appliance Displays for Visually Impaired Users,8712492,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype', 'public health relevance']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2014,368560,-0.0013180693053153614
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus     DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community.         PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.            ",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8761698,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'prognostic', 'public health relevance', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2014,314327,0.008571007325155543
"Low-Cost, Compact, and Portable Robot for Autonomous Intravenous Access using Nea     DESCRIPTION (provided by applicant): Peripheral venous access is pivotal to a wide range of clinical interventions and is consequently the leading cause of medical injury in the U.S. Complications associated with the procedure are exacerbated in difficult settings, where the rate of success depends heavily on the patient's physiology and the practitioner's experience. My dissertation thesis pertains to the development of imaging and robotic technologies to improve the accuracy and speed of blood draws and IV's. The core technology is an image-guided robotic device that accurately and autonomously introduces a cannula for venous access. The device operates by mapping in real-time the 3D structure of peripheral veins in order to robotically direct a needle into a selected vein. A working prototype has been developed and validated in several studies, the results of which are described in two journal publications. The device combines a 3D near-infrared vein imager, a robot, and computer vision software; these three components form the basis of the three Specific Aims described in this proposal. The Aims fit into the overall dissertation by 1) incorporating the current imaging hardware into a standalone, handheld imaging device; 2) introducing software for the imaging device that assists in selecting suitable cannulation sites; and 3) integrating the imaging device and software with a miniaturized version of the current robot. The outcome of this work will be a compact and low-cost system that is suited for beta-stage development.          PUBLIC HEALTH RELEVANCE: Blood draws and IV therapies are one of the most commonly performed medical routines in hospitals and clinics. Injuries to doctors and patients happen frequently because of how difficult it can be to find veins and accurately insert the needle. We are developing a portable and lightweight medical robot to perform the procedure in situations where the doctor is unable to successfully access the veins. This device may greatly improve the safety and accuracy of venous access, and has wide applications in many clinical areas.            ","Low-Cost, Compact, and Portable Robot for Autonomous Intravenous Access using Nea",8718641,F31EB018191,"['Algorithms', 'Anatomy', 'Area', 'Benchmarking', 'Blood', 'Cannulas', 'Cannulations', 'Catheters', 'Childhood', 'Clinical', 'Clinics and Hospitals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cues', 'Custom', 'Development', 'Device Safety', 'Devices', 'Emergency Care', 'Evaluation', 'Failure', 'Goals', 'Graph', 'Healthcare Systems', 'Human', 'Image', 'Imaging Device', 'In Vitro', 'Injury', 'Institutional Review Boards', 'Intervention', 'Intravenous', 'Journals', 'Knowledge', 'Literature', 'Location', 'Maps', 'Medical', 'Motivation', 'Needles', 'Neonatal', 'Outcome', 'Patients', 'Peripheral', 'Physiology', 'Pilot Projects', 'Population', 'Population Sizes', 'Positioning Attribute', 'Procedures', 'Publications', 'Reporting', 'Robot', 'Robotics', 'Safety', 'Site', 'Speed', 'Sprague-Dawley Rats', 'Staging', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Veins', 'Venous', 'Visual', 'Weight', 'Work', 'arm', 'base', 'cost', 'design', 'experience', 'improved', 'in vivo', 'meetings', 'miniaturize', 'pre-clinical', 'prototype', 'public health relevance', 'robotic device', 'skeletal', 'success', 'three dimensional structure', 'three-dimensional modeling', 'tissue phantom', 'visual motor']",NIBIB,"RUTGERS, THE STATE UNIV OF N.J.",F31,2014,34424,0.0013583452864512821
"In-field FAST Procedure Support and Automation     DESCRIPTION (provided by applicant): The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound examination performed to identify intra-peritoneal hemorrhage or pericardial tamponade. FAST involves the detection of free fluid in ultrasound images from four specific abdominal areas. Unstable patients with positive FAST results are operated on, and stable patients with negative results tend to be observed.  We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life-saving FAST procedures. The proposed system will consist of a low-cost ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an intuitive application. Using that system, a novice operator will be visually guided to acquire ultrasound images from the abdominal locations and quantify the free fluid in those images.  The target for our initial deployment of the system is level 3 and 4 trauma centers. These centers must often serve areas spanning hundreds and even thousands of miles; however, they are typically under-staffed and under-equipped.  The proposal is being clinically driven by Jeffrey Lowell, MD. He is a USNR Trauma Surgeon, and he was recently deployed to Landstuhl Regional Medical Center, the only Level I Trauma Center outside the U.S.         PUBLIC HEALTH RELEVANCE: The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound-based examination for rapidly detecting blood in the abdomen, particularly after blunt abdominal trauma, which is common, for example, with car accidents. The challenge is that the FAST procedure requires expertise and equipment which is not commonly available at level 3 and 4 trauma centers that serve rural populations. We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life- saving FAST procedures. The proposed system will consist of a low-cost, hand-held ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an easy-to-follow software application.            ",In-field FAST Procedure Support and Automation,8652454,R43EB016621,"['Abdomen', 'Abdominal Injuries', 'Accidents', 'Address', 'Age', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Blood', 'Businesses', 'Caring', 'Cause of Death', 'Cessation of life', 'Computer Vision Systems', 'Computer software', 'Conduct Clinical Trials', 'Custom', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Doctor of Medicine', 'Environment', 'Equipment', 'Evaluation', 'FDA approved', 'Funding', 'Hand', 'Hemoperitoneum', 'Hemorrhage', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imagery', 'Injury', 'Kidney', 'Life', 'Liquid substance', 'Location', 'Medical', 'Medical center', 'Methods', 'Military Personnel', 'Morbidity - disease rate', 'Nurses', 'Operating Rooms', 'Organ Harvestings', 'Organ Procurements', 'Patients', 'Pediatric Hospitals', 'Pelvis', 'Pericardial body location', 'Persons', 'Phase', 'Physical Examination', 'Physics', 'Population', 'Positioning Attribute', 'Procedures', 'Publishing', 'Research', 'Running', 'Rural', 'Rural Population', 'Surgeon', 'System', 'Systems Integration', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Time', 'Training', 'Transplant Surgeon', 'Trauma', 'Ultrasonography', 'Uncompensated Care', 'Universities', 'Washington', 'Work', 'base', 'cost', 'emergency service responder', 'experience', 'follower of religion Jewish', 'health disparity', 'imaging Segmentation', 'innovation', 'medical schools', 'mortality', 'novel', 'pericardial sac', 'prototype', 'public health relevance', 'tool', 'trauma centers']",NIBIB,"KITWARE, INC.",R43,2014,195709,0.004191351586061924
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.        PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.               ",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,8628880,R01NS066340,"['Algebraic Geometry', 'Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Geometry', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2014,494546,-0.023542021021174715
"Computational Analysis of Microtubule Dynamics for Personalized Cancer Therapy DESCRIPTION (provided by applicant): Optimized optics and feedback-controlled microscope hardware permit efficient acquisition of large, high- quality image datasets. Computer-based analyses deliver fast processing of high volume of image data which manually cannot be accomplished. The most exciting contribution that computer vision systems can make to translational cancer research, however, is to give access to image-based information that is inaccessible by eye. Computer vision programs can be directly coupled to mathematical models that describe the relation between hidden, invisible processes and measurable image events. Changes in the behavior of hidden processes are thus detectable as changes in the image. This study envisages the use of such algorithms to obtain statistically representative results for the differential effects of each of the three FDA-approved taxanes on the microtubule cytoskeleton in prostate cancer (PC) cell lines. My previous work in basic research has demonstrated the ability of computer-based analysis of the microtubule (MT) cytoskeleton to distinguish between weak disease phenotypes and establish links to MT dynamics in renal cell carcinoma. Therefore, the proposed translational research project can impact clinical decision-making by equipping physicians for the first time with a computer-aided tool allowing the design of an effective personalized MT-targeting chemotherapy of metastatic PC patients. Metastatic PC is treated primarily by means of taxane-based chemotherapy with one of the three FDA- approved taxanes (paclitaxel, docetaxel and cabazitaxel). However, currently there is no way of selecting the taxane for chemotherapy based on the particular pattern of dynamic behavior of the MT cytoskeleton in individual patients. In addition, recent data have indicated that AR binds MTs in order to traffic to the nucleus and that there are several clinically relevant AR splice variants i metastatic PC patients. To date, there is no information available on the potential effects of wild type or variant AR on MT dynamics and consequently no information on differential metastatic PC cell response to taxane treatment as a function of cellular AR content. Based on preliminary research, we hypothesize that there are inherent differences in tumor MT dynamics among individual PC patients, and that the presence of AR variants affects specific parameters of MT polymerization dynamics. If correct, this hypothesis has very significant implications for PC treatment. Because different microtubule-targeting drugs (even from within the same class like the taxanes) affect distinct parameters of MT dynamics, it is conceivable that we can match each drug with an individual tumor-specific ""MT-dynamics signature"" for maximum therapeutic efficacy. PUBLIC HEALTH RELEVANCE: We envision that a systematic characterization of microtubule dynamics and their response to taxanes will allow chemotherapy customization and prolong survival of castrate-resistant prostate cancer patient. The proposed study has the potential to impact clinical decision-making by equipping physicians with a computer- aided tool allowing the design of an effective personalized medical treatment. In addition, it will bring insight into the mechanisms of inherent and acquired resistance to microtubule-targeting drugs.",Computational Analysis of Microtubule Dynamics for Personalized Cancer Therapy,8868262,F32CA177104,"['Affect', 'Algorithms', 'Androgen Receptor', 'Basic Science', 'Behavior', 'Binding', 'Biological Markers', 'Biology', 'Cancer Etiology', 'Cancer Patient', 'Cell Nucleus', 'Cell physiology', 'Cessation of life', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Computers', 'Coupled', 'Cytoskeleton', 'Data', 'Data Set', 'Dependency', 'Diagnosis', 'Disease', 'Drug Targeting', 'Dynein ATPase', 'Event', 'Eye', 'FDA approved', 'Feedback', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Health', 'Homeostasis', 'Image', 'Image Analysis', 'In Vitro', 'Individual', 'Label', 'Link', 'Malignant neoplasm of prostate', 'Measurable', 'Measures', 'Medical', 'Metastatic Prostate Cancer', 'Microscope', 'Microtubule Polymerization', 'Microtubule Stabilization', 'Microtubules', 'Modeling', 'Motor', 'Nuclear', 'Optics', 'Outcome', 'PC3 cell line', 'Paclitaxel', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Polymers', 'Process', 'Property', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Renal Cell Carcinoma', 'Research', 'Research Project Grants', 'Resistance', 'Scheme', 'Second Primary Neoplasms', 'Taxane Compound', 'Testing', 'Therapeutic', 'Time', 'Transcriptional Regulation', 'Translational Research', 'Treatment Efficacy', 'Tubulin', 'Variant', 'Work', 'anticancer research', 'base', 'behavior test', 'cancer cell', 'cancer therapy', 'cellular targeting', 'chemotherapy', 'clinical decision-making', 'clinically relevant', 'design', 'disease phenotype', 'docetaxel', 'in vivo', 'inhibitor/antagonist', 'insight', 'male', 'mathematical model', 'novel', 'programs', 'prostate cancer cell', 'receptor binding', 'response', 'taxane', 'tool', 'trafficking', 'transcription factor', 'transcriptome sequencing', 'tumor']",NCI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2014,47033,-0.05675449351260568
"Computational Analysis of Microtubule Dynamics for Personalized Cancer Therapy     DESCRIPTION (provided by applicant): Optimized optics and feedback-controlled microscope hardware permit efficient acquisition of large, high- quality image datasets. Computer-based analyses deliver fast processing of high volume of image data which manually cannot be accomplished. The most exciting contribution that computer vision systems can make to translational cancer research, however, is to give access to image-based information that is inaccessible by eye. Computer vision programs can be directly coupled to mathematical models that describe the relation between hidden, invisible processes and measurable image events. Changes in the behavior of hidden processes are thus detectable as changes in the image. This study envisages the use of such algorithms to obtain statistically representative results for the differential effects of each of the three FDA-approved taxanes on the microtubule cytoskeleton in prostate cancer (PC) cell lines. My previous work in basic research has demonstrated the ability of computer-based analysis of the microtubule (MT) cytoskeleton to distinguish between weak disease phenotypes and establish links to MT dynamics in renal cell carcinoma. Therefore, the proposed translational research project can impact clinical decision-making by equipping physicians for the first time with a computer-aided tool allowing the design of an effective personalized MT-targeting chemotherapy of metastatic PC patients. Metastatic PC is treated primarily by means of taxane-based chemotherapy with one of the three FDA- approved taxanes (paclitaxel, docetaxel and cabazitaxel). However, currently there is no way of selecting the taxane for chemotherapy based on the particular pattern of dynamic behavior of the MT cytoskeleton in individual patients. In addition, recent data have indicated that AR binds MTs in order to traffic to the nucleus and that there are several clinically relevant AR splice variants i metastatic PC patients. To date, there is no information available on the potential effects of wild type or variant AR on MT dynamics and consequently no information on differential metastatic PC cell response to taxane treatment as a function of cellular AR content. Based on preliminary research, we hypothesize that there are inherent differences in tumor MT dynamics among individual PC patients, and that the presence of AR variants affects specific parameters of MT polymerization dynamics. If correct, this hypothesis has very significant implications for PC treatment. Because different microtubule-targeting drugs (even from within the same class like the taxanes) affect distinct parameters of MT dynamics, it is conceivable that we can match each drug with an individual tumor-specific ""MT-dynamics signature"" for maximum therapeutic efficacy.         PUBLIC HEALTH RELEVANCE: We envision that a systematic characterization of microtubule dynamics and their response to taxanes will allow chemotherapy customization and prolong survival of castrate-resistant prostate cancer patient. The proposed study has the potential to impact clinical decision-making by equipping physicians with a computer- aided tool allowing the design of an effective personalized medical treatment. In addition, it will bring insight into the mechanisms of inherent and acquired resistance to microtubule-targeting drugs.            ",Computational Analysis of Microtubule Dynamics for Personalized Cancer Therapy,8656952,F32CA177104,"['Affect', 'Algorithms', 'Androgen Receptor', 'Basic Science', 'Behavior', 'Binding', 'Biological Markers', 'Biology', 'Cancer Etiology', 'Cancer Patient', 'Cell Nucleus', 'Cell physiology', 'Cessation of life', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Computers', 'Coupled', 'Cytoskeleton', 'Data', 'Data Set', 'Dependency', 'Diagnosis', 'Disease', 'Drug Targeting', 'Dynein ATPase', 'Event', 'Eye', 'FDA approved', 'Feedback', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Homeostasis', 'Image', 'Image Analysis', 'In Vitro', 'Individual', 'Label', 'Link', 'Malignant neoplasm of prostate', 'Measurable', 'Measures', 'Medical', 'Metastatic Prostate Cancer', 'Microscope', 'Microtubule Polymerization', 'Microtubule Stabilization', 'Microtubules', 'Modeling', 'Motor', 'Nuclear', 'Optics', 'Outcome', 'PC3 cell line', 'Paclitaxel', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Polymers', 'Process', 'Property', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Renal Cell Carcinoma', 'Research', 'Research Project Grants', 'Resistance', 'Scheme', 'Second Primary Neoplasms', 'Taxane Compound', 'Testing', 'Therapeutic', 'Time', 'Transcriptional Regulation', 'Translational Research', 'Treatment Efficacy', 'Tubulin', 'Variant', 'Work', 'anticancer research', 'base', 'behavior test', 'cancer cell', 'cancer therapy', 'cellular targeting', 'chemotherapy', 'clinical decision-making', 'clinically relevant', 'design', 'disease phenotype', 'docetaxel', 'in vivo', 'inhibitor/antagonist', 'insight', 'male', 'mathematical model', 'novel', 'programs', 'prostate cancer cell', 'public health relevance', 'receptor binding', 'response', 'taxane', 'tool', 'trafficking', 'transcription factor', 'transcriptome sequencing', 'tumor']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,F32,2014,9945,-0.05675449351260568
"Predicting and Detecting Glaucomatous Progression Using Pattern Recognition    DESCRIPTION (provided by applicant): This project aims to improve glaucoma management by applying novel pattern recognition techniques to improve the accurate prediction and detection of glaucomatous progression. The premise is that complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and that advanced pattern recognition techniques can find and use that hidden information. The primary goals involve the use of mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1800 glaucomatous and healthy eyes, available as the result of long-term NIH funding. With the interdisciplinary team of glaucoma and pattern recognition experts we have assembled, with our extensive NIH-supported database of eyes, and with the knowledge we have acquired in the optimal use of pattern recognition methods from previous NIH support, we believe the proposed work can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs.        The proposed project will develop and demonstrate the usefulness of pattern recognition techniques for predicting and detecting patterns of glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neurodegeneration within the visual pathways at structural and functional levels. The development/use of novel, empirical techniques for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.            ",Predicting and Detecting Glaucomatous Progression Using Pattern Recognition,8601076,R01EY022039,"['Address', 'Algorithm Design', 'California', 'Caring', 'Clinic', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Databases', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Image', 'Imaging Device', 'Informatics', 'Knowledge', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Noise', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Perimetry', 'Physiologic Intraocular Pressure', 'Physiological', 'Provider', 'Scanning', 'Science', 'Series', 'Signal Transduction', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Translational Research', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'clinical care', 'cost', 'heuristics', 'improved', 'independent component analysis', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'retinal nerve fiber layer', 'skills']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2014,379750,-0.016529535501047837
"In vivo Characterization of Stents using Intravascular OCT Imaging     DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel.         PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,8724992,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Simulate', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thrombosis', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'public health relevance', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2014,402534,-0.01280152991897046
"Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance     DESCRIPTION (provided by applicant): The neuromuscular disorders include a wide group of conditions ranging from relatively mild focal problems, such as carpal tunnel syndrome, to severe, generalized diseases, such as amyotrophic lateral sclerosis (ALS). Current methods for evaluating these disorders remain limited to a variety of tests and procedures that are either invasive or remarkably qualitative in nature. One newer technique, electrical impedance myography (EIM), offers the prospect of obtaining quantitative data on muscle condition painlessly and non-invasively. However, no commercial devices specifically tailored for EIM use exist, with nearly all previous EIM work relying upon off-the-shelf bioimpedance devices designed for ""whole-body"" rather than single-muscle assessment. In Phase 1 of this SBIR, Convergence Medical Devices, Inc (CMD) developed an initial prototype system to test proof-of-principle innovative concepts in circuit design and data acquisition to provide highly sensitive and accurate data at an extended frequency range (out to 10 MHz) and over multiple angles relative to the major muscle fiber direction. This work was followed by supplemental work that produced the first hand-held device with robust electronics capable of similar measurements with a detachable, interchangeable electrode array. In this 3-year Phase 2 SBIR, CMD proposes to further refine that technology so as to assist in disease diagnosis and for following disease progression, with a specific focus on amyotrophic lateral sclerosis. In Aim 1 of the proposed grant, testing of multiple electrode array designs will be performed on a group of normal subjects and those with ALS to determine which electrode array designs offer the greatest reproducibility and ability to discriminate healthy from diseased individuals. In Aim 2, the device and the 3 ""best"" array designs identified in Aim 1 will be tested in 30 ALS patients, 30 patients with syndromes mimicking ALS (e.g., polyradiculopathy and motor-predominant neuropathy), and 30 subjects with suspected/possible ALS to determine the single best array design for diagnosis and to determine its sensitivity and specificity. This study will take place at CMD and four external sites and will be managed by the Northeast ALS trials Consortium (NEALS), the premier organization for overseeing clinical trials in ALS. In Aim 3, the 30 suspected/possible ALS patients recruited in SA2 and 30 additional suspected/possible ALS patients will be assessed monthly using EIM and the 3 arrays identified in SA1. All subjects will also undergo standard measurements of disease progression including handheld dynamometry, ALS Functional Rating Scale, and spirometry. The best array design for assessing disease progression will be identified and compared to conventional markers of disease progression to determine EIM's sensitivity to disease status. Thus, at the conclusion of this research program, we anticipate having developed and vigorously tested an EIM device and associated electrode designs that together will serve as a powerful new diagnostic and monitoring tool for neuromuscular disease.          The neuromuscular disorders are a group of conditions that impact the lives of millions of people in the United States alone. In this study, Convergence Medical Devices, in collaboration with neurologists at several medical centers, will develop and test a new device based on the concept of electrical impedance myography, a technique that offers the promise of rapid and accurate disease assessment. With the completion of this study, a new, painless tool will be developed and studied that will assist in individual patient care and will speed drug testing in clinical trials in diseases ranging from amyotrophic lateral sclerosis and muscular dystrophy to radiculopathy and polyneuropathy.            ",Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance,8650344,R44NS070385,"['Amyotrophic Lateral Sclerosis', 'Area', 'Biological Markers', 'Biopsy', 'Businesses', 'Carpal Tunnel Syndrome', 'Clinical', 'Clinical Trials', 'Collaborations', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Electrodes', 'Electromyography', 'Electronics', 'Entrapment Neuropathies', 'Frequencies', 'Future', 'Genetic', 'Goals', 'Grant', 'Individual', 'Limb structure', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Measures', 'Medical Device', 'Medical center', 'Methods', 'Monitor', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Fibers', 'Muscular Dystrophies', 'Myography', 'Nature', 'Needles', 'Neurologist', 'Neuromuscular Diseases', 'Neuropathy', 'Outcome', 'Painless', 'Patient Care', 'Patients', 'Phase', 'Physicians', 'Polyneuropathy', 'Polyradiculopathy', 'Procedures', 'Radiculopathy', 'Recruitment Activity', 'Relative (related person)', 'Reproducibility', 'Research', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Spirometry', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Clinical Trial', 'Time', 'United States', 'Widespread Disease', 'Work', 'base', 'clinical care', 'commercial application', 'data acquisition', 'design', 'diagnosis design', 'disease diagnosis', 'drug testing', 'electric impedance', 'improved', 'indexing', 'innovation', 'muscle strength', 'muscular structure', 'neuromuscular', 'novel diagnostics', 'programs', 'prototype', 'pulmonary function', 'tool', 'validation studies']",NINDS,"MYOLEX, INC.",R44,2014,536206,-0.004667343823219171
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization     DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care.         PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.            ",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8601692,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy', 'Biopsy Specimen', 'Breast', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'public health relevance', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,623127,-0.0153089236203433
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography  Project Summary/Abstract  Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induced stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quan- titative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational im- age analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentiallly between rest and stress - that will identify my- ocardial tissue at-risk after dobutamine-induced stress. This work will involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to hu- mans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.            ",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,8614454,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Frequencies', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Radio', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'novel', 'novel strategies', 'public health relevance', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2014,819740,-0.005803162011551421
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma ABSTRACT  This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Comptutational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans. PROJECT NARRATIVE  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,8786916,R00EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'mathematical sciences', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'symposium', 'time use']",NEI,UNIVERSITY OF MEMPHIS,R00,2014,248999,-0.023610168687745306
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through  multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,8618418,K99AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,GEORGIA INSTITUTE OF TECHNOLOGY,K99,2014,90000,-0.020638281682895318
"Detecting biochemical changes in the pregnant mouse cervix by Raman spectroscopy     DESCRIPTION (provided by applicant): Our understanding of cervical remodeling during pregnancy and labor is incomplete, partly due to the lack of in vivo studies on the biochemical changes that occur in the cervix over the course of pregnancy. Elucidation of the mechanisms for cervical ripening could be used to predict the onset of preterm labor. Until recently, in vivo research methods were too invasive to be used as discovery tools, particularly in women who present with preterm labor. This proposal will use in vivo Raman spectroscopy, an optical technique that is sensitive to collagen content, collagen structure, hydration, lipids, proteins, ad other biomolecules to non-invasively investigate the biochemistry of the cervix throughout pregnancy. Using fiber optic in vivo Raman spectroscopy, we recently found significant differences in Raman spectra in at least four important peaks during the course of pregnancy in mice, including discrete signatures for lipids, collagen, amide bonds, and enriched amino acids (proline, tyrosine). Computational analysis of these spectra yielded predictive algorithms with 94% classification accuracy for stage of pregnancy. Studies performed in 2-hour windows at the end of pregnancy identified spectra predictive for the timing of parturition. This approach provides a detailed real-time biomolecular map of cervical ripening that is currently unavailable by other means. In this proposal, we hypothesize that the different mechanisms of premature cervical ripening have unique Raman spectral signatures that correspond to underlying biochemical and mechanical changes that precede preterm birth, which can be detected in vivo. Two Specific Aims are proposed: 1) Determine spectral changes in the cervix of mice with normal and abnormal pregnancy and parturition; 2) Identify specific mediators of cervical remodeling by comparing Raman spectra to mechanical and biochemical changes in the ex vivo cervix during normal and abnormal parturition. Raman spectroscopy has primarily been used for detection of disease. Collaboration between our reproductive biology and bioengineering groups will capitalize on our expertise in Raman analysis of cervical tissues to study dynamic changes in cervix composition during pregnancy. Key elements in cervical biochemistry will be identified. In vivo Raman spectroscopy will be combined with biomechanical studies and imaging mass spectrometry, a powerful tool for in situ proteomic analysis, to examine mice with premature or delayed cervical remodeling. Together, these highly innovative approaches will generate in-depth profiles of cervical biology that will translate into novel non-invasive methods to detect impending premature birth in women.         PUBLIC HEALTH RELEVANCE: This proposal will use Raman Spectroscopy, a non-invasive, optical scattering technique, to investigate the composition of the cervix throughout pregnancy and provide detailed real-time information on cervical ripening. These studies will identify spectral differences in the cervix during normal and abnormal cervical maturation; optical and biochemical markers will be identified to help monitor pregnancy non-invasively, as the fiber optic probe only requires brief contact with the external surface of the cervix to obtain measurements. Elucidating the mechanisms that initiate cervical ripening will provide a critical step for early detection and treatment of preterm birth, which is the leading cause of infant morbidity and mortality.            ",Detecting biochemical changes in the pregnant mouse cervix by Raman spectroscopy,8766404,R01HD081121,"['Address', 'Algorithms', 'Alprostadil', 'Amides', 'Amino Acids', 'Applications Grants', 'Biochemical', 'Biochemical Markers', 'Biochemistry', 'Biological', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biomechanics', 'Biomedical Engineering', 'Birth', 'Cervical', 'Cervical Ripening', 'Cervix Uteri', 'Classification', 'Clinical', 'Collaborations', 'Collagen', 'Computational algorithm', 'Computer Analysis', 'Data', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Emerging Technologies', 'Etiology', 'Fetal Development', 'Fiber Optics', 'Foundations', 'Generations', 'Goals', 'Health', 'High-Risk Pregnancy', 'Hormonal', 'Hour', 'Hydration status', 'Image', 'Immunohistochemistry', 'In Situ', 'In Situ Hybridization', 'Indium', 'Interdisciplinary Study', 'Laboratories', 'Lead', 'Link', 'Lipids', 'Machine Learning', 'Maintenance', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mechanics', 'Mediator of activation protein', 'Medical', 'Methods', 'Mifepristone', 'Modality', 'Molecular', 'Molecular Profiling', 'Monitor', 'Mus', 'Optics', 'Phenotype', 'Physiological', 'Pregnancy', 'Premature Birth', 'Premature Labor', 'Prevention', 'Process', 'Proline', 'Property', 'Proteins', 'Proteomics', 'RU-486', 'Raman Spectrum Analysis', 'Reproductive Biology', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Spectrum Analysis', 'Staging', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Tyrosine', 'Woman', 'base', 'clinical application', 'in vivo', 'infant morbidity/mortality', 'innovation', 'insight', 'mouse model', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'physical science', 'predictive modeling', 'pregnant', 'premature', 'public health relevance', 'response', 'tool']",NICHD,VANDERBILT UNIVERSITY,R01,2014,387356,-0.018641968652398668
"Detection of Glaucoma Progression with Macular OCT Imaging     DESCRIPTION (provided by applicant): This application is a formal request for a career development award (K23) for an academic glaucoma specialist with a serious interest in the role of imaging in glaucoma using optical coherence tomography (OCT). This will allow the candidate to establish a clinical research program with the main goal of improving detection of glaucoma progression through macular imaging with spectral-domain OCT. By the time the proposed research is accomplished, the candidate will have preliminary data for continuing his research as an independent investigator and will have collected longitudinal structural and functional data in a group of advanced glaucoma patients that will serve as a platform for further improving detection of glaucoma progression with macular OCT imaging. The data will help the candidate provide preliminary results for a subsequent R01 that would potentially allow the PI to continue follow-up of the patients enrolled in the K23 award period.  I have a Master's of Science degree in Clinical Investigation under my belt and intend to deepen my skills in the field of imaging and biostatistics (to be used for enhancing and handling OCT images and for analyzing longitudinal data) by completing the proposed didactic program. By the end of the award period, I expect that I will have gained additional experience, knowledge, and mentorship required to prosper as an independent clinician-scientist in the field of glaucoma. My long-term goal is to carry out longitudinal studies of glaucoma patients where current and upcoming imaging and functional tests can be applied and their utility for detection of glaucoma progression can be investigated. I am confident that the combined skills and experience of my mentors will lead to a successful outcome for the proposed K award. I also envisage myself mentoring candidates like myself in future so that our collective knowledge and wisdom can be passed along to the next generation of aspiring clinician-scientists.  My objectives during the award period are as follows: 1) To develop an individual research program in glaucoma diagnostic imaging; 2) to successfully complete credited coursework in biomathematics, advanced biostatistics, computer vision (image processing), epidemiology, and ethical issues in research.  The main goal of the research component of this proposal is to better delineate the role of macular SD- OCT imaging for detection of glaucoma progression in advanced glaucoma. The specific aims through which this goal will be accomplished are as follows:  (1) To compare the performance of various global and regional macular measures to detect glaucoma.  The potential factors influencing the performance of various macular outcome measures will be explored. Such covariates include age, race, axial length, disc size, central corneal thickness,  OCT signal strength, and outer retinal thickness among others. I hypothesize that the thickness  of the outer retina (outer nuclear layer to retinal pigment epithelium-Bruch's membrane  complex) may be the most important factor explaining the measurement variability of the inner  retinal layer thickness (GCC or ganglion cell/inner plexiform layers).  (2) To determine and compare the utility of the candidate macular measures, detected through the first  aim, for detection of glaucoma progression in moderately advanced to severe glaucoma.  Moderately advanced to severe glaucoma will be defined as eyes with visual field mean  deviation worse than -6 dB or eyes with involvement of the central 10 degrees on the 24-2  visual field. It is widely accepted that measurement of the optic nerve head or RNFL parameters  in advanced glaucoma does not provide clinicians with much useful information. In contrast, the  central macular ganglion cells are the last to die in glaucoma. Macular imaging in advanced  glaucoma is directed towards this area where detection of change may still be possible. I  hypothesize that macular OCT parameters are valid structural outcome measures (biomarkers)  that can be used to follow the course of the disease in advanced glaucoma and that such  measures are significantly correlated with changes in the central visual field. Changes in the  macular measures over time will be first correlated with the corresponding visual field change  (functional progression) over time in eyes with moderately advanced to severe glaucoma. The  utility of the best candidate macular measures for predicting subsequent glaucoma progression  will also be explored and compared. I hypothesize that there may be a lag period between  progressive loss of macular ganglion cells and subsequent visual field progression in advanced  glaucoma, and therefore, detection of worsening in one or more macular outcome measures  can be used as a proxy for subsequent visual field progression.  Collectively, these studies will provide a solid foundation for better understanding and integration of macular OCT imaging in the care of glaucoma patients. Timely detection of glaucoma progression in the later stages can significantly reduce visual disability and blindness through earlier aggressive treatment and will potentially reduce glaucoma's financial burden to society.          Detection of glaucoma progression remains a challenging task in eyes demonstrating significant damage. Even small amounts of progression in advanced glaucoma can have important consequences with regard to patient's visual function and quality of life. The results of the proposed study will potentially lead to more effective and earlier detection of glaucoma progression and will allow ophthalmologists to step up treatment in a timely manner. This will in turn result in less visual morbidity and reduced blindness from glaucoma, which is projected to cause more than 10 million cases of legal blindness around the world in 2020.            ",Detection of Glaucoma Progression with Macular OCT Imaging,8675256,K23EY022659,"['Age', 'Area', 'Award', 'Biological Markers', 'Biometry', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Caring', 'Clinical Research', 'Clinical Trials', 'Complement', 'Complex', 'Computer Vision Systems', 'Cornea', 'Data', 'Detection', 'Diagnosis', 'Diagnostic Imaging', 'Disease', 'Early Diagnosis', 'Enrollment', 'Epidemiology', 'Ethical Issues', 'Evaluation', 'Eye', 'Foundations', 'Functional Imaging', 'Future', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inner Plexiform Layer', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal Blindness', 'Length', 'Longitudinal Studies', 'Master of Science', 'Measurement', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Morbidity - disease rate', 'Nerve Fibers', 'Noise', 'Ophthalmologist', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Outcome Measure', 'Patients', 'Performance', 'Process', 'Proxy', 'Quality of life', 'Race', 'Research', 'Research Personnel', 'Retinal', 'Role', 'Scientist', 'Signal Transduction', 'Societies', 'Solid', 'Specialist', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Thick', 'Time', 'Vision', 'Visual', 'Visual Fields', 'advanced disease', 'biomathematics', 'central visual field', 'disability', 'experience', 'follow-up', 'ganglion cell', 'image processing', 'improved', 'interest', 'macula', 'next generation', 'programs', 'retina outer nuclear layer', 'retinal nerve fiber layer', 'skills']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,K23,2014,229139,-0.046552258895507174
"Context Understanding Technology to improve internet accessibility for users with DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a  web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization. PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.",Context Understanding Technology to improve internet accessibility for users with,8609036,R44EY020082,"['Advertisements', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Grouping', 'Health', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2014,357073,0.005817824137930364
"Improving Accuracy and Accessibility of Early Autism Screening     DESCRIPTION (provided by applicant): Autism is prevalent (1 in 50 children) and impairing but early intervention has been shown to improve outcomes prompting recommendations for screening at both two year and 18 month health check-ups. Detection of autism early is crucial but accurate screening tools have been elusive. In Phase II, a practical method of improving accuracy of M-CHAT, the most widely used autism screen, was created by adapting the validated and recommended follow up interview, M-CHAT F/Ui (F/U), for efficient use during the visit. In the case of a positive screen, the primary care provider (PCP) can use CHADIS, a web-based questionnaire delivery, decision support and post-visit engagement system, to conduct F/U rather than requiring a visit with another professional. Phase II data showed F/U results by a PCP were equivalent to the autism center. Phase-II data on the M-CHAT plus F/U via CHADIS replicated findings of the F/U authors in showing both excellent positive predictive value (PPV) 0.96 for children >20 months (thus effective for 24 month olds) and also low PPV 0.54 for <20 months. Promisingly, Phase II exploratory analyses using a decision tree including supplementary data from a routinely used standard language screen (ASQ communication scale) and an item from a language measure (MCDI) plus the standard autism screen (M-CHAT plus F/U) reached PPV of 0.95 in the <20 month group. This screen completion could be done efficiently online by parents. Phase IIB plans a replication of this screening procedure which promises to be accurate for 18 month olds and comparison to alternatives using the community network of >400 Maryland doctors where >22,000 autism screens have been done using the CHADIS system. A more accurate screening test is of less value if it is not universally used. In Phase II, an approach was developed that reduces disparities in access to screening using a ""talking"" tablet kiosk that was preferred by parents to alternatives, but further workflow issues will be addressed in Phase IIB. To improve screen completion, we will program an automated reminder/completion confirmation text/email system in CHADIS with coupons as incentives for parents. In Phase II, CHADIS was adapted to capture both patient input and doctor decision-making and Maintenance of Certification (MOC) accreditation was awarded by the American Board of Pediatrics for this program and earned by 140 pediatricians. This monthly doctor quality improvement program will be extended to a daily continuous quality improvement process for the whole office team to further assure patient participation in screening while providing other clinical and financial analytics of value to the office. The Phase-IIB goal is to develop and test an innovative ""screening system"" not just a new test.          PUBLIC HEALTH RELEVANCE: Autism is prevalent (1 in 50 children) and impairing but early intervention has been shown to improve outcomes prompting recommendations for screening at both two year and 18 month health check-ups. In Phase I, a standard screening procedure was adapted so that doctors could efficiently identify autistic children at two years of age but the screen did not prove accurate at 18 months. Phase II data showed that a novel method combining supplemental information and a new computerized scoring pathway promised accurate detection at the critical 18 month age. This Phase 2B proposal is aimed at replicating this unique approach to early autism identification in a community sample, comparing it with alternatives plus developing innovative strategies to assure that all children are screened by automating reminders and completion confirmation and by supporting continuous quality improvement in office implementation using automated reporting analytics.            ",Improving Accuracy and Accessibility of Early Autism Screening,8714587,R44MH085399,"['Academy', 'Accreditation', 'Address', 'Age-Months', 'Age-Years', 'Algorithms', 'American', 'Autistic Disorder', 'Award', 'Certification', 'Child', 'Child Care', 'Child health care', 'Clinical', 'Communication', 'Communities', 'Community Networks', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Decision Making', 'Decision Trees', 'Detection', 'Development', 'Diagnostic tests', 'Early Diagnosis', 'Early Intervention', 'Electronic Mail', 'Evaluation', 'Evidence based intervention', 'Family', 'Feedback', 'Goals', 'Health', 'Improve Access', 'Incentives', 'Interview', 'Language', 'Lead', 'Licensing', 'Maintenance', 'Maryland', 'Measures', 'Methods', 'Motivation', 'Online Systems', 'Outcome', 'Parents', 'Pathway interactions', 'Patient Participation', 'Patients', 'Pediatrics', 'Phase', 'Predictive Value', 'Primary Health Care', 'Procedures', 'Process', 'Provider', 'Public Health', 'Questionnaires', 'Recommendation', 'Reminder Systems', 'Reporting', 'Research', 'Running', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Symptoms', 'System', 'Tablets', 'Testing', 'Text', 'Toddler', 'Training', 'Visit', 'autistic children', 'base', 'checkup examination', 'computerized', 'follow-up', 'improved', 'indexing', 'innovation', 'meetings', 'novel', 'pediatrician', 'programs', 'public health priorities', 'public health relevance', 'screening', 'tool']",NIMH,"TOTAL CHILD HEALTH, INC.",R44,2014,796039,-0.041479816597200375
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8737899,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,335356,0.0005736579585363054
"Computational Image Analysis for Cellular and Developmental Biology     DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. !         PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.             ",Computational Image Analysis for Cellular and Developmental Biology,8414506,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'public health relevance', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2013,59383,0.0002179212586463577
"Smart Anatomic Recognition System to Guide Emergency Intubation and Resuscitation     DESCRIPTION (provided by applicant): Over 3 million emergency intubations are performed in the US every year and failure rates can be as high as 50% (3-5). Success is highly dependent on how frequently the responder performs this life-saving procedure on humans (6). Brio Device, LLC, an airway management medical device company, is addressing the need to decouple the success of the procedure from the experience of the user with their ""smart"" intubation device which integrates anatomic structure recognition algorithms and visual guidance feedback with an articulating stylet. Brio's intubation device is specifically designed fo the needs of emergency responders, such as paramedics, emergency department personnel, code teams in hospitals and military medics, who often arrive at the patient first. The smart intubation device will reduce failure rates by providing the user with visual instruction of the correct path to the trachea as he places the endotracheal tube. The guidance software uses machine learning and computer vision algorithms to recognize the anatomy and determine the path to insert the tube. Ultimately, the intubation device will include both a guidance display on an LCD screen and an optical stylet that has single-axis angulation control of the distal tip. For the purpose of this Phase I study, a laptop or desktop computer will be used for the image processing and the guidance display that accompanies the articulating stylet. The long-term goal is to create a device that is compact, light-weight and portable to suit the needs of ambulances and hospital crash carts.  The hypothesis for this study is that by incorporating a video guidance display with an articulating stylet, inexperienced users will be more successful in correctly placing the endotracheal tube using this device compared to direct laryngoscopy. To achieve this goal, image processing and machine learning algorithms will be developed to recognize key anatomic structures in the airway. Software will also be developed determine the path the tube should follow and to display this information for the user. Finally, the efficacy of the device will be validated in airway simulation mannequins with medical students serving as the inexperienced users. Phase II will focus on integrating the guidance software, articulating optical stylet and display into a portable device with embedded hardware and software contained within the stylet handle. At completion of Phase II, the device will be ready for clinica trials and FDA testing.  Brio will enter the $20 billion airway market with its intubation device. Initial sales will begin with anesthesiologists who are early adopters of new technology to assist with difficult airways. Brio will market its product to ~327,000 clinicians who use intubation devices. The U.S. addressable market for emergency intubation is ~$900M for the 41,000 ambulances and 5,800 emergency departments and hospital code teams.         PUBLIC HEALTH RELEVANCE: In this SBIR Phase I, Brio Device, LLC plans to create and evaluate a device that improves the success rate of emergency intubations by coupling a smart guidance display with a user-controlled single-axis articulating stylet. Emergency intubations are often performed in challenging situations by personnel who do the procedure infrequently. Since failure rates are as high as 50% and approximately 180,000 deaths occur each year from failed pre-hospital intubations, a device is needed to provide visual guidance information to assist the users and increase their success rates in emergency situations.            ",Smart Anatomic Recognition System to Guide Emergency Intubation and Resuscitation,8453607,R43HL114160,"['Accident and Emergency department', 'Address', 'Algorithms', 'Ambulances', 'Anatomic structures', 'Anatomy', 'Brain Death', 'Brain Injuries', 'Cessation of life', 'Clinical Trials', 'Code', 'Computer Vision Systems', 'Computer software', 'Computers', 'Coupling', 'Critical Care', 'Destinations', 'Devices', 'Distal', 'Emergency Situation', 'Failure', 'Feasibility Studies', 'Feedback', 'Goals', 'Hospitals', 'Human', 'Human Resources', 'Image', 'Imagery', 'Instruction', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Laryngoscopy', 'Left', 'Life', 'Light', 'Location', 'Lung', 'Machine Learning', 'Manikins', 'Marketing', 'Medical Device', 'Medical Students', 'Military Hospitals', 'Military Personnel', 'Optics', 'Outcome', 'Outcome Measure', 'Oxygen', 'Paramedical Personnel', 'Patients', 'Phase', 'Physicians', 'Procedures', 'Resuscitation', 'Sales', 'Small Business Innovation Research Grant', 'Structure', 'System', 'Testing', 'Time', 'Trachea', 'Tube', 'Visual', 'commercial application', 'design', 'endotracheal', 'experience', 'flexibility', 'image processing', 'improved', 'information display', 'laptop', 'light weight', 'new technology', 'novel', 'phase 1 study', 'public health relevance', 'secondary outcome', 'simulation', 'success']",NHLBI,"BRIO DEVICE, LLC",R43,2013,244710,0.002073121057918432
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8522756,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2013,150000,-0.004378159456758402
"Automated retinopathy of prematurity classification using machine learning  Project Summary/Abstract The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH- funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi- disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing. PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.                 ",Automated retinopathy of prematurity classification using machine learning,8445584,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2013,283543,-0.010891495706105323
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.         PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8466969,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'public health relevance', 'screening', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2013,1,0.023049682923936173
"Automated Facial Expression Analysis for Research and Clinical Use     DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use.          The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.            ",Automated Facial Expression Analysis for Research and Clinical Use,8464280,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2013,497842,-0.008017016733972005
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8402395,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,301051,-0.0018136090362642293
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8522304,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2013,216041,-0.003500920867051101
"A Software Platform for Sensor-based Movement Disorder Recognition     DESCRIPTION (provided by applicant): The overall objective of this SBIR project is to develop a pre-commercial prototype system capable of continuously monitoring involuntary movement disorders from a wide spectrum of neurological conditions. The impact of this innovation will enhance the availability of advanced brain and behavior research tools [PA- 11-134] by providing a continuous means of tracking the presence and severity of movement disorders during normal daily activities. This project will transform our unique movement disorder recognition algorithms into custom software that analyzes movement disorders for specific neurological conditions. The information obtained from body worn sensors will provide an accurate and objective means for assessing the complex and changeable nature of movement disorders. This goal cannot by realized using the current method of self-report questionnaires.  The research strategy for Phase I will establish the merit and feasibility of this effort by developing an Application Generation (AG) software platform using a framework of configurable signal processing modules to generate custom applications for movement disorder analysis (Aim 1). This approach reduces the effort and enhances the flexibility of designing and testing software solutions for these applications. The AG Platform will be developed using C++ software to implement signal processing and machine-learning software modules that operate within a knowledge-based framework that we have previously developed. In Aim 2 we will utilize the AG platform to generate movement disorder analysis software to evaluate a challenging test-case application: freezing-of-gait in Parkinson's disease (PD). The goal is to attain performance metrics for freezing that are comparable to those we have achieved for tremor and dyskinesia in previous efforts.  Phase II will refine the capabilities of the AG platform developed in Phase I. We will augment it with the means to automatically design and train the machine learning algorithms, improve the user-interface, and provide options for viewing and summarizing the results. The improved AG platform will be used to develop customized disorder-analysis software that encompasses the full complement of movement disorders associated with PD (e.g. dystonia, bradykinesia, Parkinsonian gait, tremor, dyskinesia), as well as for other neurological condition, such as Essential Tremor (ET). Firmware will be developed for each custom application to efficiently integrate the analytic software with our existing Trigno wireless sensor data acquisition hardware, which needs to be streamlined for this application. This combined system will be evaluated under research use-case scenarios in Neurology. Phase II will deliver an ambulatory Movement Disorder Monitoring system that not only succeeds in providing state-of-the-art monitoring solutions for PD and Essential Tremor, but has proven technology to develop monitoring solutions for a wide variety of neurological conditions. Future development will transfer this technology to a clinical version of this system.         PUBLIC HEALTH RELEVANCE: The project is intended to improve the accuracy and reduce the burden of researchers and clinicians when assessing motor outcomes for patients with involuntary movement disorders. The proposed technology will provide a means for evaluating new treatment options, and expedite the delivery of care. The attainment of these goals should increase the effectiveness of research, the time required for these research advancements to reach the consumer, and help control the rising costs of clinical care among the estimated 45 million Americans who have neurological disorders resulting in involuntary movements. The resulting improvements in motor function will ultimately lead to greater independence and productivity for this growing segment of the population.            ",A Software Platform for Sensor-based Movement Disorder Recognition,8521782,R43NS083098,"['Affect', 'Algorithms', 'American', 'Bradykinesia', 'Clinical', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Custom', 'Data', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Dystonia', 'Early Diagnosis', 'Essential Tremor', 'Freezing', 'Future', 'Gait', 'Generations', 'Goals', 'Health Care Sector', 'Health Professional', 'Home environment', 'Involuntary Movements', 'Lead', 'Left', 'Lower Extremity', 'Machine Learning', 'Methods', 'Metric', 'Miniaturization', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Neurologic', 'Neurology', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Process', 'Productivity', 'Quality of life', 'Questionnaires', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training', 'Tremor', 'Video Recording', 'Wireless Technology', 'Work', 'Writing', 'advanced system', 'base', 'brain behavior', 'care delivery', 'clinical care', 'computerized data processing', 'cost', 'data acquisition', 'design', 'disorder control', 'effectiveness research', 'flexibility', 'human subject', 'improved', 'innovation', 'knowledge base', 'motor disorder', 'nervous system disorder', 'novel therapeutics', 'prototype', 'public health relevance', 'research study', 'response', 'sensor', 'software development', 'tool']",NINDS,"ALTEC, INC.",R43,2013,424766,-0.02095127407060901
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex. We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning. To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support: First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management. Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices. Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements. These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8479372,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,474880,0.0036101492246836215
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8477880,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2013,339750,-0.013550615368157388
"Cloud-computer-aided diagnostic imaging decision support system     DESCRIPTION (provided by applicant): High-performance cloud computing (HPCC) is an integration of high-performance computing (HPC) with cloud computing that provides an alternative informatics infrastructure to deliver the supercomputer power needed for developing and reading high quality, multidimensional diagnostic images on desktop or mobile devices. Such infrastructure would advance the use of high-throughput cancer screening like virtual colonoscopy (VC), also known as computed tomography colonography (CTC). The goals of this proposal are to develop and validate the clinical benefits of a mobile HPCC-Virtual Colonoscopy decision support system (HPCC-VC) that integrates novel high-performance electronic cleansing and computer-aided detection schemes. The combination of high performance electronic cleansing (hpEC) with high performance computer aided detection (hpCAD) will allow visualization of the entire mucosal surface of the colon without artifact. Specifically, we hypothesize that the mobile HPCC-VC system will improve the quality of electronic cleansing of non-cathartic CTC (ncCTC) images, will deliver images 100 times faster than conventional approaches, and will improve reader performance in the detection of colonic lesions in the images analyzed on mobile high-resolution display devices.  To achieve these goals, an HPCC platform will be established by use of a CPU-cluster-based supercomputing and parallel image processing libraries. Then, an hpEC scheme will be developed that effectively removes the residual fecal materials in ncCTC images. In parallel, a high-resolution hpCAD scheme will be developed to support high-performance detection of colonic lesions in ncCTC. These schemes will be integrated into a mobile HPCC-VC system on the HPCC platform. Necessary preliminary studies in the development of computed EC and CAD schemes show promise; and the development and deployment of the HPCC platform will advance the quality, speed, and utility of high performance, multidimensional imaging for colon cancer screening. A comprehensive reader performance study will be conducted to determine the clinical application and benefit of images analyzed and delivered through an HPCC platform.  Successful development of HPCC-VC will demonstrate the clinical benefit of the platform for improved diagnostic imaging and facilitation of accurate, high-throughput colon cancer screening that is highly acceptable to patients. In the longer term, broad adoption and use of the HPCC-VC system will facilitate early and accurate diagnoses, and thus reduce mortality from colon cancer.          Successful development of the HPCC-VC system will demonstrate the clinical benefit of HPCC platform for diagnostic imaging, and will provide a high-throughput colon cancer screening scheme for colorectal lesions that is highly acceptable to patients and highly accurate. Such a system will promote the early diagnosis of colon cancer, and ultimately reduce the mortality due to colon cancer.                ",Cloud-computer-aided diagnostic imaging decision support system,8494421,R01CA166816,"['Adoption', 'American Cancer Society', 'Belief', 'Caring', 'Cathartics', 'Climate', 'Clinical', 'Collaborations', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Complex', 'Computed Tomographic Colonography', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Decision Support Systems', 'Densitometry', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic Imaging', 'Early Diagnosis', 'Economics', 'Electronics', 'Elements', 'Excision', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Informatics', 'Investments', 'Lesion', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Mucous Membrane', 'Patient Care', 'Patients', 'Performance', 'Persons', 'Physicians', 'Polyps', 'Population', 'Preparation', 'Process', 'Reader', 'Reading', 'Research Infrastructure', 'Residual state', 'Resolution', 'Resources', 'Risk', 'Sampling', 'Scheme', 'Screening for cancer', 'Specialist', 'Speed', 'Supercomputing', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Time Factors', 'United States', 'base', 'clinical application', 'clinical practice', 'colorectal cancer screening', 'computer aided detection', 'design', 'high end computer', 'high throughput screening', 'image processing', 'improved', 'mortality', 'novel', 'processing speed', 'scale up', 'screening', 'supercomputer']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2013,339387,-0.05384166339727857
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    The technology developed as part of this NIH SBIR project will transform the cell phone camera of visually impaired individuals into a powerful tool capable of identifying the objects they encounter, track the items they own, or navigate complex new environments. Broad access to low-cost visual intelligence technologies developed in this project will improve the independence and capabilities of the visually impaired. There has been tremendous technological progress in computer vision and in the computational power and network bandwidth of and Smartphone platforms. The synergy of these advances stands to revolutionize the way people find information and interact with the physical world. However, these technologies are not yet fully in the hands of the visually impaired, arguably the population that could benefit the most from these developments. Part of the barrier to progress in this area has been that computer vision can accurately handle only a small fraction of the typical images coming from a cell phone camera. To cope with these limitations and make any-image recognition possible, IQ Engines will develop a hybrid system that uses both computer vision and crowdsourcing: if the computer algorithms are not able to understand an image, then the image is sent to a unique crowdsourcing network of people for image analysis. The proposed research includes specific aims to both develop advanced computer vision algorithms for object recognition and advanced crowdsourced networks optimized to the needs of the visually impaired community. This approach combines the speed and accuracy of computer vision with the robustness and understanding of human vision, ultimately providing the user fast and accurate information about the content of any image.           The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.            ",Mobile Search for the Visually Impaired,8389864,R44EY019790,"['Address', 'Algorithms', 'Area', 'Car Phone', 'Cellular Phone', 'Classification', 'Client', 'Clip', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Crowding', 'Data', 'Databases', 'Detection', 'Development', 'Devices', 'Ensure', 'Environment', 'Family', 'Feedback', 'Friends', 'Glosso-Sterandryl', 'Human', 'Hybrid Computers', 'Hybrids', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Location', 'Modeling', 'Monitor', 'Phase', 'Population', 'Preparation', 'Process', 'Quality of life', 'Research', 'Running', 'Scanning', 'Services', 'Small Business Innovation Research Grant', 'Social Network', 'Source', 'Speed', 'System', 'Technology', 'Telephone', 'Time', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual impairment', 'base', 'blind', 'cell transformation', 'coping', 'cost', 'improved', 'innovation', 'novel', 'object recognition', 'open source', 'sensor', 'tool', 'visual information', 'visual search', 'volunteer']",NEI,"IQ ENGINES, INC.",R44,2013,499358,-0.03216694771858271
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8599843,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,224942,-0.017791644547600474
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired     DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering.         PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.            ",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8650411,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Healthcare', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'high school', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'public health relevance', 'rehabilitation engineering', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2013,81362,-0.017004345984384068
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8599834,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2013,249999,-0.0032919402465584704
"Automating Directly Observed Therapy as a Platform Technology     DESCRIPTION (provided by applicant): Introduction: Ai Cure Technologies LLC was established in 2009 to develop automated medication adherence monitoring solutions using computer vision technology. This SBIR Phase II will allow Ai Cure Technologies to test the accuracy and validity of its flagship product, AiView"". The SBIR Phase I demonstrated that the AiView"" platform was technically feasible and capable of confirming medication administration. Significance: Poor medication adherence is a huge burden on clinical research and clinical practice. The inability to accurately measure or improve adherence significantly compounds the problem. Clinical trials depend on people taking the drug being tested. The problem of medication adherence has been addressed - determinants of adherence are being studied and new monitoring methods developed - but no solution has been able to accurately confirm real-time medication adherence while also being affordable, flexible, and likable. The Product: Ai Cure Technologies will provide an automated DOT (Directly Observed Therapy) software platform, AiView"", for use in clinical trials which uses sophisticated computer vision technology on webcam- enabled smart phones or tablets to visually confirm medication administration. AiView"" will visually track and confirm medication administration without human supervision. Long-Term Goal: The AiView"" system will combine sophisticated computer vision technology with the best attributes of DOT for 1/400th of the cost. Automating and standardizing the way medication adherence is captured will help clinical trials better define their subjects' rates of compliance and allow them to intervene immediately in case of non-compliance. Phase II hypothesis: AiView"" can be used to accurately measure and improve medication adherence across different patient populations, and positively impact self-perception and clinical outcomes. Specific Aim #1: To demonstrate that the AiView"" system can accurately measure and improve medication adherence in a depression and a stroke patient population. Specific Aim #2: To demonstrate that the AiView"" system can improve self-perception and improve clinical outcomes in the AiView"" intervention groups Expected Outcome: The patients in the AiView"" intervention groups (depression and stroke) are expected to have statistically significant higher adherence rates than those in the pill counting groups.         PUBLIC HEALTH RELEVANCE: Poor medication adherence is a huge burden on clinical research and clinical practice with the inability to accurately measure or improve adherence significantly compounding the problem. In accordance with this SBIR Phase II grant, Ai Cure Technologies will continue development and testing of its Automated DOTSM (Directly Observed Therapy) software platform, AiView"", for use in clinical trials which uses sophisticated computer vision technology on webcam-enabled smart phones or tablets to visually confirm medication administration. Automating and standardizing the way medication adherence is captured will help clinical trials better define their subjects' rates of compliance and allow tria administrators to intervene immediately in case of non-compliance, thus improving the accuracy of clinical trials the overall safety of the drug development process.            ",Automating Directly Observed Therapy as a Platform Technology,8524716,R44TR000873,"['Address', 'Adherence', 'Administrator', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communication', 'Computer Vision Systems', 'Computer software', 'Control Groups', 'Controlled Environment', 'Data', 'Data Quality', 'Development', 'Directly Observed Therapy', 'Disease Management', 'Drug Prescriptions', 'Electronics', 'Ensure', 'Event', 'Goals', 'Grant', 'Health', 'Health Insurance Portability and Accountability Act', 'Human', 'Intervention', 'Libraries', 'Marketing', 'Measures', 'Mental Depression', 'Methods', 'Monitor', 'Oral cavity', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phase III Clinical Trials', 'Phase IV Clinical Trials', 'Population', 'Process', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Risk', 'Running', 'Safety', 'Secure', 'Self Perception', 'Small Business Innovation Research Grant', 'Solutions', 'Speed', 'Stroke', 'Supervision', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Time', 'Travel', 'base', 'clinical application', 'clinical practice', 'commercial application', 'compliance behavior', 'cost', 'design', 'drug development', 'flexibility', 'group intervention', 'improved', 'medication compliance', 'meetings', 'non-compliance', 'patient population', 'pill', 'public health relevance', 'tool', 'usability']",NCATS,"AI CURE TECHNOLOGIES, LLC",R44,2013,895818,-0.014487511785556828
"Providing Access to Appliance Displays for Visually Impaired Users  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays. This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image. For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast. These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view. Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users. Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures. The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.                ",Providing Access to Appliance Displays for Visually Impaired Users,8579051,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype', 'public health relevance']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2013,376082,-0.0016762621706826963
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8541017,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'elastography', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response', 'screening']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2013,328138,-0.02462464663222653
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.        PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.               ",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,8432789,R01NS066340,"['Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2013,480486,-0.023542021021174715
"In-field FAST Procedure Support and Automation     DESCRIPTION (provided by applicant): The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound examination performed to identify intra-peritoneal hemorrhage or pericardial tamponade. FAST involves the detection of free fluid in ultrasound images from four specific abdominal areas. Unstable patients with positive FAST results are operated on, and stable patients with negative results tend to be observed.  We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life-saving FAST procedures. The proposed system will consist of a low-cost ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an intuitive application. Using that system, a novice operator will be visually guided to acquire ultrasound images from the abdominal locations and quantify the free fluid in those images.  The target for our initial deployment of the system is level 3 and 4 trauma centers. These centers must often serve areas spanning hundreds and even thousands of miles; however, they are typically under-staffed and under-equipped.  The proposal is being clinically driven by Jeffrey Lowell, MD. He is a USNR Trauma Surgeon, and he was recently deployed to Landstuhl Regional Medical Center, the only Level I Trauma Center outside the U.S.         PUBLIC HEALTH RELEVANCE: The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound-based examination for rapidly detecting blood in the abdomen, particularly after blunt abdominal trauma, which is common, for example, with car accidents. The challenge is that the FAST procedure requires expertise and equipment which is not commonly available at level 3 and 4 trauma centers that serve rural populations. We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life- saving FAST procedures. The proposed system will consist of a low-cost, hand-held ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an easy-to-follow software application.            ",In-field FAST Procedure Support and Automation,8472102,R43EB016621,"['Abdomen', 'Abdominal Injuries', 'Accidents', 'Address', 'Age', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Blood', 'Businesses', 'Caring', 'Cause of Death', 'Cessation of life', 'Computer Vision Systems', 'Computer software', 'Computers', 'Conduct Clinical Trials', 'Custom', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Doctor of Medicine', 'Environment', 'Equipment', 'Evaluation', 'FDA approved', 'Funding', 'Hand', 'Hemoperitoneum', 'Hemorrhage', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imagery', 'Injury', 'Kidney', 'Life', 'Liquid substance', 'Location', 'Medical', 'Medical center', 'Methods', 'Military Personnel', 'Morbidity - disease rate', 'Nurses', 'Operating Rooms', 'Organ Harvestings', 'Organ Procurements', 'Patients', 'Pediatric Hospitals', 'Pelvis', 'Pericardial body location', 'Persons', 'Phase', 'Physical Examination', 'Physics', 'Population', 'Positioning Attribute', 'Procedures', 'Publishing', 'Research', 'Running', 'Rural', 'Rural Population', 'Surgeon', 'System', 'Systems Integration', 'Tablets', 'Technology', 'Testing', 'Time', 'Training', 'Transplant Surgeon', 'Trauma', 'Ultrasonography', 'Uncompensated Care', 'Universities', 'Washington', 'Work', 'base', 'cost', 'emergency service responder', 'experience', 'follower of religion Jewish', 'health disparity', 'imaging Segmentation', 'innovation', 'medical schools', 'mortality', 'novel', 'pericardial sac', 'prototype', 'public health relevance', 'tool', 'trauma centers']",NIBIB,"KITWARE, INC.",R43,2013,200000,0.004191351586061924
"Computational Analysis of Microtubule Dynamics for Personalized Cancer Therapy     DESCRIPTION (provided by applicant): Optimized optics and feedback-controlled microscope hardware permit efficient acquisition of large, high- quality image datasets. Computer-based analyses deliver fast processing of high volume of image data which manually cannot be accomplished. The most exciting contribution that computer vision systems can make to translational cancer research, however, is to give access to image-based information that is inaccessible by eye. Computer vision programs can be directly coupled to mathematical models that describe the relation between hidden, invisible processes and measurable image events. Changes in the behavior of hidden processes are thus detectable as changes in the image. This study envisages the use of such algorithms to obtain statistically representative results for the differential effects of each of the three FDA-approved taxanes on the microtubule cytoskeleton in prostate cancer (PC) cell lines. My previous work in basic research has demonstrated the ability of computer-based analysis of the microtubule (MT) cytoskeleton to distinguish between weak disease phenotypes and establish links to MT dynamics in renal cell carcinoma. Therefore, the proposed translational research project can impact clinical decision-making by equipping physicians for the first time with a computer-aided tool allowing the design of an effective personalized MT-targeting chemotherapy of metastatic PC patients. Metastatic PC is treated primarily by means of taxane-based chemotherapy with one of the three FDA- approved taxanes (paclitaxel, docetaxel and cabazitaxel). However, currently there is no way of selecting the taxane for chemotherapy based on the particular pattern of dynamic behavior of the MT cytoskeleton in individual patients. In addition, recent data have indicated that AR binds MTs in order to traffic to the nucleus and that there are several clinically relevant AR splice variants i metastatic PC patients. To date, there is no information available on the potential effects of wild type or variant AR on MT dynamics and consequently no information on differential metastatic PC cell response to taxane treatment as a function of cellular AR content. Based on preliminary research, we hypothesize that there are inherent differences in tumor MT dynamics among individual PC patients, and that the presence of AR variants affects specific parameters of MT polymerization dynamics. If correct, this hypothesis has very significant implications for PC treatment. Because different microtubule-targeting drugs (even from within the same class like the taxanes) affect distinct parameters of MT dynamics, it is conceivable that we can match each drug with an individual tumor-specific ""MT-dynamics signature"" for maximum therapeutic efficacy.         PUBLIC HEALTH RELEVANCE: We envision that a systematic characterization of microtubule dynamics and their response to taxanes will allow chemotherapy customization and prolong survival of castrate-resistant prostate cancer patient. The proposed study has the potential to impact clinical decision-making by equipping physicians with a computer- aided tool allowing the design of an effective personalized medical treatment. In addition, it will bring insight into the mechanisms of inherent and acquired resistance to microtubule-targeting drugs.            ",Computational Analysis of Microtubule Dynamics for Personalized Cancer Therapy,8526929,F32CA177104,"['Affect', 'Algorithms', 'Androgen Receptor', 'Basic Science', 'Behavior', 'Binding', 'Biological Markers', 'Biology', 'Cancer Etiology', 'Cancer Patient', 'Cell Nucleus', 'Cell physiology', 'Cessation of life', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Computers', 'Coupled', 'Cytoskeleton', 'Data', 'Data Set', 'Dependency', 'Diagnosis', 'Disease', 'Drug Targeting', 'Dynein ATPase', 'Event', 'Eye', 'FDA approved', 'Feedback', 'Gene Targeting', 'Genes', 'Genetic Transcription', 'Goals', 'Growth', 'Homeostasis', 'Image', 'Image Analysis', 'In Vitro', 'Individual', 'Label', 'Link', 'Malignant neoplasm of prostate', 'Measurable', 'Measures', 'Medical', 'Metastatic Prostate Cancer', 'Microscope', 'Microtubule Polymerization', 'Microtubule Stabilization', 'Microtubules', 'Modeling', 'Motor', 'Nuclear', 'Optics', 'Outcome', 'PC3 cell line', 'Paclitaxel', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Polymers', 'Process', 'Property', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Renal Cell Carcinoma', 'Research', 'Research Project Grants', 'Resistance', 'Scheme', 'Second Primary Neoplasms', 'Taxane Compound', 'Testing', 'Therapeutic', 'Time', 'Transcriptional Regulation', 'Translational Research', 'Treatment Efficacy', 'Tubulin', 'Variant', 'Work', 'anticancer research', 'base', 'behavior test', 'cancer cell', 'cancer therapy', 'cellular targeting', 'chemotherapy', 'clinical decision-making', 'clinically relevant', 'design', 'disease phenotype', 'docetaxel', 'in vivo', 'inhibitor/antagonist', 'insight', 'male', 'mathematical model', 'novel', 'programs', 'prostate cancer cell', 'public health relevance', 'receptor binding', 'response', 'taxane', 'tool', 'trafficking', 'transcription factor', 'transcriptome sequencing', 'tumor']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,F32,2013,53942,-0.05675449351260568
"Predicting and Detecting Glaucomatous Progression Using Pattern Recognition    DESCRIPTION (provided by applicant): This project aims to improve glaucoma management by applying novel pattern recognition techniques to improve the accurate prediction and detection of glaucomatous progression. The premise is that complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and that advanced pattern recognition techniques can find and use that hidden information. The primary goals involve the use of mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1800 glaucomatous and healthy eyes, available as the result of long-term NIH funding. With the interdisciplinary team of glaucoma and pattern recognition experts we have assembled, with our extensive NIH-supported database of eyes, and with the knowledge we have acquired in the optimal use of pattern recognition methods from previous NIH support, we believe the proposed work can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs.        The proposed project will develop and demonstrate the usefulness of pattern recognition techniques for predicting and detecting patterns of glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neurodegeneration within the visual pathways at structural and functional levels. The development/use of novel, empirical techniques for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.            ",Predicting and Detecting Glaucomatous Progression Using Pattern Recognition,8410578,R01EY022039,"['Address', 'Algorithms', 'California', 'Caring', 'Clinic', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Databases', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Image', 'Imaging Device', 'Informatics', 'Knowledge', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Noise', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Perimetry', 'Physiologic Intraocular Pressure', 'Physiological', 'Provider', 'Scanning', 'Science', 'Series', 'Signal Transduction', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Translational Research', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'clinical care', 'cost', 'design', 'heuristics', 'improved', 'independent component analysis', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'retinal nerve fiber layer', 'skills']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,368125,-0.016529535501047837
"In vivo Characterization of Stents using Intravascular OCT Imaging     DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel.         PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.            ",In vivo Characterization of Stents using Intravascular OCT Imaging,8529140,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Goals', 'Graph', 'Healed', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Simulate', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thrombosis', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'public health relevance', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2013,412883,-0.01280152991897046
"Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance     DESCRIPTION (provided by applicant): The neuromuscular disorders include a wide group of conditions ranging from relatively mild focal problems, such as carpal tunnel syndrome, to severe, generalized diseases, such as amyotrophic lateral sclerosis (ALS). Current methods for evaluating these disorders remain limited to a variety of tests and procedures that are either invasive or remarkably qualitative in nature. One newer technique, electrical impedance myography (EIM), offers the prospect of obtaining quantitative data on muscle condition painlessly and non-invasively. However, no commercial devices specifically tailored for EIM use exist, with nearly all previous EIM work relying upon off-the-shelf bioimpedance devices designed for ""whole-body"" rather than single-muscle assessment. In Phase 1 of this SBIR, Convergence Medical Devices, Inc (CMD) developed an initial prototype system to test proof-of-principle innovative concepts in circuit design and data acquisition to provide highly sensitive and accurate data at an extended frequency range (out to 10 MHz) and over multiple angles relative to the major muscle fiber direction. This work was followed by supplemental work that produced the first hand-held device with robust electronics capable of similar measurements with a detachable, interchangeable electrode array. In this 3-year Phase 2 SBIR, CMD proposes to further refine that technology so as to assist in disease diagnosis and for following disease progression, with a specific focus on amyotrophic lateral sclerosis. In Aim 1 of the proposed grant, testing of multiple electrode array designs will be performed on a group of normal subjects and those with ALS to determine which electrode array designs offer the greatest reproducibility and ability to discriminate healthy from diseased individuals. In Aim 2, the device and the 3 ""best"" array designs identified in Aim 1 will be tested in 30 ALS patients, 30 patients with syndromes mimicking ALS (e.g., polyradiculopathy and motor-predominant neuropathy), and 30 subjects with suspected/possible ALS to determine the single best array design for diagnosis and to determine its sensitivity and specificity. This study will take place at CMD and four external sites and will be managed by the Northeast ALS trials Consortium (NEALS), the premier organization for overseeing clinical trials in ALS. In Aim 3, the 30 suspected/possible ALS patients recruited in SA2 and 30 additional suspected/possible ALS patients will be assessed monthly using EIM and the 3 arrays identified in SA1. All subjects will also undergo standard measurements of disease progression including handheld dynamometry, ALS Functional Rating Scale, and spirometry. The best array design for assessing disease progression will be identified and compared to conventional markers of disease progression to determine EIM's sensitivity to disease status. Thus, at the conclusion of this research program, we anticipate having developed and vigorously tested an EIM device and associated electrode designs that together will serve as a powerful new diagnostic and monitoring tool for neuromuscular disease.          The neuromuscular disorders are a group of conditions that impact the lives of millions of people in the United States alone. In this study, Convergence Medical Devices, in collaboration with neurologists at several medical centers, will develop and test a new device based on the concept of electrical impedance myography, a technique that offers the promise of rapid and accurate disease assessment. With the completion of this study, a new, painless tool will be developed and studied that will assist in individual patient care and will speed drug testing in clinical trials in diseases ranging from amyotrophic lateral sclerosis and muscular dystrophy to radiculopathy and polyneuropathy.            ",Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance,8456053,R44NS070385,"['Amyotrophic Lateral Sclerosis', 'Area', 'Biological Markers', 'Biopsy', 'Businesses', 'Carpal Tunnel Syndrome', 'Clinical', 'Clinical Trials', 'Collaborations', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Electrodes', 'Electromyography', 'Electronics', 'Entrapment Neuropathies', 'Frequencies', 'Future', 'Genetic', 'Goals', 'Grant', 'Individual', 'Limb structure', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Measures', 'Medical Device', 'Medical center', 'Methods', 'Monitor', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Fibers', 'Muscular Dystrophies', 'Myography', 'Nature', 'Needles', 'Neurologist', 'Neuromuscular Diseases', 'Neuropathy', 'Outcome', 'Painless', 'Patient Care', 'Patients', 'Phase', 'Physicians', 'Polyneuropathy', 'Polyradiculopathy', 'Procedures', 'Radiculopathy', 'Recruitment Activity', 'Relative (related person)', 'Reproducibility', 'Research', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Spirometry', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Clinical Trial', 'Time', 'United States', 'Widespread Disease', 'Work', 'base', 'clinical care', 'commercial application', 'data acquisition', 'design', 'diagnosis design', 'disease diagnosis', 'drug testing', 'electric impedance', 'improved', 'indexing', 'innovation', 'muscle strength', 'muscular structure', 'neuromuscular', 'novel diagnostics', 'programs', 'prototype', 'pulmonary function', 'tool', 'validation studies']",NINDS,"MYOLEX, INC.",R44,2013,531082,-0.004667343823219171
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization     DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care.         PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.            ",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8420220,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy', 'Biopsy Specimen', 'Breast', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'public health relevance', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,682340,-0.0153089236203433
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.        The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8383103,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2013,222916,-0.009112194000242482
"Detection of Glaucoma Progression with Macular OCT Imaging     DESCRIPTION (provided by applicant): This application is a formal request for a career development award (K23) for an academic glaucoma specialist with a serious interest in the role of imaging in glaucoma using optical coherence tomography (OCT). This will allow the candidate to establish a clinical research program with the main goal of improving detection of glaucoma progression through macular imaging with spectral-domain OCT. By the time the proposed research is accomplished, the candidate will have preliminary data for continuing his research as an independent investigator and will have collected longitudinal structural and functional data in a group of advanced glaucoma patients that will serve as a platform for further improving detection of glaucoma progression with macular OCT imaging. The data will help the candidate provide preliminary results for a subsequent R01 that would potentially allow the PI to continue follow-up of the patients enrolled in the K23 award period.  I have a Master's of Science degree in Clinical Investigation under my belt and intend to deepen my skills in the field of imaging and biostatistics (to be used for enhancing and handling OCT images and for analyzing longitudinal data) by completing the proposed didactic program. By the end of the award period, I expect that I will have gained additional experience, knowledge, and mentorship required to prosper as an independent clinician-scientist in the field of glaucoma. My long-term goal is to carry out longitudinal studies of glaucoma patients where current and upcoming imaging and functional tests can be applied and their utility for detection of glaucoma progression can be investigated. I am confident that the combined skills and experience of my mentors will lead to a successful outcome for the proposed K award. I also envisage myself mentoring candidates like myself in future so that our collective knowledge and wisdom can be passed along to the next generation of aspiring clinician-scientists.  My objectives during the award period are as follows: 1) To develop an individual research program in glaucoma diagnostic imaging; 2) to successfully complete credited coursework in biomathematics, advanced biostatistics, computer vision (image processing), epidemiology, and ethical issues in research.  The main goal of the research component of this proposal is to better delineate the role of macular SD- OCT imaging for detection of glaucoma progression in advanced glaucoma. The specific aims through which this goal will be accomplished are as follows:  (1) To compare the performance of various global and regional macular measures to detect glaucoma.  The potential factors influencing the performance of various macular outcome measures will be explored. Such covariates include age, race, axial length, disc size, central corneal thickness,  OCT signal strength, and outer retinal thickness among others. I hypothesize that the thickness  of the outer retina (outer nuclear layer to retinal pigment epithelium-Bruch's membrane  complex) may be the most important factor explaining the measurement variability of the inner  retinal layer thickness (GCC or ganglion cell/inner plexiform layers).  (2) To determine and compare the utility of the candidate macular measures, detected through the first  aim, for detection of glaucoma progression in moderately advanced to severe glaucoma.  Moderately advanced to severe glaucoma will be defined as eyes with visual field mean  deviation worse than -6 dB or eyes with involvement of the central 10 degrees on the 24-2  visual field. It is widely accepted that measurement of the optic nerve head or RNFL parameters  in advanced glaucoma does not provide clinicians with much useful information. In contrast, the  central macular ganglion cells are the last to die in glaucoma. Macular imaging in advanced  glaucoma is directed towards this area where detection of change may still be possible. I  hypothesize that macular OCT parameters are valid structural outcome measures (biomarkers)  that can be used to follow the course of the disease in advanced glaucoma and that such  measures are significantly correlated with changes in the central visual field. Changes in the  macular measures over time will be first correlated with the corresponding visual field change  (functional progression) over time in eyes with moderately advanced to severe glaucoma. The  utility of the best candidate macular measures for predicting subsequent glaucoma progression  will also be explored and compared. I hypothesize that there may be a lag period between  progressive loss of macular ganglion cells and subsequent visual field progression in advanced  glaucoma, and therefore, detection of worsening in one or more macular outcome measures  can be used as a proxy for subsequent visual field progression.  Collectively, these studies will provide a solid foundation for better understanding and integration of macular OCT imaging in the care of glaucoma patients. Timely detection of glaucoma progression in the later stages can significantly reduce visual disability and blindness through earlier aggressive treatment and will potentially reduce glaucoma's financial burden to society.          Detection of glaucoma progression remains a challenging task in eyes demonstrating significant damage. Even small amounts of progression in advanced glaucoma can have important consequences with regard to patient's visual function and quality of life. The results of the proposed study will potentially lead to more effective and earlier detection of glaucoma progression and will allow ophthalmologists to step up treatment in a timely manner. This will in turn result in less visual morbidity and reduced blindness from glaucoma, which is projected to cause more than 10 million cases of legal blindness around the world in 2020.            ",Detection of Glaucoma Progression with Macular OCT Imaging,8529542,K23EY022659,"['Age', 'Area', 'Award', 'Biological Markers', 'Biometry', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Caring', 'Clinical Research', 'Clinical Trials', 'Complement', 'Complex', 'Computer Vision Systems', 'Cornea', 'Data', 'Detection', 'Diagnosis', 'Diagnostic Imaging', 'Disease', 'Early Diagnosis', 'Enrollment', 'Epidemiology', 'Ethical Issues', 'Evaluation', 'Eye', 'Foundations', 'Functional Imaging', 'Future', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inner Plexiform Layer', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal Blindness', 'Length', 'Longitudinal Studies', 'Master of Science', 'Measurement', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Morbidity - disease rate', 'Nerve Fibers', 'Noise', 'Ophthalmologist', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Outcome Measure', 'Patients', 'Performance', 'Process', 'Proxy', 'Quality of life', 'Race', 'Research', 'Research Personnel', 'Retinal', 'Role', 'Scientist', 'Signal Transduction', 'Societies', 'Solid', 'Specialist', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Thick', 'Time', 'Vision', 'Visual', 'Visual Fields', 'advanced disease', 'biomathematics', 'central visual field', 'disability', 'experience', 'follow-up', 'ganglion cell', 'image processing', 'improved', 'interest', 'macula', 'next generation', 'programs', 'retina outer nuclear layer', 'retinal nerve fiber layer', 'skills']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,K23,2013,229139,-0.046552258895507174
"Context Understanding Technology to improve internet accessibility for users with     DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization.         PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.                ",Context Understanding Technology to improve internet accessibility for users with,8459121,R44EY020082,"['Advertisements', 'Area', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Government', 'Grouping', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Persons', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'public health relevance', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2013,371933,0.005817824137930364
"Advanced training platform and methodologies for emergency responders and skilled     DESCRIPTION (provided by applicant): There is a need to be able to deliver just-in-time training and reference materials for first responders and skilled support personnel. Mobile computing platforms are becoming ubiquitous and provide an ideal means to reach users at any time in any location. The process of translating existing reference materials into mobile-friendly formats is currently manual and very labor intensive. Nicolalde R&D LLC is well under way to commercialize its mTraining mobile technology and service prototyped during a phase I SBIR from NIEHS. The mTraining technology is an objective and checklist-based method for delivering just-in-time training and reference materials, making it an effective Electronic Performance Support System (EPSS) for providing workers easy access to information after training, and on site prior to or during an assignment. It provides short, incident specific awareness and safety training that can be delivered prior to responding to an emergency situation. The proposed development under this phase II SBIR includes: a) a back-end document processing engine that is able to automatically parse, analyze, mark-up, and organize documents so that their content is easily cross-referenced, linked and re-organized for effective delivery on a mobile training platform or other electronic medium. This will be connected to a server and database architecture to facilitate its operation and support storing and accessing content; b) the front-end interface for the mobile training platform (mTraining) was prototyped in Phase I of this project for delivering training content to emergency responders, skilled support personnel, and volunteers before or during an incident. The improved back-end architecture will support intelligent search capabilities for a large repository of training documents with different structures. This capability relies on the document processing engine's ability to semi-automatically extract relevant data and automatically translate this data into a structured format. This data can then be used for display in the mobile application, stored into databases, and automatically populated into ontologies. Throughout this project the participatory-based design paradigm has been used for facilitating the integration of user requirements and the fast prototyping and testing of design alternatives. This approach will continue to be utilized in Phase 2 of the project.         PUBLIC HEALTH RELEVANCE: The proposed research and development will advance the field of environmental health and safety training by bringing to it new and innovative advanced training technologies that are based on the mobile and just-in-time paradigm. Furthermore, the research and development proposed herein will advance the mobile information technology field by developing robust and scalable tools for processing and linking information residing in different source documents that are semantically related.            ",Advanced training platform and methodologies for emergency responders and skilled,8518023,R44ES020135,"['Access to Information', 'Architecture', 'Awareness', 'Back', 'Case Study', 'Data', 'Databases', 'Development', 'Educational Curriculum', 'Educational Materials', 'Electronics', 'Emergency Situation', 'Environmental Health', 'Focus Groups', 'Human Resources', 'Information Technology', 'Link', 'Location', 'Manuals', 'Medical', 'Medical Students', 'Methodology', 'Methods', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Ontology', 'Performance', 'Phase', 'Process', 'Provider', 'Research Infrastructure', 'Retrieval', 'Safety', 'Semantics', 'Services', 'Simulate', 'Site', 'Small Business Innovation Research Grant', 'Source', 'Specific qualifier value', 'Structure', 'Support System', 'Technology', 'Testing', 'Time', 'Time Management', 'Training', 'Training and Education', 'Translating', 'Update', 'base', 'computer based Semantic Analysis', 'design', 'emergency service responder', 'improved', 'innovation', 'interest', 'operation', 'public health relevance', 'repository', 'research and development', 'response', 'tool', 'usability', 'volunteer']",NIEHS,"NICOLALDE R AND D, LLC",R44,2013,142612,-0.012128410591004803
"Spatially Accurate Deformable Image Registration for Thoracic C Applications    DESCRIPTION (Provided by the applicant)   Abstract:  Deformable image registration (DIR) is a cross-cutting technology with diagnostic and therapeutic medical applications. DIR algorithms were first developed in computer vision research to estimate motion between a source and target image, the resulting registered image visually appears similar to the target image. For medical applications the goal in applying DIR is to obtain an accurate spatial registration of the underlying anatomy and not simply image similarity. We developed a statistical framework for quantitative evaluation of DIR spatial accuracy based on large samples of expert-determined landmark features. Central to this framework is the statistical relationship between the number of landmark points required to assess spatial accuracy, the desired uncertainty range of the mean error, and an a priori estimated behavior of the DIR. DIR is at the heart of our strategy to quantify COPD small airway disease air-trapping and four dimensional computed tomography (4D CT) ventilation. The optimal DIR algorithm and its spatial accuracy in registering the underlying anatomy should be assessed for each application. We will develop and test new DIR algorithms for exhale and inhale breath-hold CT (eBH-CT & iBH-CT) images pairs (COPD air trapping evaluation) and for 4D CT images (4D CT ventilation). Current CT image analysis methods for COPD evaluation focus on the separate anatomic evaluation of the eBH-CT & iBH-CT images. They are unable to find air-trapping due to bronchiolitis alone. We propose to evaluate the eBH- & iBH CT image pairs simultaneously using DIR to link the two to identify regions of air-trapping due to both emphysema and bronchiolitis. Next, to continue our development of ventilation imaging derived from 4D CT, we will test the ability of 4D CT ventilation image guidance to reduce pulmonary function loss after radiotherapy in a randomized phase II trial for non-small cell lung cancer patients.    Public Health Relevance:  This study will develop novel image registration methods and their application, with an emphasis on application specific validation. With this technology we will develop and test methods to find air-trapping in chronic obstructive pulmonary disease patients. We will test our novel ventilation imaging method in radiation treatment planning to reduce normal lung injury after treatment for lung cancer.      ",Spatially Accurate Deformable Image Registration for Thoracic C Applications,8558551,DP2OD007044,"['4D Imaging', 'Aftercare', 'Air', 'Algorithms', 'Anatomy', 'Behavior', 'Breathing', 'Bronchiolitis', 'Cancer Patient', 'Chest', 'Chronic Obstructive Airway Disease', 'Computers', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Exhalation', 'Four-dimensional', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Link', 'Malignant neoplasm of lung', 'Medical', 'Methods', 'Motion', 'Non-Small-Cell Lung Carcinoma', 'Patients', 'Phase II Clinical Trials', 'Pulmonary Emphysema', 'Quantitative Evaluations', 'Radiation', 'Radiation therapy', 'Randomized', 'Sampling', 'Source', 'Technology', 'Testing', 'Therapeutic', 'Uncertainty', 'Validation', 'Vision research', 'X-Ray Computed Tomography', 'abstracting', 'base', 'image registration', 'imaging modality', 'lung injury', 'novel', 'public health relevance', 'pulmonary function', 'small airways disease', 'treatment planning']",OD,UNIVERSITY OF TX MD ANDERSON CAN CTR,DP2,2013,201518,-0.053793360438626495
"Multimodal image registration by proxy image synthesis No abstract available PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8614480,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,343798,0.0010928567278562886
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.        PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.              Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8266132,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2012,199915,0.020839788661293386
"Automated Facial Expression Analysis for Research and Clinical Use     DESCRIPTION (provided by applicant): Facial expression has been a focus of emotion research for over a hundred years. In recent decades observations of facial expressions have yielded critical and dramatic insights about the etiology of psychopathology, and have proven capable of predicting treatment outcomes (see Ekman & Rosenberg, 2005). Despite these original striking findings, there has been surprisingly little follow-up work. The primary reason fr the lack of sustained research is that the most reliable manual systems for measuring facial expression often require considerable training and are labor intensive. Automated measurement using computer vision and machine learning seeks to address the need for valid, efficient, and reproducible measurement. Recent systems have shown promise in fairly small studies using posed behavior or structured contexts with confederates, or trained interviewers, or pre-trained (person-specific) face models. For automated coding to be applied in real-world settings, a large data base with ample variability in pose, head motion, skin color, gender, partial occlusion, and expression intensity is needed. We have developed a unique database that meets this need and the algorithms necessary to enable robust automated coding. The database consists of 720 participants in three-person groups engaged in a group formation task. In a preliminary study, we demonstrated that our algorithms can successfully code two key facial signals associated with human emotion in this relatively unconstrained context (Cohn & Sayette, 2010). To achieve efficient, accurate, and valid measurement of facial expression usable in research and clinical settings, we aim to 1) train and validate classifiers to achieve reliable facial expression detectin across this unprecedentedly large, diverse data set; 2) extend the previous person-specific methods to person-independent (generic) facial feature detection, tracking, and alignment; and 3) make these tools available for research and clinical use.        PUBLIC HEALTH RELEVANCE: The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.              The project has two target application domains. For behavioral science, automated facial expression analysis will provide researchers with powerful tools to examine basic questions in emotion and interpersonal processes, as well as emotion processes underlying diverse forms of psychopathology and neurologic disorder. For clinical use, automated facial expression analysis will help clinicians to assess vulnerability and protective factors and objectively evaluate course of treatment across a wide range of disorders including major depression, bipolar disorder, schizophrenia, anxiety, addiction, suicide risk, and pain.            ",Automated Facial Expression Analysis for Research and Clinical Use,8270831,R01MH096951,"['Address', 'Algorithms', 'Anxiety', 'Behavior', 'Behavioral Sciences', 'Benchmarking', 'Bipolar Disorder', 'Clinical', 'Code', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Emotions', 'Employee Strikes', 'Environment', 'Etiology', 'Face', 'Facial Expression', 'Gender', 'Generic Drugs', 'Head', 'Hour', 'Human', 'Imagery', 'Instruction', 'Interview', 'Interviewer', 'Label', 'Laboratories', 'Learning', 'Lighting', 'Machine Learning', 'Major Depressive Disorder', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Nature', 'Pain', 'Participant', 'Personal Computers', 'Persons', 'Process', 'Psychopathology', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Schizophrenia', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Treatment outcome', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'clinical practice', 'follow-up', 'insight', 'meetings', 'nervous system disorder', 'positive emotional state', 'skin color', 'suicidal risk', 'tool']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2012,621438,-0.02748683568011099
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8323502,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2012,234509,-0.003500920867051101
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Public Health Relevance/Narrative Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8208036,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,311786,-0.001305526477177173
"Developing an online educational curriculum to enhance parent-supervised driving     DESCRIPTION (provided by applicant): Motor vehicle crashes are the leading cause of death and injury for teens, accounting annually for over 3000 deaths, 100 times as many injuries, and over 14 billion dollars in associated costs. The CDC has identified traffic crashes and associated injuries as a top public health priority. Inexperience is the leading cause of crashes among novice teen drivers, but accumulating the necessary experiences to become a safe driver can take many years. Fortunately, evidence from driving and other domains suggests that it is possible to increase experiential knowledge through scenario-based training. Current methods for providing teens with practice focus on parent-supervised driving. However, parents are ill-prepared to handle this role, with many focusing only on the mechanics of driving, laws and general safety advice. Few parents discuss decision-making aspects of driving and may even pass on inaccurate information. Many parents limit the range of driving situations teens are exposed to mistakenly believing that this increases safety rather than dangerously limiting teens' ability to accumulate important driving experience. Our long-term objective is to design and validate an innovative tool that aims to accelerate the acquisition of critical safety knowledge for teen drivers. We propose to extend our team's past work by developing scenarios appropriate for parents to use to mentor their inexperienced teen drivers. The scenarios will be part of an online educational curriculum designed to help parents provide teens with guided practice as they learn how to drive. The online tool will combine scenario- based training with innovative applications of machine learning technology to evaluate scenario responses and provide tailored feedback containing practical, developmentally appropriate strategies for improving safety as well as recommendations for parent-supervised on-the-road practice. Phase I will address these specific aims: 1) Conduct foundational research to identify realistic scenarios commonly encountered by novice teen drivers through semi-structured interviews with teen drivers aged 15-18. 2) Collect representative responses to scenarios from teens with different levels of driving experience and adults to identify the progression of knowledge and identify developmentally appropriate strategies to use as feedback. 3) Create machine learning algorithms to provide tailored feedback and recommend on-the-road driving experiences based on responses to the scenarios. 4) Develop prototype online system. Phase II will focus on additional specific aims: 5) Develop the Phase I proof of concept into a complete online curriculum with refined algorithms. 6) Evaluate the online curriculum for usability, acceptance via focus groups, and effectiveness via a driving simulator experiment and limited field trial with novice teen drivers. The proposed product represents a significant shift in trainig approaches for teen drivers and through Phase III dissemination it will fill a critical need for evidence- based parent-taught driver's education.        PUBLIC HEALTH RELEVANCE: Motor vehicle crashes are the leading cause of death and injury for teens, accounting annually for over 3000 deaths, 100 times as many injuries, and over 14 billion dollars in associated costs; despite this, many teens' primary source of driver's education is their parents. In Phase I we propose to extend our past work for teaching experiential knowledge and develop a prototype online educational curriculum that allows parents to provide teens with guided practice by utilizing innovative machine learning technologies, while Phase II will allow us to complete the prototype and evaluate its effectiveness. The proposed application represents a significant shift in training approaches that has the potential, through Phase III dissemination, to improve teen driving safety.              Motor vehicle crashes are the leading cause of death and injury for teens, accounting annually for over 3000 deaths, 100 times as many injuries, and over 14 billion dollars in associated costs; despite this, many teens' primary source of driver's education is their parents. In Phase I we propose to extend our past work for teaching experiential knowledge and develop a prototype online educational curriculum that allows parents to provide teens with guided practice by utilizing innovative machine learning technologies, while Phase II will allow us to complete the prototype and evaluate its effectiveness. The proposed application represents a significant shift in training approaches that has the potential, through Phase III dissemination, to improve teen driving safety.            ",Developing an online educational curriculum to enhance parent-supervised driving,8392844,R41HD074300,"['Accounting', 'Address', 'Adult', 'Agreement', 'Algorithms', 'Automobile Driving', 'Behavioral', 'Cause of Death', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Collection', 'Decision Making', 'Development', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Focus Groups', 'Human', 'Injury', 'Interview', 'Knowledge', 'Laws', 'Lead', 'Learning', 'Licensing', 'Machine Learning', 'Mechanics', 'Mentors', 'Methods', 'Motor Vehicles', 'Online Systems', 'Parents', 'Performance', 'Phase', 'Preparation', 'Recommendation', 'Research', 'Risk', 'Role', 'Safety', 'Sampling', 'Semantics', 'Site', 'Source', 'Staging', 'Structure', 'Surveys', 'System', 'Teaching Method', 'Techniques', 'Technology', 'Teenagers', 'Time', 'Training', 'Vehicle crash', 'Work', 'aged', 'base', 'cost', 'design', 'evidence base', 'experience', 'improved', 'innovation', 'instrument', 'prospective', 'prototype', 'public health priorities', 'research and development', 'research study', 'response', 'success', 'teen driving', 'tool', 'trafficking', 'usability', 'web page']",NICHD,"PARALLEL CONSULTING, LLC",R41,2012,116895,-0.03980683072091272
"Automated image-based biomarker computation tools for diabetic retinopathy    DESCRIPTION (provided by applicant): In this STTR project, we present EyeMark, a set of tools for automated computation of biomarkers for diabetic retinopathy using retinal image photographs. Specifically, we will develop tools for computation of microaneurysm (MA) appearance and disappearance rates (jointly known as turnover rates) for use as a biomarker in monitoring progression of diabetic retinopathy (DR). The availability of a reliable image-based biomarker will have high positive influence on various aspects of DR care, including screening, monitoring progression, drug discovery and clinical research. There is ample published evidence that MA turnover rates are a good predictor of likelihood of progression to more severe retinopathy, establishing MA turnover as an excellent biomarker for diabetic retinopathy. Measuring this quantity involves two steps: careful alignment of current and baseline images, and marking of individual MAs. This process is very time consuming and prone to error, if done by entirely by human graders. The primary goal of this project is to overcome the above limitations by automating both the steps involved in MA turnover measurement: accurate image registration, and MA detection. We will develop end-too-end desktop software for automated computation of MA turnover and also provide intuitive visualization tools for clinicians to more effectively monitor diabetic retinopathy progression.      PUBLIC HEALTH RELEVANCE: The proposed tool will greatly enhance the clinical care available to diabetic retinopathy patients by providing an automated tool for computation of a biomarker in a non-invasive manner. This will enable identification of patients who are more likely to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.              The proposed tool will greatly enhance the clinical care available to diabetic retinopathy patients by providing an automated tool for computation of a biomarker in a non-invasive manner. This will enable identification of patients who are more likely to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.            ",Automated image-based biomarker computation tools for diabetic retinopathy,8252674,R41TR000377,"['Address', 'Adoption', 'Algorithms', 'Appearance', 'Area', 'Biological', 'Biological Markers', 'Blindness', 'California', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Color', 'Computer Vision Systems', 'Computer software', 'Consultations', 'County', 'Descriptor', 'Detection', 'Development', 'Diabetic Retinopathy', 'Early identification', 'Eye', 'Face', 'Fundus', 'Future', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Joints', 'Lesion', 'Longitudinal Studies', 'Los Angeles', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Measures', 'Medical center', 'Methods', 'Microaneurysm', 'Monitor', 'Ophthalmic examination and evaluation', 'Optic Disk', 'Optometry', 'Patients', 'Pattern Recognition', 'Phase', 'Process', 'Publishing', 'Reading', 'Research', 'Retinal', 'Retinal Diseases', 'Screening procedure', 'Small Business Technology Transfer Research', 'Software Engineering', 'Software Tools', 'Time', 'Universities', 'Vision', 'Visit', 'base', 'clinical application', 'clinical care', 'clinical practice', 'clinically significant', 'cohort', 'design', 'diabetic patient', 'drug discovery', 'experience', 'image processing', 'image registration', 'macular edema', 'member', 'prevent', 'professor', 'success', 'tool', 'user-friendly']",NCATS,"EYENUK, INC.",R41,2012,260857,-0.005803781345454788
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8274831,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,503268,0.004336341815614957
"Objective imaging-based assessment of smoking behavior from used filters    DESCRIPTION (provided by applicant): Accurate measurement of smoking behaviors and exposures may become critical as FDA implements its authority to regulate tobacco products, and in particular proposes product standards and considers approval of modified risk products. Recently, digital image analysis systems have been developed that can identify the blocking of filter vents on spent cigarette filters with high accuracy and can also estimate the degree of smoker compensation. There is strong potential for such digital imaging systems to unobtrusively infer a rich set of smoker topography variables as well as a smoker's exposure to toxins. The existing literature base on filter-based assays is growing and points to growing prominence and applicability of these approaches to important research questions. We propose to modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth- level cigarette smoke exposure by examining tar stains on cigarette filter butts. The Specific Aims are designed to provide rigorous evaluations of the utility of the systems, from establishing prediction equations using machine-smoked cigarettes to cross- validation in human-smoked samples against other established measures of mouth-level exposure. At the conclusion of this project, we plan to release a validated suite of software to the research community to support external verification of digital image analysis for smoking-related research.        Accurately and simply measuring smoking behavior and smoke exposure is important, and digital image analysis systems have been developed that can estimate smoke intake and identify the blocking of filter vents on spent cigarette filters. The proposed project will modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth-level cigarette smoke exposure. We plan to make a suite of software publicly available to allow others to apply this technology in their own research.               ",Objective imaging-based assessment of smoking behavior from used filters,8328891,R21CA160825,"['Biological Assay', 'Biological Markers', 'Cigarette', 'Communities', 'Computer software', 'Data Analyses', 'Equation', 'Evaluation', 'Exposure to', 'Financial compensation', 'Human', 'Image', 'Image Analysis', 'Intake', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Oral cavity', 'Patient Self-Report', 'Research', 'Risk', 'Sampling', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Smoking Behavior', 'Staining method', 'Stains', 'System', 'Systems Analysis', 'Tars', 'Technology', 'Testing', 'Tobacco', 'Toxin', 'Validation', 'Validity and Reliability', 'Vent', 'authority', 'base', 'cigarette smoking', 'cigarette smoking', 'design', 'digital imaging']",NCI,ROSWELL PARK CANCER INSTITUTE CORP,R21,2012,195788,0.0039665548356499535
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    The technology developed as part of this NIH SBIR project will transform the cell phone camera of visually impaired individuals into a powerful tool capable of identifying the objects they encounter, track the items they own, or navigate complex new environments. Broad access to low-cost visual intelligence technologies developed in this project will improve the independence and capabilities of the visually impaired. There has been tremendous technological progress in computer vision and in the computational power and network bandwidth of and Smartphone platforms. The synergy of these advances stands to revolutionize the way people find information and interact with the physical world. However, these technologies are not yet fully in the hands of the visually impaired, arguably the population that could benefit the most from these developments. Part of the barrier to progress in this area has been that computer vision can accurately handle only a small fraction of the typical images coming from a cell phone camera. To cope with these limitations and make any-image recognition possible, IQ Engines will develop a hybrid system that uses both computer vision and crowdsourcing: if the computer algorithms are not able to understand an image, then the image is sent to a unique crowdsourcing network of people for image analysis. The proposed research includes specific aims to both develop advanced computer vision algorithms for object recognition and advanced crowdsourced networks optimized to the needs of the visually impaired community. This approach combines the speed and accuracy of computer vision with the robustness and understanding of human vision, ultimately providing the user fast and accurate information about the content of any image.      PUBLIC HEALTH RELEVANCE:    The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.                 The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.            ",Mobile Search for the Visually Impaired,8198847,R44EY019790,"['Address', 'Algorithms', 'Area', 'Car Phone', 'Cellular Phone', 'Classification', 'Client', 'Clip', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Crowding', 'Data', 'Databases', 'Detection', 'Development', 'Devices', 'Ensure', 'Environment', 'Family', 'Feedback', 'Friends', 'Glosso-Sterandryl', 'Human', 'Hybrid Computers', 'Hybrids', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Location', 'Modeling', 'Monitor', 'Phase', 'Population', 'Preparation', 'Process', 'Quality of life', 'Research', 'Running', 'Scanning', 'Services', 'Small Business Innovation Research Grant', 'Social Network', 'Source', 'Speed', 'System', 'Technology', 'Telephone', 'Time', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual impairment', 'base', 'blind', 'cell transformation', 'coping', 'cost', 'improved', 'innovation', 'novel', 'object recognition', 'open source', 'sensor', 'tool', 'visual information', 'visual search', 'volunteer']",NEI,"IQ ENGINES, INC.",R44,2012,499358,-0.04511266605882988
"OTHER FUNCTIONS SBIR TOPIC 308, PHASE I: THE MOBILE FOOD INTAKE PHOTO STORAGE AN This proposal describes plans to enhance Viocare¿s Mobile Food Intake Visual and Voice Recognizer (FIVR) System. FIVR, an active Genes, Environment and Health Initiative (GEI) project, is a novel combination of innovative technologies including computer vision and speech recognition to measure dietary intake using a mobile phone. Version 1 of FIVR uses a mobile phone¿s embedded camera to capture a short video of food to be consumed. The food to be eaten is annotated verbally on the mobile phone by the user. These video and audio files are sent to a backend server for real-time food recognition and portion size measurement through speech recognition and image analysis. This project will develop specifications to extend FIVR¿s capabilities to standardize, store, and analyze more diverse food images, such as 3D photos; to collect other food data; to enhance the analysis tools; and for interfaces to a variety of clinical/research systems. The FIVR Version 2 functional prototype will be developed to use 3D dietary images as input. A final evaluation of the FIVR V2 prototype will be conducted to assess the accuracy and feasibility of the 3D image diet capture with a group of 9 subjects in a controlled feeding study. n/a","OTHER FUNCTIONS SBIR TOPIC 308, PHASE I: THE MOBILE FOOD INTAKE PHOTO STORAGE AN",8554263,61201200042C,"['Car Phone', 'Clinical Research', 'Computer Vision Systems', 'Data', 'Diet', 'Dietary intake', 'Documentation', 'Eating', 'Environment', 'Evaluation', 'Food', 'Genes', 'Health', 'Image', 'Image Analysis', 'Measurement', 'Measures', 'Phase', 'Reporting', 'Small Business Innovation Research Grant', 'System', 'Three-Dimensional Image', 'Time', 'Visual', 'Voice', 'feeding', 'innovative technologies', 'novel', 'prototype', 'speech recognition', 'tool']",NCI,"VIOCARE, INC.",N43,2012,200000,-0.04072462835081615
"Fractal Identification System for Medication     DESCRIPTION (provided by applicant): Ai Cure Technologies LLC, was established in 2009 to develop computer vision solutions to ensure safer medication usage. This SBIR Phase I will allow Ai Cure Technologies to prove feasibility of an innovative identification and anti-counterfei labeling solution that replaces traditional barcodes and utilizes the self-similarity properties of fractals to encode and print unique secure fractal patterns directly onto pills or capsules. This SBIR Phase I will allow technical feasibility of this solution, Fractal-ID"", to be demonstrated and will test if a fractal pattern can be printed onto a pill and then recognized with computer vision software. The ability to accurately identify and authenticate pills enables medication to be correctly prescribed and administered. Yet a drug's packaging and labeling is not a stamp of authenticity. It is almost impossible for patients and healthcare professionals to identify pills based on their physical characteristics and to decipher the pill's imprint, its unique identifying code. As a result, the twin problems of counterfeit medication and medication errors - both of which depend upon pill identification - are very difficult to stem. Medication errors contribute heavily to the public health burden. 1.5 million people are harmed every year in the US because of medication errors and the cost for hospitals alone is approximately $3.5 billion. The physical appearances of pills play a large part - it is estimated that a pill's packaging and labeling are responsible for one third of medication errors. More than 10% of the world's drugs are counterfeit, rising to 50% for certain drugs in developing countries. The counterfeit drug market is estimated to be between $75 and $200 billion per year and is growing in countries with strict regulations. 100,000 deaths are attributed to counterfeit drugs every year and there is an unknown morbidity toll since substandard or counterfeit medicines are also responsible for drug resistance, therapeutic failure and dangerous health outcomes. Since medications are repackaged and change hands many times in the supply chain, direct pill and capsule labeling offers a more robust solution to medication identification. While barcodes may be used to serialize individual pills, their fixed designs are unsuitable for the shape, color, texture variablity found in pills and capsules. Furthermore, barcodes are easy to replicate, require fixed surface areas and specific alignment for printing, and are rendered unusable if occlusion occurs due to handling or damage. In addition, the item's physical attributes are distinct from the barcode itself. Ai Cure Technologies will offer pharmaceutical manufacturers, Fractal-ID(tm), a medication identification and authentication solution. The solution will equip manufacturers with printers and a license to a secure fractal label library; consumers will have access to a free computer vision software application to identify fractal pills; and investigators will be provided with higher resolution authentication tools.         PUBLIC HEALTH RELEVANCE: The ability to accurately identify and authenticate pills enables medication to be correctly prescribed and administered. As a result, the twin problems of counterfeit medication and medication errors - both of which depend upon pill identification - are very difficult to stem. Ai Cure Technologies will offer a medication identification solution for pils and capsules that will allow manufacturers, anti-counterfeit investigators, and patients to identif and authenticate medication.                       The ability to accurately identify and authenticate pills enables medication to be correctly prescribed and administered. As a result, the twin problems of counterfeit medication and medication errors - both of which depend upon pill identification - are very difficult to stem. Ai Cure Technologies will offer a medication identification solution for pils and capsules that will allow manufacturers, anti-counterfeit investigators, and patients to identif and authenticate medication.                     ",Fractal Identification System for Medication,8394091,R43TR000190,"['Address', 'Algorithms', 'Appearance', 'Area', 'Biomedical Research', 'Cessation of life', 'Characteristics', 'Code', 'Color', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Country', 'Data', 'Data Protection', 'Data Security', 'Developing Countries', 'Development', 'Devices', 'Drug Industry', 'Drug Packaging', 'Drug resistance', 'Ensure', 'Environment', 'Failure', 'Fingerprint', 'Fractals', 'Goals', 'Hand', 'Health', 'Health Professional', 'Health system', 'Hospital Costs', 'Image', 'Imaging technology', 'Individual', 'Label', 'Libraries', 'Licensing', 'Lighting', 'Manufacturer Name', 'Marketing', 'Medical', 'Medication Errors', 'Medication Systems', 'Medicine', 'Morbidity - disease rate', 'New York', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Play', 'Printing', 'Process', 'Property', 'Public Health', 'Regulation', 'Research Personnel', 'Resolution', 'Secure', 'Security', 'Shapes', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Twin Multiple Birth', 'Work', 'base', 'capsule', 'commercial application', 'design', 'drug market', 'imprint', 'innovation', 'lens', 'phase 1 study', 'pill', 'stem', 'tool', 'transmission process']",NCATS,"AI CURE TECHNOLOGIES, LLC",R43,2012,227209,-0.030661916601893206
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8320255,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2012,345408,-0.02462464663222653
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.       PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.                 Narrative This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Di(R)usion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from di(R)usion MRI scans.",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,8239526,R01NS066340,"['Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2012,497067,-0.02397838471747216
"Vision Without Sight: Exploring the Environment with a Portable Camera  Vision without Sight: Exploring the Environment with a Portable Camera Project Summary As computer vision object recognition algorithms improve in accuracy and speed, and computers become more powerful and compact, it is becoming increasingly practical to implement such algorithms on portable devices such as camera-enabled cell phones. This ""mobile vision"" approach allows normally sighted users to identify objects, signs, places and other features in the environment simply by snapping a photo and waiting a few seconds for the results of the object recognition analysis. The approach holds great promise for blind or visually impaired (VI) users, who may have no other means of identifying important features that are undetectable by non-visual cues. However, in order for the approach to be practical for VI users, the interaction between the user and the environment using the camera must be properly facilitated. For instance, since the user may not know in advance which direction to point the camera towards a desired target, he or she must be able to pan the camera left and right to search for it, and receive rapid feedback whenever it is detected. Drawing on past experience of the PI and his colaborators on object recognition systems for VI users, we propose to study the use of mobile vision technologies for exploring features in the environment, specificaly examining the process of discovering these features and obtaining guidance towards them. Our main objectives are to investigate the strategies adopted by users of these technologies to expedite the exploration process, devise and test maximally effective user interfaces consistent with these strategies, and to assess and benchmark the efficiency of the technologies. The result will be a set of minimum design standards that will specify the system performance parameters, the user interface functionality and the operational strategies necessary for any mobile vision object recognition system for VI users.  Vision without Sight: Exploring the Environment with a Portable Camera Project Narrative The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cel phones but are typicaly designed for normaly sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population",Vision Without Sight: Exploring the Environment with a Portable Camera,8334623,R21EY021643,"['Address', 'Adopted', 'Algorithms', 'American', 'Benchmarking', 'Cellular Phone', 'Computer Hardware', 'Computer Vision Systems', 'Computers', 'Cues', 'Development', 'Devices', 'Environment', 'Feedback', 'Glosso-Sterandryl', 'Goals', 'Goggles', 'Grant', 'Image Analysis', 'Impairment', 'Lead', 'Learning', 'Left', 'Location', 'Performance', 'Population', 'Printing', 'Process', 'Research', 'Self-Help Devices', 'Specific qualifier value', 'Speed', 'System', 'Task Performances', 'Technology', 'Telephone', 'Testing', 'Time', 'Touch sensation', 'Training', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'blind', 'design', 'experience', 'improved', 'insight', 'interest', 'legally blind', 'meetings', 'new technology', 'object recognition', 'operation', 'usability', 'visual feedback']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2012,229834,-0.031933124202933975
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,8234040,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2012,424407,-0.014798998932159876
"Predicting and Detecting Glaucomatous Progression Using Pattern Recognition    DESCRIPTION (provided by applicant): This project aims to improve glaucoma management by applying novel pattern recognition techniques to improve the accurate prediction and detection of glaucomatous progression. The premise is that complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and that advanced pattern recognition techniques can find and use that hidden information. The primary goals involve the use of mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1800 glaucomatous and healthy eyes, available as the result of long-term NIH funding. With the interdisciplinary team of glaucoma and pattern recognition experts we have assembled, with our extensive NIH-supported database of eyes, and with the knowledge we have acquired in the optimal use of pattern recognition methods from previous NIH support, we believe the proposed work can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs.      PUBLIC HEALTH RELEVANCE: The proposed project will develop and demonstrate the usefulness of pattern recognition techniques for predicting and detecting patterns of glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neurodegeneration within the visual pathways at structural and functional levels. The development/use of novel, empirical techniques for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.              The proposed project will develop and demonstrate the usefulness of pattern recognition techniques for predicting and detecting patterns of glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neurodegeneration within the visual pathways at structural and functional levels. The development/use of novel, empirical techniques for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.            ",Predicting and Detecting Glaucomatous Progression Using Pattern Recognition,8216617,R01EY022039,"['Address', 'Algorithms', 'California', 'Caring', 'Clinic', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Databases', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Image', 'Imaging Device', 'Informatics', 'Knowledge', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Noise', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Perimetry', 'Physiologic Intraocular Pressure', 'Physiological', 'Provider', 'Scanning', 'Science', 'Series', 'Signal Transduction', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Translational Research', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'clinical care', 'cost', 'design', 'heuristics', 'improved', 'independent component analysis', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'retinal nerve fiber layer', 'skills']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,386771,-0.02755812541094525
"A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians    DESCRIPTION (provided by applicant): A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians Abstract Project Summary Urban intersections are among the most dangerous parts of a blind person's travel. They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult. To alleviate this problem, we propose to develop and evaluate a cell phone-based system to analyze images of street intersections, taken by a blind or visually impaired person using a standard cell phone, to provide real-time feedback. Building on our past work on a prototype ""Crosswatch"" system that uses computer vision algorithms to find crosswalks and Walk lights, we will greatly enhance the functionality of the system with information about the intersection layout and the identity of its connecting streets, the presence of stop signs, one-way signs and other controls indicating right-of-way, and timing information integrated from Walk/Don't Walk lights, countdown timers and other traffic lights. The system will convey intersection information, and will actively guide the user to align himself/herself with crosswalks, using a combination of synthesized speech and audio tones. We will conduct human factors studies to optimize the system functionality and the configuration of the user interface, as well as develop interactive training applications to equip users with the skills to better use the system. These training applications, implemented as additional cell phone software to complement the intersection system, will train users to hold the camera horizontal and forward and to minimize veer when traversing a crosswalk. The intersection analysis and training software will be made freely available for download onto popular cell phones (such as iPhone, Android or Symbian models). The cell phone will not need any hardware modifications or add-ons to run this software. Ultimately a user will be able to download an entire suite of such algorithms for free onto the cell phone he or she is already likely to be carrying, without having to carry a separate piece of equipment for each function.      PUBLIC HEALTH RELEVANCE: The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.              Public Health Relevance The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.",A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians,8227997,R01EY018345,"['Address', 'Adoption', 'Algorithms', 'American', 'Cellular Phone', 'Complement', 'Complement component C4', 'Complex', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Crowding', 'Custom', 'Data', 'Development', 'Devices', 'Equipment', 'Face', 'Feedback', 'Glosso-Sterandryl', 'Grant', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Length', 'Light', 'Location', 'Mainstreaming', 'Modeling', 'Modification', 'Names', 'Process', 'Reading', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Running', 'Safety', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Speed', 'System', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Time', 'Training', 'Travel', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'abstracting', 'base', 'blind', 'consumer product', 'cost', 'design', 'improved', 'interest', 'legally blind', 'meter', 'prototype', 'public health relevance', 'sensor', 'skills', 'trafficking', 'volunteer', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2012,403177,-0.04679197714982345
"Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance     DESCRIPTION (provided by applicant): The neuromuscular disorders include a wide group of conditions ranging from relatively mild focal problems, such as carpal tunnel syndrome, to severe, generalized diseases, such as amyotrophic lateral sclerosis (ALS). Current methods for evaluating these disorders remain limited to a variety of tests and procedures that are either invasive or remarkably qualitative in nature. One newer technique, electrical impedance myography (EIM), offers the prospect of obtaining quantitative data on muscle condition painlessly and non-invasively. However, no commercial devices specifically tailored for EIM use exist, with nearly all previous EIM work relying upon off-the-shelf bioimpedance devices designed for ""whole-body"" rather than single-muscle assessment. In Phase 1 of this SBIR, Convergence Medical Devices, Inc (CMD) developed an initial prototype system to test proof-of-principle innovative concepts in circuit design and data acquisition to provide highly sensitive and accurate data at an extended frequency range (out to 10 MHz) and over multiple angles relative to the major muscle fiber direction. This work was followed by supplemental work that produced the first hand-held device with robust electronics capable of similar measurements with a detachable, interchangeable electrode array. In this 3-year Phase 2 SBIR, CMD proposes to further refine that technology so as to assist in disease diagnosis and for following disease progression, with a specific focus on amyotrophic lateral sclerosis. In Aim 1 of the proposed grant, testing of multiple electrode array designs will be performed on a group of normal subjects and those with ALS to determine which electrode array designs offer the greatest reproducibility and ability to discriminate healthy from diseased individuals. In Aim 2, the device and the 3 ""best"" array designs identified in Aim 1 will be tested in 30 ALS patients, 30 patients with syndromes mimicking ALS (e.g., polyradiculopathy and motor-predominant neuropathy), and 30 subjects with suspected/possible ALS to determine the single best array design for diagnosis and to determine its sensitivity and specificity. This study will take place at CMD and four external sites and will be managed by the Northeast ALS trials Consortium (NEALS), the premier organization for overseeing clinical trials in ALS. In Aim 3, the 30 suspected/possible ALS patients recruited in SA2 and 30 additional suspected/possible ALS patients will be assessed monthly using EIM and the 3 arrays identified in SA1. All subjects will also undergo standard measurements of disease progression including handheld dynamometry, ALS Functional Rating Scale, and spirometry. The best array design for assessing disease progression will be identified and compared to conventional markers of disease progression to determine EIM's sensitivity to disease status. Thus, at the conclusion of this research program, we anticipate having developed and vigorously tested an EIM device and associated electrode designs that together will serve as a powerful new diagnostic and monitoring tool for neuromuscular disease.        PUBLIC HEALTH RELEVANCE: The neuromuscular disorders are a group of conditions that impact the lives of millions of people in the United States alone. In this study, Convergence Medical Devices, in collaboration with neurologists at several medical centers, will develop and test a new device based on the concept of electrical impedance myography, a technique that offers the promise of rapid and accurate disease assessment. With the completion of this study, a new, painless tool will be developed and studied that will assist in individual patient care and will speed drug testing in clinical trials in diseases ranging from amyotrophic lateral sclerosis and muscular dystrophy to radiculopathy and polyneuropathy.              The neuromuscular disorders are a group of conditions that impact the lives of millions of people in the United States alone. In this study, Convergence Medical Devices, in collaboration with neurologists at several medical centers, will develop and test a new device based on the concept of electrical impedance myography, a technique that offers the promise of rapid and accurate disease assessment. With the completion of this study, a new, painless tool will be developed and studied that will assist in individual patient care and will speed drug testing in clinical trials in diseases ranging from amyotrophic lateral sclerosis and muscular dystrophy to radiculopathy and polyneuropathy.            ",Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance,8315044,R44NS070385,"['Amyotrophic Lateral Sclerosis', 'Area', 'Biological Markers', 'Biopsy', 'Businesses', 'Carpal Tunnel Syndrome', 'Clinical', 'Clinical Trials', 'Collaborations', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Electrodes', 'Electromyography', 'Electronics', 'Entrapment Neuropathies', 'Frequencies', 'Future', 'Genetic', 'Goals', 'Grant', 'Individual', 'Limb structure', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Measures', 'Medical Device', 'Medical center', 'Methods', 'Monitor', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Fibers', 'Muscular Dystrophies', 'Myography', 'Nature', 'Needles', 'Neurologist', 'Neuromuscular Diseases', 'Neuropathy', 'Outcome', 'Painless', 'Patient Care', 'Patients', 'Phase', 'Physicians', 'Polyneuropathy', 'Polyradiculopathy', 'Procedures', 'Radiculopathy', 'Recruitment Activity', 'Relative (related person)', 'Reproducibility', 'Research', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Spirometry', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Clinical Trial', 'Time', 'United States', 'Widespread Disease', 'Work', 'base', 'clinical care', 'commercial application', 'data acquisition', 'design', 'diagnosis design', 'disease diagnosis', 'drug testing', 'electric impedance', 'improved', 'indexing', 'innovation', 'muscle strength', 'muscular structure', 'neuromuscular', 'novel diagnostics', 'programs', 'prototype', 'pulmonary function', 'tool', 'validation studies']",NINDS,"MYOLEX, INC.",R44,2012,620921,-0.007239571902125317
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma  ABSTRACT  This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Comptutational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans.  PROJECT NARRATIVE  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,8209138,K99EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'symposium', 'time use']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2012,89325,-0.023610168687745306
"Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements    DESCRIPTION (provided by applicant): Thyroid nodules are present in a large fraction of healthy individuals. Between 4% and 7% of the United States adult population has palpable thyroid nodules, and up to 50% of American women older than age 50 have nodules that can be depicted on ultrasound. The vast majority (>95%) of thyroid nodules are benign. However, cancer risk increases with male gender, nodule size, extremes of age (< 30 and > 60 years), underlying autoimmune disease, nodule growth, personal or family history of thyroid cancer, and radiation exposure. Ultrasound imaging and Fine Needle Aspiration Biopsy (FNAB) remain the mainstays of thyroid nodule evaluation. Unfortunately, 25% of patients who ultimately undergo FNAB of a thyroid nodule have indeterminate cytology. Many of these patients will require at least partial thyroidectomy purely for the purpose of obtaining a definitive diagnosis. Given that only 30% of these will ultimately prove to be malignant on surgical pathology, the majority of these lobectomies could potentially be avoided if better non-invasive methods existed to evaluate indeterminate nodules. Electrical Impedance Scanning (EIS) has been previously investigated for non-invasive evaluation of thyroid nodules. The overall diagnostic accuracy of EIS was encouraging but not sufficient for routine clinical use. We have developed a modified approach termed here Resonance Electrical Impedance Spectroscopy (REIS) that should have substantially higher sensitivity and specificity for this very purpose. When using REIS technology to examine the breast, we obtained initial results that are significantly better in all respects than those obtained with traditional EIS. We believe that REIS technology will similarly improve the assessment of thyroid nodules. REIS hold promise as a reproducible modality for the risk stratification of the many patients with indeterminate thyroid nodules. It is a new non- invasive modality that may help reduce the number of diagnostic lobectomies and would be welcomed by patients with non-diagnostic FNA results. The purpose of this application is to design, assemble, and test in a preliminary clinical study a unique REIS based device for the assessment of thyroid nodules.      PUBLIC HEALTH RELEVANCE: We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.           Project narrative:  We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.",Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements,8207850,R21CA154262,"['Address', 'Adult', 'Age', 'American', 'Aspirate substance', 'Autoimmune Diseases', 'Benign', 'Biopsy', 'Breast', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Consent', 'Cytology', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Endocrine', 'Endocrinologist', 'Evaluation', 'Excision', 'Family history of', 'Fine needle aspiration biopsy', 'Follicular thyroid carcinoma', 'Frequencies', 'Gender', 'General Anesthesia', 'Growth', 'Human', 'Image', 'Incidence', 'Individual', 'Lesion', 'Lobectomy', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measurement', 'Measures', 'Methods', 'Modality', 'Neck', 'Nodule', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Palpable', 'Papillary', 'Papillary Carcinoma', 'Participant', 'Patients', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Procedures', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Radiation', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Spectrum Analysis', 'Stratification', 'Surgeon', 'Surgical Pathology', 'System', 'Techniques', 'Technology', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Thyroidectomy', 'Triage', 'Ultrasonography', 'United States', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer risk', 'clinical practice', 'design', 'diagnostic accuracy', 'electric impedance', 'imaging modality', 'improved', 'male', 'malignant breast neoplasm', 'men', 'older women', 'phase change', 'prospective', 'prototype', 'public health relevance', 'radiologist', 'tool', 'web site']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2012,164756,-0.03614091069982235
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,8473426,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Methodology', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'digital', 'experience', 'falls', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition', 'web services']",NEI,BLINDSIGHT CORPORATION,R44,2012,407051,-0.02127395300525817
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.      PUBLIC HEALTH RELEVANCE: The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.           The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8227796,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2012,197444,-0.003914016227554695
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator.  The ultimate goal of this SBIR project is to provide the DOD, DOE, and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. In Phase I, Seacoast successfully demonstrated the feasibility of using a microsensor array with a proprietary trap-and- purge preconcentrator to detect chlorinated solvents, specifically TCE, and TCA, at levels low enough to meet EPA mandated levels for drinking water. In Phase II Seacoast proposes to improve the selectivity and sensitivity of the system to better meet the needs identified by the Phase I consultant. The systems have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator traps the contaminants and releases them to a microsensor array. These sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical.  In Phase II Seacoast will specifically develop new materials to improve the sensor array selectivity, 1) by using impedance spectroscopy to study the mechanisms by which the polymer-based sensors sorb the target chemicals, 2) by implementing pattern recognition algorithms to identify chemicals for the sensor responses, and 3) by designing new preconcentrator materials that can bind these chemicals more strongly.  The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. Potential markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology.      PUBLIC HEALTH RELEVANCE: This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.           PROJECT NARRATIVE This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.",Low-Cost Electronic Nose for Groundwater Contaminants,8260510,R44ES016941,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benchmarking', 'Benzene', 'Carcinogens', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Computer software', 'Cost Analysis', 'Cost Savings', 'Data', 'Data Collection', 'Detection', 'Development', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Equation', 'Equipment', 'Evaluation', 'Fingerprint', 'Fluorescence', 'Gases', 'Goals', 'Guidelines', 'Hazardous Waste', 'Industrial Health', 'Intervention', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Maps', 'Marketing', 'Measures', 'Metals', 'Methods', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Pesticides', 'Phase', 'Plants', 'Poison', 'Pollution', 'Polymers', 'Process', 'Public Health', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Route', 'Safety', 'Sampling', 'Science', 'Scientific Advances and Accomplishments', 'Site', 'Small Business Innovation Research Grant', 'Soil', 'Solvents', 'Source', 'Spectrum Analysis', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Time', 'Trichloroethylene', 'Water', 'Wireless Technology', 'Work', 'analytical method', 'base', 'chemical binding', 'cost', 'design', 'detector', 'drinking water', 'electric impedance', 'ground water', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'method development', 'new technology', 'novel', 'operation', 'pollutant', 'programs', 'prototype', 'public health relevance', 'purge', 'remediation', 'response', 'sensor', 'success', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R44,2012,459419,-0.011096671098987473
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis  Project Summary All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This proposal takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.  Project Narrative This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8300746,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2012,151744,-0.03393378625733496
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8299311,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2011,239426,-0.003500920867051101
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8022635,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,304318,-0.0011158788305205313
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,8142000,R01EY016093,"['Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Peripheral', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2011,1141143,-0.031031299620991784
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8102722,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,458901,0.004336341815614957
"PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY    DESCRIPTION (provided by applicant): Well trained, experienced gastroenterologists in academic and high volume settings can reliably recognize 97% of pathologies in Capsule Endoscopy (CE) video. However, community physicians and infrequent users may miss up to 20%. The end goal of our proposed new line of research is to develop clinical software that provides automatic decision support to physicians who are trying to declare that a patient is pathology free or has a certain disease process. The risk for the physician - and their patients - is that of a less than optimal clinical outcome due to:  1) missing a lesion/pathology in the video and putting the patient at risk of developing a more serious condition over time, or  2) mistakenly ""identifying"" a pathology that is not present and thus subjecting the patient to unnecessary further diagnostic or surgical procedures.  The research aims in this proposal will enable Ikona to create a pathology prioritization image processing module. Implementing modern machine learning techniques such as Support Vector Machines (SVM) and Adaboost methodologies together with proprietary image feature analysis, this technology will assign a probability metric to every frame in the image sequence for specific pathology (lesions, ulcers, bleeding, etc) and the major landmarks in the GI tract (ileo-cecal valve, pyloric valve etc.). Filtering and sorting endoscopy image data will be done such that the images with the highest probability of containing pathology will be presented to the reviewer first.  This pathology prioritized sequencing is not intended to replace the clinician in the workflow, but rather to allow the clinician to focus more time on frames with a higher potential of containing pathology. Often times, clinically significant pathology may only be present in a single frame. A single ""pathological"" frame in the middle of a 50,000 frame sequence can easily be overlooked by a novice reviewer or a reviewer whose attention is temporarily distracted. With our proposed pathology prioritization, that single pathological frame will be identified and sorted near the beginning of the image sequence thus greatly increasing the likelihood of detection by the reviewer.  Specifically for Phase I, we plan to investigate and develop different algorithms for classifying image frames and recognizing pathological and normal frames, and, algorithms for ranking frames by severity of pathology. Following the implementation of a working prototype, we will further test the clinical utility of these algorithms with human clinical capsule endoscopy videos.      PUBLIC HEALTH RELEVANCE: Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.           Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.         ",PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY,8057895,R43DK091083,"['Affect', 'Algorithms', 'American', 'Attention', 'Blood', 'Categories', 'Classification', 'Classification Scheme', 'Clinical', 'Community Physician', 'Computer software', 'Crohn&apos', 's disease', 'Data', 'Data Set', 'Databases', 'Deformity', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Disease', 'Endoscopy', 'Evaluation', 'Family', 'Fatigue', 'Gastroenterologist', 'Gastrointestinal tract structure', 'Goals', 'Hemorrhage', 'Hour', 'Human', 'Image', 'Imagery', 'Lesion', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Metric', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Phase', 'Physicians', 'Polyps', 'Population', 'Probability', 'Procedures', 'Process', 'Readability', 'Reader', 'Reading', 'Research', 'Risk', 'Risk Reduction', 'Severities', 'Small Intestines', 'Sorting - Cell Movement', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'Ulcer', 'Work', 'base', 'capsule', 'clinically relevant', 'clinically significant', 'cost', 'experience', 'gastrointestinal', 'image processing', 'improved', 'innovation', 'interest', 'prospective', 'prototype', 'tumor']",NIDDK,IKONA MEDICAL CORPORATION,R43,2011,176778,0.005517305190426647
"Digital image analysis for quantitative and qualitative assessment of pig islets    DESCRIPTION (provided by applicant): The demonstration by the Edmonton group that human islet transplantation can be successfully used to manage adult type 1 diabetes patients with refractory hypoglycemia has led to increased funding of clinical trials and further research to extend the scope of this therapy by using porcine islets in place of human islets. Significant advances have been made in improving immunosuppression treatment regimens so that results obtained from treating adult diabetic patients with human islet transplants are similar to those obtained after pancreas transplantation. The major hurdle to move this therapy from clinical research to routine clinical practice is to improve the yield and quality of islets recovered from human or porcine pancreas. Presently, there are no standardized methods that can accurately assess the number or quality of islets that are used in the islet transplantation procedures so that results between laboratories can be objectively evaluated. This grant is focused on developing a robust, islet image analysis software to objectively analyze the number and quality of porcine islets recovered from the pancreas. The two major aims of the project are first to develop an improved image analysis software program that will provide a standardized measurement of the number and mass of porcine islets in a cell preparation. And second, enhance the capabilities of the software program by correlating the image signatures of each porcine islet to an artificial category. Porcine islets of similar size will be handpicked and sorted into three categories based on the shape, border, integrity, or uniformity of dithizone staining. The first software enhancement will find those features in the images that can be used to distinguish the different categories of islets. The second enhancement will assess the feasibility of using machine learning methods to correlate these features with data recovered from the images but also other discrete or continuous variables that are used to characterize the porcine islet preparations. If successful, the ability to use a rapid and objective image analysis methodology will improve the assessment of the number and quality of islets within and between laboratories; correlate image features with success of transplantation as measured by graft survival and insulin independence; and improve the islet isolation methods to achieve favorable islet image scores that are determined by retrospective analysis. The ability of a commercial firm focused on improving islet yields by focusing on tissue dissociation with a leading academic laboratory that has sophisticated expertise in developing software algorithms from microscopic images provides a fresh approach to a difficult medical that needs to be resolved to realize the full potential of islet transplantation to treat adult type 1 diabetic patients.      PUBLIC HEALTH RELEVANCE: An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.           An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.         ",Digital image analysis for quantitative and qualitative assessment of pig islets,8058009,R43DK091103,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Biochemical', 'Biological', 'Biological Assay', 'Caliber', 'Categories', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computer Assisted', 'Computer software', 'Data', 'Data Collection', 'Development', 'Dissociation', 'Dithizone', 'Drops', 'Enzymes', 'Family suidae', 'Feasibility Studies', 'Funding', 'Genetic', 'Glucose', 'Graft Survival', 'Grant', 'Human', 'Hypoglycemia', 'Image', 'Image Analysis', 'Immunosuppression', 'In Vitro', 'Insulin', 'Insulin-Dependent Diabetes Mellitus', 'Islet Cell', 'Islets of Langerhans Transplantation', 'Laboratories', 'Liver', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microscope', 'Microscopic', 'Modification', 'Optics', 'Organ', 'Outcome', 'Pancreas', 'Pancreas Transplantation', 'Pathway interactions', 'Patients', 'Pattern Recognition', 'Pattern Recognition Systems', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Portal vein structure', 'Predictive Value', 'Preparation', 'Procedures', 'Proteomics', 'Protocols documentation', 'Recovery', 'Refractory', 'Reporting', 'Research', 'Sampling', 'Sampling Errors', 'Scientist', 'Screening procedure', 'Shapes', 'Sorting - Cell Movement', 'Staining method', 'Stains', 'Standardization', 'Statistical Models', 'Stress', 'Structure', 'Survival Rate', 'System', 'Techniques', 'Time', 'Tissues', 'Transplantation', 'Treatment Protocols', 'base', 'cell preparation', 'clinical practice', 'diabetic patient', 'digital', 'digital imaging', 'improved', 'indexing', 'innovation', 'islet', 'programs', 'software development', 'standardize measure', 'success', 'tool', 'type I diabetic']",NIDDK,"VITACYTE, LLC",R43,2011,232329,0.01255802223477295
"NLP for Augmentative and Alternative Communication in Adults    DESCRIPTION (provided by applicant):  This proposal relates to the technology of Augmentative and Alternative Communication (AAC).  The research, to be developed over the three-year course of this project, relates to increasing communication speed for adult users of typing-based AAC devices. The proposed method has commonalities both with chatter bots and more sophisticated automated question answering systems. In particular, we propose to develop a program that will mine a very large database of stored interactions for sentences that are similar to the sentence currently being uttered by the interlocutor, and propose a set of plausible responses for the AAC user. The outcome of this research will be a system that improves over the current state of the art in whole utterance approaches in AAC, making use of sophisticated natural language processing techniques.    Through this research and its practical application to helping real people with real communications needs, as well as coursework, seminars, participation in the AAC and disabilities community in Portland, OR, and intensive one-on-one meetings with his mentor Dr. Melanie Fried-Oken, the PI will accrue substantial clinical experience in AAC, and will gain a deep understanding of how technology can be used to help people.      PUBLIC HEALTH RELEVANCE: The proposed project will develop a research program in the field of Augmentative and Alternative Communication. The program proposes to improve the throughput of AAC devices for conversation by modeling dialogue context for literate adult users. Specifically, we will use corpus-based techniques from question answering and chatter bots to select appropriate utterances in response to utterances from interlocutors.              The proposed project will develop a research program in the field of Augmentative and Alternative Communication. The program proposes to improve the throughput of AAC devices for conversation by modeling dialogue context for literate adult users. Specifically, we will use corpus-based techniques from question answering and chatter bots to select appropriate utterances in response to utterances from interlocutors.            ",NLP for Augmentative and Alternative Communication in Adults,8189460,K25DC011308,"['Address', 'Adult', 'Area', 'Clinical', 'Communication', 'Communication Aids for Disabled', 'Communication Disability', 'Communities', 'Computers', 'Data', 'Databases', 'Devices', 'Environment', 'Food', 'Generations', 'Hobbies', 'Interview', 'Length', 'Measures', 'Mentors', 'Methods', 'Mining', 'Modeling', 'Modification', 'Names', 'Natural Language Processing', 'Oregon', 'Outcomes Research', 'Participant', 'Play', 'Questionnaires', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Restaurants', 'Role', 'Savings', 'Self Assessment', 'Simulate', 'Source', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Travel', 'Universities', 'alternative communication', 'base', 'efficacy testing', 'experience', 'improved', 'literate', 'meetings', 'movie', 'novel', 'practical application', 'programs', 'response', 'satisfaction', 'speech recognition', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,K25,2011,162459,-0.02265521141380991
"Objective imaging-based assessment of smoking behavior from used filters    DESCRIPTION (provided by applicant): Accurate measurement of smoking behaviors and exposures may become critical as FDA implements its authority to regulate tobacco products, and in particular proposes product standards and considers approval of modified risk products. Recently, digital image analysis systems have been developed that can identify the blocking of filter vents on spent cigarette filters with high accuracy and can also estimate the degree of smoker compensation. There is strong potential for such digital imaging systems to unobtrusively infer a rich set of smoker topography variables as well as a smoker's exposure to toxins. The existing literature base on filter-based assays is growing and points to growing prominence and applicability of these approaches to important research questions. We propose to modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth- level cigarette smoke exposure by examining tar stains on cigarette filter butts. The Specific Aims are designed to provide rigorous evaluations of the utility of the systems, from establishing prediction equations using machine-smoked cigarettes to cross- validation in human-smoked samples against other established measures of mouth-level exposure. At the conclusion of this project, we plan to release a validated suite of software to the research community to support external verification of digital image analysis for smoking-related research.      PUBLIC HEALTH RELEVANCE: Accurately and simply measuring smoking behavior and smoke exposure is important, and digital image analysis systems have been developed that can estimate smoke intake and identify the blocking of filter vents on spent cigarette filters. The proposed project will modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth-level cigarette smoke exposure. We plan to make a suite of software publicly available to allow others to apply this technology in their own research.                 Accurately and simply measuring smoking behavior and smoke exposure is important, and digital image analysis systems have been developed that can estimate smoke intake and identify the blocking of filter vents on spent cigarette filters. The proposed project will modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth-level cigarette smoke exposure. We plan to make a suite of software publicly available to allow others to apply this technology in their own research.               ",Objective imaging-based assessment of smoking behavior from used filters,8166424,R21CA160825,"['Biological Assay', 'Biological Markers', 'Cigarette', 'Communities', 'Computer software', 'Data Analyses', 'Equation', 'Evaluation', 'Exposure to', 'Financial compensation', 'Human', 'Image', 'Image Analysis', 'Intake', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Oral cavity', 'Patient Self-Report', 'Research', 'Risk', 'Sampling', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Smoking Behavior', 'Staining method', 'Stains', 'System', 'Systems Analysis', 'Tars', 'Technology', 'Testing', 'Tobacco', 'Toxin', 'Validation', 'Validity and Reliability', 'Vent', 'authority', 'base', 'cigarette smoking', 'cigarette smoking', 'design', 'digital imaging']",NCI,ROSWELL PARK CANCER INSTITUTE CORP,R21,2011,137113,0.004731623711367537
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",8100386,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2011,220839,-0.041935005282968875
"Vision Without Sight: Exploring the Environment with a Portable Camera    DESCRIPTION (provided by applicant): As computer vision object recognition algorithms improve in accuracy and speed, and computers become more powerful and compact, it is becoming increasingly practical to implement such algorithms on portable devices such as camera-enabled cell phones. This ""mobile vision"" approach allows normally sighted users to identify objects, signs, places and other features in the environment simply by snapping a photo and waiting a few seconds for the results of the object recognition analysis. The approach holds great promise for blind or visually impaired (VI) users, who may have no other means of identifying important features that are undetectable by non-visual cues. However, in order for the approach to be practical for VI users, the interaction between the user and the environment using the camera must be properly facilitated. For instance, since the user may not know in advance which direction to point the camera towards a desired target, he or she must be able to pan the camera left and right to search for it, and receive rapid feedback whenever it is detected. Drawing on past experience of the PI and his collaborators on object recognition systems for VI users, we propose to study the use of mobile vision technologies for exploring features in the environment, specific examining the process of discovering these features and obtaining guidance towards them. Our main objectives are to investigate the strategies adopted by users of these technologies to expedite the exploration process, devise and test maximally effective user interfaces consistent with these strategies, and to assess and benchmark the efficiency of the technologies. The result will be a set of minimum design standards that will specify the system performance parameters, the user interface functionality and the operational strategies necessary for any mobile vision object recognition system for VI users.      PUBLIC HEALTH RELEVANCE: The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cell phones but are typically designed for normally sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population              The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cell phones but are typically designed for normally sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population            ",Vision Without Sight: Exploring the Environment with a Portable Camera,8097202,R21EY021643,"['Address', 'Adopted', 'Algorithms', 'American', 'Benchmarking', 'Cellular Phone', 'Computer Hardware', 'Computer Vision Systems', 'Computers', 'Cues', 'Development', 'Devices', 'Environment', 'Feedback', 'Glosso-Sterandryl', 'Goals', 'Goggles', 'Grant', 'Image Analysis', 'Impairment', 'Lead', 'Learning', 'Left', 'Location', 'Performance', 'Population', 'Printing', 'Process', 'Research', 'Self-Help Devices', 'Specific qualifier value', 'Speed', 'System', 'Task Performances', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Training', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'blind', 'design', 'experience', 'improved', 'insight', 'interest', 'legally blind', 'meetings', 'new technology', 'object recognition', 'operation', 'usability', 'visual feedback']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2011,205070,-0.028214651578377516
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8138459,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2011,345408,-0.02462464663222653
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.       PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.                 Narrative This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Di(R)usion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from di(R)usion MRI scans.",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,8042555,R01NS066340,"['Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2011,503274,-0.02397838471747216
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,8037095,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2011,417204,-0.014798998932159876
"New Techniques for Measuring Volumetric Structural Changes in Glaucoma    DESCRIPTION (provided by applicant) This K99/R00 application supports additional research training in computational mathematics and computer vision which will enable Dr. Madhusudhanan Balasubramanian-the applicant, to become an independent multidisciplinary investigator in computational ophthalmology. Specifically, in the K99 training phase of this grant, Dr. Balasubramanian will train at UC San Diego under the direction of Linda Zangwill PhD, an established glaucoma clinical researcher in the Department of Ophthalmology, as well as a team of co- mentors, including, Dr. Michael Holst from the Department of Mathematics and co-director for the Center for Computational Mathematics, and co-director of the Computational Science, Mathematics and Engineering and Dr. David Kriegman from Computer Science and Engineering. Training will be conducted via formal coursework, hands-on lab training, mentored research, and progress review by an advisory committee, visiting collaborating researchers and regular attendance at seminars and workshops. The subsequent R00 independent research phase involves applying Dr. Balasubramanian's newly acquired computational techniques to the difficult task of identifying glaucomatous change over time from optical images of the optic nerve head and retinal nerve fiber layer.  A documented presence of progressive optic neuropathy is the best gold standard currently available for glaucoma diagnosis. Confocal Scanning Laser Ophthalmoscope (CSLO) and Spectral Domain Optical Coherence Tomography (SD-OCT) are two of the optical imaging instruments available for monitoring the optic nerve head health in glaucoma diagnosis and management. Currently, several statistical and computational techniques are available for detecting localized glaucomatous changes from the CSLO exams. SD-OCT is a new generation ophthalmic imaging instrument based on the principle of optical interferometry. In contrast to the CSLO technology, SDOCT can resolve retinal layers from the internal limiting membrane (ILM) through the Bruch's membrane and can capture the 3-D architecture of the optic nerve head at a very high resolution. These high-resolution, high-dimensional volume scans introduce a new level of data complexity not seen in glaucoma progression analysis before and therefore, powerful (high-performance) computational techniques are required to fully utilize the high precision retinal measurements for glaucoma diagnosis. The central focus of this application in the K99 mentored phase of the application will be in 1) developing computational and statistical techniques for detecting structural glaucomatous changes in various retinal layers from the SDOCT scans, and 2) developing a new avenue of research in glaucoma management where in strain in retinal layers will be estimated non-invasively to characterize glaucomatous progression. In the R00 independent phase, the specific aims focus on developing 1) statistical and computational techniques for detecting volumetric glaucomatous change over time using 3-D SD-OCT volume scans and 2) a computational framework to estimate full-field 3-D volumetric strain from the standard SD-OCT scans.      PUBLIC HEALTH RELEVANCE:  Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.            Detecting the onset and progression of glaucomatous changes in the eye is central to glaucoma diagnosis and management. This multidisciplinary project focuses on developing powerful (high-performance) computational, mathematical, and statistical techniques for detecting volumetric glaucomatous changes from the Confocal Scanning Laser Ophthalmoscopy (CSLO) scans and volumetric Spectral Domain Optical Coherence Tomography (SD-OCT) scans of the optic nerve head. In addition, the Principal Investigator of this proposal will receive extensive training in the areas of computational mathematics and computer vision to augment and strengthen his multidisciplinary expertise essential to execute the proposed specific aims.         ",New Techniques for Measuring Volumetric Structural Changes in Glaucoma,7871151,K99EY020518,"['3-Dimensional', 'Address', 'Advisory Committees', 'Affect', 'Architecture', 'Area', 'Biology', 'Blindness', 'Brain imaging', 'Bruch&apos', 's basal membrane structure', 'Cardiology', 'Clinic', 'Clinical', 'Complex', 'Computational Science', 'Computational Technique', 'Computer Vision Systems', 'Confocal Microscopy', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Progression', 'Doctor of Philosophy', 'Educational workshop', 'Elements', 'Engineering', 'Eye', 'Functional disorder', 'Gastroenterology', 'Generations', 'Genetic screening method', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Health', 'Image', 'Interferometry', 'Lasers', 'Lead', 'Left', 'Mathematics', 'Measurement', 'Measures', 'Medicine', 'Membrane', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'National Eye Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'Onset of illness', 'Ophthalmology', 'Ophthalmoscopes', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Phase', 'Principal Investigator', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Retinal', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Treatment Effectiveness', 'Treatment Protocols', 'Validation', 'Vision', 'Vision research', 'Visit', 'analytical tool', 'base', 'bioimaging', 'blood flow measurement', 'cancer imaging', 'computer framework', 'computer science', 'cost', 'diagnostic accuracy', 'improved', 'instrument', 'medical specialties', 'multidisciplinary', 'optic nerve disorder', 'optical imaging', 'prevent', 'programs', 'retinal nerve fiber layer', 'symposium', 'time use']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2011,89922,-0.016549182529229985
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,8139155,R44RR024094,"['AIDS/HIV problem', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cell physiology', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2011,449663,-0.031300177069083834
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,8143297,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'animal tissue', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2011,132786,-0.008586282779529658
"A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians    DESCRIPTION (provided by applicant): A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians Abstract Project Summary Urban intersections are among the most dangerous parts of a blind person's travel. They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult. To alleviate this problem, we propose to develop and evaluate a cell phone-based system to analyze images of street intersections, taken by a blind or visually impaired person using a standard cell phone, to provide real-time feedback. Building on our past work on a prototype ""Crosswatch"" system that uses computer vision algorithms to find crosswalks and Walk lights, we will greatly enhance the functionality of the system with information about the intersection layout and the identity of its connecting streets, the presence of stop signs, one-way signs and other controls indicating right-of-way, and timing information integrated from Walk/Don't Walk lights, countdown timers and other traffic lights. The system will convey intersection information, and will actively guide the user to align himself/herself with crosswalks, using a combination of synthesized speech and audio tones. We will conduct human factors studies to optimize the system functionality and the configuration of the user interface, as well as develop interactive training applications to equip users with the skills to better use the system. These training applications, implemented as additional cell phone software to complement the intersection system, will train users to hold the camera horizontal and forward and to minimize veer when traversing a crosswalk. The intersection analysis and training software will be made freely available for download onto popular cell phones (such as iPhone, Android or Symbian models). The cell phone will not need any hardware modifications or add-ons to run this software. Ultimately a user will be able to download an entire suite of such algorithms for free onto the cell phone he or she is already likely to be carrying, without having to carry a separate piece of equipment for each function.      PUBLIC HEALTH RELEVANCE: The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.              The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.            ",A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians,8042468,R01EY018345,"['Address', 'Adoption', 'Algorithms', 'American', 'Cellular Phone', 'Complement', 'Complement component C4', 'Complex', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Crowding', 'Custom', 'Data', 'Development', 'Devices', 'Equipment', 'Face', 'Feedback', 'Glosso-Sterandryl', 'Grant', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Length', 'Light', 'Location', 'Mainstreaming', 'Modeling', 'Modification', 'Names', 'Process', 'Reading', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Running', 'Safety', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Speed', 'System', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Time', 'Training', 'Travel', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'abstracting', 'base', 'blind', 'consumer product', 'cost', 'design', 'improved', 'interest', 'legally blind', 'meter', 'prototype', 'sensor', 'skills', 'trafficking', 'volunteer', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2011,403177,-0.04736185230215339
"Replacement Ocular Battery (ROBatt)    DESCRIPTION (provided by applicant): The objective of this grant project is the development and pre-validation of the Replacement Ocular Battery (ROBatt), a tiered testing strategy consisting of a battery of four alternative ocular irritancy assays, which will replace regulatory mandated acute ocular irritation testing using the Draize Rabbit Eye test. ROBatt consists of the Bovine Corneal Opacity and Permeability Assay (BCOP), the Chorioallantoic Membrane Vascular Assay using 10-day fertile chicken eggs (CAMVA), the Porcine Corneal Reversibility Assay (PorCORA) and the Porcine Confocal Assay (PorFocal). This tiered strategy follows a decision tree that allows for a thorough interrogation of possible ocular irritants. Although four assays are recommended, in most cases only two or three will be used depending on the degree of irritation. The Specific Aim of the ROBatt project is to validate the decision tree variables using at least 50 chemicals listed in the European Center for Ecotoxicology and Toxicology of Chemicals (ECETOC) data bank, including Corrosive (EEC R41, GHS/EPA Cat 1), Severe (EEC R36, GHS CaL 2, HMIS 2), Moderate (EPA Cat. 3, HMIS 2), Mild (HMIS 1) and Non-irritating (EPA Cat 4, HMIS 0). The long-term project goal is to submit the ROBatt testing strategy to iCCVAM/ECVAM for consideration as a standalone alternative to the Draize Rabbit Eye test. Validation and acceptance of the ROBatt testing strategy will significantly reduce the number of rabbits used in the toxicological assessment of consumer products, chemicals and raw materials by replacing rabbits with four robust alternative assays.       PUBLIC HEALTH RELEVANCE: Ocular irritation testing is extremely relevant to assuring adequate safety levels of public health as new formulations of chemicals and products are introduced. In most cases, these safety assessments are performed using the Draize Rabbit Eye test, resulting in thousands of rabbits used in testing every year. Alternatives have been discussed since the 80s without any appreciable acceptance from regulators.           n/a",Replacement Ocular Battery (ROBatt),8150947,U01NS073481,"['Acute', 'Biological Assay', 'Blood Vessels', 'Cattle', 'Chemicals', 'Chickens', 'Cornea', 'Corneal Opacity', 'Corrosives', 'Databases', 'Decision Trees', 'Development', 'Drug Formulations', 'European', 'Eye', 'Family suidae', 'Felis catus', 'Goals', 'Grant', 'Irritants', 'Oryctolagus cuniculus', 'Permeability', 'Public Health', 'Safety', 'Test Result', 'Testing', 'Toxicology', 'Validation', 'chorioallantoic membrane', 'consumer product', 'egg', 'irritation', 'public health relevance']",NINDS,"MB RESEARCH LABORATORIES, INC.",U01,2011,483139,-0.018640460901200744
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,8059576,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological Models', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'base', 'computerized data processing', 'experience', 'gamma-Aminobutyric Acid', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2011,1244329,-0.01722351613091436
"Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements    DESCRIPTION (provided by applicant): Thyroid nodules are present in a large fraction of healthy individuals. Between 4% and 7% of the United States adult population has palpable thyroid nodules, and up to 50% of American women older than age 50 have nodules that can be depicted on ultrasound. The vast majority (>95%) of thyroid nodules are benign. However, cancer risk increases with male gender, nodule size, extremes of age (< 30 and > 60 years), underlying autoimmune disease, nodule growth, personal or family history of thyroid cancer, and radiation exposure. Ultrasound imaging and Fine Needle Aspiration Biopsy (FNAB) remain the mainstays of thyroid nodule evaluation. Unfortunately, 25% of patients who ultimately undergo FNAB of a thyroid nodule have indeterminate cytology. Many of these patients will require at least partial thyroidectomy purely for the purpose of obtaining a definitive diagnosis. Given that only 30% of these will ultimately prove to be malignant on surgical pathology, the majority of these lobectomies could potentially be avoided if better non-invasive methods existed to evaluate indeterminate nodules. Electrical Impedance Scanning (EIS) has been previously investigated for non-invasive evaluation of thyroid nodules. The overall diagnostic accuracy of EIS was encouraging but not sufficient for routine clinical use. We have developed a modified approach termed here Resonance Electrical Impedance Spectroscopy (REIS) that should have substantially higher sensitivity and specificity for this very purpose. When using REIS technology to examine the breast, we obtained initial results that are significantly better in all respects than those obtained with traditional EIS. We believe that REIS technology will similarly improve the assessment of thyroid nodules. REIS hold promise as a reproducible modality for the risk stratification of the many patients with indeterminate thyroid nodules. It is a new non- invasive modality that may help reduce the number of diagnostic lobectomies and would be welcomed by patients with non-diagnostic FNA results. The purpose of this application is to design, assemble, and test in a preliminary clinical study a unique REIS based device for the assessment of thyroid nodules.      PUBLIC HEALTH RELEVANCE: We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.           We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.         ",Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements,8015458,R21CA154262,"['Address', 'Adult', 'Age', 'American', 'Aspirate substance', 'Autoimmune Diseases', 'Benign', 'Biopsy', 'Breast', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Consent', 'Cytology', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Endocrine', 'Endocrinologist', 'Evaluation', 'Excision', 'Family history of', 'Fine needle aspiration biopsy', 'Follicular thyroid carcinoma', 'Frequencies', 'Gender', 'General Anesthesia', 'Growth', 'Human', 'Image', 'Incidence', 'Individual', 'Lesion', 'Lobectomy', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measurement', 'Measures', 'Methods', 'Modality', 'Neck', 'Nodule', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Palpable', 'Papillary', 'Papillary Carcinoma', 'Participant', 'Patients', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Procedures', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Radiation', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Spectrum Analysis', 'Stratification', 'Surgeon', 'Surgical Pathology', 'System', 'Techniques', 'Technology', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Thyroidectomy', 'Triage', 'Ultrasonography', 'United States', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer risk', 'clinical practice', 'design', 'diagnostic accuracy', 'electric impedance', 'imaging modality', 'improved', 'male', 'malignant breast neoplasm', 'men', 'older women', 'phase change', 'prospective', 'prototype', 'radiologist', 'tool', 'web site']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2011,195019,-0.03588856406995784
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,8133823,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Methodology', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'digital', 'experience', 'falls', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition', 'web services']",NEI,BLINDSIGHT CORPORATION,R44,2011,776548,-0.02127395300525817
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator.  The ultimate goal of this SBIR project is to provide the DOD, DOE, and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. In Phase I, Seacoast successfully demonstrated the feasibility of using a microsensor array with a proprietary trap-and- purge preconcentrator to detect chlorinated solvents, specifically TCE, and TCA, at levels low enough to meet EPA mandated levels for drinking water. In Phase II Seacoast proposes to improve the selectivity and sensitivity of the system to better meet the needs identified by the Phase I consultant. The systems have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator traps the contaminants and releases them to a microsensor array. These sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical.  In Phase II Seacoast will specifically develop new materials to improve the sensor array selectivity, 1) by using impedance spectroscopy to study the mechanisms by which the polymer-based sensors sorb the target chemicals, 2) by implementing pattern recognition algorithms to identify chemicals for the sensor responses, and 3) by designing new preconcentrator materials that can bind these chemicals more strongly.  The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. Potential markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology.      PUBLIC HEALTH RELEVANCE: This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.           This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.         ",Low-Cost Electronic Nose for Groundwater Contaminants,8059710,R44ES016941,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benchmarking', 'Benzene', 'Carcinogens', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Computer software', 'Cost Analysis', 'Cost Savings', 'Data', 'Data Collection', 'Detection', 'Development', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Equation', 'Equipment', 'Evaluation', 'Fingerprint', 'Fluorescence', 'Gases', 'Goals', 'Guidelines', 'Hazardous Waste', 'Industrial Health', 'Intervention', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Maps', 'Marketing', 'Measures', 'Metals', 'Methods', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Pesticides', 'Phase', 'Plants', 'Poison', 'Pollution', 'Polymers', 'Process', 'Public Health', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Route', 'Safety', 'Sampling', 'Science', 'Scientific Advances and Accomplishments', 'Site', 'Small Business Innovation Research Grant', 'Soil', 'Solvents', 'Source', 'Spectrum Analysis', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Time', 'Trichloroethylene', 'Water', 'Wireless Technology', 'Work', 'analytical method', 'base', 'chemical binding', 'cost', 'design', 'detector', 'drinking water', 'electric impedance', 'ground water', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'method development', 'new technology', 'novel', 'operation', 'pollutant', 'programs', 'prototype', 'purge', 'remediation', 'response', 'sensor', 'success', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R44,2011,532144,-0.010898679825758761
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,8123240,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Clinical Research', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost effective', 'digital imaging', 'image archival system', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'two-dimensional', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2011,677070,-0.017399630299465865
"Automated Salivary Gland Dissection for Manufacture of Malaria PfSPZ Vaccine    DESCRIPTION (provided by applicant): Sanaria was founded in 2003 to develop and commercialize an attenuated sporozoite Plasmodium falciparum (Pf) (PfSPZ) vaccine against malaria. Since then Sanaria has established a manufacturing process, manufactured the PfSPZ Vaccine under cGMPs, submitted an investigational new drug application (IND) to the FDA, received clearance from the FDA to proceed to clinical trials, and initiated the first Phase 1 clinical trial to assess safety, immunogenicity, and protective efficacy of SANARIA PfSPZ Vaccine in May 2009. The PfSPZ vaccine is comprised of Pf sporozoites extracted from infected mosquitoes and a short term challenge for Sanaria involves the optimization of this extraction step in its manufacturing process. Currently, human operators manually carry out the critical task of isolating the sporozoites by serially dissecting salivary glands from individual mosquitoes. Sanaria has established this procedure as a reliable, reproducible, consistent, and efficient process. In the next phase of development, as we optimize the efficiency and expand the scale of vaccine manufacturing, automation of mosquito dissection will prove to be beneficial on several fronts. It will enable us to cut the costs of supporting a large taskforce of skilled technicians, the time taken to train and qualify them and the dedicated space necessary for a scaled-up manual operation. Therefore in this SBIR proposal, we focus on successfully developing strategies to mechanize the process of dissection and collection of mosquito salivary glands. In collaboration with the School of Engineering and Applied Sciences at Harvard University we propose to develop novel instrumentation and innovative technologies to meet this goal. These will be addressed in three specific aims in which we will develop procedures that will allow batch processing of mosquitoes to isolate intact salivary glands with minimal manual involvement. This will be achieved using mechanical engineering and physical chemistry principles. First, in specific aim 1 we will create ordered arrays of mosquitoes and in specific aim 2 we will develop methods to decapitate mosquitoes and to extract and collect the salivary glands without losing sporozoites. The technology described here is expected to achieve very high throughput and process scalability. In specific aim 3 we propose a direct substitution of our current dissection configuration with robotic arms and vision guided microscope systems. This serial processing approach will circumvent the need to create mosquito assemblies and involves limited, if any, manual operation. The end-product from the advanced automated techniques however must match or exceed Sanaria's current standards for vaccine yield and potency and will drive the decision to translate our current method of mosquito salivary gland dissection to an automated platform.      PUBLIC HEALTH RELEVANCE: Malaria causes >300 million clinical cases and 1 million deaths annually, is responsible for >1% loss of GDP in Africa annually and is a serious concern for travelers and military personnel. Sanaria's goal is to develop and commercialize a >90% protective malaria vaccine for three primary markets with a potential for >$1 billion annual revenues: 1) Travelers from the developed world to malaria endemic areas. 2) Infants and young children in the developing world. 3) Adolescent girls in the developing world. Success in this Phase I SBIR will lead to a significant increase in the efficiency of manufacture of the PfSPZ Vaccine that will facilitate scale-up of manufacturing and significantly reduce the cost of goods.           PROJECT NARRATIVE Malaria causes >300 million clinical cases and 1 million deaths annually, is responsible for >1% loss of GDP in Africa annually and is a serious concern for travelers and military personnel. Sanaria's goal is to develop and commercialize a >90% protective malaria vaccine for three primary markets with a potential for >$1 billion annual revenues: 1) Travelers from the developed world to malaria endemic areas. 2) Infants and young children in the developing world. 3) Adolescent girls in the developing world. Success in this Phase I SBIR will lead to a significant increase in the efficiency of manufacture of the PfSPZ Vaccine that will facilitate scale-up of manufacturing and significantly reduce the cost of goods.",Automated Salivary Gland Dissection for Manufacture of Malaria PfSPZ Vaccine,8098964,R43AI088963,"['Address', 'Africa', 'Applied Research', 'Area', 'Attenuated', 'Automation', 'Blood capillaries', 'Cessation of life', 'Chest', 'Child', 'Clinical', 'Clinical Trials', 'Collaborations', 'Collection', 'Computer Vision Systems', 'Culicidae', 'Cyclic GMP', 'Development', 'Dissection', 'Engineering', 'Female Adolescents', 'Gland', 'Goals', 'Grant', 'Human', 'Individual', 'Infant', 'Intervention', 'Investigational New Drug Application', 'Lead', 'Malaria', 'Malaria Vaccines', 'Manuals', 'Marketing', 'Mechanics', 'Methods', 'Microscope', 'Military Personnel', 'Pattern', 'Phase', 'Phase I Clinical Trials', 'Physical Chemistry', 'Plasmodium falciparum', 'Positioning Attribute', 'Procedures', 'Process', 'Qualifying', 'Robotics', 'Safety', 'Salivary Glands', 'Schools', 'Small Business Innovation Research Grant', 'Sporozoites', 'Staging', 'Suction', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Translating', 'Universities', 'Vaccines', 'Vision', 'arm', 'capillary', 'cost', 'immunogenicity', 'innovative technologies', 'instrumentation', 'manufacturing process', 'manufacturing scale-up', 'meetings', 'novel', 'operation', 'protective efficacy', 'public health relevance', 'scale up', 'success', 'tool']",NIAID,"SANARIA, INC.",R43,2011,299627,-0.008889907430595865
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis    DESCRIPTION (provided by applicant): All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This application takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.      PUBLIC HEALTH RELEVANCE: This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.           This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.         ",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8192056,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2011,148255,-0.04001872323070544
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7921476,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2010,110591,-0.003500920867051101
"Robust BCT for Clinical Use    DESCRIPTION (provided by applicant): Osteoporosis is a major public health threat for over 50% of the population over age 50. Despite its importance, osteoporosis is largely under-treated, with less than 20% of those recommended for testing being screened. With substantial reimbursement cuts being introduced by Medicare for bone densitometry by dual energy X-ray absorptiometry (DXA, the current clinical standard), with a sensitivity of DXA for fracture prediction of less than 50%, and with the rapidly increasing size of the aging population of the U.S., there is an urgent need for additional and more sensitive modalities than DXA for clinical assessment of fracture risk. Biomechanical Computed Tomography (BCT) has emerged as a powerful alternative to DXA. This CT-based technology creates a structural ""finite element"" model of a patient's bone from their CT scans, and subjects that model to virtual forces in order to provide an estimate of the strength of the bone. Well validated in cadaver studies and being a better predictor of bone strength than is bone mineral density by DXA, BCT has also been shown to be highly predictive of osteoporotic fractures in clinical research studies. However, robustness remains an issue - can the technique be used easily by non-experts in research and clinical environments? Addressing this issue, the overall goal of this research is to improve the robustness of our software, such that it can automatically analyze scans from a wide range of CT scanners and using a wide variety of CT acquisition protocols, including new low-dose protocols that limit radiation exposure to the patient. Such a robust BCT diagnostic tool could then be offered as a supplementary ""add-on"" analysis to many types of CT exams taken for other purposes such as CT colonography, pelvic, abdominal, and spine exams, thus reducing hospital costs, incurring no addition radiation to the patient, requiring no change in the CT acquisition protocols, and therefore greatly increasing the number of patients that could be screened at low cost. Specifically, we propose in this Phase-I project to combine expertise in computer vision, CT scanning, and biomechanics in order to develop an automated method of ""phantomless"" cross-calibration of CT scans for robust vertebral strength assessment. Focusing on the spine, our major tasks are to perform a series of clinical studies in which patients are scanned twice using a variety of CT acquisition protocols; develop a custom external-calibration phantom and use that to determine the effects of various CT acquisition parameters on scanning standardization; and use machine learning techniques to develop a ""statistical atlas"" of the spine for automation of all image processing. We will combine these efforts to develop a phantomless BCT method that accounts for differences in image quality due to variations in CT scanners and acquisition protocols, including low-dose protocols, and that does so in a highly automated fashion requiring minimal user expertise and input. Should this project be successful, future work will further refine the techniques, extend them to the hip and quantitative analysis of muscle and other soft tissues, and address robustness of longitudinal changes for clinical monitoring.  PUBLIC HEALTH RELEVANCE: With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.",Robust BCT for Clinical Use,7902171,R43AR057616,"['Abdomen', 'Accounting', 'Address', 'Adoption', 'Affect', 'Age', 'Aging', 'Algorithms', 'Angiography', 'Atlases', 'Automation', 'Biomechanics', 'Bone Density', 'Businesses', 'Cadaver', 'Calibration', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Densitometry', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Dose', 'Dual-Energy X-Ray Absorptiometry', 'Early identification', 'Economic Burden', 'Elderly', 'Elements', 'Environment', 'Exposure to', 'Fracture', 'Future', 'Goals', 'Growth', 'Guide prevention', 'Healthcare', 'Healthcare Systems', 'Hip Fractures', 'Hip region structure', 'Hospital Costs', 'Image', 'Individual', 'Intervertebral disc structure', 'Low Dose Radiation', 'Lung', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Medicare', 'Methods', 'Minerals', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Muscle', 'Osteoporosis', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Phase', 'Population', 'Postmenopause', 'Protocols documentation', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Risk', 'Scanning', 'Screening procedure', 'Second lumbar vertebra', 'Sensitivity and Specificity', 'Series', 'Societies', 'Standardization', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Tube', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'aging population', 'base', 'bone', 'bone strength', 'cohort', 'cost', 'cost effective', 'image processing', 'improved', 'meetings', 'mortality', 'novel', 'osteoporosis with pathological fracture', 'product development', 'public health relevance', 'reconstruction', 'research study', 'soft tissue', 'spine bone structure', 'tool', 'treatment effect', 'virtual', 'voltage']",NIAMS,"O. N. DIAGNOSTICS, LLC",R43,2010,350000,-0.03419447096333416
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7904837,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2010,1196495,-0.031031299620991784
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,7761085,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2010,463608,0.0036101492246836215
"Camera-based Text Recognition from Complex Backgrounds for the Blind or Visually There are more than 10 million blind and visually impaired people living in America today. Recent technology developments in computer vision, digital cameras, and portable computers make it possible to assist these individuals by developing camera-based products that combine computer vision technology with other existing products.  Although a number of reading assistants have been designed specifically for people who are blind or visually impaired, reading text from complex backgrounds or non-flat surfaces is very challenging and has not yet been successfully addressed. Many everyday tasks involve these challenging conditions, such as reading instructions on vending machines, titles of books aligned on a shelf, instructions on medicine bottles or labels on soup cans.  This proposal focuses on the development of new computer vision algorithms to recognize text from complex backgrounds: 1) from backgrounds with multiple different colors (e.g .. the titles of books lined up on a shelf) and 2) from non-flat surfaces (e.g .. labels on medicine bottles or soup cans). The newly developed computer vision techniques will be integrated with off-the-shelf optical character recognition (OCR) and speech-synthesis software products. Visual information will be captured via a head-mounted camera (on sunglasses or hat) and analyzed by a portable computer (PDA or cell phone), while the speech display will be outputted via mini speakers, earphones, or Bluetooth device. A practical reading system prototype will be produced to read text from complex backgrounds and non-flat surfaces. The system will be cost-effective since it requires only a head mounted camera (<US$100 for 1M resolution), a wearable computer (<US$300), and two mini-speakers or earphones. The price of ""ReadIRlS"" [74] OCR software is under $150 and the ""TextAloud"" speech synthesis software is about $30 [75].  This project will be executed over two years at the City College of New York (CCNY) and Lighthouse International, New York. CCNY, located in the Harlem neighborhood of New York City, is designated as both a Minority Institution and a Hispanic-serving Institution (37% Hispanic and 27% African American). Lighthouse International is a leading non-profit organization dedicated to preserving vision and to providing critically needed vision and rehabilitation services to help people of all ages overcome the challenges of vision loss. During the two years, we will 1) develop new algorithms to recognize text from backgrounds with multiple different colors; 2) develop new algorithms to recognize text from non-flat surfaces; and 3) develop a cost-effective prototype reading system for blind users by integrating with off-the-shelf optical character recognition (OCR) and speech-synthesis software products. The effectiveness of the prototype and algorithms will be evaluated by people with normal vision and people with vision impairment. A database of text on complex backgrounds (multiple colors and non-flat surfaces) will be created for algorithm and system evaluation. The database will be made available to research communities in the areas of computer vision and vision rehabilitation science. In summary, this effort will provide a research-based foundation to inform the design of next generation reading assistants for blind persons, as well as produce a practical prototype to help the blind user read text from complex backgrounds in real-world environments. PROJECT NARRATIVE  The goal of the proposed research is to develop new computer vision algorithms for camera-based text recognition from complex backgrounds and non-flat surfaces, as well as produce a practical reading system prototype in combination with off-the-shelf  optical character recognition (OCR) and speech-synthesis software products, to help blind or visually impaired people read instructions on vending machines, titles of books aligned on a shelf, labels on medicine bottles or soup cans, etc. Visual information will be captured via a head-mounted camera (on sunglasses or hat) and analyzed in realtime through a portable computer, such as a mini laptop or a personal digital assistant (PDA). The speech display will be outputted via mini speakers, earphones, or Bluetooth device.",Camera-based Text Recognition from Complex Backgrounds for the Blind or Visually,7977496,R21EY020990,"['Address', 'African American', 'Age', 'Algorithms', 'Americas', 'Area', 'Blindness', 'Books', 'Cellular Phone', 'Cities', 'Color', 'Communities', 'Complex', 'Computer Systems Development', 'Computer Vision Systems', 'Computer software', 'Computers', 'Databases', 'Development', 'Devices', 'Effectiveness', 'Environment', 'Evaluation', 'Event', 'Facial Expression Recognition', 'Foundations', 'Goals', 'Grant', 'Head', 'Hispanics', 'Image', 'Impairment', 'Individual', 'Institution', 'Instruction', 'International', 'Label', 'Letters', 'Life', 'Mails', 'Marketing', 'Medicine', 'Methods', 'Minority', 'Neighborhoods', 'New York', 'New York City', 'Nonprofit Organizations', 'Output', 'Personal Digital Assistant', 'Price', 'Printing', 'Reading', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Resolution', 'Running', 'Scientist', 'Shapes', 'Solutions', 'Speech', 'Surface', 'System', 'Techniques', 'Technology', 'Text', 'Thick', 'Time', 'United States National Institutes of Health', 'Vertebral column', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Writing', 'base', 'blind', 'college', 'computer generated', 'computer human interaction', 'cost', 'design', 'digital', 'experience', 'laptop', 'next generation', 'optical character recognition', 'prototype', 'rehabilitation science', 'rehabilitation service', 'research and development', 'sunglasses', 'technology development', 'visual information']",NEI,CITY COLLEGE OF NEW YORK,R21,2010,190000,-0.06452284439106151
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7877019,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2010,223070,-0.041935005282968875
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7799708,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'image processing', 'meetings', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'public health relevance', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2010,427932,-0.01908227380197764
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,7940934,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Arts', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'public health relevance', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,356202,-0.02462464663222653
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.       PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.                 Narrative This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Di(R)usion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from di(R)usion MRI scans.",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,7903516,R01NS066340,"['Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Cations', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2010,506525,-0.02397838471747216
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7769507,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2010,420313,-0.014798998932159876
"Non-obtrusive Gait & Fall Monitoring    DESCRIPTION (provided by applicant):  Falls among the elderly, one of the most common reasons requiring medical intervention and a contributing factor in 40% of nursing home admissions, are a major health problem. Several studies have identified quantifiable gait markers that appear to distinguish between elderly ""fallers"" and non-fallers. These studies have relied on data acquired in gait-laboratories. Extending gait assessment capability, and falls detection, into the home could provide valuable before-the-fact information on gait weakness evolution, which in turn could be used to assess the efficiency of counter measures. Current mobile gait analysis techniques are insufficient because they rely on compliance or are too intrusive. The development of a new gait assessment and falls monitor is proposed. The device is passive and obtains gait data from sensing floor vibrations as well as a minimally invasive wireless device, precluding the need to walk on special surfaces or be observed by cameras. This study's principal aim is to validate the device's performance through a comparison with accepted gait assessment techniques at the Physical Medicine and Rehabilitation Gait lab at the University of Virginia Health System   PUBLIC HEALTH RELEVANCE:  An estimated 20% - 40% of community-dwelling elderly fall at least once a year 2 and this rate increases for nursing home residents. Fall-related injuries are among the most common reasons requiring medical intervention and are a contributing factor in 40% of nursing home admissions. The cost of falls to the national economy is significant. In 1994 the total cost due to falls was estimated to be $20.2 billion. This number is expected to climb to $32.2 billion by 2020. One suggestion for reducing the number of falls has been the creation of a fall risk assessment for institutional residents, an important component of which is gait assessment. In view of the results obtained during the Phase I effort, it appears that the floor sensor system may be able to answer a well defined need for which there is presently no other solution that promises to be as readily implementable and for which the market potential is significant.           Non-obtrusive Gait & Fall Monitoring Notice Number: NOT-OD-10-034) Notice Title: NIH Announces the Availability of Recovery Act Funds for Competitive Revision Applications for Small Business Innovation Research and Small Business Transfer Technology Research Grants (R43/R44 and R41/R42) through the NIH Basic Behavioral and Social Science Opportunity Network (OppNet) An estimated 20% - 40% of community-dwelling elderly fall at least once a year 2 and this rate increases for nursing home residents. Fall-related injuries are among the most common reasons requiring medical intervention and are a contributing factor in 40% of nursing home admissions. The cost of falls to the national economy is significant. In 1994 the total cost due to falls was estimated to be $20.2 billion. This number is expected to climb to $32.2 billion by 2020. One suggestion for reducing the number of falls has been the creation of a fall risk assessment for institutional residents, an important component of which is gait assessment. In view of the results obtained during the Phase I effort it appears that the floor sensor system may be able to answer a well defined need for which there is presently no other solution that promises to be as readily implementable and for which the market potential is significant.",Non-obtrusive Gait & Fall Monitoring,8053612,R43AG034698,"['Admission activity', 'Algorithms', 'Businesses', 'Classification', 'Communities', 'Computer Interface', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Elderly', 'Employee Strikes', 'Event', 'Evolution', 'Fingerprint', 'Floor', 'Funding', 'Gait', 'Goals', 'Health', 'Health system', 'Heel', 'Home environment', 'Impaired cognition', 'Individual', 'Injury', 'Intervention', 'Laboratories', 'Left', 'Length', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Mental Depression', 'Methodology', 'Monitor', 'Muscle Weakness', 'Noise', 'Nursing Homes', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physical Medicine', 'Principal Investigator', 'Process', 'Recovery', 'Rehabilitation therapy', 'Research Project Grants', 'Resolution', 'Retirement', 'Retrospective Studies', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Solutions', 'Suggestion', 'Surface', 'System', 'Techniques', 'Technology Transfer', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Ursidae Family', 'Virginia', 'Walkers', 'Walking', 'Wireless Technology', 'Wood material', 'base', 'behavioral/social science', 'comparative', 'cost', 'digital', 'fall risk', 'falls', 'gait examination', 'human subject', 'minimally invasive', 'operation', 'programs', 'prototype', 'response', 'sensor', 'tool', 'transmission process', 'vibration', 'volunteer']",NIA,EMPIRICAL TECHNOLOGIES CORPORATION,R43,2010,113956,-0.016665425520690134
"Spatially Accurate Deformable Image Registration for Thoracic CT Application    DESCRIPTION (Provided by the applicant)   Abstract:  Deformable image registration (DIR) is a cross-cutting technology with diagnostic and therapeutic medical applications. DIR algorithms were first developed in computer vision research to estimate motion between a source and target image, the resulting registered image visually appears similar to the target image. For medical applications the goal in applying DIR is to obtain an accurate spatial registration of the underlying anatomy and not simply image similarity. We developed a statistical framework for quantitative evaluation of DIR spatial accuracy based on large samples of expert-determined landmark features. Central to this framework is the statistical relationship between the number of landmark points required to assess spatial accuracy, the desired uncertainty range of the mean error, and an a priori estimated behavior of the DIR. DIR is at the heart of our strategy to quantify COPD small airway disease air-trapping and four dimensional computed tomography (4D CT) ventilation. The optimal DIR algorithm and its spatial accuracy in registering the underlying anatomy should be assessed for each application. We will develop and test new DIR algorithms for exhale and inhale breath-hold CT (eBH-CT & iBH-CT) images pairs (COPD air trapping evaluation) and for 4D CT images (4D CT ventilation). Current CT image analysis methods for COPD evaluation focus on the separate anatomic evaluation of the eBH-CT & iBH-CT images. They are unable to find air-trapping due to bronchiolitis alone. We propose to evaluate the eBH- & iBH CT image pairs simultaneously using DIR to link the two to identify regions of air-trapping due to both emphysema and bronchiolitis. Next, to continue our development of ventilation imaging derived from 4D CT, we will test the ability of 4D CT ventilation image guidance to reduce pulmonary function loss after radiotherapy in a randomized phase II trial for non-small cell lung cancer patients.   Public Health Relevance:  This study will develop novel image registration methods and their application, with an emphasis on application specific validation. With this technology we will develop and test methods to find air-trapping in chronic obstructive pulmonary disease patients. We will test our novel ventilation imaging method in radiation treatment planning to reduce normal lung injury after treatment for lung cancer.       n/a",Spatially Accurate Deformable Image Registration for Thoracic CT Application,7980382,DP2OD007044,"['Air', 'Algorithms', 'Anatomy', 'Behavior', 'Breathing', 'Bronchiolitis', 'Cancer Patient', 'Chest', 'Chronic Obstructive Airway Disease', 'Computer Vision Systems', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Exhalation', 'Four-dimensional', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Link', 'Medical', 'Methods', 'Motion', 'Non-Small-Cell Lung Carcinoma', 'Phase II Clinical Trials', 'Pulmonary Emphysema', 'Quantitative Evaluations', 'Radiation therapy', 'Randomized', 'Sampling', 'Source', 'Technology', 'Testing', 'Therapeutic', 'Uncertainty', 'Vision research', 'X-Ray Computed Tomography', 'abstracting', 'base', 'image registration', 'pulmonary function', 'small airways disease']",OD,UNIVERSITY OF TX MD ANDERSON CAN CTR,DP2,2010,1645038,-0.053689593885700965
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7941984,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2010,303186,-0.008586282779529658
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,7808779,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'base', 'computerized data processing', 'experience', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2010,1249881,-0.01722351613091436
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,7999420,R44RR024094,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'HIV', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2010,449663,-0.031300177069083834
"Replacement Ocular Battery (ROBatt)    DESCRIPTION (provided by applicant): The objective of this grant project is the development and pre-validation of the Replacement Ocular Battery (ROBatt), a tiered testing strategy consisting of a battery of four alternative ocular irritancy assays, which will replace regulatory mandated acute ocular irritation testing using the Draize Rabbit Eye test. ROBatt consists of the Bovine Corneal Opacity and Permeability Assay (BCOP), the Chorioallantoic Membrane Vascular Assay using 10-day fertile chicken eggs (CAMVA), the Porcine Corneal Reversibility Assay (PorCORA) and the Porcine Confocal Assay (PorFocal). This tiered strategy follows a decision tree that allows for a thorough interrogation of possible ocular irritants. Although four assays are recommended, in most cases only two or three will be used depending on the degree of irritation. The Specific Aim of the ROBatt project is to validate the decision tree variables using at least 50 chemicals listed in the European Center for Ecotoxicology and Toxicology of Chemicals (ECETOC) data bank, including Corrosive (EEC R41, GHS/EPA Cat 1), Severe (EEC R36, GHS CaL 2, HMIS 2), Moderate (EPA Cat. 3, HMIS 2), Mild (HMIS 1) and Non-irritating (EPA Cat 4, HMIS 0). The long-term project goal is to submit the ROBatt testing strategy to iCCVAM/ECVAM for consideration as a standalone alternative to the Draize Rabbit Eye test. Validation and acceptance of the ROBatt testing strategy will significantly reduce the number of rabbits used in the toxicological assessment of consumer products, chemicals and raw materials by replacing rabbits with four robust alternative assays.       PUBLIC HEALTH RELEVANCE: Ocular irritation testing is extremely relevant to assuring adequate safety levels of public health as new formulations of chemicals and products are introduced. In most cases, these safety assessments are performed using the Draize Rabbit Eye test, resulting in thousands of rabbits used in testing every year. Alternatives have been discussed since the 80s without any appreciable acceptance from regulators.           n/a",Replacement Ocular Battery (ROBatt),8068095,U01NS073481,"['Acute', 'Biological Assay', 'Blood Vessels', 'Cattle', 'Chemicals', 'Chickens', 'Cornea', 'Corneal Opacity', 'Corrosives', 'Databases', 'Decision Trees', 'Development', 'Drug Formulations', 'European', 'Eye', 'Family suidae', 'Felis catus', 'Goals', 'Grant', 'Instruction', 'Irritants', 'Oryctolagus cuniculus', 'Permeability', 'Public Health', 'Safety', 'Test Result', 'Testing', 'Toxicology', 'Validation', 'chorioallantoic membrane', 'consumer product', 'egg', 'irritation']",NINDS,"MB RESEARCH LABORATORIES, INC.",U01,2010,562935,-0.018640460901200744
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,7913126,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Businesses', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Methods', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Project Grants', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'design', 'digital', 'experience', 'falls', 'innovation', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition']",NEI,BLINDSIGHT CORPORATION,R44,2010,656703,-0.02127395300525817
"Automated Biodosimetry The Unites States Government and Federal agencies have estimated that over 1 million people may seek information on their personal risk (radiation exposure level), if an event (such as a 10 kiloton detonation of an improvised nuclear device) occurs in a large metropolitan area. There will be a need for immediate triage and rapid cytogenetic biodosimetry for estimation of whole-body dose (<2Gy, 2-4Gy, >4Gy) of individuals within 48 hours, to determine and categorize the exposed cohorts for dose based stratification and effective medical management. Individuals exposed at levels exceeding 2 Gy will need immediate treatment and further evaluation with more sophisticated and precise dosimetry tools (such as devices, bioassays, biomarkers etc) to ascertain their absorbed dose.    Several of these established available assays are very labor intensive (demands skilled personnel; cytogeneticist) and time consuming (days to weeks), which serves to be a bane during a mass-casualty event. Effective medical management, response and treatment to the exposed cohort (within a short time window) can only be maximized and achieved with the aid of robotic tools and automated system. Automated cytogenetic systems can also reduce significant level of human error caused by fatigue due to the magnitude of samples to be processed. The Automated Cytogenetics Laboratory at AFRRI, focuses on automation of various classical biodosimerty assays (Dicentric Chromosomes, Micronuclei, PCC assays etc) to effectively enhance the throughput of sample analysis, thereby medical management. n/a",Automated Biodosimetry,8172179,1OD0505,"['Area', 'Artificial Intelligence', 'Automation', 'Biological Assay', 'Biological Markers', 'Biological Neural Networks', 'Cytogenetics', 'Devices', 'Dicentric chromosome', 'Documentation', 'Dose', 'Evaluation', 'Event', 'Fatigue', 'Hour', 'Human', 'Human Resources', 'Image Analysis', 'Individual', 'Laboratories', 'Medical', 'Metaphase', 'Modeling', 'Nuclear', 'Process', 'Radiation', 'Risk', 'Robotics', 'Sampling', 'State Government', 'Stratification', 'System', 'Systems Analysis', 'Testing', 'Time', 'Triage', 'United States', 'Variant', 'base', 'biodosimetry', 'cohort', 'dosimetry', 'handheld mobile device', 'metropolitan', 'micronucleus', 'tool', 'treatment response']",OD,"OFFICE OF THE DIRECTOR, NATIONAL INSTITUTES OF HEALTH",Y01,2010,698597,-0.008622730838470323
"Computational Photography Project for Pill Identification (C3PI) In a national effort to promote patient safety, the National Library of Medicine (NLM) proposes to create a comprehensive, public digital image inventory of the nation's commercial prescription solid dose medications. The primary intention of this effort is create a test data collection for the advancement of automatic pharmaceutical identification through computer analysis from photographic data. NLM expects to promote computer-based image research applied to the domain of content-based information retrieval (CBIR) of solid-dose pharmaceuticals, and anticipates the need for generating a test environment, including variations of photographs of the same drug or sample under different environments. n/a",Computational Photography Project for Pill Identification (C3PI),8174192,76201000698P,"['Algorithms', 'Collection', 'Color', 'Computer Analysis', 'Computer Vision Systems', 'Computers', 'Data', 'Data Collection', 'Dose', 'Environment', 'Equipment', 'Equipment and supply inventories', 'Image', 'Imagery', 'Information Retrieval', 'Intention', 'Measurement', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Photography', 'Research', 'Resolution', 'Sampling', 'Shapes', 'Solid', 'Structure', 'Surface Properties', 'Testing', 'Text', 'United States National Library of Medicine', 'Variant', 'base', 'digital imaging', 'patient safety', 'pill']",NLM,"MEDICOS CONSULTANTS, LLC",N03,2010,500000,-0.02139053236968007
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7936871,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost', 'digital imaging', 'image archival system', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2010,805328,-0.017399630299465865
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),8136874,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,125017,0.009121105283708719
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),8143048,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,76123,0.009121105283708719
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7876805,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,676574,0.009121105283708719
"Automated Salivary Gland Dissection for Manufacture of Malaria PfSPZ Vaccine    DESCRIPTION (provided by applicant): Sanaria was founded in 2003 to develop and commercialize an attenuated sporozoite Plasmodium falciparum (Pf) (PfSPZ) vaccine against malaria. Since then Sanaria has established a manufacturing process, manufactured the PfSPZ Vaccine under cGMPs, submitted an investigational new drug application (IND) to the FDA, received clearance from the FDA to proceed to clinical trials, and initiated the first Phase 1 clinical trial to assess safety, immunogenicity, and protective efficacy of SANARIA PfSPZ Vaccine in May 2009. The PfSPZ vaccine is comprised of Pf sporozoites extracted from infected mosquitoes and a short term challenge for Sanaria involves the optimization of this extraction step in its manufacturing process. Currently, human operators manually carry out the critical task of isolating the sporozoites by serially dissecting salivary glands from individual mosquitoes. Sanaria has established this procedure as a reliable, reproducible, consistent, and efficient process. In the next phase of development, as we optimize the efficiency and expand the scale of vaccine manufacturing, automation of mosquito dissection will prove to be beneficial on several fronts. It will enable us to cut the costs of supporting a large taskforce of skilled technicians, the time taken to train and qualify them and the dedicated space necessary for a scaled-up manual operation. Therefore in this SBIR proposal, we focus on successfully developing strategies to mechanize the process of dissection and collection of mosquito salivary glands. In collaboration with the School of Engineering and Applied Sciences at Harvard University we propose to develop novel instrumentation and innovative technologies to meet this goal. These will be addressed in three specific aims in which we will develop procedures that will allow batch processing of mosquitoes to isolate intact salivary glands with minimal manual involvement. This will be achieved using mechanical engineering and physical chemistry principles. First, in specific aim 1 we will create ordered arrays of mosquitoes and in specific aim 2 we will develop methods to decapitate mosquitoes and to extract and collect the salivary glands without losing sporozoites. The technology described here is expected to achieve very high throughput and process scalability. In specific aim 3 we propose a direct substitution of our current dissection configuration with robotic arms and vision guided microscope systems. This serial processing approach will circumvent the need to create mosquito assemblies and involves limited, if any, manual operation. The end-product from the advanced automated techniques however must match or exceed Sanaria's current standards for vaccine yield and potency and will drive the decision to translate our current method of mosquito salivary gland dissection to an automated platform.      PUBLIC HEALTH RELEVANCE: Malaria causes >300 million clinical cases and 1 million deaths annually, is responsible for >1% loss of GDP in Africa annually and is a serious concern for travelers and military personnel. Sanaria's goal is to develop and commercialize a >90% protective malaria vaccine for three primary markets with a potential for >$1 billion annual revenues: 1) Travelers from the developed world to malaria endemic areas. 2) Infants and young children in the developing world. 3) Adolescent girls in the developing world. Success in this Phase I SBIR will lead to a significant increase in the efficiency of manufacture of the PfSPZ Vaccine that will facilitate scale-up of manufacturing and significantly reduce the cost of goods.           PROJECT NARRATIVE Malaria causes >300 million clinical cases and 1 million deaths annually, is responsible for >1% loss of GDP in Africa annually and is a serious concern for travelers and military personnel. Sanaria's goal is to develop and commercialize a >90% protective malaria vaccine for three primary markets with a potential for >$1 billion annual revenues: 1) Travelers from the developed world to malaria endemic areas. 2) Infants and young children in the developing world. 3) Adolescent girls in the developing world. Success in this Phase I SBIR will lead to a significant increase in the efficiency of manufacture of the PfSPZ Vaccine that will facilitate scale-up of manufacturing and significantly reduce the cost of goods.",Automated Salivary Gland Dissection for Manufacture of Malaria PfSPZ Vaccine,7911011,R43AI088963,"['Address', 'Africa', 'Applied Research', 'Area', 'Attenuated', 'Automation', 'Blood capillaries', 'Cessation of life', 'Chest', 'Child', 'Clinical', 'Clinical Trials', 'Collaborations', 'Collection', 'Computer Vision Systems', 'Culicidae', 'Development', 'Dissection', 'Engineering', 'Female Adolescents', 'Gland', 'Goals', 'Grant', 'Human', 'Individual', 'Infant', 'Intervention', 'Investigational New Drug Application', 'Lead', 'Malaria', 'Malaria Vaccines', 'Manuals', 'Marketing', 'Mechanics', 'Methods', 'Microscope', 'Military Personnel', 'Pattern', 'Phase', 'Phase I Clinical Trials', 'Physical Chemistry', 'Plasmodium falciparum', 'Positioning Attribute', 'Procedures', 'Process', 'Qualifying', 'Robotics', 'Safety', 'Salivary Glands', 'Schools', 'Small Business Innovation Research Grant', 'Sporozoites', 'Staging', 'Suction', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Translating', 'Universities', 'Vaccines', 'Vision', 'arm', 'capillary', 'cost', 'immunogenicity', 'innovative technologies', 'instrumentation', 'manufacturing process', 'manufacturing scale-up', 'meetings', 'novel', 'operation', 'protective efficacy', 'public health relevance', 'scale up', 'success', 'tool']",NIAID,"SANARIA, INC.",R43,2010,299989,-0.008889907430595865
"Assisting Systematic Review Preparation Using Automated Document Classification    DESCRIPTION (provided by applicant):       The work proposed in this new investigator initiated project studies the hypothesis that machine learning-based text classification techniques can add significant efficiencies to the process of updating systematic reviews (SRs). Because new information constantly becomes available, medicine is constantly changing, and SRs must undergo periodic updates in order to correctly represent the best available medical knowledge at a given time.       To support studying this hypothesis, the work proposed here will undertake four specific aims:   1. Refinement and further development of text classification algorithms optimized for use in classifying   literature for the update of systematic reviews on a variety of therapeutic domains. Comparative analysis using several different machine learning techniques and strategies will be studied, as well as various means of representing the journal articles as feature vectors input to the process.   2. Identification and evaluation of systematic review expert preferences and trade offs between high recall and high precision classification systems. There are several opportunities for including this technology in the process of creating SRs. Each of these applications has separate and unique precision and recall tradeoff thresholds that will be studied based on the benefit to systematic reviews.   3. Prospective evaluation of text classification algorithms. We will verify that our approach performs as   expected on future data.   4. Development of comprehensive gold standard test and training sets to motivate and evaluate the   proposed and future work in this area.      The long term relevance of this research to public health is that automated document classification will   enable more efficient use of expert resources to create systematic reviews. This will increase both the   number and quality of reviews for a given level of public support. Since up-to-date systematic reviews are essential for establishing widespread high quality practice standards and guidelines, the overall public health will benefit from this work.          n/a",Assisting Systematic Review Preparation Using Automated Document Classification,7664538,R01LM009501,"['Algorithms', 'Area', 'Classification', 'Data', 'Data Set', 'Development', 'Evaluation', 'Future', 'Gold', 'Guidelines', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Paper', 'Performance', 'Preparation', 'Process', 'Public Health', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Time', 'Training', 'Triage', 'Update', 'Work', 'base', 'comparative', 'expectation', 'journal article', 'preference', 'programs', 'prospective', 'systematic review', 'text searching', 'vector']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2009,318898,-0.03514123603073276
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7739714,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2009,104963,-0.003500920867051101
"Robust BCT for Clinical Use    DESCRIPTION (provided by applicant): Osteoporosis is a major public health threat for over 50% of the population over age 50. Despite its importance, osteoporosis is largely under-treated, with less than 20% of those recommended for testing being screened. With substantial reimbursement cuts being introduced by Medicare for bone densitometry by dual energy X-ray absorptiometry (DXA, the current clinical standard), with a sensitivity of DXA for fracture prediction of less than 50%, and with the rapidly increasing size of the aging population of the U.S., there is an urgent need for additional and more sensitive modalities than DXA for clinical assessment of fracture risk. Biomechanical Computed Tomography (BCT) has emerged as a powerful alternative to DXA. This CT-based technology creates a structural ""finite element"" model of a patient's bone from their CT scans, and subjects that model to virtual forces in order to provide an estimate of the strength of the bone. Well validated in cadaver studies and being a better predictor of bone strength than is bone mineral density by DXA, BCT has also been shown to be highly predictive of osteoporotic fractures in clinical research studies. However, robustness remains an issue - can the technique be used easily by non-experts in research and clinical environments? Addressing this issue, the overall goal of this research is to improve the robustness of our software, such that it can automatically analyze scans from a wide range of CT scanners and using a wide variety of CT acquisition protocols, including new low-dose protocols that limit radiation exposure to the patient. Such a robust BCT diagnostic tool could then be offered as a supplementary ""add-on"" analysis to many types of CT exams taken for other purposes such as CT colonography, pelvic, abdominal, and spine exams, thus reducing hospital costs, incurring no addition radiation to the patient, requiring no change in the CT acquisition protocols, and therefore greatly increasing the number of patients that could be screened at low cost. Specifically, we propose in this Phase-I project to combine expertise in computer vision, CT scanning, and biomechanics in order to develop an automated method of ""phantomless"" cross-calibration of CT scans for robust vertebral strength assessment. Focusing on the spine, our major tasks are to perform a series of clinical studies in which patients are scanned twice using a variety of CT acquisition protocols; develop a custom external-calibration phantom and use that to determine the effects of various CT acquisition parameters on scanning standardization; and use machine learning techniques to develop a ""statistical atlas"" of the spine for automation of all image processing. We will combine these efforts to develop a phantomless BCT method that accounts for differences in image quality due to variations in CT scanners and acquisition protocols, including low-dose protocols, and that does so in a highly automated fashion requiring minimal user expertise and input. Should this project be successful, future work will further refine the techniques, extend them to the hip and quantitative analysis of muscle and other soft tissues, and address robustness of longitudinal changes for clinical monitoring.  PUBLIC HEALTH RELEVANCE: With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.",Robust BCT for Clinical Use,7747873,R43AR057616,"['Abdomen', 'Accounting', 'Address', 'Adoption', 'Affect', 'Age', 'Aging', 'Algorithms', 'Angiography', 'Atlases', 'Automation', 'Biomechanics', 'Bone Density', 'Businesses', 'Cadaver', 'Calibration', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Densitometry', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Dose', 'Dual-Energy X-Ray Absorptiometry', 'Early identification', 'Economic Burden', 'Elderly', 'Elements', 'Environment', 'Exposure to', 'Fracture', 'Future', 'Goals', 'Growth', 'Guide prevention', 'Healthcare', 'Healthcare Systems', 'Hip Fractures', 'Hip region structure', 'Hospital Costs', 'Image', 'Individual', 'Intervertebral disc structure', 'Low Dose Radiation', 'Lung', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Medicare', 'Methods', 'Minerals', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Muscle', 'Osteoporosis', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Phase', 'Population', 'Postmenopause', 'Protocols documentation', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Risk', 'Scanning', 'Screening procedure', 'Second lumbar vertebra', 'Sensitivity and Specificity', 'Series', 'Societies', 'Standardization', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Tube', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'aging population', 'base', 'bone', 'bone strength', 'cohort', 'cost', 'cost effective', 'image processing', 'improved', 'meetings', 'mortality', 'novel', 'osteoporosis with pathological fracture', 'product development', 'public health relevance', 'reconstruction', 'research study', 'soft tissue', 'spine bone structure', 'tool', 'treatment effect', 'virtual', 'voltage']",NIAMS,"O. N. DIAGNOSTICS, LLC",R43,2009,350000,-0.03419447096333416
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7668573,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,1187062,-0.031031299620991784
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7922310,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,152260,-0.031031299620991784
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7664924,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2009,225323,-0.041935005282968875
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator. Seacoast's Phase I research will focus on developing the sensor array, demonstrating sensitivity to chlorinated hydrocarbons at relevant concentrations, and field tests in actual contaminated sites. The ultimate goal is to provide the DOD, DOE, NIEHS and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. The systems will have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator collects the contaminants and releases them to a microsensor array. The sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical. An array of differently responding sensors and pattern recognition can thereby compensate for changes in humidity, temperature, and composition. These low-power systems can be left unattended and transmit data wirelessly or through USB to a central location. The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. The potential commercial markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology. PUBLIC HEALTH RELEVANCE: This proposal will describe a potential method to specifically address the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.          n/a",Low-Cost Electronic Nose for Groundwater Contaminants,7847964,R43ES016941,"['Address', 'Algorithms', 'Characteristics', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Data', 'Data Collection', 'Detection', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Feedback', 'Fingerprint', 'Fluorescence', 'Goals', 'Humidity', 'Industrial Health', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Location', 'Machine Learning', 'Maps', 'Marketing', 'Measures', 'Methods', 'Modification', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Phase', 'Poison', 'Polymers', 'Process', 'Public Health', 'Pump', 'ROC Curve', 'Recommendation', 'Research', 'Risk', 'Safety', 'Sampling', 'Science', 'Simulate', 'Site', 'Soil', 'Solutions', 'Source', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Trichloroethylene', 'Water', 'Work', 'aqueous', 'base', 'cold temperature', 'computerized data processing', 'cost', 'cost effectiveness', 'design', 'detector', 'drinking water', 'ground water', 'innovation', 'membrane assembly', 'pollutant', 'prototype', 'public health relevance', 'remediation', 'response', 'sensor', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R43,2009,11376,-0.018319705421712667
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7589644,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'image processing', 'meetings', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'public health relevance', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2009,426946,-0.01908227380197764
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,7730229,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Arts', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'public health relevance', 'response']",NEI,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2009,391450,-0.02462464663222653
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7837005,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,229517,-0.014798998932159876
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7585774,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,411032,-0.014798998932159876
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,7616844,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'base', 'computerized data processing', 'experience', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2009,1255061,-0.01722351613091436
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7804332,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2009,363247,-0.008586282779529658
"DEVELOPMENT OF SOFTWARE SYSTEMS TO FACILITATE THE USE OF ELECTRONIC DATA RECORDS The objective of this project is to build a commercially-viable automated system to identify records required for population-based cancer surveillance and extract from them specific data elements and their values. The system is to express the elements and values in standard nomenclatures and transmit them to defined destinations. A prototype system using artificial intelligence techniques has been successfully developed to extract reports of CNS neoplasms from CT and MRI reports. During this project that prototype wi1J be extended to receive reports for a second cancer site and to incorporate MRI-F and PET reports. The revised prototype will be implemented in four production environments, transmitting to three central registries. The reports wilt be processed by the software and also manually reviewed by a team of expert CTR's. Results will be compared and the software will be improved to achieve sensitivity and specificity goals in the 98-99% range. The benefits to central cancer registries will be measured in terms of case ascertainment, level of effort and timeliness. A marketing effort will be launched to determine the commercial viability and identify customers for the software. Post Phase II, other lexicons will be added to process other cancer sites found through MRI/CT/PET/F-MRI techniques. n/a",DEVELOPMENT OF SOFTWARE SYSTEMS TO FACILITATE THE USE OF ELECTRONIC DATA RECORDS,7952603,61200900040C,[' '],NCI,QUANTUMMARK LLC,N44,2009,749996,-0.0776290823707069
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7563977,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug candidate', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2009,355016,-0.0847103157653044
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7915039,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2009,168580,0.009121105283708719
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7643324,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2009,815277,0.009121105283708719
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7686733,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2009,819428,-0.017399630299465865
"Assisting Systematic Review Preparation Using Automated Document Classification    DESCRIPTION (provided by applicant):       The work proposed in this new investigator initiated project studies the hypothesis that machine learning-based text classification techniques can add significant efficiencies to the process of updating systematic reviews (SRs). Because new information constantly becomes available, medicine is constantly changing, and SRs must undergo periodic updates in order to correctly represent the best available medical knowledge at a given time.       To support studying this hypothesis, the work proposed here will undertake four specific aims:   1. Refinement and further development of text classification algorithms optimized for use in classifying   literature for the update of systematic reviews on a variety of therapeutic domains. Comparative analysis using several different machine learning techniques and strategies will be studied, as well as various means of representing the journal articles as feature vectors input to the process.   2. Identification and evaluation of systematic review expert preferences and trade offs between high recall and high precision classification systems. There are several opportunities for including this technology in the process of creating SRs. Each of these applications has separate and unique precision and recall tradeoff thresholds that will be studied based on the benefit to systematic reviews.   3. Prospective evaluation of text classification algorithms. We will verify that our approach performs as   expected on future data.   4. Development of comprehensive gold standard test and training sets to motivate and evaluate the   proposed and future work in this area.      The long term relevance of this research to public health is that automated document classification will   enable more efficient use of expert resources to create systematic reviews. This will increase both the   number and quality of reviews for a given level of public support. Since up-to-date systematic reviews are essential for establishing widespread high quality practice standards and guidelines, the overall public health will benefit from this work.          n/a",Assisting Systematic Review Preparation Using Automated Document Classification,7468470,R01LM009501,"['Algorithms', 'Area', 'Classification', 'Data', 'Data Set', 'Development', 'Evaluation', 'Future', 'Gold', 'Guidelines', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Numbers', 'Paper', 'Performance', 'Preparation', 'Process', 'Public Health', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Review, Systematic (PT)', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Time', 'Training', 'Triage', 'Update', 'Work', 'base', 'comparative', 'expectation', 'journal article', 'preference', 'programs', 'prospective', 'text searching', 'vector']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2008,286582,-0.03514123603073276
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7500697,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2008,1146026,-0.031031299620991784
"Diagnostic Innovations in Glaucoma: Clinical Electrophysiology    DESCRIPTION (provided by applicant): This application proposes to investigate the diagnostic precision for detecting glaucoma of clinical electrophysiological measurement (pattern electroretinogram, PERG; and multifocal visual evoked potentials, mfVEP), a technique identified as an important recent glaucoma- related development in eye research by the 2004 National Eye Institute (NEI) National Plan. Aim 1: Electrophysiological responses will be characterized in glaucoma, suspect and healthy eyes and the diagnostic accuracy of these commercially available techniques will be compared to current reference standards (evaluation of stereoscopic photographs of the optic disc and standard automated perimetry) and to recently developed diagnostic techniques including optical imaging of the optic disc and retinal nerve fiber layer (RNFL) (confocal scanning laser ophthalmoscopy, optical coherence tomography, and scanning laser polarimetry) and visual function-specific perimetry (short-wavelength automated perimetry and frequency doubling technology perimetry). Aim 2: Novel use of machine learning classifier techniques (e.g. relevance vector machines, support vector machines, mixture of Gaussian techniques, independent components analysis) will be applied to electrophysiological data to improve its diagnostic accuracy and data from different diagnostic techniques (named above) will be combined to improve overall diagnostic accuracy. Aim 3: Electrophysiological measurements will be validated as functional indicators of optic nerve damage by examining the relationship between electrophysiological abnormality and optic disc and RNFL damage in glaucoma and glaucoma suspect patients. 210 patients (105 glaucoma's, 105 glaucoma suspects) and 105 healthy participants will be enrolled and studied cross-sectionally. The specific aims of this proposal address the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset, determining functional correlates of optic nerve damage, and characterizing glaucomatous neurodegeneration within the visual pathways at structural and functional levels. Information about the relative usefulness of electrophysiological measurement, optical imaging techniques, and ganglion cell-specific perimetry for glaucoma detection is important to the clinical community for determining future evidence-based changes in standard of care for glaucoma diagnosis and monitoring. These studies will demonstrate the relative usefulness of electrophysiological measurement (pattern electroretinogram, PERG; multi-focal visual evoked potential, mfVEP) compared to optical imaging techniques (confocal scanning ophthalmoscopy, optical coherence tomography, scanning laser polarimetry) and ganglion cell-specific perimetry (short wavelength and frequency doubling perimetry) for glaucoma detection. The proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset, determining functional correlates of optic nerve damage, and characterizing glaucomatous neurodegeneration within the visual pathways at structural and functional levels. Findings will be important to the clinical community for determining future evidence-based changes in standard of care for glaucoma diagnosis and monitoring.                n/a",Diagnostic Innovations in Glaucoma: Clinical Electrophysiology,7452327,R21EY018190,"['Address', 'California', 'Caring', 'Clinical', 'Communities', 'Data', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electrophysiology (science)', 'Electroretinography', 'Enrollment', 'Evaluation', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Image', 'Imaging Techniques', 'Individual', 'Investigation', 'Lasers', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Names', 'National Eye Institute', 'Nerve Degeneration', 'Onset of illness', 'Ophthalmoscopy', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Pattern', 'Perimetry', 'Peripheral', 'Personal Satisfaction', 'Photography', 'Psychophysiology', 'Range', 'Reference Standards', 'Relative (related person)', 'Research', 'Retinal', 'Scanning', 'Scotoma', 'Sensitivity and Specificity', 'Severities', 'Standards of Weights and Measures', 'Structure', 'Suspect Glaucomas', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual', 'Visual Pathways', 'Visual evoked cortical potential', 'base', 'design', 'diagnostic accuracy', 'ganglion cell', 'improved', 'independent component analysis', 'innovation', 'novel', 'novel diagnostics', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'response', 'retinal nerve fiber layer', 'stereoscopic', 'vector']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2008,189263,-0.039149620104473586
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7596500,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Numbers', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'desire', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'size', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2008,225323,-0.041935005282968875
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator. Seacoast's Phase I research will focus on developing the sensor array, demonstrating sensitivity to chlorinated hydrocarbons at relevant concentrations, and field tests in actual contaminated sites. The ultimate goal is to provide the DOD, DOE, NIEHS and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. The systems will have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator collects the contaminants and releases them to a microsensor array. The sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical. An array of differently responding sensors and pattern recognition can thereby compensate for changes in humidity, temperature, and composition. These low-power systems can be left unattended and transmit data wirelessly or through USB to a central location. The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. The potential commercial markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology. PUBLIC HEALTH RELEVANCE: This proposal will describe a potential method to specifically address the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.          n/a",Low-Cost Electronic Nose for Groundwater Contaminants,7537117,R43ES016941,"['Address', 'Algorithms', 'Characteristics', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Compatible', 'Condition', 'Data', 'Data Collection', 'Detection', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Feedback', 'Fingerprint', 'Fluorescence', 'Goals', 'Humidity', 'Industrial Health', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Location', 'Machine Learning', 'Maps', 'Marketing', 'Measures', 'Methods', 'Modification', 'Monitor', 'Nose', 'Numbers', 'Pattern Recognition', 'Phase', 'Poison', 'Polymers', 'Process', 'Public Health', 'Pump', 'ROC Curve', 'Range', 'Rate', 'Recommendation', 'Research', 'Risk', 'Safety', 'Sampling', 'Science', 'Simulate', 'Site', 'Soil', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Trichloroethylene', 'Water', 'Work', 'aqueous', 'base', 'cold temperature', 'computerized data processing', 'cost', 'cost effectiveness', 'design', 'detector', 'drinking water', 'ground water', 'innovation', 'membrane assembly', 'pollutant', 'prototype', 'remediation', 'response', 'sensor', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R43,2008,97690,-0.018319705421712667
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7480255,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2008,89733,-0.01921883892225529
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7446299,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Count', 'Custom', 'Daily', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Public Health', 'Range', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Standards of Weights and Measures', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'desire', 'image processing', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2008,421791,-0.01908227380197764
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7496032,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2008,189850,-0.004608689142215958
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,7316099,R01DC005241,"['Affect', 'Algorithms', 'Archives', 'Area', 'Articulators', 'Behavior', 'Child', 'Code', 'Communication', 'Computer Systems Development', 'Computer Vision Systems', 'Computers', 'Data', 'Databases', 'Development', 'Education', 'Educational process of instructing', 'Emotions', 'Equipment and supply inventories', 'Face', 'Facial Expression', 'Future', 'Goals', 'Guidelines', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Image', 'Individual', 'Investigation', 'Joints', 'Learning', 'Life', 'Lighting', 'Linguistics', 'Manuals', 'Modeling', 'Modification', 'Nightmare', 'Parents', 'Pattern Recognition', 'Population', 'Preparation', 'Process', 'Regulation', 'Research Design', 'Semantics', 'Series', 'Sign Language', 'Social Interaction', 'Speech', 'Stimulus', 'Structure', 'System', 'Testing', 'Translations', 'Trees', 'Work', 'computerized data processing', 'computerized tools', 'direct application', 'innovation', 'native American sign language', 'phonology', 'practical application', 'research study', 'syntax', 'teacher']",NIDCD,PURDUE UNIVERSITY,R01,2008,476784,-0.013450546890939039
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7355521,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Class', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Pliability', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Score', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'desire', 'experience', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2008,431744,-0.014798998932159876
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,7409622,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic Models', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Localized', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Range', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'USA Georgia', 'Western Asia Georgia', 'base', 'computerized data processing', 'experience', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2008,1249160,-0.01722351613091436
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7405144,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Numbers', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Range', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2008,394557,-0.0847103157653044
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): The proposed Clinical Cytometry Analysis Software Project described in this grant application is designed to create a new, more efficient and effective way of analyzing cells for the presence of cancer, HIV/AIDS and other disease, using a fully automated software system. Using modern data mining techniques (pattern recognition, feature recognition, image analysis) we will design software which will analyze data (the cell samples from patients) at a much faster rate and with fewer false positives and negatives than the manual method now in use. Objectives: Assemble and validate algorithms in software that can automatically classify regions of interest in flow cytometry data. We will demonstrate that the particular populations required by our use cases can be validly, rigorously and repeatably identified automatically. Develop and validate graphical and statistical results that satisfy FDA requirements for medical device software, simplify regulatory compliance by the clinical user, and automatically deliver analysis results to diagnostic expert systems and/or LIMS systems. Satisfy the  translational medicine  goals outlined in the NIH Roadmap. This software will bring the clinician streamlined testing currently only available in research labs. Methods: Four use cases have been selected, one employing synthetic data and three clinical data; Leukemia/Lymphoma test, Analysis of longitudinal Graft vs. Host Disease (GvHD) in bone marrow transplant specimens for predictive markers and HIV/AIDS - Gag-specific T cell cytokine response profile assay. For each we have access to a substantial body of existing data, analyzed by experts. Beginning with the autogating routines in our own FlowJo software, we will test and expand the application of Magnetic gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural and Support Vector Machines (SVM). Using a sampling of human operators to establish a control range, we will test each of these five techniques against the four use cases in cooperation with our collaborators. Events in the manually classified samples are given a weighted score based on the frequency with which they are included by all the operators. A single operator's score or the gating algorithm's score is compared with the cumulative score of the expert group and a match rating is computed. Additional validation techniques include combinatory validation on internal measures with respect to Pareto optimality, and Predictive Power/Stability self consistency checks using resampled or perturbed data measured with external indices such as the adjusted Rand index and the Variation of Information index.  PUBLIC HEALTH RELEVANCE: By eliminating the operator's time, we estimate that the cost of clinical flow cytometry analysis can be reduced to half the current figure while delivering the results much faster. By eliminating the subjectivity and human error of manually created regions and reducing the range of variability of the so created, there would result fewer false positives and false negatives, improving the clinical outcome for those patients needing therapy but undetected by current methods. An order of magnitude increase in speed means faster therapeutic intervention.  A less expensive test improves outcome by making the test accessible to more patients.          n/a",Clinical Cytometry Analysis Software with Automated Gating,7482923,R43RR024094,"['AIDS/HIV problem', 'Algorithms', 'Applications Grants', 'B-Lymphocytes', 'Biological Assay', 'Biological Neural Networks', 'Bone Marrow Transplantation', 'Cells', 'Characteristics', 'Class', 'Classification', 'Clinical', 'Clinical Data', 'Cluster Analysis', 'Complex', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cytometry', 'Data', 'Data Analyses', 'Data Files', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Educational process of instructing', 'Environment', 'Evaluation', 'Event', 'Expert Systems', 'Facility Construction Funding Category', 'Flow Cytometry', 'Frequencies', 'Funding', 'Future', 'Gagging', 'Generations', 'Goals', 'Grant', 'Graph', 'Human', 'Image Analysis', 'Individual', 'Instruction', 'Knowledge', 'Legal patent', 'Life Cycle Stages', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Noise', 'Numbers', 'Outcome', 'Output', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Population', 'Probability', 'Process', 'Public Health', 'Publishing', 'Range', 'Rate', 'Regulation', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Scientist', 'Score', 'Software Design', 'Software Engineering', 'Software Tools', 'Solutions', 'Specific qualifier value', 'Specimen', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'T-Lymphocyte', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tube', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Voting', 'Weight', 'base', 'clinical Diagnosis', 'commercialization', 'cost', 'cytokine', 'data mining', 'design', 'improved', 'indexing', 'innovation', 'interest', 'leukemia/lymphoma', 'novel', 'predictive modeling', 'relating to nervous system', 'research study', 'response', 'software systems', 'statistics', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R43,2008,100854,-0.01941369320091545
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7665248,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2008,80289,0.009121105283708719
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7489821,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2008,1042528,0.009121105283708719
"Webcam Interface for Audio/touch Graphics Access by Blind People    DESCRIPTION (provided by applicant):  The goal of this project is to develop a compact inexpensive alternative to the bulky expensive touchpads now required by blind people for audio/touch access to graphical information. Audio/touch is known to provide excellent access to computer-literate blind people as well as people with dyslexia or other severe print disabilities. Preparing Audio/touch materials was very expensive until ViewPlus introduced the IVEO Scalable Vector Graphic (SVG) Authoring/conversion software in 2005. IVEO permits virtually any graphical information to be created or converted/imported easily to a well- structured highly accessible SVG format. Tactile copy was also very expensive before 2000 when ViewPlus introduced the Tiger embossing Windows printers that ""print"" by embossing. The new ViewPlus Emprint printer/embossers emboss and also print color images, creating color tactile images particularly useful for people with dyslexia and a number of other print disabilities. An audio/touch user reads an IVEO SVG graphic using the free IVEO Viewer, a tactile copy of the image, and a touchpad. The user places the tactile graphic on the touchpad and presses a point of interest. The touchpad communicates the position of that point back to the computer, and the IVEO Viewer speaks the appropriate information. Tactile text made from mainstream graphics has a distinctive pattern. When a user presses, that text is spoken by the IVEO Viewer. When the user presses a graphic object having a SVG title within the file, that title will be spoken. Objects may also have arbitrarily long description fields that can be spoken and browsed. All spoken information can be displayed on an attached braille display if desired. Graphical information is ubiquitous today, but almost none is accessible to blind people. Government agencies, libraries, companies, and agencies serving people with disabilities could easily send highly accessible IVEO graphics files and tactile graphic copies to clients with disabilities, but there is a ""chicken and egg"" dilemma that must be overcome before they are likely to do so. Few blind people have a touchpad (which cost $500 or more), so few could use that information. The specific aim of this Phase I proposal is to develop an affordable webcam-based prototype as an alternative to touchpads. It is based on an inexpensive webcam that is focused on the graphic and follows a finger. A touchpad press is emulated in this prototype by pressing some computer key with the other hand. This project could be the key to bringing accessible graphics to all blind computer users and is clearly of interest to NEI whose mission statement includes mental health and quality of life of blind people. PUBLIC HEALTH RELEVANCE:  This proposal is relevant to the mission of the National Eye Institute, because it could be the key to making nearly all graphical information easily accessible to people who are blind or have other severe print disabilities. Graphical information is ubiquitous in the world today but is not presently accessible to blind people except through expensive and time-consuming conversion by trained transcribers. Making all graphical information accessible would have an obviously highly beneficial direct effect on education and professional opportunities, mental health, and quality of life of blind people. Mental health and quality of life issues for blind people are parts of the mission of the National Eye Institute.          n/a",Webcam Interface for Audio/touch Graphics Access by Blind People,7480812,R43EY018973,"['Back', 'Braille Display', 'Businesses', 'Chickens', 'Client', 'Color', 'Communities', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consultations', 'Development', 'Devices', 'Disabled Persons', 'Dyslexia', 'Event', 'Fingers', 'Goals', 'Government Agencies', 'Hand', 'Home environment', 'Image', 'Information Systems', 'Institution', 'Internet', 'Libraries', 'Link', 'Mainstreaming', 'Marketing', 'Mental Health', 'Methods', 'Mission', 'Modeling', 'Mus', 'National Eye Institute', 'Numbers', 'Oregon', 'Pattern', 'Phase', 'Positioning Attribute', 'Printing', 'Professional Education', 'Public Health', 'Publications', 'Quality of life', 'Range', 'Reading', 'Site', 'Structure', 'Structure of nail of finger', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Text', 'Tigers', 'Time', 'Title', 'Today', 'Touch sensation', 'Training', 'Universities', 'Visual', 'Visually Impaired Persons', 'base', 'blind', 'braille', 'cost', 'desire', 'digital', 'disability', 'egg', 'interest', 'literate', 'print disabilities', 'programs', 'prototype', 'research and development', 'tool', 'touchpad', 'vector']",NEI,"VIEWPLUS TECHNOLOGIES, INC.",R43,2008,100001,-0.009399494027619627
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7494022,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Compatible', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Condition', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Numbers', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'computerized', 'cost', 'day', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2008,856688,-0.017399630299465865
"Indoor Magnetic Wayfinding For The Visually Impaired    DESCRIPTION (provided by applicant): Advanced Medical Electronics (AME) proposes the development of an indoor way-finding device utilizing the unique magnetic anomaly patterns that exist in modern, man-made structures. The proposed system will record the magnitude of magnetic field strength from sensors in three orthogonal axes. The time history of these magnetic data points can be continuously compared with an electronic map of magnetic anomalies (or, ""signature"") to determine current position within a building. The phase I developed prototype system tracked in feasibility experiments with an accuracy of 1 foot (radius). Magnetic anomalies render a magnetic compass useless for finding a directional bearing. However, these same invisible anomalies represent valuable, unique indoor terrain features measurable by magnetic sensors located inside a small, portable device. Such a device would be able to provide low-vision users with a valuable indoor low-cost way-finding tool analogous to a Global Positioning System (GPS) device used outdoors. About 3.7 million Americans are visually disabled. Of these, 200,000 are blind, and the rest have low vision. The key advantage of the way-finding concept presented in this proposal, over other methods, is that the benefits are made available to the visually impaired community without requiring expensive building infrastructure investments. This is of particular advantage to large government buildings and educational campuses. The proposed approach allows a cost effective solution to way-finding within these buildings.          n/a",Indoor Magnetic Wayfinding For The Visually Impaired,7477498,R44EY015616,"['American', 'Appointment', 'Building Codes', 'Cognition', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Development', 'Devices', 'Disabled Persons', 'Doctor of Philosophy', 'Education', 'Electronics', 'Engineering', 'Fee-for-Service Plans', 'Funding', 'Government', 'Hand', 'Housing', 'Human', 'Indoor Magnetic Wayfinding', 'Investments', 'Joints', 'Label', 'Location', 'Magnetism', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Medical Electronics', 'Minnesota', 'Modeling', 'Modification', 'Neurosciences', 'Numbers', 'Oceans', 'Pattern', 'Pattern Recognition', 'Pennsylvania', 'Persons', 'Phase', 'Population', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychology', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Rest', 'Services', 'Silicon Dioxide', 'Solutions', 'Somatotype', 'Speech', 'Steel', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Today', 'Universities', 'Vision', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Wireless Technology', 'World Health Organization', 'base', 'blind', 'college', 'computer science', 'concept', 'cost', 'cost effective', 'court', 'design', 'digital', 'foot', 'human subject', 'innovation', 'interest', 'magnetic field', 'miniaturize', 'motor control', 'performance tests', 'professor', 'prototype', 'radius bone structure', 'research study', 'sensor', 'sensory integration', 'tool', 'way finding']",NEI,ADVANCED MEDICAL ELECTRONICS CORPORATION,R44,2008,365248,0.0051715322536526375
"Development and Dissemination of Robust Brain MRI Measurement Tools    DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: This application responds to RFA: PAR-07-249, ""Collaborations with National Centers for Biomedical Computing"". The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods. The project will collaborate with the National Alliance for Medical Image Computing (NA-MIC) to develop the software using the NA-MIC Software Engineering Process, leverage the NA-MIC engineering infrastructure, and integrate this software into the 3D Slicer, a well-architected application environment being developed in NA-MIC. The particular software package will include both a brain image registration and warping algorithm, called HAMMER, and an algorithm for the segmentation of white matter lesions (WMLs), which can arise from a variety of pathologies including vascular pathology and multiple sclerosis. HAMMER received 2006 Best Paper Award from IEEE Signal Processing Society. HAMMER has been successfully applied to many large clinical research studies and clinical trials involving over 5,000 MR brain images and has been downloaded by 318 users from 102 institutions in over 20 countries. The WML segmentation algorithm has been successfully applied to ""Action to Control Cardiovascular Risk in Diabetes-Memory in Diabetes"" (ACCORD-MIND) sub- study, with data acquired from 4 centers on 650 patients over a period of 8 years. Designing an easy-to-use, robust software package for these two algorithms and incorporating it into the 3D Slicer will benefit a large community of end-users that need access to advanced image analysis methods in various neuroimaging studies. To increase the robustness of the algorithms to the highly variable quality and characteristics of clinical image data, further algorithm development is necessary. To increase ease of use by non-experts in computer analysis methods and integrate this software into the Slicer platform, significant software engineering efforts are planned. Three aims will be investigated. The first aim is to further develop and extend novel image analysis methods aiming at improving the robustness and performance of HAMMER registration and WML segmentation algorithms, so that they can be easily applied to various clinical research studies. The second and third aims are to design separate software modules for these two algorithms, and to incorporate them into the 3D Slicer. These two modules will be designed (1) with consistent cross-platform interactive and scripted interfaces, (2) allowing end-users to interactively explore the suitable parameters for their data, (3) enabling developers to add new functions. The robustness of these two modules will be extensively tested and improved by both software engineering tools and various clinical research data (acquired from different centers). The final software will be freely available in both source code and pre-compiled programs. PUBLIC HEALTH REVELANCE: The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods.          n/a",Development and Dissemination of Robust Brain MRI Measurement Tools,7556497,R01EB006733,"['Academia', 'Address', 'Adopted', 'Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Arts', 'Attention', 'Automobile Driving', 'Award', 'Behavioral', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Blood Vessels', 'Brain', 'Brain imaging', 'Brain region', 'Budgets', 'California', 'Characteristics', 'Child', 'Class', 'Clinical', 'Clinical Data', 'Clinical Engineering', 'Clinical Research', 'Clinical Trials', 'Cocaine', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Communities', 'Compatible', 'Complex', 'Computational algorithm', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computers', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Documentation', 'Educational Materials', 'Educational process of instructing', 'Educational workshop', 'Elderly', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'General Hospitals', 'Genetic', 'Genomics', 'Goals', 'Government', 'Hand', 'Head', 'Health', 'Healthcare', 'Heavy Drinking', 'Hemoglobin', 'Histocompatibility Testing', 'Hormonal', 'Hospitals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Industry', 'Information Technology', 'Institutes', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Lesion', 'Licensing', 'Life', 'Localized', 'Longitudinal Studies', 'Los Angeles', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Memory', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Mind', 'Modality', 'Modeling', 'Molecular Abnormality', 'Morphology', 'Multimodal Imaging', 'Multiple Sclerosis', 'National Center for Research Resources', 'Nature', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'North Carolina', 'Numbers', 'Operative Surgical Procedures', 'Organ', 'Paper', 'Participant', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Philosophy', 'Physiological', 'Play', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Production', 'Property', 'Protocols documentation', 'Psychiatry', 'Public Health', 'Publications', 'Purpose', 'Radiology Specialty', 'Range', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Secure', 'Series', 'Services', 'Simulate', 'Site', 'Societies', 'Software Engineering', 'Software Tools', 'Source', 'Source Code', 'Spatial Distribution', 'Speed', 'Structure', 'System', 'Talents', 'Techniques', 'Technology', 'Testing', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'USA Georgia', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Upper arm', 'Ursidae Family', 'Utah', 'Visible Radiation', 'Vision', 'Vision research', 'Western Asia Georgia', 'Woman', 'Women&apos', 's Health', 'Work', 'abstracting', 'base', 'bioimaging', 'biomedical scientist', 'cardiovascular risk factor', 'computerized data processing', 'computerized tools', 'cost', 'design', 'disability', 'egg', 'endophenotype', 'experience', 'follow-up', 'human disease', 'image registration', 'improved', 'innovation', 'mathematical model', 'medical schools', 'member', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'open source', 'outreach program', 'portability', 'professor', 'programs', 'receptor', 'repository', 'research and development', 'research study', 'scripting interface', 'software development', 'tool', 'usability', 'user-friendly', 'vector', 'vision development', 'water diffusion', 'web-enabled', 'white matter']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2008,402999,-0.014824681264502754
"Machine Learning Applied to Automated Planar Patch Clamps    DESCRIPTION (provided by applicant): The introduction of automated planar patch clamp instruments over the past two years has increased the throughput of voltage clamp ion channel assays by a factor of at least ten. This is possible because the automated systems can perform assays in parallel using16 and 384-well plates. While the drug discovery industry has embraced this new technology, the enthusiasm has been tempered by the modest success rates of the assays and by the high cost of the consumable patch substrate. Currently, typical success rates for a standard ion channel assay, using, for example, the Q-Patch from Sophion Biosciences, the Port-a-Patch system from Nanion Biosciences, or the PatchXpress from Molecular Devices Corp., is around 50%. In other words, for every16 channel chip used in these systems, only eight will produce useable data. This effectively doubles the price of each data point over what is ideally possible. In order for a planar patch clamp experiment to succeed, several events need to occur (assuming that the cell expresses the appropriate ion channels in functional states): the cell of interest must form a high-resistance seal with the planar substrate, the whole-cell configuration must be achieved, and fluidic pathways must be intact so that compounds of interest maybe applied to the cell. A failure of anyone of these steps will result in no data collected from that well. We propose to optimize the first two steps in this process, namely, seal formation and entry into whole-cell recording configuration. We will use machine learning approaches to examine how a human patch clamp expert interacts with the patch clamp system in order to develop a model that will provide parameters that can be used to more efficiently and successfully provide useable whole-cell recording configuration. It is important to note that the model that we derive from our approach will not actually copy what the expert does, but will attempt to optimize the process based on cues that mayor may not be consciously monitored by the expert. The Specific Aims of the Phase I component will be to: (1) integrate recording capabilities into existing automated patch clamp software from Nanion, (2) evaluate the success rate of the procedure specified by our machine learning analysis, and (3) develop stand-alone software for use specifically with manual patch clamp setups and for exploration of the potential benefits of using machine learning via expert training in other applications. In Phase II we propose to develop the proof-of-concept software into a user-friendly commercial software module which we will offer to existing and potential automated patch clamp companies. We will also simplify and streamline the user interface of this software as a stand-alone component for manual patch clamp systems. Developing drugs that target ion channels has been hindered by the expense of the consumables used in automated patch clamp screening devices. We propose to develop a method, using machine learning techniques which may increase the success rate of these instruments and therefore lower the overall cost of ion channel drug discovery.          n/a",Machine Learning Applied to Automated Planar Patch Clamps,7220448,R43EB007148,"['Biological Assay', 'Cells', 'Chemistry', 'Computer software', 'Condition', 'Cues', 'Data', 'Devices', 'Drug Delivery Systems', 'Employee Strikes', 'Event', 'Failure', 'Goals', 'Housing', 'Human', 'Industry', 'Ion Channel', 'Learning', 'Licensing', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Monitor', 'Pathway interactions', 'Performance', 'Phase', 'Price', 'Procedures', 'Process', 'Programmed Learning', 'Protocols documentation', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Resistance', 'Running', 'Sales', 'Scientist', 'Screening procedure', 'Software Engineering', 'Solutions', 'Specific qualifier value', 'Spottings', 'Standards of Weights and Measures', 'Suction', 'Surface', 'System', 'Techniques', 'Testing', 'Training', 'Visual', 'Whole-Cell Recordings', 'Work', 'Writing', 'base', 'cell type', 'concept', 'cost', 'drug discovery', 'improved', 'instrument', 'interest', 'new technology', 'patch clamp', 'programs', 'research study', 'seal', 'success', 'tool', 'user-friendly', 'voltage', 'voltage clamp']",NIBIB,BLATZ SCIENTIFIC,R43,2007,199389,-0.033747623672917476
"Computer Vision Methods for the Real Time Assessment of Dietary Intake    DESCRIPTION (provided by applicant): Obesity is a leading cause of preventable death and disability in the U.S. Self- monitoring of all foods and beverages consumed is central to weight loss and maintenance efforts; however, this places a heavy burden on the user. These same burdens also impede nutritional research. The proposed research is for the testing of a semi-automated, objective, near real-time computer vision and pattern recognition approach to the measurement of dietary intake. In the proposed product, cell phone pictures of meals and snacks will be analyzed by software in an attempt to automatically recognize as many items as possible. A small number of intelligent yes/no questions will help provide additional information when necessary in order to meet the accuracy demands of the target application. Following identification of the items, the software will estimate the portion sizes of all identified items. The experiments comprising this Phase I SBIR are (a) extract the most informative sets of features using a large number of food and beverage items taken from an existing database of real world meal images, (b) compare the accuracy of candidate pattern recognition approaches to identify items based on the extracted features, (c) identify the most feasible algorithms for estimating portion size, and (d) test usability and user acceptance with a simulated version of the product. Phase II will (a) apply the approach to a greater variety of food and beverage items, (b) improve automated analysis, and (c) compare the approach to existing assessment instruments. This research will extend defense- and security-related technologies to the assessment and treatment of obesity.          n/a",Computer Vision Methods for the Real Time Assessment of Dietary Intake,7405586,R43CA124265,"['Address', 'Adherence', 'Algorithms', 'Area', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Biometry', 'Body Weight decreased', 'Calculi', 'Cellular Phone', 'Cessation of life', 'Class', 'Coin', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Decision Trees', 'Diabetic Diet', 'Diet Records', 'Dietary intake', 'Disease', 'Eating', 'Eating Behavior', 'Face', 'Feedback', 'Fingerprint', 'Food', 'Food and Beverages', 'Goals', 'Habits', 'Health', 'Image', 'Individual', 'Information Theory', 'Intake', 'Iris', 'Life', 'Life Style', 'Lighting', 'Machine Learning', 'Maintenance', 'Marketing', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Numbers', 'Nutritional', 'Nutritionist', 'Obesity', 'Obesity associated disease', 'Pattern Recognition', 'Phase', 'Placement', 'Principal Investigator', 'Public Health', 'Research', 'Research Personnel', 'Security', 'Shapes', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Three-Dimensional Image', 'Time', 'Training', 'Treatment Protocols', 'United States', 'Wing', 'base', 'design', 'digital imaging', 'disability', 'improved', 'innovation', 'instrument', 'interest', 'obesity treatment', 'research study', 'size', 'usability']",NCI,"MEDIABALANCE, INC.",R43,2007,191710,0.004045205114720218
"Assisting Systematic Review Preparation Using Automated Document Classification    DESCRIPTION (provided by applicant):       The work proposed in this new investigator initiated project studies the hypothesis that machine learning-based text classification techniques can add significant efficiencies to the process of updating systematic reviews (SRs). Because new information constantly becomes available, medicine is constantly changing, and SRs must undergo periodic updates in order to correctly represent the best available medical knowledge at a given time.       To support studying this hypothesis, the work proposed here will undertake four specific aims:   1. Refinement and further development of text classification algorithms optimized for use in classifying   literature for the update of systematic reviews on a variety of therapeutic domains. Comparative analysis using several different machine learning techniques and strategies will be studied, as well as various means of representing the journal articles as feature vectors input to the process.   2. Identification and evaluation of systematic review expert preferences and trade offs between high recall and high precision classification systems. There are several opportunities for including this technology in the process of creating SRs. Each of these applications has separate and unique precision and recall tradeoff thresholds that will be studied based on the benefit to systematic reviews.   3. Prospective evaluation of text classification algorithms. We will verify that our approach performs as   expected on future data.   4. Development of comprehensive gold standard test and training sets to motivate and evaluate the   proposed and future work in this area.      The long term relevance of this research to public health is that automated document classification will   enable more efficient use of expert resources to create systematic reviews. This will increase both the   number and quality of reviews for a given level of public support. Since up-to-date systematic reviews are essential for establishing widespread high quality practice standards and guidelines, the overall public health will benefit from this work.          n/a",Assisting Systematic Review Preparation Using Automated Document Classification,7242352,R01LM009501,"['Algorithms', 'Area', 'Classification', 'Data', 'Data Set', 'Development', 'Evaluation', 'Future', 'Gold', 'Guidelines', 'Human', 'Knowledge', 'Literature', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Numbers', 'Paper', 'Performance', 'Preparation', 'Process', 'Public Health', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resources', 'Review, Systematic (PT)', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Time', 'Training', 'Triage', 'Update', 'Work', 'base', 'comparative', 'expectation', 'journal article', 'preference', 'programs', 'prospective', 'text searching', 'vector']",NLM,OREGON HEALTH AND SCI UNIVERSITY,R01,2007,292133,-0.03514123603073276
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7172503,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2007,1159531,-0.031031299620991784
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,7278340,R44CA088684,"['Acute leukemia', 'Antibodies', 'Area', 'Aspirate substance', 'Biopsy Specimen', 'Blast Cell', 'Bone Marrow', 'Bone marrow biopsy', 'Cells', 'Chronic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Color', 'Compatible', 'Computer software', 'Count', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Disease', 'Dysmyelopoietic Syndromes', 'Ensure', 'Equipment', 'Evaluation', 'Evaluation Reports', 'Event', 'Experimental Designs', 'Florida', 'Fluorescence', 'Funding', 'Future', 'Generations', 'Goals', 'Grant', 'Hematopathology', 'Histology', 'Image', 'Image Analysis', 'Immunophenotyping', 'Label', 'Laboratories', 'Legal patent', 'Light', 'Lighting', 'Machine Learning', 'Malignant - descriptor', 'Manuals', 'Mechanics', 'Medical Device', 'Methodology', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Morphology', 'Myelodysplastic/Myeloproliferative Disease', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Procedures', 'Protocols documentation', 'Public Health Schools', 'Purpose', 'Qualifying', 'Range', 'Reagent', 'Reporting', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Series', 'Side', 'Slide', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Engineering', 'Software Tools', 'Software Validation', 'Source', 'Speed', 'Staging', 'Staining method', 'Stains', 'Standards of Weights and Measures', 'System', 'Testing', 'Therapeutic', 'Time', 'United States Food and Drug Administration', 'Universities', 'Validation', 'Washington', 'Work', 'base', 'cellular imaging', 'design', 'experience', 'innovation', 'instrument', 'instrumentation', 'leukemia', 'light microscopy', 'novel', 'programs', 'research study', 'response', 'software development']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2007,1006481,-0.025540147170691228
"The Use of Mathematic Algorithms in the Prevention of Improper Medical Payments    DESCRIPTION (provided by applicant): The goal of this research is to create software that uses mathematical algorithms to detect medical billing coding errors prior to payment. The well-publicized failure of current healthcare cost containment technologies to prevent improper payments in both the commercial healthcare market and the federal Medicare program highlights the urgent need for a new approach to the growing problem of out of control medical costs. A recent federal study by the GAO estimated that improper payments by Medicare alone were in excess of 21 billion dollars, a truly staggering 48.1 percent of all improper payments by federal programs. Like SPAM, whose dynamic nature makes static or post hoc remedies ineffective, effective cost containment in one area often merely leads to the creation of new areas of abuse. Clearly, the ideal solution is a system that can evaluate the fairness of payments before they are made, and that can respond to dynamic patterns of abuse. The first step in creating such a system is the creation of robust method for sorting bills for appropriate rule-based analysis on the basis of the type of bill. Currently neither Medicare nor major insurers are capable of making this classification reliably except through the use of inefficient, static rules and the use of manual sorting--a costly and inefficient approach to assuring timely payment to hospitals and medical providers. We propose a novel method for using mathematical algorithms that utilize machine-learning (ML) methods to address the problem of medical bill categorization, the first step in coding error detection. Specifically, we propose the evaluation of a variety of genetic algorithms that are well adapted to the problems of large, dynamic datasets and can be ""trained"" using real world correctly coded datasets in healthcare claims. This work is particularly timely due to recent Medicare contracting reform. Using more than 50 contractors and carriers, bill classification is largely determined by the carrier's contract. Centralizing this process to only four payment centers will require the classification system we propose. [This research is directed toward the development of software applications that will detect billing errors and perform proper edits to payment of medical bills. Current anticipated changes and reforms in the Medicare system will require these systems, which do not currently exist in the public or private sector.]             n/a",The Use of Mathematic Algorithms in the Prevention of Improper Medical Payments,7316071,R43LM009190,"['Address', 'Age', 'Algorithms', 'Area', 'Arts', 'Classification', 'Code', 'Collaborations', 'Computer Simulation', 'Computer software', 'Contractor', 'Contracts', 'Cost Control', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Development', 'Elements', 'Environment', 'Evaluation', 'Failure', 'Genetic Programming', 'Goals', 'Health Care Costs', 'Health Care Fraud', 'Health Personnel', 'Healthcare', 'Healthcare Market', 'Healthcare Systems', 'Hospitals', 'Industry', 'Inpatients', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Manuals', 'Mathematics', 'Medical', 'Medicare', 'Methods', 'Mining', 'Modeling', 'Nature', 'Numbers', 'Operative Surgical Procedures', 'Outcome', 'Outpatients', 'Pattern', 'Phase', 'Policies', 'Population', 'Prevention', 'Private Sector', 'Process', 'Provider', 'Rate', 'Reporting', 'Research', 'Running', 'Small Business Technology Transfer Research', 'Solutions', 'Sorting - Cell Movement', 'Standards of Weights and Measures', 'System', 'Technology', 'Testing', 'Training', 'Work', 'base', 'college', 'computerized', 'cost', 'design', 'experience', 'improved', 'mathematical algorithm', 'novel', 'novel strategies', 'payment', 'prevent', 'programs', 'size', 'software development', 'stem', 'success']",NLM,"QMEDTRIX SYSTEMS, INC.",R43,2007,92482,-0.009150968521763869
"Diagnostic Innovations in Glaucoma: Clinical Electrophysiology    DESCRIPTION (provided by applicant): This application proposes to investigate the diagnostic precision for detecting glaucoma of clinical electrophysiological measurement (pattern electroretinogram, PERG; and multifocal visual evoked potentials, mfVEP), a technique identified as an important recent glaucoma- related development in eye research by the 2004 National Eye Institute (NEI) National Plan. Aim 1: Electrophysiological responses will be characterized in glaucoma, suspect and healthy eyes and the diagnostic accuracy of these commercially available techniques will be compared to current reference standards (evaluation of stereoscopic photographs of the optic disc and standard automated perimetry) and to recently developed diagnostic techniques including optical imaging of the optic disc and retinal nerve fiber layer (RNFL) (confocal scanning laser ophthalmoscopy, optical coherence tomography, and scanning laser polarimetry) and visual function-specific perimetry (short-wavelength automated perimetry and frequency doubling technology perimetry). Aim 2: Novel use of machine learning classifier techniques (e.g. relevance vector machines, support vector machines, mixture of Gaussian techniques, independent components analysis) will be applied to electrophysiological data to improve its diagnostic accuracy and data from different diagnostic techniques (named above) will be combined to improve overall diagnostic accuracy. Aim 3: Electrophysiological measurements will be validated as functional indicators of optic nerve damage by examining the relationship between electrophysiological abnormality and optic disc and RNFL damage in glaucoma and glaucoma suspect patients. 210 patients (105 glaucoma's, 105 glaucoma suspects) and 105 healthy participants will be enrolled and studied cross-sectionally. The specific aims of this proposal address the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset, determining functional correlates of optic nerve damage, and characterizing glaucomatous neurodegeneration within the visual pathways at structural and functional levels. Information about the relative usefulness of electrophysiological measurement, optical imaging techniques, and ganglion cell-specific perimetry for glaucoma detection is important to the clinical community for determining future evidence-based changes in standard of care for glaucoma diagnosis and monitoring. These studies will demonstrate the relative usefulness of electrophysiological measurement (pattern electroretinogram, PERG; multi-focal visual evoked potential, mfVEP) compared to optical imaging techniques (confocal scanning ophthalmoscopy, optical coherence tomography, scanning laser polarimetry) and ganglion cell-specific perimetry (short wavelength and frequency doubling perimetry) for glaucoma detection. The proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset, determining functional correlates of optic nerve damage, and characterizing glaucomatous neurodegeneration within the visual pathways at structural and functional levels. Findings will be important to the clinical community for determining future evidence-based changes in standard of care for glaucoma diagnosis and monitoring.                n/a",Diagnostic Innovations in Glaucoma: Clinical Electrophysiology,7242398,R21EY018190,"['Address', 'California', 'Caring', 'Clinical', 'Communities', 'Data', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electrophysiology (science)', 'Electroretinography', 'Enrollment', 'Evaluation', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Image', 'Imaging Techniques', 'Individual', 'Investigation', 'Lasers', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Names', 'National Eye Institute', 'Nerve Degeneration', 'Onset of illness', 'Ophthalmoscopy', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Pattern', 'Perimetry', 'Peripheral', 'Personal Satisfaction', 'Photography', 'Psychophysiology', 'Range', 'Reference Standards', 'Relative (related person)', 'Research', 'Retinal', 'Scanning', 'Scotoma', 'Sensitivity and Specificity', 'Severities', 'Standards of Weights and Measures', 'Structure', 'Suspect Glaucomas', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual', 'Visual Pathways', 'Visual evoked cortical potential', 'base', 'design', 'diagnostic accuracy', 'ganglion cell', 'improved', 'independent component analysis', 'innovation', 'novel', 'novel diagnostics', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'response', 'retinal nerve fiber layer', 'stereoscopic', 'vector']",NEI,UNIVERSITY OF CALIFORNIA,R21,2007,218125,-0.039149620104473586
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,7269383,R01RR014477,[' '],NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2007,307022,-0.034498508195038816
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7298516,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2007,88539,-0.01921883892225529
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7362843,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2007,235138,-0.004608689142215958
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,7151198,R01DC005241,"['Affect', 'Algorithms', 'Archives', 'Area', 'Articulators', 'Behavior', 'Child', 'Code', 'Communication', 'Computer Systems Development', 'Computer Vision Systems', 'Computers', 'Data', 'Databases', 'Development', 'Education', 'Educational process of instructing', 'Emotions', 'Equipment and supply inventories', 'Face', 'Facial Expression', 'Future', 'Goals', 'Guidelines', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Image', 'Individual', 'Investigation', 'Joints', 'Learning', 'Life', 'Lighting', 'Linguistics', 'Manuals', 'Modeling', 'Modification', 'Nightmare', 'Parents', 'Pattern Recognition', 'Population', 'Preparation', 'Process', 'Regulation', 'Research Design', 'Semantics', 'Series', 'Sign Language', 'Social Interaction', 'Speech', 'Stimulus', 'Structure', 'System', 'Testing', 'Translations', 'Trees', 'Work', 'computerized data processing', 'computerized tools', 'direct application', 'innovation', 'native American sign language', 'phonology', 'practical application', 'research study', 'syntax', 'teacher']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2007,471644,-0.013450546890939039
"Wayfinding for the blind & visually impaired using passive environmental labels    DESCRIPTION (provided by applicant): The objective of this proposal is to tackle the problem of way finding (finding one's way in an environment), faced by blind and severely visually impaired persons who are unable to find or read signs, landmarks and locations. We propose a novel and very inexpensive environmental labeling system to provide this population with access to information needed for indoor way finding (where GPS is not available). The system uses simple passive landmark symbols printed on paper or other material, placed next to text, Braille signs or barcode at locations of interest (offices, bathrooms, etc.) in an environment such as an office building. These printed patterns contain spatial and semantic information that is detected using computer vision algorithms running on a standard camera cell phone. By scanning the environment with the device, which detects all landmark symbols in its line of sight up to distances of 10 meters, the user can determine his or her approximate location in the environment as well as the information encoded near each landmark symbol. The system extracts this information in real-time and communicates it to the user by sound, synthesized speech and/or tactile feedback. This information includes spatial (e.g. audio tones to indicate the presence and direction of a label in the camera's field of view) and semantic information (""Mr. Johnson's office, room 429, at 11 o'clock""). The research proposed here will produce a prototype system that will be tested by blind and low vision subjects. Our team includes a blind expert on psychoacoustics (and other in-house blind staff) and an expert consultant on low-vision way finding and navigation to help optimize the user interface and guide development into a practical, easy-to-use system.              n/a",Wayfinding for the blind & visually impaired using passive environmental labels,7295688,R21EY017003,"['Access to Information', 'Address', 'Algorithms', 'Auditory', 'Bar Codes', 'Canes', 'Canis familiaris', 'Cellular Phone', 'Clutterings', 'Cognitive', 'Color', 'Complement component C1s', 'Computer Vision Systems', 'Computer software', 'Condition', 'Consultations', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Elderly', 'Employment', 'Environment', 'Exhibits', 'Feedback', 'Future', 'Goals', 'Home environment', 'Housing', 'Image', 'Individual', 'Instruction', 'Label', 'Localized', 'Location', 'Modality', 'Museums', 'Paper', 'Pattern', 'Persons', 'Population', 'Printing', 'Psychoacoustics', 'Quality of life', 'Range', 'Rate', 'Reading', 'Research', 'Running', 'Scanning', 'Semantics', 'Shapes', 'Source', 'Speech', 'Standards of Weights and Measures', 'Stress', 'System', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'age group', 'base', 'blind', 'braille', 'concept', 'cost', 'design', 'interest', 'legally blind', 'meter', 'novel', 'optical character recognition', 'programs', 'prototype', 'research study', 'size', 'skills', 'sound', 'success', 'symposium', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2007,193398,-0.012980104349149932
"An implantable device to predict and prevent seizures    DESCRIPTION (provided by applicant): After the first four years of our Bioengineering Research Partnership, implantable devices for epilepsy are now a reality. This is due, in part, to translation of technology developed by our group to industry. Data from multi-center clinical trials of first generation responsive antiepileptic devices indicate that this new technology is safe, and that there is promise of significant benefit to patients. They also demonstrate that 1st-generation devices rarely make patients seizure free. This is because we do not yet understand when, where and how to deliver electrical stimulation to pre-empt seizures, or the mechanisms underlying seizure generation in epileptic networks. These challenges, and translating them into more effective second-generation devices, are the focus of this proposal. Specifically, our aims are: (1) To understand mechanisms underlying seizure generation in two well characterized, spontaneously seizing animal models of epilepsy with documented similarities to refractory human epilepsy, (2) To map seizure generation in the epileptic network to determine where to place sensing electrodes and when to stimulate to maximize seizure suppression and minimize side effects. (3) To develop more effective closed loop stimulation algorithms for controlling seizures. These Aims will be accomplished through a series of projects led by established collaborators in neurology, neuroscience, bioengineering and industry, at Penn, CHOP, Georgia Tech, and BioQuantix, Inc. Teams will focus on improving upon results from first-generation human devices through detailed animal experiments on multiple temporal and spatial scales. These include: (1) the cellular level, through broad-band unit recording and biophysically accurate computational modeling; (2) the network level, with in vitro experiments on hippocampal slices using voltage sensitive dyes and multi-electrode arrays; and (3) the whole brain level, through simultaneous micro and macroelectrode field recordings and responsive brain stimulation in vivo. These experiments will build upon the substantial progress made during the first cycle of our Bioengineering Research Partnership grant. The unique composition of our group, its track record of successful technology transfer, and our ability to learn from and immediately convey our discoveries to existing programmable devices, provide an unprecedented opportunity to perform cutting-edge neuroscience and bioengineering research and immediately translate it into better treatment for patients.           n/a",An implantable device to predict and prevent seizures,7125319,R01NS041811,"['Adverse effects', 'Algorithms', 'Animal Experimentation', 'Animal Experiments', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Biological', 'Biomedical Engineering', 'Brain', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collaborations', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Devices', 'Drops', 'Dyes', 'Eels', 'Electric Stimulation', 'Electrodes', 'Elements', 'Engineering', 'Epilepsy', 'Event', 'Evolution', 'Feedback', 'Frequencies', 'Generations', 'Genetic Models', 'Grant', 'Hippocampus (Brain)', 'Human', 'In Vitro', 'Industry', 'Interneurons', 'Learning', 'Link', 'Localized', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Metabotropic Glutamate Receptors', 'Methods', 'Multi-Institutional Clinical Trial', 'Neurology', 'Neurosciences', 'Organism', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Prevention', 'Probability', 'Process', 'Protocols documentation', 'Range', 'Refractory', 'Research', 'Research Personnel', 'Resolution', 'Rodent Model', 'Seizures', 'Series', 'Signal Transduction', 'Simulate', 'Site', 'Slice', 'Statistical Methods', 'Statistical Models', 'Subclinical Seizures', 'Synaptic plasticity', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Translating', 'Translations', 'USA Georgia', 'Western Asia Georgia', 'base', 'computerized data processing', 'experience', 'implantable device', 'improved', 'in vitro Model', 'in vivo', 'insight', 'interest', 'markov model', 'neurosurgery', 'new technology', 'novel', 'prevent', 'programs', 'research study', 'sensor', 'voltage']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2007,1322181,-0.01722351613091436
"Automatic Detection of Critical Dermoscopy Features for Melanoma Diagnosis    DESCRIPTION (provided by applicant): Malignant melanoma, with an estimated growth in incidence of about 6% per year for decades, causes considerable loss of life. Yet melanoma can be easily cured if detected early. Digital dermoscopy has shown promise for more accurate detection, particularly at an early stage. Recent conferences have highlighted a general agreement on definition of dermoscopic features and moderate agreement on the most useful structural features. Automatic detection of these specific structures that are critical for early diagnosis and are used in various dermoscopic diagnostic algorithms would be desirable. Yet little work has been published on automatic detection of any specific dermoscopic structures. Although specific colors figure prominently in the definition of the most critical dermoscopic structures, little work has been done on finding the specific regions or region combinations in the color space where colors are located, particularly with reference to the surrounding skin. The work in Phase I and after Phase I successfully segmented the border within 5% of the range of the dermatologists' borders, found several highly accurate dermoscopy features, and brought mean diagnostic accuracy on difficult early lesions to a high level. This proposal seeks to develop a digital dermosocopy system by 1) comparing classifiers 2) testing border accuracy and modifying segmentation if needed 3) developing an algorithm that uses a three-dimensional representation of a probability density function to specify single and paired melanoma colors via cluster methods and fuzzy logic techniques 4) identifying critical structural features including brown globules, abrupt border cutoff, granularity, regression, and pigment asymmetry with high accuracy 5) developing a clinical interface for acquisition of images within the clinic 6) testing the new algorithms in six dermatology clinics including two pigmented lesion clinics with both EpiLight and DermLite II Pro dermoscopy images taken in the clinic. Key features of the research include dermatopathology confirmation of specific structures and the use of relative color analysis. If successful, software will be marketed to the growing number of dermatologists with digital dermoscopy capability. The commercial software package will be ready for marketing as a diagnostic adjunct for digital camera dermoscopy attachments. Malignant melanoma, with an estimated growth in incidence of about 6% per year for decades, causes considerable loss of life. Melanoma can be easily cured if detected early, and this project seeks to develop a digital dermoscopy device that can detect very early melanomas. The project goal is to develop inexpensive melanoma detection software and test it in multiple dermatology clinics.          n/a",Automatic Detection of Critical Dermoscopy Features for Melanoma Diagnosis,7284886,R44CA101639,"['Agreement', 'Algorithms', 'Am 80', 'Amelanotic Melanoma', 'American', 'Architecture', 'Area', 'Benign', 'Biological', 'Biological Neural Networks', 'Biopsy', 'Blood Vessels', 'Borderline Lesion', 'Boxing', 'Calibration', 'Characteristics', 'Cicatrix', 'Class', 'Classification', 'Clinic', 'Clinical', 'Code', 'Color', 'Computer software', 'Computer-Assisted Image Analysis', 'Count', 'Decision Trees', 'Dermatologist', 'Dermatology', 'Dermoscopy', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease regression', 'Dysplastic Nevus', 'Early Diagnosis', 'Effectiveness', 'Equipment', 'Evaluation', 'Excision', 'Fuzzy Logic', 'Goals', 'Government', 'Growth', 'Hair', 'Hair Removal', 'Head', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Incidence', 'Lentigo', 'Lesion', 'Life', 'Lighting', 'Location', 'Machine Learning', 'Manuals', 'Marketing', 'Measures', 'Methods', 'N(delta)-acetylornithine, -isomer', 'N-dodecanoylglutamic acid, -isomer, sodium salt', 'Noise', 'Numbers', 'Odds Ratio', 'Pattern', 'Peripheral', 'Persons', 'Phase', 'Phase I Clinical Trials', 'Physicians', 'Pigments', 'Precancerous melanosis', 'Probability', 'Process', 'Published Comment', 'Publishing', 'Purpose', 'ROC Curve', 'Radial', 'Range', 'Rate', 'Relative (related person)', 'Reporting', 'Research', 'Risk', 'Score', 'Series', 'Skin', 'Software Tools', 'Source', 'Specificity', 'Staging', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'To specify', 'Training', 'Work', 'alpha-difluoromethyl-DOPA, -isomer', 'alpha-methylornithine dihydrochloride, -isomer', 'base', 'density', 'diagnostic accuracy', 'digital', 'experience', 'improved', 'indexing', 'melanoma', 'reconstruction', 'software development', 'software systems', 'statistics', 'symposium', 'tool development', 'vector']",NCI,STOECKER & ASSOCIATES,R44,2007,494442,-0.025209191503698724
"A Laser-Based Device for Work Site Stability Assessment    DESCRIPTION (provided by applicant): Summary: A laser-based acoustic emission (AE) detection device is proposed for work site structural stability assessment. This new device will take advantage of innovations in laser ultrasonics, artificial intelligence (Al) and advanced acoustic emission technology to provide mine workers with a unique instant, real time stability assessment of immediate rock structures in the working environment, which was not attainable in the past. Nonlinear optical interferometry based on two-wave mixing / photo-induced electromotive force techniques will be used for AE signal detection from rock structures in mine sites. Al criteria will be established by wave pattern recognition to identify unstable areas in mine sites. This research will also result in a unique non-contact monitoring device for acoustic emission/microseismic studies, which will be very useful in many areas of application. The primary objective of the Phase II research is to develop the prototype of the AE detector and test it in real-world mining facilities. The primary objective consists of six specific aims: 1. instrumentation development, 2. pre-field experiment preparation, 3. in-situ data collection, 4. Al criteria development, 5. system integration and in-situ trial, and 6. documentation and reporting. Relevance to Public Health: The innovation will contribute to a reduction the occupational injuries and fatalities caused by roof falls, sidewall crumples, stope collapses, and slope slides, etc., in the mining industry. The research and development addresses the miner's safety and contributes to ensuring the mineworker's right to ""safe and healthful working conditions"" (Occupational Safety and Health Act of 1970).          n/a",A Laser-Based Device for Work Site Stability Assessment,7278614,R44OH007662,[' '],NIOSH,AAC INTERNATIONAL,R44,2007,363328,-0.01241798470139254
"The BioSense Initiative to Improve Early Event Detection RTI International, in partnership with the University of North Carolina at Chapel Hill (UNC-CH), and in collaboration with the North Carolina Division of Public Health (NC-DPH), is submitting this application to work with the Centers for Disease Control and Prevention (CDC) to improve early detection of disease outbreaks of public health significance. Rapid detection of disease outbreaks rests on a foundation of accurate classification of patient symptoms early in the course of their illness. The overarching objective of this research is to define, evaluate, and standardize a methodology for creating useful case definitions designed for the early detection of intentional and naturally occurring disease outbreaks. The specific aim of this research proposal is to develop and test methods for increasing the sensitivity and specificity of syndrome definitions using timely emergency department data. Improved case definitions will enhance CDC's capacity to detect and investigate threats to the health of the population, which CDC undertakes as part of its mission. Emergency department data may serve as a rich source for early signals of health threats to the population, but case definitions have not been standardized, and new methods are needed to process and use the textual information found within the emergency record. To address these challenges, we propose an innovative and iterative research plan that leverages RTI's and UNC-CH's capabilities to best serveCDC and the public health community. We will use emergency department data captured through North Carolina's Bioterrorism and Emerging Infections PreventiveService, the operational syndromic surveillance system used by NC-DPH to monitor the state. After (1) developing a gold standard data set of ED visits for evaluating syndrometest characteristics, we will (2) evaluate natural language processing for preprocessing chief complaints; (3) explore use of semantic networking tools for developing definitions; (4) apply a reverse engineering process using ICD-9-CMcode groupings; and (5) assess the applicability of early event detection for creating situational awareness following detection of an event. These methods will make use of information within the emergency record and create syndrome definitions with acceptable sensitivity, specificity, and positisve predictive value. Valid syndromedefinitions will enable public health officials to operate a national monitoring system that can automatically detect signals that may represent disease outbreaks or other potential threats to health. Operation of this system will protect the public health and will strengthen the capacity of public health officials to investigate and respond to these threats rapidly. n/a",The BioSense Initiative to Improve Early Event Detection,7428896,R01PH000038,[' '],PHPPO,RESEARCH TRIANGLE INSTITUTE,R01,2007,415565,-0.03047380553643137
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7214118,R42ES013321,"['Accounting', 'Animals', 'Architecture', 'Biological Assay', 'Biological Neural Networks', 'Chemicals', 'Clinical', 'Clinical Trials', 'Computer Simulation', 'Computer software', 'Contracts', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Drug Formulations', 'Drug Industry', 'Drug toxicity', 'End Point', 'Expert Systems', 'Funding', 'Future', 'Fuzzy Logic', 'Gene Expression', 'Guidelines', 'Health Care Costs', 'Hepatotoxicity', 'Investments', 'Learning', 'Liver', 'Marketing', 'Methods', 'Network-based', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Process', 'Proteomics', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Rate', 'Relative (related person)', 'Reliance', 'Research', 'Research Personnel', 'Screening procedure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Training', 'Validation', 'base', 'computational chemistry', 'cost', 'data acquisition', 'design', 'highly advanced system', 'improved', 'innovation', 'knowledge base', 'metabolomics', 'quantum', 'serial analysis of gene expression', 'subtraction hybridization', 'tool']",NIEHS,"YAHSGS, LLC",R42,2007,257269,-0.019503309328806943
"Development of rapid detection tests for Brucella species    DESCRIPTION (provided by applicant): Brucellosis is a re-emerging zoonotic disease that affects humans and a variety of farm animals. As well as a threat to public health it has considerable economic importance. The etiologic agent responsible for human infection, Brucella melitensis, is classified by both NIAID and CDC as a Category B biothreat pathogen. Antibiotics are only partially effective at controlling the disease and there is no vaccine approved for use in humans. Thus, prompt and accurate diagnosis is the key to containing infection. Currently, the most common diagnostic tests for Brucella are based on indirect serology which are lacking in specificity and sensitivity as well as speed of execution. Thus, there is a pressing need to develop improved diagnostics, especially technologies that may be used at field level. This investigation proposes to address this issue and develop a superior and robust technique for diagnosing Brucella infection with highly specific, non-cross reactive antibody reactions. We will achieve this goal by screening the Brucella genome using novel proteomic chip technology to identify unique antigens that will yield highly specific and accurate diagnoses. This work will be undertaken in Phase 1 of the application. In Phase 2, when antigens have been selected, we anticipate that we will proceed to develop ELISA and immunoblot assays. In parallel, both ELISA and lateral flow ""dipstick"" tests for Brucella antigen will be constructed. We envisage that the antigen assays will have particular utility in detecting Brucella disseminated in the context of the bioterrorism event. The diagnostic tools developed within this application will be rigorously evaluated for sensitivity and specificity using large and diverse panels of human and animal Brucella-positive sera available through our collaborators. The project proposes to develop a highly sensitive and robust diagnostic test for brucellosis, also known as ""undulant fever"", an infectious disease that causes serious illness in farm animals and humans. The current techniques for diagnosing infection are somewhat unreliable and based on outmoded methods. This investigation will use state- of-the-art technology to identify new structures or antigens on Brucella bacteria that may be used to develop a test with superior diagnostic performance.          n/a",Development of rapid detection tests for Brucella species,7278655,R43AI068166,"['Acute', 'Address', 'Affect', 'Algorithms', 'Animals', 'Antibiotics', 'Antibodies', 'Antigen Targeting', 'Antigens', 'Area', 'Artificial Intelligence', 'Arts', 'Bacteria', 'Bioinformatics', 'Biological Assay', 'Bioterrorism', 'Brucella', 'Brucella abortus', 'Brucella melitensis', 'Brucellosis', 'Categories', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Clinical', 'Communicable Diseases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Economics', 'Enzyme-Linked Immunosorbent Assay', 'Event', 'Fluorescence', 'Genes', 'Genome', 'Goals', 'Human', 'Immune Sera', 'Immunoassay', 'Immunoblotting', 'Immunodominant Antigens', 'Infection', 'Investigation', 'Lateral', 'Livestock', 'Methods', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Peptides', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Printing', 'Proteomics', 'Public Health', 'Reaction', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Serologic tests', 'Serum', 'Speed', 'Structure', 'Study of serum', 'System', 'Techniques', 'Technology', 'Testing', 'Vaccines', 'Work', 'Yersinia enterocolitica', 'base', 'biothreat', 'disorder control', 'improved', 'novel', 'pathogen', 'prototype', 'rapid detection', 'response', 'tool']",NIAID,"INBIOS INTERNATIONAL, INC.",R43,2007,278818,-0.0025580675869879537
"Smart Wheelchair Component System    DESCRIPTION (provided by applicant):  Independent mobility is critical to individuals of any age. While the needs of many individuals with disabilities can be satisfied with power wheelchairs, some members of the disabled community find it difficult or impossible to operate a standard power wheelchair. This population includes, but is not limited to, individuals with low vision, visual field neglect, spasticity, tremors, or cognitive deficits. The goal of this project is to develop a set of components that can be added to standard power wheelchairs to convert them into ""smart"" wheelchairs which can assist the user in navigation and obstacle avoidance. During Phase I, a prototype of the Smart Wheelchair Component System (SWCS) was developed from a laptop computer and a collection of sonar, infrared and bump sensors. The evaluation activities performed during Phase I demonstrated that the system is compatible with multiple brands of wheelchairs, can accept both continuous and switch-based input, and can support front-, mid-, and rear-wheel drive wheelchairs. During Phase II, we propose to refine the system hardware and software; replace the laptop computer with an embedded microprocessor; fabricate enclosures for the system components; and develop tools to support clinicians in installing and configuring the system. The system will be evaluated in tests involving potential users, clinicians, and wheelchair design standards. The final product will be a market-ready modular system which can be attached to a variety of standard power wheelchairs. This product has the potential to increase the independence and quality of life of many wheelchair users and potential wheelchair users whose disabilities limit their capacity for independent wheelchair navigation.       n/a",Smart Wheelchair Component System,7237214,R44HD040023,"['Adult', 'Age', 'Child', 'Client', 'Cognitive deficits', 'Collection', 'Communities', 'Compatible', 'Computer Vision Systems', 'Computer software', 'Computers', 'Condition', 'Destinations', 'Development', 'Disabled Persons', 'Disadvantaged', 'Documentation', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Individual', 'Joystick', 'Laboratories', 'Learning', 'Location', 'Locomotion', 'Manufacturer Name', 'Marketing', 'Methods', 'Microprocessor', 'Numbers', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Powered wheelchair', 'Production', 'Quality of life', 'Range', 'Relative (related person)', 'Research Personnel', 'Robot', 'Self Perception', 'Standards of Weights and Measures', 'System', 'Technology', 'Testing', 'Touch sensation', 'Travel', 'Tremor', 'Visual Fields', 'Visual impairment', 'Wheelchairs', 'Work', 'base', 'data acquisition', 'design', 'disability', 'laptop', 'member', 'neglect', 'peer', 'prototype', 'sensor', 'sonar', 'tool']",NICHD,AT SCIENCES,R44,2007,387828,-0.002967985747208583
"Mobile Food Intake Visualization and Voice Recognize (FIVR) Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives. n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7490204,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2007,3000,0.008168027004252152
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7340845,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2007,1039742,0.009121105283708719
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7289973,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Compatible', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Condition', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Numbers', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'computerized', 'cost', 'day', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2007,853883,-0.017399630299465865
"Indoor Magnetic Wayfinding For The Visually Impaired    DESCRIPTION (provided by applicant): Advanced Medical Electronics (AME) proposes the development of an indoor way-finding device utilizing the unique magnetic anomaly patterns that exist in modern, man-made structures. The proposed system will record the magnitude of magnetic field strength from sensors in three orthogonal axes. The time history of these magnetic data points can be continuously compared with an electronic map of magnetic anomalies (or, ""signature"") to determine current position within a building. The phase I developed prototype system tracked in feasibility experiments with an accuracy of 1 foot (radius). Magnetic anomalies render a magnetic compass useless for finding a directional bearing. However, these same invisible anomalies represent valuable, unique indoor terrain features measurable by magnetic sensors located inside a small, portable device. Such a device would be able to provide low-vision users with a valuable indoor low-cost way-finding tool analogous to a Global Positioning System (GPS) device used outdoors. About 3.7 million Americans are visually disabled. Of these, 200,000 are blind, and the rest have low vision. The key advantage of the way-finding concept presented in this proposal, over other methods, is that the benefits are made available to the visually impaired community without requiring expensive building infrastructure investments. This is of particular advantage to large government buildings and educational campuses. The proposed approach allows a cost effective solution to way-finding within these buildings.          n/a",Indoor Magnetic Wayfinding For The Visually Impaired,7326673,R44EY015616,"['American', 'Appointment', 'Building Codes', 'Cognition', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Development', 'Devices', 'Disabled Persons', 'Doctor of Philosophy', 'Education', 'Electronics', 'Engineering', 'Fee-for-Service Plans', 'Funding', 'Government', 'Hand', 'Housing', 'Human', 'Indoor Magnetic Wayfinding', 'Investments', 'Joints', 'Label', 'Location', 'Magnetism', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Medical Electronics', 'Minnesota', 'Modeling', 'Modification', 'Neurosciences', 'Numbers', 'Oceans', 'Pattern', 'Pattern Recognition', 'Pennsylvania', 'Persons', 'Phase', 'Population', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychology', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Rest', 'Services', 'Silicon Dioxide', 'Solutions', 'Somatotype', 'Speech', 'Steel', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Today', 'Universities', 'Vision', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Wireless Technology', 'World Health Organization', 'base', 'blind', 'college', 'computer science', 'concept', 'cost', 'cost effective', 'court', 'design', 'digital', 'foot', 'human subject', 'innovation', 'interest', 'magnetic field', 'miniaturize', 'motor control', 'performance tests', 'professor', 'prototype', 'radius bone structure', 'research study', 'sensor', 'sensory integration', 'tool', 'way finding']",NEI,ADVANCED MEDICAL ELECTRONICS CORPORATION,R44,2007,386674,0.0051715322536526375
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,7111722,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2006,314029,-0.034498508195038816
"A Laser-Based Device for Work Site Stability Assessment    DESCRIPTION (provided by applicant): Summary: A laser-based acoustic emission (AE) detection device is proposed for work site structural stability assessment. This new device will take advantage of innovations in laser ultrasonics, artificial intelligence (Al) and advanced acoustic emission technology to provide mine workers with a unique instant, real time stability assessment of immediate rock structures in the working environment, which was not attainable in the past. Nonlinear optical interferometry based on two-wave mixing / photo-induced electromotive force techniques will be used for AE signal detection from rock structures in mine sites. Al criteria will be established by wave pattern recognition to identify unstable areas in mine sites. This research will also result in a unique non-contact monitoring device for acoustic emission/microseismic studies, which will be very useful in many areas of application. The primary objective of the Phase II research is to develop the prototype of the AE detector and test it in real-world mining facilities. The primary objective consists of six specific aims: 1. instrumentation development, 2. pre-field experiment preparation, 3. in-situ data collection, 4. Al criteria development, 5. system integration and in-situ trial, and 6. documentation and reporting. Relevance to Public Health: The innovation will contribute to a reduction the occupational injuries and fatalities caused by roof falls, sidewall crumples, stope collapses, and slope slides, etc., in the mining industry. The research and development addresses the miner's safety and contributes to ensuring the mineworker's right to ""safe and healthful working conditions"" (Occupational Safety and Health Act of 1970).          n/a",A Laser-Based Device for Work Site Stability Assessment,7109905,R44OH007662,"['artificial intelligence', 'bioengineering /biomedical engineering', 'data collection methodology /evaluation', 'human mortality', 'injury prevention', 'interferometry', 'lasers', 'mechanical stress', 'minings', 'monitoring device', 'occupational hazard', 'occupational health /safety', 'sound perception', 'technology /technique development', 'ultrasonography', 'work site']",NIOSH,AAC INTERNATIONAL,R44,2006,386471,-0.01241798470139254
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,7287568,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2006,38558,-0.030313512385656206
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7125135,R42ES013321,"['artificial intelligence', 'chemical structure function', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug discovery /isolation', 'drug screening /evaluation', 'functional /structural genomics', 'hepatotoxin', 'microarray technology', 'toxicant screening']",NIEHS,"YAHSGS, LLC",R42,2006,387181,-0.019503309328806943
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,7004518,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2006,457462,0.016626917597330117
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6985348,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2006,475410,-0.013450546890939039
"Wayfinding for the blind & visually impaired using passive environmental labels    DESCRIPTION (provided by applicant): The objective of this proposal is to tackle the problem of way finding (finding one's way in an environment), faced by blind and severely visually impaired persons who are unable to find or read signs, landmarks and locations. We propose a novel and very inexpensive environmental labeling system to provide this population with access to information needed for indoor way finding (where GPS is not available). The system uses simple passive landmark symbols printed on paper or other material, placed next to text, Braille signs or barcode at locations of interest (offices, bathrooms, etc.) in an environment such as an office building. These printed patterns contain spatial and semantic information that is detected using computer vision algorithms running on a standard camera cell phone. By scanning the environment with the device, which detects all landmark symbols in its line of sight up to distances of 10 meters, the user can determine his or her approximate location in the environment as well as the information encoded near each landmark symbol. The system extracts this information in real-time and communicates it to the user by sound, synthesized speech and/or tactile feedback. This information includes spatial (e.g. audio tones to indicate the presence and direction of a label in the camera's field of view) and semantic information (""Mr. Johnson's office, room 429, at 11 o'clock""). The research proposed here will produce a prototype system that will be tested by blind and low vision subjects. Our team includes a blind expert on psychoacoustics (and other in-house blind staff) and an expert consultant on low-vision way finding and navigation to help optimize the user interface and guide development into a practical, easy-to-use system.              n/a",Wayfinding for the blind & visually impaired using passive environmental labels,7143942,R21EY017003,"['clinical research', 'computers', 'reading', 'semantics', 'touch', 'vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2006,224601,-0.012980104349149932
"Simulation Algorithms for Spatial Pattern Recognition    DESCRIPTION (provided by applicant):    This SBIR project is developing methods and software for the specification, construction and simulation of neutral spatial models, and for applying these neutral models within the framework of probabilistic pattern recognition. Results will allow epidemiologists, environmental scientists and image analysts across a broad range of commercial disciplines to more accurately identify patterns in spatial data by removing the bias towards false positives that is caused by unrealistic null hypotheses such as ""complete spatial randomness"" (CSR). This project will accomplish 5 aims:      1. Conduct a requirements analysis to specify the neutral models and functionality to incorporate in the software.   2. Develop and test a software prototype to evaluate feasibility of the proposed models.   3. Propose a topology of neutral models and develop strategies to generate them and to conduct sensitivity analysis for investigating the impact of implicit assumptions (i.e. spatial autocorrelation or non-uniform risk) and number of realizations on test results.   4. Incorporate the neutral models in the first commercially established software package that allows for user-specified alternate hypothesis in spatial statistical tests.   5. Apply the software and methods to demonstrate the approach and its unique benefits for exposure and health risk assessment.      Feasibility of this project was demonstrated in the Phase I. This Phase II project will accomplish aims three through five. These technologic, scientific and commercial innovations will revolutionize our ability to identify, document and assess the probability of spatial patterns relative to neutral models that incorporate realistic local, spatial and multivariate dependencies. The neutral models and methods in this proposal make possible, for the first time ever, evaluation of the sensitivity of the results of cluster or boundary analyses to specification of the null hypothesis.         n/a",Simulation Algorithms for Spatial Pattern Recognition,7015648,R44CA092807,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'human data', 'image processing', 'imaging /visualization /scanning', 'statistics /biometry', 'visual cortex']",NCI,BIOMEDWARE,R44,2006,500182,-0.002333686871062996
"Spatial Modeling in Glaucoma DESCRIPTION (provided by applicant): This career training proposal is to train Michael D. Twa, OD, MS as an independent clinician-scientist. A five year training program is proposed, consisting of formal coursework in vision science, specific training in computer science and image processing, and mentoring in the application of these skills to clinical outcomes research in glaucoma. In September 2003, NIH announced a new ""Roadmap"" to accelerate advances in biomedical research for the 21st century. Three areas listed in this Roadmap are relevant to this research proposal: (1) Interdisciplinary research training. (2) Clinical research informatics. (3) Development of enabling technologies for improved assessment of clinical outcomes. The Roadmap emphasizes coordinated strategies to develop both technological and human resources to take full advantage of multidisciplinary and translational research opportunities. This proposal addresses the stated training objectives at an individual level.  Glaucoma is a leading cause of blindness. Visual field assessment and optic nerve head imaging (confocal scanning laser tomography) are commonly used to diagnose the disease and monitor its progression, yet there is considerable controversy about how to interpret and make best use of this information. Currently, raw data from these observations are reduced to statistical indices that are meant to summarize clinically meaningful features and provide a basis for classifying test results as normal or not. Unfortunately, these indices may sacrifice other relevant features in the data for interpretability.  We will use mathematical modeling methods (polynomial modeling, spline fitting and wavelet analysis) to quantify patterns in visual field data and topographic images of the optic nerve head. We will use features derived from these modeling methods to apply novel pattern recognition techniques from computer and information sciences-decision trees and non-linear regression analysis-and then compare these techniques to current methods to identify glaucoma. By improving current methods of analysis we can provide a more quantitative basis for clinical decisions, and offer greater consistency and objectivity on data interpretation. The long-term objective of this proposal is to translate advances in computer and information sciences to the analysis of clinical outcomes research in glaucoma and other eye diseases. n/a",Spatial Modeling in Glaucoma,7015012,K23EY016225,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer assisted diagnosis', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human data', 'image processing', 'mathematical model', 'model design /development', 'neuroimaging', 'optic nerve', 'patient oriented research', 'tomography', 'visual fields']",NEI,OHIO STATE UNIVERSITY,K23,2006,142642,-0.033956289756003746
"Paperless Quality Donor System with Decision Making DESCRIPTION (provided by applicant):    The long-term objectives of this project are to improve the safety and availability of the US blood supply. The principal aim of this SBIR Competing Continuation Phase II Proposal for a Paperless Quality Donor System with Decision Making is to complete the development of its Quality Donor System(tm) (QDS) and to secure ongoing 510(k) clearances for it from the US Food & Drug Administration (FDA), Center for Biologies Evaluation and Research (CBER) for implementation and evaluation of the total system in blood centers and hospital blood banks.      The research is based on continuing development of the Quality Donor System and deploying it in regional blood centers and hospital blood banks. System use by donors and staff and user satisfaction will be measured and analyzed to assess success. Blood safety is enhanced by eliminating FDA-reportable errors and by increasing blood donor honesty in disclosing risky behaviors. Blood availability is enhanced by increasing donor satisfaction, resulting in higher return rates for new blood donors and increasing employer sponsorship of blood drives. n/a",Paperless Quality Donor System with Decision Making,7127266,R44HL072635,"['Internet', 'artificial intelligence', 'blood bank /supply contamination', 'blood donor', 'case history', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'decision making', 'human subject', 'interview', 'nonEnglish language', 'patient safety /medical error', 'phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2006,927498,-0.020910952138261447
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,7243612,R33RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R33,2006,350636,0.00555108919741629
"Intelligent Tutor for WMD EMS Incident Management    DESCRIPTION (provided by applicant): We propose to develop EMS/IM ITS, a suite of simulation-based intelligent tutoring systems and scenarios that will enable practice-based learning of WMD emergency medical services incident management principles and skills, including situation assessment, decision-making, and real-time execution of EMS tasks within an incident command structure. To support practical and economical development of many EMS/IM ITS training scenarios, we will also develop software tools and development methods that enable efficient authoring of new scenarios and adaptation/enhancement of existing scenarios by instructors or subject matter experts, without programming. We will leverage our tutoring system development tools and our experience developing tutoring systems for medical training, command and control, and tactical decision-making. The National Incident Management System (NIMS) was mandated by HSPD-5 to provide a comprehensive, national approach to domestic incident management, so that all levels of government across the nation could work efficiently and effectively together to prepare for, respond to, and recover from domestic incidents. We believe that EMS/IM ITS can contribute to NIMS by providing scenario-based learning of incident management principles for medical first responders, consistent with NIMS, and tailorable via scenario authoring to the specific circumstances and incident management plans of each government organization. This proposed Phase I effort will lay the groundwork for the Phase II effort, by producing 1) requirements and design of the system to be developed during Phase II, 2) a software prototype that illustrates our concept, and 3) a formative evaluation of the prototype and design that provides a basis for estimating the feasibility and effectiveness of the operational system that would be developed during Phase II.             n/a",Intelligent Tutor for WMD EMS Incident Management,7115108,R43ES014801,"['artificial intelligence', 'computer assisted instruction', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'educational resource design /development', 'emergency service /first responder', 'health care personnel education', 'health care professional practice', 'health services research tag', 'medical education', 'method development', 'patient care management', 'training']",NIEHS,"STOTTLER HENKE ASSOCIATES, INC.",R43,2006,99999,-0.003769084248795965
"Trainable Early Warning System for Epileptic Seizures DESCRIPTION (provided by applicant):  Individuals with epilepsy, their families and the professionals that treat them have long felt the need for reliable warning of an impending epileptic seizure. In Phase I, we developed a unique, multi-parameter, individualized, trainable seizure predetection system which extracts spectral, wavelet and time domain features and uses recurrent neural networks to analyze many hours of multichannel EEG and predetect seizure onsets with a high level of accuracy and reliability. The underlying analytical software for this system was tested on large database of scalp EEG recordings from five epilepsy centers and contained over 373 hours of recordings from 17 patients containing 50 seizures. This is a large database compared to those reported by most investigators in this field. Phase I results were very accurate and reliable (sensitivity: 100%, false positive rate 0.02/hr and detection times that occurred an average of 9.1 seconds, before seizure onset). This is entirely acceptable for our primary target application, of warning of a seizure onset to enable timely diagnostic injection to locate the brain region where the seizure starts using SPECT imaging. In Phase II we will refine the detection process, validate performance in a large data set, implement the software in C++ modules, and test the commercial prototype in a clinical setting. These steps will result in a company supported Phase III product development, integration into existing EEG recording systems, beta testing and commercialization. While Phase 2 will concentrate on the SPECT application using scalp electrodes, the scalp EEG techniques developed will be applicable without change for general use in an epilepsy monitoring facility to alert staff of impending seizures and allow them to attend to patient safety in a timely manner. Predetection will also facilitate neuropsychological or other testing in the epilepsy monitoring environment. With additional work, the techniques developed can be applied to ambulatory devices for seizure alert, or for episodic vagal nerve stimulation to block seizures. n/a",Trainable Early Warning System for Epileptic Seizures,7109311,R44NS039214,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain disorder diagnosis', 'brain electrical activity', 'brain imaging /visualization /scanning', 'brain mapping', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'electroencephalography', 'epilepsy', 'human subject', 'neuropsychology', 'noninvasive diagnosis', 'patient monitoring device', 'radiotracer', 'single photon emission computed tomography']",NINDS,"CHATTEN ASSOCIATES, INC.",R44,2006,400929,0.004923444487527682
"Traffic Intersection Analysis Algorithms for the Blind DESCRIPTION (provided by applicant): This project aims to explore, develop and test computer vision algorithms to analyze images of street intersections from a camera worn by a blind person.  Urban intersections are the most dangerous parts of a blind person's travel.  They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult.  We will explore computer vision algorithms to help a blind person find the crosswalk, find the pedestrian signal button, determine when the ""walk"" light is on, and alert him/her to any veering out of the crosswalk.  We will emphasize the development of completely novel methods of analyzing non-ideal images including shadows, occlusions and other irregularities using spatial grouping techniques based on Bayesian inference.  The resulting algorithms are intended for eventual integration as modules for a computer vision system we are already developing to help blind persons with travel tasks such as finding and reading aloud printed signs and negotiating street crossings.  The combined system would have potential for a radical advance in independent travel for blind persons.  In this exploratory project, we aim to: (1) Explore and test alternative approaches to algorithm design to process intersection images and extract the information about the crosswalk, crossing signal, etc., using a database of real-world images taken by blind persons at a variety of different kinds of intersections.  (2) Test the algorithms using a portable camera connected to a notebook computer with speech output. n/a",Traffic Intersection Analysis Algorithms for the Blind,7096566,R21EY015187,"['blind aid', 'blindness', 'clinical research', 'computer simulation', 'computer system design /evaluation', 'gait', 'human subject', 'injury prevention', 'mathematical model', 'statistics /biometry', 'transportation /recreation safety', 'urban area']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2006,214738,-0.0007740408336395909
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,7072754,U01DE013331,"['biomarker', 'biopsy', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'enzyme linked immunosorbent assay', 'facial muscles', 'gas chromatography mass spectrometry', 'human subject', 'inflammation', 'interview', 'magnetic resonance imaging', 'mastication', 'musculoskeletal disorder diagnosis', 'oral facial pain', 'pain threshold', 'psychobiology', 'questionnaires', 'radioimmunoassay', 'sign /symptom', 'statistics /biometry', 'synovial fluid', 'temporomandibular joint syndrome', 'tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2006,371497,-0.006583128058954038
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,7096660,R44CA088684,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biopsy', 'blood cell count', 'bone marrow', 'bone marrow exam', 'cell morphology', 'cell population study', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'flow cytometry', 'hematopoietic stem cells', 'high throughput technology', 'histopathology', 'human tissue', 'image enhancement', 'immunocytochemistry', 'leukemia', 'light emission', 'light microscopy', 'lighting', 'molecular /cellular imaging', 'neoplasm /cancer diagnosis', 'spectrometry']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2006,1029373,-0.025540147170691228
"MobileEye OCR for the Visually Impaired    DESCRIPTION (provided by applicant): In this SBIR we propose to demonstrate the technical feasibility of Mobile OCR, a portable software system which makes use of existing personal devices to provide access to textual materials for the elderly or the visually impaired. The system will help these low vision individuals with basic daily activities, such as shopping, preparing meals, taking medication, and reading traffic signs. It will step beyond our proposed MobileEyes vision enhancement system to apply cutting edge recognition technology for mobile devices. The system will use common camera phone hardware to capture and enhance textual information, perform Optical Character Recognition (OCR) and provide audio or visual feedback. Our research will focus on implementing and integrating new vision enhancement and analysis techniques on limited resource mobile devices. Specifically, we will develop algorithms for detection and rectification of text on planes and generalized cylinders subject to perspective distortions, implement more robust and efficient algorithms and systems for stabilization and enhancement of text blocks, provide mobile OCR on complex textured backgrounds, and implement these techniques on small devices across a variety of platforms. The recognized text will be presented through Text-to-Speech (TTS), or displayed on the device with enhanced quality which can be easily read by low vision users. Phase I will focus on demonstrating the technical feasibility of our approach, and will incorporate a performance measurement methodology to quantitatively evaluate progress and evaluate our system against other approaches. In comparison to existing vision enhancement devices, such as magnifying glasses, telescopes, and text reading devices such as scanner-based OCR, our solution has several advantages: 1) it makes use of a single, portable device (camera cell phone) that is commonly available and typically already carried for its telecommunications capabilities; 2) it can be used selectively by users so they will not be overwhelmed by irrelevant information; and 3) it can be integrated directly with other applications for specialized tasks. Our research results will impact the millions of low-vision individuals and the blind, as well as vision and computer vision researchers. Our team is uniquely qualified to explore the feasibility of extending visual applications to these devices, and provide a platform for integrating future vision algorithms.         n/a",MobileEye OCR for the Visually Impaired,7053650,R43EY017216,"['reading', 'solutions', 'vision']",NEI,"APPLIED MEDIA ANALYSIS, LLC",R43,2006,104935,-0.03093635859431244
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6916483,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2005,321788,-0.034498508195038816
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6910621,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2005,245768,-0.030313512385656206
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6995047,R43EY014487,"['artificial intelligence', 'biomedical equipment development', 'clinical research', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'data collection', 'digital imaging', 'functional ability', 'human subject', 'image processing', 'medical rehabilitation related tag', 'patient oriented research', 'portable biomedical equipment', 'questionnaires', 'vision aid', 'vision disorders', 'visual fields', 'visual perception', 'visual threshold', 'visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2005,144106,-0.009694128863795214
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7052491,R42ES013321,"['artificial intelligence', 'chemical structure function', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug discovery /isolation', 'drug screening /evaluation', 'functional /structural genomics', 'hepatotoxin', 'microarray technology', 'toxicant screening']",NIEHS,"YAHSGS, LLC",R42,2005,180862,-0.019503309328806943
"The BioSense Initiative to Improve Early Event Detection RTI International, in partnership with the University of North Carolina at Chapel Hill (UNC-CH), and in collaboration with the North Carolina Division of Public Health (NC-DPH), is submitting this application to work with the Centers for Disease Control and Prevention (CDC) to improve early detection of disease outbreaks of public health significance. Rapid detection of disease outbreaks rests on a foundation of accurate classification of patient symptoms early in the course of their illness. The overarching objective of this research is to define, evaluate, and standardize a methodology for creating useful case definitions designed for the early detection of intentional and naturally occurring disease outbreaks. The specific aim of this research proposal is to develop and test methods for increasing the sensitivity and specificity of syndrome definitions using timely emergency department data. Improved case definitions will enhance CDC's capacity to detect and investigate threats to the health of the population, which CDC undertakes as part of its mission. Emergency department data may serve as a rich source for early signals of health threats to the population, but case definitions have not been standardized, and new methods are needed to process and use the textual information found within the emergency record. To address these challenges, we propose an innovative and iterative research plan that leverages RTI's and UNC-CH's capabilities to best serve CDC and the public health community. We will use emergency department data captured through North Carolina's Bioterrorism and Emerging Infections Preventive Service, the operational syndromic surveillance system used by NC-DPH to monitor the state. After (1) developing a gold standard data set of ED visits for evaluating syndrome test characteristics, we will (2) evaluate natural language processing for preprocessing chief complaints; (3) explore use of semantic networking tools for developing definitions; (4) apply a reverse engineering process using ICD-9-CM code groupings; and (5) assess the applicability of early event detection for creating situational awareness following detection of an event. These methods will make use of information within the emergency record and create syndrome definitions with acceptable sensitivity, specificity, and positisve predictive value. Valid syndrome definitions will enable public health officials to operate a national monitoring system that can automatically detect signals that may represent disease outbreaks or other potential threats to health. Operation of this system will protect the public health and will strengthen the capacity of public health officials to investigate and respond to these threats rapidly.  n/a",The BioSense Initiative to Improve Early Event Detection,7097771,R01PH000038,"['artificial intelligence', 'biohazard detection', 'bioterrorism /chemical warfare', 'communicable disease diagnosis', 'computer assisted diagnosis', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'disease /disorder classification', 'disease outbreaks', 'early diagnosis', 'emergency health services', 'emerging infectious disease', 'environmental health', 'health services research tag', 'human data', 'informatics', 'interdisciplinary collaboration', 'public health', 'rapid diagnosis', 'vocabulary development for information system']",PHPPO,RESEARCH TRIANGLE INSTITUTE,R01,2005,412947,-0.028423360448003244
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,6832762,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2005,461157,0.016626917597330117
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6881434,R01MH051435,"['artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'emotions', 'face expression', 'human subject', 'image processing', 'interpersonal relations', 'statistics /biometry', 'videotape /videodisc', 'visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2005,358843,-0.003090001677942138
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6841137,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2005,473795,-0.013450546890939039
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6944025,R13CA093819,"['artificial intelligence', 'computer human interaction', 'videotape /videodisc', 'workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2005,5000,0.007224595515132196
"BIOROBOTICS TOOLKIT FOR ENABLING RAPID EXPERIEMENTATION    DESCRIPTION (provided by applicant): We propose to create a biorobotic toolkit for rapid experimentation in the life sciences, medicine, and bioengineering. This toolkit will allow the rapid creation of biorobots derived from reference designs. These reference designs are contributed by the community of researchers. The anticipated outcome will be a vast improvement in methodology in this field. The specific aims of phase I are: (1) The design of 1 reference model (2) Demonstration of a modular plug and play sensor that will be part of a biorobot derived from the reference model (3)Demonstration of a modular plug and play Actuator that will be part of a biorobot derived from the reference model (4) Assemble a robot derived from the reference model, and using the plug and play sensors and actuators achieved in aims 2,3. (5) Quantify the closed loop performance of the sensor-actuator network. (6) Layout a preliminary specification of the architecture.         n/a",BIOROBOTICS TOOLKIT FOR ENABLING RAPID EXPERIEMENTATION,6975326,R43EB004827,"['artificial intelligence', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment', 'biomedical equipment development', 'computational biology', 'model design /development', 'neuropsychology', 'psychological models', 'robotics']",NIBIB,"IGUANA ROBOTICS, INC.",R43,2005,150419,-0.006645548069254409
"Perception and Inter-Observer Variability in Mammography DESCRIPTION (provided by applicant):    Inter-observer variability in mammogram reading has been well documented in the literature. Various factors have been used to explain this variability; among them, the most significant are related to the management of perceived findings.  However, the nature of this inter-observer variability has not been explored. Namely, were the lesions that were consistently reported by the radiologists any different from the ones that yield disagreement? Furthermore, could these differences be quantitatively assessed? Moreover, were these differences in any way related with the experience level of the observer? In addition, the interpretation of perceived findings is closely related with the visual search strategy used to scan the breast tissue, because observers compare perceived findings with the background, in order to determine their uniqueness. Hence, what is the effect of visual search strategy on inter-observer variability? Can this effect be modeled using Artificial Neural Networks (ANNs)? Can inferences be made regarding the observers' decision patterns by analyzing the results of simulations run on the ANNs?  The work described here aims at answering these questions. We will use spatial frequency analysis to characterize the areas on mammogram cases where mammographers, chest radiologists with experience reading mammograms and radiology residents at the end of their mammography rotation, indicate the presence of a finding, or fail to do so. We will assess inter-observer agreement, as well as intra- and inter-group agreement for the various groups of observers. In addition, we will train artificial neural networks to represent each observer, in such a way that by changing the nature of the features input to the ANNs we will be able to simulate how such changes would have affected the actual observer. We will assess the effects on inter-observer variability of changing the search strategy used by the observer to sample the breast tissue. In our setting, the inter-observer variability will be assessed by comparing the outputs of the ANNs that represent each observer. In addition, the changes in sampling strategy will correspond to actual possible strategies for the human observers themselves. n/a",Perception and Inter-Observer Variability in Mammography,6924688,R21CA100107,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasm /cancer diagnosis', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'human data', 'human therapy evaluation', 'mammography', 'visual perception']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2005,167063,-0.038782003974101184
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6951380,R44HL071470,"['artificial intelligence', 'atherosclerotic plaque', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical automation', 'cardiovascular disorder diagnosis', 'clinical research', 'diagnosis design /evaluation', 'human data', 'image processing', 'informatics', 'magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R44,2005,374972,-0.0251864541218124
"Simulation Algorithms for Spatial Pattern Recognition    DESCRIPTION (provided by applicant):    This SBIR project is developing methods and software for the specification, construction and simulation of neutral spatial models, and for applying these neutral models within the framework of probabilistic pattern recognition. Results will allow epidemiologists, environmental scientists and image analysts across a broad range of commercial disciplines to more accurately identify patterns in spatial data by removing the bias towards false positives that is caused by unrealistic null hypotheses such as ""complete spatial randomness"" (CSR). This project will accomplish 5 aims:      1. Conduct a requirements analysis to specify the neutral models and functionality to incorporate in the software.   2. Develop and test a software prototype to evaluate feasibility of the proposed models.   3. Propose a topology of neutral models and develop strategies to generate them and to conduct sensitivity analysis for investigating the impact of implicit assumptions (i.e. spatial autocorrelation or non-uniform risk) and number of realizations on test results.   4. Incorporate the neutral models in the first commercially established software package that allows for user-specified alternate hypothesis in spatial statistical tests.   5. Apply the software and methods to demonstrate the approach and its unique benefits for exposure and health risk assessment.      Feasibility of this project was demonstrated in the Phase I. This Phase II project will accomplish aims three through five. These technologic, scientific and commercial innovations will revolutionize our ability to identify, document and assess the probability of spatial patterns relative to neutral models that incorporate realistic local, spatial and multivariate dependencies. The neutral models and methods in this proposal make possible, for the first time ever, evaluation of the sensitivity of the results of cluster or boundary analyses to specification of the null hypothesis.         n/a",Simulation Algorithms for Spatial Pattern Recognition,6863029,R44CA092807,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'human data', 'image processing', 'imaging /visualization /scanning', 'statistics /biometry', 'visual cortex']",NCI,BIOMEDWARE,R44,2005,498368,-0.002333686871062996
"Multiresolution Autofocusing for Automated Microscopy    DESCRIPTION (provided by applicant): This project will further develop and refine an innovative digital auto-focus technology for automated microscopy. Auto-focusing is essential to automated microscope imaging. Currently available techniques rely on various algorithms of focus computation at a single image resolution and suffer from inherent performance limitations, which affect their success and utilization in clinical and research applications. Auto-focusing for fluorescence microscopy, for example, represents a serious challenge to existing methods for desired accuracy, reliability and speed since in this case the images have very low signal-to-noise ratio and narrow depth-of-fields while specimen exposure to fluorescent excitation must be minimized to avoid photo-bleaching and formation of undesirable substances such as free radicals and singlet oxygen. We propose a novel multi-resolution image analysis approach to microscope auto-focusing, based on the recently developed mathematical theory of wavelet transform. The new approach overcomes a number of inherent limitations of currently available techniques, and holds the promise to make the measurement of the microscope focus function and the detection of best-focus imaging position considerably more accurate, reliable, and fast. This innovative technology will significantly increase the ability and efficacy of automated microscope instruments for a wide range of clinical and research applications where a large number of specimens need to be imaged and quantitatively analyzed on a routine basis. During the Phase 1 project we investigated the feasibility of the proposed technology for fluorescence microscopy. We developed software to implement the algorithms for multi-resolution focus function measurements and for in-focus imaging position search. We evaluated the new approach in software simulation on a variety of sample image stacks of cytogenetic FISH specimens, and compared it with all current best-performing methods for microscope auto-focusing using the criteria of (1) accuracy, (2) range, (3) robustness, and (4) speed. The Phase 1 results suggest that, by using a proper wavelet-based auto-focus function, the new multi-resolution method significantly outperforms all competing methods in each of the aforementioned performance categories, and clearly exceeds the Phase 1 feasibility criteria. In the Phase 2 project, we will further develop, refine, integrate, and validate the new technology in real-time operation environment. We plan to build a prototype system with multi-resolution auto-focusing capabilities for both fluorescence and bright-field microscope imaging. We will evaluate the system extensively for a variety of applications including genetics, pathology, and cytology. We will beta test the new system and technology in routine clinical laboratory environment and optimize the technology as end user input and feedbacks are gathered. Once fully developed and qualified, this new technology will be patented and incorporated into future IRIS automated imaging cytometry instruments. It will also be made commercially available to Applied Imaging Corporation and other manufacturers of automated microscope instruments through licensing agreements and partnerships.           n/a",Multiresolution Autofocusing for Automated Microscopy,6951446,R44RR016817,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'flow cytometry', 'fluorescence microscopy', 'fluorescent in situ hybridization', 'human data', 'image enhancement', 'image processing', 'mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2005,318350,-0.024408626843021433
"Intelligent Adaptive Wireless Reconfigurable EEG    DESCRIPTION (provided by the applicant)  The overall goal of the proposal is to improve ambulatory and long-term EEG monitoring using an innovative wireless EEG system. The specific aim of this proposal is to develop an ambulatory wireless EEG monitoring system with real-time adaptive and re-configuration capabilities, which will allow more clinical data to be transmitted in the same bandwidth and in a small portable package. The proposed device will adapt its data acquisition hardware to the underlying clinical event permitting it to focus its high transmission rates to periods of clinically relevant events. The events will be detected by our powerful seizure monitor algorithm which will have direct control over a flexible and innovative hardware. The result is enhanced wireless EEG in a small package, low power and with data quality comparable to bulkier clinical tethered system. The ability to optimize bandwidth is timely due to new FDA telemetry guidelines, which restricts the availability of frequencies and bandwidths in medical devices. Another advantage to optimizing output is that more meaningful data can be created without excessively large data files, which will speed analysis and review. Finally, the proposed device will be able to dynamically reconfigure itself in real time to compensate for serious data-corrupting events such as when one or several electrodes become loose or detached. In summary, the two major innovations are: 1- Real-time adaptive capability for adjusting the quantity and quality of the acquired and transmitted EEG data to better reflect the underlying clinical event (such as a seizure), 2- more practical and accurate ambulatory monitoring by the real-time automatic reconfiguration of the EEG acquisition system.       In Phase I, we designed, fabricated and tested a prototype system. Bench top and clinical testing showed that the system can indeed modify its output in response to artifacts or changes in EEG morphology. In Phase II, we will complete development including a radio design that meets the new FDA guidelines, and test on long-term patients with epilepsy.               n/a",Intelligent Adaptive Wireless Reconfigurable EEG,6952455,R44NS042999,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'electrodes', 'electroencephalography', 'epilepsy', 'human subject', 'patient monitoring device', 'patient oriented research', 'portable biomedical equipment', 'telemedicine', 'telemetry']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R44,2005,671838,0.0022958796032566753
"Multi-microphone long probe for OAE acquisition DESCRIPTION (provided by applicant): The development of an innovative multi-microphone probe and acquisition system for recording otoacoustic emissions {OAEs} with advanced noise cancellation algorithms, increased frequency and intensity ranges and pressurization capabilities is proposed. Two advanced noise cancellation algorithm will be implemented: 1) a multi-reference adaptive noise cancellation (ANC) network and 2) two-dimensional filtering. These algorithms will utilize the independent measurements provided by the multiple microphones in order to reduce noise contaminants. Each microphone or microphone groupings will be connected to individual analog-to-digital (A/D) converters in order to allow for the implementation of the digital signal processing algorithms. The pressurization capabilities of the probe will allow implementation of tympanometry and the acquisition of OAEs while compensating for pressure imbalances between the outer and middle ear. Results from a prototype single microphone long probe are presented demonstrating that the design concept is valid and provides good quality OAE recordings while reducing the undesirable effects of the metal response. The proposed probe will also improve upon the limited dynamic and frequency range of current OAE probes. The probe is expected to be able to provide stimulus levels of up to 90 dB HL and a frequency response of up to 24 kHz. During Phase I, various probes will be constructed and tested under different noise conditions in adult and infant subjects. During Phase II, the pressurization capabilities of the new probe will be further developed and examined. The optimal probe designed will be implemented along with the optimal noise cancellation algorithm and tested in a comprehensive clinical study incorporating the pressurization capabilities of the probe. n/a",Multi-microphone long probe for OAE acquisition,6933674,R43DC007543,"['adult human (21+)', 'artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical biomedical equipment', 'clinical research', 'computer program /software', 'ear disorder diagnosis', 'infant human (0-1 year)', 'mathematics', 'noise', 'otoacoustic emission', 'sound frequency']",NIDCD,INTELLIGENT HEARING SYSTEMS,R43,2005,100000,0.00542077168407302
"Spatial Modeling in Glaucoma DESCRIPTION (provided by applicant): This career training proposal is to train Michael D. Twa, OD, MS as an independent clinician-scientist. A five year training program is proposed, consisting of formal coursework in vision science, specific training in computer science and image processing, and mentoring in the application of these skills to clinical outcomes research in glaucoma. In September 2003, NIH announced a new ""Roadmap"" to accelerate advances in biomedical research for the 21st century. Three areas listed in this Roadmap are relevant to this research proposal: (1) Interdisciplinary research training. (2) Clinical research informatics. (3) Development of enabling technologies for improved assessment of clinical outcomes. The Roadmap emphasizes coordinated strategies to develop both technological and human resources to take full advantage of multidisciplinary and translational research opportunities. This proposal addresses the stated training objectives at an individual level.  Glaucoma is a leading cause of blindness. Visual field assessment and optic nerve head imaging (confocal scanning laser tomography) are commonly used to diagnose the disease and monitor its progression, yet there is considerable controversy about how to interpret and make best use of this information. Currently, raw data from these observations are reduced to statistical indices that are meant to summarize clinically meaningful features and provide a basis for classifying test results as normal or not. Unfortunately, these indices may sacrifice other relevant features in the data for interpretability.  We will use mathematical modeling methods (polynomial modeling, spline fitting and wavelet analysis) to quantify patterns in visual field data and topographic images of the optic nerve head. We will use features derived from these modeling methods to apply novel pattern recognition techniques from computer and information sciences-decision trees and non-linear regression analysis-and then compare these techniques to current methods to identify glaucoma. By improving current methods of analysis we can provide a more quantitative basis for clinical decisions, and offer greater consistency and objectivity on data interpretation. The long-term objective of this proposal is to translate advances in computer and information sciences to the analysis of clinical outcomes research in glaucoma and other eye diseases. n/a",Spatial Modeling in Glaucoma,6863529,K23EY016225,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer assisted diagnosis', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human data', 'image processing', 'mathematical model', 'model design /development', 'neuroimaging', 'optic nerve', 'patient oriented research', 'tomography', 'visual fields']",NEI,OHIO STATE UNIVERSITY,K23,2005,143096,-0.033956289756003746
"Paperless Quality Donor System with Decision Making DESCRIPTION (provided by applicant):    The long-term objectives of this project are to improve the safety and availability of the US blood supply. The principal aim of this SBIR Competing Continuation Phase II Proposal for a Paperless Quality Donor System with Decision Making is to complete the development of its Quality Donor System(tm) (QDS) and to secure ongoing 510(k) clearances for it from the US Food & Drug Administration (FDA), Center for Biologies Evaluation and Research (CBER) for implementation and evaluation of the total system in blood centers and hospital blood banks.      The research is based on continuing development of the Quality Donor System and deploying it in regional blood centers and hospital blood banks. System use by donors and staff and user satisfaction will be measured and analyzed to assess success. Blood safety is enhanced by eliminating FDA-reportable errors and by increasing blood donor honesty in disclosing risky behaviors. Blood availability is enhanced by increasing donor satisfaction, resulting in higher return rates for new blood donors and increasing employer sponsorship of blood drives. n/a",Paperless Quality Donor System with Decision Making,6990079,R44HL072635,"['Internet', 'artificial intelligence', 'blood bank /supply contamination', 'blood donor', 'case history', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'decision making', 'human subject', 'interview', 'nonEnglish language', 'patient safety /medical error', 'phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2005,910764,-0.020910952138261447
"A Run-to-Run Algorithm for Glucose Regulation DESCRIPTION (provided by applicant):    The long term objective of this work is to develop new algorithmic approaches to optimize the delivery of insulin in an automated fashion to people with type 1 diabetes. Specifically, we aim to develop a strategy, inspired by run-to-run control theory established by the chemical process industries, that ""learns"" from the previous sequence of glucose responses to insulin dosing (over the course of days), and optimally predicts the appropriate strategy for the forthcoming day. The notion of a ""cycle"" in engineering will be extended to manage the 24 hour routine of repeated meals, activities, and sleep cycles and the corresponding dosing of insulin. The algorithm will be tested in both simulation and clinical trials for robustness to sensor noise, uncertainty in the patient characterization, variability in the timing of the postprandial glucose peak, and variability in the carbohydrate content in the meals. The Specific Aims of this project are to: i) construct predictive patient sensitivity models for calculation of optimal insulin dosing from elevated (or depressed) glucose levels, ii) develop run-to-run algorithm for insulin bolus dosing to provide corrections in subsequent days based on previous history of glucose levels and insulin dosage, and iii) evaluate the robustness of the algorithm through meal challenges of varying carbohydrate content. The aims will blend prototype algorithms that are drawn from systems engineering with validation in a series of clinical tests. The proposed collaboration between systems engineers and renowned diabetes researchers in an established clinical research setting will allow a novel fusion of methods that can be truly characterized as ""innovative"". The medical collaborators in the proposal are located at the prestigious Sansum Medical Research Institute, which is located less than 10 miles from the campus of the University of California, Santa Barbara. The exchange of personnel will be facilitated, allowing the student and post-doc supported on this project to work at both the institute and the university over the span of the project n/a",A Run-to-Run Algorithm for Glucose Regulation,6953163,R01DK068663,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical automation', 'blood glucose', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer simulation', 'dietary carbohydrates', 'drug administration rate /duration', 'drug delivery systems', 'glucose metabolism', 'human subject', 'insulin dependent diabetes mellitus', 'insulin sensitivity /resistance', 'mathematical model', 'model design /development', 'patient oriented research']",NIDDK,SANSUM DIABETES RESEARCH INSTITUTE,R01,2005,202350,-0.029092389071194467
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,6914863,R21RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R21,2005,167918,0.00555108919741629
"Trainable Early Warning System for Epileptic Seizures DESCRIPTION (provided by applicant):  Individuals with epilepsy, their families and the professionals that treat them have long felt the need for reliable warning of an impending epileptic seizure. In Phase I, we developed a unique, multi-parameter, individualized, trainable seizure predetection system which extracts spectral, wavelet and time domain features and uses recurrent neural networks to analyze many hours of multichannel EEG and predetect seizure onsets with a high level of accuracy and reliability. The underlying analytical software for this system was tested on large database of scalp EEG recordings from five epilepsy centers and contained over 373 hours of recordings from 17 patients containing 50 seizures. This is a large database compared to those reported by most investigators in this field. Phase I results were very accurate and reliable (sensitivity: 100%, false positive rate 0.02/hr and detection times that occurred an average of 9.1 seconds, before seizure onset). This is entirely acceptable for our primary target application, of warning of a seizure onset to enable timely diagnostic injection to locate the brain region where the seizure starts using SPECT imaging. In Phase II we will refine the detection process, validate performance in a large data set, implement the software in C++ modules, and test the commercial prototype in a clinical setting. These steps will result in a company supported Phase III product development, integration into existing EEG recording systems, beta testing and commercialization. While Phase 2 will concentrate on the SPECT application using scalp electrodes, the scalp EEG techniques developed will be applicable without change for general use in an epilepsy monitoring facility to alert staff of impending seizures and allow them to attend to patient safety in a timely manner. Predetection will also facilitate neuropsychological or other testing in the epilepsy monitoring environment. With additional work, the techniques developed can be applied to ambulatory devices for seizure alert, or for episodic vagal nerve stimulation to block seizures. n/a",Trainable Early Warning System for Epileptic Seizures,7287646,R44NS039214,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain disorder diagnosis', 'brain electrical activity', 'brain imaging /visualization /scanning', 'brain mapping', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'electroencephalography', 'epilepsy', 'human subject', 'neuropsychology', 'noninvasive diagnosis', 'patient monitoring device', 'radiotracer', 'single photon emission computed tomography']",NINDS,"CHATTEN ASSOCIATES, INC.",R44,2005,91900,0.004923444487527682
"Trainable Early Warning System for Epileptic Seizures DESCRIPTION (provided by applicant):  Individuals with epilepsy, their families and the professionals that treat them have long felt the need for reliable warning of an impending epileptic seizure. In Phase I, we developed a unique, multi-parameter, individualized, trainable seizure predetection system which extracts spectral, wavelet and time domain features and uses recurrent neural networks to analyze many hours of multichannel EEG and predetect seizure onsets with a high level of accuracy and reliability. The underlying analytical software for this system was tested on large database of scalp EEG recordings from five epilepsy centers and contained over 373 hours of recordings from 17 patients containing 50 seizures. This is a large database compared to those reported by most investigators in this field. Phase I results were very accurate and reliable (sensitivity: 100%, false positive rate 0.02/hr and detection times that occurred an average of 9.1 seconds, before seizure onset). This is entirely acceptable for our primary target application, of warning of a seizure onset to enable timely diagnostic injection to locate the brain region where the seizure starts using SPECT imaging. In Phase II we will refine the detection process, validate performance in a large data set, implement the software in C++ modules, and test the commercial prototype in a clinical setting. These steps will result in a company supported Phase III product development, integration into existing EEG recording systems, beta testing and commercialization. While Phase 2 will concentrate on the SPECT application using scalp electrodes, the scalp EEG techniques developed will be applicable without change for general use in an epilepsy monitoring facility to alert staff of impending seizures and allow them to attend to patient safety in a timely manner. Predetection will also facilitate neuropsychological or other testing in the epilepsy monitoring environment. With additional work, the techniques developed can be applied to ambulatory devices for seizure alert, or for episodic vagal nerve stimulation to block seizures. n/a",Trainable Early Warning System for Epileptic Seizures,6993754,R44NS039214,"['artificial intelligence', 'bioimaging /biomedical imaging', 'brain disorder diagnosis', 'brain electrical activity', 'brain imaging /visualization /scanning', 'brain mapping', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'electroencephalography', 'epilepsy', 'human subject', 'neuropsychology', 'noninvasive diagnosis', 'patient monitoring device', 'radiotracer', 'single photon emission computed tomography']",NINDS,"ASTRO-MED, INC.",R44,2005,306142,0.004923444487527682
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6935840,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2005,399984,-0.03427802836608889
"Medical Advice from Glaucoma Informatics (MAGI)  DESCRIPTION (provided by applicant):  The project, Medical Advice from Glaucoma Informatics (MAGI), seeks to improve glaucoma diagnosis and management with state-of-the-art machine learning classifiers. These classifiers will automate the interpretation of standard automated perimetry (SAP), newer visual field tests, and structural tests for glaucoma in the general population and in stratified glaucoma populations. Phase 1 will complete the feasibility testing already underway. Phase 2 will apply the refined methods to a wider set of glaucoma testing problems.The management of glaucoma depends on a series of classifications. The glaucoma provider classifies tests as normal or indicative of glaucoma. The clinician then determines whether an eye has glaucoma or has had progression. Assembling these classifications, the provider makes decisions about management. Automated test interpreters, either as part of the testing machine or as a computer-based resource, can aid glaucoma providers with real-time interpretations. The research we propose takes advantage of our extensive data sets and builds on the ongoing research in our laboratories.Statistical classifiers, Bayesian nets, machine learning classifiers, and expert systems represent different types of classifiers with diverse properties. Machine learning classifiers can perform exceptionally well at identifying classes, even when the data are complex and have dependencies. We will test and select the optimal machine learning classifier for diagnosis. We will further improve classifier performance and determine feature utility by optimizing the feature set visual field tests are time consuming and stressful. We will streamline the tests by removing unimportant test points.Even with decades of experience, there is uncertainty with regard to the evaluation of the SAP. There is less accumulated knowledge about non-standard tests, such as short-wavelength automated perimetry, nerve fiber layer thickness, or optic nerve head topography. Machine classifiers may learn how to interpret nonstandard tests better. We will go beyond STATPAC's capabilities with classifiers that have learned to interpret SAP, nonstandard visual field tests, structural glaucoma tests, and STATPAC plots in the general population and in patients stratified by race, family history, and other information available at the time of the test.Conversion of suspects to glaucoma and progression of glaucoma cannot yet be predicted from tests. We will develop classifiers for these predictions. Classifiers will be designed to diagnose early glaucoma, detect early progression, and identify glaucomatous eyes at risk of progression.Unsupervised learning provides cluster analysis that can determine distinct groups with members in some way similar from the test data. In an effort to discover new and use useful information with unsupervised learning, we will mine our data in visual function and structural tests for glaucoma  and in specific combinations of population groups. n/a",Medical Advice from Glaucoma Informatics (MAGI),6937074,R33EY013928,"['clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human subject', 'neural information processing', 'neuropathology', 'visual fields']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R33,2005,606534,-0.03611527391044353
"Traffic Intersection Analysis Algorithms for the Blind DESCRIPTION (provided by applicant): This project aims to explore, develop and test computer vision algorithms to analyze images of street intersections from a camera worn by a blind person.  Urban intersections are the most dangerous parts of a blind person's travel.  They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult.  We will explore computer vision algorithms to help a blind person find the crosswalk, find the pedestrian signal button, determine when the ""walk"" light is on, and alert him/her to any veering out of the crosswalk.  We will emphasize the development of completely novel methods of analyzing non-ideal images including shadows, occlusions and other irregularities using spatial grouping techniques based on Bayesian inference.  The resulting algorithms are intended for eventual integration as modules for a computer vision system we are already developing to help blind persons with travel tasks such as finding and reading aloud printed signs and negotiating street crossings.  The combined system would have potential for a radical advance in independent travel for blind persons.  In this exploratory project, we aim to: (1) Explore and test alternative approaches to algorithm design to process intersection images and extract the information about the crosswalk, crossing signal, etc., using a database of real-world images taken by blind persons at a variety of different kinds of intersections.  (2) Test the algorithms using a portable camera connected to a notebook computer with speech output. n/a",Traffic Intersection Analysis Algorithms for the Blind,6920594,R21EY015187,"['blind aid', 'blindness', 'clinical research', 'computer simulation', 'computer system design /evaluation', 'gait', 'human subject', 'injury prevention', 'mathematical model', 'statistics /biometry', 'transportation /recreation safety', 'urban area']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2005,255198,-0.0007740408336395909
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6901098,U01DE013331,"['biomarker', 'biopsy', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'enzyme linked immunosorbent assay', 'facial muscles', 'gas chromatography mass spectrometry', 'human subject', 'inflammation', 'interview', 'magnetic resonance imaging', 'mastication', 'musculoskeletal disorder diagnosis', 'oral facial pain', 'pain threshold', 'psychobiology', 'questionnaires', 'radioimmunoassay', 'sign /symptom', 'statistics /biometry', 'synovial fluid', 'temporomandibular joint syndrome', 'tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2005,1520994,-0.006583128058954038
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,6938339,R44CA088684,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biopsy', 'blood cell count', 'bone marrow', 'bone marrow exam', 'cell morphology', 'cell population study', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'flow cytometry', 'hematopoietic stem cells', 'high throughput technology', 'histopathology', 'human tissue', 'image enhancement', 'immunocytochemistry', 'leukemia', 'light emission', 'light microscopy', 'lighting', 'molecular /cellular imaging', 'neoplasm /cancer diagnosis', 'spectrometry']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2005,1000582,-0.025540147170691228
"Development of Ultrasonic Appratus for Dental Diagnosis DESCRIPTION: An ultrasonic diagnostic apparatus has been proposed for Dental applications in determining tooth pathologies such as demineralization/caries, hidden fractures, and formation of abscesses. The equipment adopts a piezoelectric and laser optic hybrid transduction system for interrogation of teeth. Ultrasonic responses of the tooth structure will be analyzed by a pattern recognition expert system (artificial intelligence) to determine the diagnosis of the tooth inspected. The proposed research will eventually help to reduce the use of harmful X-ray radiation in Dental clinics and contribute to artificial intelligence based diagnosis. The proposed concept has been successfully demonstrated in the previous Phase I study. In this Phase II study, instrumentation for clinical data collection using a combination of conventional piezoelectric and new laser-based ultrasonic technologies will be developed and optimized; an artificial intelligence based diagnostic function will be developed using clinical data and implemented using embedded computing; numerical simulations will be used to enhance diagnostic function development; and finally, initial clinical trials will be conducted to demonstrate the performance of the prototype equipment. The ultrasonic apparatus for Dental diagnosis outlined in this application is a first application of AI-based NDE in Dentistry. The research concept may also extend to periodontal and craniofacial applications. n/a",Development of Ultrasonic Appratus for Dental Diagnosis,6777482,R44DE014270,"['artificial intelligence', 'biomedical equipment development', 'clinical research', 'clinical trials', 'dental disorder diagnosis', 'dental structure', 'dentistry', 'diagnosis design /evaluation', 'human subject', 'patient oriented research', 'tooth', 'tooth surface']",NIDCR,AAC INTERNATIONAL,R44,2004,367866,0.00029467509528327866
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6799187,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2004,321983,-0.034498508195038816
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6740904,R24HD038585,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biological signal transduction', 'biomedical automation', 'biomedical equipment development', 'clinical research', 'electromyography', 'evaluation /testing', 'human subject', 'motor neurons', 'neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2004,626002,-0.04028588234762947
"A Laser-Based Device for Work Site Stability Assessment DESCRIPTION (provided by applicant): A laser-based acoustic emission (AE) detection device is proposed (Phase I & II) for work site structural stability assessment in order to reduce the occupational injuries and fatalities caused by roof falls, sidewall crumples, stop collapses, slope slides, etc., in the mining industry. This applied research and development addresses the miner's safety and contributes to ensuring the mineworker's right to ""safe and healthful working conditions"" (Occupational Safety and Health Act of 1970). This new device will take advantage of innovations in laser ultrasonic, artificial intelligence (AI) and conventional acoustic emission technology to provide mine workers with a unique instant, real time stability assessment of immediate rock structures in the working environment, which was not attainable in the past. This research will also result in a unique non-contact monitoring device for acoustic emission/microseismic studies, which will be very useful in many areas of application. The primary objective of the Phase I research is to demonstrate under laboratory conditions the concept of the laser device for stability assessment, and to construct a prototype setup for further development and optimization in the subsequent Phase II research. This primary objective consists of five specific aims: 1. Specimen preparation, 2. Development of laser-based AE monitor, 3. AE data collection and failure criteria development, 4. laboratory demonstration, and 5. final report and Phase II proposal. n/a",A Laser-Based Device for Work Site Stability Assessment,6730974,R43OH007662,"['artificial intelligence', 'bioengineering /biomedical engineering', 'data collection methodology /evaluation', 'human mortality', 'injury prevention', 'interferometry', 'lasers', 'mechanical stress', 'minings', 'monitoring device', 'occupational hazard', 'occupational health /safety', 'sound perception', 'technology /technique development', 'ultrasonography', 'work site']",NIOSH,AAC INTERNATIONAL,R43,2004,99998,-0.002611605372279733
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6774688,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2004,242058,-0.030313512385656206
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,6739928,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2004,462571,0.016626917597330117
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6907787,R01MH051435,"['artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'emotions', 'face expression', 'human subject', 'image processing', 'interpersonal relations', 'statistics /biometry', 'videotape /videodisc', 'visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2004,42260,-0.003090001677942138
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6736314,R01MH051435,"['artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'emotions', 'face expression', 'human subject', 'image processing', 'interpersonal relations', 'statistics /biometry', 'videotape /videodisc', 'visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2004,305282,-0.003090001677942138
"Modeling the Nonmanuals in American Sign Language    DESCRIPTION (provided by applicant): This revised proposal describes a project to systematically investigate the facial components, combinations of components, and interactions of components that constitute facial expressions (nonmanual markers) in the grammar of American Sign Language (ASL). Some of these components have already been shown to differ in significant ways from those used by the general hearing population. They may carry semantic, prosodic, pragmatic, and syntactic information that may not be provided by the manual signing itself. We will compile an inventory of facial articulations, construct a database of video images of these in isolation and in context, and use these data and innovative computational tools to construct a model of facial behavior in ASL. To successfully accomplish this, we propose an innovative integrated linguistic and computational approach to the study of nonmanuals. Our goal in this project is to construct an initial phonological model of ASL nonmanuals. We have targeted a relevant set of facial features and have identified 4 experiments to obtain appropriate information on each of them. A necessary step in preparation for these experiments is to develop computer vision and pattern recognition algorithms that automatically extract these facial features from a large quantity of videos. These algorithms will be capable of processing data more accurately and efficiently than can be done by hand. Finally, by comparing these results with those obtained from native ASL signers in a series of perceptual studies, we can determine what further modifications are still needed. The study of facial expressions in ASL has very practical applications to several areas affecting the lives of Deaf individuals. The absence of clear information on the facial components makes teaching them to individuals trying to learn ASL, such as parents, deaf children, future teachers and interpreters, a pedagogical nightmare. Another important practical application is the development of systems that automatically recognize ASL. Such a system is not feasible without the ability to handle ASL nonmanuals, which carry grammatical information.         n/a",Modeling the Nonmanuals in American Sign Language,6733239,R01DC005241,"['artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'communication behavior', 'communication disorder aid', 'computational biology', 'computer data analysis', 'computer simulation', 'computer system design /evaluation', 'face expression', 'human subject', 'information systems', 'paralinguistic behavior', 'phonology', 'semantics', 'sign language', 'video recording system', 'videotape /videodisc']",NIDCD,PURDUE UNIVERSITY WEST LAFAYETTE,R01,2004,499766,-0.013450546890939039
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6793307,R13CA093819,"['artificial intelligence', 'computer human interaction', 'videotape /videodisc', 'workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2004,5000,0.007224595515132196
"Markov Chain Monte Carlo and Exact Logistic Regression    DESCRIPTION (provided by applicant): Today, software for fitting logistic regression models to binary data belongs in the toolkit of every professional biostatistician, epidemiologist, and social scientist. A natural follow-up to this development is the adoption of exact logistic regression by mainstream biostatisticians and data analysts for any setting in which the accuracy of a statistical analysis based on large-sample maximum likelihood theory is in doubt. Cutting-edge researchers in biometry and numerous other fields have already recognized that it is necessary to supplement inference based on large-sample methods with exact inference for small, sparse and unbalanced data. The LogXact software package developed by Cytel Software Corporation fills this need. It has been used since its inception in 1993 to produce exact inferences for data generated from a wide range fields including clinical trials, epidemiology, disease surveillance, insurance, criminology, finance, accounting, sociology and ecology. In all these applications exact logistic regression was adopted because the limitations of the corresponding asymptotic procedures were clearly recognized in advance by the investigators and the exact inference was computationally feasible. But most of the time it will not be obvious whether asymptotic or exact methods are applicable. Ideally one would prefer to run both types of analyses if there is any doubt about the appropriateness of the asymptotic inference. However, because of the computational limits of the exact algorithms, investigators are currently inhibited from attempting the exact analysis. There is uncertainty about the how long the computations will take and even whether they will produce any results at all before the computer runs out of memory. The current project eliminates this uncertainty by introducing a new generation of numerical algorithms that utilize network based Monte Carlo rejection sampling. The Phase 1 progress report has demonstrated that these new algorithms can speed up the computations by factors of 50 to 1000 relative to what is currently available in LogXact. More importantly they can predict how long a job will take so that the user may decide whether to proceed at once or at a better time. The Phase 2 effort aims to incorporate this new generation of computing algorithms into future versions of LogXact.         n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6703756,R44CA093112,"['artificial intelligence', 'clinical research', 'computer data analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'mathematics', 'statistics /biometry']",NCI,"CYTEL, INC",R44,2004,411387,-0.004610843341649574
"Perception and Inter-Observer Variability in Mammography DESCRIPTION (provided by applicant):    Inter-observer variability in mammogram reading has been well documented in the literature. Various factors have been used to explain this variability; among them, the most significant are related to the management of perceived findings.  However, the nature of this inter-observer variability has not been explored. Namely, were the lesions that were consistently reported by the radiologists any different from the ones that yield disagreement? Furthermore, could these differences be quantitatively assessed? Moreover, were these differences in any way related with the experience level of the observer? In addition, the interpretation of perceived findings is closely related with the visual search strategy used to scan the breast tissue, because observers compare perceived findings with the background, in order to determine their uniqueness. Hence, what is the effect of visual search strategy on inter-observer variability? Can this effect be modeled using Artificial Neural Networks (ANNs)? Can inferences be made regarding the observers' decision patterns by analyzing the results of simulations run on the ANNs?  The work described here aims at answering these questions. We will use spatial frequency analysis to characterize the areas on mammogram cases where mammographers, chest radiologists with experience reading mammograms and radiology residents at the end of their mammography rotation, indicate the presence of a finding, or fail to do so. We will assess inter-observer agreement, as well as intra- and inter-group agreement for the various groups of observers. In addition, we will train artificial neural networks to represent each observer, in such a way that by changing the nature of the features input to the ANNs we will be able to simulate how such changes would have affected the actual observer. We will assess the effects on inter-observer variability of changing the search strategy used by the observer to sample the breast tissue. In our setting, the inter-observer variability will be assessed by comparing the outputs of the ANNs that represent each observer. In addition, the changes in sampling strategy will correspond to actual possible strategies for the human observers themselves. n/a",Perception and Inter-Observer Variability in Mammography,6821032,R21CA100107,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasm /cancer diagnosis', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'human data', 'human therapy evaluation', 'mammography', 'visual perception']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2004,153968,-0.038782003974101184
"Multiparametric Computational Echocardiography DESCRIPTION (provided by applicant):    In the United States, myocardial ischemia is the underlying etiology in nearly 70% of the 5 million patients suffering from mechanical failure of the cardiac left ventricle (LV). Echocardiography (echo) is well suited for the analysis of LV function, however, the problem of conveying this clinically important information in a quantitative, objective, and reproducible manner persists.      To address this problem and respond to the NIH PA-00-117 solicitation for innovations in biomedical information science and technology, the long-term goal of the proposed R21/R33 project is to develop methods for 1) quantitative and objective measurement of LV function, 2) reproducible diagnostic interpretation based on these measurements, and 3) standardized topologic mapping and parametric display of the results. We defined 3 parameters of LV function: 1) rate of local deformation (strain rate), 2) amplitude of deformation (strain), and 3) time interval to the transition (crossover) point of cyclic deformation.      The practical implementation of the long-term objectives will be achieved through the development of a Multiparametric Computational Echo (MPCE) system. The main hypothesis of this R21/R33 project is that the MPCE system will a) precisely and accurately quantitate (R21 phase) and b) reproducibly clinically interpret (R33 phase) segmental LV function. This hypothesis will be tested on digital echo data from animal models and clinical cases of myocardial ischemia representing a wide range of segmental LV dysfunction.      Specific Aims (R21 phase):   Aim 1 - Develop algorithms for parametric analysis of local ventricular function (Year 1).   Aim 2 - Test precision and accuracy of local LV functional analysis using MPCE (Year 2).   Satisfaction of the predefined milestones will initiate the commencement of the R33 phase.      Specific Aims (R33 phase):   Aim 1 - Develop a neural network MPCE system and test it initially in animals (Year 3).   Aim 2 - Refine parametric mapping and test reproducibility of MPCE data in humans (Year 4).   Successful completion of this project will result in noninvasive, quantitative, objective, and reproducible interpretation of LV function, thus facilitating optimal diagnostic and therapeutic decisions in cardiology. n/a",Multiparametric Computational Echocardiography,6783325,R21HL070363,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'echocardiography', 'evaluation /testing', 'heart function', 'human subject', 'method development', 'swine']",NHLBI,MAYO CLINIC,R21,2004,144693,-0.011566957241932229
"Physiological Controller for Rotary Blood Pumps DESCRIPTION (provided by applicant):    As the prospects of chronic mechanical assistance for the failing human heart are fast becoming a reality, and patients are indeed returning home to regain a normal lifestyle, the limitations of this technology upon quality of life are becoming more apparent. To address many of these limitations, investigators are developing next-generation ventricular assist devices. Based on turbopump technology, these new devices offer smaller size, greater efficiency (hence smaller batteries), high reliability, and are more cost effective as compared to their pulsatile predecessors. For all the virtues of these new turbopumps, they bring additional challenges. Arguably the most urgent is the need for added ""intelligence."" These relatively ignorant devices are highly dependent on feedback-control to provide normal physiological response. The goal of the Phase- II effort proposed herein is to design a robust controller that may be incorporated into these turbodynamic pump systems for clinical use. The primary end product of this program would be a validated algorithm, in the form of firmware that will be embedded into existing rotary pump controller -- capable of maintaining optimal perfusion of the patient under a variety of hemodynamic demands and disturbances, while avoiding deleterious conditions such as ventricular suction. n/a",Physiological Controller for Rotary Blood Pumps,6803953,R44HL066656,"['artificial intelligence', 'auxiliary heart prosthesis', 'biomedical device power system', 'biomedical equipment development', 'cardiac output', 'circulatory assist', 'computer system design /evaluation', 'cow', 'electrophysiology', 'hemolysis', 'mathematical model', 'microprocessor /microchip', 'sheep']",NHLBI,"LAUNCHPOINT TECHNOLOGIES, INC.",R44,2004,374766,-0.007830178038866932
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6833334,R44HL071470,"['artificial intelligence', 'atherosclerotic plaque', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical automation', 'cardiovascular disorder diagnosis', 'clinical research', 'diagnosis design /evaluation', 'human data', 'image processing', 'informatics', 'magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R44,2004,374972,-0.0251864541218124
"Intelligent Adaptive Wireless Reconfigurable EEG    DESCRIPTION (provided by the applicant)  The overall goal of the proposal is to improve ambulatory and long-term EEG monitoring using an innovative wireless EEG system. The specific aim of this proposal is to develop an ambulatory wireless EEG monitoring system with real-time adaptive and re-configuration capabilities, which will allow more clinical data to be transmitted in the same bandwidth and in a small portable package. The proposed device will adapt its data acquisition hardware to the underlying clinical event permitting it to focus its high transmission rates to periods of clinically relevant events. The events will be detected by our powerful seizure monitor algorithm which will have direct control over a flexible and innovative hardware. The result is enhanced wireless EEG in a small package, low power and with data quality comparable to bulkier clinical tethered system. The ability to optimize bandwidth is timely due to new FDA telemetry guidelines, which restricts the availability of frequencies and bandwidths in medical devices. Another advantage to optimizing output is that more meaningful data can be created without excessively large data files, which will speed analysis and review. Finally, the proposed device will be able to dynamically reconfigure itself in real time to compensate for serious data-corrupting events such as when one or several electrodes become loose or detached. In summary, the two major innovations are: 1- Real-time adaptive capability for adjusting the quantity and quality of the acquired and transmitted EEG data to better reflect the underlying clinical event (such as a seizure), 2- more practical and accurate ambulatory monitoring by the real-time automatic reconfiguration of the EEG acquisition system.       In Phase I, we designed, fabricated and tested a prototype system. Bench top and clinical testing showed that the system can indeed modify its output in response to artifacts or changes in EEG morphology. In Phase II, we will complete development including a radio design that meets the new FDA guidelines, and test on long-term patients with epilepsy.               n/a",Intelligent Adaptive Wireless Reconfigurable EEG,6888368,R44NS042999,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'electrodes', 'electroencephalography', 'epilepsy', 'human subject', 'patient monitoring device', 'patient oriented research', 'portable biomedical equipment', 'telemedicine', 'telemetry']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R44,2004,416347,0.0022958796032566753
"Wireless EEG/PSG System with Novel Artifact Removal DESCRIPTION (provided by applicant): EEG is a valuable non-invasive clinical tool in numerous applications, from the diagnosis and treatment of brain diseases to the clinical monitoring of neurological injuries, sleep disorders and depth of anesthesia.  However, EEG signals are very susceptible to various artifacts which seriously impede the EEG interpretation and compromise its therapeutic capabilities. Methods currently employed for removing artifacts from EEG recordings are not clinically effective or feasible for real-time and long-term neuro-monitoring. Hence, the overall goal of this project is to develop a novel, high-fidelity artifact identification and removal technique that will be specifically useful for ambulatory EEG recording and intervention.      The proposed novel artifact removal technique is based on the Wavelet-Based Artifact Removal (WBAR) method, which exploits the excellent time-frequency localization of artifacts provided by the wavelet decomposition. The WBAR method is computationally very efficient and allows for simultaneous, real-time removal of a variety of EEG artifacts. It has been recently developed by the PI and tested for a single EEG channel in an extensive clinical study as part of a novel depth-of-anesthesia monitor.       The WBAR method will be improved by combining it with the Wavelet Neural Networks for the precise artifact classification, and recursive EEG Parameterization methods for the reliable estimation of the corrupted EEG components. The combination of these methods will result in fully automated, real-timeartifact removal technique that maximally preserves valid EEG information.       The development and implementation of this novel method will greatly enhance the functionality and  utilization of Cleveland Medical Devices' entire line of ambulatory wireless EEG/PSG systems. n/a",Wireless EEG/PSG System with Novel Artifact Removal,6792393,R43NS046978,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'brain electrical activity', 'clinical biomedical equipment', 'clinical research', 'computer program /software', 'electroencephalography', 'human subject', 'patient monitoring device', 'patient oriented research', 'polysomnography', 'portable biomedical equipment', 'sleep']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R43,2004,204478,-0.026424896631839195
"Epileptic Seizures in the Neonatal EEG   DESCRIPTION: (provided by applicant) The identification of electrographic            seizures during long-term EEG monitoring in the neonate is currently based upon      visual interpretation of the graphic record, a process that is very                  time-consuming. While significant progress has been made in the automated            detection of seizures in the adult population, relatively little work has been       done in the neonatal area. Therefore, the major objective of this project is         the development of techniques for the reliable automated detection of                electrographic seizures in the neonatal EEG. We propose a multi-stage, hybrid        approach to detection that will employ a combination of signal processing,           pattern recognition, neural networks, and expert rules. Through the successive       stages of the detection process, multichannel neonatal EEG data containing all       types of background activity and artifacts will be analyzed to detect and            classify electrographic seizures. We postulate that the varied types and             morphologies of seizures in the neonatal EEG, as compared to seizures in the         adult EEG, can best be detected and classified using this hybrid approach. We        will test the methods we develop on data recorded from infants in the Clinical       Research Center for Neonatal Seizures, The Methodist Hospital, in Houston,           Texas. We expect that the information we gain from the research will lead to         the development of a practical seizure detection system and further our              long-term goals of reduced expense in the reading and interpretation of              neonatal EEGs, and also facilitate the efficient collection of seizure               parameters for possible use in future research studies.                                                                                                                   n/a",Epileptic Seizures in the Neonatal EEG,6780874,R01NS040577,"['adult human (21+)', 'age difference', 'artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'brain electrical activity', 'computer assisted diagnosis', 'electroencephalography', 'epilepsy', 'human subject', 'newborn human (0-6 weeks)', 'patient monitoring device', 'patient oriented research']",NINDS,UNIVERSITY OF HOUSTON,R01,2004,194888,-0.01324190809223535
"Multiresolution Autofocusing for Automated Microscopy    DESCRIPTION (provided by applicant): This project will further develop and refine an innovative digital auto-focus technology for automated microscopy. Auto-focusing is essential to automated microscope imaging. Currently available techniques rely on various algorithms of focus computation at a single image resolution and suffer from inherent performance limitations, which affect their success and utilization in clinical and research applications. Auto-focusing for fluorescence microscopy, for example, represents a serious challenge to existing methods for desired accuracy, reliability and speed since in this case the images have very low signal-to-noise ratio and narrow depth-of-fields while specimen exposure to fluorescent excitation must be minimized to avoid photo-bleaching and formation of undesirable substances such as free radicals and singlet oxygen. We propose a novel multi-resolution image analysis approach to microscope auto-focusing, based on the recently developed mathematical theory of wavelet transform. The new approach overcomes a number of inherent limitations of currently available techniques, and holds the promise to make the measurement of the microscope focus function and the detection of best-focus imaging position considerably more accurate, reliable, and fast. This innovative technology will significantly increase the ability and efficacy of automated microscope instruments for a wide range of clinical and research applications where a large number of specimens need to be imaged and quantitatively analyzed on a routine basis. During the Phase 1 project we investigated the feasibility of the proposed technology for fluorescence microscopy. We developed software to implement the algorithms for multi-resolution focus function measurements and for in-focus imaging position search. We evaluated the new approach in software simulation on a variety of sample image stacks of cytogenetic FISH specimens, and compared it with all current best-performing methods for microscope auto-focusing using the criteria of (1) accuracy, (2) range, (3) robustness, and (4) speed. The Phase 1 results suggest that, by using a proper wavelet-based auto-focus function, the new multi-resolution method significantly outperforms all competing methods in each of the aforementioned performance categories, and clearly exceeds the Phase 1 feasibility criteria. In the Phase 2 project, we will further develop, refine, integrate, and validate the new technology in real-time operation environment. We plan to build a prototype system with multi-resolution auto-focusing capabilities for both fluorescence and bright-field microscope imaging. We will evaluate the system extensively for a variety of applications including genetics, pathology, and cytology. We will beta test the new system and technology in routine clinical laboratory environment and optimize the technology as end user input and feedbacks are gathered. Once fully developed and qualified, this new technology will be patented and incorporated into future IRIS automated imaging cytometry instruments. It will also be made commercially available to Applied Imaging Corporation and other manufacturers of automated microscope instruments through licensing agreements and partnerships.           n/a",Multiresolution Autofocusing for Automated Microscopy,6833120,R44RR016817,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'flow cytometry', 'fluorescence microscopy', 'fluorescent in situ hybridization', 'human data', 'image enhancement', 'image processing', 'mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2004,427818,-0.024408626843021433
"Optimized Retinal Camera DESCRIPTION (provided by applicant):  A low-cost, high-resolution, high-contrast color digital camera optimized for ophthalmology will be demonstrated. This Optimized Retinal Camera will be specifically tested for its effectiveness in meeting the image quality requirements for the screening and assessment of pre-proliferative and proliferative diabetic retinopathy in both traditional clinical settings and in telemedicine. The proposed device exploits recent technological advances in high sensitivity charge coupled device (CCD) cameras and digital signal processing electronics. Today's CCD cameras do not have the dynamic range to image the human retina. The human retina is characterized by regions of high reflectivity (20-40 percent), such as the optic disc, and very low reflectivity (<2 percent), such as the macula and fovea. Further, these existing digital cameras treat each of the color channels in the same manner and do not consider the special, red-saturated characteristics of the retina. The approach builds on existing fundus imaging technology developed by Kestrel for the National Eye Institute. The proposed Optimized Retinal Camera will be shown to offer significant improvement over existing digital color cameras by addressing each of the deficiencies mentioned above. Joslin Diabetes Center, the University of Iowa Department of Opthalmology, and the University of New Mexico Health Sciences Center will provide independent, ""masked"" evaluation of the optimized digital retinal images. n/a",Optimized Retinal Camera,6752819,R44EY013038,"['artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'charge coupled device camera', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'diabetic retinopathy', 'digital imaging', 'human subject', 'image processing', 'ophthalmoscopy', 'thermodynamics']",NEI,KESTREL CORPORATION,R44,2004,340158,-0.0005495032998634107
"Paperless Quality Donor System with Decision Making    DESCRIPTION (provided by applicant):    The principal aim of this proposal is for Talisman to develop, implement and evaluate a computerized, integrated system for processing blood donors that incorporates a series of decision aids and decision algorithms.  The system is expected to significantly reduce donor and staff errors and omissions, increase blood availability, improve staff efficiency and have substantial commercial appeal to blood centers and blood collecting hospitals.      The secondary aim of the proposal is for Talisman to continue assessment of the effectiveness of its computer-assisted, audio-video donor health history self interviewing system, QDS, in reducing donor lying on sexual and other sensitive questions, increasing the frequency of donor returns, reducing staff errors and omissions, and increasing staff efficiency.         n/a",Paperless Quality Donor System with Decision Making,6745080,R44HL072635,"['artificial intelligence', 'blood bank /supply contamination', 'blood donor', 'case history', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'decision making', 'human subject', 'interview', 'patient safety /medical error', 'phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2004,359477,-0.007241873234475443
"Paperless Quality Donor System with Decision Making    DESCRIPTION (provided by applicant):    The principal aim of this proposal is for Talisman to develop, implement and evaluate a computerized, integrated system for processing blood donors that incorporates a series of decision aids and decision algorithms.  The system is expected to significantly reduce donor and staff errors and omissions, increase blood availability, improve staff efficiency and have substantial commercial appeal to blood centers and blood collecting hospitals.      The secondary aim of the proposal is for Talisman to continue assessment of the effectiveness of its computer-assisted, audio-video donor health history self interviewing system, QDS, in reducing donor lying on sexual and other sensitive questions, increasing the frequency of donor returns, reducing staff errors and omissions, and increasing staff efficiency.         n/a",Paperless Quality Donor System with Decision Making,6930165,R44HL072635,"['artificial intelligence', 'blood bank /supply contamination', 'blood donor', 'case history', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'decision making', 'human subject', 'interview', 'patient safety /medical error', 'phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2004,394563,-0.007241873234475443
"A Run-to-Run Algorithm for Glucose Regulation DESCRIPTION (provided by applicant):    The long term objective of this work is to develop new algorithmic approaches to optimize the delivery of insulin in an automated fashion to people with type 1 diabetes. Specifically, we aim to develop a strategy, inspired by run-to-run control theory established by the chemical process industries, that ""learns"" from the previous sequence of glucose responses to insulin dosing (over the course of days), and optimally predicts the appropriate strategy for the forthcoming day. The notion of a ""cycle"" in engineering will be extended to manage the 24 hour routine of repeated meals, activities, and sleep cycles and the corresponding dosing of insulin. The algorithm will be tested in both simulation and clinical trials for robustness to sensor noise, uncertainty in the patient characterization, variability in the timing of the postprandial glucose peak, and variability in the carbohydrate content in the meals. The Specific Aims of this project are to: i) construct predictive patient sensitivity models for calculation of optimal insulin dosing from elevated (or depressed) glucose levels, ii) develop run-to-run algorithm for insulin bolus dosing to provide corrections in subsequent days based on previous history of glucose levels and insulin dosage, and iii) evaluate the robustness of the algorithm through meal challenges of varying carbohydrate content. The aims will blend prototype algorithms that are drawn from systems engineering with validation in a series of clinical tests. The proposed collaboration between systems engineers and renowned diabetes researchers in an established clinical research setting will allow a novel fusion of methods that can be truly characterized as ""innovative"". The medical collaborators in the proposal are located at the prestigious Sansum Medical Research Institute, which is located less than 10 miles from the campus of the University of California, Santa Barbara. The exchange of personnel will be facilitated, allowing the student and post-doc supported on this project to work at both the institute and the university over the span of the project n/a",A Run-to-Run Algorithm for Glucose Regulation,6827448,R01DK068663,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical automation', 'blood glucose', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer simulation', 'dietary carbohydrates', 'drug administration rate /duration', 'drug delivery systems', 'glucose metabolism', 'human subject', 'insulin dependent diabetes mellitus', 'insulin sensitivity /resistance', 'mathematical model', 'model design /development', 'patient oriented research']",NIDDK,SANSUM DIABETES RESEARCH INSTITUTE,R01,2004,203050,-0.029092389071194467
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,6810083,R21RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R21,2004,178840,0.00555108919741629
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6834860,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2004,350214,-0.03427802836608889
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6801171,R01EY013875,"['blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer program /software', 'cues', 'human subject', 'reading', 'vision aid', 'vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,329706,-0.015406092792716172
"Medical Advice from Glaucoma Informatics (MAGI)  DESCRIPTION (provided by applicant):  The project, Medical Advice from Glaucoma Informatics (MAGI), seeks to improve glaucoma diagnosis and management with state-of-the-art machine learning classifiers. These classifiers will automate the interpretation of standard automated perimetry (SAP), newer visual field tests, and structural tests for glaucoma in the general population and in stratified glaucoma populations. Phase 1 will complete the feasibility testing already underway. Phase 2 will apply the refined methods to a wider set of glaucoma testing problems.The management of glaucoma depends on a series of classifications. The glaucoma provider classifies tests as normal or indicative of glaucoma. The clinician then determines whether an eye has glaucoma or has had progression. Assembling these classifications, the provider makes decisions about management. Automated test interpreters, either as part of the testing machine or as a computer-based resource, can aid glaucoma providers with real-time interpretations. The research we propose takes advantage of our extensive data sets and builds on the ongoing research in our laboratories.Statistical classifiers, Bayesian nets, machine learning classifiers, and expert systems represent different types of classifiers with diverse properties. Machine learning classifiers can perform exceptionally well at identifying classes, even when the data are complex and have dependencies. We will test and select the optimal machine learning classifier for diagnosis. We will further improve classifier performance and determine feature utility by optimizing the feature set visual field tests are time consuming and stressful. We will streamline the tests by removing unimportant test points.Even with decades of experience, there is uncertainty with regard to the evaluation of the SAP. There is less accumulated knowledge about non-standard tests, such as short-wavelength automated perimetry, nerve fiber layer thickness, or optic nerve head topography. Machine classifiers may learn how to interpret nonstandard tests better. We will go beyond STATPAC's capabilities with classifiers that have learned to interpret SAP, nonstandard visual field tests, structural glaucoma tests, and STATPAC plots in the general population and in patients stratified by race, family history, and other information available at the time of the test.Conversion of suspects to glaucoma and progression of glaucoma cannot yet be predicted from tests. We will develop classifiers for these predictions. Classifiers will be designed to diagnose early glaucoma, detect early progression, and identify glaucomatous eyes at risk of progression.Unsupervised learning provides cluster analysis that can determine distinct groups with members in some way similar from the test data. In an effort to discover new and use useful information with unsupervised learning, we will mine our data in visual function and structural tests for glaucoma  and in specific combinations of population groups. n/a",Medical Advice from Glaucoma Informatics (MAGI),6830123,R33EY013928,"['clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human subject', 'neural information processing', 'neuropathology', 'visual fields']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R33,2004,589323,-0.03611527391044353
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6773915,U01DE013331,"['biomarker', 'biopsy', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'enzyme linked immunosorbent assay', 'facial muscles', 'gas chromatography mass spectrometry', 'human subject', 'inflammation', 'interview', 'magnetic resonance imaging', 'mastication', 'musculoskeletal disorder diagnosis', 'oral facial pain', 'pain threshold', 'psychobiology', 'questionnaires', 'radioimmunoassay', 'sign /symptom', 'statistics /biometry', 'synovial fluid', 'temporomandibular joint syndrome', 'tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2004,1637046,-0.006583128058954038
"Tree Ensemble Regression and Classification Methods    DESCRIPTION (provided by applicant):    This SBIR aims to produce next generation classification and regression software based upon ensembles of decision trees: bagging, random forests, and boosting. The prediction accuracy of these methods has caused much excitement in the machine learning community, and both challenges and complements the data modeling culture prevalent among biostatisticians. Recent research extends the methodology to likelihood based methods used in biostatistics, leading to models for survival data and generalized forest models. Generalized forest models extend regression forests in the same way that generalized linear models extend linear models.      This software would apply broadly, including to medical diagnosis, prognostic modeling, and detecting cancer; and for modeling patient characteristics like blood pressure, discrete responses in clinical trials, and count data.      Phase I work will prototype software for survival data, and investigate the performance of ensemble methods on simulated and real data. For survival applications, we will assess out-of-bag estimates of performance, and investigate measures of variable importance and graphics that help clinicians understand the results. Experience writing prototypes and using them on data will lead to a preliminary software design that serves as the foundation of Phase II work.      Phase II will expand upon this work to create commercial software. We will research and implement algorithms for a wider range of applications including generalized forest models, classification, and least squares regression. We will also implement robust loss criteria that enable good performance on noisy data, and make adaptations to handle large data sets.      This proposed software will enable medical researchers to obtain high prediction accuracy, and complement traditional tools like discriminant analysis, linear and logistic regression models, and the Cox model.         n/a",Tree Ensemble Regression and Classification Methods,6832086,R43CA105724,"['clinical research', 'computer assisted medical decision making', 'computer graphics /printing', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'method development', 'model design /development', 'neoplasm /cancer classification /staging', 'neoplasm /cancer diagnosis', 'neoplasm /cancer remission /regression', 'prognosis', 'statistics /biometry']",NCI,INSIGHTFUL CORPORATION,R43,2004,99937,-0.0017739730952064285
"Development of Ultrasonic Appratus for Dental Diagnosis DESCRIPTION: An ultrasonic diagnostic apparatus has been proposed for Dental applications in determining tooth pathologies such as demineralization/caries, hidden fractures, and formation of abscesses. The equipment adopts a piezoelectric and laser optic hybrid transduction system for interrogation of teeth. Ultrasonic responses of the tooth structure will be analyzed by a pattern recognition expert system (artificial intelligence) to determine the diagnosis of the tooth inspected. The proposed research will eventually help to reduce the use of harmful X-ray radiation in Dental clinics and contribute to artificial intelligence based diagnosis. The proposed concept has been successfully demonstrated in the previous Phase I study. In this Phase II study, instrumentation for clinical data collection using a combination of conventional piezoelectric and new laser-based ultrasonic technologies will be developed and optimized; an artificial intelligence based diagnostic function will be developed using clinical data and implemented using embedded computing; numerical simulations will be used to enhance diagnostic function development; and finally, initial clinical trials will be conducted to demonstrate the performance of the prototype equipment. The ultrasonic apparatus for Dental diagnosis outlined in this application is a first application of AI-based NDE in Dentistry. The research concept may also extend to periodontal and craniofacial applications. n/a",Development of Ultrasonic Appratus for Dental Diagnosis,6691772,R44DE014270,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' clinical trials', ' dental disorder diagnosis', ' dental structure', ' dentistry', ' diagnosis design /evaluation', ' human subject', ' patient oriented research', ' tooth', ' tooth surface']",NIDCR,AAC INTERNATIONAL,R44,2003,382129,0.00029467509528327866
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6682996,R01RR014477,"['X ray crystallography', ' artificial intelligence', ' automated data processing', ' chemical structure', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' crystallization', ' data collection methodology /evaluation', ' image processing', ' mathematics', ' method development', ' protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2003,298672,-0.034498508195038816
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6642050,R24HD038585,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biological signal transduction', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' electromyography', ' evaluation /testing', ' human subject', ' motor neurons', ' neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2003,562596,-0.04028588234762947
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6617187,R01EY014162,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' diagnosis design /evaluation', ' eye disorder diagnosis', ' eye refractometry', ' human data', ' image processing', ' ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2003,241570,-0.030313512385656206
"Content based mammogram retrieval as a diagnostic aid The objective of this project is to perform the initial development and evaluation of a computer aid to assist radiologists in their interpretation of mammograms. We will develop and evaluate an approach to computer-aided diagnosis (CAD(, in which the radiologist will be assisted by a content-based search engine that will display examples of lesions, with known pathology, that are similar to the lesion being evaluated. We will model the perceptual similarity between two lesion images as a non-linear function of those images, and use algorithms (support vector machines and artificial neural networks) to learn this function from similarity techniques that will allow the radiologist to refine the search by indicating preferences among the retrieved images, providing a capability similar to that present in text-search engines. We will focus only on the retrieval of images of microcalcification clusters (MCCs) to determine the feasibility of later developing a more-complete system capable of handling multiple lesion classes. The project will involve a thorough performance evaluation to determine the merits of continued development of the proposed approach to CAD. We will perform statistical analyses of inter-observer and intra-observer notions of image similarity, and use modern statistical resampling procedures to evaluate the generation error of our nonlinear similarity model. The specific aims of the proposed project are as follows: 1) Develop support-vector-machine and artificial-neural network methods for predicting radiologists' similarity assessments from image features extracted by computer; 2) Develop relevance-feedback techniques for refining searches based on user-assessed relevance of retrieved images; 3) Based on an MCC data set, obtain radiologists' similarity assessments, for training and testing the proposed image-retrieval system; and 4) Evaluate retrieval performance by using quantitative measures, such as precision-recall curves and generalization error, and studies of inter-observer and intra-observer variability; study diagnostic utility by measuring the fraction of retrieved images that share th same pathology as the query.  n/a",Content based mammogram retrieval as a diagnostic aid,6621877,R21CA089668,"['artificial intelligence', ' breast neoplasms', ' calcification', ' calcium disorder', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' human data', ' information retrieval', ' mammography']",NCI,ILLINOIS INSTITUTE OF TECHNOLOGY,R21,2003,147213,-0.10096951555383842
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6710523,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,139234,-0.009694128863795214
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6665322,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,245656,-0.009694128863795214
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6639029,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2003,297999,-0.003090001677942138
"Development of a Multi-State Decoding Framework DESCRIPTION (provided by applicant): This proposal aims to increase the capability and decrease the cost of decoding the Illumina bead array platform by adding decode states. DNA probes attached to microbeads are randomly loaded onto fiber optic bundles. A decoding process of sequential hybridization stages is necessary to determine the locus correspondence of each bead. Decoders (sequences complementary to the DNA probes on the beads) that are either unlabeled, or labeled with a dye are hybridized to the array. Images are taken after each hybridization, and the experiment is designed so that the hybridization signature of each bead through the decode process, uniquely determines the identity of the bead. The cost and time of decoding is proportional to the number of decode stages. The number of stages is determined by the number of loci represented on the array and the number of distinguishable labels, or decode states, used in the decode process (e.g. ON in dye 1). The current availability of 3 states allows the decoding of 1,500 probes in 8 stages. The successful execution of this project would extend the number of states to at least 8. With 8 states, the number of stages for the 1,500-probe product would become 4. The number of probes that could be decoded in 8 stages would increase by 3 orders of magnitude. The main components of the project are wet lab chemistry and algorithm development. Wet lab chemistry will be used to determine the optimal mixture of dye labeled and unlabeled oligonucleotides that will lead to distinguishable intensity states. Beads will have signal levels in FAM and CY3 dye. Variability in the process will need to be sufficiently low to reliably distinguish different concentrations of dye labeled oligonucleo tides. Three levels of FAM and CY3 signal would lead to 9 states. It is likely that 8 of these will be reliably distinguishable. Pattern matching algorithms will be developed to decode the beads. Decision tree methods based on expected signal will be applied. Arrays will be decoded twice -- first with the current 3-state decoding, and then with the multi-state decoding -- to enable training and machine learning algorithms. Achieving 8 state decoding will decrease the cost of the array and dramatically increase the number of loci explored and the number of probes per locus. n/a",Development of a Multi-State Decoding Framework,6737095,R43HG003096,"['chemistry', ' cost effectiveness', ' dyes', ' mathematics', ' microarray technology', ' nucleic acid probes', ' technology /technique development']",NHGRI,"ILLUMINA, INC.",R43,2003,141830,0.0010126656522388882
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6644867,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2003,5000,0.007224595515132196
"Ab-Initio Geometry Optimization of Large Molecules    DESCRIPTION (provided by applicant):  While density-functional calculations of the energy are now feasible for biomolecules, the use of density-functional geometry optimizers is still confined to relatively small molecules containing no more than thirty atoms. The key limitation of conventional density-functional geometry optimizers is that the cost of the geometry optimization scales at least quadratically with the number of atoms in the molecule. In contrast the energy at a fixed geometry can be evaluated for a cost which scales linearly with molecule size, enabling very large molecules to be treated. This proposal is based on a radical change in the algorithm for density-functional geometry optimization, potentially reducing the total cost from quadratic to linear in molecule size and enabling a quantum leap in the size of molecules that can be optimized. The proposed algorithm resembles a conventional self-consistent calculation of the energy at a fixed geometry but at convergence the proposed algorithm yields not only the density but also the optimized geometry. This is achieved by simultaneous optimization of the wavefunction and the geometry via a modified self-consistent-field procedure. The proposed algorithm will be implemented in the QChem software package and, if successful, widely distributed through QChem Inc. and Spartan Inc.           n/a",Ab-Initio Geometry Optimization of Large Molecules,6583907,R43GM067335,"['artificial intelligence', ' chemical models', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' mathematics', ' molecular dynamics', ' molecular size', ' quantum chemistry']",NIGMS,"Q-CHEM, INC.",R43,2003,99639,-0.013532294093277188
"Permutation Test Software for Randomized Clinical Trials The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of an RCT are almost always analyzed using some form of statistical hypothesis test. The most frequently used hypothesis tests assume a population model for statistical inference, even though a randomization model is more consistent with real-world characteristics of RCTs. Approximate p- values returned by population-model tests can, under certain circumstances, be misleading, resulting in effective drugs being declared ineffective, or ineffective drugs being declared effective. To support analysis of RCTs using the appropriate randomization model, sophisticated software for conducting randomization-based permutation tests is needed. Ongoing advances in computing technology have created a favorable climate for widespread use of such software. The goal of this research is to develop flexible and robust software for carrying out randomization-based permutation tests for single- or multi- clinic RCTs. A subset of this functionality has been successfully implemented in a Phase I pre-prototype (""RTAnalyzer""). Phase II seeks to build a full-scale prototype capable of handling a wide variety of trial designs, including designs using adaptive randomization. The Phase II project includes collaborations with two experts in the field of permutation testing: Dr. William Rosenberger and Dr. Bonnie LaFleur. PROPOSED COMMERCIAL APPLICATION: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid. n/a",Permutation Test Software for Randomized Clinical Trials,6622262,R44CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R44,2003,373280,-0.00508349225119978
"Vector Quantization for Image Pattern Recognition    DESCRIPTION (provided by applicant):    This Phase-I SBIR application addresses the increasingly significant challenges faced by pathologists and clinicians in manually inspecting microscope slides. Microscopic inspection suffers from being labor-intensive, subjective, expensive and limited by the need for physical access to the glass slide specimen of interest. The obstacle to automated microscopic inspection has been the inability to efficiently digitize entire microscope specimens at high resolutions. Aperio has developed the ScanScope (R), a novel microscope slide scanner that makes it practical - for the first time - to rapidly create virtual microscope slides at high resolutions. Virtual slides set the stage for automating microscopic inspection using automated pattern recognition. This research aims to adapt and optimize Aperio's existing and novel algorithms for vector quantization (VQ) to the problem of automatic pattern recognition in virtual slides. VQ is a general mathematical technique for encoding bitstreams using a vocabulary. The primary aim is to demonstrate the feasibility of using VQ for pattern recognition in a practical and well-characterized application: automatically finding virtually all micrometastasis clusters in cytology specimens. This proposed research represents a first attempt to automate pattern recognition in virtual slides using VQ.         n/a",Vector Quantization for Image Pattern Recognition,6695147,R43EB001617,"['artificial intelligence', ' automated data processing', ' bioimaging /biomedical imaging', ' cell line', ' computer system design /evaluation', ' cytology', ' digital imaging', ' high throughput technology', ' metastasis', ' microscopy', ' nomenclature']",NIBIB,"APERIO TECHNOLOGIES, INC.",R43,2003,97269,0.0065653124601254935
"Markov Chain Monte Carlo and Exact Logistic Regression    DESCRIPTION (provided by applicant): Today, software for fitting logistic regression models to binary data belongs in the toolkit of every professional biostatistician, epidemiologist, and social scientist. A natural follow-up to this development is the adoption of exact logistic regression by mainstream biostatisticians and data analysts for any setting in which the accuracy of a statistical analysis based on large-sample maximum likelihood theory is in doubt. Cutting-edge researchers in biometry and numerous other fields have already recognized that it is necessary to supplement inference based on large-sample methods with exact inference for small, sparse and unbalanced data. The LogXact software package developed by Cytel Software Corporation fills this need. It has been used since its inception in 1993 to produce exact inferences for data generated from a wide range fields including clinical trials, epidemiology, disease surveillance, insurance, criminology, finance, accounting, sociology and ecology. In all these applications exact logistic regression was adopted because the limitations of the corresponding asymptotic procedures were clearly recognized in advance by the investigators and the exact inference was computationally feasible. But most of the time it will not be obvious whether asymptotic or exact methods are applicable. Ideally one would prefer to run both types of analyses if there is any doubt about the appropriateness of the asymptotic inference. However, because of the computational limits of the exact algorithms, investigators are currently inhibited from attempting the exact analysis. There is uncertainty about the how long the computations will take and even whether they will produce any results at all before the computer runs out of memory. The current project eliminates this uncertainty by introducing a new generation of numerical algorithms that utilize network based Monte Carlo rejection sampling. The Phase 1 progress report has demonstrated that these new algorithms can speed up the computations by factors of 50 to 1000 relative to what is currently available in LogXact. More importantly they can predict how long a job will take so that the user may decide whether to proceed at once or at a better time. The Phase 2 effort aims to incorporate this new generation of computing algorithms into future versions of LogXact.         n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6587476,R44CA093112,"['artificial intelligence', ' clinical research', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' human data', ' mathematical model', ' mathematics', ' statistics /biometry']",NCI,CYTEL SOFTWARE CORPORATION,R44,2003,400084,-0.004610843341649574
"Multiparametric Computational Echocardiography DESCRIPTION (provided by applicant):    In the United States, myocardial ischemia is the underlying etiology in nearly 70% of the 5 million patients suffering from mechanical failure of the cardiac left ventricle (LV). Echocardiography (echo) is well suited for the analysis of LV function, however, the problem of conveying this clinically important information in a quantitative, objective, and reproducible manner persists.      To address this problem and respond to the NIH PA-00-117 solicitation for innovations in biomedical information science and technology, the long-term goal of the proposed R21/R33 project is to develop methods for 1) quantitative and objective measurement of LV function, 2) reproducible diagnostic interpretation based on these measurements, and 3) standardized topologic mapping and parametric display of the results. We defined 3 parameters of LV function: 1) rate of local deformation (strain rate), 2) amplitude of deformation (strain), and 3) time interval to the transition (crossover) point of cyclic deformation.      The practical implementation of the long-term objectives will be achieved through the development of a Multiparametric Computational Echo (MPCE) system. The main hypothesis of this R21/R33 project is that the MPCE system will a) precisely and accurately quantitate (R21 phase) and b) reproducibly clinically interpret (R33 phase) segmental LV function. This hypothesis will be tested on digital echo data from animal models and clinical cases of myocardial ischemia representing a wide range of segmental LV dysfunction.      Specific Aims (R21 phase):   Aim 1 - Develop algorithms for parametric analysis of local ventricular function (Year 1).   Aim 2 - Test precision and accuracy of local LV functional analysis using MPCE (Year 2).   Satisfaction of the predefined milestones will initiate the commencement of the R33 phase.      Specific Aims (R33 phase):   Aim 1 - Develop a neural network MPCE system and test it initially in animals (Year 3).   Aim 2 - Refine parametric mapping and test reproducibility of MPCE data in humans (Year 4).   Successful completion of this project will result in noninvasive, quantitative, objective, and reproducible interpretation of LV function, thus facilitating optimal diagnostic and therapeutic decisions in cardiology. n/a",Multiparametric Computational Echocardiography,6688878,R21HL070363,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' echocardiography', ' evaluation /testing', ' heart function', ' human subject', ' method development', ' swine']",NHLBI,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R21,2003,136861,-0.011566957241932229
"MicroSeer, Analysis software for microscopy imagery  DESCRIPTION (provided by applicant): This project will create new pattern recognition software to improve the analysis and interpretation of in vivo  biomedical imagery. Currently, researchers can get remarkably detailed images of living cells and their  constituent proteins using molecular genetic and microscopy-based approaches in conjunction with  sophisticated microscopy hardware. Available image analysis techniques and software, however, lag behind  the power of this new imaging equipment to visualize the microscopic world.  This phase I SBIR project will apply existing technology in spatial analysis of satellite image data to microscopy data, create new statistical techniques specific to the study of spatial association of proteins in  cells, and create software that implements these statistics for use in the analysis of spatial association timeslice in vivo biomedical imagery.   n/a","MicroSeer, Analysis software for microscopy imagery",6581125,R43EB000575,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' image processing', ' statistics /biometry', ' structural biology']",NIBIB,BIOMEDWARE,R43,2003,177261,-0.01362511562003177
"Automated Plaque Detection and Classification using MRI DESCRIPTION (provided by applicant):    Acute thrombus formation on disrupted/eroded human atherosclerotic lesions plays a critical role on the onset of acute coronary syndromes and progression of atherosclerosis. Pathological evidence has clearly established that it is plaque composition rather than stenotic severity that modulates plaque vulnerability and thrombogenicity. Therefore, the possibility of detecting and characterizing atherosclerotic lesions would have significant clinical implications. Among the different imaging modalities, MRI seems to be the most promising in terms of discrimination and due to its non-invasive nature. We propose to develop an automated MRI image analysis system for detecting, measuring, and classifying atherosclerotic plaques. The proposed project will be conducted by a highly experienced team of experts in signal processing, pattern recognition, statistics, and product development in close collaboration with key cardiovascular researchers, with specific expertise in MRI imaging and atherosclerosis. Automation would establish a fast, objective (observer-independent), and standard diagnostic measure of plaque burden, allowing for comparison of results between laboratories, throughout longitudinal studies, and across different imaging equipment. In a clinical setting, this system would greatly reduce the diagnostic costs involved in measuring the degree of stenosis and detecting thrombosis-prone plaques. n/a",Automated Plaque Detection and Classification using MRI,6643700,R43HL071470,"['artificial intelligence', ' atherosclerotic plaque', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical automation', ' cardiovascular disorder diagnosis', ' diagnosis design /evaluation', ' human data', ' image processing', ' magnetic resonance imaging']",NHLBI,ISCHEM CORPORATION,R43,2003,99850,-0.0251864541218124
"System for Cost Effective Clinical Trial Design The long-term objective of this project is to develop software to facilitate the design of cost effective clinical trials. In 1999, the pharmaceutical industry and NIH spent more than $23 billion on clinical trials. Developments in clinical trial design theory, and in optimization algorithms have opened possibilities for more cost- effective designs that can be executed for lower total cost, over shorter periods of time and / or requiring fewer patients. The proposed System for Cost Effective Trials (SCET) will be a software package to guide the trial designer through comparisons of the power, sample size requirements, and cost of alternate trial designs. These methods are under-used throughout medical research, but are particularly applicable to trials with relatively short treatment regimens and rapid ascertainment of endpoints, such as many cancer treatment trials. The aims of SCET Phase II are to build the system, validate it in compliance with FDA regulations for software validation, perform Beta testing at a range of target client organizations, and use the Beta test findings to produce a marketable release. PROPOSED COMMERCIAL APPLICATION: The potential market for this software system includes virtually every pharmaceutical company in the world (multiple licenses to each), every biotech company involved in clinical trials, every contract research organization involved in the design or conduct of clinical trials, coordinating centers of NIH-sponsored multi-center clinical trials, individual university-based investigators who conduct clinical trials, individual biostatistical consultants who design clinical trials, and agricultural businesses and researchers that conduct animal research. n/a",System for Cost Effective Clinical Trial Design,6626050,R44CA088667,"['artificial intelligence', ' clinical trials', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' cost effectiveness', ' drug design /synthesis /production', ' experimental designs']",NCI,"RHO FEDERAL SYSTEMS DIVISION, INC.",R44,2003,386197,-0.007509163773253143
"Software to Handle Missing Values in Large Data DESCRIPTION (provided by applicant):    This SBIR aims to produce commercial software for handling missing data in large data sets, where the goal is data mining and knowledge discovery. There may be a large number of subjects, variables, or both. Examples include microarray data, surveys, genomic data, and high throughput screening data.      Handling missing data is one important step of careful data preparation, which is key to the success of an entire project. Missing values often arise in medical data. This is an obstacle because many data mining tools either require complete data or are not robust to missing data.      Principled methods of handling missing data are computationally intensive. Therefore computational feasibility is a challenge to handling missing values in large data sets.      Phase I work will explore strategies such as sampling, constraining parameters, and monotone data algorithms for model based techniques. Factor analysis and multivariate linear mixed effects models will be used to reduce the number of parameters. A variable-by-variable approach using a popular data mining technique, recursive partitioning, will also be used to impute missing values.      For each of the methods, we will write prototype software and test performance on missing data patterns simulated on real data. Several ad hoc techniques will serve as a baseline for comparison.   Experience writing prototypes and using them in simulations will lead to preliminary software design that will serve as the foundation of Phase II work.       This proposed software will enable medical researchers to gain more from their data mining efforts: maximally extracting information and achieving unbiased predictions, despite missing data. n/a",Software to Handle Missing Values in Large Data,6690119,R43RR017862,"['artificial intelligence', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' human data', ' mathematical model', ' statistics /biometry']",NCRR,INSIGHTFUL CORPORATION,R43,2003,99847,-0.010989612533021739
"Optical Detection of Intravenous Infiltration  DESCRIPTION (provided by applicant): About 80% of hospital patients in the United States require IV therapy and 50% of IV lines fail due to infiltration, a clot in the cannula, an inflammatory response of the vein, or separation of the cannula from the vein. IV infiltration is usually accompanied by pain, erythema, and swelling at the cannula tip or the insertion site. Severe infiltration may lead to necrosis requiring skin debridement, skin grafting, or amputation. Early detection of infiltration prevents the occurrence of serious incidents that may require surgical correction. The long-term objective of this project is to develop an infiltration sensor for monitoring IV failures. The Phase II research design includes the development of an advanced prototype, improvement of algorithms, evaluation of the prototype on animal models and human measurements, investigation of its accuracy and utility, and the examination of the commercial potential. The innovation of this project lies in the use of an optical method coupled with the advanced development in fiber optics and algorithms for tissue optics to provide a means for noninvasive monitoring of the IV sites. It will provide routine, automated, continuous, and real-time monitoring capabilities for patients undergoing IV therapy.   n/a",Optical Detection of Intravenous Infiltration,6666836,R44HL062008,"['artificial intelligence', ' blood coagulation', ' catheterization', ' clinical research', ' diagnosis design /evaluation', ' fiber optics', ' human subject', ' intravenous administration', ' medical complication', ' necrosis', ' optics', ' patient monitoring device', ' swine', ' technology /technique development']",NHLBI,"CW OPTICS, INC.",R44,2003,381881,-0.03195512606927973
"Diagnostic Aid Software for Visual Field Test    DESCRIPTION (provided by applicant): Visual Field (VF) test is a widely used, noninvasive technique for evaluating pathology or dysfunction in the visual pathways. The VF test, in conjunction with other diagnostics, is used for detection of early stages of glaucoma and for following its progression. Early detection is critical as blindness from glaucoma is preventable in nearly all cases, provided treatment is administered early in the progression. However, the inherent subjectivity of the VF test makes it often difficult to interpret even for a skilled practitioner. There is a need for automated decision aid tool that will facilitate and standardize the interpretation task.   In Phase 1 of this project, IAC will design and implement novel software algorithms to automate the interpretation of VF test data for detection of glaucoma. The software will classify VF test data into normal, borderline glaucomatous, glaucomatous and unknown (not normal or glaucomatous). The aim is to provide classification performance close to that of a highly skilled human expert. The emphasis will be on the detection of early stages of glaucoma. In addition to the classification output, the software will produce a set of comprehensive rules that will explain the decision path leading to the suggested diagnosis.         n/a",Diagnostic Aid Software for Visual Field Test,6582662,R43EY014077,"['artificial intelligence', ' computer assisted diagnosis', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' early diagnosis', ' glaucoma', ' glaucoma test', ' human data', ' noninvasive diagnosis', ' vision tests', ' visual fields']",NEI,INTELLIGENT AUTOMATION CORPORATION,R43,2003,99681,-0.03881446694910089
"Physiological Controller for Rotary Blood Pumps DESCRIPTION (provided by applicant):    As the prospects of chronic mechanical assistance for the failing human heart are fast becoming a reality, and patients are indeed returning home to regain a normal lifestyle, the limitations of this technology upon quality of life are becoming more apparent. To address many of these limitations, investigators are developing next-generation ventricular assist devices. Based on turbopump technology, these new devices offer smaller size, greater efficiency (hence smaller batteries), high reliability, and are more cost effective as compared to their pulsatile predecessors. For all the virtues of these new turbopumps, they bring additional challenges. Arguably the most urgent is the need for added ""intelligence."" These relatively ignorant devices are highly dependent on feedback-control to provide normal physiological response. The goal of the Phase- II effort proposed herein is to design a robust controller that may be incorporated into these turbodynamic pump systems for clinical use. The primary end product of this program would be a validated algorithm, in the form of firmware that will be embedded into existing rotary pump controller -- capable of maintaining optimal perfusion of the patient under a variety of hemodynamic demands and disturbances, while avoiding deleterious conditions such as ventricular suction. n/a",Physiological Controller for Rotary Blood Pumps,6690298,R44HL066656,"['artificial intelligence', ' auxiliary heart prosthesis', ' biomedical device power system', ' biomedical equipment development', ' cardiac output', ' circulatory assist', ' computer system design /evaluation', ' cow', ' electrophysiology', ' hemolysis', ' mathematical model', ' microprocessor /microchip', ' sheep']",NHLBI,"LAUNCHPOINT TECHNOLOGIES, INC.",R44,2003,370076,-0.007830178038866932
"Vessel Segmentation/Registration from Ultrasound Images    DESCRIPTION (provided by applicant):    Ultrasound is widely used for imaging of blood vessels as it is non-invasive, real-time, and relatively inexpensive. This proposal focuses on segmentation of abdominal aortic aneurysms (AAA) from ultrasound images with extension to other vascular imaging applications in the long term. Reliable quantitative evaluation of AAAs plays a pivotal role in diagnoses and frequent follow-up studies needed to avoid life-threatening rupture. These studies require vessel segmentation (for size analysis) and registration between serial studies (for monitoring the progression of the disease before and/or after vascular repair). AAA evaluation is routinely carried out for both high-risk patient populations and those treated with endovascular repair. Currently, AAA management is primarily based on measurements from two-dimensional (2-D) slices in CT scans. AAA monitoring and follow-up could be improved by 1) measurement from 3-D reconstructions, and 2) use of ultrasound imaging to minimize radiation exposure and reduce costs. 3-D ultrasound reconstructions provide accuracy comparable to that of CT. However, large inter-observer variability and long processing times preclude routine clinical use of 3-D image information. This research aims to develop software solutions for improved ultrasound-based AAA monitoring and other vascular diseases (in the long term). The tools used will be based on advanced image segmentation and registration algorithms involving curvature-driven image processing techniques and deformable models. The goal of the Phase I study is to establish feasibility of the proposed methods by demonstrating an improvement in the repeatability and accuracy of measurements and reduction in delineation time.         n/a",Vessel Segmentation/Registration from Ultrasound Images,6641019,R43HL069540,"['abdomen', ' aorta aneurysm', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' gastrointestinal circulation disorder', ' gastrointestinal imaging /visualization', ' human data', ' mathematics', ' three dimensional imaging /topography']",NHLBI,INSIGHTFUL CORPORATION,R43,2003,99621,-0.0157284268710205
"Smart Power Assistance Module for Manual Wheelchairs    DESCRIPTION (provided by applicant): We propose to use power assistance as the basis for a Smart Power Assistance Module (SPAM) that provides independent power assistance to the right and left rear wheels of a manual wheelchair. The SPAM will detect obstacles near the wheelchair, and modify the forces applied to each wheel to avoid obstacles.  For individuals with visual impairments that are unable to walk with a long cane or walker, the SPAM will provide safe travel by assisting the user to avoid obstacles. This research will build on the investigative team's previous experience with power assistance for manual wheelchairs and obstacle avoidance for power wheelchairs and rollators. Extensive outside evaluation of the SPAM will be provided throughout the course of the project by clinicians active in wheelchair seating and mobility.         n/a",Smart Power Assistance Module for Manual Wheelchairs,6667132,R43EY014490,"['artificial intelligence', ' assistive device /technology', ' biomedical device power system', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' field study', ' human subject', ' medical rehabilitation related tag', ' vision aid', ' vision disorders']",NEI,AT SCIENCES,R43,2003,209800,-0.01714809897777186
"Epileptic Seizures in the Neonatal EEG   DESCRIPTION: (provided by applicant) The identification of electrographic            seizures during long-term EEG monitoring in the neonate is currently based upon      visual interpretation of the graphic record, a process that is very                  time-consuming. While significant progress has been made in the automated            detection of seizures in the adult population, relatively little work has been       done in the neonatal area. Therefore, the major objective of this project is         the development of techniques for the reliable automated detection of                electrographic seizures in the neonatal EEG. We propose a multi-stage, hybrid        approach to detection that will employ a combination of signal processing,           pattern recognition, neural networks, and expert rules. Through the successive       stages of the detection process, multichannel neonatal EEG data containing all       types of background activity and artifacts will be analyzed to detect and            classify electrographic seizures. We postulate that the varied types and             morphologies of seizures in the neonatal EEG, as compared to seizures in the         adult EEG, can best be detected and classified using this hybrid approach. We        will test the methods we develop on data recorded from infants in the Clinical       Research Center for Neonatal Seizures, The Methodist Hospital, in Houston,           Texas. We expect that the information we gain from the research will lead to         the development of a practical seizure detection system and further our              long-term goals of reduced expense in the reading and interpretation of              neonatal EEGs, and also facilitate the efficient collection of seizure               parameters for possible use in future research studies.                                                                                                                   n/a",Epileptic Seizures in the Neonatal EEG,6642804,R01NS040577,"['adult human (21+)', ' age difference', ' artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' brain electrical activity', ' computer assisted diagnosis', ' electroencephalography', ' epilepsy', ' human subject', ' newborn human (0-6 weeks)', ' patient monitoring device', ' patient oriented research']",NINDS,UNIVERSITY OF HOUSTON,R01,2003,193637,-0.01324190809223535
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6626641,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2003,482862,-0.03411358685880645
"Automated Quantitation of 3D Echocardiograms In Phase I we developed a method for automated border detection (ABD) of echocardiographic scans that is feasible for clinical application. The accuracy of our processes provides exceeds Phase I goals and is comparable to interobserver variability in measuring volume and ejection fraction, and in border location. For a diverse set of patients, we have achieved an accuracy of 10 ml for endocardial volume, 4% for ejection fraction, and ,2.0 mm for border position. Our processes operates in 4 min. In Phase II we propose to continue research and development to move our ABD technology closer to clinical user. Our first specific aim is to reduce the amount of manual input required even further. Our second aim is to develop a prototype system suitable for clinical evaluation. Our third aim is to perform a pilot trial to evaluate the performance of our ABD process, as a preparation for a more formal, multi-center clinical trial planned for Phase III. The proposed research is important because quantitative 3D echo provides greater accuracy and reproducibility and more comprehensive information on cardiac status than currently available imaging techniques. The significant advantages of 3D echo are not currently available for clinical practice because it is impractical without automation. PROPOSED COMMERCIAL APPLICATIONS: Automation of echocardiogram border detection enables physicians to obtain accurate, reproducible and comprehensive measurements of the heart's size, shape and function. This technology can be included in ultrasound systems or provided in workstations. The core technology can be applied to other organs and other imaging modalities. n/a",Automated Quantitation of 3D Echocardiograms,6622226,R44HL059054,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' echocardiography', ' heart disorder diagnosis', ' heart ventricle', ' human subject', ' image processing', ' papillary muscles', ' pericardium']",NHLBI,"QUANTIGRAPHICS, INC.",R44,2003,244092,-0.008313082011071221
"Optimized Retinal Camera DESCRIPTION (provided by applicant):  A low-cost, high-resolution, high-contrast color digital camera optimized for ophthalmology will be demonstrated. This Optimized Retinal Camera will be specifically tested for its effectiveness in meeting the image quality requirements for the screening and assessment of pre-proliferative and proliferative diabetic retinopathy in both traditional clinical settings and in telemedicine. The proposed device exploits recent technological advances in high sensitivity charge coupled device (CCD) cameras and digital signal processing electronics. Today's CCD cameras do not have the dynamic range to image the human retina. The human retina is characterized by regions of high reflectivity (20-40 percent), such as the optic disc, and very low reflectivity (<2 percent), such as the macula and fovea. Further, these existing digital cameras treat each of the color channels in the same manner and do not consider the special, red-saturated characteristics of the retina. The approach builds on existing fundus imaging technology developed by Kestrel for the National Eye Institute. The proposed Optimized Retinal Camera will be shown to offer significant improvement over existing digital color cameras by addressing each of the deficiencies mentioned above. Joslin Diabetes Center, the University of Iowa Department of Opthalmology, and the University of New Mexico Health Sciences Center will provide independent, ""masked"" evaluation of the optimized digital retinal images. n/a",Optimized Retinal Camera,6583366,R44EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' human subject', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R44,2003,431799,-0.0005495032998634107
"AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION Quantification of Minimal Residual Disease (MRD) is a general concern in oncology since this parameter is likely to give valuable information to clinicians to customize chemotherapeutic treatments and to anticipate possible relapses. An automated system will be developed for the quantification of MRD by using real-time PCR to quantify cancer cells in a background of non pathologic DNA. The system will be derived from an existing high-throughput sample handling system (developed by Meldrum and team) named Acapella. Acapella has a pipelined serial architecture which makes it possible to develop an adaptive PCR control algorithm ensuring a level of sensitivity and accuracy for the quantification results specified by the clinician. In the R21 phase of the project, a critical component of the system is the real-time thermocycler. It will provide DNA quantification results of greater precision than what is currently possible with commercial instruments such as the ABI PRISM 7700 Sequence Detector by taking advantage of a high performance custom fluorescence analyzer and sophisticated data analysis methods. The fluorescence analyzer will have a signal to noise ratio and a dynamic range of at least one order of magnitude larger than the optics used on commercial systems. This unique feature will permit precise measurements of the amplification kinetics during at least five cycles in the exponential phase of the reaction. The amplification yield will he derived from these data using statistical estimators customized to meet the requirements of real-time PCR data analysis. The sample DNA content will be derived from the amplification yield and the calibrated fluorescence measurements of the reaction kinetics. This new approach will make it possible to run series of real-time PCRs with more flexibility than would be possible if the assay was based on standard reactions required to have the same amplification yield as the clinical samples. PCR conditions will be adapted online without concerns about possible differences of amplification rate. The assay control algorithm will adapt the reaction DNA content, the primer selection, and the number of PCRs to meet the clinician requirements for particular patient DNA. During the R21 phase of the project a prototype of the real-time thermocycler will be developed to demonstrate the optic performance and the possibility to estimate the PCR amplification rates with 5% accuracy. A conceptual design of the fully integrated process from patient blood sample to MRD quantification data will be completed to allow assessment of expected performance, cost, and risks associated with the development of the fully engineered system. The development of the various hardware and software components along with their integration into the automated system will take place during the R33 phase of the project. Performance of the system will he evaluated on real biological samples provided by the UW Department of Laboratory Medicine. Results returned by the system will he compared with results of t(14; 18) PCR performed in this department with an ABI PRISM 7700 for the diagnosis of patients suffering from follicular lymphomas.  n/a",AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION,6633609,R33CA084691,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosome translocation', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence', ' high throughput technology', ' human tissue', ' minimal residual disease', ' neoplasm /cancer diagnosis', "" nonHodgkin's lymphoma"", ' nucleic acid quantitation /detection', ' polymerase chain reaction']",NCI,UNIVERSITY OF WASHINGTON,R33,2003,618638,0.0069035415313369024
"Paperless Quality Donor System with Decision Making    DESCRIPTION (provided by applicant):    The principal aim of this proposal is for Talisman to develop, implement and evaluate a computerized, integrated system for processing blood donors that incorporates a series of decision aids and decision algorithms.  The system is expected to significantly reduce donor and staff errors and omissions, increase blood availability, improve staff efficiency and have substantial commercial appeal to blood centers and blood collecting hospitals.      The secondary aim of the proposal is for Talisman to continue assessment of the effectiveness of its computer-assisted, audio-video donor health history self interviewing system, QDS, in reducing donor lying on sexual and other sensitive questions, increasing the frequency of donor returns, reducing staff errors and omissions, and increasing staff efficiency.         n/a",Paperless Quality Donor System with Decision Making,6728674,R44HL072635,"['artificial intelligence', ' blood bank /supply contamination', ' blood donor', ' case history', ' clinical research', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer program /software', ' computer system design /evaluation', ' decision making', ' human subject', ' interview', ' patient safety /medical error', ' phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2003,514079,-0.007241873234475443
"Paperless Quality Donor System with Decision Making    DESCRIPTION (provided by applicant):    The principal aim of this proposal is for Talisman to develop, implement and evaluate a computerized, integrated system for processing blood donors that incorporates a series of decision aids and decision algorithms.  The system is expected to significantly reduce donor and staff errors and omissions, increase blood availability, improve staff efficiency and have substantial commercial appeal to blood centers and blood collecting hospitals.      The secondary aim of the proposal is for Talisman to continue assessment of the effectiveness of its computer-assisted, audio-video donor health history self interviewing system, QDS, in reducing donor lying on sexual and other sensitive questions, increasing the frequency of donor returns, reducing staff errors and omissions, and increasing staff efficiency.         n/a",Paperless Quality Donor System with Decision Making,6585908,R44HL072635,"['artificial intelligence', ' blood bank /supply contamination', ' blood donor', ' case history', ' clinical research', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer program /software', ' computer system design /evaluation', ' decision making', ' human subject', ' interview', ' patient safety /medical error', ' phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2003,119826,-0.007241873234475443
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by investigator):  The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47% to 58% of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy, with 8% stating that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side-effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better-informed treatment decisions, and facilitate coping when it occurs.         n/a",Computer Imaging to Diminish Alopecia Distress,6586963,R43CA099873,"['alopecia', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted patient care', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' coping', ' desensitization psychotherapy', ' drug adverse effect', ' female', ' imaging /visualization /scanning', ' psychological aspect of cancer', ' quality of life', "" women's health""]",NCI,"BARRON ASSOCIATES, INC.",R43,2003,99973,-0.03426901056747601
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6666671,R01EY013875,"['blind aid', ' blindness', ' clinical research', ' computer human interaction', ' computer program /software', ' cues', ' human subject', ' reading', ' vision aid', ' vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,327524,-0.015406092792716172
"Medical Advice from Glaucoma Informatics (MAGI)  DESCRIPTION (provided by applicant):  The project, Medical Advice from Glaucoma Informatics (MAGI), seeks to improve glaucoma diagnosis and management with state-of-the-art machine learning classifiers. These classifiers will automate the interpretation of standard automated perimetry (SAP), newer visual field tests, and structural tests for glaucoma in the general population and in stratified glaucoma populations. Phase 1 will complete the feasibility testing already underway. Phase 2 will apply the refined methods to a wider set of glaucoma testing problems.The management of glaucoma depends on a series of classifications. The glaucoma provider classifies tests as normal or indicative of glaucoma. The clinician then determines whether an eye has glaucoma or has had progression. Assembling these classifications, the provider makes decisions about management. Automated test interpreters, either as part of the testing machine or as a computer-based resource, can aid glaucoma providers with real-time interpretations. The research we propose takes advantage of our extensive data sets and builds on the ongoing research in our laboratories.Statistical classifiers, Bayesian nets, machine learning classifiers, and expert systems represent different types of classifiers with diverse properties. Machine learning classifiers can perform exceptionally well at identifying classes, even when the data are complex and have dependencies. We will test and select the optimal machine learning classifier for diagnosis. We will further improve classifier performance and determine feature utility by optimizing the feature set visual field tests are time consuming and stressful. We will streamline the tests by removing unimportant test points.Even with decades of experience, there is uncertainty with regard to the evaluation of the SAP. There is less accumulated knowledge about non-standard tests, such as short-wavelength automated perimetry, nerve fiber layer thickness, or optic nerve head topography. Machine classifiers may learn how to interpret nonstandard tests better. We will go beyond STATPAC's capabilities with classifiers that have learned to interpret SAP, nonstandard visual field tests, structural glaucoma tests, and STATPAC plots in the general population and in patients stratified by race, family history, and other information available at the time of the test.Conversion of suspects to glaucoma and progression of glaucoma cannot yet be predicted from tests. We will develop classifiers for these predictions. Classifiers will be designed to diagnose early glaucoma, detect early progression, and identify glaucomatous eyes at risk of progression.Unsupervised learning provides cluster analysis that can determine distinct groups with members in some way similar from the test data. In an effort to discover new and use useful information with unsupervised learning, we will mine our data in visual function and structural tests for glaucoma  and in specific combinations of population groups. n/a",Medical Advice from Glaucoma Informatics (MAGI),6788651,R33EY013928,"['clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' early diagnosis', ' eye disorder diagnosis', ' glaucoma', ' glaucoma test', ' human subject', ' neural information processing', ' neuropathology', ' visual fields']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R33,2003,591603,-0.03611527391044353
"Novel Methods for Automated Key Image Selection    DESCRIPTION (provided by the applicant):  Significant new knowledge about human behavior and the brain has come to light in recent years, due in part to rapid technical developments in imaging. As the role of imaging becomes increasingly important in neurosciences, effective methods for managing and retrieving images will become even more critical; without such advances, further progress will be hindered. The goal of this proposal is the automated summarization of large imaging sets. Image summarization proffers a method to compress imaging studies by selecting only pertinent image slices that objectively document a patient's condition; as such, its applications include multimedia electronic medical records, telemedicine, and teaching files. In Phase I, development is focused on a customizable brain atlas used for registering patient imaging studies in order to select key images. This phase addresses selection of images from ""normal"" studies and studies with only subtle morphological changes, as typical of most patients with psychiatric disorders. Automatic techniques for customizing the atlas to imaging study acquisition parameters are developed, in addition to registration methods for mapping the atlas to the patient's original study. Building from this initial work, Phase II expands to encompass selection of images from ""abnormal"" studies that exhibit gross morphological changes through principle component analysis, further customization of the atlas for different age groups (e.g., pediatric), and incorporation of structured data entry (SDE) and natural language processing (NLP) of medical reports to help guide automatic selection of key images. The resultant product will be a fully automated software system that can select relevant images from any imaging study. Initial evaluation in Phase I will examine the performance of the contrast customizable atlas and summarization/relevant slice selection, as compared to human experts.         n/a",Novel Methods for Automated Key Image Selection,6583176,R43MH065764,"['archives', ' biomedical automation', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' human data', ' image processing', ' method development']",NIMH,MEDAXIS CORPORATION,R43,2003,93365,-0.02261659145336376
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6640921,U01DE013331,"['biomarker', ' biopsy', ' clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' enzyme linked immunosorbent assay', ' facial muscles', ' gas chromatography mass spectrometry', ' human subject', ' inflammation', ' interview', ' magnetic resonance imaging', ' mastication', ' musculoskeletal disorder diagnosis', ' oral facial pain', ' pain threshold', ' psychobiology', ' questionnaires', ' radioimmunoassay', ' sign /symptom', ' statistics /biometry', ' synovial fluid', ' temporomandibular joint syndrome', ' tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2003,1388868,-0.006583128058954038
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6707987,U01DE013331,"['biomarker', ' biopsy', ' clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' enzyme linked immunosorbent assay', ' facial muscles', ' gas chromatography mass spectrometry', ' human subject', ' inflammation', ' interview', ' magnetic resonance imaging', ' mastication', ' musculoskeletal disorder diagnosis', ' oral facial pain', ' pain threshold', ' psychobiology', ' questionnaires', ' radioimmunoassay', ' sign /symptom', ' statistics /biometry', ' synovial fluid', ' temporomandibular joint syndrome', ' tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2003,376755,-0.006583128058954038
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6536089,R24HD038585,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biological signal transduction', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' electromyography', ' evaluation /testing', ' human subject', ' motor neurons', ' neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2002,622485,-0.04028588234762947
"Content based mammogram retrieval as a diagnostic aid The objective of this project is to perform the initial development and evaluation of a computer aid to assist radiologists in their interpretation of mammograms. We will develop and evaluate an approach to computer-aided diagnosis (CAD(, in which the radiologist will be assisted by a content-based search engine that will display examples of lesions, with known pathology, that are similar to the lesion being evaluated. We will model the perceptual similarity between two lesion images as a non-linear function of those images, and use algorithms (support vector machines and artificial neural networks) to learn this function from similarity techniques that will allow the radiologist to refine the search by indicating preferences among the retrieved images, providing a capability similar to that present in text-search engines. We will focus only on the retrieval of images of microcalcification clusters (MCCs) to determine the feasibility of later developing a more-complete system capable of handling multiple lesion classes. The project will involve a thorough performance evaluation to determine the merits of continued development of the proposed approach to CAD. We will perform statistical analyses of inter-observer and intra-observer notions of image similarity, and use modern statistical resampling procedures to evaluate the generation error of our nonlinear similarity model. The specific aims of the proposed project are as follows: 1) Develop support-vector-machine and artificial-neural network methods for predicting radiologists' similarity assessments from image features extracted by computer; 2) Develop relevance-feedback techniques for refining searches based on user-assessed relevance of retrieved images; 3) Based on an MCC data set, obtain radiologists' similarity assessments, for training and testing the proposed image-retrieval system; and 4) Evaluate retrieval performance by using quantitative measures, such as precision-recall curves and generalization error, and studies of inter-observer and intra-observer variability; study diagnostic utility by measuring the fraction of retrieved images that share th same pathology as the query.  n/a",Content based mammogram retrieval as a diagnostic aid,6437170,R21CA089668,"['artificial intelligence', ' breast neoplasms', ' calcification', ' calcium disorder', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' human data', ' information retrieval', ' mammography']",NCI,ILLINOIS INSTITUTE OF TECHNOLOGY,R21,2002,143782,-0.10096951555383842
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6580977,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2002,246164,-0.009694128863795214
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6538699,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2002,290602,-0.003090001677942138
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6522796,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2002,5000,0.007224595515132196
"Permutation Test Software for Randomized Clinical Trials The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of an RCT are almost always analyzed using some form of statistical hypothesis test. The most frequently used hypothesis tests assume a population model for statistical inference, even though a randomization model is more consistent with real-world characteristics of RCTs. Approximate p- values returned by population-model tests can, under certain circumstances, be misleading, resulting in effective drugs being declared ineffective, or ineffective drugs being declared effective. To support analysis of RCTs using the appropriate randomization model, sophisticated software for conducting randomization-based permutation tests is needed. Ongoing advances in computing technology have created a favorable climate for widespread use of such software. The goal of this research is to develop flexible and robust software for carrying out randomization-based permutation tests for single- or multi- clinic RCTs. A subset of this functionality has been successfully implemented in a Phase I pre-prototype (""RTAnalyzer""). Phase II seeks to build a full-scale prototype capable of handling a wide variety of trial designs, including designs using adaptive randomization. The Phase II project includes collaborations with two experts in the field of permutation testing: Dr. William Rosenberger and Dr. Bonnie LaFleur. PROPOSED COMMERCIAL APPLICATION: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid. n/a",Permutation Test Software for Randomized Clinical Trials,6444337,R44CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R44,2002,362409,-0.00508349225119978
"Narrow-Band Active Noise Reduction for DPOAE Measurement DESCRIPTION (provided by applicant): The aim of this project is to enable accurate acquisition of distortion product otoacoustic emission (DPOAE) measurements in relatively high noise environments for use in hearing evaluations and screening. DPOAE measurements have been shown to be an effective and efficient method for screening infant, children, and adult hearing. Environmental noise, however, has been shown to adversely affect the ability to successfully obtain DPOAE measurements, especially at frequencies below 1500 Hz.  We will achieve our aim by developing a narrow-band, adaptive active noise reduction system that will seamlessly augment existing DPOAE measurement protocols. Our innovation will supplement existing DPOAE measurement systems with both low-cost acoustic hardware and advanced signal processing techniques. By reducing background noise levels in a narrow frequency band near the DPOAE test frequencies, we will enable higher signal-to-noise ratio DPOAE measurement sequences. The increased SNR will result in the ability to obtain DPOAE measurements in relatively high noise environments such as the newborn intensive care unit and nursery, offices of pediatricians, schools without special audiology facilities, field hospitals, and remote or mobile clinics. n/a",Narrow-Band Active Noise Reduction for DPOAE Measurement,6485483,R43DC005112,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' clinical research', ' computer program /software', ' hearing tests', ' human subject', ' measurement', ' noise', ' otoacoustic emission', ' sound frequency']",NIDCD,"CREARE, INC.",R43,2002,103954,-0.009820766809227138
"Actuarial Generation of Diagnostic Possibilities in Ment  DESCRIPTION (provided by applicant):  The primary goal of this Phase I project is to test the feasibility of a computerized diagnostic tool for collaborative assessment of psychiatric disorders in children and adolescents.  Such a system is sorely needed in both clinical and research settings because (a) structured clinical interviews, although the gold standard in diagnosis, are time consuming and underutilized, and (b) the clinical judgment that is often substituted is of Limited accuracy and subject to several significant biases.  Using the diagnostic rules from the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV), the proposed product will provide clinicians with automated actuarial symptom and diagnostic data thereby circumventing these limitations while assisting the collaborative diagnostic process.  These goals will be accomplished by integrating a reliable and valid symptom checklist filled out by patient informants with an advanced rule-based documentation system that employs an established logic-processing engine and which utilizes the complete DSM-IV rule set.  Based on the presence and severity of discrete symptoms, clinicians will be provided with actuarially derived probability values that indicate the likelihood of specific DSM-IV criteria or disorders.  Additionally, it will facilitate rapid and complete documentation DSM-IV criterion necessary to formally validate or refute diagnoses.  The improved integration of client and clinician information will provide increased diagnostic precision and facilitate collaboration between providers and clients.  In Phase II, the system will be extended to support repeated assessment, direct access via the World Wide Web, and larger sampling to collect further psychometric information.  Phase I objectives include: 1. To produce a highly usable collaborative diagnostic assessment tool that will be used by individual practitioners, small group practices and their clients.  2. To automate the determination of the positive and negative predictive power of informant symptom data for corresponding DSM-IV criterion and diagnoses, and to collect an initial data set to evaluate usability and psychometric properties of the system.  Phase II objectives include: (1) creation of a user interfaces and program logic to support repeated assessment (2) scaling to provide direct access via the World Wide Web and (3) larger sampling to extend the known psychometric properties of the system.  PROPOSED COMMERCIAL APPLICATION: Commercial potential is present in several areas related to psychiatric diagnosis and clinical decision-making: clinical practice, enterprise decision support, training, education, research, medical records, and managed care.   n/a",Actuarial Generation of Diagnostic Possibilities in Ment,6549219,R43MH062266,"['Internet', ' artificial intelligence', ' clinical research', ' computer assisted diagnosis', ' computer human interaction', ' computer system design /evaluation', ' diagnosis design /evaluation', ' human subject', ' mental disorder diagnosis', ' psychometrics']",NIMH,"MEDICINE RULES, INC.",R43,2002,99996,0.0025193340210831676
"System for Cost Effective Clinical Trial Design The long-term objective of this project is to develop software to facilitate the design of cost effective clinical trials. In 1999, the pharmaceutical industry and NIH spent more than $23 billion on clinical trials. Developments in clinical trial design theory, and in optimization algorithms have opened possibilities for more cost- effective designs that can be executed for lower total cost, over shorter periods of time and / or requiring fewer patients. The proposed System for Cost Effective Trials (SCET) will be a software package to guide the trial designer through comparisons of the power, sample size requirements, and cost of alternate trial designs. These methods are under-used throughout medical research, but are particularly applicable to trials with relatively short treatment regimens and rapid ascertainment of endpoints, such as many cancer treatment trials. The aims of SCET Phase II are to build the system, validate it in compliance with FDA regulations for software validation, perform Beta testing at a range of target client organizations, and use the Beta test findings to produce a marketable release. PROPOSED COMMERCIAL APPLICATION: The potential market for this software system includes virtually every pharmaceutical company in the world (multiple licenses to each), every biotech company involved in clinical trials, every contract research organization involved in the design or conduct of clinical trials, coordinating centers of NIH-sponsored multi-center clinical trials, individual university-based investigators who conduct clinical trials, individual biostatistical consultants who design clinical trials, and agricultural businesses and researchers that conduct animal research. n/a",System for Cost Effective Clinical Trial Design,6485420,R44CA088667,"['artificial intelligence', ' clinical trials', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' cost effectiveness', ' drug design /synthesis /production', ' experimental designs']",NCI,"RHO FEDERAL SYSTEMS DIVISION, INC.",R44,2002,380192,-0.007509163773253143
"Ultrasonic Registration of Knee Anatomy to MRI Images  DESCRIPTION (provided by applicant): The proposed research will investigate the feasibility of using intra-operative ultrasound (US) images to noninvasively register the bone surfaces of the knee to preoperative magnetic resonance (MR) images. A surgical navigation system, KneeNav, is being developed by CASurgica for intraoperatively planning the proper location of ligament attachment sites and drill tunnel locations and then guiding the surgeon to execute the plan. Despite agreement on the correct points of insertion, great variability exists in tunnel placement among surgeons and the rate of misplaced tunnels in ACL reconstruction surgery has been reported to be between 10-40 percent. Malpositioning of the bone tunnels is the main reason for revision surgery. The proposed research would increase the accuracy of the procedure versus current videoscopic techniques or versus competitive image guidance systems. The research plan is to establish a ""gold standard"" for registration accuracy using reconstructed CT scans, point-based surface matching algorithms, and optical tracking. Reconstructed MR models will be substituted for CT models and the accuracy reassessed. The US probe will then be calibrated and US surface collection will then be substituted for point based collection and the accuracy reassessed. Finally, registration of US directly to MR without reconstruction will be assessed.  PROPOSED COMMERCIAL APPLICATION: Not Available. n/a",Ultrasonic Registration of Knee Anatomy to MRI Images,6550304,R41AR049104,"['artificial intelligence', ' bioimaging /biomedical imaging', ' bone imaging /visualization /scanning', ' computed axial tomography', ' computer program /software', ' knee', ' magnetic resonance imaging', ' orthopedics', ' surgery material /equipment']",NIAMS,"CASURGICA, INC.",R41,2002,99995,-0.04559499655146343
"Optical Detection of Intravenous Infiltration  DESCRIPTION (provided by applicant): About 80% of hospital patients in the United States require IV therapy and 50% of IV lines fail due to infiltration, a clot in the cannula, an inflammatory response of the vein, or separation of the cannula from the vein. IV infiltration is usually accompanied by pain, erythema, and swelling at the cannula tip or the insertion site. Severe infiltration may lead to necrosis requiring skin debridement, skin grafting, or amputation. Early detection of infiltration prevents the occurrence of serious incidents that may require surgical correction. The long-term objective of this project is to develop an infiltration sensor for monitoring IV failures. The Phase II research design includes the development of an advanced prototype, improvement of algorithms, evaluation of the prototype on animal models and human measurements, investigation of its accuracy and utility, and the examination of the commercial potential. The innovation of this project lies in the use of an optical method coupled with the advanced development in fiber optics and algorithms for tissue optics to provide a means for noninvasive monitoring of the IV sites. It will provide routine, automated, continuous, and real-time monitoring capabilities for patients undergoing IV therapy.   n/a",Optical Detection of Intravenous Infiltration,6550261,R44HL062008,"['artificial intelligence', ' blood coagulation', ' clinical research', ' diagnosis design /evaluation', ' fiber optics', ' human subject', ' intravenous administration', ' medical complication', ' necrosis', ' optics', ' patient monitoring device', ' swine', ' technology /technique development']",NHLBI,"CW OPTICS, INC.",R44,2002,250708,-0.03195512606927973
"Applying Usability to A Knowledge Based System A cancer genetics-tracking database will be redesigned using usability engineering techniques to improve the functionality and usability of the current system. This is important because it will lead to a system that is easier to use and learn, will decrease the chance of errors, and will increase productivity, and user satisfaction. The current state of informatics offers the potential for the creation of tools to assist in the reduction of medical errors. The redesign of this tracking database will be completed through a three-phase process. The first phase will use the results of a usability analysis to redesign and prototype the cancer genetics-tracking database. In the second phase, usability studies will then be conducted to ensure that the system is functional, easy to use, easy to learn, and meets the goals of the users. The usability studies will include heuristic evaluations, keystroke level models, talk-aloud methods, and cognitive walkthrough techniques. The system will be modified based upon the results of these studies. Research will be compiled on the advantages and disadvantages of ICD coding Vs. SNOMED followed by the selection of the most useful system for coding medical information. In the third phase the final redesign will be compared to the old system using a within-subject design to determine if the redesign decreases the error rate, increases productivity, and user satisfaction. This will be followed-up with a survey to determine the perceived usability of the redesigned application. Throughout the redesign process, specific usability guidelines will be developed for designing healthcare software that is computational and knowledge- based in nature.  n/a",Applying Usability to A Knowledge Based System,6538226,F38LM007188,"['artificial intelligence', ' cancer information system', ' cancer registry /resource', ' computer assisted medical decision making', ' computer human interaction', ' computer system design /evaluation', ' family genetics', ' human data', ' neoplasm /cancer genetics']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2002,66954,-0.016663760734681506
"VIRUS STRUCTURE DETERMINATION SOFTWARE Virus structure determination using electron microscopy has become a useful research tool aimed at understanding viral assembly and infectivity to facilitate the design of anti-viral drugs and virus-based gene delivery systems. Our long term goal is to broaden the group of people able to determine virus structures by providing an integrated software suite for three-dimensional virus structure determination using electron microscopy. The software suite, called Tumbleweed, will allow easy, efficient, and routine determination of icosahedral virus structures from electron micrographs. Novel aspects of Tumbleweed will include a comprehensive suite of tools for icosahedral structure determination, incorporation of an expert system to guide users through the reconstruction procedure, and data analysis tools to ensure that structures are determined accurately. Tumbleweed will also provide a consistent easy to use graphical user interface to all reconstruction tools including data analysis, data management, and data logging. In addition, Tumbleweed will provide tools for image selection, quality assessment, and structure visualization that can be used with any electron microscopy structure determination method. Thus, in addition to virologists, target users include electron microscopists and structural biologists. The result of this Phase Il SBIR will be a completely integrated and tested software package allowing easy, efficient, and routine virus structure determination. PROPOSED COMMERCIAL APPLICATIONS: Tumbleweed is targeted at a large group of users with varied knowledge, experience, and research goals. Virologists will be attracted to the extensive user guidance and intuitive design. Structural biologists and electron microscopists performing virus structure determination will be attracted to the concept of a complete integrated software package. Last, all electron microscopists and structural biologists will be attracted to the integration of all general data processing into a single extendible package. Combined this group should provide a large user-base allowing QED Labs to commercialize Tumbleweed successfully.  n/a",VIRUS STRUCTURE DETERMINATION SOFTWARE,6490198,R44GM058327,"['artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data management', ' electron microscopy', ' molecular dynamics', ' structural biology', ' virus assembly', ' virus morphology']",NIGMS,QED LABS,R44,2002,331492,-0.0361110188870516
"Automated PCR Pathogen Detection and Quantification  DESCRIPTION (provided by applicant):  We will develop software for automated pathogen detection and quantification using data from PCR experiments. Automated pathogen detection using data from a PCR experiment requires software to determine whether DNA from the pathogen is present or absent in a sample. We will develop a pattern-matching algorithm to mathematically analyze PCR amplification data. We will optimize the algorithm against a data set of at least 5000 PCR reactions (including a significant set of data gathered during the anthrax attack) to determine its efficacy and limitations. We expect the pathogen detection algorithms to distinguish positives samples from negative samples in more than 98% of the samples, to find inconclusive results in less than 1% of the samples, and to incorrectly classify less than 1% of the samples. We will also develop software to perform automated melting curve analysis of samples that our detection algorithm has determined to be positive or inconclusive. The melting profile of the probes is a property of the assay, and it can be used for secondary confirmation of a pathogen by comparing the profile of the unknown samples to the profile of the assay's positive controls. We will develop algorithms to automatically determine whether the melting profile of the sample and controls match. With melting analysis confirmation, the failure rate of the final detection algorithm should be less than 0.5%.   Automated pathogen quantification requires software to determine the number of copies of a pathogen's DNA in a sample. We will develop discrete dynamical models of PCR for quantification. We will optimize these methods against a large data set of PCR reactions with dilution series. We will systematically determine the features of the models that provide information and the features that can be ignored. We will measure efficacy by comparing computed DNA copy numbers against the known concentrations (as specified by experimenters), and against each other. We will use the most effective model (or models) in the software we produce.   n/a",Automated PCR Pathogen Detection and Quantification,6555484,R43AI052944,"['artificial intelligence', ' bioterrorism /chemical warfare', ' communicable disease diagnosis', ' computer program /software', ' computer system design /evaluation', ' microorganism', ' nucleic acid denaturation', ' nucleic acid quantitation /detection', ' phase change', ' polymerase chain reaction']",NIAID,IDAHO TECHNOLOGY,R43,2002,100000,-0.013772886075396179
"COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION There are approximately 2.5 million people in the US who are speech impaired to the extent that it is considered a functional limitation.  Today, many people with severe communication disabilities lack access to electronic and even printed material, have a lack of opportunity for interaction and opportunity for self-advocacy, and experience isolation.  Providing accessibility to wireless voice, data and Internet communications directly from the device is of tremendous importance to people with severe communication disabilities. The primary objective under the Phase I grant was to investigate the potential of word-level disambiguation technology for text generation on a communication aid to meet the needs of many individuals requiring augmentative and alternative communication (AAC).  Phase I findings validated T9 technology as a viable method for text generation and also AAC device users want to access wireless voice, data and Internet communications directly from the device.  The specific aims of Phase II are to: investigate hardware platforms for AAC device host candidates, develop Windows software modules for T9 and AAC, develop portable AAC resources, integrate wireless voice and data communications, and conduct usability testing of the product as it develops. PROPOSED COMMERCIAL APPLICATION The outcome of Phase II will be a communication aid device for production in Phase III that is based on commercially available hardware with minimal custom AAC hardware support.  The goal is that the software platform developed in Phase II will be ported to existing low-cost hardware as much as possible to: make use of newly developed platforms, provide more choice to AAC device users, provide more flexibility in user interface, and reduce overall device costs to the end user when commercially manufactured.  n/a",COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION,6569890,R44RR013191,"['Internet', ' artificial intelligence', ' biomedical equipment development', ' clinical biomedical equipment', ' clinical research', ' communication disorder aid', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' human subject', ' online computer', ' vocabulary', ' voice']",NCRR,"MADENTEC (USA), INC.",R44,2002,139082,-0.004114674385123955
"Diagnostic Logic and Adaptive Assessment for Psychiatry  DESCRIPTION (provided by applicant):  This SBIR Phase I application proposes to extend an existing multi-tier Internet client-server system (""CliniMetricar"") by integrating active diagnostic logic.  CliniMetrica currently provides systematic psychiatric assessment using the World Health Organization (WHO) Schedules for Clinical Assessment in Neuropsychiatry (SCAN, version 2.1). CliniMetrica automatically indexes digital audio recording of assessment interviews, and was developed with SBIR support from NIMH Digital video functions are currently being implemented and tested with additional NIMH support, as are functions to support remote psychometrics for the training and monitoring of interviewers.  The CliniMetrica system is increasing in sophistication and functionality, and has applications for clinical research (e.g., clinical trials) as well as for more routine clinical practice.  The current lack of fully developed and tested diagnostic functionality is a major gap.  A number of potential customers have requested integrated DSM-IV and/or lCD-10 diagnostic results to be automatically linked to assessments.  In order to meet this market need, we propose to implement the DSM-IV and ICD-10 nosologic systems as two classification knowledge bases that a logic engine will process to generate diagnostic results.  These logical functions are difficult to implement and manipulate with procedural languages (e. g. C + +). so the use of a logic engine provides significant technical benefits.  This diagnostic logic version of CliniMetrica is referred to as ""CliniMetrica-Dx.""  To assist raters in thorough examination and to support adaptive assessment, a user interface coupled to logic processing modules will allow tracking the diagnostic status of a subject (the sets of true, false, partially true, or partially false DSM-IV and lCD-10 diagnoses during assessment.  The logic engine will dynamically generate assessment item subsets (currently from the SCAN) needed to rule-in or rule-out DSM-IV and lCD-10 diagnoses. During the assessment, presentation of these symptom sets to the assessor can further guide the interview. By narrowing the ""search space,"" the efficiency of assessments will be increased. By formalizing the search, reliability and validity can be enhanced In addition, to provide support for nosologic research and development, in Phase II the system will include mappings between DSM-IV and lCD-10, and between current and future versions of the DSM and lCD.  The CliniMetrica-Dx system as an application framework will generalize to other clinical psychiatric assessment instruments such as the SCID, to adaptive self-report systems, and to other medical specialties.  It also will have applications for education and training.   n/a",Diagnostic Logic and Adaptive Assessment for Psychiatry,6549963,R43MH066434,"['Internet', ' artificial intelligence', ' clinical research', ' computer assisted diagnosis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' disease /disorder classification', ' human subject', ' indexing', ' mental disorder diagnosis', ' psychometrics']",NIMH,"MEDICAL DECISION LOGIC, INC.",R43,2002,94169,0.005873141887173281
"Genomic application of suspension array technology DESCRIPTION (provided by applicant): The principle of the proposed project is the application of fluorescent microsphere based suspension array technology (SAT) to the cytometry based simultaneous detection of multi analytes. The proposal consists of four overlapping subprojects: (a) Technological development of biological microbead procedures using cells or microorganisms as substitutes for polymeric microspheres to lower the cost of SAT compared to the cost of methods using microbeads manufactured by polymer chemistry. (b) Development of a test to detect gene translocations and rearragements frequently responsible for malignant transformations. A method based on measuring bead-based hybridization of specific 5' and 3' nucleotide sequences in the vicinity of chromosomal translocation breakpoints would allow large scale screening of leukemias and various types of cancers by the measurement of 5'/3' sequence ratio. (c) Development of a DNA binding protein profiling assay providing easy, reproducible and high throughput technology to determine the expression pattern of transcription factors (TFs) binding to single stranded hexamere oligonucleotide sequences anchored to the solid phase surface of microspheres. This subproject is at the R&D level and needs to be thoroughly tested. (d) Development of artificial neural network software applications to analyze and classify the ""fingerprint patterns"" produced by the SAT measurements in subprojects (b) and (c). One of the most important goals of the work in Phase I will be to select the approach worth focusing on in Phase II. n/a",Genomic application of suspension array technology,6483937,R43CA096379,"['DNA binding protein', ' artificial intelligence', ' bacteria', ' chromosome translocation', ' flow cytometry', ' functional /structural genomics', ' gene rearrangement', ' genetic recombination', ' genome', ' high throughput technology', ' microarray technology', ' oligonucleotides', ' polymers', ' technology /technique development', ' tissue /cell culture', ' transcription factor']",NCI,"SOFT FLOW, INC.",R43,2002,100000,-0.02909564693732965
"A Personal Status Monitor for the Home The purpose of this Phase II SBIR is to develop a portable and completely wireless system that detects, processes, and analyzes muscle activity for remotely monitoring the functional status of an individual. The Personal Status Monitor (PSM) will remotely monitor the use of muscles during the exertion of motor tasks in a continuous and unobstructed fashion. Through pattern recognition of surface electromyographic (EMG) signals, the PSM will provide the caregiver with an objective parametric measure of how physically active their patient has been, such as walling, sitting, personal care, and feeding. The PSM will consist of three components: 1) four wireless EMG sensors, 2) a body worn transceiver (Repeater), and 3) the Base Station, which processes the signals for pattern recognition and feature extraction. The information can be sent to a remote location via telephone lines or the Internet. The specific aims of this program for Phase II are: Aim 1: To continue with Phase I development of the pattern recognition algorithms in patients with stroke; Aim 2: Design and build a working prototype of the hardware and software for the PSM; and Aim 3: Field test the prototype wireless system among stroke patients in the home environment. PROPOSED COMMERCIAL APPLICATIONS: The MA will primarily augment clinical service by making the line an effective place for rehabilitation. In addition, the PSM will have direct applicability to the field of ergonomics for work-site assessment, or in sports or recreational activities as a feedback device to facilitate training of skilled movements. Numerous other applications in the field of rehabilitation could include monitoring of drug therapies for tremor or other neuromuscular conditions, or home-exercise compliance. The knowledge base and prototypes developed in this project are directly transferable to other acquisition systems for biological signals recorded from the skin, such as EEGs and EKGs.  n/a",A Personal Status Monitor for the Home,6534517,R44AR047272,"['artificial intelligence', ' biomedical equipment development', ' caregivers', ' computer program /software', ' computer system design /evaluation', ' electromyography', ' functional ability', ' home health care', ' human subject', ' muscle function', ' patient monitoring device', ' portable biomedical equipment', ' stroke', ' telemedicine', ' telemetry']",NIAMS,"ALTEC, INC.",R44,2002,404087,-0.04622975841814038
"Smart Power Assistance Module for Manual Wheelchairs    DESCRIPTION (provided by applicant): We propose to use power assistance as the basis for a Smart Power Assistance Module (SPAM) that provides independent power assistance to the right and left rear wheels of a manual wheelchair. The SPAM will detect obstacles near the wheelchair, and modify the forces applied to each wheel to avoid obstacles.  For individuals with visual impairments that are unable to walk with a long cane or walker, the SPAM will provide safe travel by assisting the user to avoid obstacles. This research will build on the investigative team's previous experience with power assistance for manual wheelchairs and obstacle avoidance for power wheelchairs and rollators. Extensive outside evaluation of the SPAM will be provided throughout the course of the project by clinicians active in wheelchair seating and mobility.         n/a",Smart Power Assistance Module for Manual Wheelchairs,6581049,R43EY014490,"['artificial intelligence', ' assistive device /technology', ' biomedical device power system', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' field study', ' human subject', ' medical rehabilitation related tag', ' vision aid', ' vision disorders']",NEI,AT SCIENCES,R43,2002,249727,-0.01714809897777186
"Multiresolution Autofocusing for Automated Cytogenetics The goal of this project is to develop innovative digital microscope autofocusing techniques for automated cytogenetics applications.  We propose a novel multi-resolution image analysis approach to focus measurement and detection, based on the recently developed mathematical theory of wavelet transform.  In comparison to currently available single-resolution techniques, the proposed method overcomes their fundamental limitations and promises considerably more accurate, reliable and faster means to compute and determine in-focus image position for image acquisition.  This will significantly increase the ability and efficacy of automated scanning microscope instruments for clinical and cancer cytogenetics applications. In Phase 1 we will investigate the feasibility of the proposed method based on its utilization in fluorescence microscopy.  We will develop and implement the algorithm and software for multi-resolution focus function computation and in-focus position determination.  We will test and evaluate the new method against the current best-performing algorithms by comparing (1) Accuracy; (2)  Range; (3)  Insensitivity to other parameters; and (4)  Speed. If the new approach achieves superior performance, in Phase 2 the technique will be further developed and extended to bright-field microscopy applications.  When fully developed, the new technology will be made available to Applied Imaging (AIC) for integration into the PowerGene cytogenetics automation products. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new techniques are developed and qualified for routine application, they will be made available to AIC for incorporation into the PowerGene product line of cytogenetics automation equipment, both in new systems sold and as an upgrade to existing systems already in use in cytogenetics labs, thus commercializing the technology quickly. n/a",Multiresolution Autofocusing for Automated Cytogenetics,6443502,R43RR016817,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' cytogenetics', ' digital imaging', ' fluorescence microscopy', ' fluorescent in situ hybridization', ' human data', ' image enhancement', ' image processing', ' mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R43,2002,91727,-0.015818761278316436
"Epileptic Seizures in the Neonatal EEG   DESCRIPTION: (provided by applicant) The identification of electrographic            seizures during long-term EEG monitoring in the neonate is currently based upon      visual interpretation of the graphic record, a process that is very                  time-consuming. While significant progress has been made in the automated            detection of seizures in the adult population, relatively little work has been       done in the neonatal area. Therefore, the major objective of this project is         the development of techniques for the reliable automated detection of                electrographic seizures in the neonatal EEG. We propose a multi-stage, hybrid        approach to detection that will employ a combination of signal processing,           pattern recognition, neural networks, and expert rules. Through the successive       stages of the detection process, multichannel neonatal EEG data containing all       types of background activity and artifacts will be analyzed to detect and            classify electrographic seizures. We postulate that the varied types and             morphologies of seizures in the neonatal EEG, as compared to seizures in the         adult EEG, can best be detected and classified using this hybrid approach. We        will test the methods we develop on data recorded from infants in the Clinical       Research Center for Neonatal Seizures, The Methodist Hospital, in Houston,           Texas. We expect that the information we gain from the research will lead to         the development of a practical seizure detection system and further our              long-term goals of reduced expense in the reading and interpretation of              neonatal EEGs, and also facilitate the efficient collection of seizure               parameters for possible use in future research studies.                                                                                                                   n/a",Epileptic Seizures in the Neonatal EEG,6529026,R01NS040577,"['adult human (21+)', ' age difference', ' artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' brain electrical activity', ' computer assisted diagnosis', ' electroencephalography', ' epilepsy', ' human subject', ' newborn human (0-6 weeks)', ' patient monitoring device', ' patient oriented research']",NINDS,UNIVERSITY OF HOUSTON,R01,2002,193637,-0.01324190809223535
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6489213,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2002,474210,-0.03411358685880645
"Automated Quantitation of 3D Echocardiograms In Phase I we developed a method for automated border detection (ABD) of echocardiographic scans that is feasible for clinical application. The accuracy of our processes provides exceeds Phase I goals and is comparable to interobserver variability in measuring volume and ejection fraction, and in border location. For a diverse set of patients, we have achieved an accuracy of 10 ml for endocardial volume, 4% for ejection fraction, and ,2.0 mm for border position. Our processes operates in 4 min. In Phase II we propose to continue research and development to move our ABD technology closer to clinical user. Our first specific aim is to reduce the amount of manual input required even further. Our second aim is to develop a prototype system suitable for clinical evaluation. Our third aim is to perform a pilot trial to evaluate the performance of our ABD process, as a preparation for a more formal, multi-center clinical trial planned for Phase III. The proposed research is important because quantitative 3D echo provides greater accuracy and reproducibility and more comprehensive information on cardiac status than currently available imaging techniques. The significant advantages of 3D echo are not currently available for clinical practice because it is impractical without automation. PROPOSED COMMERCIAL APPLICATIONS: Automation of echocardiogram border detection enables physicians to obtain accurate, reproducible and comprehensive measurements of the heart's size, shape and function. This technology can be included in ultrasound systems or provided in workstations. The core technology can be applied to other organs and other imaging modalities. n/a",Automated Quantitation of 3D Echocardiograms,6443269,R44HL059054,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' echocardiography', ' heart disorder diagnosis', ' heart ventricle', ' human subject', ' image processing', ' papillary muscles', ' pericardium']",NHLBI,"QUANTIGRAPHICS, INC.",R44,2002,255191,-0.008313082011071221
"Digital Elevation Models for Population Estimates Research exploring the feasibility of deriving population estimates from remotely sensed data demonstrates that objects in the urban landscape can be identified and incorporated into a population estimates system based on the housing unit method. Nonetheless, this research also reveals shortcomings in the technology producing the input files used in the automatic detection of objects. The problem involves the assumption and techniques used when converting high resolution images into digital elevation models (DEM). DEM files serve as input to the programs used in the detection of housing units. Efforts to correctly identify housing units are time-consuming and error-prone without clear and distinct DEMs. The objectives of this Phase I SBIR application are to further refine strengthen and test the software employed in transforming satellite and aerial imagery into digital elevation model (DEMs). DEM files serve as input to the programs used in the detection of housing units. Efforts to correctly identify housing units are time-consuming and error-prone without clear and distinct DEMs. The objectives of this Phase I SBIR application are to further refine, strengthen and test the software employed in transforming satellite and aerial imagery into digital elevation models. Specific goals of this Phase I proposal include: 1) modifying and coding new assumptions into the DEM software, 2) testing the accuracy and reliability of the digital elevation code on new sub1, aerial imagery, and 3) designing a new GUI for use in the pre- processing phase of DEM building. PROPOSED COMMERCIAL APPLICATIONS: The commercial value of this specific research is best understood when viewed as part of a larger effort to produce an automated system for deriving population estimates of user defined areas based on current, remotely sensed data. Such a system will serve a wide range of commercial interests seeking ""up-to-the-minute"" counts and measures of population and housing change. n/a",Digital Elevation Models for Population Estimates,6443114,R43HD041774,"['altitude', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' environment', ' geographic site', ' human population distribution', ' mathematical model', ' population survey', ' urban area']",NICHD,"SENECIO SOFTWARE, INC.",R43,2002,99979,0.0010609006351836525
"Deployment Framework for Medical Imaging Applications DESCRIPTION (provided by applicant): There are many reasons for the relatively slow proliferation of advanced medical image processing methods but a significant reason is the present paradigm for providing access: most applications are still tied to proprietary software and hardware environments that carry significant up-front costs. The ultimate intent of this work is leverage commodity computing technologies to develop an open, extensible framework for deploying medical image processing applications in the heterogeneous, networked computing environment of today. The framework will provide clinicians and researchers access to state-of-the-art image processing applications regardless of their particular computing platform or locally available computing resources connecting them with federated database resources, with high-end computing resources, or even with their colleagues in a peer-to-peer computing environment. The aims for Phase I of this project are: (1) Demonstrate that the framework provides access to image processing applications to an extent that is largely independent of local computing resources. (2) Demonstrate that the framework is general in that the same components can be reused for deploying a wide variety of medical imaging applications. (3) Demonstrate that the framework is customizable both by third-party developers and by end-users allowing power-users to both create and deploy new applications. Work in Phase II will extend the framework and develop two-demonstration applications--computer aided diagnosis (CAD) for mammography and multimodality image fusion. The ultimate goal is to obtain key partnerships and the private equity investment necessary for commercialization, which will proceed by launching revenue-generating versions of the CAD and image fusion applications. n/a",Deployment Framework for Medical Imaging Applications,6494576,R44EB000149,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computed axial tomography', ' computer assisted diagnosis', ' computer human interaction', ' computer network', ' computer program /software', ' computer system design /evaluation', ' human data', ' image processing', ' mammography', ' mathematics', ' positron emission tomography', ' telemedicine']",NIBIB,"FRONTIER MEDICAL, LLC",R44,2002,143577,-0.03695075792400652
"AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION Quantification of Minimal Residual Disease (MRD) is a general concern in oncology since this parameter is likely to give valuable information to clinicians to customize chemotherapeutic treatments and to anticipate possible relapses. An automated system will be developed for the quantification of MRD by using real-time PCR to quantify cancer cells in a background of non pathologic DNA. The system will be derived from an existing high-throughput sample handling system (developed by Meldrum and team) named Acapella. Acapella has a pipelined serial architecture which makes it possible to develop an adaptive PCR control algorithm ensuring a level of sensitivity and accuracy for the quantification results specified by the clinician. In the R21 phase of the project, a critical component of the system is the real-time thermocycler. It will provide DNA quantification results of greater precision than what is currently possible with commercial instruments such as the ABI PRISM 7700 Sequence Detector by taking advantage of a high performance custom fluorescence analyzer and sophisticated data analysis methods. The fluorescence analyzer will have a signal to noise ratio and a dynamic range of at least one order of magnitude larger than the optics used on commercial systems. This unique feature will permit precise measurements of the amplification kinetics during at least five cycles in the exponential phase of the reaction. The amplification yield will he derived from these data using statistical estimators customized to meet the requirements of real-time PCR data analysis. The sample DNA content will be derived from the amplification yield and the calibrated fluorescence measurements of the reaction kinetics. This new approach will make it possible to run series of real-time PCRs with more flexibility than would be possible if the assay was based on standard reactions required to have the same amplification yield as the clinical samples. PCR conditions will be adapted online without concerns about possible differences of amplification rate. The assay control algorithm will adapt the reaction DNA content, the primer selection, and the number of PCRs to meet the clinician requirements for particular patient DNA. During the R21 phase of the project a prototype of the real-time thermocycler will be developed to demonstrate the optic performance and the possibility to estimate the PCR amplification rates with 5% accuracy. A conceptual design of the fully integrated process from patient blood sample to MRD quantification data will be completed to allow assessment of expected performance, cost, and risks associated with the development of the fully engineered system. The development of the various hardware and software components along with their integration into the automated system will take place during the R33 phase of the project. Performance of the system will he evaluated on real biological samples provided by the UW Department of Laboratory Medicine. Results returned by the system will he compared with results of t(14; 18) PCR performed in this department with an ABI PRISM 7700 for the diagnosis of patients suffering from follicular lymphomas.  n/a",AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION,6514339,R33CA084691,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosome translocation', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence', ' high throughput technology', ' human tissue', ' minimal residual disease', ' neoplasm /cancer diagnosis', "" nonHodgkin's lymphoma"", ' nucleic acid quantitation /detection', ' polymerase chain reaction']",NCI,UNIVERSITY OF WASHINGTON,R33,2002,582434,0.0069035415313369024
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6547549,R01EY013875,"['blind aid', ' blindness', ' clinical research', ' computer human interaction', ' computer program /software', ' cues', ' human subject', ' reading', ' vision aid', ' vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2002,338540,-0.015406092792716172
"Medical Advice from Glaucoma Informatics (MAGI)  DESCRIPTION (provided by applicant):  The project, Medical Advice from Glaucoma Informatics (MAGI), seeks to improve glaucoma diagnosis and management with state-of-the-art machine learning classifiers. These classifiers will automate the interpretation of standard automated perimetry (SAP), newer visual field tests, and structural tests for glaucoma in the general population and in stratified glaucoma populations. Phase 1 will complete the feasibility testing already underway. Phase 2 will apply the refined methods to a wider set of glaucoma testing problems.The management of glaucoma depends on a series of classifications. The glaucoma provider classifies tests as normal or indicative of glaucoma. The clinician then determines whether an eye has glaucoma or has had progression. Assembling these classifications, the provider makes decisions about management. Automated test interpreters, either as part of the testing machine or as a computer-based resource, can aid glaucoma providers with real-time interpretations. The research we propose takes advantage of our extensive data sets and builds on the ongoing research in our laboratories.Statistical classifiers, Bayesian nets, machine learning classifiers, and expert systems represent different types of classifiers with diverse properties. Machine learning classifiers can perform exceptionally well at identifying classes, even when the data are complex and have dependencies. We will test and select the optimal machine learning classifier for diagnosis. We will further improve classifier performance and determine feature utility by optimizing the feature set visual field tests are time consuming and stressful. We will streamline the tests by removing unimportant test points.Even with decades of experience, there is uncertainty with regard to the evaluation of the SAP. There is less accumulated knowledge about non-standard tests, such as short-wavelength automated perimetry, nerve fiber layer thickness, or optic nerve head topography. Machine classifiers may learn how to interpret nonstandard tests better. We will go beyond STATPAC's capabilities with classifiers that have learned to interpret SAP, nonstandard visual field tests, structural glaucoma tests, and STATPAC plots in the general population and in patients stratified by race, family history, and other information available at the time of the test.Conversion of suspects to glaucoma and progression of glaucoma cannot yet be predicted from tests. We will develop classifiers for these predictions. Classifiers will be designed to diagnose early glaucoma, detect early progression, and identify glaucomatous eyes at risk of progression.Unsupervised learning provides cluster analysis that can determine distinct groups with members in some way similar from the test data. In an effort to discover new and use useful information with unsupervised learning, we will mine our data in visual function and structural tests for glaucoma  and in specific combinations of population groups. n/a",Medical Advice from Glaucoma Informatics (MAGI),6551796,R21EY013928,"['clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' early diagnosis', ' eye disorder diagnosis', ' glaucoma', ' glaucoma test', ' human subject', ' neural information processing', ' neuropathology', ' visual fields']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R21,2002,144319,-0.03611527391044353
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6528412,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2002,325555,-0.05302234469684174
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6516567,U01DE013331,"['biomarker', ' biopsy', ' clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' enzyme linked immunosorbent assay', ' facial muscles', ' gas chromatography mass spectrometry', ' human subject', ' inflammation', ' interview', ' magnetic resonance imaging', ' mastication', ' musculoskeletal disorder diagnosis', ' oral facial pain', ' pain threshold', ' psychobiology', ' questionnaires', ' radioimmunoassay', ' sign /symptom', ' statistics /biometry', ' synovial fluid', ' temporomandibular joint syndrome', ' tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2002,1325497,-0.006583128058954038
"Development of Ultrasonic Apparatus for Dental Diagnosis   DESCRIPTION: Ultrasonic diagnostic apparatus has been proposed (Phases 1 and 2)      for Dental applications in determining tooth pathologies such as                     demineralization, caries, fractures, abscesses, and tooth wear. The equipment        adopts piezoelectric and optic hybrid transduction system for interrogation on       teeth. Ultrasonic responses of the tooth structure will then be analyzed by a        pattern recognition expert system (artificial intelligence) to determine the         diagnosis of the tooth inspected. The proposed research will eventually help to      reduce the use of harmful X-ray radiation in Dental clinic and also contribute       to artificial intelligence based diagnosis. In the Phase 1 research, tooth           specimens will be collected from local Dental clinics; demonstration                 instrumentation will be constructed; ultrasonic testing will be conducted on         the tooth specimens in vitro; and finally, the test data will be analyzed to         show the potential for Dental pathology identification. The feasibility of the       proposed research concept will be demonstrated, if: 1) meaningful ultrasonic         tests can be conducted using the simple piezo-/opto-ultrasonic system on the         tooth specimens collected; 2) various Dental pathologies in the tooth specimens      may be characterized by using wave pattern of the ultrasonic responses; and 3)       by identifying particular features of an ultrasonic wave pattern, the actual         tooth pathology may be recognized.                                                   PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                          n/a",Development of Ultrasonic Apparatus for Dental Diagnosis,6402448,R43DE014270,"['artificial intelligence', ' biomedical equipment development', ' dental disorder diagnosis', ' dental structure', ' dentistry', ' diagnosis design /evaluation', ' tooth', ' tooth surface']",NIDCR,AAC INTERNATIONAL,R43,2001,100000,-0.0007178925941906189
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6388212,R24HD038585,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biological signal transduction', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' electromyography', ' evaluation /testing', ' human subject', ' motor neurons', ' neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2001,604881,-0.04028588234762947
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING   DESCRIPTION (adapted from investigator's abstract): Facial expression provides       sensitive cues about emotional response and plays a critical role in the             regulation of interpersonal behavior. Human-observer based methods for               measuring facial expression are labor intensive, qualitative, and difficult to       standardize across laboratories and over time. To make feasible more rigorous,       quantitative measurement of facial expression in diverse applications, the           investigators formed an interdisciplinary research group that covers expertise       in facial expression analysis and computer vision. In August 1995, the research      group received initial funding for Facial Expression Analysis by Computer Image      Processing (NIMH #IRO1MH51435). With NIMH support, they created a large              representative database for method development and developed and validated a         face analysis system that tracks gaze and facial features in digitized image         sequences of infant, child, and adult subjects. In near frontal views, the Face      Analysis System has achieved concurrent validity with manual FACS coding for 16      of 44 FAGS action units and more than 30 combinations in which they occur. For       the competing renewal, the investigators will (1) Increase system robustness to      head orientation and head motion (2) Increase the number of recognizable action      units to include all 30 of those that have a specific anatomic basis, and (3)        Conduct a systematic, large-scale, comprehensive test of the developed Face          Analysis System by using multiple databases. These databases encompass subjects      of various ages and backgrounds and varying types of emotion induction, head         orientation, head motion, size of the face in pixels, and presence of speech.        The databases were initially collected to answer substantive questions about         emotion processes; they represent the types of data that the Face Analysis           System will encounter in psychology research and clinical applications. n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6287970,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2001,334747,-0.003090001677942138
"COMPUTER VISION ANALYSIS OF DYNAMIC FACIAL BEHAVIOR DESCRIPTION (Applicant's abstract): Facial expressions provide an important behavioral measure for the study of emotion, cognitive processes, and social interaction, and contain diagnostic information for neurological disorders and depression. Facial expression measurement from video is less intrusive than EEG, EMO, ANS or brain imaging measurements as an indicator of emotional activity. The measurement is presently performed by human experts. The goal of this research is to develop an automatic system for recognition, measurement, and coding of facial expressions from video using computer vision technology. This project will utilize probabilistic models of dynamical systems to mod& the facial behavior underlying the observed image sequences. These techniques include hidden Markov models, and a new stochastic modeling technique developed by Movellan and colleagues called diffusion networks [38]. Diffusion networks offer the advantage over traditional dynamical models of allowing continuous time dynamics and continuous states. An automated system would make facial expression measurement more widely accessible as a research tool in behavioral science and investigations of the neural substrates of emotion.  n/a",COMPUTER VISION ANALYSIS OF DYNAMIC FACIAL BEHAVIOR,6391721,F32MH012417,"['behavior test', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' clinical research', ' cognition', ' computer assisted diagnosis', ' depression', ' emotions', ' face expression', ' human subject', ' image processing', ' mathematical model', ' social integration']",NIMH,UNIVERSITY OF CALIFORNIA SAN DIEGO,F32,2001,41996,-0.009121690720187302
"Applied Imagery Pattern Recognition Workshop   DESCRIPTION (Provided by Applicant):                                                 The Applied Imagery, Pattern Recognition (AIPR) Workshop is held annually in         Washington, D.C., at the Cosmos Club.  This workshop brings together 60-80           members of academia, industry, and other federal agencies, with a particular         history of involvement with the broader intelligence community in image              processing and analysis.  The workshop format for the last decade has                generally involved three days of high-quality presentations and investigator         interaction, both formally and informally at evening meeting receptions held         at the Cosmos Club.  The 30th meeting will be held from October 10-12, 2001,         and focus on Time-Varying Imagery.  This has particular relevance to medical         imaging, as it is increasingly being used to describe intrinsically-varying          physiologic phenomena (e.g., blood flow, intra-operative conditions).  The           goals of the meeting are the following: to provide technology transfer among         the three groups and to demonstrate the complementary capabilities of the            groups.  This is especially important in the area of validation of algorithms,       and the consequent need for databases that permit that validation.  Among the        specific topics to be covered at this meeting are: Real-time event                   understanding,  Extraction of information from video, video compression and          decompression, and hand and body gesture recognition.  A five-year period of         support is requested, to enable the meeting to grow in participation and             breadth of disciplines attracted.                                                                                                                                                                                                                              n/a",Applied Imagery Pattern Recognition Workshop,6421360,R13CA093819,"['artificial intelligence', ' computer human interaction', ' videotape /videodisc', ' workshop']",NCI,GEORGE WASHINGTON UNIVERSITY,R13,2001,5000,0.007224595515132196
"ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR Imaging detectors for 10 to 150 keV photons have many uses in medical technology, including tumor imaging, SPECT, and radiography. Digital output is particularly useful since it allows image enhancement, analysis, transmission and storage. In Phase I we proposed a new technology that could capture images with 100 microm spatial resolution and 1 keV energy resolution or better. This capability would facilitate entirely new classes of medical diagnostic procedures, particularly for transgenic small animal imaging. Our Phase I work demonstrated the feasibility of this approach. In this Phase II effort, collaborating with Paul Luke at LBNL, we will construct 1 cm thick crossed-strip HPGe detectors having 10 x 10 strips, each 2 mm x 20 mm. We will develop cooled FET preamplifiers having low noise and large bandwidth properties specifically required by this approach. We will also develop analog filtering electronics to condition the detector's novel signals and employ digital pulse processing electronics to acquire these signals at rates up to 10/6 cps. Finally, we will devise procedures to test the detector's linearity and develop processing algorithms to perfect this quality. Phase II will conclude with a working and tested prototype. Phase III will entail primarily production engineering efforts. PROPOSED COMMERCIAL APPLICATION: As an energy resolved digital detector with 100 microm spatial resolution, the proposed detector technology could find many medical applications, including SPECT, energy resolved angiography for small mammals, bone densitometry on rodent bones, and small, hand-held gamma cameras. Non-medical applications would include non-destructive testing, astrophysical gamma imaging, nuclear cleanup uses, and x-ray diffraction detectors.  n/a",ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR,6376544,R44CA075844,"['X ray', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R44,2001,373949,-0.023309271658753097
"Advanced Vision Intervention Algorithm(AVIA)   Description (from the investigator's abstract): The objective of this                application is to implement an iterative, nine-step advanced vision                  intervention algorithm (AVIA) in software to optimize the predictability of          virtually any current or anticipated customized human vision intervention            method. The software program will use the investigator's Visual Optics class         library, as well as new software for the ray transfer element, database              analysis routines, and the ray tracing surface optimization algorithm. The           program will allow, but not require, exam data from commercially available           ophthalmic instruments such as corneal topography and wavefront aberration for       input in the optical modeling of an individual's eye. This algorithm is, to the      investigator's knowledge, the only formal framework designed specifically to         optimize the predictability of surgical and non-surgical correction methods. It      is not only a technological innovation in its own right, it also makes the most      of the current and future vision correction methods to which it is applied.          PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",Advanced Vision Intervention Algorithm(AVIA),6403968,R43EY013666,"['artificial intelligence', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' eye surgery', ' laser therapy', ' ophthalmoscopy', ' statistics /biometry', ' vision disorders']",NEI,"SARVER AND ASSOCIATES, INC.",R43,2001,99785,-0.029359337350301797
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6445973,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2001,354009,-0.009939780380044604
"VIRUS STRUCTURE DETERMINATION SOFTWARE Virus structure determination using electron microscopy has become a useful research tool aimed at understanding viral assembly and infectivity to facilitate the design of anti-viral drugs and virus-based gene delivery systems. Our long term goal is to broaden the group of people able to determine virus structures by providing an integrated software suite for three-dimensional virus structure determination using electron microscopy. The software suite, called Tumbleweed, will allow easy, efficient, and routine determination of icosahedral virus structures from electron micrographs. Novel aspects of Tumbleweed will include a comprehensive suite of tools for icosahedral structure determination, incorporation of an expert system to guide users through the reconstruction procedure, and data analysis tools to ensure that structures are determined accurately. Tumbleweed will also provide a consistent easy to use graphical user interface to all reconstruction tools including data analysis, data management, and data logging. In addition, Tumbleweed will provide tools for image selection, quality assessment, and structure visualization that can be used with any electron microscopy structure determination method. Thus, in addition to virologists, target users include electron microscopists and structural biologists. The result of this Phase Il SBIR will be a completely integrated and tested software package allowing easy, efficient, and routine virus structure determination. PROPOSED COMMERCIAL APPLICATIONS: Tumbleweed is targeted at a large group of users with varied knowledge, experience, and research goals. Virologists will be attracted to the extensive user guidance and intuitive design. Structural biologists and electron microscopists performing virus structure determination will be attracted to the concept of a complete integrated software package. Last, all electron microscopists and structural biologists will be attracted to the integration of all general data processing into a single extendible package. Combined this group should provide a large user-base allowing QED Labs to commercialize Tumbleweed successfully.  n/a",VIRUS STRUCTURE DETERMINATION SOFTWARE,6343026,R44GM058327,"['artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data management', ' electron microscopy', ' molecular dynamics', ' structural biology', ' virus assembly', ' virus morphology']",NIGMS,QED LABS,R44,2001,376147,-0.0361110188870516
"Applying Usability to A Knowledge Based System A cancer genetics-tracking database will be redesigned using usability engineering techniques to improve the functionality and usability of the current system. This is important because it will lead to a system that is easier to use and learn, will decrease the chance of errors, and will increase productivity, and user satisfaction. The current state of informatics offers the potential for the creation of tools to assist in the reduction of medical errors. The redesign of this tracking database will be completed through a three-phase process. The first phase will use the results of a usability analysis to redesign and prototype the cancer genetics-tracking database. In the second phase, usability studies will then be conducted to ensure that the system is functional, easy to use, easy to learn, and meets the goals of the users. The usability studies will include heuristic evaluations, keystroke level models, talk-aloud methods, and cognitive walkthrough techniques. The system will be modified based upon the results of these studies. Research will be compiled on the advantages and disadvantages of ICD coding Vs. SNOMED followed by the selection of the most useful system for coding medical information. In the third phase the final redesign will be compared to the old system using a within-subject design to determine if the redesign decreases the error rate, increases productivity, and user satisfaction. This will be followed-up with a survey to determine the perceived usability of the redesigned application. Throughout the redesign process, specific usability guidelines will be developed for designing healthcare software that is computational and knowledge- based in nature.  n/a",Applying Usability to A Knowledge Based System,6340157,F38LM007188,"['artificial intelligence', ' cancer information system', ' cancer registry /resource', ' computer assisted medical decision making', ' computer human interaction', ' computer system design /evaluation', ' family genetics', ' human data', ' neoplasm /cancer genetics']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2001,68753,-0.016663760734681506
"Neural Network System for Detection of EEG Microsleeps   DESCRIPTION (Verbatim from the Applicant's Abstract): A software system based        on Artificial Neuro-fuzzy hybrid technology will be developed for automatic          detection of microsleep events from EEG data. The software system will be            designed for used as a model-free and rule-free classification tool that             achieves generalization power through learning from examples.   The development of the software system will require a Graphical User Interface       for data example selection, frequency-analytic preprocessing of EEG raw data,        feature extraction for microsleep characterization, design and training of           neural networks for single EEG channels, and a fuzzy system for contextual           combination of network response for multiple EEG channels to a single system         response.                                                                                                                       The training and testing of the neural networks will be based on a database of       visually scored examples of microsleep and non-microsleep events from                electrophysiological data, which will be randomly divided into training,             validation and test sets.                                                                                 The performnance of the software system will be evaluated based on the               false-positive and false-negative rate for the microsleep detection using data       examples unknown to the system. The agreement rate between the combined network      response and results from visual and conventional automatic scoring will be          used as additional evaluation parameter.        PROPOSED COMMERCIAL APPLICATION: The software system will be an attractive tool for researchers, medical and technical  personal, industrial engineers. It enables the user to quantify alertness/sleepiness  in studies on sleep disorders, shiftwork, drug effects and fatigue countermeasures.  It will help reduce time-consuming visual scoring by human experts. In addition, it  will widen our knowledge about the rapid transition events (microsleeps) between  wake and sleep and can contribute to the development of alertness monitor systems.                                                                                                                                                                                                                                                                                                      n/a",Neural Network System for Detection of EEG Microsleeps,6338195,R43NS039711,"['artificial intelligence', ' biomedical automation', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' electroencephalography', ' electrophysiology', ' human data', ' neural information processing', ' sleep']",NINDS,"CIRCADIAN TECHNOLOGIES, INC.",R43,2001,93457,-0.06548913987558268
"MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING   A low-cost, high-resolution, high-contrast color digital camera optimized        for ophthalmology will be demonstrated. The maximum entropy camera         will be tested for its effectiveness in meeting the image quality requirements       for telemedicine and for remote screening of pre-proliferative and                   proliferative diabetic retinopathy. The proposed device exploits recent              technological advances in high sensitivity CCD cameras and digital signal            processing electronics. Today's low cost 8-bit CCD cameras do not have the           dynamic range to image the human retina, which is characterized by regions of        high reflectivity (20-40 percent), such as the optic disc, and very low              reflectivity (<2 percent), such as the macula and fovea. Existing digital            cameras used in ophthalmology are not designed to deal with the high dynamic         range and do not consider the special re-saturated characteristics of the            retina. The proposed device will be shown to offer significant improvement over      existing digital color cameras by addressing each of the deficiencies                mentioned.                                                                           PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING,6292349,R43EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R43,2001,107706,-0.007789887283497178
"COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION There are approximately 2.5 million people in the US who are speech impaired to the extent that it is considered a functional limitation.  Today, many people with severe communication disabilities lack access to electronic and even printed material, have a lack of opportunity for interaction and opportunity for self-advocacy, and experience isolation.  Providing accessibility to wireless voice, data and Internet communications directly from the device is of tremendous importance to people with severe communication disabilities. The primary objective under the Phase I grant was to investigate the potential of word-level disambiguation technology for text generation on a communication aid to meet the needs of many individuals requiring augmentative and alternative communication (AAC).  Phase I findings validated T9 technology as a viable method for text generation and also AAC device users want to access wireless voice, data and Internet communications directly from the device.  The specific aims of Phase II are to: investigate hardware platforms for AAC device host candidates, develop Windows software modules for T9 and AAC, develop portable AAC resources, integrate wireless voice and data communications, and conduct usability testing of the product as it develops. PROPOSED COMMERCIAL APPLICATION The outcome of Phase II will be a communication aid device for production in Phase III that is based on commercially available hardware with minimal custom AAC hardware support.  The goal is that the software platform developed in Phase II will be ported to existing low-cost hardware as much as possible to: make use of newly developed platforms, provide more choice to AAC device users, provide more flexibility in user interface, and reduce overall device costs to the end user when commercially manufactured.  n/a",COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION,6188611,R44RR013191,"['Internet', ' artificial intelligence', ' biomedical equipment development', ' clinical biomedical equipment', ' clinical research', ' communication disorder aid', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' human subject', ' online computer', ' vocabulary', ' voice']",NCRR,"MADENTEC (USA), INC.",R44,2001,316991,-0.004114674385123955
"A Personal Status Monitor for the Home The purpose of this Phase II SBIR is to develop a portable and completely wireless system that detects, processes, and analyzes muscle activity for remotely monitoring the functional status of an individual. The Personal Status Monitor (PSM) will remotely monitor the use of muscles during the exertion of motor tasks in a continuous and unobstructed fashion. Through pattern recognition of surface electromyographic (EMG) signals, the PSM will provide the caregiver with an objective parametric measure of how physically active their patient has been, such as walling, sitting, personal care, and feeding. The PSM will consist of three components: 1) four wireless EMG sensors, 2) a body worn transceiver (Repeater), and 3) the Base Station, which processes the signals for pattern recognition and feature extraction. The information can be sent to a remote location via telephone lines or the Internet. The specific aims of this program for Phase II are: Aim 1: To continue with Phase I development of the pattern recognition algorithms in patients with stroke; Aim 2: Design and build a working prototype of the hardware and software for the PSM; and Aim 3: Field test the prototype wireless system among stroke patients in the home environment. PROPOSED COMMERCIAL APPLICATIONS: The MA will primarily augment clinical service by making the line an effective place for rehabilitation. In addition, the PSM will have direct applicability to the field of ergonomics for work-site assessment, or in sports or recreational activities as a feedback device to facilitate training of skilled movements. Numerous other applications in the field of rehabilitation could include monitoring of drug therapies for tremor or other neuromuscular conditions, or home-exercise compliance. The knowledge base and prototypes developed in this project are directly transferable to other acquisition systems for biological signals recorded from the skin, such as EEGs and EKGs.  n/a",A Personal Status Monitor for the Home,6403447,R44AR047272,"['artificial intelligence', ' biomedical equipment development', ' caregivers', ' computer program /software', ' computer system design /evaluation', ' electromyography', ' functional ability', ' home health care', ' human subject', ' muscle function', ' patient monitoring device', ' portable biomedical equipment', ' stroke', ' telemedicine', ' telemetry']",NIAMS,"ALTEC, INC.",R44,2001,403938,-0.04622975841814038
"Epileptic Seizures in the Neonatal EEG   DESCRIPTION: (provided by applicant) The identification of electrographic            seizures during long-term EEG monitoring in the neonate is currently based upon      visual interpretation of the graphic record, a process that is very                  time-consuming. While significant progress has been made in the automated            detection of seizures in the adult population, relatively little work has been       done in the neonatal area. Therefore, the major objective of this project is         the development of techniques for the reliable automated detection of                electrographic seizures in the neonatal EEG. We propose a multi-stage, hybrid        approach to detection that will employ a combination of signal processing,           pattern recognition, neural networks, and expert rules. Through the successive       stages of the detection process, multichannel neonatal EEG data containing all       types of background activity and artifacts will be analyzed to detect and            classify electrographic seizures. We postulate that the varied types and             morphologies of seizures in the neonatal EEG, as compared to seizures in the         adult EEG, can best be detected and classified using this hybrid approach. We        will test the methods we develop on data recorded from infants in the Clinical       Research Center for Neonatal Seizures, The Methodist Hospital, in Houston,           Texas. We expect that the information we gain from the research will lead to         the development of a practical seizure detection system and further our              long-term goals of reduced expense in the reading and interpretation of              neonatal EEGs, and also facilitate the efficient collection of seizure               parameters for possible use in future research studies.                                                                                                                   n/a",Epileptic Seizures in the Neonatal EEG,6383999,R01NS040577,"['adult human (21+)', ' age difference', ' artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' brain electrical activity', ' computer assisted diagnosis', ' electroencephalography', ' epilepsy', ' human subject', ' newborn human (0-6 weeks)', ' patient monitoring device', ' patient oriented research']",NINDS,UNIVERSITY OF HOUSTON,R01,2001,200999,-0.01324190809223535
"A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER   Skin cancer is the fastest growing cancer. Approximately 34,100         Americans developed cutaneous melanoma in 1995; of the survivors, many must          contend with the ongoing trauma of disfigurement and fear. Skin biopsies are         now the most frequently performed medical procedure. It is axiomatic among           dermatologists that early detection and diagnosis are critical. Great strides        have been made in early detection of suspect skin lesions; however failure to        biopsy the right lesion has severe consequences. The dilemma is exacerbated          since 50- 80 percent of biopsies prove unnecessary, contributing to an enormous      waste of health care dollars, patient trauma and negative patient behavior           feedback. The Phase I work in dermatological spectroscopy and artificial neural      net technology suggest that an automated clinical diagnostic aid which produces      a quantitative rather than qualitative diagnostic assessment of skin lesions is      possible. This project proposes development and testing of such a product.           During Phase II a large number of spectroscopic samples of melanoma and nevi         will be used to complete development of an artificial neural net classifier.         Such a classifier system will lead to a commercial product to discriminate           ""normal,"" pre-cancerous and cancerous skin lesions.                                   PROPOSED COMMERCIAL APPLICATION:  The proposed project will lead to a non-invasive, in-office, real-time test to provide an  automated, repeatable diagnostic probability of the nature of skin lesions prior to biopsy.  Skin biopsies are now the most frequently performed reimbursed Medicare procedure,   and as many as 50-80% are found not to be necessary after the fact.  The low cost of   this test, and rapid amortization of the system, coupled with the enormous health care   cost savings possible in conjunction with a significant and widely recognized health   problem, suggest that this product could have great commercial potential.  n/a",A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER,6376769,R44CA078006,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence spectrometry', ' histology', ' human subject', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' reflection spectrometry', ' skin neoplasms', ' spectrometry']",NCI,"WESTERN RESEARCH COMPANY, INC.",R44,2001,359255,-0.014529095936257418
"KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY  The proposed work extends previous research performed by this                                                                     investigator in the field of knowledge-based systems for the analysis of             histopathologic material, mainly neoplastic tissue; and mostly focusing on           adenocarcinoma of the prostate. The present application concerns the creation        of methods for the definition and analysis of novel histopathologic features         predominantly derived from nuclear image data, with the objective of defining        ""prototype identities."" According to the investigator, these are fundamental         complexes of histologic features unique to individual tissue samples, or small       groups of such samples, that should convey useful predictive value for               individual patients. Many of these features are not normally discernable to the      eye, even to the experienced observer. They encompass a large number of primary      and derived nuclear morphometric measures, including what are referred to as         ""weak features,"" that is those that have not in the past shown strong                correlative utility by standard statistical measures. Derived measures include       feature and heterogeneity profiles. These data will form the inputs to a logic       network (""inference network"") designed to perform an identification process and      ultimately to generate the prototype identities.                                                                                                                          n/a",KNOWLEDGED BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6286183,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' human tissue', ' hyperplasia', ' image processing', ' information system analysis', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2001,465813,-0.03411358685880645
"Nosocomial infections: Automated typing and data mining   DESCRIPTION (provided by applicant): Nosocomial infections cause about 90,000        deaths annually in the U.S. and have an associated medical care cost of about        3.5 billion dollars. Despite being the fourth leading cause of death, there has      been limited development of rapid, integrated tools for determination of             outbreaks of hospital-acquired infections. The goal of the proposed research is      to test feasibility of development of software algorithms for identifying            clusters of bacteria involved in nosocomial infections. This will be                 accomplished by creation of new algorithms for clustering bacterial fatty acid       composition data to detect infection clusters and through the creation of a          ""data mining"" algorithm to provide patient demographic information needed to         distinguish nosocomial outbreaks from community-acquired infections or               pseudo-outbreaks. These software algorithms will be integrated into the MIDI         Sherlock Microbial Identification System as a fully automated real-time              epidemiology tool. Hospital infection-control personnel will be able to use the      output to immediately implement infection control measures, and thus to reduce       the impact of nosocomial infections.                                                  PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                             n/a",Nosocomial infections: Automated typing and data mining,6401774,R43AI050257,"['artificial intelligence', ' bacteria characteristic', ' bacterial proteins', ' biomedical automation', ' computer program /software', ' computer system design /evaluation', ' data management', ' fatty acids', ' information retrieval', ' microorganism classification', ' nosocomial infection control', ' nosocomial infections', ' patient /disease registry', ' tissue /cell culture']",NIAID,"MICROBIAL ID, INC.",R43,2001,97560,-0.012284277983001564
"AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION Quantification of Minimal Residual Disease (MRD) is a general concern in oncology since this parameter is likely to give valuable information to clinicians to customize chemotherapeutic treatments and to anticipate possible relapses. An automated system will be developed for the quantification of MRD by using real-time PCR to quantify cancer cells in a background of non pathologic DNA. The system will be derived from an existing high-throughput sample handling system (developed by Meldrum and team) named Acapella. Acapella has a pipelined serial architecture which makes it possible to develop an adaptive PCR control algorithm ensuring a level of sensitivity and accuracy for the quantification results specified by the clinician. In the R21 phase of the project, a critical component of the system is the real-time thermocycler. It will provide DNA quantification results of greater precision than what is currently possible with commercial instruments such as the ABI PRISM 7700 Sequence Detector by taking advantage of a high performance custom fluorescence analyzer and sophisticated data analysis methods. The fluorescence analyzer will have a signal to noise ratio and a dynamic range of at least one order of magnitude larger than the optics used on commercial systems. This unique feature will permit precise measurements of the amplification kinetics during at least five cycles in the exponential phase of the reaction. The amplification yield will he derived from these data using statistical estimators customized to meet the requirements of real-time PCR data analysis. The sample DNA content will be derived from the amplification yield and the calibrated fluorescence measurements of the reaction kinetics. This new approach will make it possible to run series of real-time PCRs with more flexibility than would be possible if the assay was based on standard reactions required to have the same amplification yield as the clinical samples. PCR conditions will be adapted online without concerns about possible differences of amplification rate. The assay control algorithm will adapt the reaction DNA content, the primer selection, and the number of PCRs to meet the clinician requirements for particular patient DNA. During the R21 phase of the project a prototype of the real-time thermocycler will be developed to demonstrate the optic performance and the possibility to estimate the PCR amplification rates with 5% accuracy. A conceptual design of the fully integrated process from patient blood sample to MRD quantification data will be completed to allow assessment of expected performance, cost, and risks associated with the development of the fully engineered system. The development of the various hardware and software components along with their integration into the automated system will take place during the R33 phase of the project. Performance of the system will he evaluated on real biological samples provided by the UW Department of Laboratory Medicine. Results returned by the system will he compared with results of t(14; 18) PCR performed in this department with an ABI PRISM 7700 for the diagnosis of patients suffering from follicular lymphomas.  n/a",AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION,6467733,R33CA084691,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosome translocation', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence', ' high throughput technology', ' human tissue', ' minimal residual disease', ' neoplasm /cancer diagnosis', "" nonHodgkin's lymphoma"", ' nucleic acid quantitation /detection', ' polymerase chain reaction']",NCI,UNIVERSITY OF WASHINGTON,R33,2001,607570,0.0069035415313369024
"MULTICHANNEL EEG DATA COMPRESSION Recently, recording high-resolution Electroencephalograms (EEGs) from            a large number of electrodes has become a clear trend in both brain              research and clinical diagnosis.  However, the current EEG data                  acquisition systems store the collected data in a form that has never            changed since digital EEG emerged about 30 years ago.  As a result, the          size of the output data file increases enormously as the number of               recording channels increases, causing various problems including high            costs in data analysis, database management, archiving, and transmission         through the internet.                                                                                                                                             This proposal seeks to solve this problem through fundamental research           on data compression specifically for EEG data, but applicable to other           physiological data as well.  Our key approach is based on the                    application of advanced mathematical and signal processing technologies          to this critical problem.  We will develop and optimize a variable               sampling technique which eliminates redundant data samples using spline          interpolation and wavelet transformation.  We will also investigate              lossless data compression algorithms that possess two important                  features: 1) any part of the data within the compressed file can be read         without having to decompress the entire file, and 2) the compressed data         can be transmitted and presented in coarse or fine resolutions as                needed.  We expect that, using both variable sampling and lossless               compression, the EEG file size can be reduced by approximately 70                percent.                                                                          n/a",MULTICHANNEL EEG DATA COMPRESSION,6363936,R01NS038494,"['Internet', ' artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' clinical biomedical equipment', ' clinical research', ' computer data analysis', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' digital imaging', ' electroencephalography', ' human data', ' human subject', ' informatics', ' technology /technique development']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2001,177776,-0.02309963288985617
"RULE DISCOVERY IN BODY CAVITY EFFUSIONS  DESCRIPTION (adapted from the Abstract):                                             Machine learning methods are innovative tools used to find patterns in medical       data.  Laboratory data is suited to computerized Interpretation because of its       objective, quantitative nature.  Body fluid analysis is a good model for             evaluating machine learning in the laboratory.  Pathologists spend a                 substantial amount of time analyzing and classifying body fluids, or                 effusions, which are abnormal accumulations of fluid within body cavities of         human beings and animals, caused by diseases such as congestive heart failure.       Fluid classification provides clinicians with important diagnostic information       about the underlying disease process.  Automation of body fluid analysis by a        machine learning system would substantially increase the efficiency and              profitability of a medical laboratory.  In a pilot study, RIPPER (Repeated           Incremental Pruning to Produce Error Reduction), a rule discovery tool,              accurately classified effusions from animals into five standard categories,          based on the physical, chemical, and cellular characteristics of the fluid.          The purposes of this study are: 1) to determine the accuracy of RIPPER on a          larger data set, to expand and strengthen the results of the pilot; 2) to test       the accuracy of RIPPER's fluid classifications prospectively in a large              veterinary teaching hospital laboratory, 3) to determine the acceptance rate         or reason for rejection of RIPPER's classification by clinical pathologists;         and (4) to use RIPPER to discover novel rules for classifying effusions by           underlying disease process.                                                                                                                                               The results of this study will validate and test the acceptance of a machine         learning system applicable to fluid analysis in both human and veterinary            clinical laboratories.  By discovering new patterns in quantitative data that        identify the specific underlying disease, RIPPER can greatly enhance the             diagnostic value of laboratory analysis.                                                                                                                                  n/a",RULE DISCOVERY IN BODY CAVITY EFFUSIONS,6467346,F32LM000095,"['body fluids', ' classification', ' computer assisted instruction', ' programmed instruction', ' veterinary science']",NLM,UNIVERSITY OF CALIFORNIA DAVIS,F32,2001,52501,-0.02207308872319011
"ACTUARIAL STRATEGIES IN CHILD DIAGNOSTIC ASSESSMENT  The proposed project involves a preliminary investigation of                                                                                   potentially significant methodological advance in diagnostic assessment. The         current state-of-the-art in diagnostic assessment involves the use of a              structured interview. Typically, structured interviews involve a static skip         structure, i.e., some portions of the interview are administered conditional on                                 particular responses to prior questions. For example, if there is a negative         response to a question about depression and anhedonia, most structured               interviews require the clinical to skip the remaining questions about                associated symptoms (e.g., sleep disturbance, impaired concentration, etc.).         Although structured interviews represent an enormous advantage over earlier          diagnostic procedures, their inflexible structure is often incompatible with         the heterogeneity of most child and adolescent populations, and can result in        superfluous questioning about uncommon disorders and insufficient follow-up          about more common ones. Many interviews do not make exceptions for individual        characteristics. For example, 1) a 17 year old boy might need to answer ""no"" to      5 or 6 questions about separation anxiety before the interviewer may move on to      another set of questions; or 2) an underweight 16 year old girl might not be         asked important follow-up questions when replying ""no"" to the initial question       about eating disorders. One might conclude that introducing more clinician           flexibility would be the solution; however, the literature on clinical judgment      suggests that increasing clinician involvement in determination of interview         structure would likely degrade classification accuracy and introduce unwanted        sources of error and bias. To address this issue in another manner, the              principal investigator has developed a data-driven, actuarial expert system to       guide a flexible interview structure. Thus, interview structure is dynamically       responsive to individual characteristics, without introducing error associated       with qualitative clinical judgments. Pilot modeling revealed that his system         offers advantages in classification accuracy over state-of-the-art diagnostic        approaches, with the additional benefit of reducing administration time for          particular disorders. The current project is planned to generate requisite data      to develop a formal expert system and to forecast its relative accuracy and          efficiency in a child and adolescent population. It is predicted that this           system will demonstrate improvements in classification accuracy over a static        structured interview approach, with reduced administration time. If the data         are supportive, these developments have the potential to significantly advance       the manner in which future diagnostic interviews are conducted with mental           health populations.                                                                                                                                                       n/a",ACTUARIAL STRATEGIES IN CHILD DIAGNOSTIC ASSESSMENT,6392530,R03MH060134,"['adolescence (12-20)', ' anxiety', ' artificial intelligence', ' behavior test', ' behavioral /social science research tag', ' child (0-11)', ' child behavior disorders', ' child psychology', ' clinical research', ' computer assisted diagnosis', ' data collection methodology /evaluation', ' depression', ' diagnosis design /evaluation', ' human subject', ' interview', ' mathematical model', ' mental disorder diagnosis', ' model design /development', ' mood disorders', ' psychometrics', ' questionnaires']",NIMH,UNIVERSITY OF HAWAII AT MANOA,R03,2001,60756,-0.021819701186541033
"IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION Colorectal carcinoma is the second leading cause of cancer deaths in the         United States today.  In an effort to reduce mortality, Congress                 recently included a provision in the Balanced Budget Act of 1997 to              support screening colonoscopy as a means for early detection and removal         of colorectal polyps, the precursors to cancer.  In this country alone,          more than 68 million people are eligible for colorectal screening, but           the majority are unlikely to comply with screening recommendations               because of the costs, risks, discomfort, and inconvenience associated            with traditional endoscopy.  Furthermore, even if a small fraction of            eligible persons are examined, the number of available                           gastroenterologists would be insufficient to perform so many procedures.                                                                                          We have developed a new technique, called virtual colonoscopy (VC), as           an alternative to screening diagnostic colonoscopy (DC). The procedure           consists of cleansing a patient's colon, inflating the colon with air,           scanning the abdomen with helical computed tomography (CT), and                  generating a rapid sequence of three-dimensional (3D) images of the              colon by means of virtual reality computer technology.  Although VC              makes possible the visualization of 3D images of the colon in a manner           similar to that of DC, a correct diagnosis depends upon a physician's            ability to identify small and sometimes subtle polyps within hundreds            of 3D images.  The absence of visual cues that normally occur with DC            makes VC interpretation tedious and susceptible to error.                                                                                                         With support from a National Science Foundation (NSF) grant, we have             developed a computer-assisted polyp detection (CAPD) system that                 calculates areas of abnormal colon wall thickness in helical CT image            data in order to highlight potential polyps in the 3D images.  A                 physician ultimately determines if each detected lesion represents a             true abnormality.  Although we have found CAPD to be sensitive for               finding subtle abnormalities, poor specificity can be attributed to              several obstacles, including imprecise image segmentation, limited               feature analysis, and suboptimal bowel preparation prior to helical CT           scanning.  With these challenges in mind, we propose research to perfect         CAPD. Our specific aims are as follows: 1. To develop an image                   segmentation algorithm that accurately isolates the colon from helical           CT image data; 2. To improve our polyp detection algorithm with expanded         feature analysis and artificial intelligence methods; 3. To optimize             bowel preparation with digital subtraction of opacified feces and                controlled gas distention; and 4. To validate the accuracy of VC, with           the modifications achieved in the stated aims, by comparing the results          of VC and DC in 200 patients undergoing usual-care colonoscopy.                                                                                                   If VC with CAPD proves accurate and efficient in the diagnosis of                colorectal polyps, it could evolve into a simple laboratory test,                thereby meeting the demand for worldwide colorectal cancer screening.             n/a",IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION,6376842,R01CA078485,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical research', ' colon neoplasms', ' colon polyp', ' computed axial tomography', ' computer assisted diagnosis', ' computer simulation', ' diagnosis design /evaluation', ' endoscopy', ' gastrointestinal imaging /visualization', ' human subject', ' image enhancement', ' mathematical model', ' model design /development', ' neoplasm /cancer diagnosis']",NCI,WAKE FOREST UNIVERSITY,R01,2001,607399,-0.05591273081929797
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6404288,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2001,673495,-0.05302234469684174
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6286594,U01DE013331,"['biomarker', ' biopsy', ' clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' enzyme linked immunosorbent assay', ' facial muscles', ' gas chromatography mass spectrometry', ' human subject', ' inflammation', ' interview', ' magnetic resonance imaging', ' mastication', ' musculoskeletal disorder diagnosis', ' oral facial pain', ' pain threshold', ' psychobiology', ' questionnaires', ' radioimmunoassay', ' sign /symptom', ' statistics /biometry', ' synovial fluid', ' temporomandibular joint syndrome', ' tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2001,1222618,-0.006583128058954038
"INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE This application is a request for support of the July 2001 meeting on Information Processing in Medical Imaging (IPMI'01) to be held on the campus of the University of California, Davis. During 16 previous meetings, this biennial workshop-style conference has traditionally concentrated on the latest advancements in the acquisition, processing, analysis, display, and perception of medical images. At the 2001 meeting, we intend to continue this tradition while encouraging contributions from young investigators, specifically advanced graduate students, postdoctoral fellows, and junior faculty. The emphasis is on applied mathematical techniques in computer vision, microimaging techniques, and information technology. Advances reported at this meeting are especially important in the study of neurological disorders, cardiovascular disease and cancer, although applications in the area of functional genomics, orthopedics and soft tissue biomechanics are also represented. The conference attracts researchers from a broad range of disciplines, particularly computer scientists, neuroscientists, electrical engineers, cardiologists, mathematicians, oncologists, and physicists. All share an interest in improving the quality of health care through the extraction and presentation of diagnostic information from medical image data. Approximately 130 individuals will be invited to attend; there will be approximately 25-30 speakers and 25-30 poster presentations. Papers are accepted based on peer review by a 25 member scientific committee of 15-20 page manuscripts. Selected papers will be published in proceedings that will be available at the conference.  n/a",INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE,6231502,R13RR015416,"['bioimaging /biomedical imaging', ' biomechanics', ' cardiovascular disorder', ' computer data analysis', ' diagnosis design /evaluation', ' functional /structural genomics', ' image processing', ' informatics', ' mathematics', ' meeting /conference /symposium', ' neoplasm /cancer', ' nervous system disorder', ' orthopedics']",NCRR,UNIVERSITY OF CALIFORNIA DAVIS,R13,2001,5000,-0.012227063377460691
"RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION The goal of the proposed research is to develop and test a computational theory for the human ability to recognize objects under variable illumination (including extreme shadowing) and viewpoint changes. The ability to recognize objects is of fundamental importance in everyday life and the loss of this ability, due to a stroke or Alzheimer's disease, is a serious handicap to the person involved. The computational theory is based on a new paradigm for object representation --generative modeling - - in which an image-based model of an object is ""generated"" from a small set of training images. This theory has been demonstrated to successfully recognize objects from real images under extreme lighting variations. This gives a reality check on the theory and can be thought of as making it an ecological theory (in the sense that it yields good results on the types of images that humans encounter in the real world and not just on the visual stimuli occurring in laboratories). We have assembled a team of researchers with interdisciplinary skills in computer and biological vision. who will divide their efforts on the project based on their expertise. It is our explicit intent that the algorithms and psychophysical studies develop in tandem, with each group verifying the other's results. Indeed, as reviewed below, the computer vision theory, when applied to human performance, makes a number of predictions. some of which have already been partially confirmed by our preliminary experimental work. Our proposal is organized into three main areas. The psychophysical work parallels the computational issues in three series of experiments in which we investigate: (I) How human observers learn and recognize objects, given variable lighting conditions, from a single fixed viewpoint. (II) How illumination and viewpoint interact in human object recognition. (III) The role of class-specific knowledge in recognition.  n/a",RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION,6384831,R01EY012691,"['computer simulation', ' form /pattern perception', ' human subject', ' light intensity', ' psychophysics', ' visual perception']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2001,356485,-0.0398648736401354
"METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES DESCRIPTION (Adapted from Applicant's Abstract):  The aim of this proposal       is to further develop and validate algorithms for analysis of SPAMM MR           cardiac images based on novel spline methods.  MRI is unique in its ability      to non-invasively and selectively alter tissue magnetization, and create         tagged patterns within the deforming tissue such as the heart muscle.  The       resulting pattern defines a time-varying curvilinear coordinate system on        the underlying tissue, allowing for precise and quantitative measurement of      tissue motion and deformation.  The investigators are developing two             frameworks for analysis of SPAMM tagged images, both of these aimed at           providing a more automated and reproducible approach to analysis of SPAMM        data, as well as providing dense 3-D displacement information at all points      within the LV myocardium.  The investigators propose to (a) further develop      and extend our analyses techniques.  The extensions considered will all be       related and based on currently developed computer vision-based techniques        for regional LV wall motion analysis, that operates either on a sequence of      SA slice stacks or on a time sequence of single slice.  (b) The                  investigators will validate the motion tracking methods by comparing ""true""      and algorithm-estimated motion trajectories:  1) on dense field of points        derived from 3-D tagged computer models of objects that simulate the moving      LV, 2) on dense field of points derived from Finite Element Model                simulations of the constitutive equations of LV deformations (once again tag     planes will be superimposed on the time course of simulated geometries), 3)      on selected points in the LV myocardium of the in vivo heart using a porcine     model.  Here, ""true"" motion will be determined by tracking implanted image       distinguishable markers.  (c) The investigators will test whether regions of     postmortem myocardial injury imply similar-sized and locate regions of           altered deformations (as measured by parameters developed in (a)).  The          algorithm-derived LV function assessment based on the analysis of in vivo        tagged MRI sequences will be compared with postmortem myocardial injury          assessment determined by myocardial staining techniques.  The validated          parameters will also be use to examine the time-course of change in the          ischemic areas of the chronic animal models.                                      n/a",METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES,6389619,R01HL057628,"['bioimaging /biomedical imaging', ' cardiography', ' clinical research', ' computer data analysis', ' computer simulation', ' diagnosis design /evaluation', ' heart motion', ' histopathology', ' human subject', ' image processing', ' magnetic resonance imaging', ' myocardial ischemia /hypoxia', ' swine']",NHLBI,BARNES-JEWISH HOSPITAL,R01,2001,122402,-0.037101490422922705
"SIGN FINDER: COMPUTER VISION TO FIND AND READ SIGNS In this Phase l proposal we plan to develop and test a new vision technology to locat and read general informational signs (street names, building directories, office door plates) and location and directional signs (EXIT, Information, aisle signs in supermarkets). To strengthen feasibility, we will target a restricted class of signs: those consisting primarily of one- color text on a different one-color background, and whose shape falls within a prescribed set. The intended market is for people who are blind or whose sight is impaired and hence cannot read these signs unaided. Our approach makes extensive use of recently developed computer vision recognition algorithms. We also make use of the Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for determining what the potential users will require from such a system. The ultimate goal, for Phase II, is to build and test a highly portable PC- based device implementing this vision technology using a CCD camera as input and a voice-generator as output. The user would scan/point the device at a scene and it would locate and read one or more signs. Given the pace of increase in power and decrease in size of computing devices, a hand-held Sign-Finder system may be plausible to build entirely with commercial, off-the-shelf hardware in two to three years. PROPOSED COMMERCIAL APPLICATION: The potential utility to blind and visually impaired individuals is great; a commercial product could have a market potential of 500,000.  n/a",SIGN FINDER: COMPUTER VISION TO FIND AND READ SIGNS,2720318,R43EY011821,"['artificial intelligence', ' blind aid', ' charge coupled device camera', ' computer graphics /printing', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' information display', ' portable biomedical equipment', ' symbolism', ' technology /technique development', ' vision aid']",NEI,BLINDSIGHT CORPORATION,R43,2000,100000,0.000292550538853837
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6054979,R24HD038585,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biological signal transduction', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' electromyography', ' evaluation /testing', ' human subject', ' motor neurons', ' neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2000,593340,-0.04028588234762947
"ADVANCED DIAGNOSTIC LOGIC FOR PSYCHIATRY   DESCRIPTION: (Verbatim from the Applicant's Abstract): This Phase I project          proposes to assess the feasibility of an advanced diagnostic logic system            (Diagnostica) to support the clinical assessment process for diagnosis in            psychiatry. A working prototype of the diagnostic rules in the American              Psychiatric Association Diagnostic and Statistical Manual (DSM-IV) uses and          artificial intelligence engine (""XSB"") to implement the logic of DSM-IV along        with and an interactive graphical user interface to allow a user to add              information and understand conclusions reached by the system. The Phase I            programming objectives are to make Diagnostica ready for commercial use by           improving its graphical user interface, and finalizing implementation of its         logical rules. The resulting system will be a practical tool in clinical             settings, and relies on computer science innovations that have preciously            neither been explored nor applied in the domain of medical reasoning. With the       emergence of decision support systems, the need for better quality diagnostic        information is becoming increasingly apparent. This has been due, in part, to        the complexity of diagnostic processes and the emphasis on support of financial      processes. Within mental health, the DSM-IV provides both a model and a              standard for making diagnoses. A software component that provides flexible,          complete, and efficient application of this standard is of great value. The          innovation of Diagnostica relies on the sophistication of its modeling of            DSM-IV rules, and it's flexibility in applying those rules. Diagnostica will         automatically track the status of the information entered and allow users to         tie up 'loose ends' in documenting the proof of diagnoses formally. AS example,      the user may indicate that a set of diagnoses in 'believed true' without             specifying the symptoms needed to make the diagnoses formally ( a procedure          used routinely in clinical practice). the application will track whatever            'residual' data this is necessary in order to complete formal diagnoses, while       leaving the option of when, or if, to complete the process up to the user.                                                                                                Phase II objectives include: (1) extending Diagnostica to provide other              software applications needing diagnostic decision support services, and              specifically to link Diagnostica to the World Health Organization Schedules for      Clinical Assessment in Neuropsychiatry (SCAN); (2) addressing logical modeling       of time and creating an effective user interface for repeated assessment; (3)        incorporating probabilistic information about sets of symptoms based on              empirical information initially obtained in Phase I; and (4) developing and          testing ""belief revision"" functions to changes in knowledge stemming from            repeated clinical assessment.                                                        PROPOSED COMMERCIAL APPLICATION:                                                                                     Computerization of diagnostic logic for clinical use can improve the quality of      mental health services by efficient standardization of assessment and through        motivating and making more practical the creation of data bases which can be         used for clinical quality improvement and knowledge discovery.                                                                                                            n/a",ADVANCED DIAGNOSTIC LOGIC FOR PSYCHIATRY,6210194,R43MH059420,"['artificial intelligence', ' computer assisted diagnosis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' interactive multimedia', ' mental disorder diagnosis', ' psychiatry']",NIMH,"MEDICINE RULES, INC.",R43,2000,98441,0.0045965214749714755
"COMPUTER VISION ANALYSIS OF DYNAMIC FACIAL BEHAVIOR DESCRIPTION (Applicant's abstract): Facial expressions provide an important behavioral measure for the study of emotion, cognitive processes, and social interaction, and contain diagnostic information for neurological disorders and depression. Facial expression measurement from video is less intrusive than EEG, EMO, ANS or brain imaging measurements as an indicator of emotional activity. The measurement is presently performed by human experts. The goal of this research is to develop an automatic system for recognition, measurement, and coding of facial expressions from video using computer vision technology. This project will utilize probabilistic models of dynamical systems to mod& the facial behavior underlying the observed image sequences. These techniques include hidden Markov models, and a new stochastic modeling technique developed by Movellan and colleagues called diffusion networks [38]. Diffusion networks offer the advantage over traditional dynamical models of allowing continuous time dynamics and continuous states. An automated system would make facial expression measurement more widely accessible as a research tool in behavioral science and investigations of the neural substrates of emotion.  n/a",COMPUTER VISION ANALYSIS OF DYNAMIC FACIAL BEHAVIOR,6185479,F32MH012417,"['behavior test', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' clinical research', ' cognition', ' computer assisted diagnosis', ' depression', ' emotions', ' face expression', ' human subject', ' image processing', ' mathematical model', ' social integration']",NIMH,UNIVERSITY OF CALIFORNIA SAN DIEGO,F32,2000,37516,-0.009121690720187302
"NEW ROC METHODOLOGY TO ASSESS DIAGNOSTIC ACCURACY DESCRIPTION (Adapted from Applicant's Abstract):  Receiver Operating             Characteristic (ROC) analysis is recognized widely as the best way of            measuring and specifying the accuracies of diagnostic procedures, because it     is able to distinguish between actual differences in discrimination              capacity, on one hand, and apparent differences that are due only to             decision-threshold effects, on the other.  Key methodological needs remain       to be satisfied before ROC analysis can address all of the practically           important situations that arise in diagnostic applications, however.  This       project employs signal detection theory and computer simulation to address       several of those needs, by:  (1) refining and continuing distribution of         software developed previously by the applicants for fitting ROC curves and       for testing the statistical significance of differences between ROC curve        estimates; (2) developing and evaluating new algorithms for ROC                  curve-Fitting and statistical testing, based on their recently-developed         ""proper"" binormal model, that should provide more meaningful results in          experimental situations that involve small samples of cases; (3)                 investigating the usefulness of a form of ROC methodology that is based on       mixture distributions in order to rduce the need for diagnostic truth in ROC     experiments; (4) investigating the effect of case-saple difficulty on the        statistical power tests for differences between ROC curves, in order to          determine the optimal difficulty of cases that shouldbe studied on rank          diagnostic systems; and (5) developing methods for training artificial           neural networks (ANNs) to maximize diagnostic accuracy in terms of ROC           analysis and signal detection theory.                                             n/a",NEW ROC METHODOLOGY TO ASSESS DIAGNOSTIC ACCURACY,6181168,R01GM057622,"['artificial intelligence', ' computer assisted diagnosis', ' computer system design /evaluation', ' method development', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R01,2000,218176,-0.010401056597641862
"IMPROVED COLLIMATION FOR PIXELATED RADIATION DETECTORS   DESCRIPTION: The investigators propose to test the feasibility of developing         improved collimators for use with higher performance pixelated detectors under       development for use in gamma cameras now under development, as further               described by their abstract:                                                                                                                                              ""In nuclear medicine, the collimator plays a critical role in the formation of       a projection image of the radiopharmaceutical distribution within a patient.         The current state-of-the-art of collimator design for Nuclear Medicine has           matured, under the assumption that gamma-ray detectors have an intrinsic             position dependant Gaussian response function. A fundamental rethinking of           collimator design is necessary to optimize collimation for solid state               detectors that have a fixed intrinsic rect function response. We will construct      design tools by first developing a mathematical model of collimation for             detectors with intrinsic pixels and then implement it by computer algorithms.        We will conduct experiments to measure performance and validate the simulation       tools. Using the validated simulator we will then explore novel collimator           designs and hole patterns. We will examine all proposed designs for                  sensitivity, resolution, cost and manufacture. To advance clinical                   applications, collimator design will need to keep pace with the anticipated          improvements in detector technology. Phase II brings a production prototype of       the new collimator design to laboratory and clinical testing.""  PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                                          n/a",IMPROVED COLLIMATION FOR PIXELATED RADIATION DETECTORS,6071510,R41RR013519,"['artificial intelligence', ' biomedical equipment development', ' mathematical model', ' model design /development', ' nuclear medicine', ' radiation detector', ' scintillation cameras']",NCRR,MOSAIC IMAGING TECHNOLOGY,R41,2000,137074,0.002995037079974555
"ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR Imaging detectors for 10 to 150 keV photons have many uses in medical technology, including tumor imaging, SPECT, and radiography. Digital output is particularly useful since it allows image enhancement, analysis, transmission and storage. In Phase I we proposed a new technology that could capture images with 100 microm spatial resolution and 1 keV energy resolution or better. This capability would facilitate entirely new classes of medical diagnostic procedures, particularly for transgenic small animal imaging. Our Phase I work demonstrated the feasibility of this approach. In this Phase II effort, collaborating with Paul Luke at LBNL, we will construct 1 cm thick crossed-strip HPGe detectors having 10 x 10 strips, each 2 mm x 20 mm. We will develop cooled FET preamplifiers having low noise and large bandwidth properties specifically required by this approach. We will also develop analog filtering electronics to condition the detector's novel signals and employ digital pulse processing electronics to acquire these signals at rates up to 10/6 cps. Finally, we will devise procedures to test the detector's linearity and develop processing algorithms to perfect this quality. Phase II will conclude with a working and tested prototype. Phase III will entail primarily production engineering efforts. PROPOSED COMMERCIAL APPLICATION: As an energy resolved digital detector with 100 microm spatial resolution, the proposed detector technology could find many medical applications, including SPECT, energy resolved angiography for small mammals, bone densitometry on rodent bones, and small, hand-held gamma cameras. Non-medical applications would include non-destructive testing, astrophysical gamma imaging, nuclear cleanup uses, and x-ray diffraction detectors.  n/a",ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR,6211037,R44CA075844,"['X ray', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R44,2000,416478,-0.023309271658753097
"KNOWLEDGE BASES FOR STRUCTURED CARDIOVASCULAR REPORTING Healthcare has lagged behind other industries in automating the storage and retrieval of information. While billing, blood testing, and other services are widely computerized, the bulk of patient clinical information is not. The central barrier to coding clinically useful data - patient historical, test, and procedural results - is the absence of effective knowledge frameworks for entry and review of clinical data. For this reason, sofiware for storage and retrieval of patient data remains suboptimal. This project focuses on methods for recording a specific subset of patient data: results of cardiovascular tests, Although only a subset of clinical knowledge, cardiovascular procedure reporting is typical of the larger problem of how knowledge is handled. Moreover, there is an unmet market demand for cardiology reportrng tools. In Phase I we will develop a methodology for creating and maintaining the knowledge bases needed for structured entry of cardiovascular data. We will apply and hone this methodology by creating two important knowledge bases: echocardiography and cardiac catheterization. Together with the methodology we use, these two developments will dovetail into a larger Phase II  project of systematically addressing knowledge-representation and structured data entry for cardiology. Beyond Phase II  we will apply our methodology to other branches of medicine. PROPOSED COMMERCIAL APPLICATION: This research will provide a means to optimize structured recording of patient test results in a computer-searchable format improving the process of procedural reporting, and facilitating implementation of an electronic medical record.  n/a",KNOWLEDGE BASES FOR STRUCTURED CARDIOVASCULAR REPORTING,6141030,R43HL062806,"['artificial intelligence', ' cardiovascular disorder diagnosis', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' echocardiography', ' heart catheterization', ' human data', ' informatics']",NHLBI,"CYBERPULSE, LLC",R43,2000,107000,-0.026323320736798404
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6210821,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2000,395990,-0.009939780380044604
"CLINICAL RESEARCH TOWARD CLOSED LOOP INSULIN DELIVERY DESCRIPTION (Adapted from applicant's abstract): The ""closed-loop                artificial pancreas,"" a device that would measure glucose level and              deliver insulin automatically as needed, has been an elusive goal in the         treatment of diabetes. There are three essential components: the blood           glucose sensor, linking algorithms and the delivery system. For the first        time, a viable sensor and a proven delivery system are now available for         research. The broad goal of this clinical research proposal is to complete       the studies needed to link the sensor to the delivery system, paving the         way for a functional closed-loop artificial pancreas. First, we will make        a detailed analysis of sensor signal as it reflects glucose level in             normal and diabetic humans. Second, we will study the precise                    pharmacokinetics of insulin delivery by external and implantable insulin         pumps. Third, analysis of these two data sets will provide the basis for         algorithms that link the sensor signal to insulin delivery. A formal             safety analysis will evaluate the safety features needed in a closed loop        device. In the last year of the project, the entire system will be tested        and fine-tuned. This project takes advantage of our relatively extensive         investigational experience with mechanical insulin delivery pumps in             people with diabetes, and the recent availability, for research, of a            subcutaneously placed, glucose oxidase-based continuous glucose sensor.          The investigators have established experienced with clinical research in         diabetes, and the resources of an excellent General Clinical Research            Center. The co-investigators have extensive experience with mathematical         modeling of biologic systems. There is a close working relationship              between the research team and the manufacturer of the sensor and pumps, as       reflected by the Interactive Research Project Grant collaboration, and by        a long-standing history of collaboration. It is essential to emphasize           that we do not anticipate completion of a manufacturable, clinically             usable, commercially viable artificial pancreas within the time-frame of         this work. Rather, we aim to complete the basic studies and modeling             analyses that would form the basis of such a system, and demonstrate the         feasibility of linking the sensor to the delivery device. If these studies       and these trials were successful, they would be a major step towards             development of a clinically useful close-loop artificial pancreas.                n/a",CLINICAL RESEARCH TOWARD CLOSED LOOP INSULIN DELIVERY,6177804,R01DK055132,"['artificial endocrine pancreas', ' artificial intelligence', ' biosensor device', ' clinical research', ' drug delivery systems', ' glucose metabolism', ' human subject', ' insulin', ' insulin dependent diabetes mellitus', ' medical implant science', ' pharmacokinetics']",NIDDK,JOHNS HOPKINS UNIVERSITY,R01,2000,252566,-0.015593173377061342
"CLUSTERING AND HYPER-LINKING OF LONG-TERM EEGS The proposed work offers enhancements to the MagicMarker software developed in Phase I.  This software offers a new methodology for the display and analysis of long-term EEG records.  Epochs of similar activity are grouped into segments and then states via two-pass hierarchial clustering.  This results in clearly differentiated background, paroxysmal activity and patient state transitions.  The underlying EEG  is always available via hyper- links so that artifacts can be distinguished from ""real EEG."" The Phase II work adds classification abilities (intelligence) to the Phase I software.  Proposed are an expert-level seizure detector, an ICU abnormality detector and a user-defined activity detector.  The effort includes the development of a large library of carefully analyzed and annotated prolonged EEG studies. Newborns, older children and adults will be included ensuring robust algorithms for all age groups. The proposed software greatly reduces staff requirements for long-term monitoring through intelligent notification (visual, audible and dial-up pager) of interesting events.  This, in addition to the ability to monitor patients ""away from the lab,"" provides more frequent patient checks and improved clinical outcomes. PROPOSED COMMERCIAL APPLICATION The proposed software would be a valuable addition to any digital EEG because of the great timesavings it provides for both neurologists and EEG technicians.  The software will be marketed along with current Persyst products (Insight, SpikeDetector and Prism), which support and are sold by virtually every major DEEG manufacturer.  n/a",CLUSTERING AND HYPER-LINKING OF LONG-TERM EEGS,6186323,R44MH055895,"['Internet', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' electroencephalography', ' generalized seizures', ' human data', ' image processing', ' intensive care']",NIMH,PERSYST DEVELOPMENT CORPORATION,R44,2000,352280,-0.008186286161653416
"WAVELET-BASED AUTOMATED CHROMOSOME IDENTIFICATION Commercial automated karyotyping instruments have improved to the point where the major factor limiting throughput is the time required for operator correction of chromosome classification errors. An improvement in chromosome classification accuracy would significantly increase the value of these instruments in cytogenetics labs. The goal of this project is to develop and commercialize significantly improved chromosome measurement and classification techniques for automated karyotyping. Currently the best-performing chromosome classification approach uses Weighted Density Distribution (WDD) features [11] to quantify the banding pattern of the chromosomes. These are computed as inner products between the banding profile and a set of WDD basis functions. The particular set of 1unctions originally proposed by Granum [11,38] has come into widespread use. In Phase I we showed that better function sets exist and that our new approach can find better WDD features than the best currently used. We have an innovative wavelet-based method for generating WDD functions and a chromosome classification testbed which supports large scale classification experiments. We propose to conduct a thorough, methodical search for better performing basis functions in Phase II. Phase III will incorporate the technology into PSI's PowerGene automated karyotyping instruments. PROPOSED COMMERCIAL APPLICATIONS: When the new chromosome classification technology is qualified for routine application, it will be incorporated into PSI's Powergene products, both in new systems sold and as an upgrade to existing systems.  n/a",WAVELET-BASED AUTOMATED CHROMOSOME IDENTIFICATION,6173267,R44CA076896,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosomes', ' computer program /software', ' cytogenetics', ' density', ' genetic mapping', ' genetic techniques', ' human genetic material tag', ' human tissue', ' image processing']",NCI,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2000,366807,0.005245905141344447
"MICRO-OPTICS-BASED DIGITAL ALLERGEN COUNTER The current pollen identification and counting method based on microscopic visual examination is very time consuming and labor intensive. More importantly, it is very ""subjective"" and not truly scientific. Intelligent Optical Systems, Inc. proposes to develop a portable digital allergen counter (DAC) to accurately and reliably count and identify airborne pollen grains and fungal spores. The proposed DAC combines a micro-image scanner, a high-speed video chip, an allergen morphology data bank, and a built-in image processor into an integrated and automated pollen counter. The DAC will rapidly identify and quantify pollen, grains and spores. By making it much easier to collect allergen information in multiple locations, the proposed device will reduce morbidity by providing improved warnings on days with high pollen counts. The specific aims of the Phase I project are to design and construct optical image scanner suitable for allergen detection, identify the morphology of several types of pollen, grains, and spores, integrate the DAC system and test and evaluate the system feasibility. In Phase II, an engineering prototype of a portable instrument will be built and field-validated with real-world samples. We will also expand its capability to increase the pollen types of interest. PROPOSED COMMERCIAL APPLICATIONS: A compact, simple, and easy-to-use digital allergen counting system that can monitor indoor or outdoor air quality that will minimize people's overexposure to allergens.  This device is for aerobiological research that could be beneficial for public health, medical pharmaceutical and engineering applications. Universities, physicians, public health organizations, National Allergy Bureau (NAB) stations, and private air sampling consultants will  purchase the device.  n/a",MICRO-OPTICS-BASED DIGITAL ALLERGEN COUNTER,6211164,R43HL064459,"['air sampling /monitoring', ' allergens', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' computer program /software', ' computer system design /evaluation', ' image processing', ' monitoring device', ' optics', ' particle counter', ' pollen']",NHLBI,"INTELLIGENT OPTICAL SYSTEMS, INC.",R43,2000,99995,0.010682122692064786
"PERMUTATION TEST SOFTWARE FOR RANDOMIZED CLINICAL TRIALS The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of a randomized clinical trial are almost always analyzed using some form of statistical hypothesis test. Most hypothesis tests used for analyzing clinical trials assume a population model for statistical inference, when in fact a randomization model is more consistent with the way randomized clinical trials are actually conducted. Failure to consider the randomization model when analyzing clinical trials can lead to effective drugs being declared ineffective, and ineffective drugs being declared effective. In order to analyze clinical trials in accordance with the randomization model, sophisticated software for conducting permutation tests is needed. The overall goal of this research is to develop flexible and robust software, usable by statisticians or other medical data analysts, for conducting permutation tests for single- or multi-clinic randomized clinical trials. The ongoing advances in computing technology have created a favorable climate for development of software for conducting permutation tests. This project includes a collaboration with Dr. Rosenberger of the University of Maryland, Baltimore County who is a recognized expert on randomization based inference and adaptive designs. PROPOSED COMMERCIAL APPLICATIONS: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid.  n/a",PERMUTATION TEST SOFTWARE FOR RANDOMIZED CLINICAL TRIALS,6141347,R43CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R43,2000,98172,-0.009698745628844424
"IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY DESCRIPTION:  The research and development of teleradiology and telemedicine     systems has progressed through many technical and clinical endeavors.  When      dealing with large volume image transmission and storage, image data             compression is an outstanding issue in medical applications to which current     techniques were not designed to address.  The technical objectives of this       project are to develop optimized error-free as well as error-controllable        methods for medical image compression based on wavelet transform and             associated methods.  In this project, we employ both advanced artificial         intelligent and compression techniques to achieve these goals.                                                                                                    Our recent research outcomes include:  (a) development of a mathematics          approach to unify prediction, subband, and wavelet transforms, (b)               development of convolution neural network training methods to obtain             optimized wavelet kernel, (c) development of a data splitting technique to       improve edge accuracy and to provide error-control methods, and (d)              development of an integer implementation method for all wavelet transforms,      etc.  Based on the above technical advances, we propose to use integer form      of an adaptive (optimized) wavelets in conjunction with newly developed          coding methods such as ""partitioning in hierarchical trees"" (PHT) for            lossless compression.  For error-controllable approaches, we propose to use      adaptive wavelets coupled with optimized neural network prediction methods       in this study.  Since lossless compression is a part of the error -              controllable method, both systems can be implemented in the same scheme          which is a breakthrough approach in the field.  We will compare the              compression results (i.e., compression ratio and speed) of the proposed          compression methods with those of the current wavelet techniques using the       embedded zero-tree coding method.  At the end of the project, we will            deliver a software package for the radiological society.  Hence, the             evaluation for various clinical applications using the proposed methods can      be performed by the investigators.                                                                                                                                As the field of telemedicine is rapidly growing, we believe that development     of a dedicated compression module for economical storage and fast                communication of patient data (particularly for patient images) is               necessary.  This project is designed to address the related technical issues     with a strong clinical consideration.                                             n/a",IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY,6173899,R01CA079139,"['artificial intelligence', ' bioimaging /biomedical imaging', ' charge coupled device camera', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' human data', ' image processing', ' radiology', ' telemedicine']",NCI,GEORGETOWN UNIVERSITY,R01,2000,176034,-0.0038738104045048416
"DEVELOPMENT OF A KNOWLEDGE-BASED IMAGE REPORTING SYSTEM We have constructed a prototype structured reporting system that replaces conventional dictation and transcription for medical image reporting. Key design features include reporting speed, generation of graphical reports, structured storage of imaging findings, and the use of existing lexicons. Pilot timing data suggest that a radiologist using our system can generate a report more rapidly than with conventional reporting methods or speech recognition systems. Support is sought to refine the prototype, and to conduct feasibility testing. The specific aims are (1) to augment and refine a hierarchical test lexicon of imaging terms (2) to develop methods for the representation and reporting of imaging findings and their logical relationships, (3) to evaluate the system's performance on clinical imaging reports, and (4) to assess the completeness of existing lexicons for imaging. The project is supported by a Technical Advisory Committee comprised of experts in key methodological areas. A successful Phase I will lead (in Phase II) to testing of the approach for cross-sectional imaging, to adoption, augmentation, and use of an existing lexicon, to construction of real-time decision support techniques based on the knowledge base of imaging findings generated by the system, and to system evaluation in a clinical setting. PROPOSED COMMERCIAL APPLICATIONS: Our structured reporting system is appealing to radiologists because it speeds up the reporting process compared to conventional dictation/transcription or speech recognition. In addition, the system eliminates the costs, delays, inaccuracies, and other organizational problems associated with transcription services, thereby improving patient care. Therefore, time-efficient, speech-augmented structured reporting systems will likely capture a significant segment of the $1.2 billion annual market for radiology transcription services.  n/a",DEVELOPMENT OF A KNOWLEDGE-BASED IMAGE REPORTING SYSTEM,6073984,R43LM006837,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted medical decision making', ' computer system design /evaluation', ' data management', ' imaging /visualization /scanning', ' information systems', ' vocabulary', ' vocabulary development for information system']",NLM,"EDICT SYSTEMS, INC.",R43,2000,98563,-0.07166258905066404
"VIRUS STRUCTURE DETERMINATION SOFTWARE Virus structure determination using electron microscopy has become a useful research tool aimed at understanding viral assembly and infectivity to facilitate the design of anti-viral drugs and virus-based gene delivery systems. Our long term goal is to broaden the group of people able to determine virus structures by providing an integrated software suite for three-dimensional virus structure determination using electron microscopy. The software suite, called Tumbleweed, will allow easy, efficient, and routine determination of icosahedral virus structures from electron micrographs. Novel aspects of Tumbleweed will include a comprehensive suite of tools for icosahedral structure determination, incorporation of an expert system to guide users through the reconstruction procedure, and data analysis tools to ensure that structures are determined accurately. Tumbleweed will also provide a consistent easy to use graphical user interface to all reconstruction tools including data analysis, data management, and data logging. In addition, Tumbleweed will provide tools for image selection, quality assessment, and structure visualization that can be used with any electron microscopy structure determination method. Thus, in addition to virologists, target users include electron microscopists and structural biologists. The result of this Phase Il SBIR will be a completely integrated and tested software package allowing easy, efficient, and routine virus structure determination. PROPOSED COMMERCIAL APPLICATIONS: Tumbleweed is targeted at a large group of users with varied knowledge, experience, and research goals. Virologists will be attracted to the extensive user guidance and intuitive design. Structural biologists and electron microscopists performing virus structure determination will be attracted to the concept of a complete integrated software package. Last, all electron microscopists and structural biologists will be attracted to the integration of all general data processing into a single extendible package. Combined this group should provide a large user-base allowing QED Labs to commercialize Tumbleweed successfully.  n/a",VIRUS STRUCTURE DETERMINATION SOFTWARE,6071498,R44GM058327,"['artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data management', ' electron microscopy', ' molecular dynamics', ' structural biology', ' virus assembly', ' virus morphology']",NIGMS,QED LABS,R44,2000,364001,-0.0361110188870516
"WAVELET ENHANCEMENT OF CHROMOSOME BANDING PATTERNS This project aims to develop and commercialize significantly improved software for digital enhancement of the detail of chromosome banding patterns in microscopic images. These investigators have developed an innovative technique for this application, based upon wavelet transforms and multiresolution image analysis. Used with modern computerized chromosome analysis the proposed technique promises significantly improved enhancement of chromosome banding patterns and more effective visual detection of subtle rearrangements. This will help clinicians and researchers detect previously invisible or sub-visible band pattern alterations in conventional and high resolution banding. It will significantly increase the ability of automated instruments to assist the evaluation of chromosome alterations in clinical samples and in normal and neoplastic mammalian cells. During Phase I we implemented and tested three wavelet transforms with desirable mathematical properties. We developed a prototype multiresolution image processing system for chromosome enhancement. We obtained extremely encouraging results, strongly suggesting that these techniques offer considerably improved enhancement capability over conventional methods. and clearly demonstrating the feasibility of this approach. In Phase II we will complete the implementation and refinement of the software. We will implement several wavelet design approaches and evaluate many wavelet transform basis function sets that potentially can bring out relevant detail in chromosome banding patterns. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new enhancement techniques are developed and qualified for routine application, they will be incorporated into PSII's PowerGene products, both in new systems sold and as an upgrade to existing systems.  n/a",WAVELET ENHANCEMENT OF CHROMOSOME BANDING PATTERNS,6181715,R44HD033658,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' chromosome aberrations', ' chromosomes', ' computer data analysis', ' computer program /software', ' computer simulation', ' cytogenetics', ' digital imaging', ' image enhancement', ' image processing', ' molecular dynamics']",NICHD,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2000,260552,0.0008280893477043308
COMPUTER AIDED CARDIAC MEASUREMENT The objective of the proposed research is to develop a method for providing fast and accurate measurements of volume and ejection fraction from 3D echo images. Our Computer Aided Measurement System will reconstruct the LV endocardium using a few user selected points on oriented echocardiographic images together with prior shape and size knowledge. The Specific Aims for Phase I are: 1. To improve the accuracy of quantitative echo while minimizing manual labor. 2. To improve the ease of use of the prototype system for application in a clinical setting. 3. To expand the catalog representing our knowledge base by acquiring additional large volume and abnormally shaped LV's in order to enhance fitting accuracy for atypical shapes. Previously described methods of analyzing echocardiograms in 3D require so much manual labor that this modality has been limited to research applications. The advantages of our proposed approach are that it makes the superior accuracy and reproducibility of 3D echo available for clinical practice. Furthermore this process will be applicable to other imaging modalities. PROPOSED COMMERCIAL APPLICATIONS: This research will lead to products which can be sold to echocardiography system manufacturers and end users. The products will provide accurate and convenient value measurements.  n/a,COMPUTER AIDED CARDIAC MEASUREMENT,6211201,R43HL065827,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' echocardiography', ' heart dimension /size', ' heart disorder diagnosis', ' human data', ' image processing', ' measurement']",NHLBI,"QUANTIGRAPHICS, INC.",R43,2000,100000,-0.0054513932818174215
"A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER   Skin cancer is the fastest growing cancer. Approximately 34,100         Americans developed cutaneous melanoma in 1995; of the survivors, many must          contend with the ongoing trauma of disfigurement and fear. Skin biopsies are         now the most frequently performed medical procedure. It is axiomatic among           dermatologists that early detection and diagnosis are critical. Great strides        have been made in early detection of suspect skin lesions; however failure to        biopsy the right lesion has severe consequences. The dilemma is exacerbated          since 50- 80 percent of biopsies prove unnecessary, contributing to an enormous      waste of health care dollars, patient trauma and negative patient behavior           feedback. The Phase I work in dermatological spectroscopy and artificial neural      net technology suggest that an automated clinical diagnostic aid which produces      a quantitative rather than qualitative diagnostic assessment of skin lesions is      possible. This project proposes development and testing of such a product.           During Phase II a large number of spectroscopic samples of melanoma and nevi         will be used to complete development of an artificial neural net classifier.         Such a classifier system will lead to a commercial product to discriminate           ""normal,"" pre-cancerous and cancerous skin lesions.                                   PROPOSED COMMERCIAL APPLICATION:  The proposed project will lead to a non-invasive, in-office, real-time test to provide an  automated, repeatable diagnostic probability of the nature of skin lesions prior to biopsy.  Skin biopsies are now the most frequently performed reimbursed Medicare procedure,   and as many as 50-80% are found not to be necessary after the fact.  The low cost of   this test, and rapid amortization of the system, coupled with the enormous health care   cost savings possible in conjunction with a significant and widely recognized health   problem, suggest that this product could have great commercial potential.  n/a",A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER,6143548,R44CA078006,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence spectrometry', ' histology', ' human subject', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' reflection spectrometry', ' skin neoplasms', ' spectrometry']",NCI,"WESTERN RESEARCH COMPANY, INC.",R44,2000,363073,-0.014529095936257418
"AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION Quantification of Minimal Residual Disease (MRD) is a general concern in oncology since this parameter is likely to give valuable information to clinicians to customize chemotherapeutic treatments and to anticipate possible relapses. An automated system will be developed for the quantification of MRD by using real-time PCR to quantify cancer cells in a background of non pathologic DNA. The system will be derived from an existing high-throughput sample handling system (developed by Meldrum and team) named Acapella. Acapella has a pipelined serial architecture which makes it possible to develop an adaptive PCR control algorithm ensuring a level of sensitivity and accuracy for the quantification results specified by the clinician. In the R21 phase of the project, a critical component of the system is the real-time thermocycler. It will provide DNA quantification results of greater precision than what is currently possible with commercial instruments such as the ABI PRISM 7700 Sequence Detector by taking advantage of a high performance custom fluorescence analyzer and sophisticated data analysis methods. The fluorescence analyzer will have a signal to noise ratio and a dynamic range of at least one order of magnitude larger than the optics used on commercial systems. This unique feature will permit precise measurements of the amplification kinetics during at least five cycles in the exponential phase of the reaction. The amplification yield will he derived from these data using statistical estimators customized to meet the requirements of real-time PCR data analysis. The sample DNA content will be derived from the amplification yield and the calibrated fluorescence measurements of the reaction kinetics. This new approach will make it possible to run series of real-time PCRs with more flexibility than would be possible if the assay was based on standard reactions required to have the same amplification yield as the clinical samples. PCR conditions will be adapted online without concerns about possible differences of amplification rate. The assay control algorithm will adapt the reaction DNA content, the primer selection, and the number of PCRs to meet the clinician requirements for particular patient DNA. During the R21 phase of the project a prototype of the real-time thermocycler will be developed to demonstrate the optic performance and the possibility to estimate the PCR amplification rates with 5% accuracy. A conceptual design of the fully integrated process from patient blood sample to MRD quantification data will be completed to allow assessment of expected performance, cost, and risks associated with the development of the fully engineered system. The development of the various hardware and software components along with their integration into the automated system will take place during the R33 phase of the project. Performance of the system will he evaluated on real biological samples provided by the UW Department of Laboratory Medicine. Results returned by the system will he compared with results of t(14; 18) PCR performed in this department with an ABI PRISM 7700 for the diagnosis of patients suffering from follicular lymphomas.  n/a",AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION,6062376,R21CA084691,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosome translocation', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence', ' high throughput technology', ' human tissue', ' minimal residual disease', ' neoplasm /cancer diagnosis', "" nonHodgkin's lymphoma"", ' nucleic acid quantitation /detection', ' polymerase chain reaction']",NCI,UNIVERSITY OF WASHINGTON,R21,2000,154460,0.0069035415313369024
"KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY DESCRIPTION (Adapted from Applicant's Abstract):  Knowledge-guided, fully        automated image analytic procedures will be applied, and further developed       for the extraction of diagnostic and prognostic information from                 histopathologic sections.  It is proposed to develop knowledge files for the     grading of solar lesions, for the analysis of prostatic intraepithelial          neoplastic lesions (PIN), for benign proliferative epithelial lesions of the     breast, and for kidney tumors.  Quantitative progression indices will be         derived from histometric measurements.  These may serve to identify patients     at high risk to develop infiltrating disease, to measure rate of lesion          progression, and to allow a numeric assessment of the efficacy of                chemopreventive intervention.                                                                                                                                     Knowledge files are under development for a quantitative measurement of the      vascularization around PIN lesions.                                                                                                                               For nuclei, lesions and patients, novel methodology is proposed to               characterize these entities by identification, rather than by mere               classification.  This will allow a significantly more precise                    characterization of the nuceli in a lesion and of the state of lesion            progression.  The identification methods will be integrated into the current     diagnostic decision support system, and be given capabilities to handle          missing data, contradictory evidence, atypical diagnostic clue expression.       This capability relies on automated reasoning will be developed, and the         methodology will be adapted for used in histopathologic diagnosis.                n/a",KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6137486,R01CA053877,"['artificial intelligence', ' bioimaging /biomedical imaging', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' image processing', ' information system analysis', ' kidney neoplasms', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2000,442719,-0.023123826554497934
"FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING DESCRIPTION (Applicant's Abstract):  Facial expression communicates              information about emotional response and plays a critical role in the            regulation of interpersonal behavior.  Current human-observer based methods      for measuring facial expression are labor intensive, qualitative, and            difficult to standardize across laboratories and over time.  To make             feasible more rigorous, quantitative measurement of facial expression in         diverse applications, we formed an interdisciplinary research group which        covers expertise in facial expression analysis and image processing.  In the     funding period, we developed and demonstrated the first version of an            automated system for measuring facial expression in digitized images.  The       system can discriminate nine combinations of FACS action units in the upper      and lower face, quantity the timing and topography of action unit intensity      in the brow region; and geometrically normalize image sequences within a         range of plus or minus 20 degrees of out of-plane.                                                                                                                In the competing renewal, we will increase the number of action unit             combinations that are recognized, implement convergent methods of                quantifying action unit intensity, increase the generalizability of action       unit estimation to a wider range of image orientations, test facial image        processing (FIP) in image sequences from directed facial action tasks and        laboratory studies of emotion regulation, and facilitate the integration of      FIP into existing data management and statistical analysis software for use      by behavioral science researchers and clinicians.  With these goals              completed, FIP will eliminate the need for human observers in coding facial      expression, promote standardize measurement, make possible the collection        and processing of larger, more representative data sets, and open new areas      of investigation and clinical application.                                        n/a",FACIAL EXPRESSION ANALYSIS BY IMAGE PROCESSING,6185949,R01MH051435,"['artificial intelligence', ' behavioral /social science research tag', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' emotions', ' face expression', ' human subject', ' image processing', ' interpersonal relations', ' statistics /biometry', ' videotape /videodisc', ' visual tracking']",NIMH,MELLON PITTS CORPORATION (MPC CORP),R01,2000,233574,-0.0019373951505205654
"RULE DISCOVERY IN BODY CAVITY EFFUSIONS  DESCRIPTION (adapted from the Abstract):                                             Machine learning methods are innovative tools used to find patterns in medical       data.  Laboratory data is suited to computerized Interpretation because of its       objective, quantitative nature.  Body fluid analysis is a good model for             evaluating machine learning in the laboratory.  Pathologists spend a                 substantial amount of time analyzing and classifying body fluids, or                 effusions, which are abnormal accumulations of fluid within body cavities of         human beings and animals, caused by diseases such as congestive heart failure.       Fluid classification provides clinicians with important diagnostic information       about the underlying disease process.  Automation of body fluid analysis by a        machine learning system would substantially increase the efficiency and              profitability of a medical laboratory.  In a pilot study, RIPPER (Repeated           Incremental Pruning to Produce Error Reduction), a rule discovery tool,              accurately classified effusions from animals into five standard categories,          based on the physical, chemical, and cellular characteristics of the fluid.          The purposes of this study are: 1) to determine the accuracy of RIPPER on a          larger data set, to expand and strengthen the results of the pilot; 2) to test       the accuracy of RIPPER's fluid classifications prospectively in a large              veterinary teaching hospital laboratory, 3) to determine the acceptance rate         or reason for rejection of RIPPER's classification by clinical pathologists;         and (4) to use RIPPER to discover novel rules for classifying effusions by           underlying disease process.                                                                                                                                               The results of this study will validate and test the acceptance of a machine         learning system applicable to fluid analysis in both human and veterinary            clinical laboratories.  By discovering new patterns in quantitative data that        identify the specific underlying disease, RIPPER can greatly enhance the             diagnostic value of laboratory analysis.                                                                                                                                  n/a",RULE DISCOVERY IN BODY CAVITY EFFUSIONS,6144004,F32LM000095,"['body fluids', ' classification', ' computer assisted instruction', ' programmed instruction', ' veterinary science']",NLM,UNIVERSITY OF CALIFORNIA DAVIS,F32,2000,52420,-0.02207308872319011
"MULTICHANNEL EEG DATA COMPRESSION Recently, recording high-resolution Electroencephalograms (EEGs) from            a large number of electrodes has become a clear trend in both brain              research and clinical diagnosis.  However, the current EEG data                  acquisition systems store the collected data in a form that has never            changed since digital EEG emerged about 30 years ago.  As a result, the          size of the output data file increases enormously as the number of               recording channels increases, causing various problems including high            costs in data analysis, database management, archiving, and transmission         through the internet.                                                                                                                                             This proposal seeks to solve this problem through fundamental research           on data compression specifically for EEG data, but applicable to other           physiological data as well.  Our key approach is based on the                    application of advanced mathematical and signal processing technologies          to this critical problem.  We will develop and optimize a variable               sampling technique which eliminates redundant data samples using spline          interpolation and wavelet transformation.  We will also investigate              lossless data compression algorithms that possess two important                  features: 1) any part of the data within the compressed file can be read         without having to decompress the entire file, and 2) the compressed data         can be transmitted and presented in coarse or fine resolutions as                needed.  We expect that, using both variable sampling and lossless               compression, the EEG file size can be reduced by approximately 70                percent.                                                                          n/a",MULTICHANNEL EEG DATA COMPRESSION,6165278,R01NS038494,"['Internet', ' artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' clinical biomedical equipment', ' clinical research', ' computer data analysis', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' digital imaging', ' electroencephalography', ' human data', ' human subject', ' informatics', ' technology /technique development']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2000,172553,-0.02309963288985617
"ACTUARIAL STRATEGIES IN CHILD DIAGNOSTIC ASSESSMENT  The proposed project involves a preliminary investigation of                                                                                   potentially significant methodological advance in diagnostic assessment. The         current state-of-the-art in diagnostic assessment involves the use of a              structured interview. Typically, structured interviews involve a static skip         structure, i.e., some portions of the interview are administered conditional on                                 particular responses to prior questions. For example, if there is a negative         response to a question about depression and anhedonia, most structured               interviews require the clinical to skip the remaining questions about                associated symptoms (e.g., sleep disturbance, impaired concentration, etc.).         Although structured interviews represent an enormous advantage over earlier          diagnostic procedures, their inflexible structure is often incompatible with         the heterogeneity of most child and adolescent populations, and can result in        superfluous questioning about uncommon disorders and insufficient follow-up          about more common ones. Many interviews do not make exceptions for individual        characteristics. For example, 1) a 17 year old boy might need to answer ""no"" to      5 or 6 questions about separation anxiety before the interviewer may move on to      another set of questions; or 2) an underweight 16 year old girl might not be         asked important follow-up questions when replying ""no"" to the initial question       about eating disorders. One might conclude that introducing more clinician           flexibility would be the solution; however, the literature on clinical judgment      suggests that increasing clinician involvement in determination of interview         structure would likely degrade classification accuracy and introduce unwanted        sources of error and bias. To address this issue in another manner, the              principal investigator has developed a data-driven, actuarial expert system to       guide a flexible interview structure. Thus, interview structure is dynamically       responsive to individual characteristics, without introducing error associated       with qualitative clinical judgments. Pilot modeling revealed that his system         offers advantages in classification accuracy over state-of-the-art diagnostic        approaches, with the additional benefit of reducing administration time for          particular disorders. The current project is planned to generate requisite data      to develop a formal expert system and to forecast its relative accuracy and          efficiency in a child and adolescent population. It is predicted that this           system will demonstrate improvements in classification accuracy over a static        structured interview approach, with reduced administration time. If the data         are supportive, these developments have the potential to significantly advance       the manner in which future diagnostic interviews are conducted with mental           health populations.                                                                                                                                                       n/a",ACTUARIAL STRATEGIES IN CHILD DIAGNOSTIC ASSESSMENT,6096946,R03MH060134,"['adolescence (12-20)', ' anxiety', ' artificial intelligence', ' behavior test', ' behavioral /social science research tag', ' child (0-11)', ' child behavior disorders', ' child psychology', ' clinical research', ' computer assisted diagnosis', ' data collection methodology /evaluation', ' depression', ' diagnosis design /evaluation', ' human subject', ' interview', ' mathematical model', ' mental disorder diagnosis', ' model design /development', ' mood disorders', ' psychometrics', ' questionnaires']",NIMH,UNIVERSITY OF HAWAII AT MANOA,R03,2000,63589,-0.021819701186541033
"IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION Colorectal carcinoma is the second leading cause of cancer deaths in the         United States today.  In an effort to reduce mortality, Congress                 recently included a provision in the Balanced Budget Act of 1997 to              support screening colonoscopy as a means for early detection and removal         of colorectal polyps, the precursors to cancer.  In this country alone,          more than 68 million people are eligible for colorectal screening, but           the majority are unlikely to comply with screening recommendations               because of the costs, risks, discomfort, and inconvenience associated            with traditional endoscopy.  Furthermore, even if a small fraction of            eligible persons are examined, the number of available                           gastroenterologists would be insufficient to perform so many procedures.                                                                                          We have developed a new technique, called virtual colonoscopy (VC), as           an alternative to screening diagnostic colonoscopy (DC). The procedure           consists of cleansing a patient's colon, inflating the colon with air,           scanning the abdomen with helical computed tomography (CT), and                  generating a rapid sequence of three-dimensional (3D) images of the              colon by means of virtual reality computer technology.  Although VC              makes possible the visualization of 3D images of the colon in a manner           similar to that of DC, a correct diagnosis depends upon a physician's            ability to identify small and sometimes subtle polyps within hundreds            of 3D images.  The absence of visual cues that normally occur with DC            makes VC interpretation tedious and susceptible to error.                                                                                                         With support from a National Science Foundation (NSF) grant, we have             developed a computer-assisted polyp detection (CAPD) system that                 calculates areas of abnormal colon wall thickness in helical CT image            data in order to highlight potential polyps in the 3D images.  A                 physician ultimately determines if each detected lesion represents a             true abnormality.  Although we have found CAPD to be sensitive for               finding subtle abnormalities, poor specificity can be attributed to              several obstacles, including imprecise image segmentation, limited               feature analysis, and suboptimal bowel preparation prior to helical CT           scanning.  With these challenges in mind, we propose research to perfect         CAPD. Our specific aims are as follows: 1. To develop an image                   segmentation algorithm that accurately isolates the colon from helical           CT image data; 2. To improve our polyp detection algorithm with expanded         feature analysis and artificial intelligence methods; 3. To optimize             bowel preparation with digital subtraction of opacified feces and                controlled gas distention; and 4. To validate the accuracy of VC, with           the modifications achieved in the stated aims, by comparing the results          of VC and DC in 200 patients undergoing usual-care colonoscopy.                                                                                                   If VC with CAPD proves accurate and efficient in the diagnosis of                colorectal polyps, it could evolve into a simple laboratory test,                thereby meeting the demand for worldwide colorectal cancer screening.             n/a",IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION,6173999,R01CA078485,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical research', ' colon neoplasms', ' colon polyp', ' computed axial tomography', ' computer assisted diagnosis', ' computer simulation', ' diagnosis design /evaluation', ' endoscopy', ' gastrointestinal imaging /visualization', ' human subject', ' image enhancement', ' mathematical model', ' model design /development', ' neoplasm /cancer diagnosis']",NCI,WAKE FOREST UNIVERSITY,R01,2000,563099,-0.05591273081929797
"RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION The goal of the proposed research is to develop and test a computational theory for the human ability to recognize objects under variable illumination (including extreme shadowing) and viewpoint changes. The ability to recognize objects is of fundamental importance in everyday life and the loss of this ability, due to a stroke or Alzheimer's disease, is a serious handicap to the person involved. The computational theory is based on a new paradigm for object representation --generative modeling - - in which an image-based model of an object is ""generated"" from a small set of training images. This theory has been demonstrated to successfully recognize objects from real images under extreme lighting variations. This gives a reality check on the theory and can be thought of as making it an ecological theory (in the sense that it yields good results on the types of images that humans encounter in the real world and not just on the visual stimuli occurring in laboratories). We have assembled a team of researchers with interdisciplinary skills in computer and biological vision. who will divide their efforts on the project based on their expertise. It is our explicit intent that the algorithms and psychophysical studies develop in tandem, with each group verifying the other's results. Indeed, as reviewed below, the computer vision theory, when applied to human performance, makes a number of predictions. some of which have already been partially confirmed by our preliminary experimental work. Our proposal is organized into three main areas. The psychophysical work parallels the computational issues in three series of experiments in which we investigate: (I) How human observers learn and recognize objects, given variable lighting conditions, from a single fixed viewpoint. (II) How illumination and viewpoint interact in human object recognition. (III) The role of class-specific knowledge in recognition.  n/a",RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION,6179288,R01EY012691,"['computer simulation', ' form /pattern perception', ' human subject', ' light intensity', ' psychophysics', ' visual perception']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2000,332626,-0.0398648736401354
"METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES DESCRIPTION (Adapted from Applicant's Abstract):  The aim of this proposal       is to further develop and validate algorithms for analysis of SPAMM MR           cardiac images based on novel spline methods.  MRI is unique in its ability      to non-invasively and selectively alter tissue magnetization, and create         tagged patterns within the deforming tissue such as the heart muscle.  The       resulting pattern defines a time-varying curvilinear coordinate system on        the underlying tissue, allowing for precise and quantitative measurement of      tissue motion and deformation.  The investigators are developing two             frameworks for analysis of SPAMM tagged images, both of these aimed at           providing a more automated and reproducible approach to analysis of SPAMM        data, as well as providing dense 3-D displacement information at all points      within the LV myocardium.  The investigators propose to (a) further develop      and extend our analyses techniques.  The extensions considered will all be       related and based on currently developed computer vision-based techniques        for regional LV wall motion analysis, that operates either on a sequence of      SA slice stacks or on a time sequence of single slice.  (b) The                  investigators will validate the motion tracking methods by comparing ""true""      and algorithm-estimated motion trajectories:  1) on dense field of points        derived from 3-D tagged computer models of objects that simulate the moving      LV, 2) on dense field of points derived from Finite Element Model                simulations of the constitutive equations of LV deformations (once again tag     planes will be superimposed on the time course of simulated geometries), 3)      on selected points in the LV myocardium of the in vivo heart using a porcine     model.  Here, ""true"" motion will be determined by tracking implanted image       distinguishable markers.  (c) The investigators will test whether regions of     postmortem myocardial injury imply similar-sized and locate regions of           altered deformations (as measured by parameters developed in (a)).  The          algorithm-derived LV function assessment based on the analysis of in vivo        tagged MRI sequences will be compared with postmortem myocardial injury          assessment determined by myocardial staining techniques.  The validated          parameters will also be use to examine the time-course of change in the          ischemic areas of the chronic animal models.                                      n/a",METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES,6184044,R01HL057628,"['bioimaging /biomedical imaging', ' cardiography', ' clinical research', ' computer data analysis', ' computer simulation', ' diagnosis design /evaluation', ' heart motion', ' histopathology', ' human subject', ' image processing', ' magnetic resonance imaging', ' myocardial ischemia /hypoxia', ' swine']",NHLBI,BARNES-JEWISH HOSPITAL,R01,2000,119129,-0.037101490422922705
"TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH Developing artificial intelligence technology for medical imaging applications requires training models on large and diverse datasets.  Currently, aggregation of large data repositories, including radiology and pathology images, is limited by concerns around patient privacy.  In order to successfully share medical images, an institution must be able to quickly and accurately de-identify large numbers of images in batches.  This process is currently manual and time-consuming. We propose a pipeline to remove PHI from both radiology DICOM images and pathology whole slide images by leveraging machine learning, natural language processing, and compartmentalized workflow techniques to significantly reduce the human intervention needed to anonymize medical images.  In addition to examining header data in the images, we will use optical character recognition and computer vision algorithms to detect text in any location or orientation in the image, then automatically record and subsequently purge these regions. These techniques will be configured to work on a variety of image types (CT, MRI, radiograph, etc) and cover multiple OEM vendors for both radiology and pathology images. This phase I statement of work will construct the software tools, methods, and datasets necessary to facilitate a phase II where the complex algorithms needed for autonomous deidentification will be developed.  This phase II processing will be referred to throughout this document as the workflow. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH,10274086,5N91020C00023,"['Algorithms', 'Artificial Intelligence', 'Complex', 'Computer Vision Systems', 'Consumption', 'Contracts', 'Data', 'Data Set', 'Digital Imaging and Communications in Medicine', 'Elements', 'Excision', 'Head', 'Human', 'Image', 'Ingestion', 'Institution', 'Intervention', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Medical Imaging', 'Medical Technology', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology', 'Phase', 'Process', 'Radiology Specialty', 'Research', 'Sampling', 'Slide', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Vendor', 'Work', 'cancer imaging', 'data ingestion', 'data warehouse', 'file format', 'optical character recognition', 'pathology imaging', 'patient privacy', 'purge', 'radiological imaging', 'whole slide imaging']",NCI,"BIODATA CONSORTIUM, LLC",N43,2020,386526,0.007775382881528403
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10224492,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,233900,-0.007405342142125164
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10017950,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,513041,-0.007405342142125164
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10019459,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2020,291252,-0.00656123822083304
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9913520,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Visualization', 'Work', 'algorithm training', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,235027,-0.020709508526604376
"Clinical and genetic analysis of retinopathy of prematurity Project Summary The long-term goal of this project is to establish a quantitative framework for retinopathy of prematurity (ROP) care based on clinical, imaging, genetic, and informatics principles. In the previous grant period, we have developed artificial intelligence methods for ROP diagnosis, but real-world adoption has been limited by lack of prospective validation and by perception of these systems as “black boxes” that do not explain their rationale for diagnosis. Furthermore, although biomedical research data are being generated at an enormous pace, much less work has been done to integrate disparate scientific findings across the spectrum from genomics to imaging to clinical medicine. This renewal will address current gaps in knowledge in these areas. Our overall hypotheses are that developing a quantitative framework for ROP care using artificial intelligence and analytics will improve clinical disease management, that building “explainable” artificial intelligence systems will enhance clinical acceptance and educational opportunities, and that analysis of relationships among clinical, imaging, environmental, and genetic findings, in ROP will improve understanding of disease pathogenesis and risk. These hypotheses will be tested using three Specific Aims: (1) Evaluation performance of an artificial intelligence system for ROP diagnosis and screening prospectively. This will include: (a) recruit a target of over 2000 eye exams including wide-angle retinal images from 375 subjects at 5 centers, (b) optimize an image quality detection algorithm we have recently developed, and (c) analyze system accuracy for ROP diagnosis and screening (using a novel quantitative vascular severity scale). (2) Improve the interpretability of our existing artificial intelligence methods for ROP diagnosis. This will include: (a) increase “explainability” of systems by combining deep learning with traditional feature extraction methods, (b) develop neural networks to identify changes between serial images, and (c) evaluate these methods through systematic feedback by experts. (3) Develop integrated models for ROP pathogenesis and risk. This will include: (a) build and improve ROP risk prediction models based on clinical, image, and demographic features, and (b) integrate genetic, imaging, clinical, and environmental variables through genetic risk prediction by machine learning, by investigating casual relationships with genetic variants and genetic risk scores, and by incorporating SNP associations with gene expression measurements to identify functional genes of ROP. Ultimately, these studies will significantly reduce barriers to adoption of technologies such as artificial intelligence for clinicians, and will demonstrate a prototype for health information management which combines genotypic and phenotypic data. This project will be performed by a multi-disciplinary team of investigators who have worked successfully together for nearly 10 years, and who have expertise in ophthalmology, biomedical informatics, computer science, computational biology, ophthalmic genetics, genetic analysis, and statistical genetics. Project Narrative ROP is a leading cause of childhood blindness in the US and throughout the world, and the number of infants at risk for disease is increasing as the rate of premature birth rises. Rapidly-progressive changes associated with retinal vascular development may be visualized by clinical examination, captured by wide-angle imaging, and analyzed genetically. This project will develop, enhance, and validate artificial intelligence and analytic tools to help clinicians identify infants at risk for severe ROP using image analysis, genetic analysis, and integrative informatics that combines these factors – while also providing insight about disease pathogenesis.",Clinical and genetic analysis of retinopathy of prematurity,9974137,R01EY019474,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biomedical Research', 'Blindness', 'Blood Vessels', 'Caring', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Research', 'Cohort Studies', 'Computational Biology', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Evaluation', 'Expert Systems', 'Feedback', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Infant', 'Informatics', 'Information Management', 'International', 'Knowledge', 'Longitudinal Studies', 'Machine Learning', 'Macular degeneration', 'Measurement', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular Genetics', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Other Genetics', 'Oxygen', 'Paper', 'Pathogenesis', 'Peer Review', 'Perception', 'Performance', 'Phenotype', 'Predisposition', 'Premature Birth', 'Premature Infant', 'Publishing', 'Randomized', 'Reference Standards', 'Research', 'Research Personnel', 'Retina', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Severities', 'System', 'Technology', 'Testing', 'United States', 'Validation', 'Work', 'analytical tool', 'base', 'biomedical informatics', 'care delivery', 'clinical Diagnosis', 'clinical examination', 'clinical phenotype', 'clinical risk', 'clinically significant', 'computer science', 'data access', 'data integration', 'deep learning', 'diagnosis standard', 'disorder risk', 'feature extraction', 'genetic analysis', 'genetic variant', 'high risk', 'imaging genetics', 'improved', 'insight', 'multidisciplinary', 'multiple data types', 'neovascular', 'neural network', 'novel', 'phenotypic data', 'prospective', 'prototype', 'real world application', 'recruit', 'retinal imaging', 'risk prediction model', 'screening', 'serial imaging']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,764279,-0.04257276741887383
"Improved Glaucoma Monitoring Using Artificial-Intelligence Enabled Dashboard Detecting functional and structural loss due to glaucoma is critical to making treatment decisions with the goal of preserving vision and maintaining quality of life. However, most of the approaches for glaucoma assessment through visual fields (VFs) or optical coherence tomography (OCT) measurements have several limitations that poses critical challenge to their clinical utility. Identifying glaucoma-induced changes from a sequence of VF or OCT data is challenging either if the patients is in the early stages of the disease with subtle manifested structural and functional signs or if the patients are in the later stages of the disease with significant VF variability and OCT flooring effect. A major limitation of the current glaucoma monitoring techniques is that they generate a binary outcome of whether the glaucoma is worsening or not while current high-throughput data (e.g., OCT) has more information than a binary outcome. Another major drawback of some of these approaches is that they rely on traditional paradigms for progression detection such as linear regression. However, rates of glaucomatous progression may be non-linear and rapid, particularly during the later stages of the disease. Another limitation is that ad-hoc rules are adopted to define glaucoma progression while objective criteria are required to define thresholds for progression. Finally, a major deficiency of most of these methods is that they lack advanced visualization and interpretation. We propose to address these limitations by developing artificial intelligence (AI)-enabled visualization tools for effectively monitoring the functional and structural loss in patients with glaucoma. This approach provides qualitative and quantitative means to monitor 1) global visual functional and structural worsening, 2) extent of loss in hemifields, and 3) local patterns of functional and structural loss on advanced 2-D visualization tools. To achieve these objectives, we have assembled a team of interdisciplinary experts with access to large clinically annotated glaucoma data. The central hypothesis of this proposal is that advanced interpretable machine learning applied to a complete profile of VFs in all test locations (e.g., 54 in 24-2 system) and OCT-derived measurements of retinal nerve fiber layer (RNFL) (e.g., 768 A-scans around the optic disc and 7 global sectoral regions) can objectively and automatically learn and quantify the most important features, yielding a more specific and sensitive means for monitoring of glaucoma worsening than current subjectively-specified or statistically-identified approaches. We also hypothesize that machine learning can provide interpretable models with several layers of glaucoma knowledge that may provide a promising complement to current glaucoma assessment tests. Our proposed studies may offer substantial improvements in prognosis and management of glaucoma through effective use of analysis and visualization to improve glaucoma management and making more informed treatment options. Current glaucoma assessment is hampered by several limitations including lack of visualization and interpretation, providing binary rather than more-informed results, utilizing traditional approaches for data analysis, and adopting ad-hoc assessment criteria. Glaucoma is best managed and treated if both functional and structural data is utilized and mined using advanced computational tools to generate more-informative quantitative results. We propose developing artificial intelligence (AI)-enabled visualization dashboards for qualitative and quantitative monitoring of global visual functional and structural worsening, extent of loss in hemifields, and local patterns of functional and structural loss on advanced interpretable 2-D and 3-D visualization maps.",Improved Glaucoma Monitoring Using Artificial-Intelligence Enabled Dashboard,10043768,R21EY031725,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Algorithms', 'Artificial Intelligence', 'Axon', 'Big Data to Knowledge', 'Clinical', 'Clinical Trials', 'Communities', 'Complement', 'Computer Systems', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Eye', 'Floor', 'Glaucoma', 'Goals', 'Health', 'High Performance Computing', 'Image', 'Incidence', 'Knowledge', 'Learning', 'Linear Regressions', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Pattern', 'Principal Component Analysis', 'Quality of life', 'Reproducibility', 'Research', 'Retinal Ganglion Cells', 'Savings', 'Scanning', 'Severities', 'Specific qualifier value', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Treatment Cost', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual Fields', 'Visualization', 'Visualization software', 'base', 'computerized tools', 'dashboard', 'field study', 'glaucoma test', 'hands-on learning', 'improved', 'large datasets', 'longitudinal dataset', 'multidimensional data', 'open source', 'outcome forecast', 'preservation', 'retinal nerve fiber layer', 'structured data', 'three-dimensional visualization', 'tool', 'treatment strategy', 'unsupervised learning']",NEI,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R21,2020,253379,-0.023222614667819545
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,9867431,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,806128,-0.026356360821713363
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,9895214,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2020,235500,-0.025757633099447414
"AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition ABSTRACT Dietary intake is a complex human behavior that drives disease risk and corresponding economic and healthcare burdens worldwide. Poor diet is the leading cause of death in the US and a known driver of obesity – a global epidemic. A major contributor to poor diet is food eaten away from home, such as restaurant foods. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods. Accurate approaches and tools to evaluate food and nutrient intake are essential in monitoring the nutritional status of individuals. There is a critical need for real-time data capture that minimizes burden and reduces error. While progress has been made, there is no tool available that accurately and automatically estimates foods left unconsumed in a meal. Two major limitations of existing systems is the reliance of a fiducial marker for food detection and volume estimation, and reliance on humans – either the respondent or a trained researcher – to estimate the portion of food leftover. This application leverages novel technology to remove those limitations. The long-term research goal is to utilize digital imaging (DI), artificial intelligence (AI) and computer vision (CV) techniques to develop a novel hybrid methodology for rapid, accurate measurement of dietary intake. To attain this goal, our objective in this R21 application is to refine and test a system architecture that (a) uses digital images to record dietary intake in real-time and (b) uses AI and CV techniques to identify food/beverage items and determine amounts leftover. We plan to build on our current prototype in which digital food images are captured before and after the meal, analyzed to detect the food items, a three-dimensional (3-D) virtual model constructed, and volume remaining after the meal estimated, which will be used to calculate the amount leftover based on the initial volume. Volume consumed will be converted to weight and linked to public-use nutrition information. These calorie estimates will be compared against calories those from (a) DIs coded by trained research staff and (b) weighed plate waste methodology. Our expectation is to develop a valid system architecture for rapidly estimating dietary intake. The outcome of this proposal is expected to have a significant positive impact, enabling nutrition and health researchers to collect high-quality food consumption data in real world settings, increasing knowledge of dietary patterns and improving capacity to assess dietary interventions. This work will lead to an R01 application that will expand food types and meal settings and test the utility of our system among consumers. Project Narrative Solutions to address the global obesity epidemic are urgently needed. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods, a known driver of obesity. This study integrates nutrition science, computer science, and engineering to develop and test a new method for assessing dietary intake, and if successful would yield a rapid, reliable, accurate and cost- effective tool.",AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition,9978495,R21CA250024,"['3-Dimensional', 'Address', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Behavior', 'Beverages', 'Body Weight decreased', 'Calories', 'Cause of Death', 'Cellular Phone', 'Code', 'Complex', 'Computer Vision Systems', 'Consumption', 'Data', 'Databases', 'Detection', 'Development', 'Diet', 'Diet Records', 'Dietary Assessment', 'Dietary Intervention', 'Dietary Practices', 'Dietary intake', 'Economics', 'Engineering', 'Epidemic', 'Food', 'Goals', 'Gold', 'Health', 'Healthcare', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Intake', 'Intervention', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Nutrient', 'Nutritional Science', 'Nutritional status', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Output', 'Participant', 'Research', 'Research Personnel', 'Research Training', 'Respondent', 'Restaurants', 'Side', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Validation', 'Weight', 'Work', 'base', 'computer science', 'cost', 'cost effective', 'design', 'digital', 'digital imaging', 'disorder risk', 'expectation', 'food consumption', 'food quality', 'handheld mobile device', 'improved', 'knowledge base', 'new technology', 'novel', 'nutrition', 'prototype', 'success', 'system architecture', 'tool', 'virtual model', 'wasting', 'weight maintenance']",NCI,TUFTS UNIVERSITY BOSTON,R21,2020,222002,-0.009387574000747132
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9997914,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,498014,-0.02720637432496448
"A Machine Learning-Based Mobile Application and Cloud Platform to Enable Accurate and Streamlined Surveillance of Soil-Transmitted Helminth Infection and Schistosomiasis PROJECT SUMMARY/ABSTRACT Soil-transmitted helminth (STH) infections and schistosomiasis affect 2 billion people and have significant detrimental effects on health. Strategies to implement STH and schistosomiasis interventions currently rely on testing for these parasites by microscopic analysis of stool samples to detect parasite eggs and identify egg species. Accurate surveillance testing and timely and accurate reporting of results are required for effective decision-making at the programmatic level to implement infection control strategies. Approaches that increase the speed and standardize the accuracy of microscopy-based testing and streamline reporting could help eliminate STH infections and schistosomiasis. We propose to develop a mobile phone-based STH-schistosome egg identification and counting tool that employs machine learning (deep learning) and works in the absence of an internet connection. With this app, users will collect surveillance data for integration into a cloud platform. Surveillance data can then be visualized in dashboards to inform interventions to control disease. Our approach is fundamentally different from other published work that develop machine learning algorithms for STH and schistosomiasis because it will very accurately identify egg types during surveillance activities, and it will be available to users in an app and integrate with cloud storage and reporting. Our interdisciplinary team combines the expertise of global health researchers, product usability testing experts, microscopists, and data scientists. In the R21 phase, we will collect the largest ever microscopy image set of STH and schistosome eggs (> 15 000). We will train an algorithm based on convolutional neural networks that make highly accurate parasite egg classification (species identification) and embed this algorithm into a mobile app that works without internet connectivity. To promote app utility, we will evaluate its accuracy and usability in a surveillance setting. We established the feasibility of our approach in preliminary data by building a web app that serves the results of a deep learning model that identifies STH and schistosome eggs with > 98% accuracy. The R33 phase will be only undertaken if well-defined milestones are achieved. We will further develop the mobile app as a data capture system that will integrate with cloud storage and a dynamic data visualization system to enable increased accuracy in STH and schistosomiasis surveillance over time and across geographic location. ​Validation studies will assess the​ benefits of the system to time and cost savings and quality of data collected during surveillance activities. The overall goal of this work is to increase the accuracy and streamline STH and schistosomiasis surveillance to enable effective decision-making in disease control. PROJECT NARRATIVE Accurate surveillance testing in the field and timely and accurate reporting of results are required for effective decision-making by soil-transmitted helminth (STH) infection and schistosomiasis control and prevention programs. This project will develop and test a mobile phone-based STH-schistosomiasis diagnostic system that employs machine learning to very accurately identify and count parasite eggs from microscopy images of stool samples. This mobile app will work in the absence of any internet connection and will streamline collection of surveillance data for integration into a cloud-based surveillance platform that increases data visibility.",A Machine Learning-Based Mobile Application and Cloud Platform to Enable Accurate and Streamlined Surveillance of Soil-Transmitted Helminth Infection and Schistosomiasis,10058110,R21TW011753,"['Affect', 'Algorithms', 'Architecture', 'Car Phone', 'Classification', 'Collection', 'Cost Savings', 'Data', 'Data Aggregation', 'Data Collection', 'Data Scientist', 'Databases', 'Decision Making', 'Diagnostic', 'Feedback', 'Future', 'Geographic Locations', 'Goals', 'Health', 'Helminths', 'Image', 'Infection Control', 'Internet', 'Intervention', 'Location', 'Machine Learning', 'Microscope', 'Microscopic', 'Microscopy', 'Modeling', 'Pain', 'Parasites', 'Parasitic infection', 'Phase', 'Prevention', 'Prevention program', 'Process', 'Publishing', 'Reporting', 'Research Personnel', 'Schistosoma', 'Schistosomiasis', 'Soil', 'Speed', 'Standardization', 'Surface', 'System', 'Testing', 'Time', 'Validation', 'Work', 'algorithm training', 'base', 'cloud based', 'cloud platform', 'cloud storage', 'convolutional neural network', 'cost', 'dashboard', 'data access', 'data integration', 'data visualization', 'deep learning', 'design', 'digital', 'disorder control', 'egg', 'global health', 'helminth infection', 'improved', 'machine learning algorithm', 'microscopic imaging', 'mobile application', 'prevent', 'product development', 'stool sample', 'surveillance data', 'tool', 'transmission process', 'usability', 'validation studies', 'web app']",FIC,"PARASITE ID, CORP.",R21,2020,186698,-0.019727742369430742
"TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT This Fast Track SBIR aims to implement comprehensive image anonymization within an enterprise imaging informatics platform built on XNAT.  Our vision is for this platform to provide large healthcare enterprises with tools to generate secure research databases at scale that mirror their clinical image archives.  These databases would then provide local academic and industry collaborators with a rich resource for clinical research and development of AI-powered applications. Thus, our proposed anonymization services are designed to be scalable, risk-based, and verifiable. The platform's AI-powered image anonymization will include automated detection of PHI using a deep learning based natural language processing engine and automated detection of PHI in image content using a convolutational neural network.  The anonymization services will be integrated into Radiologics enterprise and clinical trial XNAT products. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT,10274066,5N91020C00025,"['Clinical Research', 'Clinical Trials', 'Computer software', 'Contracts', 'Data', 'Database Management Systems', 'Databases', 'Detection', 'Healthcare', 'Image', 'Industry Collaboration', 'Intelligence', 'Natural Language Processing', 'Phase', 'Radiology Specialty', 'Research', 'Resources', 'Risk', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Vision', 'base', 'clinical imaging', 'deep learning', 'design', 'image archival system', 'imaging informatics', 'neural network', 'prototype', 'research and development', 'tool']",NCI,"RADIOLOGICS, INC.",N43,2020,399691,-0.014039444729375131
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9976466,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'neural network classifier', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,385010,-0.04256328622548262
"Support for New Bioinformatics Methods Development New bioinformatics method development support includes, image analysis for glyphosate toxicity where deep-learning based image processing tmethods were used to discriminate between normal, stressed and cell-death conditions of HepaRG cells and primary hepatocytes; Evidence tagging protocols were develop for evidence mapping for the OHAT group;  an evaluation of existing tagging methods was performed currently available in the SWIFT-Review program; Machine Learning methods were used for Document tagging activity exploring alternative to the keyword-based tagging strategy currently used in SWIFT-Review. n/a",Support for New Bioinformatics Methods Development,10281443,73201700001C,"['Bioinformatics', 'Cell Death', 'Cells', 'Chemical Exposure', 'Chemicals', 'Contractor', 'DNA Sequence', 'Development', 'Evaluation', 'Genes', 'Hepatocyte', 'Image Analysis', 'Measures', 'Methods', 'Output', 'Program Reviews', 'Programming Languages', 'Protocols documentation', 'Sampling', 'Series', 'Specific qualifier value', 'Stress', 'Toxic effect', 'base', 'bioinformatics tool', 'deep learning', 'differential expression', 'glyphosate', 'image processing', 'machine learning method', 'method development', 'programs', 'transcriptomics']",NIEHS,"SCIOME, LLC",N01,2020,210270,-0.03349241554988859
"Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models Project Summary Amyotrophic lateral sclerosis (ALS) and Frontotemporal Dementia FTD are devastating neurodegenerative disorders that lie on a genetic and mechanistic continuum. ALS is a disease of motor neurons that that is almost uniformly lethal within only 3-5 years of diagnosis. FTD is a heterogeneous, rapidly progressing syndrome that is among the top three causes of presenile dementia. About 10% of ALS cases are caused by dominantly transmitted gene defects. SOD1 and FUS mutations cause aggressive motor neuron pathology while TDP43 mutations cause ALS-FTD. Further, wild type FUS and TDP43 are components of abnormal inclusions in many FTD cases, suggesting a mechanistic link between these disorders. Early phenotypes are of particular interest because these could lead to targeted interventions aimed at the root cause of the disorder that could stem the currently inexorable disease progression. Elucidating such early, potentially shared characteristics of these disorders should be greatly aided by: 1) knock-in animal models expressing familial ALS-FTD genes; 2) sensitive, rigorous and objective behavioral phenotyping methods to analyze and compare models generated in different laboratories. In published work the co-PIs applied their first-generation, machine vision-based automated phenotyping method, ACBM ‘1.0’ (automated continuous behavioral monitoring) to detect and quantify the earliest-observed phenotypes in Tdp43Q331K knock-in mice. This method entails continuous video recording for 5 days to generate >14 million frames/mouse. These videos are then scored by a trained computer vision system. In addition to its sensitivity, objectivity and reproducibility, a major advantage of this method is the ability to acquire and archive video recordings and to analyze the data at sites, including the Cloud, remote from those of acquisition. We will use Google Cloud TPUs supercomputers that have been designed from the ground up to accelerate cutting-edge machine learning workloads, with a special focus on deep learning. We will analyze this data using Bayesian hierarchical spline models that describe the different mouse behaviors along the circadian rhythm. The current proposal has two main goals: 1) Use deep learning to refine and apply a Next Generation ACBM - ‘2.0’ - that will allow for more sensitive, expansive and robust automated behavioral phenotyping of four novel knock-in models along with the well characterized SOD1G93A transgenic mouse. 2) To establish and validate procedures to enable remote acquisition of video recording data with cloud-based analysis. Our vision is to establish sensitive, robust, objective, and open-source machine vision-based behavioral analysis tools that will be widely available to researchers in the field. Since all the computer-annotated video data is standardized in ACBM 2.0 and will be archived, we envision a searchable ‘behavioral database’, that can be freely mined and analyzed. Such tools are critical to accelerate the development of novel and effective therapeutics for ALS-FTD. Narrative ALS and Frontotemporal Dementia (FTD) are devastating, rapidly progressing diseases and current treatments are of limited value. In this proposal a neuroscientist and a computer scientist have teamed up to develop a new machine vision-based method for behavioral analysis novel mouse models of ALS-FTD. The ultimate goal is to reveal early phenotypes in ALS-FTD models that can be used in understanding disease pathology and in the development of new therapeutic targets.",Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models,9979408,R21NS112743,"['Amyotrophic Lateral Sclerosis', 'Animal Model', 'Archives', 'Behavior', 'Behavior monitoring', 'Behavioral', 'Characteristics', 'Circadian Rhythms', 'Computer Vision Systems', 'Computers', 'Data', 'Data Set', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Expression Profiling', 'Familial Amyotrophic Lateral Sclerosis', 'Frontotemporal Dementia', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Hour', 'Human', 'Intervention', 'Knock-in', 'Knock-in Mouse', 'Laboratories', 'Lead', 'Link', 'Machine Learning', 'Methods', 'Modeling', 'Motor Neuron Disease', 'Motor Neurons', 'Mus', 'Mutation', 'Neurodegenerative Disorders', 'Paralysed', 'Pathology', 'Phenotype', 'Plant Roots', 'Presenile Dementia', 'Procedures', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Respiratory Paralysis', 'Scientist', 'Site', 'Standardization', 'Syndrome', 'TensorFlow', 'Time', 'Training', 'Transgenic Mice', 'Transgenic Organisms', 'Treatment Efficacy', 'Video Recording', 'Vision', 'Work', 'Workload', 'base', 'behavioral phenotyping', 'cloud based', 'data archive', 'deep learning', 'design', 'frontotemporal lobar dementia-amyotrophic lateral sclerosis', 'interest', 'knockin animal', 'machine vision', 'mouse model', 'new therapeutic target', 'next generation', 'novel', 'open source', 'programs', 'protein TDP-43', 'stem', 'supercomputer', 'superoxide dismutase 1', 'tool']",NINDS,BROWN UNIVERSITY,R21,2020,446875,-0.0196452557039077
"Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity PROJECT SUMMARY The long-term goal of this project is to determine whether optical coherence tomography (OCT) and OCT angiography (OCTA) might lead more accurate and objective diagnosis, earlier intervention, and improved outcomes in retinopathy of prematurity (ROP). International consensus and National Institute of Health (NIH) funded clinical trials over the last 30 years have defined the phenotypic classifications, natural history, prognosis, and management of ROP. However, it is well established that due to the subjectivity of the ophthalmoscopic examination, and systematic bias between examiners, there is significant variation in treatment of the most severe forms of ROP in the real world. This leads to both under-treatment (and poor outcomes due to retinal detachment) and over-treatment (exposing neonates to the ocular and systemic risks of treatment). Roughly 20,000 babies per year develop retinal detachments (RD) due to ROP and there is strong evidence that most of these are preventable. In adult retinal vascular diseases, most notably diabetic retinopathy (DR), OCT and OCTA can detect and quantify disease features such as diabetic macular edema (DME) and retinal neovascularization (NV) before they are noted clinically, enabling earlier treatment and reducing the risk of blindness from RD. However, evaluating the use of this technology in neonates requires high speed and portable technology, and the commercially available handheld OCTs are too slow for ultra-widefield (UWF) OCT and OCTA imaging. Several groups (including our own) have published preliminary results using prototype 100 to 200 kHz swept- source (SS) OCT systems, however consistent data acquisition remains challenging due to the lack of fixation and subsequent motion in an awake neonate, which has limited the evaluation of the potential benefits of the technology in this population. Recently, there has been much interest in using artificial intelligence (AI) (specifically deep learning), which relies on high speed graphics processing units (GPUs) to provide real time OCT image processing, segmentation, and tracking. This application addresses 2 fundamental gaps in knowledge: (1) Can we overcome the technical challenges through the development of a faster ultrawide-field view SS-OCT system coupled with a GPU-enabled DL software system to enable consistent data acquisition in neonates? (2) Would quantitative objective metrics of ROP improve objectivity of ROP diagnosis and detect subclinical signs of disease progression which may enable earlier intervention and improved outcomes in the future. By leveraging our institution’s OCT, AI, and ROP expertise, we will address these questions in three specific aims: (1) Develop an ultra-high speed, handheld, panoramic ultra-widefield OCT/OCTA system. (2) Develop real time GPU accelerated intelligent image acquisition software. (3) Evaluate the clinical significance OCT derived biomarkers. Successful translation of this technology to the ROP population could improve the accuracy and objectivity of ROP diagnosis, and lead to earlier intervention and improved outcomes in patients with severe ROP. PROJECT NARRATIVE Optical Coherence Tomography (OCT) and OCT angiography (OCTA) have proven the ability to detect subclinical disease, provide quantitative evaluation of disease progression, and improve outcomes in the leading causes of blindness in adults, age-related macular degeneration and diabetic retinopathy. Technological and practical limitations have limited the application of this technology in routine use for non-sedated children undergoing routine screening for retinopathy of prematurity (ROP), the leading cause of blindness in children. The proposed project will develop an ultra-high speed, handheld OCT system with graphics processing unit (GPU) enabled real-time processing to improve the feasibility of panoramic ultra-widefield OCT/OCTA imaging in non-sedated neonates and evaluate the clinical utility of OCT-derived biomarkers in ROP.",Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity,9943875,R01EY031331,"['Address', 'Adult', 'Aftercare', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Blindness', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Trials', 'Computer software', 'Consensus', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Disease Progression', 'Dyes', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Evaluation', 'Eye', 'Fluorescein Angiography', 'Funding', 'Fundus', 'Future', 'Goals', 'Image', 'Image Analysis', 'Injections', 'Institution', 'Intelligence', 'International', 'Knowledge', 'Lasers', 'Lead', 'Length', 'Longitudinal Studies', 'Measurement', 'Medical Imaging', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Natural History', 'Neonatal', 'Ophthalmic examination and evaluation', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Pilot Projects', 'Population', 'Primary Health Care', 'Publishing', 'Quantitative Evaluations', 'Retina', 'Retinal Detachment', 'Retinal Neovascularization', 'Retinopathy of Prematurity', 'Risk', 'Scanning', 'Severities', 'Severity of illness', 'Source', 'Speed', 'Structure', 'System', 'Systematic Bias', 'Technology', 'Testing', 'Time', 'Translations', 'United States National Institutes of Health', 'Variant', 'Vascular Diseases', 'Visualization', 'accurate diagnosis', 'arm', 'awake', 'base', 'blind', 'clinical Diagnosis', 'clinically significant', 'data acquisition', 'deep learning', 'design', 'diabetic', 'disease classification', 'disorder of macula of retina', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'instrument', 'interest', 'lens', 'macular edema', 'neonate', 'neovascularization', 'novel', 'outcome forecast', 'overtreatment', 'parallel computer', 'portability', 'prototype', 'real-time images', 'research clinical testing', 'routine screening', 'sample fixation', 'software systems', 'standard of care', 'treatment response', 'treatment risk']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,341800,-0.010688738073505327
"Developing a virtual placenta biobank Project Summary / Abstract The placenta is the first organ to develop and functions as the fetal lung, kidney, gut, skin, immune and endocrine systems. It is the cause of, and reflects changes from, most diseases in pregnancy, yet remains understudied. This career development proposal will train me in the tools and practice of digital pathology, while I apply them to the placenta with the hypothesis that there are reproducible, quantitative changes in the placenta that can be modeled and used to identify abnormalities via artificial intelligence (AI). I will create a publicly available atlas of microscopically normal placentas from throughout the 2nd and 3rd trimesters. Whole slide imaging will be performed on microscopic slides of placentas from the beginning of the 2nd trimester (13 weeks) through post-term (42 weeks). I will lead a team to annotate tissue type, structures, and cells. Algorithms will be trained to replicate the manual annotations. To study the changes in the placenta over time, automated measurements will be performed to identify changes in shape, size, and cellularity of placental structures that correlate with gestational age. This research can be used to develop a model of placental development and study prematurity. I will demonstrate detection of diseases of pregnancy, using preeclampsia (PreE) as an example. Placentas with microscopic changes classically seen in PreE will be scanned and annotated and algorithms trained and tested to identify them. Like many diseases of pregnancy, placental changes in PreE are variable and sometimes absent. Slides from PreE cases with no microscopic abnormalities will be scanned and examined using the quantitative parameters developed for normal placentas, testing the hypothesis that one or more of them will significantly differ between PreE cases and gestational age- matched controls. I am an Assistant Professor of Pathology at Northwestern University with an emerging focus in informatics and machine learning for diseases of pregnancy. The mentor for this project is Lee D.A. Cooper, PhD, an expert in digital pathology and machine learning. The co-mentor is David M. Aronoff, MD, an expert in maternal-child health. Mentor and co-mentor both have a history of NIH funding and graduating mentees to independence. The advisory committee consists of a digital pathology expert (Gutman), a pediatrician (Mestan) and a pathologist physician scientist (Yang). They have proposed an aggressive schedule of one-on-one meetings, coursework, seminars, and scientific meetings to supplement learning by doing the science. Completion of these studies will build my expertise in the application of machine learning to placental pathology while creating a new, publicly- accessible tool for the rapid assessment and understanding of organ structure and function with great potential to improve maternal-child health. Project Narrative The placenta grows over the course of gestation from a single layer of cells to a complex organ that acts as the fetal skin, lung, gut, kidney, immune system, and endocrine system. This project will develop an online repository of placenta microscopic images over the course of gestation from normal placentas and one disease of pregnancy, preeclampsia. Using artificial intelligence to quantitatively describe the changes over time in normal placentas and those with disease could help understand preterm birth and diseases of pregnancy.",Developing a virtual placenta biobank,10040733,K08EB030120,"['Advisory Committees', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Biological', 'Cells', 'Cellularity', 'Child', 'Chorion', 'Complex', 'Data', 'Decidual Cell', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Elements', 'Endocrine system', 'Endothelium', 'Event', 'Feeds', 'Fetal Lung', 'Fibrinoid necrosis', 'Funding', 'Gestational Age', 'Glass', 'Goals', 'Hematoma', 'Hemosiderosis', 'Histology', 'Histopathology', 'Human', 'Immune system', 'Infarction', 'Informatics', 'Kidney', 'Lead', 'Learning', 'Length', 'Liver', 'Lung', 'Machine Learning', 'Manuals', 'Maternal and Child Health', 'Measurement', 'Membrane', 'Mentors', 'Microscopic', 'Modeling', 'Morphology', 'Organ', 'Pathogenicity', 'Pathologic', 'Pathologist', 'Pathology', 'Physicians', 'Physiological', 'Physiology', 'Placenta', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Premature Birth', 'Radar', 'Recording of previous events', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Scanning', 'Schedule', 'Science', 'Scientist', 'Second Pregnancy Trimester', 'Shapes', 'Skin', 'Slide', 'Specimen', 'Spiral Artery of the Endometrium', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Third Pregnancy Trimester', 'Time', 'Tissues', 'Training', 'Umbilical cord structure', 'United States National Institutes of Health', 'Universities', 'Variant', 'Villous', 'Villus', 'Yang', 'algorithm training', 'biobank', 'career development', 'cell type', 'chorionic plate', 'digital', 'digital pathology', 'fetal', 'health of the mother', 'improved', 'interest', 'intrahepatic cholestasis of pregnancy', 'machine learning algorithm', 'macrophage', 'meetings', 'microscopic imaging', 'novel', 'online repository', 'pediatrician', 'premature', 'professor', 'supplemental instruction', 'tool', 'trophoblast', 'virtual', 'whole slide imaging']",NIBIB,NORTHWESTERN UNIVERSITY AT CHICAGO,K08,2020,185630,-0.020884326807284935
"Novel machine learning approaches for improving structural discrimination in cryo-electron tomography Project Summary Cellular cryo-electron tomography (Cryo-ET) has made possible the observation of cellular organelles and macromolecular complexes at nanometer resolution with native conformations. The rapid increasing amount of Cryo-ET data available however brings along some major challenges for analysis which we will timely ad- dress in this proposal. We will design novel data-driven machine learning algorithms for improving structural discrimination and resolution. In particular, we have the following speciﬁc aims: (1) We will develop a novel Autoencoder and Iterative region Matching (AIM) algorithm for marker-free alignment of image tilt-series to re- construct tomograms with improved resolution; (2) We will develop a saliency-based auto-picking algorithm for better detecting macromolecular complexes, and combine it with an innovative 2D-to-3D framework to further improve structure detection accuracy; (3) We will design an end-to-end convolutional model for pose-invariant clustering of subtomograms. This model will produce an initial clustering which will be reﬁned by a new subto- mogram averaging algorithm that automatically down-weights subtomograms of noise and little contribution; (4) We will perform experimental evaluations by using previously reported bacterial secretion systems and mito- chondrial ultrastructures datasets to improve the ﬁnal resolution. Implementing algorithms in Aims 1-3, we will develop a user-friendly open-source graphical user interface -tom to directly beneﬁt the scientiﬁc community.  -tom will be systematically compared with existing software including IMOD, EMAN2, and Relion on simulated and benchmark datasets. To facilitate distribution, -tom will be integrated into existing software platforms Sci- pion and TomoMiner. Our data-driven algorithms and software not only will facilitate and accelerate the future use of Cryo-ET, but also can be readily used on analyzing the existing large amounts of Cryo-ET data to im- prove our understanding of the structure, function, and spatial organization of macromolecular complexes in situ. Project Narrative This project will create a system of machine learning algorithms to accelerate and facilitate the use and re-use of the rapidly accumulating Cryo-ET datasets. For easy use, we will develop an open-source GUI -Tom (to be disseminated into the Scipion and TomoMiner software platforms) that streamlines the new approaches from the initial tomogram reconstruction step to the ﬁnal subtomogram averaging step. We will validate the performance of our system by applying it on published Cryo-ET datasets and monitor the improvement of the ﬁnal results.",Novel machine learning approaches for improving structural discrimination in cryo-electron tomography,9973462,R01GM134020,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Back', 'Benchmarking', 'Biological Process', 'Cells', 'Communities', 'Computer Analysis', 'Computer software', 'Cryo-electron tomography', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Discrimination', 'Evaluation', 'Future', 'Gaussian model', 'Group Structure', 'Hour', 'Image', 'In Situ', 'Knowledge', 'Laplacian', 'Literature', 'Machine Learning', 'Macromolecular Complexes', 'Manuals', 'Methods', 'Mitochondria', 'Modeling', 'Molecular Conformation', 'Monitor', 'Neurophysiology - biologic function', 'Noise', 'Organelles', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Series', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tomogram', 'Weight', 'Work', 'autoencoder', 'automated algorithm', 'base', 'deep learning', 'design', 'falls', 'feature detection', 'graphical user interface', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'nano', 'nanometer resolution', 'novel', 'novel strategies', 'open source', 'particle', 'pi-Mesons', 'programs', 'reconstruction', 'success', 'user-friendly']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2020,342970,-0.023288686543244848
"Development and Deployment of Artificial Intelligence (AI) Driven Methods to Enable Chest X-ray Radiography as an Alternative Diagnostic Method for COVID-19 Pneumonia ABSTRACT In this competitive revision, within the same scope of developing and deploying algorithms to make a quantum leap in clinical diagnosis as that in our current U01EB021183, we would like to revise the original aims to add a new Aim to leverage our expertise in the areas of algorithm development and clinical translation to make immediate contributions to combat the COVID-19 pandemic. Specifically, we propose to develop and deploy artificial intelligence (AI) methods to enable chest x-ray radiography (CXR) as an alternative diagnostic tool to diagnose COVID-19 pneumonia, to rapidly triage patients for appropriate treatment, to monitor the treatment response in a contained environment, and to optimize the distribution of the limited medical resources during the current COVID-19 crisis. PROJECT NARRATIVE In this project, our overarching objective is to develop automated artificial intelligence (AI)-based algorithms to help radiologists to differentiate COVID-19 related pneumonia from other non-COVID-19 related pneumonia using CXR images. The advantages of the proposed AI equipped CXR technique include: i) widely available, ii) inexpensive, iii) excellent coronavirus exposure profile for patient, technologist, and equipment, and iv) rapid and automated DL interpretation, which is effectively instantaneous.",Development and Deployment of Artificial Intelligence (AI) Driven Methods to Enable Chest X-ray Radiography as an Alternative Diagnostic Method for COVID-19 Pneumonia,10156179,U01EB021183,"['Accident and Emergency department', 'Air', 'Algorithms', 'American College of Radiology', 'Anosmia', 'Appearance', 'Area', 'Artificial Intelligence', 'Bilateral', 'COVID-19', 'COVID-19 pandemic', 'Case Study', 'Cessation of life', 'China', 'Clinic', 'Clinical', 'Communities', 'Containment', 'Coronavirus', 'Coughing', 'Country', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic Sensitivity', 'Diagnostic radiologic examination', 'Diarrhea', 'Disease', 'Disease Outbreaks', 'Dyspnea', 'Environment', 'Equipment', 'European', 'Exposure to', 'Fatigue', 'Fever', 'Glass', 'Gold', 'Health Personnel', 'Health care facility', 'Hospitals', 'Human', 'Image', 'Individual', 'Investigation', 'Lung', 'Lung diseases', 'Medical', 'Medical Imaging', 'Methods', 'Monitor', 'North America', 'Parents', 'Pathway interactions', 'Patient Triage', 'Patients', 'Performance', 'Persons', 'Pleural effusion disorder', 'Pneumonia', 'Process', 'Radiology Specialty', 'Reading', 'Reporting', 'Resources', 'Reverse Transcriptase Polymerase Chain Reaction', 'Rural', 'Sensitivity and Specificity', 'Societies', 'Symptoms', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Triage', 'United States', 'Viral Pneumonia', 'War', 'World Health Organization', 'X-Ray Computed Tomography', 'accurate diagnosis', 'algorithm development', 'base', 'chest computed tomography', 'clinical Diagnosis', 'clinical translation', 'combat', 'deep learning', 'high risk', 'high risk population', 'imaging facilities', 'imaging modality', 'improved', 'intelligent algorithm', 'neural network architecture', 'pandemic disease', 'prevent', 'profiles in patients', 'quantum', 'radiologist', 'screening', 'success', 'tool', 'treatment response', 'urgent care']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,U01,2020,605070,-0.009576549371039394
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9973167,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'algorithm training', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2020,383601,-0.028635669580790304
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9952370,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2020,695400,-0.011483251551786536
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9899994,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2020,416374,-0.03416532809363495
"International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020 Project summary  The Medical Image Computing and Computer Assisted Interventions (MICCAI) society is dedicated to the promotion, preservation and facilitation of research and education in the fields of medical image computing and computer assisted interventions, including biomedical imaging and robotics. This aim is achieved through the organization and operation of regular international conferences of the highest quality, and publications that promote and foster the exchange and dissemination of advanced knowledge, expertise and experience by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their origin in three separate but related conferences beginning in early 1990s--Visualization in Biomedical Computing, Computer Vision and Virtual Reality in Robotics and Medicine, and Medical Robotics and Computer Assisted Surgery--, which merged into a single annual conference in 1998. MICCAI Conferences have defined new scientific disciplines over the years and have become the premier meeting in the field. The conference proceedings have an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & medical image processing, computer-aided diagnosis, interventions & surgery, machine learning in medical imaging, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry.  The MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance). Selected presented papers became landmark publications over the years with up to 2,000 citations. The conference series includes satellite events like community-driven software challenges, workshops and tutorials just before and/or after the main conference. These events focus on the current status and advances in topics relevant to MICCAI and are very well attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendees are typically from over 45 countries, with strong student representation (>40%). The MICCAI 2020 Conference will be held in Lima, Peru in October 4th-8th, 2020. Since 2018, a Mentorship Program to connect students and young investigators with established mentors from academia and industry is also part of the conference. Along with the Mentorship Program and mission of the “Women in MICCAI” Committee, this proposal requests funds to support student and early investigator travel awards to enhance diversity in conference attendance (including women, underrepresented minorities, students with disabilities, and people from disadvantaged backgrounds) and provide minority groups with a unique opportunity to reach an international audience for career development and collaborations. Project narrative The Medical Image Computing and Computer Assisted Intervention (MICCAI) 2020 Conference will be held in Lima, Peru, October 4th-8th, 2020. MICCAI is the premier meeting in the medical image computing and computer assisted intervention communities, having introduced landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students and early investigators to present their work at MICCAI 2020--with focus on minority groups and underrepresented populations--providing them with an opportunity to attend the meeting, foster professional development and identify collaborations in an established international community.",International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020,10070479,R13EB030422,"['Academia', 'Academy', 'American', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Costs and Benefits', 'Country', 'Development', 'Disabled Persons', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority Groups', 'Mission', 'Oncology', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Peru', 'Physicians', 'Physiology', 'Policies', 'Postdoctoral Fellow', 'Psychiatry', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Robotics', 'Role', 'Scientist', 'Series', 'Societies', 'Students', 'Training', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Populations', 'United States National Institutes of Health', 'Visualization', 'Woman', 'Women&apos', 's Group', 'Work', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'community organizations', 'cost', 'disabled students', 'early-career faculty', 'experience', 'graduate student', 'image guided', 'image processing', 'imaging system', 'innovation', 'interest', 'meetings', 'operation', 'posters', 'preservation', 'programs', 'racial and ethnic', 'robotic system', 'social', 'student participation', 'success', 'supportive environment', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NIBIB,CHILDREN'S RESEARCH INSTITUTE,R13,2020,9850,-0.0005680094413513293
"Quantitative MR Imaging of Vascular Factors in Parkinsons Disease Abstract Vascular health has been shown to be an important factor in the development of neurodegenerative diseases like Alzheimer’s and Parkinson’s diseases. Hence, the ability to measure reliably and quantitatively early hemodynamic changes in the aging brain can be a powerful tool for diagnosing, studying, and developing treatments. Arterial Spin Labeling (ASL) magnetic resonance imaging can yield quantitative perfusion images without the use of contrast agents. We propose that combining new ASL techniques, such as Velocity Selective Inversion (VSI) labeling pulses and magnetic resonance fingerprinting (MRF) with deep learning regression methods will allow quantification of multiple hemodynamic parameters beyond perfusion, thus providing a much more nuanced picture of the state of the vasculature. We also expect that the new technique will offer dramatic improvements in SNR, specificity and sensitivity of ASL, and that the proposed techniques will have many other applications in research and in the clinic. We propose to use these techniques to fill the knowledge gap regarding the relationship between vascular changes and Parkinson’s disease and its symptoms, particularly fatigue, whose pathogenesis is not well understood. If we are successful in this application, future work will use the hemodynamic parameters of interest as biomarkers to assess risk of neurodegeneration, determine therapeutic targets, and guide in the development of new therapies. Public Health Statement Vascular health is an important factor in the development of neurodegenerative diseases like Alzheimer’s and Parkinson’s diseases We propose to develop a method that can produce quantifiable images of multiple blood flow related parameters with a single scan and without the use of contrast injections. We will use this method to gain a better understanding of the relationship between Parkinson’s disease and cerebral blood flow, and expect that our method will have multiple applications beside Parkinson’s disease.",Quantitative MR Imaging of Vascular Factors in Parkinsons Disease,9968566,R01NS112233,"['Address', 'Agreement', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Arteries', 'Biological', 'Biological Markers', 'Blood Vessels', 'Blood Volume', 'Blood flow', 'Bolus Infusion', 'Brain', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Contrast Media', 'Development', 'Diagnosis', 'Disease', 'Ensure', 'Etiology', 'Fatigue', 'Fingerprint', 'Future', 'Health', 'Human Volunteers', 'Hybrids', 'Image', 'Injections', 'Knowledge', 'Label', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Movement', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuronal Injury', 'Noise', 'Parkinson Disease', 'Pathogenesis', 'Pathologic', 'Patients', 'Perfusion', 'Physiologic pulse', 'Public Health', 'Reproducibility', 'Research', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Spatial Distribution', 'Spin Labels', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Validation', 'Weight', 'Work', 'aging brain', 'deep learning', 'feeding', 'hemodynamics', 'imaging biomarker', 'insight', 'interest', 'machine learning algorithm', 'neural network', 'non-invasive imaging', 'novel therapeutics', 'patient stratification', 'perfusion imaging', 'relating to nervous system', 'success', 'support vector machine', 'therapeutic target', 'tool', 'vascular factor', 'vector', 'white matter']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,348762,-0.025665643803680464
"Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions Project Summary Fluoroscopy guidance using C-arm X-ray systems is used in more than 17 million procedures across the US and constitutes the state-of-care for various percutaneous procedures, including internal ﬁxation of pelvic ring injuries. To infer procedural progress from 2D radiographs, well-deﬁned views onto anatomy must be achieved and restored multiple times during surgery. This process, known as ”ﬂuoro hunting”, is associated with 4.7 s of excessive ﬂuoroscopy time per C-arm position (c. f. 120 s total per ﬁxation), yielding radiographs that are never interpreted clinically, but drastically increasing procedure time and radiation dose to patient and surgical staff.  Our long-term project goal is to use concepts from machine learning and active vision to develop task-aware algorithms for autonomous robotic C-arm servoing that interpret intra-operative radiographs and autonomously adjust the C-arm pose to acquire ﬂuoroscopic images that are optimal for inference. We have three speciﬁc aims: 1) Detecting unfavorable K-wire trajectories from monoplane ﬂuoroscopy images: We will extend a physics-based sim- ulation framework for ﬂuoroscopy from CT that enables fast generation of structured and realistic radiographs documenting procedural progress. Based on this data, we will train a state-of-the-art convolutional neural net- work that interprets ﬂuoroscopic images to infer procedural progress. 2) Developing and validating a task-aware imaging system in silico: Using the autonomous interpretation tools and simulation pipeline available through Aim 1, we will train an artiﬁcial agent based on reinforcement learning and active vision. This agent will be capable of analyzing intra-operative ﬂuoroscopic images to autonomously adjust the C-arm pose to yield task- optimal views onto anatomy. 3) Demonstrating feasibility of our task-aware imaging concept ex vivo: Our third aim will establish task-aware C-arm imaging in controlled clinical environments. We will attempt internal ﬁxation of anterior pelvic ring fractures and our task-aware artiﬁcial agent will interpret intra-operatively acquired ra- diographs to infer procedural progress and suggest optimal C-arm poses that will be realized manually with an optically-tracked mobile C-arm system.  This work combines the expertise of a computer scientist, a surgical robotics expert, and an orthopedic trauma surgeon to explore the untapped, understudied area of autonomous imaging enabled by advances in machine learning in ﬂuoroscopy-guided procedures. This development has only recently been made feasible by innovations in fast ﬂuoroscopy simulation from CT to provide structured data for training that is sufﬁciently realistic to warrant generalization to clinical data. With support from the NIH Trailblazer Award, our team will be the ﬁrst to investigate autonomous and task-aware C-arm imaging systems, paving the way for a new paradigm in medical image acquisition, which will directly beneﬁt millions of patients by task-oriented image acquisition on a patient-speciﬁc basis. Subsequent R01 funding will customize this concept to other high-volume procedures, such as vertebroplasty. Project Narrative Fluoroscopy guidance using C-arm X-ray systems is the state-of-care for percutaneous fracture ﬁxation, and requires surgeons to achieve and reproduce well deﬁned views onto anatomy to infer procedural progress. This requirement alone is estimated to contribute 4.7 s of ﬂuoroscopy time per C-arm repositioning (c. f. 120 s total per ﬁxation), drastically increasing procedure time and radiation dose to patient and surgical team. The goal of this project is to develop machine learning-based C-arm servoing algorithms that introduce task awareness by interpreting intra-operative radiographs and autonomously adjusting the C-arm pose to task-optimal views.",Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions,9972122,R21EB028505,"['3-Dimensional', 'Age-Years', 'Algorithms', 'Anatomy', 'Anterior', 'Area', 'Artificial Intelligence', 'Assessment tool', 'Automobile Driving', 'Award', 'Awareness', 'Back', 'Bladder', 'Cadaver', 'Caring', 'Clinical', 'Clinical Data', 'Compression Fracture', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Environment', 'Exhibits', 'Expert Systems', 'Fluoroscopy', 'Fracture', 'Fracture Fixation', 'Funding', 'Generations', 'Goals', 'Image', 'Incidence', 'Injury', 'Intervention', 'Label', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Modality', 'Modernization', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Patients', 'Pelvis', 'Physics', 'Population', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Psychological reinforcement', 'Radiation Dose Unit', 'Risk', 'Robotics', 'Roentgen Rays', 'Scientist', 'Specimen', 'Structure', 'Surgeon', 'System', 'Testing', 'Time', 'Training', 'Trauma', 'United States', 'United States National Institutes of Health', 'Variant', 'Vertebral column', 'Width', 'Work', 'active vision', 'adverse outcome', 'algorithm training', 'arm', 'base', 'bone', 'convolutional neural network', 'deep learning algorithm', 'deep reinforcement learning', 'femoral artery', 'imaging modality', 'imaging system', 'improved outcome', 'in silico', 'innovation', 'learning algorithm', 'mortality', 'multitask', 'novel strategies', 'pre-clinical', 'sample fixation', 'simulation', 'spine bone structure', 'structured data', 'success', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,193784,-0.04312254497082088
"Functional and Structural Optical Coherence Tomography for Glaucoma PROJECT SUMMARY Glaucoma is a leading cause of blindness. Early diagnosis and close monitoring of glaucoma are important because the onset is insidious and the damage is irreversible. Advanced imaging modalities such as optical coherence tomography (OCT) have been used in the past 2 decades to improve the objective evaluation of glaucoma. OCT has higher axial spatial resolution than other posterior eye imaging modalities and can precisely measure neural structures. However, structural imaging alone has limited sensitivity for detecting early glaucoma and only moderate correlation with visual field (VF) loss. Using high-speed OCT systems, we have developed novel OCT angiography technologies to image vascular plexuses that supply the retinal nerve fibers and ganglion cells damaged by glaucoma. Our results showed that OCT angiographic parameters have better correlation with VF parameters. We have also found that measurement of focal and sectoral glaucoma damage using high-definition volumetric OCT angiographic and structural parameters improves diagnostic performance. The goal of the proposed project is to further improve the diagnosis and monitoring of glaucoma using ultrahigh-speed OCT and artificial intelligence machine learning techniques. The specific aims are: 1. Develop quantitative wide-field OCT angiography. We will develop a swept-source OCT prototype that  is 4 times faster than current commercial OCT systems. The higher speed will be used to fully sample the  neural structures and associated capillary plexuses damaged by glaucoma. 2. Simulate VF by combining structural and angiographic OCT. Preliminary results showed that both  structural and angiographic OCT parameters have high correlation with VF on a sector basis. It may be  possible to accurately simulate VF results by combining these parameters using an artificial neural  network. The simulated VF may be more precise and reliable than subjective VF testing. 3. Longitudinal clinical study in glaucoma diagnosis and monitoring. Our novel OCT structural and  angiographic parameters have high accuracy in diagnosing glaucoma. Neural network analysis of structural  and angiographic data from a larger clinical study could further improve diagnostic accuracy. Longitudinal  follow-up will assess if simulated VF could monitor disease progression as well as actual VF. 4. Clinical study to assess the effects of glaucoma treatments. Preliminary results suggest that OCT  angiography could detect the improvement in capillary density after glaucoma surgery and the effects of  drugs. These intriguing effects will be tested in before-and-after comparison studies. If successful, we will have an OCT diagnostic system that in minutes provides objective information on the location and severity of glaucoma damage. This approach could replace time-consuming and unreliable VF testing. Measuring the improvement in retinal circulation could be a quicker way to detect the benefit of glaucoma therapies that work through neuroprotection or regeneration, compared to monitoring VF. PROJECT NARRATIVE Optical coherence tomography is a high-resolution imaging technology that can non-invasively measure both the eye structures and small blood vessels that are damaged by glaucoma, a leading cause of blindness. The proposed research will further improve this technology so that it can provide detailed measurement over wider areas inside the eye, detect earlier stages of glaucoma, evaluate the location and severity of glaucoma damage, monitor disease progression, and provide more timely assessment of the effectiveness of therapy. A goal of this project is to determine if this objective imaging technology can provide information that is equivalent to or better than subjective visual field testing, which though time-consuming and poorly reliable, is the current gold standard for long-term monitoring and management of glaucoma.",Functional and Structural Optical Coherence Tomography for Glaucoma,9952373,R01EY023285,"['Abbreviations', 'Affect', 'Angiography', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Biomedical Engineering', 'Blindness', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Clinical', 'Clinical Research', 'Complex', 'Computer software', 'Consumption', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Effectiveness', 'Evaluation', 'Eye', 'Eyedrops', 'Functional disorder', 'Future', 'Geography', 'Glaucoma', 'Glossary', 'Goals', 'Gold', 'Grant', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Lasers', 'Location', 'Longitudinal observational study', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Monitor', 'Natural regeneration', 'Nerve Fibers', 'Noise', 'Operative Surgical Procedures', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Pathway Analysis', 'Patients', 'Performance', 'Perfusion', 'Pharmaceutical Preparations', 'Physiologic Intraocular Pressure', 'Postoperative Period', 'Research', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal macula', 'Role', 'Safety', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Shunt Device', 'Signal Transduction', 'Source', 'Speed', 'Staging', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trabeculectomy', 'Variant', 'Vision', 'Visit', 'Visual Fields', 'Work', 'analytical tool', 'artificial neural network', 'base', 'bulk motion', 'cell injury', 'clinical practice', 'cost', 'density', 'diagnostic accuracy', 'fiber cell', 'field study', 'follow-up', 'ganglion cell', 'glaucoma surgery', 'high resolution imaging', 'high risk', 'imaging modality', 'improved', 'innovation', 'insight', 'macula', 'neural network', 'neuroprotection', 'new technology', 'novel', 'prototype', 'quantitative imaging', 'relating to nervous system', 'retina circulation', 'screening', 'tool', 'treatment effect', 'vascular factor', 'visual performance']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,564228,-0.013645371831079521
"Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit SUMMARY  Many of the estimated four million adults in the U.S. with severe speech and physical impairments (SSPI) resulting from neurodevelopmental or neurodegenerative diseases cannot rely on current assistive technologies (AT) for communication. During a single day, or as their disease progresses, they may transition from one access technology to another due to fatigue, medications, changing physical status, or progressive motor dysfunction. There are currently no clinical or AT solutions that adapt to the multiple, dynamic access needs of these individuals, leaving many people poorly served. This competitive renewal, called BCI-FIT (Brain Computer Interface-Functional Implementation Toolkit) adds to our innovative multidisciplinary translational research conducted over the past 11 years for the advancement of science related to non-invasive BCIs for communication for these clinical populations. BCI-FIT relies on active inference and transfer learning to customize a completely adaptive intent estimation classifier to each user's multiple modality signals in real-time. The BCI-FIT acronym has many implications: our BCI fits to each user's brain signals; to the environment, offering relevant personal language; to the user's internal states, adjusting signals based on drowsiness, medications, physical and cognitive abilities; and to users' learning patterns from BCI introduction to expert use.  Three specific aims are proposed: (1) Develop and evaluate methods for optimizing system and user performance with on-line, robust adaptation of multi-modal signal models. (2) Develop and evaluate methods for efficient user intent inference through active querying. (3) Integrate language interaction and letter/word supplementation as input modalities in real-time BCI use. Four single case experimental research designs will evaluate both user performance and technology performance for functional communication with 35 participants with SSPI in the community, and 30 healthy controls for preliminary testing. The same dependent variables will be tested in all experiments: typing accuracy (correct character selections divided by total character selections), information transfer rate (ITR), typing speed (correct characters/minute), and user experience (UX) questionnaire responses about comfort, workload, and satisfaction. Our goal is to establish individualized recommendations for each user based on a combination of clinical and machine expertise. The clinical expertise plus user feedback added to active sensor fusion and reinforcement learning for intent inference will produce optimized multi-modal BCIs for each end-user that can adjust to short- and long-term fluctuating function. Our research is conducted by four sub-teams who have collaborated successfully to implement translational science: Electrical/computer engineering; Neurophysiology and systems science; Natural language processing; and Clinical rehabilitation. The project is grounded in solid machine learning approaches with models of participatory action research and AAC participation. This project will improve technologies and BCI technical capabilities, demonstrate BCI implementation paradigms and clinical guidelines for people with severe disabilities. PROJECT NARRATIVE The populations of US citizens with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies, as proposed in BCI-FIT. This project implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit,10044301,R01DC009834,"['Adult', 'Attention', 'Behavioral', 'Brain', 'Calibration', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communication', 'Communities', 'Computers', 'Custom', 'Data', 'Decision Making', 'Disease', 'Drowsiness', 'Electroencephalography', 'Engineering', 'Environment', 'Eye Movements', 'Fatigue', 'Feedback', 'Goals', 'Guidelines', 'Head Movements', 'Impairment', 'Individual', 'Informed Consent', 'Knowledge', 'Language', 'Learning', 'Letters', 'Life', 'Locked-In Syndrome', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Motor Skills', 'Movement', 'Muscle', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Participant', 'Partner Communications', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Population', 'Protocols documentation', 'Psychological Transfer', 'Psychological reinforcement', 'Public Health', 'Questionnaires', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Design', 'Role', 'Science', 'Secondary to', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Solid', 'Source', 'Speech', 'Speed', 'Supplementation', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vocabulary', 'Workload', 'acronyms', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinical implementation', 'cognitive ability', 'community based participatory research', 'computer science', 'disability', 'experience', 'experimental study', 'improved', 'innovation', 'learning strategy', 'motor disorder', 'multidisciplinary', 'multimodality', 'neurophysiology', 'phrases', 'residence', 'response', 'satisfaction', 'sensor', 'signal processing', 'simulation', 'spelling', 'theories', 'visual tracking']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,929399,-0.041436731769124525
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9929633,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2020,1011405,-0.012419495831713952
"Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis Project Summary Blood culture sensitivity in neonates is poor but is the “Gold Standard” for the diagnosis of sepsis. Universal genotyping of pathogen genomic sequences using High Resolution Melt (U-HRM) provides a simple, low cost, rapid, and modern alternative to blood culture testing. By measuring the fluorescence of an intercalating dye as PCR-amplified pathogen DNA fragments are heated and disassociate, sequence defined melt curves are generated with single-nucleotide resolution in a closed-tube reaction. We have advanced U- HRM into a digital PCR format (U-dHRM), where DNA sequences that are present in mixtures are individually amplified and identified as is needed for polymicrobial infections. We have also established unique signature melt curves for 37 bacterial species that commonly infect older children and adults and automatically identify them using machine learning technology. With the goal of creating an accurate and valid test for the timely diagnosis of neonatal sepsis, we will advance this technology to identify unique fungal, viral, and bacterial HRM signatures along with antibiotic resistance genes with an accuracy of 99-100% on minimal blood volume (1mL). Our aims are: Aim 1. Optimize and assess the U-dHRM platform for neonatal bacteremia diagnosis by expand our bacterial database (13 additional bacteria) to detect causes of >99% of neonatal bacterial infections, expand our antibiotic resistance gene database to include five clinically actionable genes, and assessing the performance of the system for bacteremia diagnosis in mock and clinical whole blood samples; Aim 2. Advance the U-dHRM platform for simultaneous detection of fungal and viral pathogens by upgrading our optical system to enable expansion to fungal and viral detection in a high-throughput format, multiplexing the assay to expand to viral and fungal pathogens causing >99% non-bacterial infections, and conducting analytical validation of the multiplexed platform using mock whole blood samples; and Aim 3. Advance the machine learning algorithm for detection of emerging pathogens by developing and integrating an anomaly detection algorithm for reporting emerging pathogens that are not included in our database and validating the algorithm using data generated in Aims 1 and 2. Thus, this proposal directly addresses the funding call by applying a multidisciplinary approach to overcome the biomedical challenge of rapidly diagnosis sepsis, a hidden public health disaster. Project Narrative Digital High Resolution Melting (dHRM) of DNA combined with machine learning creates unique “fingerprints"" for microbes and antibiotic resistance, allowing for faster and more precise detection and treatment of pathogen(s) causing sepsis. This project will advance and test the clinical performance of dHRM technology in the diagnosis of neonatal sepsis. Our goal is to rapidly and accurately identify pathogens and their resistance markers to facilitate accurate antimicrobial therapy, reducing antibiotic overuse in non-infected infants.",Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis,9915874,R01AI134982,"['Address', 'Adult', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Biological Assay', 'Birth Weight', 'Blood', 'Blood Volume', 'Blood specimen', 'Child', 'Clinical', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disasters', 'Dyes', 'Emerging Technologies', 'Exposure to', 'Fingerprint', 'Fluorescence', 'Funding', 'Genes', 'Genome', 'Genotype', 'Goals', 'Gold', 'Hour', 'Immune response', 'Individual', 'Infection', 'Machine Learning', 'Measures', 'Microbe', 'Modernization', 'Neonatal', 'Nucleotides', 'Optics', 'Organism', 'Patients', 'Performance', 'Predisposition', 'Public Health', 'RNA', 'Reaction', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Sampling', 'Sepsis', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tube', 'United States', 'Validation', 'Variant', 'Very Low Birth Weight Infant', 'Viral', 'Whole Blood', 'Woman', 'antimicrobial', 'base', 'circulating DNA', 'clinically actionable', 'clinically relevant', 'cost', 'diagnosis standard', 'digital', 'early onset', 'interdisciplinary approach', 'intrapartum', 'machine learning algorithm', 'melting', 'microbial', 'neonatal sepsis', 'neonate', 'overtreatment', 'pathogen', 'pathogen genome', 'pathogen genomics', 'pathogenic fungus', 'pathogenic virus', 'point of care', 'premature', 'rapid diagnosis', 'resistance gene', 'sample collection', 'septic', 'therapy resistant', 'viral detection']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,486161,-0.023811475882947547
"Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1 Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at certain stages of the disease severity spectrum, specifically in the early stage and in advanced disease. These difficulties are due to a variety of causes that change over the course of the disease, including large between-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we build on our long-standing contribution to ocular imaging and propose novel and sensitive means to detect glaucoma and its progression that are optimized to the various stages of disease severity. We will use information gathered from visual fields (functional information) and a leading ocular imaging technology – optical coherence tomography (OCT; structural information) to map the capability of detecting changes across the entire disease severity spectrum to identify optimal parameters for each stage of the disease. Both commonly used parameters provided by the technologies and newly developed parameters with good diagnostic potential will be analyzed. We will use state-of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. We will also utilize a new imaging technology, the visible light OCT, to generate retinal images with outstanding resolution to extract information about the oxygen saturation of the tissue. This will provide in-vivo, real time, and noninvasive insight into tissue functionality. Taken together, this program will advance the use of structural and functional information with a substantial impact on the clinical management of subjects with glaucoma Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies that will substantially improve detection of glaucoma and its progression monitoring in order to prevent blindness.",Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1,10019553,R01EY013178,"['3-Dimensional', 'Blindness', 'Characteristics', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Data', 'Detection', 'Development', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Floor', 'Future', 'Glaucoma', 'Health', 'Human', 'Image', 'Imaging technology', 'Inner Plexiform Layer', 'Knowledge', 'Laboratories', 'Lead', 'Light', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Oxygen Consumption', 'Oxygen saturation measurement', 'Pathology', 'Research Proposals', 'Resolution', 'Retina', 'Retinal Diseases', 'Scanning', 'Severities', 'Severity of illness', 'Signal Transduction', 'Source', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Technology', 'Thick', 'Time', 'Tissue Extracts', 'Tissues', 'Translating', 'Visible Radiation', 'Vision', 'Visual Fields', 'Width', 'advanced disease', 'analytical method', 'base', 'clinical practice', 'cohort', 'computerized', 'deep learning', 'density', 'ganglion cell', 'improved', 'in vivo', 'innovation', 'innovative technologies', 'insight', 'instrument', 'invention', 'knowledge base', 'longitudinal dataset', 'machine learning method', 'macula', 'mathematical methods', 'new technology', 'novel', 'novel strategies', 'ocular imaging', 'preservation', 'prevent', 'programs', 'research study', 'retinal imaging', 'retinal nerve fiber layer', 'tissue oxygenation', 'tool']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,687519,-0.02374239093224695
"Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques PROJECT SUMMARY Symptomatic urinary stone disease (USD) affects >8% of the United States population, resulting in an estimated annual medical cost exceeding $10 billion. Computed tomography (CT) is the established method for imaging urinary calculi and can provide accurate sub-millimeter details of the size and location of renal stones. However, in vivo characterization of more than just size and location is critical for quantifying stone characteristics important for optimal patient health management and essential for clinical research. A complete characterization of renal stones, including stone composition and fragility, is needed for safe and cost effective management of USD, as well as for phenotyping of research subjects. Our proposal meets these needs by developing methods to accurately and non-invasively characterize stones using low-dose, multi-energy CT. Our long-term goal is to use advanced CT methodologies to characterize urinary calculi for the purpose of directing clinical treatment and facilitating clinical investigation. Our objectives in this application are to develop and validate in vivo quantitative techniques for characterizing mixed and non-uric-acid stone types, as well as for predicting the likelihood of successful stone comminution, a novel concept we refer to as stone fragility. These image-based stone biometrics will enable evidence-based identification of treatment strategies that maximize effectiveness while minimizing risk, as well as accurate and non-invasive classification of research subjects to accelerate scientific advances in the understanding and treatment of USD. We will meet these objectives by accomplishing the following specific aims:  Specific Aim 1: Develop and validate CT techniques to characterize mixed and non-uric-acid  stone types.  Specific Aim 2: Develop and validate CT techniques to predict stone fragility. Current state-of-the-art stone imaging technology cannot accurately identify the composition of mixed and non- uric-acid stone types, nor can it provide quantitative indications of the likelihood of efficient comminution using the lowest risk technique. The innovation of this proposal lies in the use of newly developed statistical, deep learning and texture analysis techniques to quantitatively describe essential characteristics of urinary calculi, namely composition and fragility. The significance of this proposal is that the knowledge derived from using such techniques represents unique quantitative biomarkers that will allow physicians and researchers to more effectively manage and study USD. The developed methods respond to critical needs in the field of stone disease and will advance the ability of physicians to optimally direct patient therapy and scientists to phenotype research subjects. PROJECT NARRATIVE This proposal will develop imaging techniques that can determine urinary stone composition and fragility in patients. The significance of this is that these advanced CT imaging techniques will allow physicians to more efficiently direct patient therapy and perform clinical research, potentially avoiding procedures associated with higher risk or cost.","Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques",9936447,R01EB028591,"['Affect', 'Alkalies', 'Bilateral', 'Biological Markers', 'Biometry', 'Calcium Oxalate', 'Characteristics', 'Classification', 'Clinical Research', 'Clinical Treatment', 'Cost Effective Management', 'Coupled', 'Data', 'Disease', 'Dose', 'Economic Burden', 'Effectiveness', 'Excision', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury to Kidney', 'Kidney Calculi', 'Knowledge', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Minerals', 'Morphology', 'Outcome', 'Patients', 'Percutaneous Nephrolithotomy', 'Phenotype', 'Physicians', 'Population', 'Prevalence', 'Procedures', 'Publishing', 'Recovery', 'Research', 'Research Personnel', 'Research Subjects', 'Resolution', 'Risk', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Shapes', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'United States', 'Ureteroscopy', 'Uric Acid', 'Urinary Calculi', 'Validation', 'X-Ray Computed Tomography', 'attenuation', 'base', 'calcium phosphate', 'clinical investigation', 'cost', 'deep learning', 'evidence base', 'health management', 'high risk', 'imaging modality', 'in vivo', 'innovation', 'learning strategy', 'novel', 'photon-counting detector', 'prevent', 'risk minimization', 'statistical learning', 'treatment strategy']",NIBIB,MAYO CLINIC ROCHESTER,R01,2020,357486,-0.029406737524538807
"SBIR Phase I- Topic 410 - Cancer Clinical Trials Recruitment and Retention Tools for Participant Engagement.  Many clinical trials fail to meet their accrual and retention goals, which leads to delays, early termination, or inability to draw conclusions at trial completion due to loss of statistical power. NCI wants to enhance clinical trials recruitment and retention by developing tools that could enhance communication between participants and study staff. In this Phase 1 tool development application we address the NCI interest in simplified informed consent documents that enhance personal communication during the informed consent process. In this Phase I proposal we leverage natural language processing technology and our teams prior work on the Informed Consent Ontology (ICO) to improve the language in consent documents related specifically to permissions granted by a research participant. n/a",SBIR Phase I- Topic 410 - Cancer Clinical Trials Recruitment and Retention Tools for Participant Engagement. ,10265762,5N91020C00017,"['Address', 'Authorization documentation', 'Clinical Trials', 'Communication', 'Comprehension', 'Consent Forms', 'Goals', 'Grant', 'Health', 'Informed Consent', 'Language', 'Natural Language Processing', 'Ontology', 'Participant', 'Personal Communication', 'Phase', 'Process', 'Research', 'Small Business Innovation Research Grant', 'Technology', 'Work', 'base', 'cancer clinical trial', 'improved', 'interest', 'prototype', 'recruit', 'tool', 'tool development', 'user-friendly']",NCI,"MELAX TECHNOLOGIES, INC.",N43,2020,400000,-0.057572695918335345
"Leveraging Neural Imaging for Automated Neonatal Infection Diagnosis PROJECT SUMMARY/ABSTRACT Post-infectious hydrocephalus (PIH) is a leading cause of neonate mortality in the developing world, but there are limited resources in place for appropriately diagnosing and monitoring the infections that lead to hydrocephalus. There is often a lack of personnel and laboratory resources available for the gathering and processing of lumbar puncture and blood cultures, which are the gold-standard for diagnosing the infectious agents at play in sepsis and PIH. In order to overcome this obstacle, CSF and blood samples were taken from a cohort of septic neonates in Mbale, Uganda, as well as a cohort of neonates and infants who had already progressed to PIH. Cranial ultrasounds (CrUS) were taken from the cohort of septic neonates, and head CT scans were gathered from the PIH cohort. This proposal hypothesizes that the pathogens determined from RNA and DNA sequencing of the blood and CSF samples can be used to train supervised machine learning algorithms to recognize imaging phenotypes characteristic of the underlying pathogen. Therefore, PIH can be prevented by providing pathogen-specific diagnosis and targeted treatment recommendations at the bedside for septic neonates using CrUS. Furthermore, surgical treatment success for PIH can be optimized using CT for the purpose of identifying the underlying pathogen and providing management plan recommendations. This project provides an ideal training environment for a fellow interested in pediatric neurosurgery with a research emphasis on engineering and machine learning applied to image analysis. The interdisciplinary and global nature of the project encourages development of a collaborative and innovative research approach. The home institution of Penn State provides multiple clinical opportunities for growth in pediatric neurosurgery, the MD/PhD program is supportive of truly translational research efforts, and the sponsor and co-sponsor are more than adequately prepared to provide all aspects of training mentorship necessary to accomplish the aims of this project and develop a well-rounded physician-scientist. PROJECT NARRATIVE Post-infectious hydrocephalus is a devastating condition with a global impact, but diagnostic options and available treatment plans are limited in the developing world in particular. This project aims to design machine learning algorithms that leverage cranial ultrasound and head CT for the diagnosis of pathogen-specific sepsis and hydrocephalus in neonates, and propose treatment paradigms based on the diagnostic output.",Leveraging Neural Imaging for Automated Neonatal Infection Diagnosis,10066656,F30HD102120,"['Africa', 'Africa South of the Sahara', 'Anti-Bacterial Agents', 'Antiviral Agents', 'Artificial Intelligence', 'Blood', 'Blood specimen', 'Brain', 'Caregivers', 'Cauterize', 'Central Nervous System Infections', 'Cephalic', 'Cerebrospinal Fluid', 'Cessation of life', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Cognitive', 'Communicable Diseases', 'Coupled', 'DNA sequencing', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease Management', 'Doctor of Philosophy', 'Endocrine', 'Engineering', 'Environment', 'Evaluation', 'Failure', 'Functional disorder', 'Goals', 'Gold', 'Growth', 'Head', 'Healthcare Systems', 'Home environment', 'Human Resources', 'Hydrocephalus', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Infant', 'Infection', 'Infectious Agent', 'Institution', 'Laboratories', 'Lead', 'Learning', 'Machine Learning', 'Mentorship', 'Microbiology', 'Monitor', 'Nature', 'Neonatal', 'Nervous system structure', 'Neuraxis', 'Operative Surgical Procedures', 'Output', 'Pathogenicity', 'Pathologic', 'Patients', 'Pattern', 'Phenotype', 'Physicians', 'Play', 'Prevention', 'Procedures', 'Protocols documentation', 'Recommendation', 'Research', 'Resources', 'Sampling', 'Scientist', 'Secondary to', 'Sepsis', 'Shunt Device', 'Spinal Puncture', 'Structure of choroid plexus', 'Survivors', 'Technology', 'Time', 'Training', 'Translational Research', 'Uganda', 'Ultrasonography', 'Ventriculostomy', 'Work', 'X-Ray Computed Tomography', 'base', 'cerebrospinal fluid flow', 'cohesion', 'cohort', 'design', 'diagnosis standard', 'disease classification', 'genome sequencing', 'hands-on learning', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'machine learning algorithm', 'mortality', 'neonatal infection', 'neonatal sepsis', 'neonate', 'neurosurgery', 'non-invasive imaging', 'optimal treatments', 'pathogen', 'prevent', 'programs', 'relating to nervous system', 'septic', 'success', 'supervised learning', 'targeted treatment', 'transcriptome sequencing', 'treatment planning', 'treatment strategy']",NICHD,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,F30,2020,32183,-0.017825071274276346
"Validation of a lab-free low-cost screening test for prevention of cervical cancer: automated visual evaluation PROJECT SUMMARY/ABSTRACT Artificial intelligence (AI) has the potential to revolutionize medicine by improving productivity, reducing human error, and assisting with diagnosis and treatment. Image classification algorithms can be used to develop automated visual evaluation (AVE): a potential game-changer for cervical cancer prevention in low- and middle-income countries (LMICs). AVE technology reads digital photographs of a cervix to provide diagnosis and treatment recommendations in seconds. AVE is a true point of care test, low cost and does not require a laboratory. AVE could be used either for stand-alone primary screening, or to triage HPV-positive women. We will compare AVE to common screening methods in LMICs: visual inspection with acetic acid (VIA) and conventional cytology. Enhanced Visual Assessment (EVA) System by MobileODT is a cloud-connected mobile colposcope on a smartphone platform. It is FDA cleared and used in 42 countries. MobileODT is uniquely poised to integrate AVE into the EVA System. Our aim is to validate and commercialize AVE on the EVA platform. Phase I aims will adapt AVE to run on the EVA system using an optimal neural network architecture, running either directly on the phone or as a cloud- based service. Phase II is a prospective clinical trial of 10,000 patients recruited at ministry of health sites in El Salvador. All screen-positive patients, and 10% of negative patients, will undergo colposcopy with biopsy. Sensitivity of AVE as a primary screening test will be compared to cytology and to VIA. In HPV-positive women, AVE will be compared to VIA as a triage test. PROJECT NARRATIVE The proposal involves developing and testing a cervical cancer screening test: automated visual evaluation (AVE) based on an image classification algorithm that runs on smartphone-based colposcope. Included are both technical development to integrate AVE to a mobile phone application (Phase I), and a prospective validation on a screening population of 10,000 women in El Salvador (Phase II). AVE will be compared to standard tests (conventional cytology and visual inspection with acetic acid: VIA) for primary screening, and against VIA triage in an HPV+ population.",Validation of a lab-free low-cost screening test for prevention of cervical cancer: automated visual evaluation,10008280,R44CA247137,"['Acetic Acids', 'Address', 'Algorithm Design', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Bedside Testings', 'Biopsy', 'Car Phone', 'Cellular Phone', 'Cervical', 'Cervical Cancer Screening', 'Cervical Intraepithelial Neoplasia', 'Cervix Uteri', 'Clinical', 'Clinical Trials', 'Colposcopes', 'Colposcopy', 'Country', 'Cytology', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Documentation', 'El Salvador', 'Guidelines', 'HPV-High Risk', 'Health', 'Histology', 'Histopathology', 'Human Papillomavirus', 'Image', 'Internet', 'Laboratories', 'Medicine', 'Methods', 'Oncogenic', 'Patient Recruitments', 'Patients', 'Pattern', 'Performance', 'Phase', 'Population', 'Predictive Value', 'Prevention', 'Productivity', 'Provider', 'ROC Curve', 'Receiver Operating Characteristics', 'Recommendation', 'Resources', 'Running', 'Sampling', 'Screening procedure', 'Services', 'Site', 'Speed', 'System', 'Technology', 'Telephone', 'Testing', 'Triage', 'Validation', 'Visual', 'Woman', 'World Health Organization', 'automated visual evaluation', 'base', 'cervical cancer prevention', 'classification algorithm', 'cloud based', 'cost', 'data quality', 'deep learning algorithm', 'digital', 'human error', 'improved', 'innovation', 'low and middle-income countries', 'mobile application', 'neural network', 'neural network architecture', 'overtreatment', 'phase II trial', 'primary endpoint', 'product development', 'programs', 'prospective', 'quality assurance', 'screening', 'screening program', 'secondary analysis', 'secondary endpoint', 'tool']",NCI,"MOBILEODT, INC.",R44,2020,297844,-0.04380712027773003
"Objective Quantification of Neural Damage for Screening, Diagnosis and Monitoring of Glaucoma with Fundus Photographs PROJECT SUMMARY Glaucoma is a progressive optic neuropathy and the leading cause of irreversible blindness in the world. As the disease remains largely asymptomatic until late stages, there is a pressing need to develop affordable approaches for screening before visual impairment occurs. Although sophisticated imaging technologies such as Spectral domain-optical coherence tomography (SDOCT) can provide highly reproducible and accurate quantitative assessment of glaucomatous damage, their application in widespread screening or non-specialized settings is unfeasible, given the high cost and operator requirements. Fundus photography is a low-cost alternative that has been used successfully in teleophthalmology programs. However, subjective human grading of fundus photos for glaucoma is poorly reproducible and highly inaccurate, as gradings tend to largely over- or underestimate damage. We propose a new paradigm for assessing glaucomatous damage by training a deep learning (DL) convolutional neural network to provide quantitative estimates of the amount of neural damage from fundus photographs. In our Machine-to-Machine (M2M) approach, we trained a DL network to analyze fundus photos and predict quantitative measurements of glaucomatous damage provided by SDOCT, such as retinal nerve fiber layer (RNFL) thickness and neuroretinal rim measurements. Our preliminary results showed that the M2M predictions have very high correlation and agreement with the original SDOCT observations. This provides an objective method to quantify neural damage in fundus photos without requiring human graders, which could potentially be used for screening, diagnoses and monitoring in teleophthalmology and non- specialized point-of-care settings. In this proposal, we aim at refining and validating the M2M model in suitable, large datasets from population-based studies, electronic medical records, and clinical trial data. Our central hypothesis is that the M2M approach will be more accurate than subjective human gradings in screening, diagnosing, predicting and detecting longitudinal damage over time. In Aim 1, we will investigate the performance of the M2M model to screen for glaucomatous damage using large datasets from 6 population-based studies: Blue Mountains Eye Study, Los Angeles Latino Eye Study, Tema Eye Survey, Beijing Eye Study, Central India Eye and Medical Study and the Ural Eye and Medical Study, which will provide data on over 25,000 subjects of diverse racial groups. In Aim 2, we will investigate the ability of the M2M model to predict future development of glaucoma in eyes of suspects using the data from the Ocular Hypertension Treatment Study (OHTS). In Aim 3, we will investigate the ability of the M2M model in detecting glaucomatous progression over time using data from the Duke Glaucoma Registry, a large database of longitudinal structure and function data in glaucoma with over 25,000 patients followed over time. If successful, this proposal will lead to a validated, inexpensive, and widely applicable tool for screening, early diagnosis and monitoring of glaucoma, that could be applied under population-based settings and also at non-specialized point-of-care settings. Project Narrative Glaucoma is a leading cause of irreversible visual impairment in the world. This proposal will employ a novel artificial intelligence paradigm for quantifying neural damage on ocular fundus photographs for the purpose of screening, diagnosing and monitoring glaucoma damage. The approach will be validated on large datasets from population-based studies, electronic medical records and clinical trial data.","Objective Quantification of Neural Damage for Screening, Diagnosis and Monitoring of Glaucoma with Fundus Photographs",10047364,R21EY031898,"['Agreement', 'Artificial Intelligence', 'Blindness', 'Clinical Trials', 'Computerized Medical Record', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Exhibits', 'Eye', 'Eye diseases', 'Fundus', 'Fundus photography', 'Future', 'Glaucoma', 'Human', 'Imaging technology', 'India', 'Investigation', 'Label', 'Latino', 'Los Angeles', 'Manuals', 'Measurement', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Names', 'Nature', 'Ocular Hypertension', 'Ophthalmology', 'Optical Coherence Tomography', 'Output', 'Patients', 'Performance', 'Population Study', 'Race', 'Reference Standards', 'Registries', 'Reproducibility', 'Risk', 'Science', 'Screening procedure', 'Structure', 'Surveys', 'Testing', 'Thick', 'Time', 'Training', 'Validation', 'Visual impairment', 'algorithm training', 'clinical care', 'convolutional neural network', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'deep neural network', 'flexibility', 'hypertension treatment', 'intelligent algorithm', 'interest', 'large datasets', 'learning network', 'longitudinal database', 'novel', 'optic nerve disorder', 'point of care', 'population based', 'predictive modeling', 'programs', 'racial diversity', 'relating to nervous system', 'retinal nerve fiber layer', 'screening', 'time use', 'tool']",NEI,DUKE UNIVERSITY,R21,2020,241500,-0.026998477849853295
"Automatic Rib Fracture Detection in Pediatric Radiography to Identify Non-Accidental Trauma ABSTRACT Automatic Rib Fracture Detection in Pediatric Radiography to Identify Non-Accidental Trauma PI: Adam M. Alessio Non-accidental trauma caused by physical abuse is a leading cause of death in children in the United States. Because rib fractures are highly predictive of child abuse and chest radiographs are commonly performed for multiple indications, pediatric chest radiographs can have a critical role in the identification of abuse. Detection of rib fractures on pediatric radiographs is challenging and a high percentage of fractures are missed, particularly in imaging centers with limited pediatric radiology experience. Currently, there are no viable computer assisted strategies for rib fracture detection on chest radiographs. The purpose of this proposal is to develop machine learning methodology to detect rib fractures on pediatric radiographs using images from a network of hospitals. These methods will rely on a two-stage approach including a thoracic cavity segmentation stage followed by a fracture detection stage. We will explore two fracture detection strategies using novel supervised learning approaches: a heterogeneous U-net and a multi-modal regional-convolutional neural network. These methods will be trained and tested with a large set of fracture-absent radiographs (N=1000) from Seattle Children's Hospital and a diverse set of labelled fracture-present radiographs (N=500) from collaborating sites. These methods will be developed with an intentionally diverse set of radiographs, representative of the variety of fracture presentations and image quality in clinical practice, in order to position this rib fracture detection method for rapid translation to clinical practice. The ultimate goal of this proposal is to provide a computer assisted rib fracture assessment tool that would be a rapid and widely-available add-on to all pediatric chest radiograph exams, improving detection of rib fractures and potentially leading to improved identification of child abuse. NARRATIVE Automatic Rib Fracture Detection in Pediatric Radiography to Identify Non-Accidental Trauma PI: Adam M. Alessio Child abuse is a leading cause of death in children and rates of abuse are increasing. Detection of rib fractures on commonly performed chest radiographs has the potential to identify unsuspected child abuse, but it is very challenging to see fractures on these exams. This work proposes a computer assisted strategy to help radiologists detect rib fractures on pediatric chest radiographs, which may lead to improved identification of child abuse.",Automatic Rib Fracture Detection in Pediatric Radiography to Identify Non-Accidental Trauma,9976563,R21HD097609,"['Assessment tool', 'Cause of Death', 'Cessation of life', 'Chest', 'Child', 'Child Abuse', 'Childhood', 'Clinical', 'Computer Assisted', 'Data', 'Detection', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Face', 'Fracture', 'Goals', 'Hospitals', 'Image', 'Image Analysis', 'Infant', 'Injury', 'Institutional Review Boards', 'Label', 'Lead', 'Lung', 'Machine Learning', 'Mediastinal', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Non-accidental', 'Outcome', 'Patient imaging', 'Pediatric Hospitals', 'Pediatric Radiology', 'Performance', 'Population', 'Positioning Attribute', 'Respiratory Diaphragm', 'Rib Fractures', 'Role', 'Sentinel', 'Site', 'Structure', 'Supervision', 'Testing', 'Thoracic cavity structure', 'Time', 'Training', 'Translations', 'Trauma', 'United States', 'Vendor', 'Work', 'bone', 'child physical abuse', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'detector', 'experience', 'follow-up', 'hands-on learning', 'imaging platform', 'imaging study', 'improved', 'machine learning method', 'mortality', 'multimodality', 'novel', 'patient population', 'physical abuse', 'radiologist', 'rapid technique', 'rib bone structure', 'soft tissue', 'supervised learning', 'tool']",NICHD,MICHIGAN STATE UNIVERSITY,R21,2020,178149,-0.03998557434485583
"A New Tool to Rapidly Diagnose Sepsis using Flow Imaging Microscopy and Machine Learning Project Summary  Sepsis is a serious condition induced by an infection, often by a bacterial pathogen, leading to organ damage or even death. Despite numerous advances in medicine over the years, the condition still affects millions of people in both developed and developing countries. In the US, sepsis affects 1.7M and kills over 265,000 people annually. Sepsis mortality rates in developing countries are substantially higher. In terms of demographics, sepsis affects humans of all age and race, but it is most pronounced at the age extremes (infants and the elderly) and patients whose immune system is already under strain due to other illnesses or immune system-weakening therapies, e.g., cancer patients undergoing chemotherapy.  Blood cultures are currently the default technique used in detecting and diagnosing the root cause of sepsis. However, blood-cultures can take upwards of 24-48 hours in order to obtain results. In that time, the patient can experience irreversible harm due to the condition if not treated properly. Unfortunately, precise and effective antibiotic treatment requires knowledge of the pathogen causing sepsis. Beyond a long time to get an answer, blood cultures often exhibit alarmingly high false negatives (failure to detect a pathogen causing sepsis) and typically do not precisely identify the pathogen causing sepsis.  Hence there have been several efforts aimed at detecting and identifying the broad range of potential pathogens causing sepsis and circumventing the need for blood cultures. However, many of the recently proposed methods for detecting and diagnosing sepsis exhibit one or more of the following drawbacks: (i) they lack high sensitivity (ability to detect a pathogen); (ii) they cannot accurately identify a broad range of pathogens from a single sam- ple; (iii) take a (relatively) long time; (iv) require a large volume of blood; or (v) cannot be used in the real-time monitoring of sepsis (either detecting pathogens known to cause sepsis or quantifying the patient's response to antimicrobial treatment).  We are proposing a new sepsis detection method, combining ﬂow imaging microscopy (a high-throughput technique for imaging millions of microscopic particles) and deep learning based image analysis (techniques leveraged in facial recognition and self-driving cars) to overcome the above mentioned limitations. The approach has proven capable of detecting a variety of bacterial species in low concentrations of mouse blood in less than 1 hour of processing time with as little as 50 L of blood. In this proposal, one of our aims is to optimize our approach and quantify the accuracy and limits of detection in human blood. Our patent pending approach has also been licensed to a major manufacturer of ﬂow imaging microscopes. Another aim of this research is to begin integration of our technology with an existing commercial instrument with the intention of providing a compact self- contained device that can be deployed at numerous hospitals world-wide. The implementation of our platform should have a major impact on antimicrobial treatment in all areas of the hospital. Project Narrative  Sepsis affects 1.7M US citizens (causing roughly 270k deaths) each year; the condition is also the most expensive condition treated in US hospitals costing approximately 24B USD each year. Current methods for detecting and determining the source of the infection causing sepsis are inaccurate, too slow, and do not provide detailed pathogen speciﬁc information needed for effective treatment. Our proposal aims at developing a fast approach, combining ﬂow imaging microscopy and deep learning, for detecting and determining the root cause of sepsis from blood samples (addressing many issues facing sepsis detection and diagnosis) which can deployed at a variety of hospitals worldwide.",A New Tool to Rapidly Diagnose Sepsis using Flow Imaging Microscopy and Machine Learning,10078833,R43EB029863,"['Address', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Area', 'Automobile Driving', 'Bacteria', 'Bedside Testings', 'Blood', 'Blood Cells', 'Blood Volume', 'Blood specimen', 'Cancer Patient', 'Cells', 'Cessation of life', 'Classification Scheme', 'Colony-forming units', 'Computer Analysis', 'Computer Systems', 'Culture Techniques', 'DNA', 'Detection', 'Developed Countries', 'Developing Countries', 'Devices', 'Diagnosis', 'Elderly', 'Etiology', 'Exhibits', 'Face', 'Failure', 'Flow Cytometry', 'Goals', 'Growth', 'Guidelines', 'Hospital Costs', 'Hospitals', 'Hour', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Immune system', 'Infant', 'Infant Mortality', 'Infection', 'Intention', 'Knowledge', 'Legal patent', 'Length of Stay', 'Letters', 'Licensing', 'Liquid substance', 'Machine Learning', 'Manufacturer Name', 'Medicine', 'Memory', 'Methods', 'Microbe', 'Microfluidic Microchips', 'Microscopic', 'Microscopy', 'Mus', 'Newborn Infant', 'Optics', 'Organ', 'Organism', 'Pathogenicity', 'Patients', 'Plant Roots', 'Population', 'Premature Birth', 'Preparation', 'Race', 'Reporting', 'Research', 'Sampling', 'Secure', 'Sensitivity and Specificity', 'Sepsis', 'Source', 'Speed', 'Techniques', 'Technology', 'Testing', 'Time', 'Treatment Effectiveness', 'age group', 'antimicrobial', 'base', 'chemotherapy', 'clinically relevant', 'data exchange', 'deep learning', 'demographics', 'detector', 'digital imaging', 'effective therapy', 'experience', 'human DNA', 'human old age (65+)', 'image processing', 'improved', 'infant death', 'instrument', 'intrapartum', 'microscopic imaging', 'mortality', 'multi-drug resistant pathogen', 'nano', 'nanoproducts', 'neonatal sepsis', 'older patient', 'optic flow', 'particle', 'pathogen', 'pathogenic bacteria', 'patient response', 'point of care', 'preterm newborn', 'processing speed', 'prototype', 'rapid diagnosis', 'real time monitoring', 'side effect', 'tool']",NIBIB,"URSA ANALYTICS, INC.",R43,2020,112402,-0.02223736422382953
"DIGITAL HEALTH SOLUTIONS FOR COVID-19: PERSONALIZED ANALYTICS WEARABLE BIOSENSOR PLATFORM FOR EARLY DETECTION OF COVID-19 DECOMPENSATION The goal of this project is to develop an artificial intelligence-based data analytics and cloud computing platform, paired with U.S. Food and Drug Administration (FDA)-cleared wearable devices, to create a personalized baseline index that could indicate a change in health status for patients who have tested COVID-19 positive.  The project involves the development and validation of a COVID-19 Decompensation Index (CDI) that builds off physIQ’s existing wearable biosensor-derived analytics platform.  Data will be collected from 400 human subjects that are both pre-hospitalization subjects (found to be positive for COVID-19) and subjects that have been hospitalized and treated for COVID and then discharged.  This combined population will consist of COVID-19 decompensation cases (event cases) and cases for which COVID-19 did not result in any kind of decompensation (non-event cases).  The 400-patient dataset will be partitioned into a training subset and a testing subset.  Performance will be assessed using receiver operator characteristics (ROC) area under the curve (AUC) as the metric of performance.  Data collected under this project will be deidentified and securely transmitted to an NIH data hub. n/a",DIGITAL HEALTH SOLUTIONS FOR COVID-19: PERSONALIZED ANALYTICS WEARABLE BIOSENSOR PLATFORM FOR EARLY DETECTION OF COVID-19 DECOMPENSATION,10274152,5N91020C00040,"['Area Under Curve', 'Artificial Intelligence', 'Biosensor', 'COVID-19', 'Cloud Computing', 'Data', 'Data Analytics', 'Data Set', 'Development', 'Early Diagnosis', 'Event', 'Goals', 'Health', 'Health Status', 'Hospitalization', 'Patients', 'Performance', 'Population', 'Receiver Operating Characteristics', 'Secure', 'Testing', 'Training', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Validation', 'base', 'computational platform', 'coronavirus disease', 'data hub', 'digital', 'human subject', 'indexing', 'wearable device']",NCI,"VGBIO, INC.",N01,2020,2305814,-0.0191189689396493
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,9857605,K99EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'archetypal analysis', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'machine learning method', 'mathematical model', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,K99,2020,145891,-0.017544901840021887
"Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment Project Summary More than 20,000 hematopoietic stem cell transplants (including bone marrow transplants) are performed in the U.S. each year to cure a range of diseases ranging from leukemias to sickle cell anemia to autoimmune deficiencies in children. Unfortunately, most long-term non-relapse survivors will die of chronic graft-versus-host disease (cGVHD), which remains a disease of steadily increasing incidence and profound unmet need. A fundamental barrier in cGVHD management and research is a lack of sensitive and objective assessment tools that permit objective and reproducible measures of disease severity and progression. Skin is the most commonly affected organ in cGVHD and automated techniques capable of measuring precisely the surface area of involved skin in photographs may provide the tools necessary for effectively evaluating patient progress. We propose to (1) create the data set necessary to develop machine learning-based methods for the automatic analysis of cGVHD images, and (2) implement and evaluate these methods. Project Narrative  Chronic graft-versus-host disease (cGVHD) is a lethal disease that affects most long-term hematopoietic stem cell transplant (including bone marrow transplants) recipients. Skin images are used to assess disease severity and progression but the technology required to quantitatively and reproducibly analyze these images is lacking. This project aims at developing and evaluating this technology.",Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment,9864040,R21AR074589,"['3-Dimensional', 'Achievement', 'Affect', 'Agreement', 'Allogenic', 'Area', 'Assessment tool', 'Autoimmune Process', 'Body Surface', 'Bone Marrow Transplantation', 'Characteristics', 'Child', 'Circumscribed Lesion', 'Clinic', 'Clinical', 'Clinical Research', 'Cutaneous', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dermatologic', 'Dermatologist', 'Disease', 'Disease Management', 'Disease Progression', 'Documentation', 'Erythema', 'Exanthema', 'Future', 'Goals', 'Hematologic Neoplasms', 'Hematopoietic Stem Cell Transplantation', 'Hematopoietic System', 'Human', 'Image', 'Incidence', 'Industry', 'Institution', 'Label', 'Lead', 'Lesion', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methods', 'Morbidity - disease rate', 'Organ', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Population', 'Protocols documentation', 'Psoriasis', 'Reaction', 'Reproducibility', 'Research', 'Resources', 'Role', 'Scanning', 'Severities', 'Severity of illness', 'Sickle Cell Anemia', 'Site', 'Skin', 'Skin Cancer', 'Standardization', 'Surface', 'Survivors', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-dimensional analysis', 'Time', 'Transplant Recipients', 'Visit', 'Vitiligo', 'automated analysis', 'base', 'cancer imaging', 'chronic graft versus host disease', 'data warehouse', 'deep learning', 'deep neural network', 'digital', 'graft vs host disease', 'high risk', 'image processing', 'improved', 'interdisciplinary approach', 'learning strategy', 'leukemia', 'machine vision', 'mortality', 'network architecture', 'neural network architecture', 'novel therapeutics', 'patient subsets', 'prototype', 'repository', 'response', 'skin disorder', 'skin lesion', 'stereoscopic', 'success', 'tool']",NIAMS,VANDERBILT UNIVERSITY,R21,2020,201692,-0.02353828051142492
"An Integrated Software Platform for Accelerating Image-Driven Ophthalmic Research and Driving New Insights and Endpoints to the Clinic ABSTRACT More than 20 million patients suffer from age-related macular degeneration, diabetic retinopathy, or glaucoma. These degenerative eye diseases develop over decades, and their prevalence is increasing. Retinal imaging technologies such as optical coherence tomography and adaptive optics ophthalmoscopy are essential tools in the investigation and management of eye disease. New quantitative biomarkers derived from these and other imaging modalities are critical to the clinical translation of emerging ophthalmic innovations. However, biomarker development in the era of artificial intelligence requires large volumes of annotated images and transparent, reproducible processes, which places new demands on the management of living subjects research, data sharing, and algorithm development. Unfortunately, current software platforms are not effective in integrating these data in a manner that meets specific requirements in ophthalmology, Our goal in this Direct-to-Phase II SBIR, consistent with objectives of the NIH Strategic Plan for Data Science, is to create an integrated platform (PaaS) for the collection, curation, analysis, and sharing of ocular images and data. We will extend the capabilities of systems developed by the Advanced Ocular Imaging Program (AOIP), Medical College of Wisconsin (MCW), which include: (a) LATTICE - a software solution that reduces costs, reduces errors, and improves communications in the management of living-subjects research; (b) MOSAIC - an image processing platform and algorithm library with traditional and AI-trained algorithms; and (c) The AOIP Image Bank - a Repository that houses images and data on 1578 fully-consent human research subjects. To create the integrative platform, we will address four aims: (a) Extend LATTICE to meet the workflow requirements of academic and sponsored research in local and multisite environments, including the extensible direct integration of data relevant to ocular studies; (b) Design and implement a hybrid (local + cloud) REPOSITORY architecture, data schema, knowledge ontology, and query architecture for Owners and Readers of data.; (c) Integrate and demonstrate LATTICE, REPOSITORY and MOSAIC into a continuous ocular science workflow and (d) integrate and demonstrate Lattice, Repository and Mosaic into a continuous ocular science workflow. Our Integrated Translational Imaging platform will enable ophthalmic innovators to translate sight-saving insights and interventions to the clinic faster, with less frustration, and greater confidence. Our proposal fills an important technology gap in the field of ophthalmic data science and biomarker development. While the number and type of imaging devices continues to grow, the tools to develop and deploy new biomarkers and clinical endpoints using these exquisite imaging devices has not kept pace. With this program we will enable a new generation of image-driven innovation to find its way to the clinic. Project Narrative With more than 20 million patients suffering from age-related macular degeneration, diabetic retinopathy, or glaucoma, it is crucial to develop non-invasive biomarkers as early predictors of eye disease and reliable tests of the safety and efficacy of new preventative and restorative therapies. To meet the unmet need for rapid access and analysis of ophthalmic research data for the discovery of these biomarkers, we will create an integrated platform (PaaS) for the collection, curation, sharing, and analysis of ocular images and data. If we meet our objectives, our platform will reduce the cost of clinical research and increase the speed of translating critical research insights to saving the sight of millions of patients.",An Integrated Software Platform for Accelerating Image-Driven Ophthalmic Research and Driving New Insights and Endpoints to the Clinic,9908389,R44EY031198,"['Address', 'Age related macular degeneration', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Collection', 'Communication', 'Computer software', 'Consent', 'Data', 'Data Discovery', 'Data Science', 'Diabetic Retinopathy', 'Docking', 'Economics', 'Environment', 'Eye diseases', 'Foundations', 'Frustration', 'Funding', 'Glaucoma', 'Goals', 'Housing', 'Human Subject Research', 'Hybrids', 'Image', 'Imaging Device', 'Imaging technology', 'Influentials', 'Intervention', 'Investigation', 'Knowledge', 'Libraries', 'Mosaicism', 'Ontology', 'Ophthalmology', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Patients', 'Phase', 'Policies', 'Prevalence', 'Process', 'Reader', 'Research', 'Research Subjects', 'Savings', 'Science', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Strategic Planning', 'Structure', 'System', 'Technology', 'Translating', 'Translations', 'United States National Institutes of Health', 'Validation', 'Vision', 'Wisconsin', 'adaptive optics', 'algorithm development', 'algorithm training', 'application programming interface', 'biomarker development', 'biomarker discovery', 'clinical translation', 'cost', 'data access', 'data exchange', 'data integration', 'data sharing', 'data warehouse', 'deep learning', 'design', 'efficacy testing', 'experience', 'fighting', 'image processing', 'image reconstruction', 'imaging modality', 'imaging platform', 'imaging program', 'improved', 'innovation', 'insight', 'medical schools', 'microsystems', 'ocular imaging', 'process repeatability', 'programs', 'repository', 'retinal imaging', 'safety testing', 'software systems', 'structured data', 'tool', 'verification and validation', 'vision science']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R44,2020,743347,-0.013663611693348886
"Sensory Cue Integration in Melanoma Screening Imaging biomarkers are features in images that have biological implications. For example, in a picture of a person with red hair, the red hair is a feature and the implication is that there is a mutation in the MC1R gene that provides instructions for making a protein called the melanocortin 1 receptor. This feature, an imaging biomarker, can be used as a medical cue to indicate increased risk for melanoma. When used in this context, this imaging biomarker becomes an imaging biomarker cue (IBC), in the sense that it may cue the medical professional observer to alter treatment accordingly, such as recommending sunscreen use. IBCs do not individually bear the full weight of medical decision-making and instead are integrated. IBC analysis may be a process of sensory cue integration or may be a process of observation and integration by technology such as a digital camera and computer. An advantage of the latter is that computational scalability enables machine vision to compute vast permutations of IBCs that would be overwhelming to a human observer. Thus computers can try many potential diagnostic methods rapidly before picking the best one to teach back to humans. The purpose of this project is to develop a human/machine interface for bi-directional teaching so expert dermatologists can teach computers what IBCs they use to achieve accurate diagnosis and computers can teach dermatologists the best way to use current IBCs and suggest integration of new IBCs that machine learning guides them to. As an outcome, we will measure the diagnostic performance of dermatologists who undergo IBC training in detecting melanoma. It is known that early detection saves lives, but the potential of technology to improve early detection, a great need since 10,000 Americans still die each year from melanoma, is unknown. This project will help answer that unknown and if we are successful in translating IBCs with commuter vision and machine learning, more melanomas will be detected early and lives will be saved. Our long-term goal is to reduce melanoma related deaths and unnecessary biopsies by helping clinicians increase the predictive value of dermoscopy-based melanoma screening. We believe sensitivity and specificity of dermoscopy- based melanoma screening for non-expert screeners can be improved by assistive technology, which is highly desirable given the cost of false positives (patient stress and unnecessary biopsies) and the extremely high cost of false negatives (delayed melanoma treatment). This project creates a technology to help medical personnel see and integrate features of abnormal skin spots that help them determine if the spot they are looking at is a melanoma. Since melanoma is deadly if left untreated, this technology helps them guide biopsy and surgical removal of skin to potentially cut more melanomas out (saving lives) and not cut so many benign lesions out unnecessarily (leaving less scars). Our augmentation of vision and cognition uses machine learning in a way that is visually intuitive so physicians may be able to show their patients the rationale behind the choice to surgically excise abnormal skin spots or not to.",Sensory Cue Integration in Melanoma Screening,10025420,R21CA240254,"['Address', 'Algorithms', 'American', 'Area Under Curve', 'Back', 'Bayesian Modeling', 'Benign', 'Biological', 'Biopsy', 'Cessation of life', 'Cicatrix', 'Classification', 'Clinical', 'Code', 'Cognition', 'Complement Factor D', 'Computers', 'Control Groups', 'Cues', 'Decision Making', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Early Diagnosis', 'Educational process of instructing', 'Effectiveness', 'Excision', 'Exposure to', 'Feedback', 'Genes', 'Goals', 'Hair', 'Health Personnel', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Instruction', 'Intuition', 'Language', 'Left', 'Lesion', 'Logic', 'Machine Learning', 'Malignant - descriptor', 'Maps', 'Measures', 'Medical', 'Melanocortin 1 Receptor', 'Methodology', 'Modeling', 'Mole the mammal', 'Mutation', 'Nevus', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Persons', 'Physicians', 'Predictive Value', 'Procedures', 'Process', 'Proteins', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Reporting', 'Risk', 'Risk Factors', 'Savings', 'Screening Result', 'Self-Help Devices', 'Sensitivity and Specificity', 'Sensory', 'Sensory Process', 'Skin', 'Skin Abnormalities', 'Specific qualifier value', 'Spottings', 'Statistical Data Interpretation', 'Stress', 'Sunscreening Agents', 'Surface', 'Technology', 'Testing', 'Training', 'Translating', 'Uncertainty', 'Ursidae Family', 'User-Computer Interface', 'Vision', 'Visual', 'Weight', 'accurate diagnosis', 'base', 'clinical diagnostics', 'cost', 'deep learning', 'diagnostic accuracy', 'digital', 'graphical user interface', 'imaging biomarker', 'improved', 'machine learning algorithm', 'machine vision', 'melanoma', 'predictive modeling', 'prevent', 'rapid technique', 'screening', 'success', 'vector']",NCI,ROCKEFELLER UNIVERSITY,R21,2020,412585,-0.008917120163220417
"DUET: Rapid dual-mode microscopy for quantitative slide-based renal fibrosis evaluation Contact PD/PI: Fereidouni, Farzad Abstract Kidneys, like other organs, have an inherent capacity to recover from acute injury; however, severe or recurrent injury can result in chronic kidney disease (CKD), the sequelae of which result in 82,000 deaths annually in the US alone. Regardless of the etiology of the initial injury, the common final pathway leading to- end stage renal disease is closely connected to fibrosis(excess or aberrant collagen distribution), one of the most important determinants of renal disease severity and prognosis. Histology is the gold standard for evaluation, typically through the use of histochemical stains such as trichrome and PAS that highlight the presence of collagens and basement membrane, respectively. Nevertheless, these stains are not completely specific, can be technically challenging to perform well and reproducibly, and thus contribute to interobserver variability and a concomitant decrease in diagnostic precision. Moreover, they also require the preparation of extra slides and additional staining procedures, and thus increase cost and can prolong the diagnostic process. We propose to optimize, deploy and test a new kind of microscope, DUET (DUal mode Emission and Transmission microscopy), developed at UC Davis, that will be a low-cost and very rapid solution for detection and digital characterization of the presence and distribution of collagen and other macromolecules, directly from standard formalin-fixed, paraffin-embedded hematoxylin and eosin-stained slides. Specifically, we will finalize the design of the hardware and software components of the instrument itself, validate imaging performance against standard histology and immunohistochemical stains for collagen and other components, and with the assistance of scientists at our partnering institutions (John Hopkins University and University of Buffalo) develop robust tools for analysis and quantitation of fibrosis. DUET instrument hardware will be shared with JHU to ensure that the methods are technically reproducible across multiple sites. The application leverages the expertise across three institutions in optics, biomedical engineering, renal pathology and novel artificial intelligence approaches. The goal of the project is development and validation of DUET, which promises to be a robust, inexpensive and practical approach for the rapid and accurate evaluation of fibrosis, extensible to other renal pathologies, and indeed across other organs systems, with significant positive impact on disease research, clinical practice, and patient outcomes. Page 6 Project Summary/Abstract Project Narrative Evaluation of fibrosis and tubular atrophy from chemically stained kidney biopsies are essential for diagnosis and disease-severity assessment, but current techniques are time-consuming, somewhat non-specific and contribute to interobserver variability and imprecision, affecting care. We propose to optimize and test a new kind of microscope (“DUET”) that can visualize fibrosis (scarring) and other tissue abnormalities directly from standard slides to enable high-quality reproducible fibrosis scoring and evaluation. This multi-site project will also provide a unique opportunity to perform a retrospective study from hundreds of existing H&E slides with associated months to years of clinical follow-up data, and to create a method with demonstrated utility in more than one institution.",DUET: Rapid dual-mode microscopy for quantitative slide-based renal fibrosis evaluation,10261643,R56DK124873,"['Acute', 'Affect', 'Agreement', 'Algorithms', 'Allografting', 'Archives', 'Artificial Intelligence', 'Atrophic', 'Basement membrane', 'Biomedical Engineering', 'Biopsy', 'Buffaloes', 'Caring', 'Cessation of life', 'Chemicals', 'Chronic Kidney Failure', 'Cicatrix', 'Clinical', 'Collagen', 'Computer software', 'Computers', 'Consumption', 'Data', 'Data Science', 'Data Sources', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'End stage renal failure', 'Ensure', 'Etiology', 'Evaluation', 'Fibrillar Collagen', 'Fibrosis', 'Fluorescence', 'Formalin', 'Goals', 'Gold', 'Hematoxylin and Eosin Staining Method', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Injury', 'Institution', 'Interobserver Variability', 'Kidney', 'Kidney Diseases', 'Kidney Failure', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Natural History', 'Optics', 'Organ', 'Paraffin Embedding', 'Pathologist', 'Pathology', 'Pathway interactions', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Preparation', 'Procedures', 'Process', 'Property', 'Quantitative Microscopy', 'Recurrence', 'Renal Replacement Therapy', 'Renal function', 'Reproducibility', 'Research', 'Retrospective Studies', 'Running', 'Scientist', 'Severity of illness', 'Signal Transduction', 'Sirius Red F3B', 'Site', 'Slide', 'Staging', 'Stains', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissue Embedding', 'Tissues', 'Trichrome stain method', 'Tubular formation', 'Universities', 'Validation', 'base', 'body system', 'clinical care', 'clinical practice', 'clinically significant', 'cohort', 'cost', 'cost effective', 'design', 'digital', 'digital pathology', 'follow-up', 'histological stains', 'instrument', 'instrumentation', 'kidney biopsy', 'kidney fibrosis', 'macromolecule', 'novel', 'outcome forecast', 'personalized diagnostics', 'predict clinical outcome', 'predictive modeling', 'prognostic', 'prognostic value', 'software development', 'stem', 'tool', 'transmission process']",NIDDK,UNIVERSITY OF CALIFORNIA AT DAVIS,R56,2020,91725,-0.008944896486987087
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9989186,R44MH118815,"['3-Dimensional', 'Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'stem cells', 'treatment strategy', 'two-dimensional', 'usability', 'virtual environment', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2020,749716,-0.0033822594314057448
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,9979523,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2020,77243,-0.03580299376739467
"SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring This project aims to develop an interpretable, physician-in-the-loop AI-aided software that accurately delineates glioma boundaries in MRIs, computes volumetric curves, and statistically quantifies the tumor growth in longitudinal studies. The current clinical practice of visually analyzing and manually contouring tumors is subjective, time-consuming, and often inconsistent. The novelty of MRIMath's explainable, trustworthy, and physician-in-the-loop AI system is multi-fold. First, we introduce a multi-scale feature extraction framework using the inception modules in contracting and expanding paths of the U-Net image segmentation neural network architecture. Second, we propose a new loss function based on the modified Dice similarity coefficient. Third, we train and test the AI system using two learning regimes: learning to segment intra-tumoral structures and learning to segment glioma sub-regions. Finally, we produce heat maps to visualize the features extracted by the AI, thus offering physicians a view of AI's attention patterns and activation maps that were triggered during AI's decision-making. An intuitive and interactive User Interface will allow the physician to review contouring results, make adjustments and approve contours, visualize AI's explanations and volumetric measurements, and finally review the results of the statistical analysis. Any modifications made by the physician will be used later to re-train AI. n/a","SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269837,5N91020C00049,"['Artificial Intelligence', 'Attention', 'Computer software', 'Consumption', 'Contracts', 'Data', 'Data Sources', 'Decision Making', 'Diagnosis', 'Glioma', 'Human', 'Intuition', 'Learning', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measurement', 'Modality', 'Modification', 'Monitor', 'Pattern', 'Phase', 'Physicians', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'System', 'Testing', 'Time', 'TimeLine', 'Training', 'base', 'cancer imaging', 'cancer prevention', 'clinical practice', 'design', 'feature extraction', 'imaging Segmentation', 'imaging software', 'imaging system', 'loss of function', 'neural network architecture', 'prototype', 'tumor', 'tumor growth', 'usability']",NCI,"MRIMATH, LLC",N43,2020,400000,-0.027140508629286745
"SBIR Phase I Topic 402: Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring Image-based evaluation of lymph nodes is an essential step in cancer diagnosis, treatment and monitoring. Current clinical practice mostly uses qualitative or semi-quantitative measures in evaluation and thus suffers from inaccuracy due to intra- and inter-observer variability and increased human efforts. This becomes a more serious issue in head and neck cancers due to the large number of clinically relevant lymph nodes. In this project an AI-based automatic segmentation software will be developed for quantitative cervical lymph node evaluation to increase the accuracy and reduce the cost. However, there are a few challenges in developing and deploying such a software due to different clinical practices such as usage of different modalities (MRI and/or CT) and complex clinical workflow. To address these challenges, a novel AI algorithm that can handle the variability in imaging modalities and support incremental learning using site-specific data to enhance its robustness will be developed; a private-cloud-based software framework with high usability will then be developed to incorporate this algorithm and provide advanced visualization and reporting for clinical usage. This software will have high impact on all stages of patient care for head and neck cancers and can be further extended to other cancers. n/a","SBIR Phase I Topic 402: Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269836,5N91020C00048,"['Address', 'Algorithms', 'Artificial Intelligence', 'Cervical lymph node group', 'Clinical', 'Complex', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Evaluation', 'Head and Neck Cancer', 'Human', 'Image', 'Interobserver Variability', 'Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Modality', 'Monitor', 'Patient Care', 'Performance', 'Phase', 'Privatization', 'Reporting', 'Site', 'Small Business Innovation Research Grant', 'Software Framework', 'Visualization', 'automated segmentation', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer prevention', 'clinical practice', 'clinically relevant', 'cloud based', 'cost', 'imaging modality', 'lymph nodes', 'novel', 'segmentation algorithm', 'usability']",NCI,"CARINA MEDICAL, LLC",N43,2020,400000,-0.024593946738745855
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",9850968,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'disorder subtype', 'elastography', 'hepatocellular injury', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,442592,-0.010381690364051658
"DIGITAL HEALTH SOLUTIONS FOR COVID-19: COVID-19 ONGOING MONITORING (COMMUNITY) The goal of this proposal is to develop a COVID-19 detection algorithm based on self-report survey data and wearable sensor data. Data from 25K COVID-19 Experiences participants and 25K Large-scale Flu Surveillance (COVID-19 Questions added March 2020) will be used with an existing machine learning model to develop this new detection algorithm, which will be validated in a large-scale pilot population to identify individuals with undiagnosed COVID-19. Evidation will incorporate the model into an established web and multi-platform (Android, iOS) smartphone platform called Achieve which allows users to share person-generated health data (PGD) from their everyday lives. Data collected under this project will be deidentified and securely transmitted to an NIH data hub. n/a",DIGITAL HEALTH SOLUTIONS FOR COVID-19: COVID-19 ONGOING MONITORING (COMMUNITY),10274140,5N91020C00034,"['Algorithms', 'Android', 'COVID-19', 'Cellular Phone', 'Communities', 'Data', 'Detection', 'Goals', 'Health', 'Individual', 'Internet', 'Machine Learning', 'Modeling', 'Monitor', 'Participant', 'Patient Self-Report', 'Persons', 'Population', 'Secure', 'Surveys', 'United States National Institutes of Health', 'base', 'data hub', 'digital', 'experience', 'health data', 'influenza surveillance', 'wearable sensor technology']",NCI,"EVIDATION HEALTH, INC.",N01,2020,240000,-0.009944130856947994
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,10024094,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'behavioral phenotyping', 'comorbidity', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2020,422740,-0.0035776749329352363
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",9890853,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'machine learning method', 'myocardial injury', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2020,795348,-0.030164361833195458
"Georgia Clinical & Translational Science Alliance (GaCTSA) EFFECTIVE ALLOCATION OF TEST CENTERS FOR COVID-19 USING MACHINE LEARNING AND  ADAPTIVE SAMPLING ABSTRACT A critical task in managing and dealing with COVID-19 in communities is to perform diagnostic and/or antibody tests to identify diseased individuals. This information is critical to public health officials to estimate prevalence and transmission, and to effectively plan for required resources such as ICU beds, ventilators, personal protective equipment, and medical staff. Additionally, information on the number of infected people can be used to develop probabilistic and statistical models to estimate the reproduction number of the disease, and to predict the likely spatial and temporal trajectories of the outbreak. This provides vital information for planning actions and preparing policies and guidelines for social-distancing, school closures, remote work, community lockdown, etc. Despite the importance of diagnostic testing and identification of the positive cases, broad-scale testing is a challenging task particularly due to the limited number of test kits and resources. Our proposed research focuses on the development machine learning-based allocation strategies for determining the optimal location of COVID-19 test centers, including mobile and satellite centers, to minimize the local and global prediction uncertainties, maximize geographic coverage, associated with projections of spatio-temporal outbreak trajectories, and to improve efficient identification of diseased cases. EFFECTIVE ALLOCATION OF TEST CENTERS FOR COVID-19 USING MACHINE LEARNING AND  ADAPTIVE SAMPLING NARRATIVE Diagnostic and antibody tests for COVID-19 can provide invaluable information on prevalence and transmission of the disease. However, due to limited test capacity, broad-scale testing is currently not feasible. Consequently, there is a pressing need for a systematic and data-driven approach to defining testing strategies, in particular, determining the number and location of satellite and mobile testing centers (e.g., drive-through test locations). Our research program develops machine learning approaches to effectively allocate test centers for COVID-19 at the city, county, and state levels to accurately and reliably estimate the disease prevalence and its trajectory for resource planning and policy making, and to efficiently identify cases for treatment.",Georgia Clinical & Translational Science Alliance (GaCTSA),10158891,UL1TR002378,"['Active Learning', 'Antibodies', 'Area', 'Beds', 'Biology', 'COVID-19', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Cities', 'Clinical Sciences', 'Communities', 'Contracts', 'County', 'Data', 'Development', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Ecology', 'Ensure', 'Epidemic', 'Epidemiology', 'Equipment', 'Federal Government', 'Future', 'Geography', 'Goals', 'Guidelines', 'Hybrids', 'Individual', 'Local Government', 'Location', 'Machine Learning', 'Medical Staff', 'Methods', 'Modeling', 'Monitor', 'Neighborhood Health Center', 'Neurology', 'Pattern', 'Performance', 'Policies', 'Policy Making', 'Population', 'Prevalence', 'Process', 'Public Health', 'Readiness', 'Reproduction', 'Research', 'Research Project Grants', 'Resistance', 'Resources', 'Sampling', 'Scheme', 'Schools', 'Series', 'Social Distance', 'Statistical Models', 'Testing', 'Time', 'Translational Research', 'Uncertainty', 'Update', 'Ventilator', 'Virus', 'Work', 'base', 'case finding', 'disease transmission', 'environmental justice', 'evidence base', 'experience', 'flexibility', 'improved', 'metropolitan', 'multidisciplinary', 'novel', 'pandemic disease', 'programs', 'racial and ethnic', 'racial diversity', 'sociodemographics', 'socioeconomics', 'spatiotemporal', 'transmission process']",NCATS,EMORY UNIVERSITY,UL1,2020,225579,-0.008905709309745526
"Visible-light OCT angiography, velocimetry, and oximetry for characterizing retinal vascular alterations in glaucoma Project Summary Glaucoma damage to the optic nerve and impairment of vision are progressive and irreversible. Understanding mechanisms of glaucomatous injury will help to develop new approaches for treatments that can be used along with traditional therapies that lower intraocular pressure (IOP). Recent developments in optical coherence tomography (OCT) angiography have brought increased attention to the role of the inner retinal circulation in glaucoma. To improve our understanding of retinal vascular alterations in glaucoma, we can take advantage of recent developments in visible-light OCT (vis-OCT) to characterize simultaneously tissue structure, vessel density, blood flow and oxygenation. The goal of this project is to further advance vis-OCT by attaining capillary-level measurements, test the value of measuring their local alterations as early indicators of glaucoma and glaucomatous progression and use this to evaluate impaired retinal autoregulation from retinal ganglion cell (RGC) loss as a potential cause of increased susceptibility in advanced glaucoma. In Specific Aim 1 we will develop high-speed, high-sensitivity, high-resolution vis-OCT. The speed will be double that of the current system. A more stable supercontinuum laser will be used to improve system sensitivity, and a tighter focus will be used to improve lateral resolution. This will enable complete detection of capillaries that may be vulnerable to vascular dysfunction. Specific Aim 2 will develop quantitative OCT angiography, velocimetry and oximetry in capillaries as well as arteries and veins. Building on the high-resolution, high-contrast scans acquired in Aim 1, we will use machine learning to segment capillary plexuses, and advanced image processing to extract capillary architecture. Aided by this capillary architecture, we will automatically measure blood flow and oxygenation in capillary segments and incorporate them into a real-time platform. Specific Aim 3 will use this system to demonstrate that acute loss of RGCs, produced by optic nerve transection, alters retinal capillary plexus density, oximetry and velocimetry over time and that these changes precede altered oximetry and flow in larger retinal vessels. We will also show that loss of RGCs impairs the autoregulatory response to acute IOP challenge. In Specific Aim 4, we will demonstrate that optic nerve injury in a model of controlled, elevated IOP produces early alterations in capillary velocimetry, oximetry and autoregulation, show that they are more persistent with advanced injury, and demonstrate the pathophysiologic consequences of these observations. Successful development of this new technology will improve methods of early glaucoma diagnosis and detection of progression. Better understanding of retinal vascular factors that lead to increased susceptibility in advanced glaucoma will lead to improved treatments for these highly vulnerable patients. Project Narrative This project will develop advanced technology to image retinal capillaries and measure capillary blood flow and oxygen content. This may provide an early indicator of glaucoma progression and help study a potential cause of increased susceptibility to intraocular pressure in glaucoma patients.","Visible-light OCT angiography, velocimetry, and oximetry for characterizing retinal vascular alterations in glaucoma",9944107,R01EY031394,"['3-Dimensional', 'Abbreviations', 'Acute', 'Address', 'Affect', 'Angiography', 'Architecture', 'Arteries', 'Attention', 'Axon', 'Blindness', 'Blood Circulation', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Computer software', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Early identification', 'Event', 'Eye', 'Glaucoma', 'Glossary', 'Goals', 'Homeostasis', 'Impairment', 'Injury', 'Intraocular pressure test', 'Lasers', 'Lateral', 'Lead', 'Lighting', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Noise', 'Optic Nerve', 'Optic Nerve Injuries', 'Optic Nerve Transections', 'Optical Coherence Tomography', 'Oxygen', 'Oxygen saturation measurement', 'Patients', 'Performance', 'Physiologic Intraocular Pressure', 'Predisposition', 'Process', 'Progressive Disease', 'Rattus', 'Resolution', 'Retina', 'Retinal Ganglion Cells', 'Rodent Model', 'Role', 'Scanning', 'Signal Transduction', 'Speed', 'Structure', 'Structure of central vein of the retina', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Vascular Diseases', 'Veins', 'Velocimetries', 'Visible Radiation', 'Vision', 'Visual impairment', 'attenuation', 'automated segmentation', 'central retinal artery', 'data acquisition', 'deep learning', 'density', 'image processing', 'improved', 'in vivo', 'innovation', 'insight', 'metabolic rate', 'new technology', 'novel strategies', 'preservation', 'pressure', 'prototype', 'response', 'retina blood vessel structure', 'retina circulation', 'retinal imaging', 'retinal ischemia', 'traditional therapy', 'vascular factor']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,552591,-0.017650037908149757
"Development of a Wheelchair Maintenance Alert Application for Elderly Wheelchair Users Project Summary Elderly wheelchair users experience wheelchair breakdowns every 2-3 months in low- and middle-income countries (LMICs) and rural areas of high-income countries. One in three breakdowns leads to adverse physical, social, psychosocial and economic consequences to wheelchair users which increases the public health and personal burden. Preventative wheelchair maintenance has been found to reduce the frequency of wheelchair breakdowns by ten-fold, but compliance with maintenance recommendations is extremely low because they are generic and not reflective of how and where the wheelchair is being used. To address this issue, we are developing a low-cost, scalable maintenance application that leverages artificial intelligence tools to provide maintenance recommendations tailored to how a wheelchair is used. The availability of low-cost technology and widespread use of smartphones by the elderly and people with disabilities in LMICs has led us to develop a smartphone application called WheelTrak that measures wheelchair wear as a function of usage in community. Based on the wear factors, the application produces a Wheelchair Wear Index (WWI) that is representative of wear of critical wheelchair parts that are prone to breakdown. Once a WWI threshold is reached, maintenance is required, and the application notifies the user and/or caregiver who can conduct maintenance to avoid breakdowns and related health consequences. We will conduct a data collection study in collaboration with our wheelchair industry partner – UCP Wheels in El Salvador – and characterize the WWI for the elderly by tracking wear factors which include user’s travel distance, ground shocks and surface vibrations using WheelTrak and a wheel sensor. Based on the trained WWI algorithm, a preventative maintenance schedule will be developed for older adults that can be employed through WheelTrak for maintenance reminders. Semi-structured interviews will be conducted to evaluate the usability of the application and gather barriers to maintenance. User feedback will assist us in improving WheelTrak for greater user satisfaction and compliance with maintenance, and addressing any personal or logistical challenges that elderly users and their caregivers or family members may face with conducting maintenance activities in LMICs. Findings from the proposed studies in this application will assist us in planning future studies to investigate the WWI-enabled WheelTrak tool as an intervention to prevent or reduce breakdowns and health consequences with the elderly in LMICs. Preventative maintenance of wheelchairs is necessary to reduce frequent wheelchair breakdowns and corresponding health consequences experienced by the elderly in adverse environments which are commonly present in low- and middle-income countries (LMICs). WheelTrak is a smartphone application that measures real-time wheelchair wear in the community during use and triggers preventative maintenance reminders. In this study, we are modelling the application algorithm and collecting user and caregiver feedback to transform WheelTrak into a maintenance intervention tool for elderly wheelchair users in LMICs.",Development of a Wheelchair Maintenance Alert Application for Elderly Wheelchair Users,10095020,R03AG069836,"['Activities of Daily Living', 'Address', 'Adult', 'Algorithms', 'Artificial Intelligence', 'Beds', 'Caregivers', 'Cause of Death', 'Cellular Phone', 'Clinic', 'Collaborations', 'Communities', 'Country', 'Data', 'Data Collection', 'Development', 'Devices', 'Disabled Persons', 'Economics', 'El Salvador', 'Elderly', 'Environment', 'Face', 'Failure', 'Family member', 'Feedback', 'Frequencies', 'Future', 'Goals', 'Health', 'Hospitalization', 'Income', 'Injury', 'Intervention', 'Intervention Studies', 'Interview', 'Life Style', 'Logistics', 'Long-Term Care', 'Maintenance', 'Manual wheelchair', 'Measures', 'Mental Depression', 'Modeling', 'Monitor', 'Names', 'Notification', 'Pattern', 'Personal Satisfaction', 'Population', 'Preventive', 'Provider', 'Public Health', 'Recommendation', 'Risk', 'Schedule', 'Services', 'Shock', 'Societies', 'Structure', 'Study models', 'Surface', 'Technology', 'Time', 'Training', 'Travel', 'User Compliance', 'Wheelchairs', 'aged', 'base', 'cohort', 'cost', 'decubitus ulcer', 'disability', 'evidence base', 'experience', 'improved', 'indexing', 'industry partner', 'low and middle-income countries', 'prevent', 'prospective', 'psychosocial', 'rural area', 'satisfaction', 'sensor', 'sensor technology', 'smartphone Application', 'social', 'tool', 'usability', 'vibration']",NIA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R03,2020,75877,-0.03440867518504081
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10010814,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2020,819293,-0.0001574439677010525
"DIGITAL HEALTH SOLUTIONS FOR COVID-19:  COVID COMMUNITY ACTION AND RESEARCH ENGAGEMENT (COVID-CARE) The goal of this project is to develop mobile applications, data integrations, and validated machine learning algorithms to identify COVID-19 and differentiate it from the flu, and to perform contact tracing using Wi-Fi technologies.  Vibrent Health will accomplish this goal by enhancing their Vibrent Digital Health Solutions Platform (DHSP) implementation to large-scale pilot populations among diverse user groups.  The project will focus on validating the technology’s performance, usability, and reliability in refinement of analytics to generate predictive algorithms for infection.  The platform is intended to support individual, organizational, community, and societal-level decision-making in the COVID-19 pandemic response.  The first objective involves innovation to develop a technology that can differentiate between COVID-19 and flu (or other respiratory illness).  The second objective involves the development and testing of a Wi-Fi-based contact tracing tool using George Mason University’s enterprise Wi-Fi system.  The third objective involves the development of a full technical integration approach and strategy to support data exchange.  Data collected under this project will be deidentified and securely transmitted to an NIH data hub. n/a",DIGITAL HEALTH SOLUTIONS FOR COVID-19:  COVID COMMUNITY ACTION AND RESEARCH ENGAGEMENT (COVID-CARE),10274145,5N91020C00038,"['Action Research', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Communities', 'Community Actions', 'Contact Tracing', 'Data', 'Decision Making', 'Development', 'Goals', 'Health', 'Individual', 'Infection', 'Performance', 'Population', 'Secure', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Universities', 'base', 'coronavirus disease', 'data exchange', 'data hub', 'data integration', 'digital', 'flu', 'innovation', 'machine learning algorithm', 'mobile application', 'prediction algorithm', 'respiratory', 'response', 'tool', 'usability', 'wireless fidelity']",NCI,"VIGNET, INC.",N01,2020,1098256,-0.011441905621347222
"Improving Critical Congenital Heart Disease Screening and Detection of ""Secondary"" Targets PROJECT SUMMARY/ABSTRACT  We propose to develop an automated critical congenital heart disease (CCHD) screening algorithm using machine learning techniques to combine non-invasive measurements of perfusion and oxygenation. Oxygen saturation (SpO2)-based screening is the current standard for CCHD screening, however it fails to detect up to 50% of asymptomatic newborns with CCHD or nearly 900 newborns in the United States annually. The majority of newborns missed by SpO2 screening have defects with aortic obstruction, such as coarctation of the aorta (CoA), that do not result in deoxygenated blood entering circulation. Non-invasive measurements of perfusion such as perfusion index (PIx) and pulse oximetry waveform analysis is expected to improve the detection of newborns with defects such as CoA, which is currently the most commonly missed CCHD by SpO2 screening. Both PIx and pulse oximetry waveforms can be measured non-invasively and with the same equipment used for SpO2 screening.  Members of our team recently showed that the addition of PIx, a non-invasive measurement of pulsatile blood flow, has the potential to improve CCHD detection otherwise missed by SpO2 screening. However, variability of PIx over brief time periods (seconds) and human error in its interpretation limit its clinical capabilities. Additionally, human error in interpretation of the current SpO2 screening algorithm leads to missed diagnoses and inappropriate testing in healthy newborns. Therefore, an automated SpO2-PIx screening algorithm is needed to both simplify the screening process, and improve detection of defects that are missed with SpO2 screening. In order to achieve that, we will identify the optimal PIx waveforms to create a metric that discriminates between newborns with and without CCHD. We will perform pulse oximetry waveform analysis to identify other non-invasive components with discriminatory capacity for newborns with CCHD. Additionally, we will apply supervised machine learning techniques to automate the algorithm interpretation.  The proposed research is significant because an automated SpO2-PIx screening algorithm could save the lives of hundreds of newborns with CCHD that are not diagnosed by SpO2 screening. Additionally, this is innovative as it will be the first automatic interpretation of PIx measurement among newborns with CCHD and merging of automated PIx and SpO2, which will allow for easy implementation at later steps. Through collaboration with four pediatric cardiac centers, we will establish the infrastructure and necessary multidisciplinary relationships to conduct future multicenter studies to evaluate this novel combined SpO2-PIx algorithm on a large scale involving thousands of newborns. Improving the detection of CCHD will require a multidisciplinary approach among all the individuals involved in the care and screening of newborns with CCHD. Additionally, collaboration with engineering and computer sciences will be necessary to automate the SpO2-PIx CCHD screening algorithm. PROJECT NARRATIVE A screening approach that improves earlier detection of critical congenital heart defects with systemic obstruction is critically necessary. This application seeks to develop a screening algorithm that will combine the current screening standard, oxygen saturation, with non-invasive measurements of perfusion. This high risk, high reward approach is fundamentally different from other approaches as it will use machine learning techniques, and is expected to improve the detection of critical congenital heart defects with systemic obstruction and automate the interpretation of the screening results.","Improving Critical Congenital Heart Disease Screening and Detection of ""Secondary"" Targets",10018507,R21HD099239,"['Affect', 'Algorithms', 'American Heart Association', 'Aortic coarctation', 'Automatic Data Processing', 'Blood', 'Blood Circulation', 'Blood Pressure', 'Blood flow', 'California', 'Cardiac', 'Caring', 'Cessation of life', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Congenital Abnormality', 'Critical Congenital Heart Defects', 'Critical Illness', 'Data', 'Defect', 'Detection', 'Diagnosis', 'Early Diagnosis', 'Engineering', 'Equipment', 'Evaluation', 'Funding', 'Future', 'Goals', 'Individual', 'Infant', 'Infrastructure', 'Interruption', 'Intervention', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Morbidity - disease rate', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'National Institute of Child Health and Human Development', 'Neonatal Screening', 'New York', 'Newborn Infant', 'Obstruction', 'Oxygen', 'Perfusion', 'Physiologic pulse', 'Population', 'Process', 'Pulsatile Flow', 'Pulse Oximetry', 'Research', 'Savings', 'Screening Result', 'Screening procedure', 'Sensitivity and Specificity', 'Specificity', 'Techniques', 'Testing', 'Time', 'Ultrasonography', 'United States', 'Upper Extremity', 'Validation', 'aortic arch', 'automated algorithm', 'base', 'clinical application', 'cohort', 'computer science', 'congenital heart disorder', 'high reward', 'high risk', 'human error', 'improved', 'indexing', 'infant death', 'innovation', 'interdisciplinary approach', 'member', 'mortality', 'multidisciplinary', 'neonatal period', 'novel', 'prenatal', 'prevent', 'screening', 'supervised learning']",NICHD,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2020,192195,-0.02269795818514229
"A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration PROJECT SUMMARY Age-related macular degeneration (AMD), in the dry or wet form, is the leading cause of vision loss in the developed countries. The Age-Related Eye Disease Study (AREDS) showed that specific antioxidant vitamin supplementation reduces the risk of progression from intermediate stages to late AMD and maintains visual acuity in approximately 25% of patients. While treatment of wet AMD with Intraocular injections can be effective in maintaining vision, such treatments are costly and may be associated with significant cardiovascular risks, or even progression of dry AMD. Hence, it is critical to identify patients at the earlier stages. Unfortunately, there is no effective, automated screening tool to accomplish this, and the patients themselves may be asymptomatic. The goal of this SBIR Direct-to-Phase II proposal is to provide such tool. We have demonstrated the feasibility of AMD screening software ‘iPredictTM’ by successfully identifying 98.1% of individuals with early or intermediate stage AMD. iPredictTM also successfully predicted which individuals would develop late AMD within one year with 87.8% accuracy and two years with 88.4% accuracy. iPredictTM has prototype components for image analysis and machine learning. We also developed a HIPAA compliant telemedicine platform which will enable iPredictTM to perform large-scale screening from remote and rural areas. In order to bring the product to market, these components need to be integrated and tested which is the aim of our proposed Direct-to-Phase II proposal. We aim to develop the finished product which will be ready for the market. We also aim to evaluate the efficacy of iPredictTM in a clinical setup. The AMD preventative market is estimated around $5.4 billion in the U.S. alone. iPredictTM will capture the major market share with its best accuracy and be the first prediction tool for AMD. We aim to commercialize iPredictTM for the screening and prevention of AMD, saving millions of citizens from blindness and reduced quality of life. With iPredictTM’s improvements in speed of delivery, cost of care, and ease of access, the product will be a significant addition to the healthcare system. The iPredictTM’s telemedicine platform will allow large-scale screening from remote/rural areas, primary care clinics, optometry offices and ophthalmology clinics. PROJECT NARRATIVE Age-related macular degeneration (AMD) in its late forms, “dry” or “wet”, is the leading cause of blindness in developed countries. Early intervention and therapy can significantly reduce the progression of early to late AMD. Hence, the identification of patients with early AMD and referral to an ophthalmologist is critically needed to help prevent vision loss. To achieve this goal, we propose to develop an automated screening and prediction system that can be widely deployed to identify these individuals at risk of vision loss.",A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration,10010769,R44EY031202,"['Affect', 'Age', 'Age related macular degeneration', 'American', 'Antioxidants', 'Blindness', 'Categories', 'Clinic', 'Clinical', 'Clinics and Hospitals', 'Code', 'Color', 'Computer software', 'Counseling', 'Data', 'Data Set', 'Databases', 'Developed Countries', 'Devices', 'Diagnosis', 'Drusen', 'Ear', 'Early Intervention', 'Evaluation', 'Eye', 'Eye diseases', 'Feasibility Studies', 'Fees', 'Goals', 'Health Insurance Portability and Accountability Act', 'Healthcare Systems', 'Image', 'Image Analysis', 'Incentives', 'Individual', 'Injections', 'Intervention', 'Java', 'Lasers', 'Learning Module', 'Machine Learning', 'Manuals', 'Methods', 'Minerals', 'Modeling', 'New York', 'Nonexudative age-related macular degeneration', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patients', 'Phase', 'Prevention', 'Prevention strategy', 'Primary Health Care', 'Provider', 'Pythons', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Sales', 'Savings', 'Screening procedure', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Smoking', 'Specialist', 'Speed', 'Sun Exposure', 'Supplementation', 'System', 'Telemedicine', 'Testing', 'Therapeutic Intervention', 'Time', 'Trademark', 'Treatment Cost', 'Validation', 'Vision', 'Visit', 'Visual Acuity', 'Vitamins', 'age related', 'base', 'biobank', 'cardiovascular risk factor', 'care costs', 'checkup examination', 'commercial application', 'convolutional neural network', 'cost', 'deep learning', 'follow-up', 'improved', 'photobiomodulation', 'prediction algorithm', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'prospective', 'prototype', 'research clinical testing', 'retinal imaging', 'rural area', 'screening', 'sociodemographic factors', 'software as a service', 'success', 'tool', 'user-friendly']",NEI,"IHEALTHSCREEN, INC.",R44,2020,585067,-0.005718777988978382
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,10241562,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Visualization', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2020,2500,-0.023799071585340458
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10011054,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2020,1159612,-0.015017880889552098
"BlueBox: A Complete Code Blue Data Recorder, Phase II “Code blue” is the signal used in hospitals to call for an immediate cardiopulmonary resuscitation (CPR) following a cardiac or respiratory arrest. Reviewing the performance of the “code blue team” is a cornerstone for improving outcomes. The current standard of using handwritten records on a paper “code sheet” does not allow measurement of key quality indicators and is subject to human error. In the Phase I STTR project, we developed an electronic device for complete recording of code blue events, called BlueBox. The BlueBox is a small electronic recorder on an adhesive patch to be placed on the left chest next to the mid-sternum. The prototype we developed in Phase I was successfully tested on high fidelity mannequins and on pigs. In Phase II, our goal is to complete the product development and testing and prepare the BlueBox for regulatory clearance and market launch. To achieve this goal, we propose 3 Specific Aims. Aim 1 is to complete the product development of the BlueBox device and the software user interface (UI) for the “electronic code sheet.” We will turn the engineering prototype we developed in Phase I into a product ready for commercialization through rigorous product development processes. We will develop a mobile app for iPads with a software UI for the “electronic code sheet.” Aim 2 is to conduct human factors and usability engineering (HF/UE) testing and prepare for regulatory submission. The alpha prototype will undergo HF/UE testing in the Simulation Center. We will establish and maintain quality management records and conduct a pilot production run of 200 units of BlueBox. Aim 3 is to validate the BlueBox system in clinical studies. The objectives of the clinical study are: 1) to establish equivalence of the electronic code sheet to the current standard of paper code sheet; 2) to demonstrate the effectiveness of the electronic code sheet in identifying key CPR quality indicators. We will conduct a code blue simulation study of 50 sessions on high fidelity mannequins with hospital code blue teams to compare BlueBox recording with paper code sheets. We will conduct a study of 30 healthy volunteers for BlueBox sensor validation. The criteria for successful development of the product will be that it passes all required regulatory testing and is validated in the clinical study for its equivalence and effectiveness in code blue recording. There will be two major milestones in this project: (1) finalizing product development with successful test production of 200 units; and (2) completing the clinical study and preparing for a 510(k) submission. Achieving the aims will result in a validated BlueBox system ready for submission to the FDA and commercialization. We intend to first introduce the BlueBox system to hospitals as a tool for staff training and quality improvement. We will continue the technology development with machine learning to provide instant feedback in the second generation BlueBox. Our ultimate goal is to minimize human error and improve patient outcomes through the BlueBox system’s better documentation and continuous feedback mechanism. Modified Specific Aims  “Code blue” is the alert used in hospitals to initiate immediate cardiopulmonary resuscitation (CPR) following a cardiac or respiratory arrest.1 These situations are dire emergencies. Medical errors are likely to occur, and lives can be lost. Reviewing the performance quality of the “code blue team” is a cornerstone for improving outcomes of in-hospital arrests.2-4 Thorough and accurate recording of code blue events facilitates the detailed analyses needed for quality improvement.5-7 However, the current standard of using handwritten records on a paper “code sheet” does not allow measurement of key quality indicators and is subject to human errors. In our Phase I STTR project, we developed an electronic device for complete recording of code blue events, called BlueBox. The BlueBox is a small electronic recorder on an adhesive patch to be placed on the left chest next to the mid-sternum. It captures and records all code blue events -- vital signs, cardiac rhythm, verbal orders and their execution, chest compressions, cardioversion/defibrillation, procedures, medications, and labs. The prototype we developed in Phase I was successfully tested on high fidelity mannequins in the Simulation Center, and on pigs in the Animal Lab. The purpose of the BlueBox is to support medical training and quality improvement in code blue situations, and to enhance safety for patients undergoing CPR. In Phase II, our goal is to complete the product development and testing to prepare the BlueBox for regulatory clearance and market launch. To achieve this goal, we propose 3 Specific Aims: Specific Aim 1. Completing the product development of the BlueBox recorder and the software user interface (UI) for the “electronic code sheet” In Phase I, after developing the BlueBox technology and completing its proof-of-concept, the engineering prototype was tested successfully. The firmware drives all sensors and enables simultaneous recordings of all parameters with time stamps. The circuit can withstand 5kV, which is what is used in cardioversion and defibrillation. In Phase II, we will turn the prototype into a product ready for commercialization through rigorous product development processes. The product development processes include: miniaturization, mechanical design, industrial design, and usability engineering, as well as development of a mobile app for an iPad with an “electronic code sheet” user interface (UI) displaying the code blue events. To provide instant feedback during CPR, we will develop model-based and machine learning data analytics during and beyond the Phase II project. Specific Aim 2. Conducting human factors and usability testing, quality management and regulatory support and preparation We will conduct human factors and usability engineering (HF/UE) testing on the alpha prototype in the Simulation Center. The first HF/UE study aims to test the use of the BlueBox recorder by members and captains of the hospital code team in a code blue scenario. The second HF/UE study aims to test the software and UI of the electronic code sheet on iPads, as used by members of the hospital code blue team, hospital administrators, and EMR and IT specialists. We will establish and maintain quality management records and conduct a pilot production run of 200 units of BlueBox. The pilot run units will be tested for reliability and validity in the Simulation Center. We will request a pre-submission meeting (Qsub) with the FDA. In the Qsub meeting, we will discuss specific regulatory submission requirements and obtain feedback on the clinical validation study. Specific Aim 3. Validating the BlueBox system in clinical studies We will first conduct a prospective study of 50 sessions of simulated code blue resuscitations. Each session will be attended by a team of 4 clinicians-- a captain (physician), a nurse, an ancillary staff, and a code sheet recording staff (typically a nurse). We will also conduct a study of BlueBox sensor validation in 30 healthy volunteers. We will conduct a code blue simulation study on high fidelity mannequins with a hospital code blue team to compare BlueBox recording with paper code sheets. The objectives of the clinical studies are: 1) to establish equivalence of the electronic code sheet to the current standard of paper code sheet; 2) to demonstrate the effectiveness of the electronic code sheet in identifying key CPR quality indicators specified in the American Heart Association (AHA) guidelines. Feasibility Criteria: The criteria for successful development of the BlueBox are:1) it passes all required regulatory testing; 2) it is validated in the clinical study for its equivalence and effectiveness in code blue recording and quality review and improvement. Expected Outcomes and Impact: Two major milestones are (1) finalizing product development in Year 1, and (2) completing the clinical study in Year 2. Achieving the aims will result in a validated BlueBox system ready for regulatory submission to the FDA and commercialization. We intend to first market the BlueBox system to hospitals as a tool for staff training and quality improvement. We will continue the development of BlueBox technology with machine learning algorithms to provide instant feedback. Our ultimate goal is to minimize human error and improve patient outcomes through the BlueBox system’s continuous feedback mechanism. Debriefings and detailed reviews of the performance of the “code blue team” in cardiopulmonary resuscitation (CPR) can improve quality of care and patient outcomes. In Phase I, we developed and successfully tested an electronic device, the BlueBox, for recording all CPR events and enabling full displays of code blue resuscitations in an “electronic code sheet.” We will turn the engineering prototype into a product ready for regulatory submission and commercialization in the proposed Phase II project.","BlueBox: A Complete Code Blue Data Recorder, Phase II",9857035,R42GM113463,"['Accident and Emergency department', 'Adhesives', 'American Heart Association', 'Animals', 'Cardiac', 'Cardiopulmonary Resuscitation', 'Chest', 'Clinical', 'Clinical Research', 'Code', 'Code Blue', 'Data', 'Data Analytics', 'Development', 'Devices', 'Documentation', 'Effectiveness', 'Electric Countershock', 'Electronics', 'Emergency Situation', 'Engineering', 'Event', 'Family suidae', 'Feedback', 'Generations', 'Goals', 'Guidelines', 'Hospital Administrators', 'Hospitals', 'Human', 'Industrialization', 'Left', 'Machine Learning', 'Manikins', 'Measurement', 'Mechanics', 'Medical', 'Medical Errors', 'Miniaturization', 'Modeling', 'Outcome', 'Paper', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Pilot Projects', 'Preparation', 'Procedures', 'Process', 'Production', 'Quality Indicator', 'Quality of Care', 'Records', 'Resuscitation', 'Running', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specialist', 'Specific qualifier value', 'Sternum', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Validity and Reliability', 'base', 'care outcomes', 'commercialization', 'design', 'graphical user interface', 'heart rhythm', 'human error', 'improved', 'improved outcome', 'machine learning algorithm', 'meetings', 'member', 'mobile application', 'patient safety', 'product development', 'prototype', 'respiratory', 'sensor', 'simulation', 'technology development', 'tool', 'usability', 'validation studies']",NIGMS,"NEOVATIVE, INC.",R42,2020,821493,-0.016024973816097132
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9910382,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2020,510157,-0.01308682105336949
"S10 Shared Instrument Grant - Leica Aperio Digital Scanner GT450 This application is requesting funds to purchase the Aperio™ GT-450 digital pathology slide scanner from Leica Biosystems. The requested instrumentation will be located in the Pathology and Biobanking Core of the Lester and Sue Smith Breast Center at Baylor College of Medicine (BCM). The predominant use of the Aperio scanner will be research-based whole slide imaging (WSI) and analysis of patient specimens, patient-derived xenograft (PDX) cancer models, and pre-clinical investigations on various animal- and cell-line model systems. All user projects have large sample cohorts that require high throughput, high-resolution scanning and image analysis. High capacity and improved scanning with dynamic focusing makes the GT-450 microscope scanner well-suited and the most cost-effective for use in the proposed projects. An underlying theme in the studies selected for Aperio scanner-supported services integrates novel biomarker and molecular pathway discovery with spatial morphological characterization, a necessary process to investigate heterogeneity in disease states. This instrument leverages high-throughput scanning capability with open-source, fully customizable machine-learning analytics to meet the evolving needs of investigators at Baylor College of Medicine, in particular faculty groups studying mechanisms of cancer cell dynamics and the development of new therapeutic targets. Expansion of systems biology and precision medicine research is an essential component of the college’s strategic roadmap. The Aperio GT-450 is critically needed as we modernize our laboratory offerings and capabilities; the acquisition of this digital scanner will strengthen existing research programs underway and establish new, collaborative research opportunities and directions within Baylor College of Medicine and surrounding institutions. To address the growing demand for integrating quantitative spatial assessment of biomarkers with molecular pathway discovery, we request funding for the Leica Aperio GT-450 digital microscope scanner. This instrument will facilitate research that seeks to better understand molecular mechanisms of tumorigenesis in the context of its spatial environment and will be critical for the development of clinically correlative biomarkers for next generation precision medicine research initiatives at Baylor College of Medicine.",S10 Shared Instrument Grant - Leica Aperio Digital Scanner GT450,9940426,S10OD028671,"['Animals', 'Biological Models', 'Breast', 'Cancer Model', 'Cell Line', 'Development', 'Disease', 'Faculty', 'Funding', 'Grant', 'Heterogeneity', 'Image Analysis', 'Institution', 'Laboratories', 'Machine Learning', 'Medicine', 'Microscope', 'Modernization', 'Molecular', 'Morphology', 'Pathology', 'Pathway interactions', 'Patients', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Slide', 'Specimen', 'Systems Biology', 'Xenograft procedure', 'base', 'biobank', 'cancer cell', 'clinical investigation', 'cohort', 'college', 'cost effective', 'digital', 'digital pathology', 'improved', 'instrument', 'instrumentation', 'new therapeutic target', 'novel marker', 'open source', 'pre-clinical', 'precision medicine', 'programs', 'whole slide imaging']",OD,BAYLOR COLLEGE OF MEDICINE,S10,2020,477043,-0.03395078322238328
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9823881,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2020,401916,-0.020245141230480924
"Bioethics of syndrome diagnosis using 3D image analysis Project Summary/Abstract This supplement will address the unintended consequences and collateral damage that arise when facial recognition software is used for medical purposes, such as for syndrome diagnosis as in our Facebase-funded project. In Aim 1, we will determine whether the accuracy of this technology varies based on self-reported race, sex and age. In this aim, we examine our existing database for evidence of bias based on self-reported race, sex or age. We further determine the extent to which these variables influence classification performance. To the extent sample sizes allow, we will carry this analysis to the level of specific syndromes. Finally, we will use anonymized reference datasets of non-syndromic faces to compare false positive rates based on NIH race definitions, sex and age. The outcome of this aim is to objectively establish bias and estimate the effects of under-representation across race, age and sex categories within our data. In Aim 2, we will determine how the reports of race-, sex- and age-based bias in facial recognition technology may influence views of the technology and its application amongst researchers and clinicians. This aim will establish the extent to which the storing of large databases of facial images and the application of machine learning processes to them for diagnostic purposes may raise privacy concerns. The concerns investigated will include potential hacks into protected health information; fear relating to the bias in some facial recognition software (and, potentially, in the Facebase database); and fear of discrimination in the application of the technology, such as by insurers. The outcome will be a white paper that targets a high-profile journal, summarizing the findings and defining crucial issues that should guide the development of facial imaging for disease diagnosis and clinical usage. Project Narrative Our supplement application will address the important question of unintended consequences and collateral damage when facial recognition software is used for medical purposes, such as for syndrome diagnosis as in our Facebase-funded project. The use of large facial recognition databases in medicine represents a frontier that arrives with tremendous potential but undeniable risks. Our central aims are: (1) determine whether the accuracy of this technology varies based on self-reported race, sex and age; and (2) determine how the reports of race-, sex- and age-based bias in facial recognition technology may influence views of the technology and its application amongst researchers and clinicians.",Bioethics of syndrome diagnosis using 3D image analysis,10132648,U01DE028729,"['3-Dimensional', 'Address', 'Age', 'Authoritarianism', 'Bioethical Issues', 'Bioethics', 'Biometry', 'Categories', 'Classification', 'Clinic', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Computational Biology', 'Country', 'Data', 'Data Science', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Ethics', 'Face', 'FaceBase', 'Fright', 'Funding', 'General Hospitals', 'Generations', 'Genes', 'Genetic Diseases', 'Health', 'Hereditary Disease', 'Image', 'Image Analysis', 'Insurance Carriers', 'Journals', 'Libraries', 'Machine Learning', 'Medical', 'Medicine', 'Outcome', 'Paper', 'Pathology', 'Patient Self-Report', 'Patient imaging', 'Performance', 'Privacy', 'Private Sector', 'Process', 'Psychiatry', 'Public Sector', 'Race', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sample Size', 'San Francisco', 'Secure', 'Syndrome', 'Technology', 'Three-Dimensional Image', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'craniofacial', 'disease diagnosis', 'facial recognition software', 'frontier', 'human data', 'intervention cost', 'new technology', 'professor', 'repository', 'sex', 'tool']",NIDCR,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2020,152200,-0.0001987994358804621
"Development of a biomarker panel for minimally-invasive screening and diagnosis of gynecological disease PROJECT SUMMARY One-third of all women of reproductive age will experience nonmenstrual pelvic pain at some point in their lives and one-third of outpatient visits to gynecologists in the U.S. are for evaluation of abnormal uterine bleeding. For many women, these symptoms accompany infertility which is reported in ~10% of all US women and even higher percentages worldwide. For almost all of these women, these conditions result in a diagnostic odyssey wherein women struggle through multiple physicians over many years for a definitive diagnosis, frequently culminating in invasive laparoscopy or hysteroscopy with dilation and curettage (D&C) for definitive diagnosis. To reduce the burden of diagnosis and enable early treatment, MDDx, Inc. is developing the first biomarker- based diagnostic test to enable minimally invasive simultaneous diagnosis of four of the most common causes which together result in chronic pain, uterine bleeding and infertility: adenomyosis, endometrial polyps, leiomyoma, and endometriosis. MDDx, Inc. has been leveraging access to >12 years of longitudinally collected and deeply annotated biobanked uterine lavage samples from the Gynecologic Cancer Translational Research Program (Icahn School of Medicine at Mount Sinai; New York, NY and Nuvance Health; Danbury, CT) to identify diagnostic autoantibodies (AAb) that could serve as diagnostic biomarkers for these benign gynecological diseases. By performing AAb profiling against the entire human proteome and applying our novel machine-learning based method for classification of molecular profiles we have determined that there is a common set of ~200 biomarkers that could be used to diagnose women with adenomyosis, endometrial polyps, leiomyoma, or endometriosis. The goal of Phase I is to finalize and validate the optimized set of ~200 diagnostic AAbs, while Phase II will focus on validation of the commercial diagnostic assay. In Aim 1 we will expand our proprietary database of uterine lavage autoantibody profiles to ensure that we have a sample size (~935) that will enable us to confidently apply our machine learning approaches to identifying the minimal panel of AAbs for the diagnostic. We will use this enhanced database to identify a prototype panel of ~200 AAbs for construction of classification scoring functions to distinguish between adenomyosis, endometrial polyps, leiomyoma, and endometriosis. In Aim 2 we will perform a blinded validation and performance study using an independent set of 300 uterine lavage samples to provide proof-of- concept for clinically useful sensitivity and specificity prior to large scale prospective validation in Phase II. Successful completion of this Phase I program will identify the optimized panel of AAbs for an affordable, laboratory-based diagnostic test that will significantly reduce the number of women who will need to undergo laparoscopy or hysteroscopy with D&C for definitive diagnosis, enabling early treatment of disease and reducing the significant psychological and financial burden of diagnoses that otherwise can take years. PROJECTIVE NARRATIVE Nearly half of all women of reproductive age will experience some combination of nonmenstrual pelvic pain, abnormal uterine bleeding, and infertility in their lifetimes, yet there are no non-invasive methods to definitively diagnose the primary causes of these symptoms. MDDx, Inc. is developing the first laboratory diagnostic test to enable minimally invasive simultaneous diagnosis of four common causes of these often debilitating symptoms and infertility: adenomyosis, endometrial polyps, leiomyoma, and endometriosis. This test will enable early detection, early treatment, and reduce the physical, emotional, and financial burden of obtaining a diagnosis for women suffering from these common yet disruptive symptoms.",Development of a biomarker panel for minimally-invasive screening and diagnosis of gynecological disease,10146682,R41HD104402,"['Address', 'Age', 'Algorithms', 'Anesthesia procedures', 'Antigens', 'Area', 'Atypical Endometrial Hyperplasias', 'Autoantibodies', 'Benign', 'Biological Markers', 'Blinded', 'Categories', 'Classification', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Dilatation and Curettage', 'Disease', 'Early Diagnosis', 'Early treatment', 'Emotional', 'Endometrial Carcinoma', 'Ensure', 'Entropy', 'Evaluation', 'Female Genital Diseases', 'Financial Hardship', 'General Anesthesia', 'Goals', 'Gynecologist', 'Health', 'Healthcare Systems', 'Hemorrhage', 'Human', 'Hysteroscopy', 'Image', 'Infertility', 'Irrigation', 'Laboratories', 'Laparoscopy', 'Leiomyoma', 'Liquid substance', 'Machine Learning', 'Malignant Female Reproductive System Neoplasm', 'Malignant neoplasm of ovary', 'Methods', 'Molecular', 'Molecular Profiling', 'New York', 'Operating Rooms', 'Outpatients', 'Pain', 'Patients', 'Pelvic Pain', 'Performance', 'Phase', 'Physicians', 'Polyps', 'Population Control', 'Positioning Attribute', 'Preneoplastic Conditions', 'Probability', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Recording of previous events', 'Reporting', 'Risk', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Specificity', 'Structure', 'Surgeon', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Triage', 'United States', 'Uterine Polyp', 'Uterine hemorrhage', 'Uterus', 'Validation', 'Visit', 'Woman', 'Work', 'base', 'biobank', 'biomarker panel', 'chronic pain', 'clinically relevant', 'cost', 'diagnostic assay', 'diagnostic biomarker', 'diagnostic panel', 'disabling symptom', 'disease diagnosis', 'endometriosis', 'experience', 'improved', 'large datasets', 'medical schools', 'minimally invasive', 'novel', 'phase 1 study', 'programs', 'prospective', 'prototype', 'psychologic', 'reproductive', 'screening', 'translational research program', 'uterus endometriosis']",NICHD,"MDDX, INC.",R41,2020,299998,-0.05135208393008502
"An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis Project Summary  Improved methods for the bedside diagnosis and evaluation of neuromuscular disorders are needed. One technology that is finding increasing use for this purpose is electrical impedance myography (EIM). In EIM, a very weak, high frequency electrical current is passed through a muscle of interest and the resulting surface voltages are measured. Disease associated alterations in the composition and microstructural features of the muscle produce characteristic changes that can be used to help classify specific conditions and grade disease severity. To date, most studies using EIM analysis have utilized a fairly limited data set for disease assessment. While effective, this approach ignores a great deal of information locked within the impedance data, including those values that can assist in predicting specific muscle features (such as myofiber diameter) and the presence of pathological change (e.g., fat or connective tissue deposition). In addition, as it stands, the data set is challenging for the clinician to understand without a detailed knowledge of impedance theory. Myolex, Inc is a small business concern located in Boston, MA has as its main focus the development of EIM technologies for clinical use. Myolex recently completed a Phase 1 SBIR that demonstrated the potential capability of machine learning based classification algorithms to effectively discriminate healthy muscle from diseased and to discriminate one disease from another. In this proposed work, we will greatly advance this concept by embodying classification algorithms into a powerful new software suite for Myolex’s current EIM system, the mView. Our underlying hypothesis is that EIM data analysis can be automated to the point that classification systems can provide data on disease diagnosis as well as disease severity for improved ease-of-use. We propose to study this hypothesis via 2 specific aims. In Specific Aim 1, we will design a software suite capable of assisting with artifact-free data collection to be incorporated into our current EIM system, the mViewTM. Then using classification paradigms based on a prodigious amount of previous collected data, we will develop an automated data analysis tool to help provide data on disease category as well as microscopic features, muscle based on the impedance data alone using Microsoft’s Azure Cloud platform. In Specific Aim 2, we will test this developed software suite in a total of180 adult and pediatric neuromuscular disease patients and healthy participants evaluated at Ohio State University Wexner Medical Center (adults) and Boston Children’s Hospital (children). During this data collection period, the Ohio State and Boston Children’s researchers will have real- time access to Myolex staff to provide feedback and have questions/problems answered and addressed. The user interface will continue to be refined and classification algorithms improved. At the conclusion of this work, a new diagnostic tool will be developed for potential 510(k) FDA approval. It will serve as the basis for a continuously self-refining system as additional data sets are collected by end-users employing them in regular clinical use. Project Narrative  Electrical impedance myography (EIM) is a valuable technique to assist with the evaluation of a variety of conditions affecting nerve and muscle. However, to date, only simplistic EIM outcomes have been utilized to assess muscle condition. In this proposed work, we will develop a software platform using machine learning to be incorporated into current EIM technology to allow for automated diseased classification and characterization using the entire large EIM data set collected with each muscle measurement. This will serve as the basis for a new, powerful and convenient tool for neuromuscular diagnosis that will continue to advance over time.",An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis,10002324,R44NS113756,"['Address', 'Adult', 'Affect', 'Algorithmic Software', 'Amyotrophic Lateral Sclerosis', 'Area', 'Back Pain', 'Boston', 'Businesses', 'Caliber', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Classification', 'Clinical', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Set', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Duchenne muscular dystrophy', 'Effectiveness', 'Electrodes', 'Ensure', 'Evaluation', 'Fatty acid glycerol esters', 'Feedback', 'Fiber', 'Frequencies', 'Functional disorder', 'Health', 'Inclusion Body Myositis', 'Individual', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Medical Technology', 'Medical center', 'Methods', 'Microscopic', 'Morphologic artifacts', 'Muscle', 'Muscular Dystrophies', 'Myography', 'Myopathy', 'Myositis', 'Nerve', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Ohio', 'Outcome', 'Participant', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Provider', 'Radiculopathy', 'Research Personnel', 'Role', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Work', 'advanced analytics', 'base', 'classification algorithm', 'cloud based', 'cloud platform', 'commercialization', 'complex data ', 'data acquisition', 'design', 'diagnosis evaluation', 'disease classification', 'disease diagnosis', 'electric impedance', 'feature extraction', 'improved', 'indexing', 'interest', 'machine learning algorithm', 'method development', 'nerve injury', 'neuromuscular', 'novel diagnostics', 'pediatric patients', 'physical therapist', 'prototype', 'sarcopenia', 'software development', 'success', 'theories', 'tool', 'usability', 'user friendly software', 'user-friendly', 'voltage']",NINDS,"MYOLEX, INC.",R44,2020,869698,-0.013737642556120519
"Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease. ABSTRACT More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease (LD). While the CDC conventional standard two-tier (CSTT) approach for serodiagnosis of LD has worked relatively well when used as recommended, there is plenty of room for improvement. Of a number of weaknesses associated with the supplemental immunoblot of the CSTT the most significant is low reproducibility due to the subjective visual interpretation of results. To overcome these weaknesses the CDC recently updated its recommendations based on a modified STT (MSTT) in that a second EIA can replace the immunoblot. The major goal of this project is to develop an objective, quantitative, multiplex EIA that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens to build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity. The novelty of this study relies on: 1) evaluation of B. burgdorferi antigen-specific antibody isotypes and IgG subclasses that can be correlated with Lyme disease stage; and 2) development of new diagnostic tools using machine learning techniques to train and integrate all data and produce an objective result to discriminate early Lyme from early disseminated/late Lyme disease. We expect this Phase I SBIR to allow us to develop a new EIA for serodiagnosis of Lyme disease (isoEIAplex-Ld) and to further an ongoing collaboration with DCN diagnostics for the adaptation of our biomarkers to a new rapid Lateral Flow Assay (see Letter of Support) for a follow up Phase II SBIR . NARRATIVE More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease. While the CDC conventional standard two-tier approach for serodiagnosis of Lyme disease has worked relatively well when used as recommended, there is plenty of room for improvement. We propose to develop an objective multiplex enzyme immunoassay that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens and build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity.",Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease.,10080461,R43AI155211,"['Acute', 'Acute Disease', 'Affinity', 'Antibodies', 'Antibody Response', 'Antigens', 'Arthritis', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Borrelia burgdorferi', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Collaborations', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Specificity', 'Discrimination', 'Disease', 'Early Diagnosis', 'Enzyme Immunoassay', 'Evaluation', 'GTP-Binding Protein alpha Subunits, Gs', 'Genetic Recombination', 'Goals', 'Grant', 'High Prevalence', 'Human', 'IgA1', 'IgA2', 'IgE', 'IgG1', 'IgG2', 'IgG3', 'IgG4', 'Immune response', 'Immunodominant Antigens', 'Immunoglobulin A', 'Immunoglobulin D', 'Immunoglobulin G', 'Immunoglobulin Isotypes', 'Immunoglobulin M', 'Immunoglobulins', 'Infection', 'Iowa', 'Laboratories', 'Laboratory Diagnosis', 'Lateral', 'Lesion', 'Letters', 'Licensing', 'Lyme Arthritis', 'Lyme Disease', 'Machine Learning', 'OspC protein', 'Patients', 'Peptidoglycan', 'Performance', 'Phase', 'Proteins', 'ROC Curve', 'Recommendation', 'Reproducibility', 'Research', 'Serum', 'Small Business Innovation Research Grant', 'Specificity', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'V(D)J Recombination', 'Visual', 'Work', 'antigen binding', 'base', 'commercialization', 'disease diagnosis', 'erythema migrans', 'follow-up', 'improved', 'novel diagnostics', 'pathogen', 'tool']",NIAID,"IMMUNO TECHNOLOGIES, INC.",R43,2020,298123,-0.011680928146062253
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,9855767,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2020,1835520,-0.007518971448113235
"Graphene-based Nanosensor Device for Rapid, Onsite Detection of Total Lead in Tap Water PROJECT SUMMARY Detrimental health impacts of lead are largely attributed to long-term exposures to undetected lead, which are particularly troublesome and problematic because of the neurological damage to children, a situation that should not be tolerated by an advanced society like the U.S. The Flint Water Crisis and many other water catastrophes could have been avoided if early warning can be made possible through timely detection of lead in drinking water at the point of use. Our extensive customer interviews unambiguously suggest that current options for lead detection are unsatisfactory for on-site testing, as they represent two extremes: one being accurate but expensive, slow, and hard to use; and the other being low-cost, fast, and easy to use but inaccurate. NanoAffix Science LLC (NAFX) proposes to address the above unmet need and niche market product gap by empowering water users (particularly those in economically disadvantaged communities) and water service providers with a low-cost, easy-to-use, and accurate handheld tester for rapid detection of total lead in the tap water, right from the kitchen sink. The handheld lead tester combines a novel proprietary micro-sized sensor chip embedded in a proprietary test cell with a portable digital meter for direct readout of testing results. The Phase I project has successfully established the feasibility for detection of soluble lead in the tap water using an earlier version of the prototype handheld tester. The Phase II project will continue to develop the handheld tester toward total lead detection, better device uniformity, pilot scale-up manufacturing, and accurate calibration. At the end of the Phase II project, NAFX plans to produce 20 beta units of the handheld lead tester meeting all performance specifications for field validation by 10 initial customers (e.g., schools/daycares, end water users, and well water drillers). Major innovations of the proposed approach include accurate prediction of the particulate lead through partial digestion based on lead digestion kinetics, and strategic and synergistic improvement of the ultimate sensor prediction accuracy by (1) improving the physical sensor device uniformity (both intra-wafer and inter-wafer) through innovative device configuration and rigorous quality control; and (2) improving the calibration accuracy through innovative theoretical equilibrium chemistry modeling and machine learning data analytics. The NAFX handheld lead tester is the first of its kind to (1) offer all three features sought by customers: accurate, cheap, and fast; and (2) to simultaneously report all three types of lead: total lead (indicative of overall toxicity), soluble lead (indicative of slow leaching of lead), and particulate lead (indicative of sporadic flaking of lead), which thus can not only alert customers to the lead hazard in their drinking water but also enable customers to identify possible causes and most effective solutions to mitigate the lead contamination. Therefore, the project will result in not only considerable economic impact but also immense societal impact. The regular use of NAFX handheld tester - even if intermittently - will virtually eliminate the chance of chronic exposure to undetected lead, thereby accruing significant and predictable public health impact, especially in locations with the highest risk. PROJECT NARRATIVE The NanoAffix Phase II project aims to continue the development of a handheld lead tester for accurate and low- cost onsite detection of total lead in tap water by untrained users, based on the success of the Phase I project. The project will contribute to enhancing the public health by offering an accessible tool for quantitative monitoring of all three types of lead: total lead (indicative of overall toxicity), soluble lead (indicative of slow leaching of lead), and particulate lead (indicative of sporadic flaking of lead) in tap water. The regular use of NanoAffix handheld tester - even if intermittently - will virtually eliminate the chance of chronic exposure to undetected lead, thereby accruing significant and predictable public health impact, especially in locations with the highest risk.","Graphene-based Nanosensor Device for Rapid, Onsite Detection of Total Lead in Tap Water",10024064,R44ES028656,"['Address', 'Algorithms', 'Calibration', 'Cations', 'Cells', 'Chemistry', 'Child', 'Chronic', 'Communication', 'Communities', 'Complex', 'Contracts', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Digestion', 'Disinfection', 'Economically Deprived Population', 'Equilibrium', 'Equipment', 'Exposure to', 'Goals', 'Gold', 'Health', 'International', 'Interview', 'Kinetics', 'Laboratories', 'Lead', 'Lead Poisoning', 'Location', 'Machine Learning', 'Measurement', 'Michigan', 'Modeling', 'Monitor', 'Nervous System Trauma', 'Paper', 'Particulate', 'Performance', 'Phase', 'Procedures', 'Process', 'Public Health', 'Quality Control', 'Reporting', 'Research', 'Schools', 'Science', 'Site', 'Societies', 'Specialist', 'System', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Validation', 'Variant', 'Water', 'Water Supply', 'Wireless Technology', 'aqueous', 'base', 'cost', 'digital', 'drinking water', 'economic impact', 'empowered', 'graphene', 'hazard', 'high risk', 'improved', 'innovation', 'lead concentration', 'lead contamination', 'manufacturing scale-up', 'meetings', 'meter', 'nanosensors', 'novel', 'operation', 'portability', 'prototype', 'rapid detection', 'real time monitoring', 'response', 'sample collection', 'sensor', 'service providers', 'success', 'tool', 'virtual', 'water quality', 'well water']",NIEHS,"NANOAFFIX SCIENCE, LLC",R44,2020,719088,0.0002683487443353725
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,9942461,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Models', 'Cornea', 'Corneal Diseases', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2020,391938,-0.0018601349040334799
"Clinical Evaluation of Burns using Spatial Frequency Domain Imaging Program Director/Principal Investigator (Last, First, Middle): Durkin, Anthony J. Abstract The central aim of this 3 year competing R01 renewal is to characterize and apply a new, compact, clinic- friendly Spatial Frequency Domain Imaging (SFDI) device to objectively and non-invasively classify burn severity (burn grade) over a large areas of skin. Delays in determining burn severity directly impacts patient treatment plans (including decisions whether to graft), rates of infection and scarring, duration of hospitalization and ultimately cost of care. Currently, the primary method of determining burn severity continues to be clinical assessment, which is highly subjective. While both superficial thickness and full-thickness burns are typically readily diagnosed based on visual clinical impression, partial thickness burns are difficult to classify and carry with them considerable potential for complications. Burn severity classification accuracy, even by experts, is only 60–80%. Our research in animal models demonstrates that SFDI data can successfully be used to classify different regions of burn severities. Typically, these differences are not apparent to the unaided eye and a great deal of training and experience is required in order for clinicians to accurately differentiate them Our work using a research grade, hybrid-SFDI device suggests that objective parameters provided by SFDI can be used within 24 hours after injury, to accurately classify burn severity. Specifically, we have demonstrated in a porcine burn model that the research grade SFDI outperforms laser speckle imaging and thermal imaging at 24 hours post-burn, in terms of predicting whether a burn will require a graft or not. However, translating these results to the clinic has been difficult due to several device limitations. The research grade SFDI device has slow acquisition times that can result in motion artifacts. It is also sensitive to ambient light which is often an issue in a clinical setting. Additionally, the SFDI device generates so much diverse data (oxygenated and deoxygenated hemoglobin, water fraction, reduced scattering coefficients at multiple wavelengths), there is no obvious way to present it to a clinical user to make a quick decision. To this end, we propose to methodically investigate an improved next generation SFDI device that addresses these issues by using brighter LEDs and fewer wavelengths to rapidly collect data in a way that reduces motion artifacts and is independent of clinical lighting conditions. In addition, we will develop a machine learning based classification framework that will provide the clinical with actionalble diagnostic information. The central aim of this 3 year competing R01 renewal is to characterize and then modify a new clinic-friendly SFDI device (Clarifi) to objectively classify in- vivo regions of different burn severity over large areas. The proposed research seeks to investigate this via the following Specific Aims: 1) Test & Validate Clinical SFDI Instrument, 2) Compare Clinical SFDI Instrument to other Modalities on a Long Term Swine Model of Graded Burns, 3) Develop Spatially Resolved Classification Maps of Burn Severity based on SFDI Data, 4) Conduct Clinical Measurements of Burn Severity using the new SFDI device and Spatially Resolved Burn Severity Classification Maps based on SFDI data. Program Director (Last, first, middle): Durkin, Anthony J. PROJECT NARRATIVE Burn injuries rank in the top 15 causes of global burden of disease. Burn severity assessment, which is a critical step in treatment planning, is subjective, depending on the experience of the treating physician. This leads to misdiagnosis and increased days of hospitalization and cost. In order to address this, we propose to test, validate and apply a novel optical imaging device in order to provide noninvasive objective assessment of burn wound severity. This has the potential to improve management of burn patients and reduce rates of complications.",Clinical Evaluation of Burns using Spatial Frequency Domain Imaging,10052657,R01GM108634,"['Address', 'Animal Model', 'Area', 'Biometry', 'Blood Vessels', 'Burn Centers', 'Burn injury', 'Cicatrix', 'Classification', 'Clinic', 'Clinical', 'Clinical assessments', 'Collaborations', 'Custom', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Enrollment', 'Eye', 'Family suidae', 'Female', 'Hemoglobin', 'Hospital Costs', 'Hospitalization', 'Hour', 'Hybrids', 'Image', 'Imaging Device', 'Injury', 'Laser Speckle Imaging', 'Lasers', 'Light', 'Lighting', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical center', 'Methods', 'Modality', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Optics', 'Output', 'Patients', 'Physicians', 'Principal Investigator', 'Property', 'Reporting', 'Research', 'Severities', 'Side', 'Signal Transduction', 'Skin', 'Spatial Frequency Domain Imaging', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translating', 'Ulcer', 'Variant', 'Visual', 'Water', 'Work', 'base', 'burden of illness', 'burn model', 'burn wound', 'care costs', 'clinical imaging', 'cost', 'data acquisition', 'data integrity', 'data modeling', 'diverse data', 'experience', 'healing', 'human data', 'imaging system', 'impression', 'improved', 'in vivo', 'infection rate', 'male', 'next generation', 'novel', 'optical imaging', 'pre-clinical', 'programs', 'research clinical testing', 'stability testing', 'treatment planning']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2020,430325,-0.001327747499942696
"An Unobtrusive Continuous Cuff-less Blood Pressure Monitor for Nocturnal Hypertension PROJECT SUMMARY/ABSTRACT The objective of this project is to create an unobtrusive, wrist-worn, cuff-less blood pressure monitor for measurement and identification of nocturnal nondipping hypertension. The investigation includes extensive validation with state-of-the-art ambulatory blood pressure monitors at nighttime in presence of heterogeneous treatment paradigms. Cardiovascular disease (CVD) is one of the major causes of ailments worldwide. Hypertension alone affects one in three adults according to the World Health Organization. Therefore, monitoring blood pressure has become a critical part of healthcare as it is known to be linked to many CVDs. Traditionally, clinical practitioners have relied on the mercury-based (or digital equivalent) inflatable cuff-based sphygmomanometer. However, the nature of the device allows for only infrequent measurements and its somewhat invasive nature and associated discomfort prohibits additional nocturnal measurements. There is certainly a value to measuring blood pressure continuously in the natural context of the user’s environment, in particular during sleep, without being disturbed by the instrument. Our proposed technology can provide a wealth of information to physicians, help identify certain short-term dynamics/variations of blood pressure, and allow effective monitoring of response to medication, among other things. Nocturnal measurements provide additional prognostic value in identifying risk. Despite these benefits, no wearable, non-invasive device for continuous blood pressure monitoring exists on the market simply because none have been reliable enough to be considered clinical grade. This project aims to develop a robust and reliable blood pressure monitor in the form of a wrist-worn device that uses bio-impedance sensors, and for the first time, demonstrate clinical grade reliability. These sensors measure pulse wave velocity (PWV) along with several other derivatives for cardiovascular parameters including heart rate and blood volume changes in arteries, which correlate with the blood pressure. The system will incorporate clever hardware design to localize underlying vasculature and focus on arterial sites for enhanced accuracy. The device will include a motion sensor to take into account the user’s movements and motion artifacts, the contact quality, and reliability of the measurements. Advanced machine learning techniques, leveraging both general and personalized models, will be developed to convert bio-impedance measurements to blood pressure. This project aims to then validate the system and analytics in both a healthy patient cohort and a hypertensive cohort, learning the impact that nocturnal ‘nondipping’ hypertension and anti-hypertensive treatments have on PWV/other cardiovascular correlates and blood pressure estimates. After decades of relying on the inflatable cuff- based technique, this system could represent a significant change in how we measure blood pressure. PROJECT NARRATIVE Continuous monitoring of nocturnal blood pressure can help early diagnosis of developing cardiac conditions, reveal short term blood pressure variations, and also help the physician monitor differences in variations in response to medication for hypertensive patients. Moreover, the comfort and convenience of a wearable monitor would allow measurement in the natural context of daily life, including important nocturnal measurements, and reduce the burden of adherence on the user. The system will also provide feedback on quality of measurements to allow the users or care-givers to gauge reliability.",An Unobtrusive Continuous Cuff-less Blood Pressure Monitor for Nocturnal Hypertension,9998433,R01HL151240,"['Adherence', 'Adult', 'Affect', 'Age', 'Ambulatory Blood Pressure Monitoring', 'Antihypertensive Agents', 'Arteries', 'Awareness', 'Biometry', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood Volume', 'Blood flow', 'Calibration', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Characteristics', 'Clinical', 'Data', 'Data Collection', 'Development', 'Devices', 'Early Diagnosis', 'Environment', 'FDA approved', 'Feedback', 'Future', 'Gold', 'Healthcare', 'Heart Rate', 'Home environment', 'Hour', 'Human', 'Hypertension', 'Investigation', 'Learning', 'Legal patent', 'Life', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mercury', 'Methods', 'Microfabrication', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Movement', 'Nature', 'Organ', 'Outcome', 'Outcomes Research', 'Participant', 'Patient Monitoring', 'Patient risk', 'Patients', 'Pattern', 'Penetration', 'Pharmaceutical Preparations', 'Physicians', 'Physiologic pulse', 'Physiology', 'Positioning Attribute', 'Proxy', 'Reading', 'Recording of previous events', 'Regimen', 'Research', 'Risk', 'Risk Factors', 'Science', 'Signal Transduction', 'Site', 'Skin', 'Sleep', 'Sleep Deprivation', 'Sphygmomanometers', 'Structural Models', 'Supine Position', 'System', 'Techniques', 'Technology', 'Time', 'Uncertainty', 'Validation', 'Variant', 'Work', 'World Health Organization', 'Wrist', 'advanced analytics', 'analytical method', 'arterial stiffness', 'base', 'cohort', 'comorbidity', 'design', 'digital', 'effectiveness validation', 'electric impedance', 'insight', 'instrument', 'model development', 'monitoring device', 'motion sensor', 'multidisciplinary', 'novel', 'novel strategies', 'patient stratification', 'patient subsets', 'performance tests', 'prognostic value', 'response', 'sensor', 'sex', 'sleep position', 'supine sleep', 'wearable device', 'wearable sensor technology', 'willingness']",NHLBI,TEXAS ENGINEERING EXPERIMENT STATION,R01,2020,766675,-0.01648058846950492
"Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients Esophageal adenocarcinoma (EAC) is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. Barrett’s esophagus (BE) confers elevated risk for progression to EAC. Patients diagnosed with BE undergo periodic surveillance endoscopy with biopsies to detect dysplasia which can be treated by endoscopic eradication with radiofrequency ablation before it progresses to EAC. However, the majority of diagnosed EAC patients have not had prior screening endoscopy and present with advanced lesions that limit treatment options and result in poorer survival. The development of a rapid, low cost, well tolerated, non-endoscopic BE screening technique that can be performed in unsedated patients at points of care outside the endoscopy suite would improve BE detection and reduce EAC morbidity and mortality. Our program is a multidisciplinary collaboration among investigators at the Massachusetts Institute Technology and Veteran Affairs Boston Healthcare System / Harvard Medical School that integrates novel optical imaging and software design, preclinical studies in swine, clinical studies in patients, and advanced image processing / machine learning. Aim 1 will develop an omniview tethered capsule technology that generates a map of the esophageal mucosa over a multi-centimeter length of esophagus and a series of wide angle forward views to aid navigation as the capsule is swallowed or retracted. The images will resemble endoscopic white light or narrow band imaging, but will not suffer from perspective distortion present in standard endoscopic or video capsule images. This will facilitate development of automated BE detection algorithms as well as enhance their sensitivity and specificity. This aim will also perform imaging studies in swine as a translational step toward clinical studies. Aim 2 will determine reader sensitivity and specificity for BE detection versus standard endoscopy / biopsy and prepare data for developing automated BE detection. Patients undergoing screening as well as with history of BE undergoing surveillance will be recruited and unsedated capsule imaging will be performed on the same day prior to their endoscopy. Sensitivity and specificity for detecting BE will be assessed using multiple blinded readers and data sets suitable for developing automated BE detection algorithms will be developed. Aim 3 will develop image analysis methods for automated BE detection by investigating classifiers that operate on handcrafted features (colors and textures) and modern deep convolutional neural network methods for direct classification. If successful, this program will develop a rapid, low cost and scalable method for BE screening that would not require patient sedation, endoscopy, or tissue acquisition, and which could be performed in community primary care clinics. The procedure would be much faster and many times lower cost than endoscopy. Automated BE detection would enable immediate results for patient consultation and referral to gastroenterology if indicated. Larger patient populations with expanded risk criteria could be cost effectively screened and access to screening dramatically improved, reducing EAC mortality. Esophageal adenocarcinoma is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. The program proposes to develop an omniview tethered capsule technology, examination protocol, and automated analysis methods for low cost, rapid, well tolerated, and scalable screening in order to facilitate monitoring and timely treatment. Larger patient populations could be cost effectively screened and access to screening dramatically improved, reducing mortality.","Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients",10033192,R01CA252216,"['Algorithmic Software', 'Algorithms', 'Back', 'Barrett Esophagus', 'Biopsy', 'Blinded', 'Blood Vessels', 'Boston', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Color', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Set', 'Deglutition', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dysplasia', 'Endoscopic Biopsy', 'Endoscopy', 'Esophageal Adenocarcinoma', 'Esophageal mucous membrane', 'Esophagus', 'Family suidae', 'Gastroenterologist', 'Gastroenterology', 'Gastroesophageal reflux disease', 'Healthcare Systems', 'Histology', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Institutes', 'Interdisciplinary Study', 'Label', 'Length', 'Lesion', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Massachusetts', 'Measures', 'Methods', 'Modernization', 'Monitor', 'Morbidity - disease rate', 'Mucous Membrane', 'Nurse Practitioners', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Population', 'Primary Care Physician', 'Primary Health Care', 'Procedures', 'Protocols documentation', 'Radiofrequency Interstitial Ablation', 'Reader', 'Reading', 'Recording of previous events', 'Referral and Consultation', 'Research Personnel', 'Resolution', 'Risk', 'Screening Result', 'Sedation procedure', 'Sensitivity and Specificity', 'Series', 'Side', 'Software Design', 'Stomach', 'Surface', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'Validation', 'Veterans', 'advanced disease', 'automated analysis', 'automated image analysis', 'base', 'capsule', 'clinical imaging', 'convolutional neural network', 'cost', 'design', 'graphical user interface', 'image processing', 'imaging software', 'imaging study', 'improved', 'medical schools', 'mortality', 'navigation aid', 'novel', 'optical imaging', 'patient population', 'point of care', 'preclinical study', 'programs', 'recruit', 'screening']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,336293,-0.023770638953849146
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and affect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable of discovering local and global alteration of matter without the need to apriori select an anatomical region of interest. The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image datasets is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focuses on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10139715,R42MH118845,"['Affect', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Blood flow', 'Brain', 'Clinical', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Data Set', 'Databases', 'Detection', 'Deterioration', 'Diffuse', 'Disease', 'Drug Screening', 'Goals', 'Grain', 'HIV', 'Image', 'Image Analysis', 'Internet', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Measures', 'Medical Imaging', 'Metabolic', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurologic Effect', 'Neurosurgeon', 'Online Systems', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Analysis', 'Population Study', 'Positioning Attribute', 'Process', 'Questionnaires', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Software Validation', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Variant', 'Visualization', 'Washington', 'analysis pipeline', 'base', 'data access', 'data infrastructure', 'deep learning', 'experience', 'gray matter', 'high throughput screening', 'image registration', 'imaging capabilities', 'improved', 'insight', 'interest', 'metabolic rate', 'morphometry', 'nervous system disorder', 'neurodegenerative dementia', 'novel', 'programs', 'prototype', 'regional difference', 'research and development', 'shape analysis', 'software development', 'software infrastructure', 'task analysis', 'tool', 'usability', 'web app', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R42,2020,456359,-0.023745272644196683
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10153499,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Health', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'digital', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2020,511154,-0.026796258115883397
"Human Tumor Atlas Network: Data Coordinating Center Supplement This proposal is a collaboration with the HTAN Data Coordination Center DCC and describes an Image Data Project aimed at developing and deploying the technology needed for storage, distribution and basic analysis of cell and tissue images collected by multiple HTAN Centers. Multiplexed tissue images are an important type of data for nearly all of the centers contributing to the HTAN (second only to single cell sequencing data in number of centers collecting data). However, the software needed to visualize, analyze, manage, and share multiplexed images of tissues and tumors is underdeveloped. The initial availability of SARDANA images has highlighted the challenges faced by HTAN, including the DCC, in deploying an infrastructure for distributing large and complex images. We therefore propose a two-year HTAN Image Data Project (IDP) led by the DCC and HMS PCA focused on the rapid development and deployment of image informatic systems and computational resources for image management and analysis. Our goal is to put in place a functional first-generation system no later than summer 2020 and to then steadily refine the system so that it becomes the backbone of cross-functional HTAN atlases. As a matter of necessity, we will start with informatic systems and software that are either available today or in a relatively advanced state of development. However, we expect to evaluate these choices throughout the IDP and change course as necessary to incorporate potentially superior approaches. We will also support the diverse needs and formats of centers using different data collection methods. Aim 1 will focus on the deployment and progressive improvement of a cloud-based database for image management based on the OMERO standard as well as a parallel system for access to primary data. Aim 2 will develop and deploy software for visualizing HTAN image data by the general public. The IDP will use the existing MCWG and DAWG mechanisms for oversight and reporting, and all centers will be invited to participate. Within IDP, the HMS PCA will take primary responsibility for initial deployment of image informatics software. The DCC and HMS will jointly undertake software development and code hardening, and the DCC will take the lead in user assistance and software deployment, particularly in year two. Images of tumor specimens obtained from biopsy or surgery are one of the primary ways in which cancer is diagnosed and staged by pathologists, but such images have typically lacked molecular detail. The highly multiplexed tissue images being collected by HTAN will fundamentally change this, and it is therefore essential that the data be efficiently and widely distributed. The HTAN Image Data Project IDP will address an acute need for software for data dissemination and visualization.",Human Tumor Atlas Network: Data Coordinating Center Supplement,10206514,U24CA233243,"['Acute', 'Address', 'Atlases', 'Bioinformatics', 'Biopsy', 'Client', 'Code', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Databases', 'Development', 'Diagnosis', 'European', 'General Population', 'Generations', 'Goals', 'Human', 'Image', 'Imaging Device', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Malignant Neoplasms', 'Manuscripts', 'Methods', 'Modeling', 'Molecular', 'Operative Surgical Procedures', 'Output', 'Pathologist', 'Performance', 'Reporting', 'Side', 'Slide', 'Software Tools', 'Specimen', 'System', 'Technology', 'Testing', 'Tissue imaging', 'Tissues', 'Vertebral column', 'Visualization', 'base', 'cancer imaging', 'cellular imaging', 'cloud based', 'computing resources', 'data dissemination', 'data management', 'data resource', 'data visualization', 'imaging Segmentation', 'imaging informatics', 'improved', 'machine learning algorithm', 'multiplexed imaging', 'programs', 'relational database', 'single cell sequencing', 'software development', 'supervised learning', 'tumor']",NCI,DANA-FARBER CANCER INST,U24,2020,926364,-0.013109387623504257
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10115288,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'Visualization', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'machine learning method', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2020,99860,-0.02225070204084334
"Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. Annually, malaria affects more than 200 million people and claims the lives of over 440,000 people worldwide, mostly African children. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM and incorrect treatment. An accurate means to confirm the presence of CM or to investigate for a non-malarial illness is critically needed to improve outcomes. Since Malarial retinopathy (MR) is greater than 90% specific and sensitive to the presence of CM once clinically diagnosed, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. VisionQuest Biomedical and its collaborators have assembled a team of inter-disciplinary scientists with considerable experience in automated retinal image analysis, clinical ophthalmology with specialized research in malarial retinopathy (MR), and cerebral malaria diagnosis (CM). This team will develop and test ASPIRE, a system for detection of MR consisting of automated MR detection software integrated with a low-cost and portable retinal camera. Our proposed ASPIRE system will augment, not replace, the current CM diagnostic standard; increasing the accuracy of CM diagnoses, leading to a smaller number of false positive outcomes. In Phases I and II, the research team at VisionQuest Biomedical developed the automated MR detection software and interfaced it with a handheld retinal camera. The resulting clinical prototype of ASPIRE was tested onsite in a health-clinic in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In Phase II-B, the MR detection system will be refined, productized, and the resulting commercial prototype will be validated on prospective datasets. We will accomplish this through three specific aims. In the first aim, the software system for MR detection will be adapted and improved to work with low-cost and portable iNview camera. In the second aim, we will refine iNview’s driver-software and integrate the camera with MR detection software to produce the first commercial prototype. The third aim will focus on collecting the retinal image data for algorithm testing as well as for validating the commercial prototype in an observational clinical study to be conducted at nine clinical sites in Malawi, Uganda, and Zambia in Africa. Narrative Cerebral malaria is a life-threatening clinical syndrome associated with malarial infection, which affects about 200 million people annually and claims the lives of over 440,000 people worldwide, mostly African children. The presence of malarial retinopathy can provide additional insight and improve the diagnostic accuracy of CM. This project proposes the development of a fully-automated malaria retinopathy detection system consisting of a low-cost retinal camera and automatic malaria retinopathy detection software.",Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria,9839485,R44AI112164,"['5 year old', 'Address', 'Affect', 'Africa', 'African', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Cellular Phone', 'Cerebral Malaria', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Country', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Enrollment', 'Expert Systems', 'Foundations', 'Goals', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Image Analysis', 'Incidence', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Medicine', 'Ophthalmologist', 'Ophthalmology', 'Ophthalmoscopy', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Poison', 'Predictive Value', 'Price', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Safety', 'Scientist', 'Seasons', 'Series', 'Site', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Test Result', 'Testing', 'Uganda', 'Validation', 'Work', 'Zambia', 'base', 'clinical Diagnosis', 'clinical research site', 'cost', 'cost effectiveness', 'design', 'diagnostic accuracy', 'experience', 'imaging capabilities', 'improved', 'improved outcome', 'innovation', 'insight', 'malaria infection', 'mortality', 'performance site', 'portability', 'programs', 'prospective', 'prototype', 'research study', 'response', 'retinal imaging', 'screening', 'smartphone Application', 'software development', 'software systems', 'success', 'usability']",NIAID,VISIONQUEST BIOMEDICAL INC,R44,2020,1000000,-0.012128422093540652
"Organ Procurement and Information Process Optimization Project Summary: Organ Procurement and Information Process Optimization A recent White House initiative titled Advancing American Kidney Health outlines the current administration's plans to increase the supply of kidneys in the US, along with other measures that attempt to correct the imbalance between supply and demand for kidneys. In alignment with this White House initiative, the principal investigator (PI) of this project will develop algorithms to assist Organ Procurement Organizations (OPOs) make donor disposition decisions with the goal of increasing the supply of transplantable organs. The PI will harness the vast amount of data collected by OPOs, and customize as well as develop new Artiﬁcial Intelligence (AI) algorithms to identify good donors. These algorithms will reduce case coordinators workload and improve the accuracy of their decisions. The PI's objective is to quantity the impact of AI-assisted decision-making on increasing the supply of kidneys by ﬁnding missed opportunities on account of the current manual processes. Even a few more potential donors per OPO will help reduce the organ shortage problem when scaled to all 58 OPOs across the country.  This project will leverage unique data sets to generate and test hypotheses concerning which fac- tors aﬀect donor disposition decisions, and which information processing protocols produce greater referral-to-donor conversion rate. It will also customize classiﬁcation algorithms to assist case co- ordinators make donor disposition decisions. The focus will be on improving both the accuracy and speed of such decisions. As a follow up of this project, the PI will conduct a broader study involving at least ﬁve additional OPOs. The ﬁve OPOs will be selected to represent the diversity in size, population, and geography among the 58 OPOs across the country. Results of this and the follow-up study will be shared freely with all OPOs. The proposed research has the potential to increase the number of donors, free up staﬀ time, and lower OPO labor costs.  The potential impact of this project lies in the formulation and testing of hypotheses that can beneﬁt OPO decision-making and people on transplant wait list, customization of existing machine learning algorithms and computational techniques for sequential decision-making in a novel setting, and laying the groundwork for the development of new methods in the future.  The PI has the necessary disciplinary expertise, and management and leadership experience to succeed in the proposed eﬀorts. He has access to advanced computing resources and administrative help from the University of Texas. Finally, he has obtained the necessary IRB approval to proceed with this project. 1 Project Narrative: Organ Procurement and Information Process Optimization The widespread use of electronic medical record systems by hospitals, and electronic capture of referrals data by the organ procurement organizations (OPOs) makes it possible to harness large amounts of data to augment human decision-making and ask whether this can increase the supply of organs, speciﬁcally kidneys. The PI in this project will focus on improving the speed and accuracy of case coordinators' donor-disposition decisions by developing and testing customized machine learning and sequential decision-making algorithms using data from two OPOs. These eﬀorts will help quantify the potential beneﬁt of leveraging OPO data to increase kidney supply and pave the way for a larger study focusing on multiple OPOs.",Organ Procurement and Information Process Optimization,10042096,R03HS027671,[' '],AHRQ,"UNIVERSITY OF TEXAS, AUSTIN",R03,2020,41981,-0.013943706391009916
"Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes/eyelids and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to develop a more precise DR scoring scheme. This would help identify patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images,10082348,R44EY028081,"['Agreement', 'Algorithms', 'Applications Grants', 'Biological', 'Blindness', 'Cataract', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Ensure', 'Exposure to', 'Eye', 'Eye diseases', 'Eyelash', 'Eyelid structure', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Internet', 'Lasers', 'Lesion', 'Light', 'Localized Lesion', 'Manuals', 'Measures', 'Modality', 'Morphologic artifacts', 'Online Systems', 'Ophthalmoscopy', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scheme', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Validation', 'Vision', 'Work', 'automated analysis', 'base', 'cloud based', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability']",NEI,"EYENUK, INC.",R44,2020,1000000,-0.01054390390239888
"2020 OSA Optical Coherence Tomography Meeting NIBIB PROPOSAL – ABSTRACT 2020 OSA Optical Coherence Tomography Meeting  Biophotonics technologies have clear medical and clinical applications. However, the transformation and translation from the research lab to the clinic, and then to market is a complex process. The 2020 OSA Optical Coherence Tomography meeting will be held on 20-23 April 2020 in Fort Lauderdale, Florida, in parallel with other four topical meetings (Clinical and Translational Biophotonics, Optical Tomography and Spectroscopy, Microscopy, Histopathology and Analytics, Optics and the Brain) within the same congress, the 2020 OSA Biophotonics Congress: Biomedical Optics. The ultimate objective of this conference is to disseminate recent developments in the field of optical coherence tomography (OCT) and inspire new ideas through various forms of interactions within a broad audience that includes engineers, natural scientists (physicists, biologists, chemists, etc.), clinical researchers, industrial R&D and market experts. The meeting will report on the latest advances in this field and discuss how the OCT field can be advanced in the near future. In addition to addressing the use of adaptive optics to improve image quality, emphasis will be placed on advanced techniques to use OCT for functional imaging, real time volumetric imaging and rendering, and imaging for diagnostic and surgical guidance applications. New topics to be covered are the development and application of advanced image processing algorithms to interpret to imaging data.  A unique advantage of co-locating this meeting within a congress and presenting joint plenary sessions is the extended cross-fertilization between experts in in the distinct but synergic fields. Technical sessions that include innovative methods such as campfire, fishbowl sessions or unconference, and special programming will ensure the meetings' success as the leading forum for presenting the latest advances, while providing an ideal setting to learn. This meeting will provide an opportunities for students and early career professionals to present their work, participate in professional development activities, hear from and network with internationally-renowned speakers and participate in special programming. Ultimately, holding high-quality scientific and technical meeting, where best-in-class research is presented and discussed will advance knowledge in the field of biomedical optics and biophotonics and propel technological development forward, while augmenting standard academic training and presenting opportunities for career advancement, especially for students and early career professionals. NIBIB PROPOSAL – PROJECT NARRATIVE 2020 OSA Optical Coherence Tomography Meeting The 2020 OSA Optical Coherence Tomography Meetings will bring together many of the leaders in the OCT field, who will report on the latest advances in this field and discuss how the OCT field can be advanced in the near future, including developing and evaluating new imaging approaches to solve important clinical problems. In addition to addressing the use of adaptive optics to improve image quality, emphasis will be placed on advanced techniques to use OCT for functional imaging, real time volumetric imaging and rendering, and imaging for diagnostic and surgical guidance applications. These meeting will bring together researchers working in all aspects of this field and will serve as a forum for discussion of existing and emerging techniques as well as future directions.",2020 OSA Optical Coherence Tomography Meeting,9914797,R13EB029301,"['Academic Training', 'Address', 'Algorithms', 'Area', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophotonics', 'Brain', 'Career Mobility', 'Clinic', 'Clinical', 'Collaborations', 'Complex', 'Congresses', 'Data', 'Development', 'Diagnostic Imaging', 'Engineering', 'Ensure', 'Equilibrium', 'Event', 'Fertilization', 'Florida', 'Functional Imaging', 'Future', 'Goals', 'Hearing', 'Histopathology', 'Image', 'Industrialization', 'Industry', 'International', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Medical', 'Methods', 'Microscopy', 'National Institute of Biomedical Imaging and Bioengineering', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optical Tomography', 'Optics', 'Paper', 'Participant', 'Peer Review', 'Performance', 'Physicians', 'Process', 'Published Comment', 'Reporting', 'Research', 'Research Personnel', 'Scientist', 'Services', 'Special Event', 'Spectrum Analysis', 'Students', 'Techniques', 'Technology', 'Time', 'Translating', 'Translational Research', 'Translations', 'Work', 'academic standard', 'adaptive optics', 'bioimaging', 'career', 'clinical application', 'design', 'graduate student', 'image processing', 'imaging approach', 'improved', 'innovation', 'lectures', 'meetings', 'novel', 'posters', 'programs', 'research and development', 'success', 'symposium', 'tool']",NIBIB,OPTICAL SOCIETY OF AMERICA,R13,2020,10000,-0.025495181984293253
"Eliminating the human factor from stereotaxic surgeries Project Summary: The main goal of this research project is to develop a new line of new stereotaxic devices for small animal research that outperforms existing devices in terms of accuracy, reproducibility, and ease of use. Advancing a tool such as an electrode, injection pipette or optical fiber through a small hole in the cranium, sometimes over long distances, and placing it precisely in a particular brain area, often much less than one millimeter in diameter, is a significant experimental challenge. Any time an investigator misses the target brain area and the experiment fails as a result, a significant amount of work is lost, additional animals get sacrificed, materials are wasted, and the pace of scientific discovery has been slowed. Even in cases when experiments succeed, they can be difficult to reproduce because many research groups rely on their most experienced lab members and their “special touch” to perform these procedures – thereby adding an element of non- quantitativeness to the procedures, effectively making the experiment less reproducible. We propose to develop a novel stereotaxic apparatus which will overcome many of these shortcomings. Our device features a radically different mechanical design which is natively compatible with both traditional and novel in-vivo techniques. We propose to combine computer 3D vision and robotics for automatic and software guided adjustments of the animal's skull. Landmarks are measured with 3D vision, based on structured illumination at a level of accuracy that has not been accomplished by any of the existing devices. This information will guide a robotic platform to position the animal for the experiment. Finally, we propose to develop an open software platform for neuronavigation that will allow investigators to use the platform with any small animal species they desire to use. Brain atlas systems for neuronavigation can either be downloaded from a cloud based site, or produced de-novo by the investigator by preparing a single set of MRI and CT scans from one sample animal. Our device will help make stereotaxic procedures more accurate and less dependent on human input and thereby increase the repeatability of experiments within a laboratory as well as the reproducibility of experiments across laboratories. Narrative: The main goal of this research project is to develop a new line of new stereotaxic devices for small animal research that outperforms existing devices in terms of accuracy, reproducibility, and ease of use. These devices will help make stereotaxic procedures less dependent on human input and thereby increase the repeatability of experiments within a laboratory as well as the reproducibility of experiments across laboratories. Most importantly, they will help reduce or eliminate failed experiments due to mistargeted interventions, thereby accelerating the pace of scientific discovery.",Eliminating the human factor from stereotaxic surgeries,10080673,R41NS119079,"['3-Dimensional', 'Animal Experimentation', 'Animal Experiments', 'Animals', 'Area', 'Atlases', 'Base of the Brain', 'Brain', 'Caliber', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Devices', 'Dorsal', 'Electrodes', 'Elements', 'Ensure', 'Frustration', 'Goals', 'Human', 'Image', 'Injections', 'Intervention', 'Laboratories', 'Lighting', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Mechanics', 'Monitor', 'Neuronavigation', 'Operative Surgical Procedures', 'Persons', 'Positioning Attribute', 'Procedures', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Robotics', 'Sampling', 'Savings', 'Scanning', 'Side', 'Site', 'Speed', 'Structure', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Time', 'Touch sensation', 'Translations', 'Vision', 'Work', 'X-Ray Computed Tomography', 'age group', 'base', 'bone', 'bone imaging', 'brain tissue', 'cloud based', 'cost effective', 'cranium', 'design', 'experimental study', 'genetic strain', 'hexapod', 'in vivo', 'laboratory experience', 'member', 'millimeter', 'novel', 'operation', 'optical fiber', 'programs', 'prototype', 'soft tissue', 'software development', 'tool', 'virtual', 'wasting']",NINDS,POPNEURON LTD.,R41,2020,251960,-0.008117727057520159
"Continuous Non-Invasive Blood Pressure Monitor for Neonates Summary/Abstract Each year, about 5-18% of babies are born preterm, accounting for over 0.5M births in the US and 15M globally. Many of these babies are admitted to Neonatal Intensive Care Units (NICUs) where the medical staff generally have the option of using either invasive arterial lines (IALs) or inflatable-cuff non-invasive blood pressure (NIBP) monitoring. The former introduces the risk of infection, tissue and nerve damage, and the latter is less accurate, especially for hypotensive infants, and may add the risk of ischemic and nerve damage upon repeated measurement. There is a clear need for a safer, continuous, and cost effective form of NIBP measurement to meet the challenge of managing unhealthy blood pressures for neonates. PyrAmes Inc. has developed a novel capacitive sensor technology that is paper thin and flexible and can accurately detect blood pressure (BP). This sensor technology is part of a unique continuous BP monitoring platform that provides accurate, lightweight and comfortable BP monitoring in a wireless, wrist-worn package that is easy to use. The system uses lightweight neural networks to analyze pulse waveform data to provide continuous determination of systolic, diastolic, and mean BP, heart rate, and their variabilities. The sensor is easy to apply non-invasively and records pulsatile data similar to an arterial line, while avoiding the difficulties of placing and maintaining an arterial line. This device can provide gold standard BP monitoring without perturbing the patients for more accurate and relevant measurements. The objective of this project is to extend the platform for use with term and pre-term neonates. This goal will be accomplished through redesign of the sensor hardware and optimization of the data analytics software. We will validate these modifications with clinical data from the NICU at Stanford University Medical Center. In Phase I, we will miniaturize the electronics and modify the sensor array of a wrist-worn pulse wave monitor to be sized more appropriately for neonates. We will validate the new device design by collecting NICU clinical data from patients who have IALs in place in an IRB-approved study. From IAL and sensor data taken simultaneously, we will determine ground truth values on a pulse-by-pulse basis and use these data in conjunction with additional IAL data from historical databases to improve our sensor quality and predictive BP models. Our success metric will be to equal or exceed the quality and accuracy of our data for adults. Phase II will be a follow-up IRB-approved pivotal study using the device from Phase 1 to position our device for FDA submission and clearance and scale up to pilot production of this device. Project Narrative The goal of this Phase 1 project is to confirm that machine learning can be used to extract blood pressure values for critically ill neonates from pulse waveform data collected with a wearable, non-invasive device that is comfortable, low-cost and easy to use. The proposed device will significantly reduce the need for frequent cuff-based measurements and/or invasive arterial lines, thereby decreasing morbidity, risk of complications, patient discomfort, and overall cost of care. This project is based on the pioneering efforts of Prof. Zhenan Bao’s lab at Stanford on thin film sensors for electronic skin and includes the design and use of a miniaturized device to collect clinical data from neonates that will be used to validate a model which derives blood pressure values from the pulse waveform without external calibration.",Continuous Non-Invasive Blood Pressure Monitor for Neonates,9910153,R43HD101175,"['Academic Medical Centers', 'Accounting', 'Adult', 'Antihypertensive Agents', 'Area', 'Arterial Lines', 'Birth', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood pressure determination', 'Bluetooth', 'Calibration', 'Cells', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Research', 'Coin', 'Computer Analysis', 'Computer software', 'Consumption', 'Critical Illness', 'Data', 'Data Analytics', 'Databases', 'Development', 'Device Designs', 'Devices', 'Disadvantaged', 'Electromagnetics', 'Electronics', 'Female', 'Film', 'Goals', 'Gold', 'Heart Rate', 'Hemorrhage', 'Infant', 'Institutional Review Boards', 'Lead', 'Limb structure', 'Machine Learning', 'Measurement', 'Measures', 'Medical Staff', 'Methods', 'Modeling', 'Modification', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Neonatal', 'Neonatal Intensive Care Units', 'Nerve', 'Neural Network Simulation', 'Noise', 'Pain', 'Paper', 'Patients', 'Phase', 'Photoplethysmography', 'Physiologic pulse', 'Polychlorinated Biphenyls', 'Positioning Attribute', 'Process', 'Production', 'Pulse Pressure', 'Reading', 'Records', 'Resolution', 'Risk', 'Signal Transduction', 'Skin', 'Surface', 'System', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Wireless Technology', 'Work', 'Wrist', 'artificial neural network', 'base', 'care costs', 'cost', 'cost effective', 'demographics', 'design', 'encryption', 'flexibility', 'follow-up', 'improved', 'infection risk', 'light weight', 'male', 'miniaturize', 'neonate', 'neural network', 'novel', 'pressure', 'preterm newborn', 'scale up', 'sensor', 'sensor technology', 'skills', 'success', 'tonometry']",NICHD,"PYRAMES, INC.",R43,2020,224556,-0.00872748231962926
"A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions Abstract. Melanoma is the third most common form of skin cancer with estimated 87,110 new cases diagnosed in the United States in the year 2017. Current routine diagnostic approaches utilize microscopic evaluation of thinly sectioned patient biopsies, but in certain cases diagnosis can be contentious even among experts. The overall goal of this multi-phase SBIR project is to develop, validate, and commercialize MelanoMap™, Frontier Diagnostics' patented assay for the diagnosis of melanoma using a matrix-assisted laser desorption/ionization imaging mass spectrometry (MALDI IMS) platform—and to have this assay available to pathologists in the U.S. as a laboratory developed test. MALDI IMS is a state-of-the-art technology that generates molecular images of tens to thousands of biomolecules from tissue sections in a single analysis. The assay uses formalin-fixed paraffin embedded (FFPE) biopsies used in routine histopathological diagnosis. The proposed assay has pathologists select regions of skin biopsies for analysis via a remote web interface. The acquired IMS data from those regions unambiguously identifies malignant melanoma or benign nevus.  Phase I of this proposal will demonstrate the feasibility of this technology platform to achieve cost-effective diagnosis of melanoma from patient skin biopsies at sample volumes acceptable for a clinical laboratory. Specific Aim 1 focuses on the development of a scalable and robust analytical protocol in both sample preparation and informatics to accurately diagnose melanoma with MALDI IMS. In specific aim 2, we will test the methodology developed in Specific Aim 1 on a cohort of melanocytic lesions with known clinical outcome and subsequently validate the classification accuracy of the proposed test  In Phase II, the protocols developed in Phase I will be integrated into a diagnostic service workflow. This phase will focus on quality control measures, client facing cloud software, clinical diagnostic reporting, and completing the analysis of a 500-patient sample set for final assay validation. Specific Aim 3 of this proposal (initial aim of Phase II) will establish and implement test tissues into standard workflows that will provide performance metrics for standard operation of a test meeting Clinical Laboratory Improvement Amendments (CLIA) standards. Protocols will be developed to monitor reagents, the reproducibility of sample preparation, and mass spectrometer performance on daily basis. Specific Aim 4 will expand software capabilities to include a secure web interface for clients ordering the test and the laboratory performing the test. The software will meet regulatory compliance, perform statistical analysis, and generate and communicate reports of the MALDI IMS analysis. Specific Aim 5 proposes to expand the sample set used in the initial assay from Specific Aim 2 to include a set of 300 patient samples from our clinical collaborators with 5 or more years follow-up data. The test will be independently validated by an additional 200 patient samples with definitive diagnoses. n/a",A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions,9926849,R44CA228897,"['Antigens', 'Area', 'Benign', 'Biological Assay', 'Biopsy', 'Caliber', 'Cells', 'Classification', 'Client', 'Clinical', 'Clinical Laboratory Improvement Amendments', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Services', 'Digestion', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Formalin', 'Goals', 'Gold', 'Image', 'Incentives', 'Informatics', 'Laboratories', 'Legal patent', 'Lesion', 'Mass Spectrum Analysis', 'Measures', 'Metadata', 'Methodology', 'Microscopic', 'Microtomy', 'Monitor', 'Nevus', 'Outcome', 'Paraffin Embedding', 'Pathologist', 'Pathology Report', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Physical shape', 'Physicians', 'Preparation', 'Procedures', 'Proteins', 'Protocols documentation', 'Quality Control', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Retrieval', 'Sampling', 'Secure', 'Security', 'Sensitivity and Specificity', 'Side', 'Skin', 'Skin Cancer', 'Small Business Innovation Research Grant', 'Software Tools', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Standardization', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Treatment Cost', 'United States', 'Validation', 'accurate diagnosis', 'analytical method', 'base', 'clinical diagnostics', 'cloud software', 'cohort', 'cost', 'cost effective', 'data acquisition', 'diagnosis standard', 'diagnostic assay', 'disease classification', 'follow-up', 'frontier', 'histopathological examination', 'instrumentation', 'interest', 'large datasets', 'machine learning algorithm', 'mass spectrometer', 'meetings', 'melanoma', 'molecular diagnostics', 'molecular imaging', 'mortality risk', 'operation', 'prototype', 'quality assurance', 'skin lesion', 'tissue preparation', 'web interface']",NCI,"FRONTIER DIAGNOSTICS, LLC",R44,2020,944492,0.0009811455245065245
"Development of a web-based platform implementing novel Predictor of Skin Sensitization for Medical Devices (PreSS/MD) PROJECT SUMMARY Medical devices have been documented to contain toxic chemicals that can leach and cause acute contact dermatitis (ACD) after repeated exposure or prolonged contact of the skin to these toxins. ACD is credited for 10-15% of all occupational illnesses and is also the second highest reported occupational hazard. Given its prevalence, ACD is also a great public health burden with combined yearly costs of up to $1 billion, which spans including medical costs, worker’s compensation and lost working time due to workplace absence. To this end, the U.S. Food and Drug Administration has mandated that all medical devices must be evaluated for possible skin sensitization using in vivo animal assays, which includes the Guinea pig maximization test (GPMT). Although GPMT tests provide valuable data on the skin sensitization effects of potential toxins, these assays are time-consuming and expensive. Moreover, the Interagency Coordinating Committee on the Validation of Alternative Methods (ICCVAM) recently published a Strategic Roadmap, calling for the development of alternative approaches to reduce animal testing of chemical and medical agents. Thus, there is a stated need to modernize safety evaluation of medical devices to reduce animal testing and shorten the regulatory review time, which would ultimately bring safer devices to the market faster. To address this unmet need, the key objectives of our FDA Phase I SBIR project are to (i) produce rigorously validated computational models for the GPMT assay integrating data obtained in human, mouse, and in vitro assays; and (ii) integrate these models into a software product termed PreSS/MD (Predictor of Skin Sensitization for Medical Devices). Our specific aims for this study include: 1) collecting, curating, and integrating the largest publicly available dataset for GMPT; 2) creating and validating novel computational models for GMPT data; 3) developing the PreSS/MD web server to allow users to make predictions of skin sensitization potential in medical devices. We will also develop a model for mixtures, including compounds tested jointly in different concentrations, using an approach that we developed previously. Finally, we will implement novel approaches to help users of our PreSS/MD platform interpret the developed models in terms of key chemical features responsible for skin sensitization. In addition, we will employ biomedical knowledge graphs to elucidate Adverse Outcome Pathways (AOPs) for skin sensitizers. Successful execution of this Phase I project will yield in the development of PreSS/MD as a centralized resource to evaluate the skin sensitization potential for medical devices. We expect this software-as-a-service web server platform will be of great value for companies and sponsors seeking regulatory approval of medical devices. PROJECT NARRATIVE Given that medical devices have been documented to contain toxic chemicals that may lead to allergic contact dermatitis, the US Food and Drug Administration requires that all devices be evaluated for possible skin sensitization effects using in vivo assays such as the Guinea pig maximization test. In the effort to modernize skin sensitization safety evaluation methods to reduce in vivo animal testing, herein we propose to develop a software product, PreSS/-MD (Predictor of Skin Sensitization caused by Medical Devices), as an innovative and unique in silico alternative with the potential to better predict human response compared to the existing approaches for skin sensitization assessment. Successful execution of the objectives described in this project will result in a centralized web server platform to evaluate the skin sensitization potential for medical devices, which will be of significant value for companies and sponsors seeking regulatory approval of medical devices.",Development of a web-based platform implementing novel Predictor of Skin Sensitization for Medical Devices (PreSS/MD),10079701,R43ES032371,"['Acute', 'Address', 'Advanced Development', 'Allergic Contact Dermatitis', 'Animal Testing', 'Animals', 'Bayesian Method', 'Bayesian Modeling', 'Biological Assay', 'Cavia', 'Chemical Structure', 'Chemicals', 'Computer Models', 'Computer software', 'Consumption', 'Contact Dermatitis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Economics', 'Evaluation', 'Feedback', 'Generations', 'Human', 'Immune response', 'Instruction', 'Interagency Coordinating Committee on the Validation of Alternative Methods', 'International', 'Knowledge', 'Lead', 'Medical', 'Medical Care Costs', 'Medical Device', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Occupational', 'Online Systems', 'Pathway interactions', 'Phase', 'Poison', 'Prevalence', 'Prostheses and Implants', 'Public Health', 'Publishing', 'Pythons', 'Quantitative Structure-Activity Relationship', 'Reaction', 'Reporting', 'Resources', 'Safety', 'Skin', 'Small Business Innovation Research Grant', 'Structure', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Toxin', 'United States Food and Drug Administration', 'Validation', 'Workers&apos', ' Compensation', 'Workplace', 'adverse outcome', 'chemical release', 'cost', 'experience', 'in silico', 'in vitro Assay', 'in vivo', 'innovation', 'knowledge graph', 'lymph nodes', 'machine learning algorithm', 'model development', 'novel', 'novel strategies', 'occupational hazard', 'operation', 'phase 1 study', 'response', 'skin patch', 'software as a service', 'success', 'systemic toxicity', 'tool', 'web portal', 'web server']",NIEHS,"PREDICTIVE, LLC",R43,2020,167910,-0.020937408281626234
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10082215,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2020,749858,-0.017215856477633015
"A portable photoacoustic imager for diagnosing vascular diseases Project Summary/Abstract Vascular diseases are the leading cause of death worldwide. Some common vascular diseases include: cardio vascular disease, stroke, and peripheral artery disease (PAD). Many of these vascular diseases need point-of- care (POC) diagnosis and monitoring using non-ionizing, non-invasive and cost-effective approaches. Although Doppler ultrasound meets all these requirements, it only maps blood flow, which is operator dependent and influenced by motion artifacts, resulting in limited sensitivity and specificity to detect the disease in its early stage. A POC technique that provides direct label-free molecular and functional information of vasculature is needed to reliably detect and monitor vascular diseases.  A mobile photoacoustic imager (mPAI) is proposed for diagnosing various vascular diseases in resource poor settings of the world. Leveraging on strong multispectral optical absorption of oxy- and de-oxy hemoglobins, the mPAI is capable of providing multi-parametric information of deep vasculature, such as blood oxygen saturation, plaque lipids, blood flow and blood clot. The mPAI is non-invasive, real time and uses non-ionizing optical and ultrasound radiation. This will be the first and perhaps the only portable technology capable of deriving such multiparametric functional information of deep vasculature without the use of contrast agents. Competing technologies cannot provide such a direct information of vascular health, and certainly not in a compact portable device form. Health care providers can use the mPAI to instantly diagnose several vascular diseases affecting humans of all ages, including infants.  In the R21 phase, Aim1 will design and develop the mPAI, integrating the low-cost optical illumination and piezoelectric micromachined ultrasound transducer (PMUT) arrays. Dr. Rundra Pratap team from the Indian Institute of Science (IISc), Bangalore, will design and fabricate the PMUT arrays. Dr. Kothapalli team will develop the mPAI and validate its performance on tissue mimicking vascular phantoms in Aim 1, and rat models of PAD in Aim 2. The ultimate goal of the two-year R21 phase is to achieve a clinical grade mPAI device with reliable vascular imaging metrics.  In the R33 phase, to test the clinical performance of the mPAI, the following multicenter pilot clinical studies on PAD patients will be conducted in 1) Penn State Hershey medical center, 2) Vikram Hospital in India through collaborations with the IISc team, and 3) in Ghana in Year 5 with the help of Dr. Colette Pameijer of Penn State who conducts medical camps in Ghana every year through Penn State Global Health Program. Clinical studies in R33 phase will be undertaken only if well-defined milestones are achieved in the R21 phase.  The overall goal of these studies is to carefully validate the clinical potential of emerging label-free photoacoustic imaging technology to screen for vascular diseases, in a portable form, in resource poor settings of the world. Project Narrative Vascular diseases are becoming epidemic with increase in aging population, obesity and type II diabetes. They affect humans of all age groups, including neonates. This proposal aims to develop and validate the first ever portable photoacoustic imager for diagnosing and monitoring vascular diseases in resource poor settings.",A portable photoacoustic imager for diagnosing vascular diseases,10058614,R21EB030370,"['3-Dimensional', 'Adipose tissue', 'Affect', 'Age', 'Animals', 'Anticoagulants', 'Arteriovenous malformation', 'Award', 'Blood', 'Blood Vessels', 'Blood Volume', 'Blood coagulation', 'Blood flow', 'Brown Fat', 'Care Technology Points', 'Cause of Death', 'Chronic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computer software', 'Computers', 'Contrast Media', 'Coupled', 'Data', 'Deep Vein Thrombosis', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Doppler Ultrasound', 'Electronics', 'Engineering', 'Epidemic', 'Fiber Optics', 'Functional Imaging', 'Ghana', 'Goals', 'Health', 'Health Personnel', 'Hemangioma', 'Hematoma', 'Hemoglobin', 'Hospitals', 'Human', 'Human Resources', 'Image', 'Imaging Device', 'Imaging technology', 'India', 'Infant', 'Institutes', 'Label', 'Lasers', 'Light', 'Lighting', 'Lipids', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Medical', 'Medical center', 'Modeling', 'Molecular', 'Monitor', 'Morphologic artifacts', 'Motion', 'Multi-site clinical study', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Optics', 'Oxygen', 'Patients', 'Performance', 'Peripheral arterial disease', 'Phase', 'Physicians', 'Population Heterogeneity', 'Radiation', 'Rattus', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Science', 'Screening procedure', 'Sensitivity and Specificity', 'Signal Transduction', 'Source', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Ultrasonic Transducer', 'Ultrasonography', 'Vascular Diseases', 'Venous Insufficiency', 'absorption', 'age group', 'aging population', 'cost', 'cost effective', 'data acquisition', 'deep learning algorithm', 'design', 'falls', 'global health', 'imager', 'imaging capabilities', 'imaging platform', 'imaging system', 'in vivo', 'light scattering', 'miniaturize', 'neonate', 'next generation', 'older patient', 'phantom model', 'photoacoustic imaging', 'point of care', 'portability', 'preclinical study', 'prognostic', 'programs', 'research clinical testing', 'screening', 'time use', 'tissue phantom', 'transmission process']",NIBIB,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R21,2020,1000,-0.01516476895749793
