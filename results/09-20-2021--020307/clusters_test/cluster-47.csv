text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease. ABSTRACT More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease (LD). While the CDC conventional standard two-tier (CSTT) approach for serodiagnosis of LD has worked relatively well when used as recommended, there is plenty of room for improvement. Of a number of weaknesses associated with the supplemental immunoblot of the CSTT the most significant is low reproducibility due to the subjective visual interpretation of results. To overcome these weaknesses the CDC recently updated its recommendations based on a modified STT (MSTT) in that a second EIA can replace the immunoblot. The major goal of this project is to develop an objective, quantitative, multiplex EIA that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens to build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity. The novelty of this study relies on: 1) evaluation of B. burgdorferi antigen-specific antibody isotypes and IgG subclasses that can be correlated with Lyme disease stage; and 2) development of new diagnostic tools using machine learning techniques to train and integrate all data and produce an objective result to discriminate early Lyme from early disseminated/late Lyme disease. We expect this Phase I SBIR to allow us to develop a new EIA for serodiagnosis of Lyme disease (isoEIAplex-Ld) and to further an ongoing collaboration with DCN diagnostics for the adaptation of our biomarkers to a new rapid Lateral Flow Assay (see Letter of Support) for a follow up Phase II SBIR . NARRATIVE More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease. While the CDC conventional standard two-tier approach for serodiagnosis of Lyme disease has worked relatively well when used as recommended, there is plenty of room for improvement. We propose to develop an objective multiplex enzyme immunoassay that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens and build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity.",Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease.,10204992,R43AI155211,"['Acute', 'Acute Disease', 'Affinity', 'Antibodies', 'Antibody Response', 'Antigens', 'Arthritis', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Borrelia burgdorferi', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Collaborations', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Specificity', 'Discrimination', 'Disease', 'Early Diagnosis', 'Enzyme Immunoassay', 'Evaluation', 'GTP-Binding Protein alpha Subunits, Gs', 'Genetic Recombination', 'Goals', 'Grant', 'High Prevalence', 'Human', 'IgA1', 'IgA2', 'IgE', 'IgG1', 'IgG2', 'IgG3', 'IgG4', 'Immune response', 'Immunodominant Antigens', 'Immunoglobulin A', 'Immunoglobulin D', 'Immunoglobulin G', 'Immunoglobulin Isotypes', 'Immunoglobulin M', 'Immunoglobulins', 'Infection', 'Iowa', 'Laboratories', 'Laboratory Diagnosis', 'Lesion', 'Letters', 'Licensing', 'Lyme Arthritis', 'Lyme Disease', 'Machine Learning', 'OspC protein', 'Patients', 'Peptidoglycan', 'Performance', 'Phase', 'Proteins', 'ROC Curve', 'Recommendation', 'Reproducibility', 'Research', 'Serum', 'Small Business Innovation Research Grant', 'Specificity', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'V(D)J Recombination', 'Visual', 'Work', 'antigen binding', 'base', 'commercialization', 'disease diagnosis', 'erythema migrans', 'follow-up', 'improved', 'lateral flow assay', 'novel diagnostics', 'pathogen', 'tool']",NIAID,"IMMUNO TECHNOLOGIES, INC.",R43,2021,295514
"Web-based Automated Imaging Differentiation of Parkinsonism SUMMARY Across the globe, there has been a considerable growth in the number of people diagnosed with Parkinsonism. Estimates indicate that from 1990 to 2015 the number of Parkinsonism diagnoses doubled, with more than 6 million people currently carrying the diagnosis, and by year 2040, 12 and 14.2 million people will be diagnosed with Parkinsonism. Parkinson’s disease (PD), multiple system atrophy Parkinsonian variant (MSAp), and progressive supranuclear palsy (PSP) are neurodegenerative forms of Parkinsonism, which can be difficult to diagnose as they share similar motor and non-motor features, and they each have an increased chance of developing dementia. In the first five years of a PD diagnosis, about 58% of PD are misdiagnosed, and of these misdiagnoses about half have either MSA or PSP. Since PD, MSAp, and PSP require unique treatment plans and different medications, and clinical trials testing new medications require the correct diagnosis, there is an urgent need for both clinic ready and clinical-trial ready markers for differential diagnosis of PD, MSAp, and PSP. Over the past decade, we have developed diffusion imaging as an innovative biomarker for differentiating PD, MSAp, and PSP. In this proposal, we will leverage our extensive experience to create a web-based software tool that can process diffusion imaging data from anywhere in the world. We will disseminate and test the tool in the largest prospective cohort of participants with Parkinsonism (PD, MSAp, PSP), working closely with the Parkinson Study Group. The reason to test this in the Parkinson Study Group network, is because they are the community that evaluates Phase II and Phase III clinical trials in Parkinsonism. This web-based software tool will be capable of reading raw diffusion imaging data, performing quality assurance procedures, analyzing the data using a validated pipeline, and providing imaging metrics and diagnostic probability. We will test the performance of the wAID-P by enrolling 315 total subjects (105 PD, 105 MSAp, 105 PSP) across 21 sites in the Parkinson Study Group. Each site will perform imaging, clinical scales, diagnosis, and will upload the data to the web-based software tool. The clinical diagnosis will be blinded to the diagnostic algorithm and the imaging diagnosis will be compared to the movement disorders trained neurologist diagnosis. We will also enroll a portion of the cohort into a brain bank to ascertain pathological confirmation and to test the algorithm against cases with post-mortem diagnoses. The final outcome will be to disseminate a validated diagnostic algorithm to the Parkinson neurological and radiological community and to make it available to all on a website. NARRATIVE In this proposal, we will be developing, disseminating, and evaluating a web-based software tool that can perform MRI analyses for the diagnostic accuracy of Parkinsonism. Our goal is to leverage our years of experience and algorithm development, to test a prospective cohort of Parkinson’s disease, Multiple System Atrophy, and Progressive Supranuclear Palsy. We expect that at the end of the project, we will have validated a web-based software tool that can use MRIs from different vendors to read, analyze, and predict the diagnosis of different forms of Parkinsonism.",Web-based Automated Imaging Differentiation of Parkinsonism,10106864,U01NS119562,"['Algorithms', 'American', 'Area Under Curve', 'Autopsy', 'Biological Markers', 'Blinded', 'Brain', 'Clinic', 'Clinical', 'Clinical Trials', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Dementia', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Enrollment', 'Goals', 'Growth', 'Health', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Modeling', 'Motor', 'Movement Disorders', 'Multiple System Atrophy', 'Nerve Degeneration', 'Neurologic', 'Neurologist', 'Online Systems', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Participant', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Probability', 'Procedures', 'Process', 'Progressive Supranuclear Palsy', 'Prospective cohort', 'Protocols documentation', 'Radiology Specialty', 'Reading', 'Research Personnel', 'Risk', 'Secure', 'Signal Transduction', 'Site', 'Software Tools', 'System', 'Techniques', 'Testing', 'TimeLine', 'Tissues', 'Training', 'Translating', 'Validation', 'Variant', 'Vendor', 'Water', 'accurate diagnosis', 'algorithm development', 'atypical parkinsonism', 'clinical Diagnosis', 'cohort', 'data exchange', 'diagnostic accuracy', 'diagnostic biomarker', 'disease diagnosis', 'dopamine transporter', 'experience', 'imaging biomarker', 'improved', 'indexing', 'individualized medicine', 'innovation', 'outcome forecast', 'performance tests', 'programs', 'quality assurance', 'support vector machine', 'tool', 'treatment planning', 'web site']",NINDS,UNIVERSITY OF FLORIDA,U01,2021,1553260
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,10061631,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2021,1261742
"Reading workstation for clinical contrast echocardiography Proposal Summary There is increasing appreciation of a syndrome in which patients female patients, present with chest pain due to myocardial ischemia and have a normal or near normal coronary angiogram. Termed coronary microvascular dysfunction (MVD) this disorder is not benign with cardiovascular event rates similar to those with established coronary artery disease. Clinical tools are therefore needed to both identify MVD patients and better understand the mechanisms causing myocardial ischemia. There is evidence that myocardial contrast echocardiography (MCE) provides incremental information in the evaluation of patients with coronary artery disease, myocardial viability, or diseases of the microvasculature. Despite data demonstrating the diagnostic and prognostic benefit of MCE in evaluating patients with MVD, its clinical use has been limited to only a handful of experts in the field, because there are currently no widely available clinical tools to support MCE quantitative analysis and interpretation. The overall aim of this Phase I proposal is to provide clinicians with a new tool to evaluate the myocardial flow-function relationship that is critical to identifying patients with MVD by using echocardiography. We will develop clinical software that can rapidly process MCE data into a standardized, quantitative and easy- to- interpret format. In Aim 1, the power of image averaging and computer aided assessment of radial wall thickening will be used to enhance the current standard of care which relies solely on readers' visual estimation of segmental function. An algorithm will be developed to rearrange the order of images so that images representing the same phase of the cardiac cycle are grouped together. Functional analysis will then be developed using computer-aided tracings of epicardial and endocardial borders. In Aim 2, a software module for quantitative analysis of real-time MCE perfusion will be developed that will incorporate statistical confidence, derived from the performance of image processing algorithms to inform the interpreter about the data strength. Machine learning will be utilized to train and deploy a neural network for the pixel-by-pixel assessment of myocardial perfusion. In Aim 3, we will combine myocardial perfusion and function modules into a novel, perfusion-function mode of imaging (PF-mode). This new mode will be applied to an archival sample of clinically diagnosed MVD cases to demonstrate the feasibility to detect abnormalities in the myocardial flow-function relationship. The composite PF-mode will include a cine-loop rendered for one cardiac cycle where parametric images (perfusion) are superimposed over averaged ultrasound images with an overlay of graphic representation of wall thickness (function). This novel mode of imaging provides the means to diagnose MVD in a single clinical study. Project Narrative Project Title: Reading workstation for clinical contrast echocardiography Despite a wealth of evidence that myocardial contrast echocardiography imaging of myocardial perfusion provides incremental information in the evaluation of patients with diseases of the myocardial microvasculature (MVD), its clinical use has been limited to only a handful of experts in the field. In this proposal, we have created a multidisciplinary partnership between physicians-scientists and engineers with the overall aim to address this clinical gap that exists between a proven echocardiographic technique and the technology necessary to enable widespread adoption of MCE clinically. We will develop a software program enabling a new method for evaluating the myocardial flow-function relationship using echocardiography that will enable the identification of MVD using MCE studies at the level of expert readers.",Reading workstation for clinical contrast echocardiography,10155647,R43HL152939,"['Address', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Angiography', 'Apical', 'Benign', 'Blood', 'Blood Flow Velocity', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular system', 'Chest Pain', 'Classification', 'Clinical', 'Clinical Research', 'Clip', 'Code', 'Color', 'Computer Assisted', 'Computer software', 'Computers', 'Contrast Echocardiography', 'Contrast Media', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Echocardiography', 'Engineering', 'Evaluation', 'Event', 'Eye', 'Female', 'Guidelines', 'Image', 'Imaging Techniques', 'Machine Learning', 'Mechanics', 'Medical', 'Methods', 'Microcirculation', 'Microvascular Dysfunction', 'Myocardial', 'Myocardial Ischemia', 'Myocardial perfusion', 'Names', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Physicians', 'Process', 'Radial', 'Reader', 'Reading', 'Recommendation', 'Rest', 'Scientist', 'Side', 'Societies', 'Software Engineering', 'Standardization', 'Stress', 'Syndrome', 'Techniques', 'Technology', 'Thick', 'Time', 'Training', 'Ultrasonography', 'Vendor', 'Visual', 'arteriole', 'base', 'clinical Diagnosis', 'endothelial dysfunction', 'image processing', 'imaging software', 'indexing', 'multidisciplinary', 'neural network', 'novel', 'parametric imaging', 'perfusion imaging', 'prognostic', 'programs', 'sample archive', 'single photon emission computed tomography', 'standard of care', 'tool', 'user-friendly']",NHLBI,"NARNAR, LLC",R43,2021,252399
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,10171859,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Models', 'Cornea', 'Corneal Diseases', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'detection sensitivity', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2021,381543
"Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance PROGRAM SUMMARY Radiological imaging is often the first step of the diagnostic pathway for many devastating diseases; thus, an erroneous assessment of “normal” can lead to death. Whereas a grayscale object in an image can be described by its first-order image statistics—such as contrast, spatial frequency, position, entropy, and orientation—none of these dimensions, by itself, indicates abnormal vs normal radiological findings. We are a highly diverse team proposing an empirical approach to determine the mixtures of the first-order statistics—the “visual textures”— that radiology experts explicitly and implicitly use to identify the locations of potential abnormalities in medical images. Our innovative approach does not rely on assumptions about which textures may or may not be im- portant to abnormality detection. Instead, we will track the oculomotor behavior of expert radiologists to deter- mine their conscious and unconscious targeting choices, and thus ascertain which textures are empirically in- formative. The ability of expert radiologists to rapidly find abnormalities suggests that they may be able to first identify them in their retinal periphery. Peripheral visual analysis skills are therefore potentially critical to radio- logic performance, despite being understudied. We will measure these skills and leverage the results to develop perceptual learning heuristics to improve peripheral abnormality texture detection. By comparing novices to ex- perts we will determine whether the first are inexpert due to a lack of sensitivity to diagnostically relevant textures (texture informativeness), or to a lack of knowledge about which textures are abnormal, or to a combined lack of both sensitivity and knowledge. Radiology also requires the acquisition of oculomotor skills through practice and optimization. Radiologic expertise thus changes the oculomotor system in predictable and detectable ways, in much the same way that an athlete’s body and brain change as a function of expertise acquisition in their sport. We will therefore analyze both the consistency between experts’ fixation choices in medical images, and the eye movement performance characteristics of experts vs novice radiologists, to create an objective oculomotor bi- omarker of radiological expertise. The differences between novices and experts will train a deep learning (DL) system, which will have human visual and oculomotor performance characteristics. Training the DL with the abnormalities identified by a panel of expert radiologists will allow it to pinpoint the possible solutions in the manner of a simulated human radiologist performing at peak accuracy, precision, and speed. The resulting rank- ordered list of possible optimal and suboptimal image-reading strategies will serve as a benchmarking tool to quantify the performance of actual clinicians and residents who read the same images, rested vs fatigued. Meas- uring the effects of both training and fatigue on radiology expertise will be a major interdisciplinary cross-cutting advance in performance assessment. Our proposal to quantify fatigue in terms of erosion of expertise represents a transformational advance towards objective fitness-for-duty and expertise measures in medicine and beyond. PROJECT NARRATIVE There are 25-32 million perceptual errors in radiological case studies worldwide each year, contributing to med- ical error, the third most common cause of death in the US. We seek to reduce detection errors in radiology with four innovations: (1) we will empirically and objectively determine the visual textures used by expert radiologists to identify abnormalities within medical images; (2) we will determine the ways in which expert radiologists use their eyes, and especially their peripheral vision, to scan images and target informative regions; (3) we will de- velop a perceptual learning paradigm to optimally train residents in both texture perception and oculomotor per- formance domains; and (4) we will construct a deep learning model bestowed with simulated human visual and oculomotor capabilities, to create a normative model of human radiological expertise. The combined results from these studies will quantify peak expert performance and be employed to track and enhance individual expertise acquisition during radiology training; thus, the proposed research will help reduce medical error and moreover provide objective fitness-for-duty measurement tools—based on quantified biomarkers—to evaluate and ame- liorate the effects of fatigue on radiologic performance.",Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance,10220201,R01CA258021,"['Assessment tool', 'Benchmarking', 'Biological Markers', 'Brain', 'COVID-19', 'Cancer Detection', 'Case Study', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical/Radiologic', 'Collection', 'Conscious', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Diagnostic', 'Dimensions', 'Disease', 'Elements', 'Ensure', 'Entropy', 'Exposure to', 'Eye', 'Eye Movements', 'Fatigue', 'Film', 'Foundations', 'Frequencies', 'Human', 'Image', 'Incentives', 'Individual', 'Instruction', 'Knowledge', 'Lead', 'Learning', 'Location', 'Measurement', 'Measures', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Modeling', 'Nature', 'North America', 'Outcome', 'Participant', 'Pathway interactions', 'Perception', 'Perceptual learning', 'Performance', 'Peripheral', 'Positioning Attribute', 'Radiologic Finding', 'Radiology Specialty', 'Reading', 'Research', 'Residencies', 'Resolution', 'Rest', 'Retina', 'Scanning', 'Societies', 'Speed', 'Sports', 'Stress', 'System', 'Testing', 'Texture', 'Thoracic Radiography', 'Time', 'Training', 'Unconscious State', 'Vision', 'Visual', 'Workload', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cancer imaging', 'cohort', 'deep learning', 'design', 'experience', 'fitness', 'heuristics', 'human error', 'human model', 'improved', 'innovation', 'learning network', 'lung imaging', 'meetings', 'novel', 'oculomotor', 'oculomotor behavior', 'pandemic disease', 'patient safety', 'programs', 'radiological imaging', 'radiologist', 'sample fixation', 'shift work', 'skills', 'statistics', 'tool', 'tool development']",NCI,SUNY DOWNSTATE MEDICAL CENTER,R01,2021,646124
"Flexible Piezoelectric Array for Cardiovascular MonitoringDuring Cardiac Arrest Project Summary In situations of out of hospital cardiac arrest, it is critical to quickly detect the performance of adequate cardiopulmonary resuscitation (CPR) through clinically acceptable pulse rate and blood pressure (BP). However, the detection of adequate CPR can be difficult for someone not trained in first aid. Currently the standard for measuring BP noninvasively is using cuff-based oscillometeric approaches. Attempts at developing these into wearable devices for automated and continuous measurements have proven difficult and so researchers have looked at other methods. However, these methods have not met the criteria for flexibility, accuracy, and low power consumption. This project aims to develop a flexible patch for accurate detection of pulse rate and blood pressure superficially through the radial, brachial, carotid, and/or femoral arteries. Piezoelectric polymers, are inherently flexible and have been used in many applications for pressure sensing, offering great potential for use as a patch-like sensor for monitoring of cardiovascular function. However, in the standard form, the material is not sensitive enough to accurately detect blood pressure. In our lab we have developed a core-shell nanofiber structure of conductive and piezoelectric nanofibers, respectively. The core-shell nanostructure shows a 4.5 times improvement in pressure sensitivity when compared to standard piezoelectric nanofibers and a nearly 40 times improvement when compared to piezoelectric polymer thin films. This improvement in pressure sensitivity should allow for a wearable device composed of these materials to exceed the necessary 35 dB signal to noise ratio required for the accurate detection of pulse wave velocity, a cardiovascular parameter used to determine blood pressure. Coupled with inkjet printing patterning techniques of conductive polymers developed in our lab, we propose to fabricate a novel core-shell nanofiber piezoelectric array in a wearable patch form for cardiovascular monitoring. In order to test this piezoelectric array and develop data-driven algorithms for the detection of blood pressure, testing will occur on a controllable simulated cardiovascular system capable of replicating a human’s diastolic and systolic blood pressures, pulse rates, and arterial mechanical properties. The blood pressure attainable by the simulated system falls within the AAMI standard benchmark for accuracy and precision for noninvasive blood pressure monitoring of 5 ± 8 mmHg. We will train various regression models using the data generated from this system to relate the detected pulse wave velocities to blood pressure and we will compare the outcomes to commonly used correlation equations. We propose that the fabrication methods we will develop, when coupled together with data-driven algorithms, will allow for the development of a low- power, flexible patch, capable of detecting pulse rate and blood pressure, giving feedback on the adequacy of CPR. Project Narrative This project plans to develop a patch-like sensor for detecting cardiovascular signals including pulse rate and blood pressure for situations of out of hospital cardiac arrest. The proposed research couples a novel core-shell piezoelectric nanostructure with an inkjet printing method for fabricating flexible arrays, to create a new class of wearable patch-like sensors for cardiovascular monitoring. Testing these sensors on a controllable simulated cardiovascular system, will allow for the development of data-driven algorithms to improve the accuracy of these devices, leading to highly accurate, patch-like cardiovascular sensing.",Flexible Piezoelectric Array for Cardiovascular MonitoringDuring Cardiac Arrest,10288237,R21EB032056,"['Algorithms', 'Arteries', 'Benchmarking', 'Biosensing Techniques', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood flow', 'Cardiopulmonary Resuscitation', 'Cardiovascular Physiology', 'Cardiovascular system', 'Caring', 'Carotid Arteries', 'Clinical', 'Complex', 'Consumption', 'Coupled', 'Couples', 'Data', 'Deposition', 'Detection', 'Development', 'Device Designs', 'Devices', 'Electrocardiogram', 'Electrodes', 'Equation', 'Feedback', 'Film', 'First Aid', 'Goals', 'Harvest', 'Heart Arrest', 'Human', 'Individual', 'Ink', 'Liquid substance', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Nanostructures', 'Noise', 'Outcome', 'Output', 'Pattern', 'Performance', 'Photoplethysmography', 'Physiologic pulse', 'Polymers', 'Printing', 'Property', 'Protocols documentation', 'Pulse Pressure', 'Pulse Rates', 'Research', 'Research Personnel', 'Signal Transduction', 'Skin', 'Sphygmomanometers', 'Structure', 'Sulfur', 'System', 'Techniques', 'Technology', 'Testing', 'Thinness', 'Time', 'Training', 'Work', 'base', 'brachial artery', 'detection method', 'falls', 'femoral artery', 'first responder', 'flexibility', 'human subject', 'improved', 'mechanical properties', 'nanofiber', 'novel', 'out-of-hospital cardiac arrest', 'polyvinylidene fluoride', 'pressure', 'pressure sensor', 'pulse pressure wave', 'radial artery', 'random forest', 'sensor', 'spatiotemporal', 'standard measure', 'wearable device']",NIBIB,DARTMOUTH COLLEGE,R21,2021,232061
"COVID-19 detection through scent analysis with a compact GC device Recent studies, including ours, have suggested that breath may allow us to diagnose COVID-19 infection and even monitor its progress. As compared to immunological and genetic based methods using sample media like blood, nasopharyngeal swab, and saliva, breath analysis is non-invasive, simple, safe, and inexpensive; it allows a nearly infinite amount of sample volume and can be used at the point-of-care for rapid detection. Fundamentally, breath also provides critical metabolomics information regarding how human body responds to virus infection and medical intervention (such as drug treatment and mechanical ventilation). The objectives of the proposed SCENT project are: (1) to refine automated, portable, high-performance micro-gas chromatography (GC) device and related data analysis / biomarker identification algorithms for rapid (5-6 minutes), in-situ, and sensitive (down to ppt) breath analysis and (2) to conduct breath analysis on up to 760 patients, and identify and validate the COVID-19 biomarkers in breath. Thus, in coordination with the RADx-rad Data Coordination Center (DCC), we will complete the following specific aims. (1) Refine 5 automated micro-GC devices to achieve higher speed and better separation capability. We will construct 5 new automated and portable one-dimensional micro-GC devices that require only ~6 minutes of assay time (improved from current 20 minutes) at the ppt level sensitivity (Sub-Aim 1a). Then the devices will be upgraded to 2-dimensional micro-GC to significantly increase the separation capability (Sub-Aim 1b). In the meantime, we will optimize and automate our existing data processing and biomarker identification algorithms and codes to streamline the workflow so that the GC device can automatically process and analyze the data without human intervention (Sub-Aim 1c). (2) Identify breath biomarkers that distinguish COVID-19 positive (symptomatic and asymptomatic) and negative patients. We will recruit a training cohort of 380 participants, including 190 COVID-19 positive patients (95 symptomatic and 95 asymptomatic) and 190 COVID-19 negative patients from two hospitals (Michigan Medicine – Ann Arbor and the Henry Ford Hospital – Detroit). We will conduct breath analysis using machine learning to identify VOC patterns that match each COVID-19 diagnostic status. (3) Validate the COVID-19 biomarkers using our refined micro-GC devices. Using the refined 2-D micro-GC devices from Sub-Aim 1b, we will recruit a new validation cohort of 380 participants (190 COVID-19 positive patients and 190 COVID-19 negative patients) to validate the biomarkers identified in Aim 2.  We will leverage existing engineering, data science, clinical, regulatory, and commercialization resources throughout the project to hit our milestones, ensuring a high likelihood of rapid patient impact. Upon completion of this work, we will have a portable micro-GC device and accompanying automated algorithms that can detect and monitor COVID-19 status for people in a variety of clinical and community settings. Narrative  Our team of engineers, clinicians, and data scientists has developed a portable, high performance breath analyzer that can be used to detect certain diseases. In this project, we will adapt and refine our existing device and algorithms so they can be used for rapid, safe, and non- invasive COVID-19 detection. People will simply breath into the device and it will quickly provide results, meaning that it can be used in a variety of everyday settings to help fight against the COVID-19 pandemic.",COVID-19 detection through scent analysis with a compact GC device,10266206,U18TR003812,"['Acute', 'Agreement', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Biotechnology', 'Blood', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 monitoring', 'COVID-19 pandemic', 'COVID-19 patient', 'Cessation of life', 'Clinical', 'Code', 'Critical Care', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Science', 'Data Scientist', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Ensure', 'Gas Chromatography', 'Genetic', 'Health', 'Hospitals', 'Human', 'Human body', 'Immunologics', 'In Situ', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Licensing', 'Machine Learning', 'Mechanical ventilation', 'Medical', 'Medicine', 'Methods', 'Michigan', 'Monitor', 'Participant', 'Patients', 'Pattern', 'Performance', 'Pharmacotherapy', 'Process', 'Production', 'RADx Radical', 'Research', 'Resources', 'Respiratory Failure', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Saliva', 'Sampling', 'Savings', 'Services', 'Severities', 'Speed', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Virus Diseases', 'Work', 'automated algorithm', 'base', 'biomarker identification', 'cohort', 'commercialization', 'community setting', 'computerized data processing', 'cost', 'design', 'fight against', 'fighting', 'global health', 'improved', 'metabolomics', 'multidisciplinary', 'nasopharyngeal swab', 'outcome forecast', 'pandemic disease', 'point of care', 'portability', 'rapid detection', 'recruit', 'respiratory hypoxia', 'screening', 'severe COVID-19', 'two-dimensional']",NCATS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,U18,2021,999775
"An Unobtrusive Continuous Cuff-less Blood Pressure Monitor for Nocturnal Hypertension PROJECT SUMMARY/ABSTRACT The objective of this project is to create an unobtrusive, wrist-worn, cuff-less blood pressure monitor for measurement and identification of nocturnal nondipping hypertension. The investigation includes extensive validation with state-of-the-art ambulatory blood pressure monitors at nighttime in presence of heterogeneous treatment paradigms. Cardiovascular disease (CVD) is one of the major causes of ailments worldwide. Hypertension alone affects one in three adults according to the World Health Organization. Therefore, monitoring blood pressure has become a critical part of healthcare as it is known to be linked to many CVDs. Traditionally, clinical practitioners have relied on the mercury-based (or digital equivalent) inflatable cuff-based sphygmomanometer. However, the nature of the device allows for only infrequent measurements and its somewhat invasive nature and associated discomfort prohibits additional nocturnal measurements. There is certainly a value to measuring blood pressure continuously in the natural context of the user’s environment, in particular during sleep, without being disturbed by the instrument. Our proposed technology can provide a wealth of information to physicians, help identify certain short-term dynamics/variations of blood pressure, and allow effective monitoring of response to medication, among other things. Nocturnal measurements provide additional prognostic value in identifying risk. Despite these benefits, no wearable, non-invasive device for continuous blood pressure monitoring exists on the market simply because none have been reliable enough to be considered clinical grade. This project aims to develop a robust and reliable blood pressure monitor in the form of a wrist-worn device that uses bio-impedance sensors, and for the first time, demonstrate clinical grade reliability. These sensors measure pulse wave velocity (PWV) along with several other derivatives for cardiovascular parameters including heart rate and blood volume changes in arteries, which correlate with the blood pressure. The system will incorporate clever hardware design to localize underlying vasculature and focus on arterial sites for enhanced accuracy. The device will include a motion sensor to take into account the user’s movements and motion artifacts, the contact quality, and reliability of the measurements. Advanced machine learning techniques, leveraging both general and personalized models, will be developed to convert bio-impedance measurements to blood pressure. This project aims to then validate the system and analytics in both a healthy patient cohort and a hypertensive cohort, learning the impact that nocturnal ‘nondipping’ hypertension and anti-hypertensive treatments have on PWV/other cardiovascular correlates and blood pressure estimates. After decades of relying on the inflatable cuff- based technique, this system could represent a significant change in how we measure blood pressure. PROJECT NARRATIVE Continuous monitoring of nocturnal blood pressure can help early diagnosis of developing cardiac conditions, reveal short term blood pressure variations, and also help the physician monitor differences in variations in response to medication for hypertensive patients. Moreover, the comfort and convenience of a wearable monitor would allow measurement in the natural context of daily life, including important nocturnal measurements, and reduce the burden of adherence on the user. The system will also provide feedback on quality of measurements to allow the users or care-givers to gauge reliability.",An Unobtrusive Continuous Cuff-less Blood Pressure Monitor for Nocturnal Hypertension,10166912,R01HL151240,"['Adherence', 'Adult', 'Affect', 'Age', 'Ambulatory Blood Pressure Monitoring', 'Antihypertensive Agents', 'Arteries', 'Awareness', 'Biometry', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood Volume', 'Blood flow', 'Calibration', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Characteristics', 'Clinical', 'Data', 'Data Collection', 'Development', 'Devices', 'Early Diagnosis', 'Environment', 'FDA approved', 'Feedback', 'Future', 'Gold', 'Healthcare', 'Heart Rate', 'Home environment', 'Hour', 'Human', 'Hypertension', 'Investigation', 'Learning', 'Legal patent', 'Life', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mercury', 'Methods', 'Microfabrication', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Movement', 'Nature', 'Organ', 'Outcome', 'Outcomes Research', 'Participant', 'Patient Monitoring', 'Patient risk', 'Patients', 'Pattern', 'Penetration', 'Pharmaceutical Preparations', 'Physicians', 'Physiologic pulse', 'Physiology', 'Positioning Attribute', 'Proxy', 'Reading', 'Recording of previous events', 'Regimen', 'Research', 'Risk', 'Risk Factors', 'Science', 'Signal Transduction', 'Site', 'Skin', 'Sleep', 'Sleep Deprivation', 'Sphygmomanometers', 'Structural Models', 'Supine Position', 'System', 'Techniques', 'Technology', 'Time', 'Uncertainty', 'Validation', 'Variant', 'Work', 'World Health Organization', 'Wrist', 'advanced analytics', 'analytical method', 'arterial stiffness', 'base', 'cohort', 'comorbidity', 'design', 'digital', 'effectiveness validation', 'electric impedance', 'insight', 'instrument', 'model development', 'monitoring device', 'motion sensor', 'multidisciplinary', 'novel', 'novel strategies', 'patient stratification', 'patient subsets', 'performance tests', 'prognostic value', 'response', 'sensor', 'sex', 'sleep position', 'supine sleep', 'wearable device', 'wearable sensor technology', 'willingness']",NHLBI,TEXAS ENGINEERING EXPERIMENT STATION,R01,2021,678001
"Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients Esophageal adenocarcinoma (EAC) is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. Barrett’s esophagus (BE) confers elevated risk for progression to EAC. Patients diagnosed with BE undergo periodic surveillance endoscopy with biopsies to detect dysplasia which can be treated by endoscopic eradication with radiofrequency ablation before it progresses to EAC. However, the majority of diagnosed EAC patients have not had prior screening endoscopy and present with advanced lesions that limit treatment options and result in poorer survival. The development of a rapid, low cost, well tolerated, non-endoscopic BE screening technique that can be performed in unsedated patients at points of care outside the endoscopy suite would improve BE detection and reduce EAC morbidity and mortality. Our program is a multidisciplinary collaboration among investigators at the Massachusetts Institute Technology and Veteran Affairs Boston Healthcare System / Harvard Medical School that integrates novel optical imaging and software design, preclinical studies in swine, clinical studies in patients, and advanced image processing / machine learning. Aim 1 will develop an omniview tethered capsule technology that generates a map of the esophageal mucosa over a multi-centimeter length of esophagus and a series of wide angle forward views to aid navigation as the capsule is swallowed or retracted. The images will resemble endoscopic white light or narrow band imaging, but will not suffer from perspective distortion present in standard endoscopic or video capsule images. This will facilitate development of automated BE detection algorithms as well as enhance their sensitivity and specificity. This aim will also perform imaging studies in swine as a translational step toward clinical studies. Aim 2 will determine reader sensitivity and specificity for BE detection versus standard endoscopy / biopsy and prepare data for developing automated BE detection. Patients undergoing screening as well as with history of BE undergoing surveillance will be recruited and unsedated capsule imaging will be performed on the same day prior to their endoscopy. Sensitivity and specificity for detecting BE will be assessed using multiple blinded readers and data sets suitable for developing automated BE detection algorithms will be developed. Aim 3 will develop image analysis methods for automated BE detection by investigating classifiers that operate on handcrafted features (colors and textures) and modern deep convolutional neural network methods for direct classification. If successful, this program will develop a rapid, low cost and scalable method for BE screening that would not require patient sedation, endoscopy, or tissue acquisition, and which could be performed in community primary care clinics. The procedure would be much faster and many times lower cost than endoscopy. Automated BE detection would enable immediate results for patient consultation and referral to gastroenterology if indicated. Larger patient populations with expanded risk criteria could be cost effectively screened and access to screening dramatically improved, reducing EAC mortality. Esophageal adenocarcinoma is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. The program proposes to develop an omniview tethered capsule technology, examination protocol, and automated analysis methods for low cost, rapid, well tolerated, and scalable screening in order to facilitate monitoring and timely treatment. Larger patient populations could be cost effectively screened and access to screening dramatically improved, reducing mortality.","Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients",10210371,R01CA252216,"['Algorithmic Software', 'Algorithms', 'Back', 'Barrett Esophagus', 'Biopsy', 'Blinded', 'Blood Vessels', 'Boston', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Color', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Set', 'Deglutition', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dysplasia', 'Endoscopic Biopsy', 'Endoscopy', 'Esophageal Adenocarcinoma', 'Esophageal mucous membrane', 'Esophagus', 'Family suidae', 'Gastroenterologist', 'Gastroenterology', 'Gastroesophageal reflux disease', 'Healthcare Systems', 'Histology', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Institutes', 'Interdisciplinary Study', 'Label', 'Length', 'Lesion', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Massachusetts', 'Measures', 'Methods', 'Modernization', 'Monitor', 'Morbidity - disease rate', 'Mucous Membrane', 'Nurse Practitioners', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Population', 'Primary Care Physician', 'Primary Health Care', 'Procedures', 'Protocols documentation', 'Radiofrequency Interstitial Ablation', 'Reader', 'Reading', 'Recording of previous events', 'Referral and Consultation', 'Research Personnel', 'Resolution', 'Risk', 'Screening Result', 'Sedation procedure', 'Sensitivity and Specificity', 'Series', 'Side', 'Software Design', 'Stomach', 'Surface', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'United States Department of Veterans Affairs', 'Validation', 'advanced disease', 'automated analysis', 'automated image analysis', 'base', 'capsule', 'clinical imaging', 'convolutional neural network', 'cost', 'design', 'graphical user interface', 'image processing', 'imaging software', 'imaging study', 'improved', 'medical schools', 'mortality', 'navigation aid', 'novel', 'optical imaging', 'patient population', 'point of care', 'preclinical study', 'programs', 'recruit', 'screening']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,345509
"Augmented Reality Platform for Telehealth Rehabilitiation Efforts to keep the most vulnerable individuals with chronic medical conditions from being exposed to COVID- 19 have triggered an unprecedented decline in the number of visits to ambulatory practices. The repercussions have impacted not only those with the disease, but the many millions of older persons in need of healthcare who forego in-person visits in fear of infection or for socioeconomic reasons. While the precipitating need for alternative healthcare delivery methods has hastened the adoption of software solutions, such as Zoom, traditional videoconferencing services fail to compensate for the lack of direct physical evaluations with a patient that is needed for evaluating musculoskeletal (MSK) deficits, planning therapeutic interventions, and guiding exercise compliance—essential components of evidence-based practice among rehabilitation practitioners. To overcome these shortcomings, our team of computer vision and human movement engineers is partnering with orthopedic rehabilitation specialists at Massachusetts General Hospital (MGH) to develop a telehealth platform that fuses high resolution RGB and Depth (RGD-D) video data readily obtainable from a modern smartphone to facilitate quantitative, MSK assessment. The innovation builds upon our work in computing movement outcome measures from vision-based body tracking algorithms, and our skills in augmented reality (AR) software development to enhance a clinician’s assessment and exercise instruction capabilities. Our pilot data demonstrate that accurate quantitative rehabilitation outcomes are obtainable using RGB-D body tracking algorithms during a sub-set of knee activities. Phase I will advance these capabilities by deriving and validating the accuracy of 3D body tracking and rehabilitation outcome measures during a wider set of activities used clinically for assessing knee mobility, alignment, posture, balance, strength, and function from depth enabled smartphone video recordings in control subjects (Aim 1). Aim 2 will develop a proof-of-concept AR telehealth platform with the help of the MGH team that delivers an enhanced telehealth experience through real-time synchronized audio-visual processing, real-time display of quantitative rehabilitation outcomes for the therapist to assess deficits or guide exercise compliance, and instructional animations for the patient to safely carry out the rehabilitation activities. The proof-of-concept prototype will undergo feasibility testing in Aim 3 among n=5 physical therapists and n=10 patients with knee OA during a simulated telehealth session to achieve high ratings for usability, accessibility, and effectiveness. The results will inform the user-requirements of a more complete Phase II telehealth platform designed in close collaboration with industry partners to provide secure cloud based communication for seamless interoperability between devices; additional examination tools (e.g. gait analysis); a broader range of baseline assessment and therapeutic exercise protocols for additional MSK conditions; and HIPAA-compliant deployment and electronic documentation management. The final prototype system will be evaluated during actual telehealth visits at multiple clinical sites to promote safe and effective clinical care. PROJECT NARRATIVE With the onset of the COVID-19 pandemic, clinical care has by necessity shifted towards telehealth delivery for people at risk due to age, who live in underserved communities or avoid in-person visits out of fear of viral transmission. Existing telehealth software platforms are generally supportive of videoconferencing but have yet to provide rehabilitation professionals with quantitative outcomes typically obtained from direct physical evaluations with a patient. To overcome this shortcoming, we are developing an augmented reality platform that fuses RGB and depth imaging from a patient’s smartphone to deliver quantitative outcomes of knee joint mobility, alignment, posture, balance, strength and function during a telehealth visit to support the mandate for more effective remote delivery of evidence-based rehabilitation during the global pandemics and beyond.",Augmented Reality Platform for Telehealth Rehabilitiation,10256844,R43AG072991,"['3-Dimensional', 'Adoption', 'Age', 'Algorithms', 'Architecture', 'Augmented Reality', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Cellular Phone', 'Chronic', 'Clinical', 'Collaborations', 'Communication', 'Computer Vision Systems', 'Computer software', 'Data', 'Devices', 'Disease', 'Documentation', 'Effectiveness', 'Elderly', 'Engineering', 'Ensure', 'Evaluation', 'Evidence based practice', 'Exercise', 'Exposure to', 'Feasibility Studies', 'Feedback', 'Focus Groups', 'Fright', 'General Hospitals', 'Goals', 'Gold', 'Health', 'Health Care Visit', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Image', 'Individual', 'Infection', 'Instruction', 'Intuition', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modality', 'Modernization', 'Motion', 'Movement', 'Musculoskeletal', 'Musculoskeletal Diseases', 'Musculoskeletal Equilibrium', 'Orthopedics', 'Outcome', 'Outcome Measure', 'Patient Self-Report', 'Patients', 'Persons', 'Phase', 'Physical Rehabilitation', 'Physical therapy', 'Protocols documentation', 'Quarantine', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Resolution', 'Risk', 'Secure', 'Services', 'Specialist', 'Supervision', 'System', 'Tablets', 'Technology', 'Testing', 'Therapeutic Intervention', 'Therapeutic exercise', 'Time', 'Validation', 'Video Recording', 'Videoconferencing', 'Virtual Tool', 'Vision', 'Visit', 'Visualization', 'Work', 'animation', 'base', 'clinical care', 'clinical practice', 'clinical research site', 'cloud based', 'design', 'evidence base', 'experience', 'feasibility testing', 'gait examination', 'health care delivery', 'industry partner', 'innovation', 'interoperability', 'joint mobilization', 'new technology', 'outpatient programs', 'pandemic disease', 'partial recovery', 'patient safety', 'physical therapist', 'prototype', 'remote delivery', 'skills', 'socioeconomics', 'software development', 'telehealth', 'tool', 'underserved community', 'usability', 'viral transmission', 'visual processing']",NIA,"ALTEC, INC.",R43,2021,286972
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10421230,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,138041
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10372655,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,52000
"Functional and Structural Optical Coherence Tomography for Glaucoma PROJECT SUMMARY Glaucoma is a leading cause of blindness in the US. The management of glaucoma is based on early detection, followed by careful evaluation and monitoring to identify those with rapid disease progression and high risk for vision loss. This allows for the rational use of medical, laser, and surgical treatments. Current methods of assessing glaucoma have significant limitations. Visual field (VF) testing has a low sensitivity for detecting early disease, and its reproducibility worsens in advanced stages, reducing its reliability for monitoring disease progression. Optical coherence tomography (OCT) precisely measure the peripapillary nerve fiber layer (NFL) thickness and is the most commonly used technology for objective glaucoma evaluation. However, NFL thickness has limited sensitivity in detecting early glaucoma, and reaches a floor value in moderate glaucoma, which prevents it from tracking glaucoma progress into later stages. The goal of the proposed research is to develop advanced OCT technology that will enhance detection of early glaucoma, improve the sensitivity of detecting significant disease progression, and increase the accuracy of measuring progression speed. The Specific Aims are: 1. Develop a directional high-resolution OCT and OCT angiography prototype to improve imaging of  structure and perfusion. The prototype will have real-time control of beam direction to maintain  perpendicular incidence on the NFL for accurate reflectance analysis, which has shown promise for very  sensitive detection of early glaucoma. Sensorless adaptive-optics aberration correction will enable high  transverse resolution to enhance the detection of nerve fiber bundle and capillary defects. Ultrahigh axial  resolution will enable assessment of the pentalaminar structure of the inner plexiform layer. 2. Wide-field OCT and OCT angiography analyses and visual field simulation. Wide peripapillary and  macular scans, using a next-generation commercial spectral-domain OCT system, will allow visualization of  nerve fiber and perfusion defects from the disc margin to temporal raphe, thus improving early glaucoma  detection. VF simulation will be performed to convert OCTA perfusion measurement to a VF-equivlaent dB-  scale familiar to clinicians for monitoring progression. The simulation has higher reproducibility than actual  VF, which improves detection of disease progression and measurement of progression speed. 3. Clinical studies in glaucoma diagnosis and monitoring. The clinical study will test whether the  proposed new technologies can improve the detection of pre-perimetric glaucoma, detection of disease  progression, and the accuracy of measuring the speed of progression. This research is likely to transform the clinical practice of glaucoma by developing novel objective functional and structural tests that can be practically implemented on the next generation of clinical OCT systems. This will save vision by achieving accurate diagnosis in early glacuoma and timely intervention in rapid progressors. PROJECT NARRATIVE Optical coherence tomography (OCT) is a high-resolution imaging technology that is already commonly used to diagnose and monitor glaucoma, a leading cause of blindness. The proposed research will further improve this technology so that it can detect earlier stages of glaucoma, evaluate the location and severity of glaucoma damage, and provide more accurate monitoring of disease progression. Directional OCT technology will be developed to accurately measure nerve fiber layer reflectance; sensorless adaptive-optics OCT technology will be used to improve imaging of nerve fiber bundles and capillaries; ultrahigh axial resolution will enable imaging of detailed internal retinal structures such as the lamellae of the inner plexiform layer; and capillary perfusion measurements will be used to simulate visual field function.",Functional and Structural Optical Coherence Tomography for Glaucoma,10211838,R01EY023285,"['3-Dimensional', 'Angiography', 'Blindness', 'Blood capillaries', 'Clinical', 'Clinical Research', 'Data', 'Defect', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Floor', 'Future', 'Ganglion Cell Layer', 'Glaucoma', 'Goals', 'Grant', 'Image', 'Imaging technology', 'Incidence', 'Inner Plexiform Layer', 'Intervention', 'Lasers', 'Location', 'Maps', 'Measurement', 'Measures', 'Medical', 'Methods', 'Monitor', 'Nerve Fibers', 'Nose', 'Open-Angle Glaucoma', 'Operative Surgical Procedures', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Performance', 'Perfusion', 'Questionnaires', 'Real-Time Systems', 'Reproducibility', 'Research', 'Resolution', 'Retina', 'Scanning', 'Severities', 'Severity of illness', 'Speed', 'Structure', 'System', 'Technology', 'Testing', 'Thick', 'Time', 'Variant', 'Vision', 'Visual Fields', 'Visualization', 'accurate diagnosis', 'adaptive optics', 'base', 'clinical practice', 'deep neural network', 'field study', 'high resolution imaging', 'high risk', 'improved', 'macula', 'new technology', 'next generation', 'novel', 'novel strategies', 'optic nerve disorder', 'prevent', 'prototype', 'quantitative imaging', 'simulation', 'tool']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,624917
"Malarial retinopathy screening system for improved diagnosis of cerebral malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. In 2018, malaria affected more than 213 million people in Africa alone and claimed 381,000 lives, more than 65% of whom were African children less than 5 years old. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM, incorrect treatment, and resulting mortality or neurological disability. The specificity of the current standard of care for clinical diagnosis of CM (physical symptoms, coma, and malaria parasite test such as rapid diagnostic testing) is reported around 61%. Therefore, there is a significant market need for a highly specific, low-cost, and easy-to-use test to improve CM diagnosis and save lives. Since Malarial retinopathy (MR) is greater than 95% specific to the presence of CM, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. Screening for MR in addition to the current standard of care improves the specificity of CM diagnosis from 61% to 100%. VisionQuest Biomedical has developed ASPIRE, the first fully automated MR detection software integrated with a low-cost and portable retinal camera, a system that can be operated by minimally trained personnel such as medical technician or nurse without the need of an ophthalmic specialist. We have assembled a multidisciplinary team of regulatory consultants, commercialization experts, business development specialists, and clinicians; to clinically deploy and launch ASPIRE in our target market in Africa. This team will validate and prepare ASPIRE for regulatory clearance as well as finalize the marketing and commercial rollout strategy. In Phase II-B, the research team at VisionQuest Biomedical deployed a fully-functional clinical version of ASPIRE and tested it in nine malaria clinics in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In CRP, ASPIRE will be validated for technical and clinical performance and will be brought to commercial readiness with regulatory clearance. We will accomplish this through four specific aims. In the first aim, the software system for MR detection will be validated to bring it under design controls. In the second aim, we will deploy ASPIRE at 25 clinics in Africa to demonstrate safety and efficacy as well as to promote market traction. The third aim will focus on preparing ASPIRE for regulatory submission. In the fourth aim, we will complete African healthcare market research for a startup market of 5 countries (Malawi, Zambia, Kenya, Uganda, Rwanda) and finalize marketing and rollout strategy. Within one year after CRP, our goal will be to deploy ASPIRE in more than 200 malaria clinics across 5 countries in Africa. Narrative Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection, which claims hundreds of thousands of lives of African children every year. The detection of retinal biomarkers of CM, called malarial retinopathy, can improve the diagnostic accuracy of CM. This project proposes the development, clinical deployment, and commercialization of a fully automated malarial retinopathy detection system consisting of a low-cost retinal camera and automatic malarial retinopathy detection software.",Malarial retinopathy screening system for improved diagnosis of cerebral malaria,10253474,SB1AI162452,"['5 year old', 'Affect', 'Africa', 'African', 'Artificial Intelligence', 'Biological Markers', 'Businesses', 'Cerebral Malaria', 'Cessation of life', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Coma', 'Computer software', 'Consult', 'Country', 'Detection', 'Development', 'Diagnosis', 'Diagnostic tests', 'Disease', 'Expert Systems', 'Feedback', 'Goals', 'Government', 'Grant', 'Health', 'Healthcare Market', 'Human Resources', 'Incidence', 'Institution', 'Institutional Review Boards', 'Internet', 'Kenya', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Market Research', 'Marketing', 'Medical', 'Medical Device', 'Medicine', 'Neurologic', 'Nurses', 'Parasites', 'Pathology', 'Performance', 'Pharmacy facility', 'Phase', 'Policies', 'Rapid diagnostics', 'Readiness', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Rwanda', 'Safety', 'Series', 'Software Validation', 'Specialist', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Traction', 'Training', 'Uganda', 'Validation', 'Work', 'Zambia', 'clinical Diagnosis', 'clinical research site', 'commercialization', 'cost', 'design', 'detection platform', 'diagnostic accuracy', 'disability', 'improved', 'malaria infection', 'mortality', 'multidisciplinary', 'physical symptom', 'portability', 'programs', 'research clinical testing', 'research study', 'screening', 'smartphone Application', 'software systems', 'standard of care', 'success', 'usability', 'verification and validation', 'web site']",NIAID,VISIONQUEST BIOMEDICAL INC,SB1,2021,999158
"Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. Annually, malaria affects more than 200 million people and claims the lives of over 440,000 people worldwide, mostly African children. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM and incorrect treatment. An accurate means to confirm the presence of CM or to investigate for a non-malarial illness is critically needed to improve outcomes. Since Malarial retinopathy (MR) is greater than 90% specific and sensitive to the presence of CM once clinically diagnosed, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. VisionQuest Biomedical and its collaborators have assembled a team of inter-disciplinary scientists with considerable experience in automated retinal image analysis, clinical ophthalmology with specialized research in malarial retinopathy (MR), and cerebral malaria diagnosis (CM). This team will develop and test ASPIRE, a system for detection of MR consisting of automated MR detection software integrated with a low-cost and portable retinal camera. Our proposed ASPIRE system will augment, not replace, the current CM diagnostic standard; increasing the accuracy of CM diagnoses, leading to a smaller number of false positive outcomes. In Phases I and II, the research team at VisionQuest Biomedical developed the automated MR detection software and interfaced it with a handheld retinal camera. The resulting clinical prototype of ASPIRE was tested onsite in a health-clinic in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In Phase II-B, the MR detection system will be refined, productized, and the resulting commercial prototype will be validated on prospective datasets. We will accomplish this through three specific aims. In the first aim, the software system for MR detection will be adapted and improved to work with low-cost and portable iNview camera. In the second aim, we will refine iNview’s driver-software and integrate the camera with MR detection software to produce the first commercial prototype. The third aim will focus on collecting the retinal image data for algorithm testing as well as for validating the commercial prototype in an observational clinical study to be conducted at nine clinical sites in Malawi, Uganda, and Zambia in Africa. Narrative Cerebral malaria is a life-threatening clinical syndrome associated with malarial infection, which affects about 200 million people annually and claims the lives of over 440,000 people worldwide, mostly African children. The presence of malarial retinopathy can provide additional insight and improve the diagnostic accuracy of CM. This project proposes the development of a fully-automated malaria retinopathy detection system consisting of a low-cost retinal camera and automatic malaria retinopathy detection software.",Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria,10074515,R44AI112164,"['5 year old', 'Address', 'Affect', 'Africa', 'African', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Cellular Phone', 'Cerebral Malaria', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Country', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Enrollment', 'Expert Systems', 'Foundations', 'Goals', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Image Analysis', 'Incidence', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Medicine', 'Ophthalmologist', 'Ophthalmology', 'Ophthalmoscopy', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Poison', 'Predictive Value', 'Price', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Safety', 'Scientist', 'Seasons', 'Series', 'Site', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Test Result', 'Testing', 'Uganda', 'Validation', 'Work', 'Zambia', 'base', 'clinical Diagnosis', 'clinical research site', 'cost', 'cost effectiveness', 'design', 'detection platform', 'diagnostic accuracy', 'experience', 'imaging capabilities', 'improved', 'improved outcome', 'innovation', 'insight', 'malaria infection', 'mortality', 'performance site', 'portability', 'programs', 'prospective', 'prototype', 'research study', 'response', 'retinal imaging', 'screening', 'smartphone Application', 'software development', 'software systems', 'success', 'usability']",NIAID,VISIONQUEST BIOMEDICAL INC,R44,2021,1000000
"Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring Abstract  Building on its commercially available Absolute Q digital PCR platform, during the 24-month Phase 2 SBIR project, Combinati will complete the development of the first Digital Melt Curve Analysis (DMCA) platform to the market to further advance the adoption of digital genomics for highly accurate, sensitive and reproducible nucleic acid quantification for longitudinal patient monitoring. To provide the “whole product” solution and prove the function, we will demonstrate the DMCA platform with Luminex’s 11- plex ESR1 (Estrogen Receptor 1) assay and conduct Beta testing at Dana Farber Cancer Institute: 1. Three beta instruments and the analysis software capable of digital melt curve analysis. 2. Complete dMCA validation internally with commercially available melt calibration kits. 3. Demonstrate <0.1% Mutation Allele Frequency of 11 cell-free DNA targets using Luminex  Corporation’s discrete melt assay. 4. Beta testing at Dana Farber Cancer Institute Narrative  Since PCR was invented back in 1983, it has become the gold standard for applications requiring quantification of nucleic acids. The continuous evolution of the technology enables PCR to be more quantitative (qPCR), more accurate, precise and reproducible (digital PCR). In parallel, with the invention of melt curve analysis in 1997, it opens another dimension in melt temperatures for applications requiring simple and inexpensive genotyping, high degree qualitative multiplexing without sequencing, and assay optimization. Despite that there is a handful of dPCR platforms in the market, none of them supports Melt Curve Analysis. By combining melt curve analysis with digital PCR, Combinati strives to accelerate the adoption of digital genomics for all nucleic acid quantification needs in research and clinical markets.",Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring,10256226,R44CA261523,"['Adopted', 'Adoption', 'Architecture', 'Back', 'Biological Assay', 'Blinded', 'Breast Cancer Patient', 'Calibration', 'Cancer Patient', 'Chemistry', 'Clinical', 'Collection', 'Color', 'Computer software', 'Computers', 'DNA', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Development', 'Dimensions', 'ESR1 gene', 'Evolution', 'Gene Frequency', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Journals', 'Letters', 'Light', 'Mainstreaming', 'Manuscripts', 'Mechanics', 'Memory', 'Metastatic breast cancer', 'Microfluidics', 'Monitor', 'Mutation', 'Nucleic Acids', 'Optics', 'Oranges', 'Patient Monitoring', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Reproducibility', 'Research', 'Resolution', 'Risk', 'Running', 'Sampling', 'Science', 'Small Business Innovation Research Grant', 'Source', 'Speed', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Validation', 'cell free DNA', 'clinically relevant', 'cost', 'cyanine dye 5', 'data exchange', 'design', 'detection limit', 'digital', 'fluorescence imaging', 'graphical user interface', 'image processing', 'improved', 'instrument', 'invention', 'lens', 'liquid biopsy', 'machine learning algorithm', 'meetings', 'melting', 'multidimensional data', 'mutant', 'mutation assay', 'neural network', 'product development', 'sensor', 'simulation']",NCI,"COMBINATI, INC.",R44,2021,772720
"Quantitative and Spectroscopic Imaging of Skeletal Muscle Changes in Sarcopenia at High Field Project Summary Sarcopenia, a condition characterized by loss of muscle mass and function in the elderly, is of increasing relevance in the United States due to its aging population. It is generally agreed that the weakening of the muscle in sarcopenia cannot be explained by loss of muscle mass alone, but the mechanisms behind this remain poorly understood. This is partly due to the lack of non-invasive techniques for observing muscle structure and composition in high detail. We propose to develop MRI techniques to measure muscle morphology, microstructure, and fat content to get a detailed view of the changes in muscle quantity and quality in patients with sarcopenia and how they relate to more easily attainable measurements of muscle function such as grip strength and gait speed. This would provide an important contribution to the ongoing debate about how such measurements could be used to define sarcopenia, which would pave the way for treatment development. We aim to develop novel methods to investigate the structure and composition of muscle using ultra-high-field MRI. Specifically, we aim to (1) obtain water-based images of skeletal muscle macro- and microstructure with unparalleled efficiency, image quality, and resolution; (2) obtain images of the spatial distribution of intramyocellular lipids in skeletal muscle, measuring both methyl and methylene to estimate saturation; and (3) to conduct a study comparing skeletal muscle structure and quality by looking at MR measurements of T2 relaxation rates, diffusivity (as proxies for inflammation and fiber size, respectively), fat fraction, and lipid composition, in subjects with sarcopenia and healthy controls and see how these quantities correlate to muscle function. This project has several innovative aspects. First, we will develop a method to estimate muscle morphology, T2 relaxation rates, and diffusivity with a single MRI sequence. Importantly, this will make the developed method easy to run at other MRI sites. Second, we will devise methods to perform robust, efficient imaging of intramyocellular lipid droplet distribution and saturation in human skeletal muscle in vivo at high field. Both of these methods will have unparalleled signal-to-noise ratio and robustness against image artifacts. The significance of this work is the investigation of the role of inflammation, fiber size, and lipid distribution in the weakening of muscle in sarcopenia and how these measurements are related to muscle function. The resulting conclusions and techniques may help establish a common standard for the definition of sarcopenia and aid in the development of future treatments for this condition. Project Narrative Sarcopenia, the loss of muscle mass and function with age, is a condition bound to increase in prevalence with an aging population. The muscle changes involved include not only reduction in mass but also changes in muscle quality not easily visualized with current methods. This work aims to develop efficient MRI techniques to investigate these changes in better detail, improving scientific understanding of the mechanisms of sarcopenia and how they relate to muscle function.",Quantitative and Spectroscopic Imaging of Skeletal Muscle Changes in Sarcopenia at High Field,10125507,K99AG066815,"['3-Dimensional', 'Affect', 'Age', 'Awareness', 'Biological Markers', 'Clinical', 'Communities', 'Consensus', 'Data', 'Development', 'Diagnostic', 'Diffuse', 'Diffusion', 'Elderly', 'Evaluation', 'Fatty acid glycerol esters', 'Fiber', 'Fracture', 'Frequencies', 'Future', 'Gait speed', 'Geriatrics', 'Goals', 'Hand Strength', 'Health', 'Health Personnel', 'Hospitalization', 'Human', 'Image', 'Imaging Techniques', 'Inflammation', 'Investigation', 'Life Expectancy', 'Lipids', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Marker', 'Methods', 'Morphologic artifacts', 'Morphology', 'Muscle', 'Muscle function', 'Muscular Atrophy', 'Noise', 'Patients', 'Phase', 'Physiologic pulse', 'Predisposition', 'Prevalence', 'Protons', 'Proxy', 'Relaxation', 'Research', 'Resolution', 'Role', 'Running', 'Signal Transduction', 'Site', 'Skeletal Muscle', 'Soleus Muscle', 'Spatial Distribution', 'Spectrum Analysis', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Treatment Effectiveness', 'United States', 'Water', 'Work', 'aging population', 'base', 'bone imaging', 'carbene', 'clinical biomarkers', 'design', 'falls', 'imaging biomarker', 'imaging modality', 'improved', 'in vivo', 'innovation', 'muscle form', 'muscle strength', 'muscular structure', 'novel', 'potential biomarker', 'quantitative imaging', 'radio frequency', 'recruit', 'sarcopenia', 'spectroscopic imaging', 'therapy development']",NIA,MASSACHUSETTS GENERAL HOSPITAL,K99,2021,114480
"Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing ABSTRACT No real-time quantitative devices are clinically used to assess oral lesions during routine examination, making in-clinic diagnostic and longitudinal monitoring challenging. Instead, lesions are evaluated through visual inspection and then histopathological analysis of tissue samples extracted during biopsy. Identifying premalignant and malignant oral lesions early is critical to ensuring effective treatment is provided to patients with malignancies. Oral cancer currently has one of the lowest 5-year survival rates (50% or less) among major cancer types, largely due to the challenges in identifying premalignant and malignant lesions early. Clearly, a real-time in-clinic device able to classify oral lesions as benign, premalignant, or malignant has the potential to provide immediate impact to patient care. Significantly different electrical property signatures have been observed between benign and malignant tissues in a variety of organs, including tongue; since the bioelectrical properties are so dependent on tissue architecture and morphology, we hypothesize that sensing and imaging these properties in the context of oral lesions will enable us to accurately characterize and classify morphologically-different benign, premalignant, and malignant oral lesions. We have developed an endoscopic electrical impedance imaging (EII) device for use in intraoperative surgical margin assessment that we aim to optimize for in-clinic oral lesion assessment. We aim to take the significant step of translating our extensive experience in impedance imaging to develop an oral lesion imaging device that can be deployed safely, and in the clinic, to provide real-time feedback regarding oral lesion classification. We propose constructing a novel chip-on-tip EII probe to sense and image at near microscopic resolution oral lesions in an effort to provide clinicians with real-time, accurate classification of oral lesion pathology that can be used for diagnostic and longitudinal monitoring purposes. The probe will be evaluated on a series of in vivo human oral lesions and compared with histopathological analysis of biopsy samples. The low-cost of a device such as this makes it an ideal technology for low-resource settings and the safety and real-time capabilities of the system make it ideal for continuously following lesions. PROJECT NARRATIVE Visual inspection of oral lesions is not sufficient for accurately classifying lesions as benign, premalignant, or malignant. The electrical properties of oral lesion have the potential to be used as a contrast mechanism to accurately classify oral lesions so that optimal treatment can be provided to patients with malignant lesions. We intend to deploy a novel small field of view chip-on-tip electrical impedance imaging (EII) probe in a cohort of patients with oral lesions to evaluate the efficacy of using EII for oral lesion classification.",Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing,10287597,R21DE031095,"['Architecture', 'Area', 'Benign', 'Biological Markers', 'Biopsy', 'Biopsy Specimen', 'Cancerous', 'Carcinoma', 'Carcinoma in Situ', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Contralateral', 'Custom', 'Data', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Dysplasia', 'Electrodes', 'Electronics', 'Ensure', 'Epithelial', 'Excision', 'Feedback', 'Frequencies', 'Hand', 'Histologic', 'Human', 'Hyperplasia', 'Image', 'Imaging Device', 'Ionizing radiation', 'Length', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Microscopic', 'Monitor', 'Morphology', 'Noise', 'Normal tissue morphology', 'Oral Characters', 'Oral cavity', 'Organ', 'Oropharyngeal', 'Pathology', 'Patient Care', 'Patients', 'Positioning Attribute', 'Procedures', 'Property', 'Research Design', 'Resolution', 'Resources', 'Safety', 'Sampling', 'Series', 'Signal Transduction', 'Site', 'Squamous Cell', 'Surgical margins', 'Survival Rate', 'System', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'Tongue', 'Translating', 'Visual', 'analog', 'base', 'bioelectricity', 'cancer type', 'cohort', 'cost', 'design', 'effective therapy', 'efficacy evaluation', 'electric impedance', 'electrical impedance tomography', 'electrical property', 'experience', 'extracellular', 'imaging probe', 'imaging properties', 'in vivo', 'interest', 'malignant mouth neoplasm', 'monitoring device', 'novel', 'optimal treatments', 'oral lesion', 'oral tissue', 'premalignant', 'pressure', 'pressure sensor', 'programs', 'response', 'soft tissue']",NIDCR,DARTMOUTH COLLEGE,R21,2021,191061
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10202460,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2021,749956
"Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array PROJECT SUMMARY COVID-19 presents a public health emergency: There is a critical need for rapid, not reagent intensive, non- invasive testing technologies. This program will lead to the production of a prototype system to diagnose COVID-19 infection using the body odor signature of the disease. Our goal is to maximize societal impact by creating a validated prototype that can be used in a community or workplace setting by minimally trained personnel for low-cost, on-the-spot diagnosis within minutes. The system will be developed in a manner that puts it on a pathway for rapid FDA approval. The Research Aims are: Aim 1. Optimization, assembly, and integration of a prototype system with the ability to odor signature of COVID-19 in samples of body odor. The system will be simple to use, pose essentially zero risk to the operator and the test subject, and report a result within minutes. The production cost at scale will be approximately $9,000 for the complete measurement system, with a per test cost of approximately $0.50. The design and construction of the prototype will be conducted by Novo Engineering, a leading firm with extensive experience in medical device development. Aim 2. Software development. Software for the system from VOC sampling to final diagnostic result will be developed to ensure error-free operation of the device. Our preliminary results suggest that simple linear discriminant analysis (LDA) does an excellent job of classifying VOCs from human body odor as COVID-19 positive or negative (92% sensitivity and 87% specificity). Optimization of the sensor array (Aim 1) and use of richer feature sets in our classifier models will lead to further performance improvements in the prototype system. Aim 3. System Benchmarking and Validation. We will benchmark the full prototype system against a number of VOC mixtures, with and without in vitro skin models. The system will undergo extensive testing against body odor samples from individuals with pathological conditions other than COVID-19 and other sources of potentially confounding VOCs. The prototype will be validated against 1000 samples drawn from the COVID-SAFE program at Penn. The screening will include all members of the Penn community, and represents incredible racial and ethnic diversity as well as a wide variance in age, sex, and gender. Aim 4. Regulatory Approval Plan The plan will be developed under the direction of Sr/Key personnel John Fuson, JD, an attorney at Crowell & Moring LLP and a former Associate Chief Counsel at FDA. Novo Engineering has extensive experience in guiding prototype design in alignment with the requirements for FDA approval. The proposed COVID-19 VOC-based testing device will be regulated by the FDA, likely as a Class I or II medical device. Because there is no clear predicate device to reference in this case, we intend to submit a direct de novo petition to FDA asking the agency to categorize and clear the proposed COVID-19 testing device as Class I or Class II without reference to any predicate. PROJECT NARRATIVE This program addresses the critical unmet need of an effective means to screen for COVID-19 infection, and potentially other novel virus infections, in a community setting based upon the body odor signature of the disease. The program will result in a validated prototype system, with a test time of minutes, a test cost of approximately $0.50, on a path to rapid FDA approval.","Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array",10266403,U18TR003775,"['Address', 'Age', 'Astronomy', 'Benchmarking', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 screening', 'COVID-19 testing', 'Carbon Nanotubes', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Chemicals', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Computers', 'Counseling', 'DNA', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Discriminant Analysis', 'Disease', 'Engineering', 'Ensure', 'Florida', 'Future', 'Gender', 'Goals', 'Gold', 'Hand', 'Health', 'Housekeeping', 'Human', 'Human Resources', 'Human body', 'In Vitro', 'Individual', 'Information Sciences', 'International', 'Intuition', 'Laboratories', 'Lawyers', 'Mass Fragmentography', 'Measurement', 'Mechanics', 'Medical Device', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Nose', 'Occupations', 'Odors', 'Participant', 'Pathologic', 'Pathway interactions', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phase', 'Physics', 'Production', 'RADx', 'Reagent', 'Reporting', 'Research', 'Risk', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Sampling', 'Skin', 'Software Engineering', 'Solid', 'Source', 'Specificity', 'Spottings', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Viral', 'Virus Diseases', 'Visual', 'Workplace', 'animal care', 'artificial neural network', 'base', 'community setting', 'coronavirus disease', 'cost', 'design', 'design and construction', 'ethnic diversity', 'experience', 'high standard', 'machine learning algorithm', 'medical schools', 'member', 'multidisciplinary', 'nano', 'nanosensors', 'next generation', 'novel virus', 'operation', 'prevent', 'programs', 'prototype', 'public health emergency', 'racial diversity', 'sample collection', 'screening', 'screening program', 'sensor', 'sex', 'software development', 'software systems', 'vapor', 'volatile organic compound']",NCATS,UNIVERSITY OF PENNSYLVANIA,U18,2021,999830
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10162472,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2021,283097
"Clinical and genetic analysis of retinopathy of prematurity Project Summary The long-term goal of this project is to establish a quantitative framework for retinopathy of prematurity (ROP) care based on clinical, imaging, genetic, and informatics principles. In the previous grant period, we have developed artificial intelligence methods for ROP diagnosis, but real-world adoption has been limited by lack of prospective validation and by perception of these systems as “black boxes” that do not explain their rationale for diagnosis. Furthermore, although biomedical research data are being generated at an enormous pace, much less work has been done to integrate disparate scientific findings across the spectrum from genomics to imaging to clinical medicine. This renewal will address current gaps in knowledge in these areas. Our overall hypotheses are that developing a quantitative framework for ROP care using artificial intelligence and analytics will improve clinical disease management, that building “explainable” artificial intelligence systems will enhance clinical acceptance and educational opportunities, and that analysis of relationships among clinical, imaging, environmental, and genetic findings, in ROP will improve understanding of disease pathogenesis and risk. These hypotheses will be tested using three Specific Aims: (1) Evaluation performance of an artificial intelligence system for ROP diagnosis and screening prospectively. This will include: (a) recruit a target of over 2000 eye exams including wide-angle retinal images from 375 subjects at 5 centers, (b) optimize an image quality detection algorithm we have recently developed, and (c) analyze system accuracy for ROP diagnosis and screening (using a novel quantitative vascular severity scale). (2) Improve the interpretability of our existing artificial intelligence methods for ROP diagnosis. This will include: (a) increase “explainability” of systems by combining deep learning with traditional feature extraction methods, (b) develop neural networks to identify changes between serial images, and (c) evaluate these methods through systematic feedback by experts. (3) Develop integrated models for ROP pathogenesis and risk. This will include: (a) build and improve ROP risk prediction models based on clinical, image, and demographic features, and (b) integrate genetic, imaging, clinical, and environmental variables through genetic risk prediction by machine learning, by investigating casual relationships with genetic variants and genetic risk scores, and by incorporating SNP associations with gene expression measurements to identify functional genes of ROP. Ultimately, these studies will significantly reduce barriers to adoption of technologies such as artificial intelligence for clinicians, and will demonstrate a prototype for health information management which combines genotypic and phenotypic data. This project will be performed by a multi-disciplinary team of investigators who have worked successfully together for nearly 10 years, and who have expertise in ophthalmology, biomedical informatics, computer science, computational biology, ophthalmic genetics, genetic analysis, and statistical genetics. Project Narrative ROP is a leading cause of childhood blindness in the US and throughout the world, and the number of infants at risk for disease is increasing as the rate of premature birth rises. Rapidly-progressive changes associated with retinal vascular development may be visualized by clinical examination, captured by wide-angle imaging, and analyzed genetically. This project will develop, enhance, and validate artificial intelligence and analytic tools to help clinicians identify infants at risk for severe ROP using image analysis, genetic analysis, and integrative informatics that combines these factors – while also providing insight about disease pathogenesis.",Clinical and genetic analysis of retinopathy of prematurity,10206145,R01HD107493,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biomedical Research', 'Blindness', 'Blood Vessels', 'Caring', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Research', 'Cohort Studies', 'Computational Biology', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Evaluation', 'Expert Systems', 'Feedback', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Infant', 'Informatics', 'Information Management', 'International', 'Knowledge', 'Longitudinal Studies', 'Machine Learning', 'Macular degeneration', 'Measurement', 'Medical Genetics', 'Mendelian randomization', 'Methods', 'Modeling', 'Molecular Genetics', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Other Genetics', 'Paper', 'Pathogenesis', 'Peer Review', 'Perception', 'Performance', 'Phenotype', 'Predisposition', 'Premature Birth', 'Premature Infant', 'Publishing', 'Reference Standards', 'Research', 'Research Personnel', 'Retina', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Severities', 'System', 'Technology', 'Testing', 'United States', 'Validation', 'Work', 'analytical tool', 'base', 'biomedical informatics', 'care delivery', 'clinical Diagnosis', 'clinical examination', 'clinical phenotype', 'clinical risk', 'clinically significant', 'computer science', 'data access', 'data integration', 'deep learning', 'detection platform', 'diagnosis standard', 'disorder risk', 'feature extraction', 'genetic analysis', 'genetic variant', 'high risk', 'imaging genetics', 'improved', 'insight', 'multidisciplinary', 'multiple data types', 'neovascular', 'neural network', 'novel', 'phenotypic data', 'prospective', 'prototype', 'real world application', 'recruit', 'retinal imaging', 'risk prediction', 'risk prediction model', 'screening', 'serial imaging', 'supplemental oxygen']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,640901
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,10136081,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'detection test', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,821265
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,10170765,R21EB025621,"['Abdomen', 'Acoustics', 'Adult', 'Age', 'Anatomy', 'Area', 'Award', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Evaluation', 'Excision', 'Family suidae', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Measurement', 'Metals', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translations', 'Ultrasonography', 'United States National Institutes of Health', 'Visualization', 'Work', 'algorithm training', 'base', 'convolutional neural network', 'cost', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'metallicity', 'obese patients', 'obese person', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,235027
"Machine learning algorithms to analyze large medical image datasets Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. Our overall objective for this research is to dramatically reduce the burden of creating high quality reference labels by requiring only a small set of such labels from experts. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. This will enable us to apply ML techniques to generate high quality labels of the large amounts of unlabeled data that are already available, which in turn will facilitate the assessment of potential quantitative imaging biomarkers. We will develop, extend and evaluate novel algorithms that represent three distinct strategies for reducing labelling cost. These three strategies are learning from unlabelled data incorporating a novel strategy for characterizing uncertainty, optimizing sample selection for expert quality labelling with a novel form of Active Learning especially suited for deep learning, and reducing the cost of achieving quality labeling by replacing or augmenting an expert with a crowd of inexperts. We will then implement and distribute these novel algorithms, facilitating the replication of our experiments. Finally, we will demonstrate the practical efficacy of these three strategies by applying them to the important challenge of identifying quantitative imaging biomarkers that best capture alterations in brain structure that are associated with characteristics of ASD. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes. Machine learning (ML) is poised to enable faster and more accurate interpretation of medical images by augmenting the capabilities of experts. Success of ML techniques for medical image interpretation may reduce the burden on radiologists, reducing errors arising from fatigue or interruption, while simultaneously reducing costs and increasing speed and accuracy for patients. The cost and difficulty of generating expert quality labelled image data is the primary limitation preventing faster progress and deployment in more domains. We propose to address this problem by creating innovative algorithms that will construct reference quality labelled data with little input from domain experts, thus dramatically reducing the cost of labelling. These fundamental advances in informatics algorithms will reduce the cost and increase the rate of obtaining quality labels, which will in turn facilitate the widespread adoption and deployment of machine learning algorithms for image interpretation. Ultimately, this will stimulate the development of new imaging biomarkers that hold the potential to dramatically improve clinical decision-making and patient outcomes.",Machine learning algorithms to analyze large medical image datasets,10182522,R01LM013608,"['Active Learning', 'Address', 'Adoption', 'Algorithms', 'Benchmarking', 'Brain', 'Characteristics', 'Child', 'Clinical', 'Collection', 'Crowding', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Fatigue', 'Image', 'Image Analysis', 'Informatics', 'Interruption', 'Label', 'Learning', 'Life', 'Machine Learning', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Noise', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Reference Standards', 'Research', 'Sampling', 'Speed', 'Structure', 'Techniques', 'Training', 'Uncertainty', 'Update', 'autism spectrum disorder', 'base', 'clinical decision-making', 'cost', 'crowdsourcing', 'deep learning', 'design', 'experimental study', 'imaging Segmentation', 'imaging biomarker', 'improved', 'innovation', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'novel', 'novel strategies', 'prevent', 'quantitative imaging', 'radiologist', 'success', 'supervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,369580
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,10077550,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2021,190362
"AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition ABSTRACT Dietary intake is a complex human behavior that drives disease risk and corresponding economic and healthcare burdens worldwide. Poor diet is the leading cause of death in the US and a known driver of obesity – a global epidemic. A major contributor to poor diet is food eaten away from home, such as restaurant foods. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods. Accurate approaches and tools to evaluate food and nutrient intake are essential in monitoring the nutritional status of individuals. There is a critical need for real-time data capture that minimizes burden and reduces error. While progress has been made, there is no tool available that accurately and automatically estimates foods left unconsumed in a meal. Two major limitations of existing systems is the reliance of a fiducial marker for food detection and volume estimation, and reliance on humans – either the respondent or a trained researcher – to estimate the portion of food leftover. This application leverages novel technology to remove those limitations. The long-term research goal is to utilize digital imaging (DI), artificial intelligence (AI) and computer vision (CV) techniques to develop a novel hybrid methodology for rapid, accurate measurement of dietary intake. To attain this goal, our objective in this R21 application is to refine and test a system architecture that (a) uses digital images to record dietary intake in real-time and (b) uses AI and CV techniques to identify food/beverage items and determine amounts leftover. We plan to build on our current prototype in which digital food images are captured before and after the meal, analyzed to detect the food items, a three-dimensional (3-D) virtual model constructed, and volume remaining after the meal estimated, which will be used to calculate the amount leftover based on the initial volume. Volume consumed will be converted to weight and linked to public-use nutrition information. These calorie estimates will be compared against calories those from (a) DIs coded by trained research staff and (b) weighed plate waste methodology. Our expectation is to develop a valid system architecture for rapidly estimating dietary intake. The outcome of this proposal is expected to have a significant positive impact, enabling nutrition and health researchers to collect high-quality food consumption data in real world settings, increasing knowledge of dietary patterns and improving capacity to assess dietary interventions. This work will lead to an R01 application that will expand food types and meal settings and test the utility of our system among consumers. Project Narrative Solutions to address the global obesity epidemic are urgently needed. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods, a known driver of obesity. This study integrates nutrition science, computer science, and engineering to develop and test a new method for assessing dietary intake, and if successful would yield a rapid, reliable, accurate and cost- effective tool.",AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition,10163822,R21CA250024,"['3-Dimensional', 'Address', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Behavior', 'Beverages', 'Body Weight decreased', 'Calories', 'Cause of Death', 'Cellular Phone', 'Code', 'Complex', 'Computer Vision Systems', 'Consumption', 'Data', 'Databases', 'Detection', 'Development', 'Diet Records', 'Dietary Assessment', 'Dietary Intervention', 'Dietary Practices', 'Dietary intake', 'Economics', 'Engineering', 'Epidemic', 'Food', 'Goals', 'Gold', 'Health', 'Healthcare', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Intake', 'Intervention', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Nutrient', 'Nutritional Science', 'Nutritional status', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Output', 'Participant', 'Research', 'Research Personnel', 'Research Training', 'Respondent', 'Restaurants', 'Side', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unhealthy Diet', 'Validation', 'Weight', 'Work', 'base', 'computer science', 'cost', 'cost effective', 'design', 'dietary', 'digital', 'digital imaging', 'disorder risk', 'expectation', 'food consumption', 'food quality', 'handheld mobile device', 'improved', 'knowledge base', 'new technology', 'novel', 'nutrition', 'prototype', 'success', 'system architecture', 'tool', 'virtual model', 'wasting', 'weight maintenance']",NCI,TUFTS UNIVERSITY BOSTON,R21,2021,197745
"Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity PROJECT SUMMARY The long-term goal of this project is to determine whether optical coherence tomography (OCT) and OCT angiography (OCTA) might lead more accurate and objective diagnosis, earlier intervention, and improved outcomes in retinopathy of prematurity (ROP). International consensus and National Institute of Health (NIH) funded clinical trials over the last 30 years have defined the phenotypic classifications, natural history, prognosis, and management of ROP. However, it is well established that due to the subjectivity of the ophthalmoscopic examination, and systematic bias between examiners, there is significant variation in treatment of the most severe forms of ROP in the real world. This leads to both under-treatment (and poor outcomes due to retinal detachment) and over-treatment (exposing neonates to the ocular and systemic risks of treatment). Roughly 20,000 babies per year develop retinal detachments (RD) due to ROP and there is strong evidence that most of these are preventable. In adult retinal vascular diseases, most notably diabetic retinopathy (DR), OCT and OCTA can detect and quantify disease features such as diabetic macular edema (DME) and retinal neovascularization (NV) before they are noted clinically, enabling earlier treatment and reducing the risk of blindness from RD. However, evaluating the use of this technology in neonates requires high speed and portable technology, and the commercially available handheld OCTs are too slow for ultra-widefield (UWF) OCT and OCTA imaging. Several groups (including our own) have published preliminary results using prototype 100 to 200 kHz swept- source (SS) OCT systems, however consistent data acquisition remains challenging due to the lack of fixation and subsequent motion in an awake neonate, which has limited the evaluation of the potential benefits of the technology in this population. Recently, there has been much interest in using artificial intelligence (AI) (specifically deep learning), which relies on high speed graphics processing units (GPUs) to provide real time OCT image processing, segmentation, and tracking. This application addresses 2 fundamental gaps in knowledge: (1) Can we overcome the technical challenges through the development of a faster ultrawide-field view SS-OCT system coupled with a GPU-enabled DL software system to enable consistent data acquisition in neonates? (2) Would quantitative objective metrics of ROP improve objectivity of ROP diagnosis and detect subclinical signs of disease progression which may enable earlier intervention and improved outcomes in the future. By leveraging our institution’s OCT, AI, and ROP expertise, we will address these questions in three specific aims: (1) Develop an ultra-high speed, handheld, panoramic ultra-widefield OCT/OCTA system. (2) Develop real time GPU accelerated intelligent image acquisition software. (3) Evaluate the clinical significance OCT derived biomarkers. Successful translation of this technology to the ROP population could improve the accuracy and objectivity of ROP diagnosis, and lead to earlier intervention and improved outcomes in patients with severe ROP. PROJECT NARRATIVE Optical Coherence Tomography (OCT) and OCT angiography (OCTA) have proven the ability to detect subclinical disease, provide quantitative evaluation of disease progression, and improve outcomes in the leading causes of blindness in adults, age-related macular degeneration and diabetic retinopathy. Technological and practical limitations have limited the application of this technology in routine use for non-sedated children undergoing routine screening for retinopathy of prematurity (ROP), the leading cause of blindness in children. The proposed project will develop an ultra-high speed, handheld OCT system with graphics processing unit (GPU) enabled real-time processing to improve the feasibility of panoramic ultra-widefield OCT/OCTA imaging in non-sedated neonates and evaluate the clinical utility of OCT-derived biomarkers in ROP.",Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity,10198930,R01HD107494,"['Address', 'Adult', 'Aftercare', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Blindness', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Trials', 'Computer software', 'Consensus', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Disease Progression', 'Dyes', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Evaluation', 'Eye', 'Fluorescein Angiography', 'Funding', 'Fundus', 'Future', 'Goals', 'Image', 'Image Analysis', 'Injections', 'Institution', 'Intelligence', 'International', 'Knowledge', 'Lasers', 'Lead', 'Length', 'Longitudinal Studies', 'Measurement', 'Medical Imaging', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Natural History', 'Neonatal', 'Ophthalmic examination and evaluation', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Pilot Projects', 'Population', 'Primary Health Care', 'Publishing', 'Quantitative Evaluations', 'Retina', 'Retinal Detachment', 'Retinal Neovascularization', 'Retinopathy of Prematurity', 'Risk', 'Scanning', 'Severities', 'Severity of illness', 'Source', 'Speed', 'Structure', 'System', 'Systematic Bias', 'Technology', 'Testing', 'Time', 'Translations', 'United States National Institutes of Health', 'Variant', 'Vascular Diseases', 'Visualization', 'accurate diagnosis', 'arm', 'awake', 'base', 'blind', 'clinical Diagnosis', 'clinically significant', 'data acquisition', 'deep learning', 'design', 'diabetic', 'disease classification', 'disorder of macula of retina', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'instrument', 'interest', 'lens', 'macular edema', 'neonate', 'neovascularization', 'novel', 'outcome forecast', 'overtreatment', 'parallel computer', 'portability', 'prototype', 'real-time images', 'research clinical testing', 'routine screening', 'sample fixation', 'software systems', 'standard of care', 'treatment response', 'treatment risk']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,377300
"Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics Abstract The primary objective is to develop an artificial intelligence-centric, quantitative and noninvasive software platform that can be integrated into 3D angiographic scanners (DSA, CTA or MRA) to provide guidance regarding the diagnosis and management of intracranial aneurysms (IA). Hemorrhagic stroke secondary to ruptured IAs leads to significant morbidity and mortality and affects over 35,000 patients on a yearly basis in the United States. The diagnosis of asymptomatic IAs is on the rise with the increasing use of cerebral imaging. However, guidance regarding which aneurysms should be treated has not advanced. Leveraging recent advances in computational science and technology, particularly artificial intelligence, the proposed software platform built on two enabling technologies can (1) propel automated “patient-specific” hemodynamic evaluations into the clinical workflow and (2) conduct “data-driven” risk assessments of IA rupture on an individual basis. Specific research aims are to (1) develop a clinically-oriented CFD platform that enables automated “patient-specific” hemodynamic evaluations of IAs, (2) investigate data-driven analytics toward prediction of rupture risk for IAs and (3) evaluate the data-driven analytics in a blind study. Once validated, a follow-up R01 project is planned to examine the clinical utility of the proposed software platform in a prospective clinical study as a single gateway for computer-aided evaluation of cerebral aneurysms. Public Health Relevance/Narrative This R01 proposal is to investigate the feasibility of developing an innovative, non-invasive and artificial intelligence-centric tool that can be used as a software add-on to clinical angiographic (e.g. DSA) scanners. The software can automatically select high-risk aneurysms for immediate treatments from a pool of patients with unruptured intracranial aneurysms, impacting the clinical management of intracranial aneurysms.",Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics,10121043,R01EB029570,"['3-Dimensional', 'Affect', 'Aneurysm', 'Angiography', 'Architecture', 'Artificial Intelligence', 'Benign', 'Biomedical Computing', 'Biomedical Engineering', 'Brain hemorrhage', 'Cerebral Aneurysm', 'Cerebrum', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational Geometry', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Engineering', 'Ensure', 'Evaluation', 'Genetic', 'Growth', 'Human', 'Image', 'Individual', 'Intracranial Aneurysm', 'Knowledge', 'Liquid substance', 'Machine Learning', 'Medicine', 'Methods', 'Michigan', 'Morbidity - disease rate', 'Morphology', 'Natural History', 'Neural Network Simulation', 'Outcome', 'Patients', 'Physics', 'Play', 'Research', 'Research Proposals', 'Risk', 'Risk Assessment', 'Role', 'Rupture', 'Ruptured Aneurysm', 'Secondary to', 'Smoker', 'Technology', 'TensorFlow', 'Testing', 'Training', 'Translational Research', 'United States', 'Universities', 'Wisconsin', 'Work', 'analytical method', 'base', 'blind', 'computer grid', 'convolutional neural network', 'deep learning', 'flexibility', 'follow-up', 'hemodynamics', 'high risk', 'image guided', 'innovation', 'learning strategy', 'mortality', 'neurosurgery', 'open source', 'personalized management', 'prevent', 'prospective', 'prototype', 'public health relevance', 'shear stress', 'success', 'tool']",NIBIB,MICHIGAN TECHNOLOGICAL UNIVERSITY,R01,2021,346966
"A Handheld Microchip for GC analysis of breath to screen for COVID-19 Project Summary  The COVID-19 pandemic has caused unprecedented societal suffering and economic disruption. In the United States, more than six million people have contracted COVID-19 and more than one hundred ninety thousand patients have died of this disease to date. Although current COVID-19 diagnostic testing technologies are critical for slowing the spread of the virus and preventing future outbreaks, they are not practical for field use. Current diagnostic tests are cumbersome to perform because they use aqueous solutions, require multiple steps, and hours-to-days to obtain results. Since the US began to reopen the economy in May, there has been a significant increase in the number of COVID-19 cases. Therefore, there is an urgent need to develop a diagnostic approach that is non-invasive, portable, and can rapidly provide test results.  The overall goal of the project is to develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). The handheld tool will be a closed system for trapping select volatile organic compounds (VOCs) on a microfabricated chip. The captured VOCs will be eluted with ethanol and then analyzed using a commercially available, portable GC-PID instrument. Artificial intelligence (AI) and machine learning algorithms will be applied to recognize the VOC pattern that correlates with COVID-19 infection. The central innovation is the microfabricated chip that captures carbonyl compounds in exhaled breath and thus serves as a preconcentrator, which enables analysis of carbonyl VOCs by the portable GC-PID. The hypothesis is that the carbonyl metabolome in exhaled breath is directly related to the body’s reaction to the novel coronavirus infection, and changes in the carbonyl VOC composition in exhaled breath relative to healthy controls can be used to detect both symptomatic and asymptomatic COVID-19 patients.  Three specific aims are proposed to fulfill the overall goal. Aim 1 is to build a disposable handheld breath analyzer tool for concentrating carbonyl VOCs. Aim 2 is to identify VOC patterns in the breath of COVID-19 patients by machine learning algorithms. Aim 3 is to integrate portable GC technology with the breath sampling tool for COVID-19 screening guided by an AI system. The University of Louisville is uniquely suited to rapidly transition the microchip technology to field use because of the PI and Co-PI’s experience in breath analysis and translational research, and the project team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence as well as the state-of-the-art facilities that include a MicroNano Technology Center, Biosafety Level 3 Regional Biocontainment Lab, and an NIH-funded REACH program. 8. Project Narrative  This project will develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). Artificial intelligence and machine learning algorithms will be used to analyze the detected signals of volatile organic compounds (VOCs) in exhaled breath by the portable GC for detection of COVID-19 patients. UofL is uniquely suited to develop this approach because of the PI’s expertise in breath analysis for detection of Tuberculosis and lung cancer and the team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence.",A Handheld Microchip for GC analysis of breath to screen for COVID-19,10266377,U18TR003787,"['2019-nCoV', 'Acute', 'Address', 'Artificial Intelligence', 'Biochemical Process', 'Biometry', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnostic', 'COVID-19 pandemic', 'COVID-19 patient', 'COVID-19 screening', 'COVID-19 test', 'Cancer Detection', 'Clinic', 'Collaborations', 'Collection', 'Communicable Diseases', 'Contracts', 'Coronavirus Infections', 'Detection', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Economics', 'Epithelial Cells', 'Ethanol', 'Exhalation', 'Expert Systems', 'Foundations', 'Funding', 'Future', 'Goals', 'Hour', 'Human', 'Influenza', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Malignant neoplasm of lung', 'Mass Fragmentography', 'Medical Device', 'Modeling', 'Monitor', 'Nasal Epithelium', 'Oxidative Stress', 'Patients', 'Pattern', 'Process', 'Production', 'Protocols documentation', 'Rapid screening', 'Reaction', 'Reagent', 'Research Project Grants', 'Role', 'SARS-CoV-2 infection', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Silicon', 'Sterilization', 'System', 'Technology', 'Test Result', 'Testing', 'Training', 'Translational Research', 'Tuberculosis', 'United States', 'United States National Institutes of Health', 'Universities', 'Vial device', 'Viral', 'Viral Respiratory Tract Infection', 'Virulent', 'Virus', 'Virus Diseases', 'adduct', 'aqueous', 'asymptomatic COVID-19', 'biosafety level 3 facility', 'bronchial epithelium', 'carbonyl compound', 'detection sensitivity', 'detector', 'experience', 'innovation', 'instrument', 'machine learning algorithm', 'metabolome', 'microchip', 'mobile computing', 'novel coronavirus', 'photoionization', 'point of care', 'portability', 'prevent', 'programs', 'prototype', 'reagent testing', 'tool', 'virology', 'volatile organic compound']",NCATS,UNIVERSITY OF LOUISVILLE,U18,2021,1026672
"Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors ABSTRACT Aura is a digital health platform that uses Epilog™, a miniature, wireless, wearable EEG sensor worn on the scalp below hairline that can record clinical and subclinical seizures. After an initial diagnosis of epilepsy, an epileptologist will use known information about patients’ seizures to guide the best scalp location to place the Epilog EEG sensor (A). EEG data is continuously transferred (B) to the Aura app on a person’s smartphone (C) using secure BluetoothTM where it communicates over WiFi (D) to the Aura cloud platform (E). Epilog EEG is analyzed for seizures and a daily digital seizure diary is shared with epileptologists (F) and pushed back to the Aura app (G). Epilog is recharged daily, and reusable for a year. Epilog is designed to be discreet, allowing for continuous use in all facets of daily life. Data are a 10 s snippet of the beginning of a focal seizure with motor impairment and intact awareness (ILAE 1A1) recorded from Epitel’s single-channel Epilog sensor placed on the left forehead. The patient was admitted for video-EEG monitoring as standard-of-care. This seizure was verified independently by three epileptologists. In Phase I, automated, machine learning-based seizure detection algorithms will be designed to first work in the Aura cloud to detect seizures in Epilog EEG, including seizures a person may not consciously know they are having (>50% of all seizures), such as while sleeping. Aura will run these algorithms developed exclusively for Epilog’s single-channel of EEG to provide a daily digital seizure diary. In Phase II, the Aura system will enter clinical validation trials for FDA clearance as an EEG-based automated home seizure detection and alerting system. Early in Phase II Aura will be commercialized as a medical device-enabled-service business model. Out-of-pocket costs for a person living with epilepsy is an average of $380/year. Armed with long-term, reproducible EEG, epileptologists will now have a more precise, quantitative record of seizure counts, enabling them to adapt patient treatment more rapidly and successfully to improve quality of life. Aura will give people living with epilepsy their lives back. Aura provides certainty where you are and when you need it. Throughout Phase II, physiological, psychological, behavioral, and environmental factors will be combined in the Aura app to collect 27,000 days of multi-modal data from 300 patients to create an unprecedented dataset of features known to precipitate seizures. These data will be used in Phase III to create a robust, wearable seizure forecasting system using artificial intelligence that combines multi-modal seizure precipitating factors, creating an hourly seizure probability. Aura will profoundly disrupt how epilepsy is managed and improve the quality of life of people living with epilepsy. This grant proposal aims to create a digital health platform that includes a wearable medical device worn on the scalp below the hairline. The system detects and counts seizures, and alerts to seizures in real time. The goal is to empower people with epilepsy to take control of their seizure monitoring and help improve the treatment of epilepsy.",Automated Seizure Detection for Home Seizure Monitoring with Epilog Sensors,10200346,U44NS121562,"['Adoption', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Auras', 'Awareness', 'Back', 'Behavioral', 'Bluetooth', 'Businesses', 'Cellular Phone', 'Clinical', 'Community Hospitals', 'Consumption', 'Cues', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Electroencephalography', 'Emergency Medicine', 'Environment', 'Environmental Risk Factor', 'Epilepsy', 'Event', 'Family', 'Financial Hardship', 'Focal Seizure', 'Forehead', 'Freedom', 'Goals', 'Gold', 'Home environment', 'Hospitals', 'Hour', 'Left', 'Life', 'Location', 'Machine Learning', 'Manuals', 'Medical Device', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Neurologic', 'Paper', 'Patient Self-Report', 'Patients', 'Periodicity', 'Persons', 'Phase', 'Physiological', 'Precipitating Factors', 'Predisposition', 'Probability', 'Process', 'Quality of life', 'Reproducibility', 'Running', 'Scalp structure', 'Screening procedure', 'Secure', 'Seizures', 'Services', 'Sleep', 'Subclinical Seizures', 'System', 'Time', 'Validation', 'Wireless Technology', 'Work', 'base', 'cloud platform', 'cost', 'design', 'diaries', 'digital', 'digital health', 'effective therapy', 'encryption', 'improved', 'machine learning algorithm', 'motor impairment', 'multimodal data', 'multimodality', 'optimal treatments', 'programs', 'psychologic', 'remote monitoring', 'sensor', 'social', 'standard of care']",NINDS,"EPITEL, INC.",U44,2021,999853
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,10162650,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'algorithm training', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual clinical trial', 'virtual patient']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2021,384396
"Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging PROJECT SUMMARY/ABSTRACT There has been significant work in creating tools that leverage computer vision algorithms to automate medical image analysis. Most of these algorithms have been developed for natural images, which are usually single static images that can be treated individually. However, medical images are usually part of a study that may include various views and orientations that are considered together with other clinical data when making a diagnosis. Three dimensional convolution neural networks (CNN) can address this issue in part when images are evenly spaced, but many medical imaging modalities such as ultrasound (US), fluoroscopy, and biopsy imaging have variable orientations and irregular spacing. Graph convolutional networks (GCN) have the potential to address this issue as they generalize the assumptions of CNNs to work on arbitrarily structured graphs. Automatic thyroid nodule detection in ultrasound (US) is one application that such a graph-based approach could have a large impact. The thyroid cancer incidence rate has tripled in the past thirty years, with an estimated cost of $18-21 billon in 2019. US is the imaging modality of choice, which consists of multiple 2D images of different locations and orientations. US readings are often vague and subjective in nature, which has resulted in a steady increase in the number of biopsies performed over the past 20 years. It is estimated that about one-third of all thyroid biopsy procedures performed in the United States are medically unnecessary, leading to the unmet need for noninvasive diagnostic tests that can reliably identify which nodules require a biopsy. The research objective of this R21 is to develop a new graph-based approach to leverage spatial information contained within imaging studies that will be combined with biomarkers and other known risk factors. Our graph model will enable more complete detection of thyroid cancer, as well as the prediction of future cancer aggression, both with spatially localized explanations. GCN features will be used to predict voxel-level cancer suspicion, thereby enabling a novel method for performing “imaging biopsy.” Finally, voxel-level suspicion maps will be aggregated into patient-level quantitative imaging biomarkers and combined with clinical data to create a multimodal nomogram for performing risk stratification. PROJECT NARRATIVE Medical image analysis plays an important role in computer aided detection and diagnosis, but usually focuses on individual images in isolation. Graph convolutional networks have the ability to utilize the relationships be- tween images in a study to aggregate information and make a more accurate evaluation. The focus of this project is to implement a graph-based approach for distinguishing indolent from aggressive thyroid cancer, thus pre- venting patients from receiving unnecessary treatment and incurring associated negative functional outcomes.",Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging,10110934,R21EB030691,"['3-Dimensional', 'Address', 'Age', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Attention', 'Biological Markers', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Diagnostic tests', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fluoroscopy', 'Functional disorder', 'Future', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'Indolent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Manuals', 'Maps', 'Medical', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Nodule', 'Nomograms', 'Pathology', 'Patient risk', 'Patients', 'Pattern', 'Physiological', 'Play', 'Probability', 'Procedures', 'Protocols documentation', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Role', 'Savings', 'Series', 'Signal Transduction', 'Structure', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Tweens', 'Ultrasonography', 'United States', 'Work', 'base', 'body system', 'cancer imaging', 'cancer risk', 'clinical imaging', 'clinically significant', 'computer aided detection', 'convolutional neural network', 'cost estimate', 'deep learning', 'detection platform', 'functional outcomes', 'image registration', 'imaging biomarker', 'imaging modality', 'imaging study', 'innovation', 'mortality', 'multimodality', 'network models', 'noninvasive diagnosis', 'novel', 'patient stratification', 'predictive modeling', 'prevent', 'quantitative imaging', 'radiologist', 'risk stratification', 'tool', 'treatment planning', 'unnecessary treatment', 'ward']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,224566
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,10150027,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2021,695400
"Portable GC detector for breath-based COVID diagnostics Project Summary/Abstract: This proposal has two major goals: 1) Define signature exhaled breath volatile organic compounds (VOCs) to diagnose SARS-CoV-2 infections, and 2) Develop a portable chemical sensing device that can capture and detect exhaled VOCs and includes machine learning algorithms for automated data processing and results interpretation. This project will bring a portable sensor forward into clinical use with the aim of supplementing COVID-19 diagnostics with a reagentless alternative. Breath testing of exhaled VOC biomarkers is a relatively new concept that has the potential to transform healthcare in the US and globally. Our overarching hypothesis is that a miniature breath analysis device can measure signatures of exhaled breath VOCs in real-time and correlate their profile to viral upper respiratory infections such as SARS-CoV-2, even asymptomatically. In Aim #1, we propose a prospective, observational study to analyze breath samples from COVID-19 positive and negative subjects, solely for the purpose of analysis through gold standard GC- MS to define breath VOC biomarkers of infection. We will recruit subjects at two local sites, the UC Davis Medical Center (Sacramento, CA) and VA Northern California Health Care System (Mather, CA), where MPI Dr. Kenyon and Co-Is Drs. Harper and Schivo have joint clinical appointments. Our group has a proven track record to conduct these types of clinical breath studies. In Aim #2, we will develop a portable breath analysis device using our novel miniature differential mobility spectrometry (DMS) detector, coupled with chip-based gas chromatography. DMS is a subset of ion mobility spectrometry and detects VOCs at ambient temperatures and pressures, making it highly appropriate for portable devices. This device would include our custom chip- based preconcentrator, which is packed with a chemical sorbent for extraction of VOCs from breath, and will compare functionality of a compact commercially available GC column to a micro-GC column chip from Deviant, a subcontractor in this work. Individual components of this device have already been developed, and under direction of MPI Prof. Davis, Chair of Mechanical and Aerospace Engineering, a team of research engineers would integrate these pieces together into a single unit. Collaborator Prof. Chuah would guide development of a custom software package for the device with machine learning and artificial intelligence capabilities for automated data processing and interpretation. The device would be placed in the hands of clinicians, who would provide feedback that engineers would immediately incorporate into the device and return to the clinicians for more testing. Under Aim #3, our team would process the GC-MS and GC-DMS data generated in this work, identifying a novel VOC profile for COVID-19 diagnostics. Aim #4 would initiate towards the end of this study to develop both a regulatory pathway & contract manufacturing plan for large scale production and deployment of the device for clinical approval. These efforts are supported by collaborator Dr. Nam Tran, Director of Clinical Pathology & Clinical Chemistry at the UC Davis Medical Center. Project Narrative: In the United States and worldwide, public health experts agree that nations must increase their capacity to test for COVID-19, yet global supplies for testing materials remain scarce. This project would lead to the development of an entirely new type of COVID-19 test, one that could diagnose infections with only a breath sample. Through this proposal, our team would develop a portable device that could identify people with COVID-19 infections by analyzing volatile organic compounds (VOCs) found in exhaled breath.",Portable GC detector for breath-based COVID diagnostics,10266337,U18TR003795,"['2019-nCoV', 'Aerospace Engineering', 'Appointment', 'Artificial Intelligence', 'Automatic Data Processing', 'Benchmarking', 'Biological Markers', 'Breath Tests', 'COVID diagnostic', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 test', 'California', 'Catalogs', 'Chemicals', 'Clinical', 'Clinical Chemistry', 'Clinical Pathology', 'Clinical Trials', 'Communities', 'Computer software', 'Consultations', 'Contact Tracing', 'Contracts', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Engineering', 'Environment', 'Exhalation', 'Feedback', 'Fingerprint', 'Flushing', 'Funding', 'Gas Chromatography', 'Gases', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Heating', 'Human Resources', 'Individual', 'Industry', 'Infection', 'Intuition', 'Joints', 'Lead', 'Liquid substance', 'Machine Learning', 'Manufacturer Name', 'Maps', 'Mass Spectrum Analysis', 'Materials Testing', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical center', 'National Institute of Biomedical Imaging and Bioengineering', 'Observational Study', 'Output', 'Pattern', 'Polymerase Chain Reaction', 'Process', 'Production', 'Public Health', 'Publishing', 'Rapid diagnostics', 'Reagent', 'Regulatory Pathway', 'Research', 'SARS-CoV-2 infection', 'SARS-CoV-2 positive', 'Sampling', 'Sensitivity and Specificity', 'Site', 'Skin', 'Spectrometry', 'Standardization', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'United States National Institutes of Health', 'Upper Respiratory Infections', 'Viral', 'Work', 'base', 'biomarker signature', 'clinical care', 'detector', 'deviant', 'differential expression', 'disease transmission', 'graphical user interface', 'instrument', 'intelligent algorithm', 'ion mobility', 'large scale production', 'machine learning algorithm', 'metabolomics', 'novel', 'novel diagnostics', 'pandemic disease', 'portability', 'pressure', 'programs', 'prospective', 'prototype', 'recruit', 'risk mitigation', 'scale up', 'sensor', 'standard of care', 'volatile organic compound']",NCATS,UNIVERSITY OF CALIFORNIA AT DAVIS,U18,2021,975463
"Optical design and the development of high accuracy automated tick classification using computer vision Abstract. The incidence of US tick-borne diseases has more than doubled in the last two decades. Due to lack of effective vaccines for tick-borne diseases, prevention of tick bites remains the primary focus of disease mitigation. Tick vector surveillance—monitoring an area to understand tick species composition, abundance, and spatial distribution—is key to providing the public with accurate and up-to-date information when they are in areas of high risk, and enabling precision vector control when necessary. Despite the importance of vector surveillance, current practices are highly resource intensive and require significant labor and time to collect and identify vector specimens. Acarologist or field taxonomist expertise is a limited resource required for tick identification, creating a significant capability barrier for national tick surveillance practice. While mobile applications to facilitate passive surveillance and reporting of human-tick encounters have grown in popularity, variable image quality, limited engagement, and scientist misidentification of rare, invasive, or morphologically similar tick species hinder the scalability of this approach. No automated solutions exist to build tick identification capacity. We seek to develop the first imaging and automated identification system capable of instantaneously and accurately identifying the top nine tick vectors in the US. This proposal will first characterize the optical requirements necessary to image diagnostic morphological features associated with adult ticks and develop a standardized imaging platform for tick identification. This will enable the development of a high-quality tick image dataset in partnership with the Walter Reed Biosystems Unit (WRBU) which will be used to train high-accuracy computer vision models for tick species and sex identification. Ultimately the approaches developed here will enable new tick identification tools for both the lab and citizen scientists; allowing vector surveillance managers to leverage image recognition in a practical system that will increase capacity and capability for biosurveillance, and equipping citizen scientists with improved tools to identify tick species during a human-tick encounter. Project Narrative. Despite the importance of tick vector surveillance for disease prevention, current practices to collect and identify specimens are resource intensive, limiting the quality and quantity of the data informing control efforts. Here we propose the determination of optical requirements for visualization of diagnostic features of the top nine US tick vectors, and the development of high-accuracy computer vision algorithms for the identification of tick species and sex for use in a standardized optical configuration. The high-accuracy tick classification system developed through this proposal promises to expand capacity and capability for tick vector surveillance.",Optical design and the development of high accuracy automated tick classification using computer vision,10325667,R43AI162425,"['Adult', 'Agreement', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Car Phone', 'Cellular Phone', 'Classification', 'Collaborations', 'Computer Vision Systems', 'Culicidae', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Disease Surveillance', 'Disease Vectors', 'Future', 'Goals', 'Grain', 'Human', 'Image', 'Incidence', 'Insecta', 'Larva', 'Learning', 'Leg', 'Life', 'Lighting', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Nymph', 'Optics', 'Phase', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Resolution', 'Resources', 'Scientist', 'Spatial Distribution', 'Specimen', 'Standardization', 'Surveillance Methods', 'System', 'Telephone', 'Testing', 'Tick-Borne Diseases', 'Ticks', 'Time', 'Training', 'Vaccines', 'Validation', 'Visual', 'Visualization', 'Work', 'base', 'citizen science', 'convolutional neural network', 'design', 'detection method', 'disorder prevention', 'field study', 'flexibility', 'high resolution imaging', 'high risk', 'human disease', 'imaging platform', 'imaging system', 'improved', 'insight', 'intelligent algorithm', 'interest', 'mobile application', 'novel', 'sample collection', 'sex', 'tick bite', 'tool', 'validation studies', 'vector', 'vector control', 'vector tick']",NIAID,"VECTECH, LLC",R43,2021,295705
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,10129965,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2021,403882
"A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment  Unhealthy diet is strongly linked to risks of chronic diseases, such as cardiovascular diseases, diabetes and certain types of cancer. The Global Burden of Disease Study has found that, among the top 17 risk factors, poor diet is overwhelmingly the No. 1 risk factor for human diseases. Despite the strong connection between diet and health, unhealthy foods with large portion sizes are widely consumed. Currently, 68.5% of U.S. adults are overweight, among the highest in developed countries. The recent decline in U.S. life expectancy sent another alarming signal about the general health of the American people. Understanding how the diet-related risk factors affect people’s health and finding effective ways to empower them in improving lifestyle habits are among the most important tasks in public health. Unfortunately, dietary assessment in real-world settings has been exceedingly complex and inaccurate to implement. Technology is needed that allows researchers to assess dietary intake easily and accurately in real world settings so that effective intervention to manage obesity and related chronic diseases can be developed. We propose a biomedical engineering project to address the dietary assessment problem, taking advantage of advanced mathematical modeling, wearable electronics and artificial intelligence.  Our research team has been improving the ability to assess diet for over a decade. We have designed the eButton, a small wearable device pinned on clothes in front of the chest, capable of collecting image-based dietary data objectively and passively (i.e., without depending on subject’s self-report or volitional operation of the device). We have also developed algorithms to compute food volumes and nutrients from images. Since the eButton was developed, it has been used by many researchers in the U.S. and other countries for objective and passive diet-intake studies in both adults and children.  Despite the past successes, there have been two lingering critical problems associated with the objective and passive dietary assessment using wearable devices: 1) substantial manual efforts are required for researchers to visually examine image data to identify foods and estimate their volumes (portion sizes), and 2) there are privacy concerns about researchers’ viewing of participants’ real-life images. Although solving these problems could enable the eButton and other wearable devices for large-scale diet-intake studies, we were not able to find effective solutions until recently when Artificial intelligence (AI) emerged. Advanced AI systems, especially those based on deep learning, can be trained by large amounts of labeled data to produce results comparable or even superior to those produced by human in numerous fields of applications. AI technology is also a powerful tool for dietary assessment, potentially providing an ideal solution to the two previously mentioned problems. We thus propose to develop a human-mimetic AI system to recognize foods from images, estimate portion sizes, and find energy and nutrient values from a database in a fully automatic process. Using the AI approach, there will be no need for researchers to view participants’ real-life images, and the AI system well-respects individuals’ privacy because it is trained to recognizes human foods only, nothing else.  Currently, the performances of existing AI systems are limited by the extensive variety and high variability of human foods, insufficient training data, and difficulty in finding appropriate nutritional information from food databases. In this application, we propose a new strategy to personalize the AI system for each research participant using an advanced mathematical model of personal food choices. With this personalization step, the dimensionality of our envisioned AI system can be reduced drastically, and our goal of automatic, objective and passive dietary assessment can be reached realistically. We also propose to improve the electronic hardware and develop a biomimetic camera to enlarge the field of view for the eButton. Finally, we will conduct a thorough evaluation of the personalized AI system in real-world settings using human subjects. This research aims to apply advanced mathematical modeling, wearable electronics and artificial intelligence to evaluate individual’s energy and nutrient intake automatically and objectively.","A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment",10111099,R01DK127310,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'American', 'Artificial Intelligence', 'Biomedical Engineering', 'Biomimetics', 'Cardiovascular Diseases', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Chest', 'Child', 'Chronic Disease', 'Complex', 'Consumption', 'Country', 'Data', 'Databases', 'Developed Countries', 'Devices', 'Diabetes Mellitus', 'Diet', 'Dietary Assessment', 'Dietary intake', 'Dietetics', 'Dimensions', 'Eating', 'Evaluation', 'Expert Systems', 'Eye', 'Feedback', 'Food', 'Food Energy', 'Future', 'Goals', 'Gold', 'Habits', 'Health', 'Health care facility', 'Healthcare', 'Heart Diseases', 'Human', 'Image', 'Individual', 'Intake', 'Label', 'Life', 'Life Expectancy', 'Life Style', 'Link', 'Malignant Neoplasms', 'Manuals', 'Modeling', 'Nutrient', 'Nutritional', 'Nutritional Science', 'Obesity', 'Output', 'Participant', 'Patient Self-Report', 'Performance', 'Persons', 'Play', 'Privacy', 'Problem Solving', 'Process', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Shapes', 'Signal Transduction', 'System', 'Technology', 'Training', 'Unhealthy Diet', 'Update', 'Volition', 'base', 'burden of illness', 'cancer type', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'dietary', 'effective intervention', 'field study', 'good diet', 'human disease', 'human subject', 'improved', 'infancy', 'intelligent algorithm', 'mathematical model', 'mimetics', 'neural network', 'obesity management', 'operation', 'overweight adults', 'robotic system', 'success', 'tool', 'validation studies', 'wearable device']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,657303
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9841303,R01DC014498,"['3-Dimensional', 'Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deaf', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'machine learning algorithm', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,317844
"Improving Virtual Gross Anatomy: Enhancing the Information Content of Cadaveric CT Scans Project Summary The long-term goal of this research is to establish a pipeline for automated image processing that enhances cadaveric non-contrast enhanced (NCE) CT data and extracts meaningful models and metrics to improve anatomy research and education. The objective is to develop the necessary toolset for this image processing, and feature extraction. The central hypothesis is that it is possible to enrich the information content of biomedical imaging data, particularly that of cadaveric NCE CT imaging, for use in gross anatomy education and research. The rationale behind this project is that cadaveric dissection, while an important part of anatomy education, is limited due to sample size, infrastructure, cost, and time. Biomedical imaging can preserve specimens for posterity and be used to supplement this material by providing statistical and quantitative information from anatomical structures. This research will attempt to establish a working pipeline for efficient information extraction through the following specific aims: (1) Improving inter-observer anatomical agreement in cadaveric CT scans; (2) Develop an approach to automatically segment anatomical structures from non-contrast enhanced CT images; and (3) Establish normal variation of anatomical structures and its relationship to pathologies. This project is innovative because it applies artificial intelligence to efficiently extract anatomical information from cadaveric NCE CT imaging, which has only been performed with traditional registration- dependent methods that often fail and are domain specific, acting on a single organ at a time. In addition, this project works with multi-species data to enhance human image data.  This project is significant because it will allow students to understand anatomical variation better by both expanding student exposure to more samples, while also extracting useful representations and analytics from these samples for education and research. The expected outcome of this project is a toolset that is capable of enhancing anatomy education and research by increasing soft-tissue contrast, automatically segmenting the kidneys, liver, mandible, and intraosseus sites of the cranial nerves, and performing statistical analysis on these organs, including but not limited to statistical shape modelling and shape analysis. This will have a positive impact on anatomical education and student retention because it will provide students with a broader range of sample variability information which will decrease pervading biases in medical training that result from small, limited sample sizes, and improve medical training. Project Narrative Dissection is a critical component of anatomy education but is limited due to the infrastructure required by the institution, the amount of variability in the available specimens, and the limited number of specimens available within the course. Biomedical imaging and analysis can be used to supplement dissection, allowing for an expansion in the number of anatomical specimens that students can observe and the amount of clinically relevant material that is available to students to improve their understanding of pathology and variation. This will expand student exposure to anatomical variation, produce more proficient medical professionals, and improve anatomy research.",Improving Virtual Gross Anatomy: Enhancing the Information Content of Cadaveric CT Scans,10141430,F31EB030904,"['3-Dimensional', 'Address', 'Agreement', 'Anatomic Models', 'Anatomy', 'Artificial Intelligence', 'Blood coagulation', 'Buffaloes', 'Cadaver', 'Characteristics', 'Clinical', 'Computer Models', 'Contrast Media', 'Coupled', 'Cranial Nerves', 'Data', 'Development', 'Diagnostic', 'Disease', 'Dissection', 'Education', 'Exposure to', 'Gifts', 'Goals', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Individual', 'Information Retrieval', 'Infrastructure', 'Institution', 'Kidney', 'Lead', 'Libraries', 'Liver', 'Machine Learning', 'Mandible', 'Manuals', 'Medical', 'Medical Students', 'Methods', 'Modeling', 'Modernization', 'Morphology', 'Nature', 'Noise', 'Organ', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Population', 'Preservation Technique', 'Process', 'Reading', 'Research', 'Research Personnel', 'Sample Size', 'Sampling', 'Scanning', 'Shapes', 'Signal Transduction', 'Site', 'Specimen', 'Statistical Data Interpretation', 'Structure', 'Students', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Variant', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'bioimaging', 'clinically relevant', 'cohort', 'contrast enhanced', 'cost', 'deep learning', 'demographics', 'education research', 'feature extraction', 'human imaging', 'image processing', 'image registration', 'improved', 'innovation', 'interest', 'non-invasive imaging', 'posters', 'preservation', 'programs', 'quantitative imaging', 'retention rate', 'segmentation algorithm', 'shape analysis', 'soft tissue', 'success', 'virtual']",NIBIB,STATE UNIVERSITY OF NEW YORK AT BUFFALO,F31,2021,30805
"Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions Project Summary Fluoroscopy guidance using C-arm X-ray systems is used in more than 17 million procedures across the US and constitutes the state-of-care for various percutaneous procedures, including internal ﬁxation of pelvic ring injuries. To infer procedural progress from 2D radiographs, well-deﬁned views onto anatomy must be achieved and restored multiple times during surgery. This process, known as ”ﬂuoro hunting”, is associated with 4.7 s of excessive ﬂuoroscopy time per C-arm position (c. f. 120 s total per ﬁxation), yielding radiographs that are never interpreted clinically, but drastically increasing procedure time and radiation dose to patient and surgical staff.  Our long-term project goal is to use concepts from machine learning and active vision to develop task-aware algorithms for autonomous robotic C-arm servoing that interpret intra-operative radiographs and autonomously adjust the C-arm pose to acquire ﬂuoroscopic images that are optimal for inference. We have three speciﬁc aims: 1) Detecting unfavorable K-wire trajectories from monoplane ﬂuoroscopy images: We will extend a physics-based sim- ulation framework for ﬂuoroscopy from CT that enables fast generation of structured and realistic radiographs documenting procedural progress. Based on this data, we will train a state-of-the-art convolutional neural net- work that interprets ﬂuoroscopic images to infer procedural progress. 2) Developing and validating a task-aware imaging system in silico: Using the autonomous interpretation tools and simulation pipeline available through Aim 1, we will train an artiﬁcial agent based on reinforcement learning and active vision. This agent will be capable of analyzing intra-operative ﬂuoroscopic images to autonomously adjust the C-arm pose to yield task- optimal views onto anatomy. 3) Demonstrating feasibility of our task-aware imaging concept ex vivo: Our third aim will establish task-aware C-arm imaging in controlled clinical environments. We will attempt internal ﬁxation of anterior pelvic ring fractures and our task-aware artiﬁcial agent will interpret intra-operatively acquired ra- diographs to infer procedural progress and suggest optimal C-arm poses that will be realized manually with an optically-tracked mobile C-arm system.  This work combines the expertise of a computer scientist, a surgical robotics expert, and an orthopedic trauma surgeon to explore the untapped, understudied area of autonomous imaging enabled by advances in machine learning in ﬂuoroscopy-guided procedures. This development has only recently been made feasible by innovations in fast ﬂuoroscopy simulation from CT to provide structured data for training that is sufﬁciently realistic to warrant generalization to clinical data. With support from the NIH Trailblazer Award, our team will be the ﬁrst to investigate autonomous and task-aware C-arm imaging systems, paving the way for a new paradigm in medical image acquisition, which will directly beneﬁt millions of patients by task-oriented image acquisition on a patient-speciﬁc basis. Subsequent R01 funding will customize this concept to other high-volume procedures, such as vertebroplasty. Project Narrative Fluoroscopy guidance using C-arm X-ray systems is the state-of-care for percutaneous fracture ﬁxation, and requires surgeons to achieve and reproduce well deﬁned views onto anatomy to infer procedural progress. This requirement alone is estimated to contribute 4.7 s of ﬂuoroscopy time per C-arm repositioning (c. f. 120 s total per ﬁxation), drastically increasing procedure time and radiation dose to patient and surgical team. The goal of this project is to develop machine learning-based C-arm servoing algorithms that introduce task awareness by interpreting intra-operative radiographs and autonomously adjusting the C-arm pose to task-optimal views.",Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions,10143238,R21EB028505,"['3-Dimensional', 'Age-Years', 'Algorithms', 'Anatomy', 'Anterior', 'Area', 'Artificial Intelligence', 'Assessment tool', 'Automobile Driving', 'Award', 'Awareness', 'Back', 'Bladder', 'Cadaver', 'Caring', 'Clinical', 'Clinical Data', 'Compression Fracture', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Environment', 'Exhibits', 'Expert Systems', 'Fluoroscopy', 'Fracture', 'Fracture Fixation', 'Funding', 'Generations', 'Goals', 'Image', 'Incidence', 'Injury', 'Intervention', 'Label', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Modality', 'Modernization', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Patients', 'Pelvis', 'Physics', 'Population', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Psychological reinforcement', 'Radiation Dose Unit', 'Risk', 'Robotics', 'Roentgen Rays', 'Scientist', 'Specimen', 'Structure', 'Surgeon', 'System', 'Testing', 'Time', 'Training', 'Trauma', 'United States', 'United States National Institutes of Health', 'Variant', 'Vertebral column', 'Width', 'Work', 'active vision', 'adverse outcome', 'algorithm training', 'arm', 'base', 'bone', 'convolutional neural network', 'deep learning algorithm', 'deep reinforcement learning', 'femoral artery', 'imaging modality', 'imaging system', 'improved outcome', 'in silico', 'innovation', 'learning algorithm', 'mortality', 'multitask', 'novel strategies', 'pre-clinical', 'sample fixation', 'simulation', 'spine bone structure', 'structured data', 'success', 'tool', 'trauma surgery']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2021,197201
"Quantitative MR Imaging of Vascular Factors in Parkinsons Disease Abstract Vascular health has been shown to be an important factor in the development of neurodegenerative diseases like Alzheimer’s and Parkinson’s diseases. Hence, the ability to measure reliably and quantitatively early hemodynamic changes in the aging brain can be a powerful tool for diagnosing, studying, and developing treatments. Arterial Spin Labeling (ASL) magnetic resonance imaging can yield quantitative perfusion images without the use of contrast agents. We propose that combining new ASL techniques, such as Velocity Selective Inversion (VSI) labeling pulses and magnetic resonance fingerprinting (MRF) with deep learning regression methods will allow quantification of multiple hemodynamic parameters beyond perfusion, thus providing a much more nuanced picture of the state of the vasculature. We also expect that the new technique will offer dramatic improvements in SNR, specificity and sensitivity of ASL, and that the proposed techniques will have many other applications in research and in the clinic. We propose to use these techniques to fill the knowledge gap regarding the relationship between vascular changes and Parkinson’s disease and its symptoms, particularly fatigue, whose pathogenesis is not well understood. If we are successful in this application, future work will use the hemodynamic parameters of interest as biomarkers to assess risk of neurodegeneration, determine therapeutic targets, and guide in the development of new therapies. Public Health Statement Vascular health is an important factor in the development of neurodegenerative diseases like Alzheimer’s and Parkinson’s diseases We propose to develop a method that can produce quantifiable images of multiple blood flow related parameters with a single scan and without the use of contrast injections. We will use this method to gain a better understanding of the relationship between Parkinson’s disease and cerebral blood flow, and expect that our method will have multiple applications beside Parkinson’s disease.",Quantitative MR Imaging of Vascular Factors in Parkinsons Disease,10266020,R01NS112233,"['Address', 'Agreement', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Arteries', 'Biological', 'Biological Markers', 'Blood Vessels', 'Blood Volume', 'Blood flow', 'Bolus Infusion', 'Brain', 'Cerebrovascular Circulation', 'Classification', 'Clinic', 'Clinical', 'Contrast Media', 'Development', 'Diagnosis', 'Disease', 'Ensure', 'Etiology', 'Fatigue', 'Fingerprint', 'Future', 'Health', 'Human Volunteers', 'Hybrids', 'Image', 'Injections', 'Knowledge', 'Label', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Movement', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuronal Injury', 'Noise', 'Parkinson Disease', 'Pathogenesis', 'Pathologic', 'Patients', 'Perfusion', 'Physiologic pulse', 'Public Health', 'Reproducibility', 'Research', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Spatial Distribution', 'Spin Labels', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Validation', 'Weight', 'Work', 'aging brain', 'deep learning', 'feeding', 'hemodynamics', 'imaging biomarker', 'insight', 'interest', 'machine learning algorithm', 'neural network', 'non-invasive imaging', 'novel therapeutics', 'patient stratification', 'perfusion imaging', 'relating to nervous system', 'success', 'support vector machine', 'therapeutic target', 'tool', 'vascular factor', 'vector', 'white matter']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,281031
"Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit SUMMARY  Many of the estimated four million adults in the U.S. with severe speech and physical impairments (SSPI) resulting from neurodevelopmental or neurodegenerative diseases cannot rely on current assistive technologies (AT) for communication. During a single day, or as their disease progresses, they may transition from one access technology to another due to fatigue, medications, changing physical status, or progressive motor dysfunction. There are currently no clinical or AT solutions that adapt to the multiple, dynamic access needs of these individuals, leaving many people poorly served. This competitive renewal, called BCI-FIT (Brain Computer Interface-Functional Implementation Toolkit) adds to our innovative multidisciplinary translational research conducted over the past 11 years for the advancement of science related to non-invasive BCIs for communication for these clinical populations. BCI-FIT relies on active inference and transfer learning to customize a completely adaptive intent estimation classifier to each user's multiple modality signals in real-time. The BCI-FIT acronym has many implications: our BCI fits to each user's brain signals; to the environment, offering relevant personal language; to the user's internal states, adjusting signals based on drowsiness, medications, physical and cognitive abilities; and to users' learning patterns from BCI introduction to expert use.  Three specific aims are proposed: (1) Develop and evaluate methods for optimizing system and user performance with on-line, robust adaptation of multi-modal signal models. (2) Develop and evaluate methods for efficient user intent inference through active querying. (3) Integrate language interaction and letter/word supplementation as input modalities in real-time BCI use. Four single case experimental research designs will evaluate both user performance and technology performance for functional communication with 35 participants with SSPI in the community, and 30 healthy controls for preliminary testing. The same dependent variables will be tested in all experiments: typing accuracy (correct character selections divided by total character selections), information transfer rate (ITR), typing speed (correct characters/minute), and user experience (UX) questionnaire responses about comfort, workload, and satisfaction. Our goal is to establish individualized recommendations for each user based on a combination of clinical and machine expertise. The clinical expertise plus user feedback added to active sensor fusion and reinforcement learning for intent inference will produce optimized multi-modal BCIs for each end-user that can adjust to short- and long-term fluctuating function. Our research is conducted by four sub-teams who have collaborated successfully to implement translational science: Electrical/computer engineering; Neurophysiology and systems science; Natural language processing; and Clinical rehabilitation. The project is grounded in solid machine learning approaches with models of participatory action research and AAC participation. This project will improve technologies and BCI technical capabilities, demonstrate BCI implementation paradigms and clinical guidelines for people with severe disabilities. PROJECT NARRATIVE The populations of US citizens with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies, as proposed in BCI-FIT. This project implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit,10213005,R01DC009834,"['Adult', 'Attention', 'Behavioral', 'Brain', 'Calibration', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communication', 'Communities', 'Computers', 'Custom', 'Data', 'Decision Making', 'Disease', 'Drowsiness', 'Electroencephalography', 'Engineering', 'Environment', 'Eye Movements', 'Fatigue', 'Feedback', 'Goals', 'Guidelines', 'Head Movements', 'Impairment', 'Individual', 'Informed Consent', 'Knowledge', 'Language', 'Learning', 'Letters', 'Life', 'Locked-In Syndrome', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Motor Skills', 'Movement', 'Muscle', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Participant', 'Partner Communications', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Population', 'Protocols documentation', 'Psychological Transfer', 'Psychological reinforcement', 'Public Health', 'Questionnaires', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Design', 'Role', 'Science', 'Secondary to', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Solid', 'Source', 'Speech', 'Speed', 'Supplementation', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vocabulary', 'Workload', 'acronyms', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinical implementation', 'cognitive ability', 'community based participatory research', 'computer science', 'disability', 'experience', 'experimental study', 'improved', 'innovation', 'learning strategy', 'motor disorder', 'multidisciplinary', 'multimodality', 'neurophysiology', 'phrases', 'residence', 'response', 'satisfaction', 'sensor', 'signal processing', 'simulation', 'spelling', 'theories', 'visual tracking']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,915264
"Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis Project Summary Blood culture sensitivity in neonates is poor but is the “Gold Standard” for the diagnosis of sepsis. Universal genotyping of pathogen genomic sequences using High Resolution Melt (U-HRM) provides a simple, low cost, rapid, and modern alternative to blood culture testing. By measuring the fluorescence of an intercalating dye as PCR-amplified pathogen DNA fragments are heated and disassociate, sequence defined melt curves are generated with single-nucleotide resolution in a closed-tube reaction. We have advanced U- HRM into a digital PCR format (U-dHRM), where DNA sequences that are present in mixtures are individually amplified and identified as is needed for polymicrobial infections. We have also established unique signature melt curves for 37 bacterial species that commonly infect older children and adults and automatically identify them using machine learning technology. With the goal of creating an accurate and valid test for the timely diagnosis of neonatal sepsis, we will advance this technology to identify unique fungal, viral, and bacterial HRM signatures along with antibiotic resistance genes with an accuracy of 99-100% on minimal blood volume (1mL). Our aims are: Aim 1. Optimize and assess the U-dHRM platform for neonatal bacteremia diagnosis by expand our bacterial database (13 additional bacteria) to detect causes of >99% of neonatal bacterial infections, expand our antibiotic resistance gene database to include five clinically actionable genes, and assessing the performance of the system for bacteremia diagnosis in mock and clinical whole blood samples; Aim 2. Advance the U-dHRM platform for simultaneous detection of fungal and viral pathogens by upgrading our optical system to enable expansion to fungal and viral detection in a high-throughput format, multiplexing the assay to expand to viral and fungal pathogens causing >99% non-bacterial infections, and conducting analytical validation of the multiplexed platform using mock whole blood samples; and Aim 3. Advance the machine learning algorithm for detection of emerging pathogens by developing and integrating an anomaly detection algorithm for reporting emerging pathogens that are not included in our database and validating the algorithm using data generated in Aims 1 and 2. Thus, this proposal directly addresses the funding call by applying a multidisciplinary approach to overcome the biomedical challenge of rapidly diagnosis sepsis, a hidden public health disaster. Project Narrative Digital High Resolution Melting (dHRM) of DNA combined with machine learning creates unique “fingerprints"" for microbes and antibiotic resistance, allowing for faster and more precise detection and treatment of pathogen(s) causing sepsis. This project will advance and test the clinical performance of dHRM technology in the diagnosis of neonatal sepsis. Our goal is to rapidly and accurately identify pathogens and their resistance markers to facilitate accurate antimicrobial therapy, reducing antibiotic overuse in non-infected infants.",Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis,10151581,R01AI134982,"['Address', 'Adult', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Biological Assay', 'Birth Weight', 'Blood', 'Blood Volume', 'Blood specimen', 'Child', 'Clinical', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disasters', 'Dyes', 'Emerging Technologies', 'Exposure to', 'Fingerprint', 'Fluorescence', 'Funding', 'Genes', 'Genome', 'Genotype', 'Goals', 'Gold', 'Hour', 'Immune response', 'Individual', 'Infection', 'Machine Learning', 'Measures', 'Microbe', 'Modernization', 'Neonatal', 'Nucleotides', 'Optics', 'Organism', 'Patients', 'Performance', 'Predisposition', 'Public Health', 'RNA', 'Reaction', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Sampling', 'Sepsis', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tube', 'United States', 'Validation', 'Variant', 'Very Low Birth Weight Infant', 'Viral', 'Whole Blood', 'Woman', 'antimicrobial', 'base', 'circulating DNA', 'clinically actionable', 'clinically relevant', 'cost', 'detection limit', 'diagnosis standard', 'digital', 'early onset', 'interdisciplinary approach', 'intrapartum', 'machine learning algorithm', 'melting', 'microbial', 'neonatal sepsis', 'neonate', 'overtreatment', 'pathogen', 'pathogen genome', 'pathogen genomics', 'pathogenic fungus', 'pathogenic virus', 'point of care', 'premature', 'rapid diagnosis', 'resistance gene', 'sample collection', 'septic', 'therapy resistant', 'viral detection']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,469594
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,10150910,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction', 'risk prediction model', 'risk stratification', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2021,984177
"Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques PROJECT SUMMARY Symptomatic urinary stone disease (USD) affects >8% of the United States population, resulting in an estimated annual medical cost exceeding $10 billion. Computed tomography (CT) is the established method for imaging urinary calculi and can provide accurate sub-millimeter details of the size and location of renal stones. However, in vivo characterization of more than just size and location is critical for quantifying stone characteristics important for optimal patient health management and essential for clinical research. A complete characterization of renal stones, including stone composition and fragility, is needed for safe and cost effective management of USD, as well as for phenotyping of research subjects. Our proposal meets these needs by developing methods to accurately and non-invasively characterize stones using low-dose, multi-energy CT. Our long-term goal is to use advanced CT methodologies to characterize urinary calculi for the purpose of directing clinical treatment and facilitating clinical investigation. Our objectives in this application are to develop and validate in vivo quantitative techniques for characterizing mixed and non-uric-acid stone types, as well as for predicting the likelihood of successful stone comminution, a novel concept we refer to as stone fragility. These image-based stone biometrics will enable evidence-based identification of treatment strategies that maximize effectiveness while minimizing risk, as well as accurate and non-invasive classification of research subjects to accelerate scientific advances in the understanding and treatment of USD. We will meet these objectives by accomplishing the following specific aims:  Specific Aim 1: Develop and validate CT techniques to characterize mixed and non-uric-acid  stone types.  Specific Aim 2: Develop and validate CT techniques to predict stone fragility. Current state-of-the-art stone imaging technology cannot accurately identify the composition of mixed and non- uric-acid stone types, nor can it provide quantitative indications of the likelihood of efficient comminution using the lowest risk technique. The innovation of this proposal lies in the use of newly developed statistical, deep learning and texture analysis techniques to quantitatively describe essential characteristics of urinary calculi, namely composition and fragility. The significance of this proposal is that the knowledge derived from using such techniques represents unique quantitative biomarkers that will allow physicians and researchers to more effectively manage and study USD. The developed methods respond to critical needs in the field of stone disease and will advance the ability of physicians to optimally direct patient therapy and scientists to phenotype research subjects. PROJECT NARRATIVE This proposal will develop imaging techniques that can determine urinary stone composition and fragility in patients. The significance of this is that these advanced CT imaging techniques will allow physicians to more efficiently direct patient therapy and perform clinical research, potentially avoiding procedures associated with higher risk or cost.","Quantitative, non-invasive characterization of urinary stone composition and fragility using multi-energy CT and machine learning techniques",10129958,R01EB028591,"['Affect', 'Alkalies', 'Bilateral', 'Biological Markers', 'Biometry', 'Calcium Oxalate', 'Characteristics', 'Classification', 'Clinical Research', 'Clinical Treatment', 'Cost Effective Management', 'Coupled', 'Data', 'Disease', 'Dose', 'Economic Burden', 'Effectiveness', 'Excision', 'Future', 'Generations', 'Goals', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury to Kidney', 'Kidney Calculi', 'Knowledge', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Minerals', 'Morphology', 'Outcome', 'Patients', 'Percutaneous Nephrolithotomy', 'Phenotype', 'Physicians', 'Population', 'Prevalence', 'Procedures', 'Publishing', 'Recovery', 'Research', 'Research Personnel', 'Research Subjects', 'Resolution', 'Risk', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Shapes', 'Source', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'United States', 'Ureteroscopy', 'Uric Acid', 'Urinary Calculi', 'Validation', 'X-Ray Computed Tomography', 'attenuation', 'base', 'calcium phosphate', 'clinical investigation', 'cost', 'deep learning', 'evidence base', 'health management', 'high risk', 'imaging modality', 'in vivo', 'innovation', 'learning strategy', 'novel', 'photon-counting detector', 'prevent', 'risk minimization', 'statistical learning', 'treatment strategy']",NIBIB,MAYO CLINIC ROCHESTER,R01,2021,350335
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,10316448,R00EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'archetypal analysis', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'machine learning method', 'mathematical model', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,R00,2021,247154
"Automating mosquito microdissection for a malaria PfSPZ vaccine ABSTRACT Despite annual investments of >$3 billion for intensive control measures, in 2018, the 228 million cases of malaria were an increase of ~16 million cases over 2015, and no decrease in number of deaths. The impact of available malaria control measure has plateaued. Moreover, WHO estimates deaths from malaria could double across sub-Saharan Africa this year due to disruptions in access to control measures due to the current global COVID-19 pandemic malaria. New tools, especially a vaccine, are needed. Only broad deployment of an effective vaccine holds the promise of true elimination or eradication, especially in the face of sudden developments like COVID-19. More than 98% of all deaths from malaria are caused by Plasmodium falciparum (Pf). Thus, a vaccine against Pf malaria is the priority. Sanaria is moving in 2021 to Phase 3 clinical trials of its Pf sporozoite (SPZ), PfSPZ Vaccine, and is planning for marketing authorization (licensure) from FDA and EMA in 2022/2023. Over the next 5-10 years we aim to decrease the cost of goods (COGs) and efficiency of production of PfSPZ vaccines so they can be used most effectively and economically by individuals who suffer the most from malaria. Microdissection of mosquitoes is a crucial step in extraction of PfSPZ vaccine products, and ensures a 10,000-fold purification away from irrelevant mosquito parts as the starting material for downstream purification procedures that then achieve a final product purity of 99.9%. To-date, mosquito salivary gland PfSPZ have demonstrated in vivo infectivity/potency superior to those extracted from whole mosquitoes, or grown outside a mosquito. However, extraction of mosquito salivary glands is a rate-limiting, labor-intensive, expensive step in production of PfSPZ-based vaccines. The overarching aim of this proposal is to enable implementation of an interim semi-automated dissection device in cGMP production of PfSPZ-based vaccines against malaria, and develop an integrated dissection system incorporating multiple automation steps downstream of mosquito orientation, for commercial-scale manufacturing. The unique application of robotic technology, state-of-the art computer vision and machine learning algorithms, and software systems to production-scale processing of very small insects in cleanrooms not only advances manufacturing capabilities, but also represents a spectrum of milestone innovations in automation. Success in this project involving a highly-skilled multi-disciplinary team of investigators, manufacturing and quality experts will decidedly lead to further streamlining and process optimization during the key step of isolating mosquito salivary glands for manufacture of our highly effective PfSPZ-based vaccines. The breakthroughs that initially defined a vaccine that is far superior to competing technologies in both safety and protective efficacy, will continue, as we advance in the proposed studies to make vaccine extraction more cost-effective due to greater efficiencies, mitigation of human error and operator fatigue, reduced timeframes, greatly reduced training periods, and increased product purity, towards deployment of a highly-impactful tool in the fight against malaria. Malaria claims upwards of 600,000 human lives each year, with more than 1,000 children succumbing every day. Sanaria’s Plasmodium falciparum (Pf) sporozoite (SPZ)-based vaccines against malaria have demonstrated outstanding safety and efficacy in numerous clinical trials. The manufacturing procedure for PfSPZ-based crucially involves a currently labor-intensive process of mosquito salivary gland extraction entirely by manual dissection. Our aim in this proposal is to first introduce an interim semi-automated dissection fixture for this process. In parallel efforts, incorporating automation in key steps of mosquito decapitation, and extraction of glands will lead to greater efficiencies, reduce timeframes, greatly reduce training times, mitigate human error and operator fatigue while maintaining product purity and quality that is thought to underlie an incredible safety record of Sanaria’s PfSPZ vaccines. These outcomes will accelerate Sanaria’s march to licensure and production of commercial-scale volumes required to meet demand for post-licensure distribution to populations with greatest need, world- wide.",Automating mosquito microdissection for a malaria PfSPZ vaccine,10258416,R44AI134500,"['Africa South of the Sahara', 'Authorization documentation', 'Automation', 'Body part', 'COVID-19', 'COVID-19 pandemic', 'Cessation of life', 'Characteristics', 'Chest', 'Child', 'Clinical Trials', 'Collection', 'Comb animal structure', 'Computer Vision Systems', 'Culicidae', 'Cyclic GMP', 'Decapitation', 'Development', 'Devices', 'Dissection', 'Ensure', 'Environment', 'Equipment', 'Falciparum Malaria', 'Fatigue', 'Feasibility Studies', 'Geometry', 'Gland', 'Goals', 'Head', 'Hour', 'Human', 'Human Resources', 'Individual', 'Injections', 'Insecta', 'Investments', 'Lead', 'Licensure', 'Malaria', 'Malaria Vaccines', 'Manuals', 'Marketing', 'Measures', 'Methodology', 'Methods', 'Microdissection', 'Microscope', 'Modeling', 'Modification', 'Molds', 'Needles', 'Outcome', 'Output', 'Phase', 'Phase III Clinical Trials', 'Plasmodium falciparum', 'Plasmodium falciparum vaccine', 'Population', 'Procedures', 'Process', 'Production', 'Research Personnel', 'Robotics', 'Running', 'Safety', 'Salivary Glands', 'Scheme', 'Sporozoites', 'Stainless Steel', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Vaccines', 'Vision', 'base', 'cGMP production', 'commercialization', 'cost', 'cost effective', 'design', 'experience', 'feeding', 'fight against', 'human error', 'improved', 'in vivo', 'innovation', 'insight', 'machine learning algorithm', 'manufacturing scale-up', 'multidisciplinary', 'operation', 'process optimization', 'protective efficacy', 'prototype', 'robotic system', 'software systems', 'success', 'tool']",NIAID,"SANARIA, INC.",R44,2021,1000000
"Deformable motion compensation for 3D image-guided interventional radiology PROJECT SUMMARY / ABSTRACT C-arm cone-beam CT (CBCT) plays an increasing role in guidance of interventional radiology (IR) procedures in the abdo- men, with special emphasis in embolization procedures, such as transarterial chemoembolization (TACE) for treatment of hepatocellular carcinoma (HCC) or transarterial embolization (TAE) for control of internal hemorrhage. However, relatively long scan time of CBCT results in artifacts arising from organ motion (respiratory and cardiac motion and peristalsis). This poses a significant challenge to guidance in interventional radiology: for example, motion artifacts were found to render up to 25% of CBCT images un-interpretable in image-guided TACE, and 18% in CBCT-guided emergency TAE. The impact of motion is most significant in cases of single or isolated lesions treated with selective embolization that requires visual- ization of very small vascular structures. Existing motion correction methods often invoke assumption of periodicity, lim- iting their applicability outside of cardiac and respiratory motions, or rely on fiducial tracking or gated acquisition that disrupt IR workflow and/or increase radiation dose. Therefore, the application of CBCT in image-guided interventional procedures in the abdomen would significantly benefit from new methods that estimate complex deformable motion directly from image data. “Autofocus” techniques based on maximization of a regularized image sharpness criterion were shown to yield effective patient motion compensation in extremity, head and cardiac CBCT. However, current applications of such methods are limited to rigid motions. We hypothesize that deformable organ motion compensation in interven- tional soft-tissue CBCT can be achieved with advanced autofocus techniques using multiple locally rigid regions of in- terest, preconditioned with basic motion characteristics obtained through a machine learning decision framework. The following aims will be pursued: 1) Develop a joint multi-region autofocus optimization method to compensate deforma- ble organ motion. This includes incorporation into a comprehensive artifacts correction and image reconstruction pipe- line, design of multi-stage optimization schedules for convergence acceleration, and performance evaluation in deforma- ble phantoms, and cadaver and animal experiments. 2) Develop a decision framework for preconditioning of the motion compensation method through a combination of projection-based approaches for physiological signal estimations (res- piratory cycle) and a multi-input, multi-branch, deep learning architecture trained on extremely realistic simulated data that will estimate basic properties of motion (spatial distribution of amplitude, direction, and frequency) from an initial motion-contaminated image and its associated raw projection data. 3) Evaluate deformable motion compensation in animal experiments and in a clinical study in 50 cases of CBCT-guided TACE and assess image quality via expert observer evaluation of satisfaction and utility. The proposed work will yield a robust, practical method for compensation of deform- able soft-tissue motion in CBCT, removing a critical impediment to 3D guidance in IR. The deformable autofocus frame- work will be applicable to other interventions in which soft-tissue motion diminishes CBCT guidance, such as image-guided radiation therapy. PROJECT NARRATIVE Interventional Cone Beam CT (CBCT) provides critical 3D information to guide minimally-invasive procedures in the abdomen, but CBCT image quality is often compromised by organ deformation due to breathing, cardiac, and peristaltic motions. We propose a novel framework to mitigate the effects of this complex deformable motion using only the CBCT image data, without a need for gating, external trackers, or fiducial markers. This algorithm will remove a major impediment to 3D guidance in procedures such as transcatheter embolization procedures in the abdomen.",Deformable motion compensation for 3D image-guided interventional radiology,10100337,R01EB030547,"['3-Dimensional', 'Abdomen', 'Acceleration', 'Affect', 'Algorithms', 'Angiography', 'Animal Experiments', 'Animals', 'Architecture', 'Arterial Embolization', 'Arteries', 'Blood Vessels', 'Breathing', 'Cadaver', 'Cardiac', 'Characteristics', 'Chemoembolization', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Emergency Situation', 'Evaluation', 'Exhibits', 'Family suidae', 'Financial compensation', 'Fluoroscopy', 'Frequencies', 'Head', 'Hemorrhage', 'Image', 'Intervention', 'Interventional radiology', 'Joints', 'Learning', 'Lesion', 'Limb structure', 'Liver', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Motion', 'Organ', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Periodicity', 'Peristalsis', 'Physiological', 'Play', 'Primary carcinoma of the liver cells', 'Procedures', 'Property', 'Prostate Ablation', 'Radiation Dose Unit', 'Recurrence', 'Reporting', 'Residual state', 'Role', 'Scanning', 'Schedule', 'Signal Transduction', 'Spatial Distribution', 'Structure', 'Techniques', 'Testing', 'Therapeutic Embolization', 'Three-Dimensional Image', 'Time', 'Training', 'Validation', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'arm', 'base', 'clinical application', 'cone-beam computed tomography', 'convolutional neural network', 'deep learning', 'design', 'experimental study', 'feeding', 'heart motion', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'image reconstruction', 'imaging modality', 'improved', 'internal control', 'minimally invasive', 'novel', 'preconditioning', 'radiologist', 'respiratory', 'satisfaction', 'simulation', 'soft tissue', 'standard care', 'tumor']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2021,368438
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,10128374,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2021,77243
"Focal nerve fiber layer reflectance analysis for glaucoma evaluation PROJECT SUMMARY Glaucoma is a leading cause of blindness, and effective glaucoma management requires early detection. Nerve fiber layer (NFL) thickness measurement by optical coherence tomography (OCT) is useful for confirming the diagnosis of glaucoma, but its diagnostic sensitivity is not sufficient to be used alone for population-based screening.  NFL reflectivity is reduced in glaucoma subjects, presumably due to loss of axons and axonal microtubule content. But its diagnostic value is diminished by its dependence on the incident angle of the OCT beam, which is highly variable in routine clinical imaging. We hypothesize that the diagnostic accuracy can be boosted by reducing incidence angle effects with azimuthal filtering of NFL reflectance profile, and by analysis of focal rather than average reflectance changes. The preliminary result, bases on 100 normal and glaucoma eyes, showed that the diagnostic sensitivity was significantly improved from 71% for average NFL thickness to 97% for focal NFL reflectance loss in PG eyes, at a 99% specificity cutoff. We propose to validate this result in the large Advanced Imaging for Glaucoma (AIG) study dataset that comprises 249 perimetric glaucoma (PG), 252 pre-perimetric glaucoma (PPG), and 145 normal participants. The AIG study has an average follow-up of more than 4 years, which also allows assessment of the accuracy in predicting glaucoma progression. 1. Reproduce the high diagnostic accuracy of focal NFL reflectance loss analysis using the large AIG  dataset. If we could again demonstrate high diagnostic accuracy in the AIG dataset, especially in the PPG  and early PG subgroups, this could bring OCT glaucoma evaluation into the realm of population screening.  The primary performance metric will be the diagnostic sensitivity at a fixed 99% specificity cut point. 2. Use focal NFL reflectance loss to predict visual field (VF) conversion and progression. In the AIG  study, focal thinning of the macular ganglion cell complex (GCC) and peripapillary nerve fiber layer (NFL)  were found to be the best predictors of VF conversion (development of glaucomatous VF abnormality in an  eye with normal baseline VF) and progression (significant worsening of VF). We hypothesize that focal  NFL reflectance loss would have even better predictive accuracy. Predictive accuracy will be assessed  using the area under the receiver operating curve (AROC) and logistic regression (odds ratio). 3. Combine OCT reflectance and structural maps using machine learning to improve glaucoma  diagnostic accuracy. A combination of disc, peripapillary, and macular thickness parameters had  previously been shown to be synergistic, producing higher AROC than any single parameter. We  hypothesize that the addition of the novel NFL reflectance loss map to the set of input parameters will  further enhance the diagnostic accuracy of a machine learning algorithm. PROJECT NARRATIVE Nerve fiber layer (NFL) thickness using OCT is widely used in clinic for glaucoma diagnosis, but the diagnostic sensitivity is limited. Combination of NFL reflectivity and other structural OCT information promises to improve the diagnostic accuracy to a level where population-based screening would be feasible.",Focal nerve fiber layer reflectance analysis for glaucoma evaluation,10108277,R21EY032146,"['Algorithms', 'Area', 'Axon', 'Blindness', 'Clinic', 'Clinical Management', 'Complex', 'Data Set', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Sensitivity', 'Diagnostic Specificity', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Glaucoma', 'Image', 'Incidence', 'Logistic Regressions', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Nerve Fibers', 'Odds Ratio', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Performance', 'Population', 'Retina', 'Sampling', 'Scanning', 'Specificity', 'Structure', 'Subgroup', 'System', 'Thick', 'Thinness', 'Visual Fields', 'base', 'clinical imaging', 'cost', 'diagnostic accuracy', 'disorder risk', 'follow-up', 'ganglion cell', 'improved', 'machine learning algorithm', 'macula', 'novel', 'population based', 'screening']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2021,192500
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",10075930,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Reference Standards', 'Research', 'Risk', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'diagnostic technologies', 'disorder subtype', 'elastography', 'hepatocellular injury', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'risk stratification', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,448421
"Portable Hearing Laboratory  - CRP In the parent Phase II project (R44DC016247; PI: C. Pavlovic) we successfully developed a portable platform for developing and testing new hearing aid technology. This Portable Hearing Laboratory, or PHL, has now been acquired and is being used by a number of leading university laboratories and other research centers and their feedback has been extremely positive. The device features a central unit (BatAndCat Box) which provides an appropriate and complete hearing aid ambient for developing new algorithms. A number of realistic interfaces has also been provided. This includes an extremely high quality BTE system we designed; an ITE system adapted by us, as well as an appropriate interface circuitry for typical wearables (e.g; headsets via the line input). Finally, a smart phone app features interfaces both for the researcher and the subject. The system runs the Master Hearing aid sweet developed concurrently in R01DC015429 (PIs Hohmann and Pavlovic). In this CRP renewal we will achieve the following goals: 1. Implement various Design for Excellence Measures (DFX) and super modern manufacturing  technology to obtain the highest product quality at the lowest product cost. This would make  the product affordable for large clinical studies and, potentially, for some consumer sales. 2. In response to the recent availability of, and the recent research demand for, a far greater  processing power to enable the development of algorithms which rely on machine learning,  we plan to increase the processing power of the device by at least 10 times, and likely 20  times, by changing the processor core to a multicore system. 3. Introduce modern low-latency BLE technology to enable efﬁcient noise reduction by utilizing  remote microphones and machine learning. 4. The other complementary requirement to extract speech from noise is being able to inform  the system whom the listener is actually listening to. This will be achieved by providing on  the PHL the interface means for external multi-sensor arrays such as EEG, OEG, etc. 5. Execute electrical and mechanical design changes dramatically reducing the size and  weight of the device. This would not only be a much more acceptable device for long clinical  trials, but would also open up a direct-to-consumer, secondary market for the device. 6. It is our strong determination to provide continuous support to the Beta sites for extensive  further testing of the device in a variety of settings. We consider this the best means to  reach the perfection. Portable Hearing Laboratory (PHL), developed in R44DC016247 has been deployed successfully at various research centers and it features a central unit connected to a number of realistic interfaces such as BTEs, ITEs, or typical wearables. In this CRP renewal we upgrade the technology to support demanding machine learning algorithms interfaced almost inconspicuously to a number of EEG and EOG electrodes to extract perfectly speech from noise. Simultaneously, we apply modern manufacturing technology to produce small, powerful and low cost devices.",Portable Hearing Laboratory  - CRP,10138807,R44DC016247,"['Acoustics', 'Algorithms', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Code', 'Communities', 'Data', 'Device or Instrument Development', 'Devices', 'Ear', 'Electrodes', 'Electroencephalography', 'Environment', 'Esthetics', 'Evaluation', 'Feedback', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Institution', 'Laboratories', 'Libraries', 'Life', 'Linux', 'Machine Learning', 'Measures', 'Mechanics', 'Modernization', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Parents', 'Phase', 'Process', 'Reporting', 'Request for Applications', 'Research', 'Research Personnel', 'Running', 'Sales', 'Signal Transduction', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Source Code', 'Speech', 'System', 'Technology', 'Testing', 'Time', 'Transducers', 'Universities', 'Validation', 'Weight', 'Wireless Technology', 'Work', 'algorithm development', 'base', 'cost', 'design', 'improved', 'machine learning algorithm', 'man', 'manufacturing process', 'meter', 'microphone', 'new technology', 'open source', 'parent project', 'portability', 'response', 'sensor', 'signal processing', 'simulation', 'smartphone Application', 'sound', 'speech in noise', 'tool', 'virtual']",NIDCD,"BATANDCAT, INC.",R44,2021,837653
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,10178133,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'behavioral phenotyping', 'comorbidity', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2021,422740
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",10139080,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'machine learning method', 'myocardial injury', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2021,790095
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10183329,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2021,797476
"An enhancement to nGoggle: a VR Goggle for Structural and Functional assessment in Glaucoma PROJECT SUMMARY  Assessments of functional loss and of structural damage to the optic nerve are typical evaluations per- formed in the diagnosis and monitoring of glaucoma. This proposal aims at developing the hardware system that will allow acquisition of fundus photographs using the nGoggle, a portable Brain-Computer Interface (BCI) which integrates a wearable, wireless, electroencephalogram (EEG) system and a head-mounted display to monitor electrical brain activities associated with visual field stimulation. In a previous project, we developed the nGoggle portable system for the assessment of visual function deficits in order to address limitations of standard automated perimetry (SAP), a traditional but subjective visual field test. We compared the diagnostic accuracies of the nGoggle and SAP in discriminating patients with glaucoma from healthy subjects and found that the BCI performed at least as well, if not better than SAP, with the additional advantage of portability and objectivity.  With rapid advancements in smartphone cameras, it is now possible to develop compact auto-focusing fundus cameras and integrate them into our neuro-monitoring nGoggle. Recently we developed an approach named Machine-to-Machine (M2M), a deep learning algorithm that was trained to analyze fundus photos and predict quantitative measurements of retinal nerve fiber layer thickness and neuroretinal rim provided by spectral domain-optical coherence tomography (SDOCT), with high correlation and agreement with the original SDOCT observations. This approach opens up the possibility of using simple fundus photographs to extract quantitative information about neural damage in glaucoma. By combining functional assessment currently provided by the nGoggle with structural assessment capability, this new system would result in a very unique device capable of portable structural and functional assessment of optic nerve damage for a multitude of eye conditions, not limited to glaucoma, such as age-related macular degeneration, retinal degenerations and non-glaucomatous optic neu- ropathies.  The specific aims of this Phase I SBIR project are (1) to incorporate a high-resolution auto-focusing fundus camera to the nGoggle head-mounted display in full compliance with ophthalmic instrument safety stand- ards and fundus camera functional standards, and (2) to demonstrate the ability of the nGoggle fundus camera to capture high-quality optical nerve images from a model eye. Successful development of this system will enable both structural and functional assessments of retinal conditions to be performed easily and inexpensively using a portable device. PROJECT NARRATIVE NGoggle Inc. proposes to develop a new wearable ophthalmic diagnostic instrument capable of performing con- current structural and functional assessment to diagnose and monitor optic neuropathies and retinal diseases. This project aims at developing a pair of compact high-resolution fundus cameras in full compliance with oph- thalmic instrument safety standards and integrating them into our neuro-monitoring nGoggle, an instrument with the demonstrated capability of estimating functional vision loss in glaucoma patients based on their electroen- cephalogram (EEG) responses evoked by visual stimuli. We also intend to demonstrate that the optic nerve images of model eyes taken by the integrated fundus cameras can yield consistent and compatible cup-to-disc ratios when compared with the measurements obtained from the same model eyes using optical coherence tomography (OCT). After successful demonstration, we plan to conduct clinical tests in the subsequent phase of this project.",An enhancement to nGoggle: a VR Goggle for Structural and Functional assessment in Glaucoma,10253661,R43EY032820,"['Address', 'Age related macular degeneration', 'Agreement', 'Algorithms', 'Anatomy', 'Blindness', 'Cellular Phone', 'Clinic', 'Clinical', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Electroencephalogram', 'Electroencephalography', 'Evaluation', 'Eye', 'Flare', 'Fundus', 'Fundus photography', 'Glaucoma', 'Healthcare', 'Image', 'Imaging technology', 'Light', 'Measurement', 'Modeling', 'Monitor', 'Names', 'Nerve', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Performance', 'Perimetry', 'Phase', 'Physiologic pulse', 'Publications', 'Reproducibility', 'Resolution', 'Resources', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Safety', 'Series', 'Small Business Innovation Research Grant', 'Source', 'Structure', 'System', 'Systems Development', 'Testing', 'Thick', 'Time', 'Training', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Visual impairment', 'Wireless Technology', 'base', 'brain computer interface', 'brain electrical activity', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'detection test', 'diagnostic accuracy', 'disability', 'field study', 'functional loss', 'gaze', 'hazard', 'head mounted display', 'innovation', 'instrument', 'loss of function', 'neural network algorithm', 'optic nerve disorder', 'patient response', 'portability', 'prevent', 'relating to nervous system', 'retinal imaging', 'retinal nerve fiber layer', 'screening', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R43,2021,299600
"Development of A High Throughput Image-Guided IMRT System for Preclinical Research Project Summary/Abstract Preclinical radiobiology experiments on small animals are crucial to test the safety and efficacy before human clinical trials. However, limited by currently available technologies, preclinical animal studies substantially differ from state-of-the-art human treatments in dose conformity. Consequently, the animal studies poorly mimic the radiobiological, radioimmunological, and toxicity environment of human therapies. The disparity adversely affects our ability to meaningfully test hypotheses that are intended for human translation. With decades of advancement, human radiotherapy has achieved high targeting accuracy and dose conformality based on technological breakthroughs, including intensity-modulated radiotherapy (IMRT), which is unavailable for mouse experiments. A practical device and algorithm to modulate the x-ray intensity for the scale of small animals is the first step to bridge the gap. With the support of an NIH R21 grant, we engineered a novel small animal IMRT dose modulator termed sparse orthogonal collimator (SOC). Equally important as the hardware, we created the enabling mathematical tools to deliver SOC IMRT plans with higher achievable resolution than a theoretically miniaturized MLC-based IMRT. We commissioned and tested prototypical SOCs to deliver highly modulated doses in silico and on phantoms. Nonetheless, there are still large gaps between an intensity modulation device and a small animal IMRT system suitable for broad adoption and impact. The required time, resources, and training to create sophisticated SOC-IMRT plans are incompatible with preclinical settings. Furthermore, without automation, the existing image-guided small animal IMRT treatment is prohibitively slow for treating live animals under anesthesia. Lastly, the current manual method to switch between imaging and therapy modes results in intractable uncertainties in dose delivery. We propose to fill these gaps using automation, robotics, and system optimization. We propose the following specific aims. Specific Aim 1 (SA1). Automated organ segmentation for mice using deep learning neural networks. Specific Aim 2 (SA2). Development of a fully functional, automated, and efficient IMRT system. Specific Aim 3 (SA3). Development and validation of a robotic Multi Mouse Automated Treatment Environment (Multi-MATE) for automated imaging and treatment. Besides dosimetry, we will quantify the time performance, which is critical to small animal IMRT system. As a result, in addition to improving the hardware accuracy and reliability, the proposed project will provide a fully automated planning and delivery system, thus removing the last barriers towards the broad adoption of small animal IMRT. The success of the proposed project will help existing research to achieve the full potential for human translation and enable future hypotheses testing where accurate complex dose distribution is critical. Project Narrative A major impediment in translating animal radiation studies to human patients is the disparity in radiation techniques. Existing methods cannot create human like conformal radiation dose on mice with necessary accuracy and efficiency. To better mimic human treatment without prohibitively complicated and slow procedures, we propose to develop a high throughput image guided small animal conformal irradiation platform.",Development of A High Throughput Image-Guided IMRT System for Preclinical Research,10317441,R01CA259008,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Anesthesia procedures', 'Animals', 'Automation', 'Calibration', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collimator', 'Complex', 'Computer software', 'Conformal Radiotherapy', 'Development', 'Devices', 'Dose', 'Engineering', 'Environment', 'Future', 'Grant', 'Human', 'Image', 'Individual', 'Intensity-Modulated Radiotherapy', 'Intervention', 'Knowledge', 'Manuals', 'Mathematics', 'Methods', 'Mus', 'Organ', 'Patients', 'Performance', 'Procedures', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Radiobiology', 'Research', 'Resolution', 'Resources', 'Risk', 'Robotics', 'Roentgen Rays', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Toxic effect', 'Training', 'Translating', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'automated segmentation', 'base', 'biological research', 'deep learning', 'deep neural network', 'design', 'dosimetry', 'experimental study', 'image guided', 'improved', 'in silico', 'innovation', 'irradiation', 'miniaturize', 'novel', 'pre-clinical', 'pre-clinical research', 'process optimization', 'robotic system', 'safety testing', 'success', 'tool', 'treatment planning', 'trend', 'tumor', 'user-friendly']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,441662
"Biomedical Raman Imaging Workshop Summary The purpose of the planned conference is to facilitate development of Raman-spectroscopy based clinical appli- cations.  Raman scattering provides label-free contrast for imaging that derives from intrinsic molecular vibrations. Because it is label-free and reports in an unbiased way on all molecular species in a sample, it provides a holistic “view” of the chemical environment in clinical samples, and thus holds signiﬁcant value as a diagnostic and treatment monitoring tool.  While the phenomenon of Raman scattering has been known since 1920, and its clinical potential has been recognized for many decades, roadblocks including weak signal levels and complexity of its readout has precluded it from clinical use. These roadblocks are now being removed through innovations in instrument development and machine learning. Narrative Raman spectroscopy provides diagnostically important chemical proﬁles of clinical samples, withouth the need of labeling. Throgh this it holds tremendous potential to improve many diagnostic and monitoring aspects of healthcare. The purpose of this workshop is to facilitate efﬁcient development of these techniques in a way that will be clinically acceptable.",Biomedical Raman Imaging Workshop,10318774,R13EB032251,"['Adopted', 'Adoption', 'Antibiotic susceptibility', 'Area', 'Biological', 'Biology', 'Brain', 'Caring', 'Chemicals', 'Clinical', 'Complex', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Diagnostic', 'Educational workshop', 'Environment', 'Excision', 'Fingerprint', 'Fruit', 'Generations', 'Healthcare', 'Histology', 'Image', 'Image Analysis', 'Imaging technology', 'In Situ', 'Label', 'Light', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Molecular', 'Monitor', 'Nature', 'Paper', 'Pathogen detection', 'Photons', 'Physicians', 'Publishing', 'Raman Spectrum Analysis', 'Reporting', 'Role', 'Sampling', 'Scheme', 'Signal Transduction', 'Time', 'Tissues', 'Translating', 'Voice', 'base', 'clinical application', 'clinical practice', 'contrast imaging', 'imaging approach', 'imaging modality', 'improved', 'in vivo', 'innovation', 'liquid biopsy', 'screening', 'symposium', 'technique development', 'technology development', 'tool', 'tumor', 'vibration']",NIBIB,GEORGIA INSTITUTE OF TECHNOLOGY,R13,2021,9996
"A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration PROJECT SUMMARY Age-related macular degeneration (AMD), in the dry or wet form, is the leading cause of vision loss in the developed countries. The Age-Related Eye Disease Study (AREDS) showed that specific antioxidant vitamin supplementation reduces the risk of progression from intermediate stages to late AMD and maintains visual acuity in approximately 25% of patients. While treatment of wet AMD with Intraocular injections can be effective in maintaining vision, such treatments are costly and may be associated with significant cardiovascular risks, or even progression of dry AMD. Hence, it is critical to identify patients at the earlier stages. Unfortunately, there is no effective, automated screening tool to accomplish this, and the patients themselves may be asymptomatic. The goal of this SBIR Direct-to-Phase II proposal is to provide such tool. We have demonstrated the feasibility of AMD screening software ‘iPredictTM’ by successfully identifying 98.1% of individuals with early or intermediate stage AMD. iPredictTM also successfully predicted which individuals would develop late AMD within one year with 87.8% accuracy and two years with 88.4% accuracy. iPredictTM has prototype components for image analysis and machine learning. We also developed a HIPAA compliant telemedicine platform which will enable iPredictTM to perform large-scale screening from remote and rural areas. In order to bring the product to market, these components need to be integrated and tested which is the aim of our proposed Direct-to-Phase II proposal. We aim to develop the finished product which will be ready for the market. We also aim to evaluate the efficacy of iPredictTM in a clinical setup. The AMD preventative market is estimated around $5.4 billion in the U.S. alone. iPredictTM will capture the major market share with its best accuracy and be the first prediction tool for AMD. We aim to commercialize iPredictTM for the screening and prevention of AMD, saving millions of citizens from blindness and reduced quality of life. With iPredictTM’s improvements in speed of delivery, cost of care, and ease of access, the product will be a significant addition to the healthcare system. The iPredictTM’s telemedicine platform will allow large-scale screening from remote/rural areas, primary care clinics, optometry offices and ophthalmology clinics. PROJECT NARRATIVE Age-related macular degeneration (AMD) in its late forms, “dry” or “wet”, is the leading cause of blindness in developed countries. Early intervention and therapy can significantly reduce the progression of early to late AMD. Hence, the identification of patients with early AMD and referral to an ophthalmologist is critically needed to help prevent vision loss. To achieve this goal, we propose to develop an automated screening and prediction system that can be widely deployed to identify these individuals at risk of vision loss.",A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration,10320271,R44EY031202,"['Affect', 'Age', 'Age related macular degeneration', 'American', 'Antioxidants', 'Blindness', 'Categories', 'Clinic', 'Clinical', 'Clinics and Hospitals', 'Code', 'Color', 'Computer software', 'Counseling', 'Data', 'Data Set', 'Databases', 'Developed Countries', 'Devices', 'Diagnosis', 'Drusen', 'Ear', 'Early Intervention', 'Evaluation', 'Eye', 'Eye diseases', 'Feasibility Studies', 'Fees', 'Goals', 'Health Insurance Portability and Accountability Act', 'Healthcare Systems', 'Image', 'Image Analysis', 'Incentives', 'Individual', 'Injections', 'Intervention', 'Java', 'Lasers', 'Learning Module', 'Machine Learning', 'Manuals', 'Methods', 'Minerals', 'Modeling', 'New York', 'Nonexudative age-related macular degeneration', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patients', 'Phase', 'Prevention', 'Prevention strategy', 'Primary Health Care', 'Provider', 'Pythons', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Sales', 'Savings', 'Screening procedure', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Smoking', 'Specialist', 'Speed', 'Sun Exposure', 'Supplementation', 'System', 'Telemedicine', 'Testing', 'Therapeutic Intervention', 'Time', 'Trademark', 'Treatment Cost', 'Validation', 'Vision', 'Visit', 'Visual Acuity', 'Vitamins', 'age related', 'base', 'biobank', 'cardiovascular risk factor', 'care costs', 'checkup examination', 'commercial application', 'convolutional neural network', 'cost', 'deep learning', 'efficacy evaluation', 'follow-up', 'improved', 'photobiomodulation', 'prediction algorithm', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'prospective', 'prototype', 'remote screening', 'research clinical testing', 'retinal imaging', 'rural area', 'screening', 'sociodemographic factors', 'software as a service', 'success', 'tool', 'user-friendly']",NEI,"IHEALTHSCREEN, INC.",R44,2021,45000
"A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration PROJECT SUMMARY Age-related macular degeneration (AMD), in the dry or wet form, is the leading cause of vision loss in the developed countries. The Age-Related Eye Disease Study (AREDS) showed that specific antioxidant vitamin supplementation reduces the risk of progression from intermediate stages to late AMD and maintains visual acuity in approximately 25% of patients. While treatment of wet AMD with Intraocular injections can be effective in maintaining vision, such treatments are costly and may be associated with significant cardiovascular risks, or even progression of dry AMD. Hence, it is critical to identify patients at the earlier stages. Unfortunately, there is no effective, automated screening tool to accomplish this, and the patients themselves may be asymptomatic. The goal of this SBIR Direct-to-Phase II proposal is to provide such tool. We have demonstrated the feasibility of AMD screening software ‘iPredictTM’ by successfully identifying 98.1% of individuals with early or intermediate stage AMD. iPredictTM also successfully predicted which individuals would develop late AMD within one year with 87.8% accuracy and two years with 88.4% accuracy. iPredictTM has prototype components for image analysis and machine learning. We also developed a HIPAA compliant telemedicine platform which will enable iPredictTM to perform large-scale screening from remote and rural areas. In order to bring the product to market, these components need to be integrated and tested which is the aim of our proposed Direct-to-Phase II proposal. We aim to develop the finished product which will be ready for the market. We also aim to evaluate the efficacy of iPredictTM in a clinical setup. The AMD preventative market is estimated around $5.4 billion in the U.S. alone. iPredictTM will capture the major market share with its best accuracy and be the first prediction tool for AMD. We aim to commercialize iPredictTM for the screening and prevention of AMD, saving millions of citizens from blindness and reduced quality of life. With iPredictTM’s improvements in speed of delivery, cost of care, and ease of access, the product will be a significant addition to the healthcare system. The iPredictTM’s telemedicine platform will allow large-scale screening from remote/rural areas, primary care clinics, optometry offices and ophthalmology clinics. PROJECT NARRATIVE Age-related macular degeneration (AMD) in its late forms, “dry” or “wet”, is the leading cause of blindness in developed countries. Early intervention and therapy can significantly reduce the progression of early to late AMD. Hence, the identification of patients with early AMD and referral to an ophthalmologist is critically needed to help prevent vision loss. To achieve this goal, we propose to develop an automated screening and prediction system that can be widely deployed to identify these individuals at risk of vision loss.",A Model for Predicting 2-Year Risk of Incident Late Age-related Macular Degeneration,10172914,R44EY031202,"['Affect', 'Age', 'Age related macular degeneration', 'American', 'Antioxidants', 'Blindness', 'Categories', 'Clinic', 'Clinical', 'Clinics and Hospitals', 'Code', 'Color', 'Computer software', 'Counseling', 'Data', 'Data Set', 'Databases', 'Developed Countries', 'Devices', 'Diagnosis', 'Drusen', 'Ear', 'Early Intervention', 'Evaluation', 'Eye', 'Eye diseases', 'Feasibility Studies', 'Fees', 'Goals', 'Health Insurance Portability and Accountability Act', 'Healthcare Systems', 'Image', 'Image Analysis', 'Incentives', 'Individual', 'Injections', 'Intervention', 'Java', 'Lasers', 'Learning Module', 'Machine Learning', 'Manuals', 'Methods', 'Minerals', 'Modeling', 'New York', 'Nonexudative age-related macular degeneration', 'Ophthalmologist', 'Ophthalmology', 'Optometry', 'Patients', 'Phase', 'Prevention', 'Prevention strategy', 'Primary Health Care', 'Provider', 'Pythons', 'Quality of life', 'Reporting', 'Research', 'Resolution', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Risk', 'Risk Factors', 'Sales', 'Savings', 'Screening procedure', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Smoking', 'Specialist', 'Speed', 'Sun Exposure', 'Supplementation', 'System', 'Telemedicine', 'Testing', 'Therapeutic Intervention', 'Time', 'Trademark', 'Treatment Cost', 'Validation', 'Vision', 'Visit', 'Visual Acuity', 'Vitamins', 'age related', 'base', 'biobank', 'cardiovascular risk factor', 'care costs', 'checkup examination', 'commercial application', 'convolutional neural network', 'cost', 'deep learning', 'efficacy evaluation', 'follow-up', 'improved', 'photobiomodulation', 'prediction algorithm', 'predictive modeling', 'prevent', 'prognostic', 'programs', 'prospective', 'prototype', 'remote screening', 'research clinical testing', 'retinal imaging', 'rural area', 'screening', 'sociodemographic factors', 'software as a service', 'success', 'tool', 'user-friendly']",NEI,"IHEALTHSCREEN, INC.",R44,2021,545819
"Using Multi-Spectral Imaging with Microchip Electrophoresis to Accurately Screen Newborns for Sickle Cell Disease PROJECT SUMMARY Hemoglobin (Hb) disorders are among the world's most common monogenic diseases. Nearly 7% of the world’s population carry Hb gene variants. Sickle cell disease (SCD) arises when Hb mutations are inherited homozygously (HbSS) or paired with another β-globin gene mutation. Globally, an estimated 400,000 babies are born annually with SCD, and 70%-75% are in sub-Saharan Africa (SSA). It is estimated that 50-90% in SSA die by their 5th birthday, 70% of these deaths are preventable. Effective management of SCD involves early diagnosis, and genetic counselling, and, importantly, nationwide newborn screening (NBS). NBS programs utilizing centralized laboratories have dramatically reduced SCD mortality in high-resource countries. NBS requires sensitive detection of relatively low levels of Hb variants in the presence of high fetal Hb (HbF). Normal HbA and sickle HbS should be accurately identified in the presence of high levels (up to 90%) of HbF. The current gold standard for Hb variant testing is high-performance liquid chromatography (HPLC), which requires expensive equipment and reagents, highly trained personnel, and modern laboratories. In low- resource regions, very few centralized laboratories can perform costly Hb testing. Testing is not available to the large percentage of infants born outside of a major hospital or city. There is an unmet need for affordable, portable, easy-to-use, accurate, point-of-care (POC) tests to facilitate decentralized Hb testing to enable nationwide NBS programs. In 2019, the World Health Organization (WHO) listed Hb electrophoresis as an essential in vitro diagnostic in low- and middle-income countries. We have developed a POC microchip electrophoresis Hb variant testing system, MicroChip Electrophoresis (MCE), under the product name “Gazelle Hb Variant” by Hemex Health, Inc. MCE reports Hb phenotype, Hb quantification (%Hb), and an interpretive statement showing genotype (such as SCD, Sickle Cell Trait, or Normal). MCE has been extensively validated for hemoglobinopathies, including SCD, hemoglobin E disease, and thalassemia. Newborns and infants below 6 weeks of age have very low concentrations of Hb variants other than Hb F which is high, therefore an improvement to lower the limit of detection (LoD) is needed to support NBS programs worldwide. By decreasing the LoD from the current 10% to 2%, newborns and infants can be screened with this affordable system. The innovation in this SBIR Phase I is the integration of multi-spectral imaging and machine learning based data analysis capability to MCE to develop MCE+ to accurately screen newborns for common Hb variants. We propose the following aims: Aim 1: Integrate multi-spectral imaging and machine learning algorithm into the MCE platform to enable identification and quantification of hemoglobin variants in newborns. Aim 2: Perform clinical testing of the MCE+ multi-spectral newborn screening system. Significance of this project is that MCE+ is the only affordable POC system for quantitative and objective hemoglobin variant testing that allows screening at birth. PROJECT NARRATIVE Up to 50 to 90% of children born with sickle cell disease (SCD) in economically disadvantaged countries (over 400,000 per year) die before the age of five, although the WHO estimates that 70% could be saved through simple, cost-effective treatments. Early diagnosis starting at birth is critical for implementing effective disease management, but newborn screening is a challenge for low resource environments where a decentralized, point-of-care solution is needed. This project enables our affordable, point-of-care platform based on microchip electrophoresis technology to accurately perform newborn screening.",Using Multi-Spectral Imaging with Microchip Electrophoresis to Accurately Screen Newborns for Sickle Cell Disease,10255480,R43HL156685,"['Africa', 'Africa South of the Sahara', 'Age', 'Bedside Testings', 'Birth', 'Blood', 'Care Technology Points', 'Caring', 'Child', 'Cities', 'Clinical', 'Clinical Research', 'Country', 'Data Analyses', 'Decentralization', 'Detection', 'Development', 'Disease', 'Disease Management', 'Drops', 'Early Diagnosis', 'Economically Deprived Population', 'Electrophoresis', 'Ensure', 'Environment', 'Equipment', 'Fetal Hemoglobin', 'Gender', 'Gene Mutation', 'Genetic Counseling', 'Genotype', 'Ghana', 'Gold', 'Health', 'Health Status', 'Hemoglobin', 'Hemoglobin E Disease', 'Hemoglobin concentration result', 'Hemoglobinopathies', 'High Pressure Liquid Chromatography', 'Hospitals', 'Human Resources', 'India', 'Infant', 'Inherited', 'Laboratories', 'Machine Learning', 'Mendelian disorder', 'Microchip Electrophoresis', 'Modernization', 'Mutation', 'Names', 'Neonatal Screening', 'Newborn Infant', 'Phase', 'Phenotype', 'Point-of-Care Systems', 'Population', 'Race', 'Reagent', 'Reference Standards', 'Reporting', 'Resources', 'Sickle Cell Anemia', 'Sickle Cell Trait', 'Small Business Innovation Research Grant', 'Southeastern Asia', 'Specificity', 'System', 'Teaching Hospitals', 'Technology', 'Testing', 'Thalassemia', 'Training', 'Validation', 'Variant', 'Work', 'World Health Organization', 'base', 'beta Globin', 'commercialization', 'cost', 'cost effective treatment', 'detection limit', 'diagnostic accuracy', 'genetic variant', 'improved', 'in-vitro diagnostics', 'innovation', 'innovative technologies', 'low and middle-income countries', 'machine learning algorithm', 'miniaturize', 'mortality', 'novel', 'point of care', 'portability', 'preventable death', 'research clinical testing', 'screening', 'screening program', 'sickling', 'spectrograph', 'trait']",NHLBI,"HEMEX HEALTH, INC.",R43,2021,256580
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10143312,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2021,499966
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,10091434,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2021,498914
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,10066353,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2021,373738
