text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Innovative Vaccine Approaches ABSTRACT Support is requested for a Keystone Symposia conference entitled Innovative Vaccine Approaches, organized by Drs. Mariagrazia Pizza, Galit Alter and Gordon Dougan. The conference will be held in Vancouver, Canada from June 27- July 1, 2021. Vaccines have the power to prevent and potentially eradicate a wide range of infectious diseases, representing one of the most effective life-saving measures at our disposal against global health threats. The recent coronavirus pandemic has brought the importance and urgency of vaccine development efforts into sharp focus. Moreover, the vaccinology field is evolving very rapidly, thanks to advances in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis of antigens and antigen- antibody complexes and impacts of variation. Over the years, this field has also experienced an elucidation of mechanisms of immunity and protection, and identification of correlates. However, many questions are still unsolved and innovative approaches are needed to address new vaccine challenges like antimicrobial resistance, emerging infectious diseases, cancer and diseases associated with our aging population. This conference will cover the latest advances and novel approaches towards vaccine development, including: (1) novel antigen delivery systems; (2) in vitro and in vivo model systems for vaccine appraisal (3) the use of human challenge models; (4) the role of ‘systems biology’ in the comprehensive analysis of immune correlates, biomarker identification and safety; (5) machine-learning approaches to define correlations between antibody repertoires and protection; and (6) strategies for developing low cost vaccines for economically challenged populations. Together these topics will provide attendees with the new ideas and tools to continue to forge new frontiers in vaccine capabilities. PROJECT NARRATIVE Vaccines have the power to prevent and potentially eradicate a wide range of both infectious and non- infectious diseases. The field is evolving very rapidly due to improvements in our understanding of microbiology, immunology and genomics, as well as advances in structural analysis techniques. This conference will accelerate advances the field, bringing together public and private communities to ensure the end of the COVID-19 pandemic and other epidemics that afflict the population. This event provides a unique opportunity for discussion of the key challenges in making low cost vaccines for economically challenged populations and how to address burning topics such as pandemics, antimicrobial resistance, emerging infectious diseases, cancer and an aging population.",Innovative Vaccine Approaches,10237543,R13AI161938,"['Address', 'Antibody Repertoire', 'Antigen-Antibody Complex', 'Antigens', 'Antimicrobial Resistance', 'Biological Models', 'COVID-19 pandemic', 'Canada', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Coronavirus', 'Disease', 'Educational workshop', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Event', 'Future', 'Genomics', 'Human', 'Immersion', 'Immune', 'Immunity', 'Immunology', 'In Vitro', 'Knowledge', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Microbiology', 'Modeling', 'Outcome', 'Population', 'Privatization', 'Research', 'Research Personnel', 'Role', 'Safety', 'Savings', 'Scientist', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Vaccines', 'Variant', 'aging population', 'biomarker identification', 'clinical practice', 'cost', 'experience', 'frontier', 'global health', 'in vivo Model', 'innovation', 'manufacturability', 'next generation', 'novel', 'novel strategies', 'novel vaccines', 'pandemic disease', 'posters', 'prevent', 'symposium', 'tool', 'vaccine development', 'vaccine discovery', 'vaccinology']",NIAID,KEYSTONE SYMPOSIA,R13,2021,8000
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,10113656,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2021,397125
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,10144435,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science Core', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Infrastructure', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'health science research', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2021,1471985
"Affective science and smoking cessation: Real time real world assessment Tobacco use plays a causal role in almost 20 different types of cancer, and although smoking cessation is a cornerstone of cancer risk reduction, the vast majority of smoking quit attempts fail. Numerous conceptual models, as well as a large body of empirical evidence, underscore that affect is a potent determinant of smoking lapse. Unfortunately, very little is known about how the constellation and temporal dynamics of distinct emotions and other factors play out in real time in the real world to influence lapse risk. This lack of knowledge severely hampers both our conceptual models and our ability to optimally intervene. Thus, the overarching objectives of this research are to create a more detailed and comprehensive conceptual model of the role of distinct emotions in self-regulation, as well as the technical, empirical, and analytic foundation necessary to develop effective interventions for smoking cessation and other cancer risk behaviors that can target real time, real world mechanisms. The proposed research directly addresses several objectives from the PAR including the influence of distinct emotions and their time course on cancer risk behaviors, whether the role of distinct emotions is altered by the presence of other emotions (e.g., “blended” emotional states), and how the influence of affective experience is modified by context. The proposed longitudinal cohort study among 300 smokers attempting to quit is guided by a conceptual framework grounded in affective science and conceptual models of self-regulation and addiction. Participants will be followed from 1 week prior to their quit date through 6 months post-quit date. They will be assessed from 1 week pre-quit date through 2 weeks post-quit date using AutoSense, geographic positioning system (GPS), and ecological momentary assessment (EMA). AutoSense, GPS, and EMA collect real time data in natural environments, communicate wirelessly with each other, and data are processed in real time on a smartphone. AutoSense detects specific behavioral and physiologic “signatures” of smoking (the primary outcome) and self regulatory capacity (an intermediate outcome; assessed using high frequency heart rate variability) in real time. GPS real time spatial tracking will be linked with spatially and temporally relevant characteristics of the environment using geographic information system (GIS) data. EMAs assess self-reported emotions, cognition, and context. Analyses utilize advanced dynamic risk prediction models and machine learning approaches to model the dynamics of real time, real world associations among distinct emotions, SRC, and lapse. Tobacco use is the leading preventable cause of death and disability in the U.S. The proposed study will yield a more detailed and comprehensive conceptual model of the role of distinct emotions in self-regulation, as well as the technical, empirical, and analytic foundation necessary to develop more effective interventions for smoking cessation and other cancer risk behaviors that can target real time, real world mechanisms. This knowledge can be utilized to reduce the public health burden of tobacco use.",Affective science and smoking cessation: Real time real world assessment,10074543,R01CA224537,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anger', 'Behavioral', 'Cause of Death', 'Cellular Phone', 'Characteristics', 'Cognition', 'Complement', 'Complex', 'Data', 'Depressed mood', 'Ecological momentary assessment', 'Emotional', 'Emotions', 'Environment', 'Failure', 'Foundations', 'Frequencies', 'Geographic Information Systems', 'Geography', 'Home environment', 'Informal Social Control', 'Intervention', 'Knowledge', 'Link', 'Longitudinal cohort study', 'Machine Learning', 'Measurement', 'Mediating', 'Mediator of activation protein', 'Modeling', 'Outcome', 'Participant', 'Patient Self-Report', 'Physiological', 'Play', 'Positioning Attribute', 'Process', 'Public Health', 'Real-Time Systems', 'Reporting', 'Research', 'Risk', 'Risk Behaviors', 'Risk Reduction', 'Role', 'Science', 'Smoker', 'Smoking', 'Smoking Cessation Intervention', 'Stress', 'System', 'Testing', 'Time', 'Tobacco', 'Tobacco use', 'Volition', 'Wireless Technology', 'adaptive intervention', 'addiction', 'advanced analytics', 'base', 'cancer prevention', 'cancer risk', 'cancer type', 'disability', 'effective intervention', 'experience', 'heart rate variability', 'knowledge base', 'mobile computing', 'negative affect', 'primary outcome', 'risk prediction model', 'role model', 'smoking cessation', 'success']",NCI,UNIVERSITY OF UTAH,R01,2021,1
"Investigating the impact and patterns of homologous recombination and adaptive evolution on bacterial genomes Project summary In contract to sexual organisms, the mechanisms of population genetics in bacteria are far less understood. Two fundamental aspects of bacterial population genetics remain sorely understudied: i) the impact of DNA exchange on the evolution of bacterial genomes and populations is largely unknown. ii) the prominence of adaptive evolution has not been comprehensively assessed in bacteria. Determining how recombination and adaptive evolution impact bacteria is key to understand the biology of these organisms and to develop relevant models of their evolution. Although bacteria reproduce clonally, there is increasing evidence that the vast majority of these organisms are capable of homologous recombination by exchanging pieces of DNA in a process similar to gene conversion in animals and plants. This process enhances microbial capacity to adapt to stresses or changing environments and the exchange of DNA between bacterial strains is a major concern for human health as exemplified by the transfer of virulence and antibiotic resistance genes. Despite the central role of this process, the rates and patterns of recombination remain unresolved in bacteria. The extent of recombination often varies greatly from one study to another and, as a result, the same bacterial species can be perceived as clonal in one study and highly recombining in another. In this project, we propose to re-evaluate the landscape of recombination rates and patterns along the genomes of hundreds of bacterial species. Using new methodological frameworks based on Approximate Bayesian Computation and Deep Learning, we will identify the factors shaping the variation in recombination rate across bacteria. We will also uncover recombination rate variation across bacterial chromosomes (i.e. hot spots and cold spots). Our rate estimates will also allow us to study how recombination drives the evolution of genomic architecture of bacteria, including turnover in gene content. Finally, we will quantify the impact of adaptive evolution in bacteria, which may be substantially larger than in other organisms due to large bacterial effective population sizes. We will also investigate the relationship between adaptation and recombination, and identify the genes/pathways responsible for adaptation. In summary, this study will evaluate the rates and patterns of recombination across hundreds of species, determine the factors driving the evolution of the recombination process, reveal the role of adaptive evolution in bacteria, and the interplay between recombination and adaptation. Project narrative Homologous recombination and adaptive evolution are key mechanisms driving bacterial adaptation to new environments and new treatments. The proposed study aims to apply new approaches to determine the rates and patterns of recombination across genomic data in order to identify the factors shaping the rates and landscapes of recombination as well as the impact of adaptive evolution on bacteria. Upon completion, this project will provide a global view of the interplay between recombination and adaptative evolution across hundreds of bacterial species.",Investigating the impact and patterns of homologous recombination and adaptive evolution on bacterial genomes,10135120,R01GM132137,"['Address', 'Affect', 'Animals', 'Antibiotic Resistance', 'Architecture', 'Automobile Driving', 'Bacteria', 'Bacterial Chromosomes', 'Bacterial Genome', 'Bacterial Infections', 'Bayesian Analysis', 'Biology', 'Chromosomes', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Contracts', 'DNA', 'Data Set', 'Ecology', 'Elements', 'Environment', 'Epidemic', 'Evolution', 'Fibrinogen', 'Frequencies', 'Gene Conversion', 'Genes', 'Genetic Models', 'Genetic Recombination', 'Genome', 'Genomics', 'Health', 'Hot Spot', 'Human', 'Individual', 'Knowledge', 'Laboratories', 'Maps', 'Mediating', 'Methodology', 'Methods', 'Modeling', 'Organism', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Prokaryotic Cells', 'Recombinants', 'Role', 'Sampling', 'Shapes', 'Spottings', 'Stress', 'Structure', 'Testing', 'Time', 'Variant', 'Virulence', 'Virulent', 'Work', 'base', 'deep learning', 'gene function', 'genome analysis', 'genomic data', 'high throughput screening', 'homologous recombination', 'innovation', 'large datasets', 'microbial', 'novel strategies', 'resistance gene', 'tool', 'trait']",NIGMS,UNIVERSITY OF NORTH CAROLINA GREENSBORO,R01,2021,289206
"Inferential methods for functional data from wearable devices Project Summary/Abstract This is a project to develop new statistical methods for comparing groups of subjects in terms of health outcomes that are assessed using data from wearable devices. Inexpensive wearable sensors for health monitoring are now capable of generating massive amounts of data collected longitudinally, up to months at a time. The project will develop inferential methods that can deal with the complexity of such data. A serious challenge is the presence of unmeasured time-dependent confounders (e.g., circadian and dietary patterns), making direct comparisons or borrowing strength across subjects untenable unless the studies are carried out in controlled experimental con- ditions. Generic data mining and machine learning tools have been widely used to provide predictions of health status from such data. However, such tools cannot be used for signiﬁcance testing of covariate effects, which is necessary for designing precision medicine interventions, for example, without taking the inherent model selection or the presence of the unmeasured confounders into account. To overcome these difﬁculties, a systematic de- velopment of inferential methods for functional outcome data obtained from wearable devices will be carried out. There are three speciﬁc aims: 1) Develop metrics for functional outcome data from wearable devices, 2) Develop nonparametric estimation and testing methods for activity proﬁles and a screening method for predictors of activity proﬁles, 3) Implement the methods in an R package and carry out two case studies using accelerometer data. For Aim 1, the approach is to reduce the sensor data to occupation time proﬁles (e.g., as a function of activity level), and formulate the statistical modeling in terms of these proﬁles using survival and functional data analytic meth- ods. This will have a number of advantages, the principal one being that time-dependent confounders become less problematic because the effect of differences in temporal alignment across subjects is mitigated. In addition, survival analysis methods can be applied by viewing the occupation time as a time-to-event outcome indexed by activity level. For Aim 2, nonparametric methods will be used to compare and order occupation time distributions between groups of subjects that are speciﬁed in terms of baseline covariate levels or treatment groups. Further, a new method of post-selection inference based on marginal screening for function-on-scalar regression will be developed to identify and formally test whether covariates are signiﬁcantly associated with activity proﬁles. Aim 3 will develop an R-package implementation, and as a test-bed for the proposed methods they will be applied to two Columbia-based clinical studies: to the study of physical activity in children enrolled in New York City Head Start, and to the study of experimental drugs for the treatment of mitochondrial depletion syndrome. Project Narrative The relevance of the project to public health is that it will develop statistical methods for the physiological eval- uation of patients on the basis of data collected by inexpensive wearable sensors (e.g., accelerometers). By introducing methods for the rigorous comparison of healthcare status among groups of patients observed longi- tudinally over time using such devices, treatment decisions that can beneﬁt targeted populations of patients in terms of continuously-assessed health outcomes will become possible.",Inferential methods for functional data from wearable devices,10135813,R01AG062401,"['Acceleration', 'Accelerometer', 'Beds', 'Bypass', 'Case Study', 'Characteristics', 'Child', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Dietary Practices', 'Drug Combinations', 'Enrollment', 'Evaluation', 'Event', 'Grant', 'Head Start Program', 'Health', 'Health Status', 'Healthcare', 'Intervention', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Monitor', 'Motivation', 'Nature', 'New York City', 'Obesity', 'Occupations', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmacotherapy', 'Physical activity', 'Physiological', 'Preschool Child', 'Process', 'Proxy', 'Public Health', 'Recording of previous events', 'Regimen', 'Signal Transduction', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Stochastic Processes', 'Survival Analysis', 'Syndrome', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Work', 'analytical method', 'base', 'circadian', 'data mining', 'design', 'experimental study', 'functional outcomes', 'indexing', 'interest', 'lower income families', 'novel', 'patient population', 'precision medicine', 'screening', 'sensor', 'theories', 'time use', 'tool', 'treatment group', 'wearable device', 'wearable sensor technology']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,298890
"ICEES+ Knowledge Provider: Leveraging Open Clinical and Environmental Data to Accelerate and Drive Innovation in Translational Research and Clinical Care. As part of the feasibility phase of the Translator program, we have developed a disease-agnostic framework and approach for openly exposing clinical data that have been integrated at the patient- and visit-level with environmental exposures data: the Integrated Clinical and Environmental Exposures Service (ICEES). We have validated ICEES and demonstrated the service’s ability to replicate and extend published findings on asthma, while also supporting open team science, accelerated translational discovery, and integration with the broader Translator ecosystem. This proposal aims to move ICEES from prototype to development via creation of an ICEES+ Knowledge Provider (KP). Specifically, we aim to address three major challenges that we have identified through research and development (R&D) of the prototype ICEES in an effort to improve the quality, value, and impact of query answers and assertions. Specific Aim 1. Advance the rigor of insights and assertions that ICEES provides. Our prototype ICEES currently provides the ability to dynamically define cohorts and conduct simple statistical associations to examine bivariate relationships between feature variables. Recently, we have identified an approach to extend the bivariate functionalities to support multivariate analysis of the data. For the proposed work, we will apply multivariate analyses, including traditional statistical methods (e.g., regression models) and machine learning methods (e.g., bayesian neural network models, variational autoencoder models), and systematically quantify the extent of data loss and analytic bounds when algorithms are imposed on the ICEES+ KP open application programming interface (API) versus the Institutional Review Board (IRB)– protected, fully identified, pre-binned, underlying integrated feature tables. The overall goal is to provide users with more rigorous insights and estimates of the robustness, validity, accuracy, and specificity of knowledge and assertions generated via the ICEES+ KP OpenAPI. Specific Aim 2. Address issues related to space–time and causality. Clinical and environmental data are inherently spatiotemporal, with observations or events that are contingent on space and time and may be causally related. For the proposed work, we will evaluate and implement technical approaches (e.g., ICEES+ design modifications), spatiotemporal statistical algorithms (e.g., conditional auto-regression), recurrent neural network models, and causal inference models. As part of this effort, we will derive insights from and contribute real-world evidence to support Causal Activity Models and Adverse Outcome Pathways. We also will explore approaches for incorporating into ICEES+ nationwide public data on school exposures—data that will allow us to begin to address patient mobility. Specific Aim 3. Evaluate the security of the ICEES+ KP to ensure that patient privacy is preserved as new capabilities are enabled. ImPACT is an NSF-funded package of tools and services that provides end-to-end infrastructure and support for privacy-assured research and computation on sensitive data. Over the award period, we will implement and evaluate ImPACT security protocols, focusing initially on application of the ImPACT secure multiparty computation (SMC) algorithm as a method to support secure multi-institutional sharing of data on rare diseases and events—a functionality that is not currently supported by ICEES. In addition, we will evaluate other ImPACT security protocols, working under the guidance of a security advisor and in the context of driving use cases and capabilities developed under Specific Aims1 and 2. Importantly, the project aims will be driven by three use cases and associated high-value queries designed to complement and extend our asthma-focused work on the prototype ICEES: (1) an asthma cohort from the Environmental Polymorphism Registry (EPR) at the National Institute for Environmental Health Sciences (NIEHS); (2) a primary ciliary disease cohort (PCD) from the UNC PCD Registry; and (3) a drug-induced liver injury (DILI) cohort from the National DILI Network. These use cases will invoke new diseases, new data types, new organ systems, new institutions, and new queries, thereby stress-testing the ICEES framework and approach and moving it from prototype to development as the ICEES+ KP. n/a",ICEES+ Knowledge Provider: Leveraging Open Clinical and Environmental Data to Accelerate and Drive Innovation in Translational Research and Clinical Care.,10333478,OT2TR003430,"['Address', 'Algorithms', 'Asthma', 'Automobile Driving', 'Award', 'Bayesian neural network', 'Clinical', 'Clinical Data', 'Complement', 'Computational algorithm', 'Data', 'Data Analyses', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Environmental Exposure', 'Etiology', 'Event', 'Funding', 'Genetic Polymorphism', 'Goals', 'Infrastructure', 'Institution', 'Institutional Review Boards', 'Knowledge', 'Methods', 'Modeling', 'Modification', 'Multivariate Analysis', 'National Institute of Environmental Health Sciences', 'Neural Network Simulation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Privacy', 'Protocols documentation', 'Provider', 'Publishing', 'Rare Diseases', 'Registries', 'Research', 'Schools', 'Science', 'Secure', 'Security', 'Services', 'Specificity', 'Statistical Algorithm', 'Statistical Methods', 'Stress Tests', 'Time', 'Translational Research', 'Variant', 'Visit', 'Work', 'adverse outcome', 'application programming interface', 'autoencoder', 'body system', 'clinical care', 'cohort', 'data sharing', 'design', 'improved', 'innovation', 'insight', 'liver injury', 'machine learning method', 'patient mobility', 'patient privacy', 'preservation', 'programs', 'prototype', 'recurrent neural network', 'research and development', 'spatiotemporal', 'tool']",NCATS,UNIV OF NORTH CAROLINA CHAPEL HILL,OT2,2021,982187
"A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers PROJECT SUMMARY/ABSTRACT  This application, “A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,” is in response to PAR-16-238, Dissemination and Implementation Research in Health (R01). Acute respiratory distress syndrome (ARDS) has high prevalence (10% of intensive care unit admissions) and mortality up to 46%. Low tidal volume ventilation (LTVV) is the most effective therapy for ARDS, lowering mortality by 20-25%, and is part of standard practice. However, use of LTVV is as low as 19% of ARDS patients. There is a poor understanding of the barriers to LTVV adoption: current approaches are deficient because they incorporate biases, lack consistency and comprehensiveness, ignore the influence of interpersonal network- or team- based factors, and do not address setting-specific variation. Our research team has previously identified some patient- and clinician-specific facilitators of and barriers to LTVV adoption. We have used two state-of-the-art data driven methods—data science and network analysis—to preliminarily quantify the impact of a diverse array of potential factors affecting LTVV adoption, including network- and team-based factors. The proposed research is guided by the Consolidated Framework for Implementation Research (CFIR) and Rogers' Diffusion of Innovations theory. The overall goals of the proposed research are to understand the differences in facilitators and barriers to LTVV adoption between academic and community settings through a definitive, systematic study in a large, diverse consortium of medical centers, and to advance implementation science by providing a model for how data science and network analysis can be applied to understand the adoption of a complex intervention. The overarching hypothesis is that there are different patient-, clinician-, network-, and team-based facilitators and barriers to LTVV adoption in academic and community settings. We will determine whether different patient- and clinician- (Aim 1 cohort study, clinician survey, and data science analysis), clinician interpersonal network- (Aim 2 network analysis), and team structure and dynamics-based (Aim 3 team construction and modeling) facilitators of and barriers to LTVV adoption exist between academic and community hospital settings. Successful completion of the proposed research will provide a comprehensive understanding of the differences in the facilitators of and barriers to LTVV adoption between academic and community settings, and will advance implementation science by serving as a model of how data science and network analysis can be applied to complex implementation problems. Implementation strategies that account for all these factors may be more likely to lead to significant practice change. PROJECT NARRATIVE  Acute respiratory distress syndrome (ARDS) has high prevalence and mortality among critically ill patients; low tidal volume ventilation is the most effective therapy for ARDS but is used infrequently. Successful completion of the proposed research will identify differences in the facilitators of and barriers to adoption of low tidal volume ventilation between academic and community hospital settings in a large and diverse consortium of medical centers. The proposed research will generate a model of how data science and network analysis can be used to understand the implementation of a complex evidence-based practice.",A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,10178076,R01HL140362,"['Acute', 'Admission activity', 'Adoption', 'Adult Respiratory Distress Syndrome', 'Affect', 'Attitude', 'Caring', 'Characteristics', 'Cohort Studies', 'Community Hospitals', 'Complex', 'Consolidated Framework for Implementation Research', 'Critical Illness', 'Data', 'Data Science', 'Diffusion of Innovation', 'Environment', 'Evidence based practice', 'Goals', 'Health', 'Healthcare Systems', 'Height', 'High Prevalence', 'Hypoxemia', 'Individual', 'Inflammatory', 'Intensive Care Units', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Medical center', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Nurses', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Professional Organizations', 'Pulmonary Edema', 'Research', 'Severities', 'Speed', 'Structure', 'Surveys', 'Syndrome', 'System', 'Testing', 'Tidal Volume', 'Variant', 'base', 'community setting', 'complex data', 'computer science', 'dissemination research', 'effective therapy', 'experimental study', 'health care settings', 'implementation research', 'implementation science', 'implementation strategy', 'lung injury', 'machine learning method', 'mortality', 'multidisciplinary', 'novel', 'respiratory', 'response', 'theories', 'ventilation']",NHLBI,NORTHSHORE UNIVERSITY HEALTHSYSTEM,R01,2021,680901
"Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome Addiction is a highly complex disease with risk factors that include genetic variants and differences in development, sex, and environment. The long term potential of precision medicine to improve drug treatment and prevention depends on gaining a much better understanding how genetics, drugs, brain cells, and neuronal circuitry interact to influence behavior. There are serious technical barriers that prevent researchers and clinicians from incorporating more powerful computational and predictive methods in addiction research. The purpose of the NIDA P30 Core Center of Excellence in Omics, Systems Genetics, and the Addictome is to empower and train researchers supported by NIH, NIDA, NIAAA, and other federal and state institutions to use more quantitative and testable ways to analyze genetic, epigenetic, and the environmental factors that influence drug abuse risk and treatment. In the Transcriptome Informatics and Mechanisms research core we assemble and upgrade hundreds of large genome (DNA) and transcriptome (RNA) datasets for experimental rodent (rat) models of addiction. In the Systems Analytics and Modeling research core, we are using innovative systems genetics methods (gene mapping) to understand the linkage between DNA differences, environmental risks such as stress, and the differential risk of drug abuse and relapse. Our Pilot core is catalyzing new collaborations among young investigator in the field of addiction research. In sum the Center is a national resource for more reproducible research in addiction. We are centralizing, archiving, distributing, analyzing and integrating high quality data, metadata, using open software systems in collaboration with many other teams of researchers. Our goal is to help build toward an NIDA Addictome Portal that will include all genomic research relevant to addiction research. PROJECT NARRATIVE The NIDA Core Center of Excellence in Omics, Systems Genetics, and the Addictome (OSGA) provides genomic and computational support to a large number of research scientists working on mechanisms and treatment of addiction. The two main research cores of OSGA are providing support for transcriptome, epigenome, and metagenome studies of rat models of addiction at many levels of analysis. We are also creating open access tools and a powerful web portal to catalyze more effective and replicable use of massive datasets generated by programs in addiction biology and treatment.","Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome",10177978,P30DA044223,"['Archives', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Bioinformatics', 'Biology', 'Biometry', 'Cellular Assay', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consult', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Interactions', 'Drug abuse', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Institution', 'Joints', 'Leadership', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences Research', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Prevention', 'Proteome', 'Publications', 'Publishing', 'Quantitative Genetics', 'Quantitative Trait Loci', 'RNA', 'Rattus', 'Relapse', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rodent', 'Role', 'Scientist', 'Site', 'Standardization', 'Statistical Models', 'Stress', 'Sum', 'System', 'Systems Analysis', 'Testing', 'Training', 'Translations', 'United States National Institutes of Health', 'Update', 'Variant', 'Visualization', 'Work', 'addiction', 'archive data', 'archived data', 'base', 'behavior influence', 'brain cell', 'career', 'cohort', 'computerized tools', 'computing resources', 'data integration', 'data modeling', 'data repository', 'data tools', 'deep learning', 'digital imaging', 'drug relapse', 'epigenome', 'experience', 'genetic analysis', 'genetic variant', 'genomic variation', 'graphical user interface', 'health record', 'high dimensionality', 'image archival system', 'improved', 'innovation', 'insight', 'metagenome', 'mouse model', 'multiple omics', 'neurogenomics', 'neuronal circuitry', 'novel', 'precision medicine', 'prevent', 'programs', 'ranpirnase', 'rat genome', 'sex', 'single cell analysis', 'software systems', 'tool', 'transcriptome', 'transcriptomics', 'web portal']",NIDA,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,P30,2021,744955
"Genetic Privacy and Identity in Community Settings - GetPreCiSe Genetic Privacy and Identity in Community Settings (GetPreCiSe), is an NHGRI Center of Excellence in ELSI Research (CEER) that, in its first four years, established an environment for multi-disciplinary study that produced innovative ways of studying genetic privacy and identity. Specifically, the center 1) parsed the concept of genetic privacy into its often conflated constituent components, including: the “right to be let alone,” control and governance of data, and concerns about downstream uses of data; 2) documented and critically assessed the privacy practices of direct to consumer genetic testing (DTC-GT) companies; 3) examined how and why people trade off personal privacy for other social goods and services; 4) used new techniques to explore how film, television, and social media reflect and affect public perceptions of genetic privacy; and 5) refined understanding of the risk that people will be re-identified from their genomic information. During this time, many developments raised new issues of privacy and identity for genetics. First is the growth of DTC-GT, which generates genetic information used to trace ancestry, acquire health information, find relatives, uncover parentage, and pursue law enforcement investigations, among other activities. Second, laws and regulations governing data privacy and security, particularly with respect to genomics, are changing rapidly in the U.S. and abroad. These often conflict and present new challenges as genomic data move across state and international borders. Third, the creation of ever larger cohorts, such as the NIH’s All of Us Research Program, raises further dilemmas because some or all of the genomic and other data participants provide will be made available to investigators working in a variety of settings and subject to different regulatory regimes. Moreover, participants in these studies may receive research results, which could be deposited in their electronic health records, making this data subject to clinical regulation and compelling action by clinical providers who may not have the knowledge or infrastructure to respond. Thus, as our understanding of genomics increases, so, too, do its multifarious roles and implications for individuals, families, and society evolve. Given the evolving landscape, in its next four years GetPreCiSe will address three complementary specific aims: 1) Apply multimodal methods to characterize how social practices affect, and are affected by, evolving notions of genetic privacy and identity and increased availability of data, 2) Characterize how emerging legal and regulatory frameworks influence genomic privacy and identity in the US and abroad, and 3) Engineer and evaluate new technologies and quantitative frameworks that have potential to intrude on, but also protect, genetic privacy and identity. Recognizing that genetic data processing opportunities and threats are evolving, GetPreCiSe is designed to be a multi-disciplinary center, focused on training the next generation of ELSI researchers, with sufficient agility to respond to emerging issues. We anticipate these aims will need to be refined, and possibly pivoted, over the next four years and so stand ready to seed new investigations into emerging issues and compose new teams for investigation as needed. The incorporation of genetics and genomics into medical care and the public domain raises new challenges for how we understand privacy and identity, concepts that have long been closely linked in American discourse. The Genetic Privacy and Identity in Community Settings (GetPreCiSe), an NHGRI Center of Excellence in Ethical, Legal, and Social Implications Research (CEER) will 1) characterize how social practices and genetic data access affect notions of genetic privacy and identity, 2) assess the impact of emerging laws and regulatory frameworks in the US and abroad, and 3) gauge how new technologies compromise but also uphold protections.",Genetic Privacy and Identity in Community Settings - GetPreCiSe,10256016,RM1HG009034,"['Address', 'Advertising', 'Affect', 'Age', 'All of Us Research Program', 'American', 'Area', 'Artificial Intelligence', 'Arts', 'Behavior', 'Big Data', 'CCL4 gene', 'California', 'Caring', 'Clinical', 'Clinical Research', 'Communities', 'Conceptions', 'Conflict (Psychology)', 'Data', 'Data Collection', 'Data Protection', 'Data Security', 'Deposition', 'Development', 'Electronic Health Record', 'Engineering', 'Environment', 'European Union', 'Family', 'Film', 'Gender', 'Genetic', 'Genetic Identity', 'Genetic Models', 'Genetic Privacy', 'Genetic study', 'Genomics', 'Growth', 'Health', 'Imagination', 'Individual', 'Infrastructure', 'International', 'Internet', 'Investigation', 'Knowledge', 'Law Enforcement', 'Laws', 'Legal', 'Link', 'Literature', 'Medical', 'Methods', 'Modeling', 'National Human Genome Research Institute', 'Newspapers', 'Participant', 'Perception', 'Policies', 'Privacy', 'Provider', 'Public Domains', 'Publications', 'Race', 'Radio', 'Regulation', 'Research', 'Research Personnel', 'Risk', 'Role', 'Seeds', 'Services', 'Social Network', 'Social Sciences', 'Societies', 'Technology', 'Television', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Use of New Techniques', 'Visual', 'Work', 'base', 'behavior influence', 'behavioral economics', 'blockchain', 'cohort', 'community setting', 'computerized data processing', 'data access', 'data privacy', 'data sharing', 'design', 'ethical legal social implication', 'genetic information', 'genetic testing', 'genomic data', 'innovation', 'insight', 'interest', 'legal implication', 'minimal risk', 'multidisciplinary', 'multimodality', 'new technology', 'news', 'next generation', 'sex', 'social', 'social media']",NHGRI,VANDERBILT UNIVERSITY MEDICAL CENTER,RM1,2021,1051733
"PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally. However, a vital step for EHR-based research is valid, accurate, and reliable phenotyping (i.e., correctly identifying individuals with a particular trait of interest). Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. However, each requires an extensive investment of time and resources to develop due to the heterogeneity, complexity, inaccuracy, and frequent fragmentation of EHRs. The lack of general, automatic, and portable approaches to enable accurate high- throughput phenotyping is a critical barrier that hampers our ability to leverage valuable clinical data in EHRs for better healthcare. We propose a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that we have developed from public resources and will further refine and implement across various EHRs. We recognize that mass information about phenotypes is often described in significant detail and continuedly accumulated within publicly available resources (e.g., MedlinePlus and Wikipedia). We hypothesize this information can be retrieved, filtered, organized, measured, and formalized into standard EHR phenotype profiles. Indeed, we have used such an ensemble approach to integrate four generalizable online medication resources (e.g., SIDER and RxNorm) to create MEDI--a resource linking 2,136 medications and 13,304 indications. In preliminary studies, we extended this strategy to phenotyping and created a prototype PheMAP. For each phenotype, we identified relevant clinical concepts and weighted each based on its importance to the phenotype. We then mapped all associated concepts to commonly-used clinical terminologies. Our preliminary studies showed an average consistency of 98.6%±0.8% between our early-stage PheMAP and three validated eMERGE algorithms (Type 2 Diabetes, dementia, and hypothyroidism). We seek support to refine and optimize PheMAP and develop tools to allow researchers to implement PheMAP efficiently in different EHRs. This will allow researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention. Since PheMAP is created using independent resources that are more generalizable than a local clinical dataset, the implementation will generate more consistent outcomes in different EHRs for large-scale analyses.The work we propose is a necessary step toward being able to conduct high-throughput genome-wide and phenome-wide association analyses (GWASs and PheWASs). We will use data from multiple biobanks to accomplish these tasks. Specifically, we will achieve the following goals in this grant: 1.refine PheMAP and conduct large-scale validation, 2. implement PheMAP and perform representative GWASs and PheWASs, 3. Use PheMAP to conduct GWASs for unstudied or understudied diseases and phenotypes, and 4. Share PheMAP to facilitate research using EHRs. Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally while a vital step for EHR-based research is valid, accurate, and reliable phenotyping. Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. We propose to refine, validate, and share a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that allows researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention.","PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping",10095131,R01GM139891,"['Algorithms', 'Benchmarking', 'Biological', 'Catalogs', 'Clinical', 'Clinical Data', 'Data', 'Data Set', 'Dementia', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Environment', 'Evaluation', 'Genes', 'Genotype', 'Goals', 'Grant', 'Healthcare', 'Heritability', 'Heterogeneity', 'Human', 'Hypothyroidism', 'Individual', 'Institution', 'Intervention', 'Investments', 'Knowledge', 'Left', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Medical center', 'MedlinePlus', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Sensorineural Hearing Loss', 'Signal Transduction', 'Site', 'Statistical Models', 'Terminology', 'Time', 'Validation', 'Work', 'base', 'biobank', 'biomedical ontology', 'clinically relevant', 'cost', 'data modeling', 'disease phenotype', 'experience', 'genome wide association study', 'genome-wide', 'implementation tool', 'interest', 'novel', 'off-label drug', 'off-label use', 'phenome', 'phenotyping algorithm', 'portability', 'prototype', 'tool', 'trait']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,432500
"Integrating genomic and clinical data to predict disease phenotypes using heterogeneous ensembles PROJECT SUMMARY Genomic and other “omic” profiles hold immense potential for advancing personalize/precision medicine by enabling the accurate prediction of disease phenotypes or outcomes for individual patients, which can be used by a clinician to design an appropriate plan of care. However, despite this potential, the actual impact of these omic profiles on disease phenotype prediction may be limited by the fact that even large cohorts collecting these data do not cover large enough numbers of individuals. In contrast, a variety of clinical data types, such as laboratory tests and physician notes, are routinely collected and studied for a much larger number of patients undergoing treatment for such diseases at medical centers. The abundance of these clinical data, and their complementarity with multi-omic data, offer an opportunity to advance personalized medicine by integrating these disparate types of data. However, this disparity in data formats, namely several omic profiles being structured, and several clinical data types, such as physician notes, being unstructured, poses challenges for this integration. An associated challenge due to this disparity is that different classes of computational methods are likely to be the most effective for predicting disease phenotypes from these clinical and omics datasets. These challenges pose barriers for current data integration methods to address this problem. Here, we propose an innovative approach to this integration by assimilating diverse base phenotype predictors inferred from individual clinical and omics datasets into heterogeneous ensembles. These ensembles, which have shown promise for several other computational genomics problems, can aggregate an unrestricted number and variety of base predictors, which is ideal for this integration problem. Specifically, we describe how existing heterogeneous ensemble methods for single datasets can be transformed and advanced to address the multiple clinical and omic dataset integration problem. In particular, we detail novel algorithms for improving these integrative ensembles by modeling and incorporating the inherent patient and dataset heterogeneity in these datasets. We also propose novel algorithms for leveraging the inherent complementarity among clinical and omic datasets, as well as an innovative approach for handling expected missing data, both with the goal of making ensemble phenotype predictors more accurate and applicable to patient cohorts. To assess the performance of this novel suite of data integration-oriented heterogeneous ensembles, we will validate their effectiveness for predicting asthma and Inflammatory Bowel Disease phenotypes in substantial patient cohorts with diverse omics and clinical datasets. We will publicly release efficient software implementations of the methods developed in this project to enable others to carry out similar analyses with other diverse data collections. Successful accomplishment of the proposed work will contribute to the advancement of personalized medicine through accurate individualized prediction of disease phenotypes. Predictive modeling is expected to become a cornerstone on the path to achieving precision/personalized medicine, as one of the key tasks here will be making individualized predictions of disease characteristics/phenotypes like subtype and risk of progression and/or recurrence. We propose several innovative computational algorithms for developing accurate predictive models that integrate diverse clinical and omic data, as well as several rigorous validation exercises that will demonstrate the capabilities of these models. Successful accomplishment of the proposed work will contribute to the advancement of personalized/precision medicine through more accurate individualized prediction of disease characteristics.",Integrating genomic and clinical data to predict disease phenotypes using heterogeneous ensembles,10218766,R01HG011407,"['Address', 'Algorithms', 'Asthma', 'Automobile Driving', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Disease', 'Disease Outcome', 'Docking', 'Effectiveness', 'Electronic Health Record', 'Encapsulated', 'Exercise', 'Genomics', 'Goals', 'Health', 'Individual', 'Inflammatory Bowel Diseases', 'Institution', 'Laboratories', 'Learning', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Medical center', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Molecular Profiling', 'Multiomic Data', 'Patients', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Recurrence', 'Research Personnel', 'Risk', 'Sampling', 'Structure', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Validation', 'Variant', 'Work', 'advanced disease', 'base', 'clinical phenotype', 'cohort', 'data format', 'data integration', 'deep learning', 'design', 'disease phenotype', 'diverse data', 'feature selection', 'flexibility', 'genomic data', 'heterogenous data', 'improved', 'individual patient', 'innovation', 'insight', 'member', 'multiple datasets', 'multiple omics', 'multitask', 'novel', 'novel strategies', 'outreach', 'patient population', 'personalized medicine', 'personalized predictions', 'precision medicine', 'predictive modeling', 'programs', 'rapid growth', 'repository', 'scale up', 'transcriptomics', 'vector']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,539951
"Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences Abstract A major approach in causal inference literature aimed at mitigating bias due to unmeasured confounding is the so- called instrumental variable (IV) design which relies on identifying a variable which (i) influences the treatment process, (ii) has no direct effect on the outcome other than through the treatment, and (iii) is independent of any unmeasured confounder. IV methods are very well developed and widely used in social and health science, although validity of IV inferences may not be reliable if any of required assumptions (i)-(iii) is violated. This proposal aims to develop (a) new IV methods robust to violation of any of (i)-(iii); (b) New negative control methods that can be used to detect and sometimes to nonparametrically account for unmeasured confounding bias; (c) New bracketing methods for partial inference about causal effects in comparative interrupted time series studies. The proposed methods will be used to address current scientific queries in three major substantive public health areas:(1) to understand the health effects of air pollution; (2) to quantify the causal effects of modifiable risk factors for Alzheimer's disease and related disorders; (3) To uncover the mechanism by which a randomized package of interventions produced a substantial reduction of HIV incidence in a recent major cluster randomized trial of treatment as prevention in Botswana, Africa. Our proposal will provide the best available analytical methods to date to resolve confounding concerns in these high impact public health applications and more broadly in observational studies in the health sciences. Summary This proposal aims to develop new causal inference methods to tame bias due to hidden confounding factors in obser- vational studies as well as in randomized experiments subject to non-adherence. The proposed methods are firmly grounded in modern semiparametric theory which will be used to obtain more robust and efficient inferences about causal effects in a broad range of public health applications including in Epidemiology of Aging, Environmental Health Epidemiology and HIV/AIDS Prevention.",Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences,10159821,R01AG065276,"['AIDS prevention', 'Address', 'Adherence', 'Africa', 'Aging', 'Air Pollution', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Area', 'Blood Pressure', 'Body mass index', 'Botswana', 'Cluster randomized trial', 'Data', 'Diabetes Mellitus', 'Disease', 'Environmental Health', 'Epidemiology', 'Genetic', 'HIV', 'Health', 'Health Sciences', 'Incidence', 'Interruption', 'Intervention', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Masks', 'Mendelian randomization', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Observational Study', 'Outcome', 'Participant', 'Process', 'Public Health', 'Public Health Applications Research', 'Randomized', 'Research Design', 'Research Personnel', 'Risk Factors', 'Series', 'Social Sciences', 'Testing', 'Thromboplastin', 'Time', 'ambient air pollution', 'analytical method', 'c new', 'comparative', 'design', 'experimental study', 'genetic variant', 'high dimensionality', 'intervention effect', 'modifiable risk', 'mortality', 'novel', 'pleiotropism', 'semiparametric', 'simulation', 'theories', 'treatment as prevention', 'treatment effect', 'uptake', 'user friendly software']",NIA,UNIVERSITY OF PENNSYLVANIA,R01,2021,468961
"Consortium for Immunotherapeutics against Emerging Viral Threats SUMMARY: OVERALL  This proposal, Consortium for Immunotherapeutics Against Emerging Viral Diseases, addresses a critical gap in the biodefense portfolio by building an academic-industry partnership to advance effective, fully human, antibody-based immunotherapeutics against three major families of emerging/re-emerging viruses: Lassa virus, Ebola and other Filoviruses, and mosquito-transmitted Alphaviruses that threaten millions worldwide. This program follows directly from our significant body of preliminary data (the largest available for these families of viruses), therapeutics in hand, multidisciplinary expertise, and demonstrated collaborative success. Included in the proposed CETR portfolio are: (1) the only available immunotherapeutics against endemic Lassa virus, with reversal of late-stage disease and complete survival in infected non-human primates, (2) novel Ebola and pan- ebolavirus therapeutics that also completely protect non-human primates from disease, and that were built by the paradigm-shifting and comprehensive analysis of a global consortium, and (3) much needed, first-in-class therapeutics against the re-emerging alphaviruses that have tremendous epidemic potential in the United States and around the globe. These multidisciplinary studies, founded upon pioneering structural biology of the antigen targets, include innovations such as agnostic, high-throughput Fc profiling and optimization, coupled with Fv evolution to enhance potency and developability, as well as a sophisticated statistical and computational analysis core to evaluate thresholds and correlates of protection across the major families of pathogens. Together, we aim to understand what findings represent general rules and what data are specific to each virus family. We also aim to provide streamlined systems for antibody choice and optimization that do not yet exist, and to build a broadly applicable platform for mAb discovery and delivery against any novel pathogen as they emerge. The recent resurgence of Lassa, the epidemic nature of Ebola virus and other re-emerging filoviruses, as well as the major population at risk by global movement of mosquito-borne alphaviruses together demonstrate the tremendous global need for immunotherapeutics developed and advanced by this program. NARRATIVE Three major families of emerging viruses (Lassa and other arenaviruses, Ebola and other filoviruses, and mosquito-borne alphaviruses) threaten human health worldwide, but lack approved therapeutics or vaccines. The proposed multidisciplinary consortium, an academic-industry partnership, will advance safe and effective, fully human, monoclonal antibody therapies against these viruses, using candidate therapies that confer complete protection in non-human primates as our starting point. Our collaborative databases, multivariate analyses and innovative antibody optimization strategies will establish platforms for discovery and delivery of much-needed treatments against these and other infectious diseases.",Consortium for Immunotherapeutics against Emerging Viral Threats,10158446,U19AI142790,"['Address', 'Alphavirus', 'Antibodies', 'Antigen Targeting', 'Arenavirus', 'Arthritogenic', 'Biological Assay', 'Communicable Diseases', 'Computer Analysis', 'Computer Models', 'Computing Methodologies', 'Coupled', 'Culicidae', 'Data', 'Databases', 'Developed Countries', 'Developing Countries', 'Disease', 'Ebola', 'Ebola virus', 'Epidemic', 'Evolution', 'Family', 'Filovirus', 'Fostering', 'Goals', 'Hand', 'Health', 'Human', 'Immune', 'Immunotherapeutic agent', 'Lassa virus', 'Machine Learning', 'Mathematics', 'Mediating', 'Monoclonal Antibodies', 'Monoclonal Antibody Therapy', 'Movement', 'Multivariate Analysis', 'Nature', 'Populations at Risk', 'Primate Diseases', 'Reagent', 'Research Project Grants', 'Resources', 'Statistical Data Interpretation', 'System', 'Talents', 'Testing', 'Therapeutic', 'Therapeutic Monoclonal Antibodies', 'Translating', 'Translations', 'United States', 'Vaccines', 'Viral', 'Virus', 'Virus Diseases', 'base', 'biodefense', 'chikungunya', 'clinical development', 'design', 'experience', 'human monoclonal antibodies', 'improved', 'industry partner', 'innovation', 'insight', 'mosquito-borne', 'multidisciplinary', 'nonhuman primate', 'novel', 'pandemic disease', 'pathogen', 'programs', 'research study', 'structural biology', 'success', 'synergism', 'tool']",NIAID,LA JOLLA INSTITUTE FOR IMMUNOLOGY,U19,2021,7065330
"Estimating Mediation Effects in Prevention Studies The purpose of this competing continuation grant proposal is to develop, evaluate and apply  methodological and statistical procedures to investigate how prevention programs change outcome  variables. These mediation analyses assess the link between program effects on the constructs targeted  by a prevention program and effects on the outcome. As noted by many researchers and federal  agencies, mediation analyses identify the most effective program components and increase  understanding of the underlying mechanisms leading to changing outcome variables. Information from  mediation analysis can make interventions more powerful, more efficient, and shorter. The P. I. of this grant received a one-year NIDA small grant and four multi-year grants to develop and evaluate mediation  analysis in prevention research. This work led to many publications and innovations. The proposed  five-year continuation focuses on the further development and refinement of exciting new mediation  analysis statistical developments. Four statistical topics represent next steps in this research and include  analytical and simulation research as well as applications to etiological and prevention data. The work expands on our development of causal mediation and Bayesian mediation methods that hold great promise for mediation analysis. In Study 1, practical causal mediation and Bayesian mediation analyses  for research designs are developed and evaluated. This approach will clarify methods and develop  approaches for dealing with violation of testable and untestable assumptions. Study 2 investigates  important measurement issues for the investigation of mediation. This work will focus on methods to identify critical facets of mediating variables, approaches to understanding whether mediators and  outcomes are redundant, and develop methods for studies with big data. Study 3 continues the development and evaluation of new longitudinal mediation methods for ecological momentary assessment data and other studies with massive data collection. These new methods promise to more accurately model change over time for both individuals and groups of individuals. Study 4 develops methods to  uncover subgroups in mediation analysis including causal mediation methods, multilevel models, and new  approaches based on residuals for identifying individuals for whom mediating processes differ in  effectiveness from other individuals. For each study, we will investigate unique issues with mediation analysis of prevention data including methods for small N and also massive data collection (big data), the RcErLitEicVaANl rCoEle(Soeef imnsetruacstiounrse):ment for mediating mechanisms, and the application of the growing literature on  causal methods and Bayesian methods. Study 5 applies new statistical methods to data from several NIH  The project further develops a method, statistical mediation analysis, that extracts more information from  funded prevention studies providing important feedback about the usefulness of the methods. Study 6  research. Mediation analysis explains how and why prevention and treatments are successful. Mediation  disseminates new information about mediation analysis through our website and other media, by  analysis improves prevention and treatment so that their effects are greater and even cost less. communication with researchers, and publications from the project. n/a",Estimating Mediation Effects in Prevention Studies,10168488,R37DA009757,"['Address', 'Applications Grants', 'Bayesian Method', 'Behavioral Mechanisms', 'Big Data', 'Biological Models', 'Communication', 'Complex', 'Consultations', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Ecological momentary assessment', 'Educational workshop', 'Effectiveness', 'Etiology', 'Evaluation', 'Feedback', 'Funding', 'Grant', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Outcome', 'Persons', 'Prevention', 'Prevention Research', 'Prevention program', 'Principal Investigator', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Residual state', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Work', 'base', 'computer program', 'cost', 'data space', 'design', 'dynamic system', 'improved', 'innovation', 'interest', 'longitudinal design', 'model design', 'multilevel analysis', 'novel strategies', 'programs', 'simulation', 'substance use treatment', 'successful intervention', 'theories', 'therapy design', 'tool', 'treatment research', 'web site']",NIDA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R37,2021,360584
"Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation Project Summary/Abstract: With the surge of large genomics data, there is an immense increase in the breadth and depth of different omics datasets and an increasing importance in the topic of privacy of individuals in genomic data science. Detailed genetic and environmental characterization of diseases and conditions relies on the large-scale mining of functional genomics data; hence, there is great desire to share data as broadly as possible. However, there is a scarcity of privacy studies focused on such data. A key first step in reducing private information leakage is to measure the amount of information leakage in functional genomics data, particularly in different data file types. To this end, we propose to to derive information-theoretic measures for private information leakage in different data types from functional genomics data. We will also develop various file formats to reduce this leakage during sharing. We will approach the privacy analysis under three aims. First, we will develop statistical metrics that can be used to quantify the sensitive information leakage from raw reads. We will systematically analyze how linking attacks can be instantiated using various genotyping methods such as single nucleotide variant and structural variant calling from raw reads, signal profiles, Hi-C interaction matrices, and gene expression matrices. Second, we will study different algorithms to implement privacy-preserving transformations to the functional genomics data in various forms. Particularly, we will create privacy-preserving file formats for raw sequence alignment maps, signal track files, three-dimensional interaction matrices, and gene expression quantification matrices that contain information from multiple individuals. This will allow us to study the sources of sensitive information leakages other than raw reads, for example signal profiles, splicing and isoform transcription, and abnormal three-dimensional genomic interactions. Third, we will investigate the reads that can be mapped to the microbiome in the raw human functional genomics datasets. We will use inferred microbial information to characterize private information about individuals, and then combine the microbial information with the information from human mapped reads to increase the re-identification accuracy in the linking attacks described in the second aim. We will use the tools to quantify the sensitive information and privacy-preserving file formats in the available datasets from large sequencing projects, such as the ENCODE, The Cancer Genome Atlas, 1,000 Genomes, gEUVADIS, and Genotype-Tissue Expression projects. Project Narrative: Sharing large-scale functional genomics data is critical for scientific discovery, but comes with important privacy concerns related to the possible misuse of such data. This proposal will quantify and manage the rieslkasted to releasing functional genomics datasets, based on integrating inferred genotypes from the raw sequence files, signal tracks, and microbiome mapped sequences. Finally, we will develop file formats, statistical methodologies, and related software for anonymization of functional genomics data that enable open sharing.",Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation,10251876,R01HG010749,"['3-Dimensional', 'Address', 'Algorithms', 'Assessment tool', 'Biology', 'ChIP-seq', 'Code', 'Computer software', 'Consent', 'DNA sequencing', 'Data', 'Data Files', 'Data Science', 'Data Set', 'Databases', 'Diet', 'Disease', 'Environment', 'Equilibrium', 'Extravasation', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Glean', 'Hi-C', 'Human', 'Individual', 'Institutes', 'Laws', 'Learning', 'Letters', 'Life Style', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Mining', 'Motivation', 'Participant', 'Patients', 'Phenotype', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Protein Isoforms', 'Protocols documentation', 'Provider', 'Pythons', 'Quantitative Trait Loci', 'RNA Splicing', 'Research Personnel', 'Risk', 'Risk Assessment', 'Sampling', 'Sequence Alignment', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Smoker', 'Source', 'Structure', 'Techniques', 'The Cancer Genome Atlas', 'Tissues', 'Variant', 'base', 'clinically relevant', 'computerized data processing', 'data mining', 'data sharing', 'experimental study', 'file format', 'functional genomics', 'genome sequencing', 'genomic data', 'human tissue', 'interest', 'large datasets', 'microbial', 'microbiome', 'open data', 'privacy preservation', 'social', 'tool', 'transcriptome sequencing']",NHGRI,YALE UNIVERSITY,R01,2021,526482
"Construal level as a novel pathway for affect regulation and cancer control 7. Project Summary/Abstract Lung cancer is the leading major cause of preventable death in the United States, and cigarette smoking is a contributor to lung cancer in 80%–90% of cases. Though adult cigarette smoking rates have declined substantially during the past 50 years, they remain as high as 30% in certain groups, such as individuals living in poverty. Quitting is difficult: a given quit attempt results in cessation in fewer than 10% of cases, and most adult cigarette smokers have attempted and failed to quit, and often many times. What is urgently needed are novel interventions for cigarette smoking cessation that operate through different mechanisms from those targeted by existing interventions, which are likely to have been unsuccessful for persistent smokers. A barrier to progress is that the mechanisms of action of most treatments are not known, which makes it difficult to know which treatment will work best for whom. We turn to affective science to identify a candidate technique that could serve as the basis for a novel intervention. Research on affect regulation typically focuses on down- regulation of affective states, such as craving for cigarettes, using effortful strategies such as cognitive reappraisal. However, a new insight in affect regulation is that people can construe, or subjectively understand, events with varying levels of abstraction, and that construing health-related behaviors in high- versus low-level terms promotes health behavior in several domains. For example, smokers who want to quit are more likely to resist a cigarette when they construe the same event (e.g., “abstinence”) in more abstract, high-level terms (e.g., “becoming a better me”) versus more concrete, low-level terms (e.g., “not smoking this cigarette”). There is some evidence that high-level construal might rely on distinct mechanisms from traditional affect regulation and smoking reduction interventions, but its mechanisms of action are unknown. Directly comparing its mechanisms to those of alternative affect regulation strategies and developing tools to induce high-level construal are the next steps on the path toward developing a novel intervention. Also, establishing individual differences in the effects of high-level construal will allow future interventions to be targeted to the individuals for whom they will be maximally effective. We identified two candidate mechanisms through which high-level construal might operate: down-regulation of craving and up-regulation of goal energization (i.e., motivation to quit). Functional magnetic resonance imaging (fMRI) revealed the neural systems engaged by those processes to be distinct. So, we will use multivariate analyses of fMRI data to quantify the similarity of high-level construal to each candidate (Aim 1). This will be done in a longitudinal translational experiment with 4 conditions—high- level construal, down-regulation of craving, up-regulation of goal energization, and treatment-as-usual—in a sample of persistent smokers in poverty, who are the most likely to benefit from a novel, theory-based treatment. The sample size (N = 240) affords an examination of individual differences in the effect of high-level construal on neural activity and craving, and the degree to which they predict smoking reduction (Aim 2). 8. Project Narrative Cigarette smoking is among the leading causes of preventable death in the United States because smoking increases risk for lung cancer and various diseases. Though U.S. smoking rates have declined, a substantial percentage of adults, particularly those living in poverty who have repeatedly tried and failed to quit, still smoke and therefore could benefit from novel interventions for cessation that operate through different mechanisms than those of traditional treatments. This study will use neuroimaging to uncover the mechanisms of action of a promising strategy for affect regulation and smoking cessation and also build profiles of individuals for whom this strategy does and does not work, thereby providing tangible and practical information that public health professionals and clinicians can use to inform personalized treatments for cigarette smoking cessation.",Construal level as a novel pathway for affect regulation and cancer control,10127602,R01CA240452,"['Abstinence', 'Adult', 'Affect', 'Affective', 'Behavior', 'Cancer Control', 'Centers for Disease Control and Prevention (U.S.)', 'Cigarette', 'Cigarette Smoker', 'Data', 'Decision Making', 'Disease', 'Down-Regulation', 'Event', 'Fire - disasters', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health Professional', 'Health Promotion', 'Health behavior', 'Individual', 'Individual Differences', 'Informal Social Control', 'Intervention', 'Knowledge', 'Lateral', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medial', 'Motivation', 'Multivariate Analysis', 'Neurophysiology - biologic function', 'Participant', 'Pathway interactions', 'Pattern', 'Personality Traits', 'Persons', 'Poverty', 'Process', 'Provider', 'Psychology', 'Public Health', 'Regulation', 'Reporting', 'Research', 'Risk', 'Sample Size', 'Sampling', 'Scanning', 'Science', 'Smoke', 'Smoker', 'Smoking', 'Stimulus', 'System', 'Techniques', 'Testing', 'Theoretical model', 'Time', 'Training', 'Triage', 'United States', 'Up-Regulation', 'Work', 'arm', 'base', 'cigarette craving', 'cigarette smoking', 'cognitive process', 'cognitive reappraisal', 'cost', 'craving', 'efficacy trial', 'experience', 'experimental study', 'fighting', 'insight', 'lens', 'neuroimaging', 'neuromechanism', 'novel', 'personalized medicine', 'personalized strategies', 'preventable death', 'relating to nervous system', 'response', 'smoking cessation', 'theories', 'tobacco control', 'tool', 'treatment as usual', 'treatment response']",NCI,UNIVERSITY OF OREGON,R01,2021,595543
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,10085664,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'detection limit', 'disease phenotype', 'driver mutation', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'machine learning method', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistical learning', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,305167
"Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics Project Summary/Abstract Viral genome sequencing is growing exponentially and cutting-edge molecular technologies, guided by genomic data, show great promise in detecting and responding to viruses. Yet we lack a computational framework that efficiently leverages viral data to design the nucleic or amino acid sequences applied by these technologies. The proposal provides a career development plan to (i) build computational techniques — algorithms, models, and software — that yield highly accurate diagnostic assays, with potential to outperform existing ones, and (ii) use the techniques to proactively design assays for detecting 1,000s of viruses. The project will first develop methods for designing optimal viral genome-informed diagnostics. The study will formulate objective functions that evaluate an assay’s performance across a distribution of anticipated viral targets. Combinatorial optimization algorithms and generative models, constructed in the study, will optimize the functions. The project will also develop datasets for training predictive models of assay performance, which are used in the objective functions, focusing on CRISPR-, amplification-, and antigen-based diagnostics. Preliminary experimental results suggest such models can render assays with exquisite sensitivity and specificity. The study will compare the algorithmically-designed assays to state-of-the-art tests for four viruses. With these methods, the project will design diagnostic assays that are species-specific and broadly effective across genomic diversity for all viruses known to infect vertebrates. The study will build a system to monitor the assays’ effectiveness against emerging viral genomic diversity and to continually update them as needed. To enable the broad adoption of these methods, the project will implement them efficiently in accessible software. The proposal aligns with a NIAID goal of improving diagnostics via data science. The methods developed here may also aid therapy and vaccine design, and will leave the world better prepared to combat viral outbreaks. The career development award will provide training for the candidate in applied areas of long-term interest to his career. The candidate has previous experience in developing computational methods and analyzing viral genomes. Through the award, he will gain new knowledge and skills in diagnostic applications, alongside formal and informal training in immunology, bioengineering, and related laboratory techniques. This training will help the candidate progress toward therapy and vaccine applications that could benefit from advanced computational methods. The Broad Institute provides a supportive environment for the candidate’s development, including career development workshops, research seminars aligned with the proposed plan, and opportunities to initiate collaborations with scientists having expertise complementary to the candidate’s. The research and training will help him form an independent research group focused on developing and applying computational methods to enable more effective microbial surveillance and response. Project Narrative Viral genomic data is reshaping how we prepare for and respond to viral threats, but there is a scarcity of computational techniques that harness this vast, ever-growing data for designing diagnostic assays. The project will develop and test algorithms, machine learning models, and software systems to efficiently design highly accurate diagnostic assays by optimizing well-defined objective functions, applied to multiple diagnostic technologies, and will build a resource of broadly effective diagnostic assays for 1,000s of viral species. The resource and software developed in the project will advance capabilities for detecting viruses, and the new methods may accommodate challenges in designing more effective viral therapies and vaccines.",Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics,10284445,K01AI163498,"['2019-nCoV', 'Adoption', 'Algorithm Design', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Award', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Biomedical Engineering', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Combinatorial Optimization', 'Computational Technique', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Dengue', 'Detection', 'Development', 'Development Plans', 'Diagnostic', 'Disease Outbreaks', 'Educational workshop', 'Effectiveness', 'Ensure', 'Failure', 'Focus Groups', 'Genome', 'Genomics', 'Goals', 'Growth', 'Immunology', 'Influenza', 'Institutes', 'K-Series Research Career Programs', 'Knowledge', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nucleic Acids', 'Performance', 'Research', 'Research Training', 'Resolution', 'Resources', 'Scientist', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Validation', 'Variant', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'ZIKA', 'accurate diagnostics', 'advanced analytics', 'antigen diagnostic', 'base', 'career', 'career development', 'combat', 'computer framework', 'design', 'detection assay', 'diagnostic assay', 'diagnostic technologies', 'enzyme activity', 'experience', 'genome sequencing', 'genomic data', 'improved', 'insight', 'interest', 'microbial', 'model design', 'pathogen', 'predictive modeling', 'predictive test', 'prevent', 'response', 'skills', 'software development', 'software systems', 'spatiotemporal', 'success', 'supportive environment', 'therapy design', 'viral genomics']",NIAID,"BROAD INSTITUTE, INC.",K01,2021,129165
"Deep learning based antibody design using high-throughput affinity testing of synthetic sequences Project Summary We will develop and apply a new high-throughput methodology for rapidly designing and testing antibodies for a myriad of purposes, including cancer and infectious disease immunotherapeutics. We will improve upon current approaches for antibody design by providing time, cost, and humane benefits over immunized animal methods and greatly improving the power of present synthetic methods that use randomized designs. To accomplish this, we will display millions of computationally designed antibody sequences using recently available technology, test the displayed antibodies in a high-throughput format at low cost, and use the resulting test data to train molecular dynamics and machine learning methods to generate new sequences for testing. Based on our test data our computational method will identify sequences that have ideal properties for target binding and therapeutic efficacy. We will accomplish these goals with three specific aims. We will develop a new approach to integrated molecular dynamics and machine learning using control targets and known receptor sequences to refine our methods for receptor generalization and model updating from observed data (Aim 1). We will design an iterative framework intended to enable identification of highly effective antibodies within a minimal number of experiments, in which our methods automatically propose promising antibody sequences to profile in subsequent assays (Aim 2). We will employ rounds of automated synthetic design, affinity test, and model improvement to produce highly target-specific antibodies. (Aim 3). ! Project Narrative We will develop new computational methods that learn from millions of examples to design antibodies that can be used to help cure a wide variety of human diseases such as cancer and viral infection. Previous antibody design approaches used a trial and error approach to find antibodies that worked well. In contrast our mathematical methods will directly produce new antibody designs by learning from large-scale experiments that test antibodies for function against disease targets. !",Deep learning based antibody design using high-throughput affinity testing of synthetic sequences,10116306,R01CA218094,"['Affinity', 'Animals', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Binding', 'Biological Assay', 'Budgets', 'Classification', 'Cloud Computing', 'Communicable Diseases', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Fc Receptor', 'Goals', 'Human', 'Immunize', 'Immunotherapeutic agent', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Modeling', 'Molecular Machines', 'Oligonucleotides', 'Output', 'Performance', 'Phage Display', 'Property', 'Randomized', 'Research', 'Services', 'Specific qualifier value', 'Specificity', 'Statistical Models', 'Technology', 'Test Result', 'Testing', 'Therapeutic', 'Thinness', 'Time', 'Training', 'Treatment Efficacy', 'Update', 'Virus Diseases', 'Work', 'antibody test', 'base', 'cloud based', 'commercialization', 'computing resources', 'cost', 'deep learning', 'design', 'experimental study', 'human disease', 'improved', 'iterative design', 'learning strategy', 'machine learning method', 'mathematical methods', 'molecular dynamics', 'novel', 'novel strategies', 'outcome prediction', 'predictive test', 'receptor']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,591130
"Using Machine Learning to Develop Just-in-Time Adaptive Interventions for Smoking Cessation PROJECT SUMMARY Mobile technology has enormous potential for delivering highly innovative, dynamic smoking cessation interventions. Phone sensors, wearable technology, and real time data collection methods such as ecological momentary assessment (EMA) have made it possible to collect a wealth of environmental and physiological data such as location, heart rate, and mood. Environmental and situational cues such as craving and proximity to others smoking are highly predictive of lapse among those trying to quit, suggesting that lapse risk is characterized by immediate, dynamic influences. Emerging strategies such as just-in-time adaptive interventions (JITAI), aim to prevent smoking lapse using tailored support delivered via mobile technology in the moments when it is most needed. Although research has identified antecedents of smoking lapse based on observations from EMA data, studies have been unable to utilize the full spectrum of contextual and environmental data available with current technology. Given the importance of dynamic influences on lapse risk, there is a critical need for strategies that accurately identify moments of highest lapse risk to improve cessation interventions. Recent research has demonstrated the utility of machine learning to predict individual behavior. Machine learning is a robust data analytic strategy that can produce highly accurate predictive models from large datasets and can automatically adapt to new data in real time. The overall objective of this application is to use supervised machine learning methods to develop an automated algorithm to quantify smoking lapse risk at the individual level. Specifically, we aim: 1) to apply supervised machine learning methods to quantify personalized risk of smoking lapse, and 2) to evaluate the feasibility and preliminary effectiveness of delivering a personalized, just-in-time adaptive intervention driven by machine learning prediction of smoking lapse risk in real time. The proposed research and training plan will take place at The University of Oklahoma Health Sciences Center (OUHSC) and the Stephenson Cancer Center (SCC). Training will focus on increasing knowledge of machine learning methodology, and the conduct and analysis of JITAIs, which will facilitate completion of the proposed project. Results of the proposed research have the potential to reduce the amount and frequency of data needed from participants and sensors, enabling the development of less burdensome interventions. It is expected that completion of these aims will yield preliminary data to inform an automated, dynamic intervention that fully utilizes the strengths of mobile technology for measuring individual behavior and environmental context in real time. PROJECT NARRATIVE The proposed project will be among the first to use machine learning methods to predict risk of individual smoking lapse in real time. The resulting algorithm will provide a personalized model for each participant that adapts to new data and triggers the delivery of a tailored, precision intervention when it is most needed. If successful, this project and its methodology could be adapted to target other health behaviors such as diet, physical activity, or other substance use disorders.",Using Machine Learning to Develop Just-in-Time Adaptive Interventions for Smoking Cessation,10294298,R00DA046564,"['Accelerometer', 'Address', 'Affect', 'Algorithms', 'Behavior', 'Cancer Center', 'Car Phone', 'Classification', 'Control Groups', 'Cues', 'Data', 'Data Analytics', 'Data Collection', 'Data Set', 'Demographic Factors', 'Development', 'Devices', 'Diet', 'Ecological momentary assessment', 'Effectiveness', 'Frequencies', 'Funding', 'Health Sciences', 'Health behavior', 'Heart Rate', 'Individual', 'Intervention', 'Knowledge', 'Life', 'Location', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Moods', 'Oklahoma', 'Participant', 'Patient Self-Report', 'Pattern', 'Physical activity', 'Physiological', 'Positioning Attribute', 'Randomized', 'Reporting', 'Research', 'Research Training', 'Risk', 'Sensitivity and Specificity', 'Smoking', 'Smoking Behavior', 'Smoking Cessation Intervention', 'Social Environment', 'Substance Use Disorder', 'System', 'Technology', 'Telephone', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Wrist', 'adaptive intervention', 'automated algorithm', 'base', 'craving', 'experience', 'improved', 'innovation', 'large datasets', 'machine learning algorithm', 'machine learning method', 'mobile application', 'mobile computing', 'personalized intervention', 'predictive modeling', 'prevent', 'psychologic', 'secondary analysis', 'sensor', 'standard care', 'supervised learning', 'trend', 'wearable device']",NIDA,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R00,2021,248999
"Causal machine learning methods for studying the effects of environmental exposures on childhood cancer using natural experiments Project Summary: My goal is to build an independent research program in the development of causal inference methods for investigating environmental causes of childhood cancer. This K01 will enable me to conduct the focused, intensive research that will lay the groundwork for that program and to acquire the environmental, biological, and epidemiological training needed to maximize the rigor and impact of my work. Research: We propose to develop new causal machine learning (ML) methods that enable rigorous analysis of environmental natural experiments (NE) for estimation of the causal effects of environmental exposures on childhood cancer. Classical approaches to studying relationships between environmental exposures and childhood cancer are plagued with challenges and are yielding inconsistent findings. We contend that the recent proliferation of local environmental regulatory programs has created ample relevant NEs, which provide a powerful alternative approach to study these relationships. However, existing methods for NE analysis are poorly-suited for environmental health contexts. In particular, existing methods fail in the presence of rare outcomes like childhood cancer (Aim 1), and they are not able to provide insight into the timing at which children are most susceptible to any adverse exposure effects (Aim 2). We propose causal ML methods that overcome these challenges and apply them to a NE to study the effects of traffic-related air toxics on childhood leukemia. We also provide open source software implementing these methods (Aim 3). Career Development and Training: Given my extensive prior training and experience in statistics and data science, the primary aim of the training funded by this award will be the acquisition of subject-matter proficiency, which will provide me with the insights needed to create more effective and impactful environmental health methods. Specifically, I will pursue knowledge in the biology and epidemiology of childhood cancer and in environmental health and exposure biology. The training will be achieved through a combination of (1) hands-on collaborative research as described above; (2) intensive cross-disciplinary mentorship, with mentors specializing in environmental health, pediatric oncology, cancer biology and epidemiology, and statistics; (3) carefully-selected coursework in the Departments of Epidemiology, Environmental Health, and Cell Biology at Harvard; and (4) relevant conferences, workshops, and seminars. I will place special emphasis on establishing a network of expert collaborators in all my areas of training. Environment: The Harvard Medical Campus is home to the top research teams worldwide in both childhood cancer and environmental health. Due to Harvard’s position at the forefront of scientific discovery in these fields, its unparalleled resources, its vibrant intellectual atmosphere, and its promotion of collaborative science that integrates knowledge across disciplines, it provides an ideal environment in which to train on these topics. Project Narrative: Decades of research on the relationship between environmental exposures and childhood cancer, relying on classic epidemiologic study designs, has produced a largely inconclusive body of literature, and has generated little robust, actionable evidence to protect children’s health. We propose an alternative methodological approach to this problem, which relies on environmental natural experiments to overcome many of the challenges presented by classic approaches. We develop causal machine learning methods tailored to this setting, which provide a promising new avenue for obtaining robust evidence about environmental causes of childhood cancer, and we apply the methods to study the effects of exposure to traffic-related air toxics on childhood leukemia.",Causal machine learning methods for studying the effects of environmental exposures on childhood cancer using natural experiments,10104187,K01ES032458,"['1,3-Butadiene', 'Accounting', 'Address', 'Adult', 'Affect', 'Air', 'Area', 'Award', 'Bayesian learning', 'Benzene', 'Biological', 'Biology', 'Cancer Biology', 'Case-Control Studies', 'Cellular biology', 'Chemicals', 'Child', 'Child Health', 'Childhood Leukemia', 'Code', 'Cohort Studies', 'Communities', 'Computer software', 'Data', 'Data Science', 'Development', 'Discipline', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Exposure', 'Environmental Health', 'Epidemiology', 'Event', 'Exposure to', 'Foundations', 'Funding', 'Gasoline', 'Genetic', 'Goals', 'Health', 'Heterogeneity', 'Home environment', 'Incidence', 'Investigation', 'Knowledge', 'Learning', 'Literature', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Measures', 'Medical', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Natural experiment', 'Occupational Exposure', 'Outcome', 'Pediatric Oncology', 'Play', 'Positioning Attribute', 'Process', 'Regulation', 'Reproducibility', 'Research', 'Research Design', 'Resources', 'Risk Factors', 'Role', 'Science', 'Series', 'Social Sciences', 'Societies', 'Source', 'Time', 'Time trend', 'Training', 'United States Environmental Protection Agency', 'Work', 'cancer epidemiology', 'career development', 'educational atmosphere', 'environmental agent', 'epidemiology study', 'experience', 'health application', 'health data', 'innovation', 'insight', 'leukemia', 'machine learning method', 'mortality', 'neoplasm registry', 'open source', 'prenatal', 'programs', 'simulation', 'skills', 'statistics', 'symposium', 'tool', 'usability', 'user-friendly']",NIEHS,HARVARD SCHOOL OF PUBLIC HEALTH,K01,2021,138538
"Adaptive evolutionary inference frameworks for understudied populations using generative neural networks PROJECT SUMMARY In the field of population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, these algorithms rely heavily on simulated datasets, which currently fail to recapitulate the features of diverse natural genomes. Deep neural networks in particular are disconnected from evolutionary modeling, and their results are difficult to interpret in a biological context. In this project, we propose to develop simulation frameworks that automatically adapt to any population or species. The resulting customized synthetic datasets will be used to train neural networks that quantify the unique evolutionary histories of understudied human groups. By including genealogical and epigenetic information as auxiliary input, we will be able to link predictions back to genomic features. Our results will enable us to estimate the interactions between local phenomena such as natural selection, mutation patterns, and recombination hotspots. Taken together, outcomes from our work will allow us to create a detailed model evolutionary of processes, both along the genome and across human populations. PROJECT NARRATIVE In population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, it is difficult to apply these algorithms to understudied populations, as they are reliant on custom simulations, difficult to interpret, and disconnected from evolutionary modeling. The goals of this project are to develop simulation frameworks that automatically adapt to diverse datasets, allowing us to study evolutionary forces along the genome and across human populations.",Adaptive evolutionary inference frameworks for understudied populations using generative neural networks,10114449,R15HG011528,"['Admixture', 'African', 'Algorithms', 'Area', 'Back', 'Biological', 'Biological Process', 'Chromatin', 'Classification', 'Custom', 'Data', 'Data Set', 'Decision Trees', 'Epigenetic Process', 'European', 'Event', 'Evolution', 'Exposure to', 'Genealogy', 'Genes', 'Genetic Recombination', 'Genome', 'Genomic Segment', 'Genomics', 'Geography', 'Goals', 'Graph', 'Human', 'Human Genetics', 'Image', 'Individual', 'Industry', 'Internships', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Outcome', 'Pattern', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Recording of previous events', 'Research', 'Signal Transduction', 'Students', 'Training', 'Trees', 'Validation', 'Visualization', 'Work', 'automated algorithm', 'base', 'biobank', 'computer science', 'convolutional neural network', 'deep neural network', 'epigenetic marker', 'flexibility', 'health care settings', 'machine learning algorithm', 'machine learning method', 'methylation pattern', 'migration', 'neural network', 'simulation', 'single cell sequencing', 'statistics', 'theories', 'undergraduate student']",NHGRI,HAVERFORD COLLEGE,R15,2021,432494
"Full Scale Randomized Trial of an Innovative Conversational Agent for Smoking Cessation PROJECT SUMMARY/ABSTRACT (DESCRIPTION) Cigarette smoking accounts for 480,000 premature deaths and one third of all cancer deaths annually in the US. There is enormous need for high-impact, cost-effective population-level interventions for smoking cessation. For the past 15 years, mobile phone-delivered text messaging interventions such as the NCI’s SmokefreeTXT have been a prominent technology addressing this need. However, very much like all widely available technologies for smoking cessation (e.g., websites), text messaging interventions have modest quit rates, driven largely by low engagement. Fortunately, a new technology provides a therapeutic conversation to address the problem of engagement that impacts text messaging and other current digital technologies for smoking cessation. Advances in machine learning, natural language processing, and cloud computing are now making it possible to create and widely disseminate conversational agents (CAs), which are computer-powered digital coaches designed to form long-term social-emotional connections with users through conversations. CAs are supportive, empathic, reflectively listen, provide personalized responses, and offer goal setting and advice appropriately timed to the needs of the user. Regarding CAs for smoking cessation, the major knowledge gaps are: (1) their efficacy, (2) theoretical mechanisms, and (3) the cost-effectiveness. Also unexplored are the potential baseline moderators of CAs for smoking cessation. We recently developed a CA for smoking cessation, called “QuitBot,” evaluated it in a diary study, and then tested it in a pilot randomized controlled trial (N = 306), comparing it with the NCI’s SmokefreeTXT. The pilot RCT design was very feasible with 93% three-month follow-up. QuitBot had: (a) high participant engagement and (b) high quit rates at the three-month follow-up—very promising in comparison with SmokefreeTXT. Addressing these knowledge gaps and building on the promising results of our QuitBot research, the project will conduct a randomized controlled trial of QuitBot (n = 760) versus SmokefreeTXT (n = 760) with 12-month follow-up in order to determine whether QuitBot: (1) provides higher quit rates than SmokefreeTXT, (2) has smoking cessation outcomes significantly mediated by therapeutic alliance processes and engagement, and (3) is cost-effective vs. SmokefreeTXT. In addition, this study will explore whether these baseline factors moderate the effectiveness of QuitBot: trust, social support, and demographics (e.g., sex). This innovative project will advance the fields of research on CAs both for smoking cessation in particular and for health behavior change in general— regardless of whether the results are positive or null. Positive results could have high population-level impact and stimulate new lines of research into CA dissemination and implementation, and the adaptation of CAs for multiple subpopulations of smokers, languages, and community and medical settings. PUBLIC HEALTH RELEVANCE STATEMENT The overall aim of this project is to determine the effectiveness of a conversational agent for smoking cessation. If successful, this intervention can be cost-effectively scaled on a population level, thereby making a high public health impact.",Full Scale Randomized Trial of an Innovative Conversational Agent for Smoking Cessation,10120658,R01CA247156,"['Abstinence', 'Address', 'Adopted', 'Adult', 'American', 'Antismoking', 'Car Phone', 'Cessation of life', 'Cloud Computing', 'Communication', 'Communities', 'Computers', 'Cost Measures', 'Dissemination and Implementation', 'Effectiveness', 'Emotional', 'Empathy', 'Feeling', 'Goals', 'Health behavior change', 'Internet', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Mediator of activation protein', 'Medical', 'Modeling', 'Natural Language Processing', 'Outcome', 'Participant', 'Policies', 'Population', 'Prevalence', 'Process', 'Public Health', 'Quality-Adjusted Life Years', 'Randomized', 'Randomized Controlled Trials', 'Research', 'Research Project Grants', 'Sample Size', 'Smoker', 'Smoking', 'Smoking Cessation Intervention', 'Social support', 'Technology', 'Testing', 'Text Messaging', 'Therapeutic', 'Trust', 'Work', 'arm', 'behavior change', 'cigarette smoking', 'comparative effectiveness', 'cost', 'cost effective', 'cost effectiveness', 'demographics', 'design', 'diaries', 'digital', 'effectiveness evaluation', 'follow-up', 'improved', 'innovation', 'new technology', 'patient engagement', 'premature', 'programs', 'public health relevance', 'randomized effectiveness trial', 'randomized trial', 'response', 'sex', 'smartphone Application', 'smoking cessation', 'social', 'success', 'successful intervention', 'text messaging intervention', 'web site']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,730398
"Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data Project Abstract/Summary Our interdisciplinary research team will develop algorithms to accelerate the detection of respiratory virus outbreaks at an unprecedented local scale in US cities. We propose to advance outbreak detection by combining machine learning data integration methods and spatial models of disease transmission. The dynamic models that will be developed will provide mechanistic engines for distinguishing typical from atypical disease trends and the optimization methods evaluate the informativeness of data sources to achieve specified public health goals through the rapid evaluation of diverse input data sources. Working with local healthcare and public health leaders, we will translate the algorithms into user-friendly online tools to support preparedness plans and decision-making. Our proposed research is organized around three major aims. In Aim 1, we will apply machine learning and signal processing methods to build systems that track the earliest indicators of emerging outbreaks within seven US cities. We will evaluate non-clinical data reflecting early and mild symptoms as well as clinical data covering underserved communities and geographic and demographic hotspots for viral emergence. In Aim 2, we will develop sub-city scale models reflecting the syndemics of co-circulating respiratory viruses and chronic respiratory diseases (CRD) that can exacerbate viral infections. We will infer viral transmission rates and socio-environmental risk cofactors by fitting the model to respiratory disease data extracted from millions of electronic health records (EHRs) for the last nine years. We will then partner with clinical and EHR experts to translate our models into the first outbreak detection system for severe respiratory viruses that incorporates EHR data on CRDs. Using machine learning techniques, we will further integrate other surveillance, environmental, behavioral and internet predictor data sources to maximize the accuracy, sensitivity, speed and population coverage of our algorithms. In Aim 3, we will develop an open-access Python toolkit to facilitate the integration of next generation data into outbreak surveillance models. This project will produce practical early warning algorithms for detecting emerging viral threats at high spatiotemporal resolution in several US cities, elucidate socio-geographic gaps in current surveillance systems and hotspots for viral emergence, and provide a robust design framework for extrapolating these algorithms to other US cities. Project Narrative We will develop innovative algorithms for detecting emerging respiratory viruses within US cities. To do so, we will model the syndemic dynamics of respiratory viruses and chronic respiratory diseases and apply machine learning to combine geospatial data that track early indicators of emerging threats. Working with local public health and healthcare collaborators, we will translate this research into practical tools for addressing socio- geographic gaps in surveillance and accelerating the detection, prevention and mitigation of severe outbreaks.","Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data",10265769,R01AI151176,"['Absenteeism', 'Address', 'African', 'Age', 'Algorithm Design', 'Algorithms', 'Area', 'Articulation', 'Bayesian Method', 'Behavioral', 'Caring', 'Chronic', 'Chronic Disease', 'Cities', 'Climate', 'Clinical', 'Clinical Data', 'Collaborations', 'Communicable Diseases', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Disease model', 'Ebola', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Evaluation', 'Geography', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Human', 'Individual', 'Infection', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Interdisciplinary Study', 'International', 'Internet', 'Intervention', 'Location', 'Lung diseases', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mexico', 'Modeling', 'Neighborhoods', 'Pollution', 'Population', 'Prevention', 'Public Health', 'Pythons', 'Readiness', 'Reporting', 'Research', 'Resolution', 'Risk', 'Rural', 'Schools', 'Sentinel', 'Series', 'Signal Transduction', 'Social Environment', 'Specific qualifier value', 'Speed', 'Subgroup', 'Surveillance Modeling', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Translating', 'Uncertainty', 'Validation', 'Viral', 'Virus', 'Virus Diseases', 'Visualization', 'Work', 'World Health Organization', 'austin', 'base', 'cofactor', 'comorbidity', 'dashboard', 'data acquisition', 'data integration', 'design', 'detection method', 'detection platform', 'digital', 'disease transmission', 'diverse data', 'epidemiologic data', 'epidemiological model', 'experimental study', 'flexibility', 'global health', 'health care availability', 'health goals', 'high risk', 'high risk population', 'influenza outbreak', 'influenzavirus', 'innovation', 'insight', 'metropolitan', 'next generation', 'novel', 'outcome prediction', 'pandemic disease', 'public health intervention', 'respiratory virus', 'school district', 'signal processing', 'simulation', 'social media', 'sociodemographic group', 'socioeconomics', 'sound', 'spatiotemporal', 'stem', 'tool', 'transmission process', 'trend', 'underserved community', 'user-friendly', 'viral transmission']",NIAID,YALE UNIVERSITY,R01,2021,482268
"Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data Project Abstract/Summary Our interdisciplinary research team will develop algorithms to accelerate the detection of respiratory virus outbreaks at an unprecedented local scale in US cities. We propose to advance outbreak detection by combining machine learning data integration methods and spatial models of disease transmission. The dynamic models that will be developed will provide mechanistic engines for distinguishing typical from atypical disease trends and the optimization methods evaluate the informativeness of data sources to achieve specified public health goals through the rapid evaluation of diverse input data sources. Working with local healthcare and public health leaders, we will translate the algorithms into user-friendly online tools to support preparedness plans and decision-making. Our proposed research is organized around three major aims. In Aim 1, we will apply machine learning and signal processing methods to build systems that track the earliest indicators of emerging outbreaks within seven US cities. We will evaluate non-clinical data reflecting early and mild symptoms as well as clinical data covering underserved communities and geographic and demographic hotspots for viral emergence. In Aim 2, we will develop sub-city scale models reflecting the syndemics of co-circulating respiratory viruses and chronic respiratory diseases (CRD) that can exacerbate viral infections. We will infer viral transmission rates and socio-environmental risk cofactors by fitting the model to respiratory disease data extracted from millions of electronic health records (EHRs) for the last nine years. We will then partner with clinical and EHR experts to translate our models into the first outbreak detection system for severe respiratory viruses that incorporates EHR data on CRDs. Using machine learning techniques, we will further integrate other surveillance, environmental, behavioral and internet predictor data sources to maximize the accuracy, sensitivity, speed and population coverage of our algorithms. In Aim 3, we will develop an open-access Python toolkit to facilitate the integration of next generation data into outbreak surveillance models. This project will produce practical early warning algorithms for detecting emerging viral threats at high spatiotemporal resolution in several US cities, elucidate socio-geographic gaps in current surveillance systems and hotspots for viral emergence, and provide a robust design framework for extrapolating these algorithms to other US cities. Project Narrative We will develop innovative algorithms for detecting emerging respiratory viruses within US cities. To do so, we will model the syndemic dynamics of respiratory viruses and chronic respiratory diseases and apply machine learning to combine geospatial data that track early indicators of emerging threats. Working with local public health and healthcare collaborators, we will translate this research into practical tools for addressing socio- geographic gaps in surveillance and accelerating the detection, prevention and mitigation of severe outbreaks.","Accelerating viral outbreak detection in US cities using mechanistic models, machine learning and diverse geospatial data",10113533,R01AI151176,"['Absenteeism', 'Address', 'African', 'Age', 'Algorithm Design', 'Algorithms', 'Area', 'Articulation', 'Bayesian Method', 'Behavioral', 'Caring', 'Chronic', 'Chronic Disease', 'Cities', 'Climate', 'Clinical', 'Clinical Data', 'Collaborations', 'Communicable Diseases', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Disease model', 'Ebola', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Evaluation', 'Geography', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Human', 'Individual', 'Infection', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Interdisciplinary Study', 'International', 'Internet', 'Intervention', 'Location', 'Lung diseases', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mexico', 'Modeling', 'Neighborhoods', 'Pollution', 'Population', 'Prevention', 'Public Health', 'Pythons', 'Readiness', 'Reporting', 'Research', 'Resolution', 'Risk', 'Rural', 'Schools', 'Sentinel', 'Series', 'Signal Transduction', 'Social Environment', 'Specific qualifier value', 'Speed', 'Subgroup', 'Surveillance Modeling', 'Symptoms', 'System', 'Techniques', 'Testing', 'Time', 'Translating', 'Uncertainty', 'Validation', 'Viral', 'Virus', 'Virus Diseases', 'Visualization', 'Work', 'World Health Organization', 'austin', 'base', 'cofactor', 'comorbidity', 'dashboard', 'data acquisition', 'data integration', 'design', 'detection method', 'detection platform', 'digital', 'disease transmission', 'diverse data', 'epidemiologic data', 'epidemiological model', 'experimental study', 'flexibility', 'global health', 'health care availability', 'health goals', 'high risk', 'high risk population', 'influenza outbreak', 'influenzavirus', 'innovation', 'insight', 'metropolitan', 'next generation', 'novel', 'outcome prediction', 'pandemic disease', 'public health intervention', 'respiratory virus', 'school district', 'signal processing', 'simulation', 'social media', 'sociodemographic group', 'socioeconomics', 'sound', 'spatiotemporal', 'stem', 'tool', 'transmission process', 'trend', 'underserved community', 'user-friendly', 'viral transmission']",NIAID,YALE UNIVERSITY,R01,2021,596017
"Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1 PROJECT SUMMARY Previous studies showed discrepancies of health and behavior prevalence between American Indians (AI) population and other racial or ethnic groups. Most health surveys have certain limitations when studying AI population due to the small sample sizes for AI population. Data collected by AI Tribal Epidemiology Centers (TECs) provides an excellent opportunity to conduct research for AI population due to sufficient sample size and extensive information. However, most surveys conducted by TECs used non-probability sampling design (e.g. convenient sample) due to its lower cost and increased time efficiency. Non-probability sample may suffer from sampling, coverage and nonresponse errors without further proper adjustments. Such difficulties greatly hampers the analysis of AI population in health and behavior research. Our general hypothesis is that data integration by combining information from non-probability and probability samples can reduce sampling, coverage and nonresponse errors in original non-probability sample. The Goal of this project is to develop an accurate and robust data integration methodology for AI population analysis specifically tailored to health and behavior research. During the past years, we have 1) studied data integration using calibration and parametric modeling approaches; 2) investigated machine learning and propensity score modeling methods in survey sampling and other fields; and 3) assembled an experienced team of multi-disciplinary team of experts. In this project, we propose to capitalize on our expertise and fulfill the following Specific Aims: Aim 1. Develop a data integration approach using machine learning and propensity score modeling We will develop machine learning and propensity score based data integration approaches to combine information from non-probability and probability samples. Compared to existing methods (i.e., Calibration, Parametric approach), our proposed approaches are more robust against the failure of underlying model assumptions. The inference is more general and multi-purpose (e.g. one can estimate most parameters such as means, totals and percentiles). Simulation studies will be performed to compare our proposed methods with other existing methods. A computing package will be built to implement the method in other settings. Aim 2. Evaluate the accuracy and robustness of the proposed method in AI health and behavior research We will use real data to validate the proposed methods in terms of accuracy and robustness to the various data types. The performance will also be assessed by comparing with results from existing data integration methods such as calibration and parametric modeling approaches. The planned study takes advantage of a unique data source and expands the impact of the Indian Health Service (IHS)-funded research. We expect this novel integration method will vertically advance the field by facilitating the analysis based on non-probability sample, which can provide in-depth understanding regarding the AI population health and behavior studies. Project Narrative The overall goal of this R21 project is to develop an accurate, robust and multi-purpose data integration methodology for AI population (non-probability sample) analysis specifically tailored to health and behavior research such as diabetes and smoking. The code implementing the proposed method will be released and is general enough to be applied to AI population studies of other fileds. The success of this study will vertically advance the field by facilitating the AI population analysis, which can provide a better guidance and new insights on the future precision personalized prevention and treatment of certain diseases.",Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1,10271402,R21MD014658,"['Adult', 'Age', 'American', 'American Indians', 'Behavioral', 'Behavioral Risk Factor Surveillance System', 'Calibration', 'Censuses', 'Code', 'Communities', 'Community Surveys', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Sources', 'Diabetes Mellitus', 'Disease', 'Epidemiology', 'Ethnic group', 'Event', 'Failure', 'Funding', 'Future', 'General Population', 'Geographic state', 'Goals', 'Health', 'Health Fairs', 'Health Surveys', 'Health behavior', 'High Prevalence', 'Kansas', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Not Hispanic or Latino', 'Oklahoma', 'Performance', 'Population', 'Population Analysis', 'Population Study', 'Prevalence', 'Probability', 'Probability Samples', 'Publishing', 'Race', 'Research', 'Research Personnel', 'Respondent', 'Risk Factors', 'Sample Size', 'Sampling', 'Smoking', 'Surveys', 'Target Populations', 'Testing', 'Texas', 'Time', 'Tobacco', 'Training', 'United States Indian Health Service', 'Weight', 'Work', 'Youth', 'base', 'behavioral study', 'cigarette smoking', 'cluster computing', 'cost', 'data integration', 'data quality', 'design', 'experience', 'improved', 'individualized prevention', 'innovation', 'insight', 'multidisciplinary', 'novel', 'personalized medicine', 'population health', 'simulation', 'smoking prevalence', 'success', 'therapy development', 'tribal health']",NIMHD,UNIVERSITY OF OKLAHOMA HLTH SCIENCES CTR,R21,2021,109613
"Merging machine learning and mechanistic models to improve prediction and inference in emerging epidemics PROJECT SUMMARY When an outbreak of an established or emerging infectious disease occurs we ask a standard set of questions that are critical to a lifesaving public health response: Where will future incidence occur? How many cases will there be? And where can we most effectively intervene? The proposed research is motivated by real world instances where answering these questions was critical to making practical public health decisions, and current methods came up short: from deciding if and where to build additional Ebola Treatment Units in the 2014-15 West African Ebola epidemic, to identifying priority districts where oral cholera vaccine should be used in the 2016-17 cholera outbreak in Yemen, to picking locations where sufficient cases might occur to selecting and prioritizing interventions to slow the spread of COVID-19 worldwide. Forecasts informing such decisions are typically generated either using an epidemic model that relies on knowledge of the disease transmission mechanism and epidemic theory or using a statistical model to project the expected number of cases based on the relationship between covariates and observed counts. However, both approaches are subject to limitations, particularly early in an epidemic when few cases are observed. This project is based on the overarching scientific premise that inferences that combine the strengths of mechanistic epidemic models and statistical covariate models will substantially outperform either approach alone in forecasting and making decisions to confront emerging infectious disease threats. Specifically, this project aims to (1) Develop a framework to forecast incidence in ongoing outbreaks that merges mechanistic and machine learning approaches; (2) Validate the framework using retrospective data and apply the framework to inform decision making in emerging epidemics; (3) Integrate this inferential forecasting framework into causal decision theory to optimize critical actions in the public health response to emerging epidemics; and (4) Develop accessible and extensible tools for forecasting and decision analysis in infectious disease epidemics. We will validate these approaches using rigorous simulation studies and by applying the proposed approaches to retrospective data from important recent epidemics (e.g., Ebola, Cholera and COVID-19, as mentioned above). We will prospectively apply our approach to inform the response to emerging disease threats that occur during the project period, including the ongoing COVID-19 pandemic. To ensure that the tools developed are useful, efficient, and user friendly, we will work with international humanitarian organizations responding to epidemics. Successful completion of these aims will provide a flexible and validated framework for forecasting and decision making during ongoing epidemics, while allowing for innovation in mechanistic and statistical approaches. In doing so it will provide tools to optimize responses and reduce morbidity and mortality during public health crises. PROJECT NARRATIVE The purpose of the proposed project is to improve inference, forecasting and decision making in response to emerging infectious diseases by developing a framework to integrate mechanistic and statistical approaches to epidemic modeling and causal inference. Approaches developed will be validated using simulations and retrospective data and applied prospectively to reduce morbidity and mortality in emerging public health crises. Further, they will be incorporated into publically available tools for use in epidemic response.",Merging machine learning and mechanistic models to improve prediction and inference in emerging epidemics,10142638,R01GM140564,"['African', 'Algorithms', 'Area', 'COVID-19', 'COVID-19 pandemic', 'Cholera', 'Cholera Vaccine', 'Communicable Diseases', 'Community Health', 'Cost utility', 'Data', 'Data Set', 'Decision Analysis', 'Decision Making', 'Decision Theory', 'Disease', 'Disease Outbreaks', 'Ebola', 'Emerging Communicable Diseases', 'Ensure', 'Epidemic', 'Evaluation', 'Fogs', 'Future', 'Geographic Locations', 'Incidence', 'International', 'Intervention', 'Knowledge', 'Liberia', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Online Systems', 'Oral', 'Policies', 'Public Health', 'Research', 'Research Personnel', 'Series', 'Shapes', 'Statistical Algorithm', 'Statistical Methods', 'Statistical Models', 'System', 'Time', 'Translating', 'Update', 'War', 'Work', 'Yemen', 'base', 'case-based', 'curve fitting', 'dashboard', 'disease transmission', 'experience', 'flexibility', 'improved', 'innovation', 'mortality', 'multidimensional data', 'programs', 'prospective', 'response', 'simulation', 'sound', 'surveillance data', 'theories', 'tool', 'transmission process', 'user-friendly']",NIGMS,JOHNS HOPKINS UNIVERSITY,R01,2021,429701
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,10133117,R00HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Comparative Effectiveness Research', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Infrastructure', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'blockchain', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'computer science', 'data sharing', 'design', 'digital', 'diverse data', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'machine learning algorithm', 'machine learning method', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'privacy preservation', 'privacy protection', 'programs', 'public trust', 'structural genomics', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R00,2021,249000
"eMERGE IV Northwest: A partnership to evaluate the use of genomic information in the health care of diverse participants Project Abstract eMERGE IV (E4) proposes to investigate the implementation of 15 “genomic risk assessment” (GRA) scores in a network-wide set of diverse participants. These GRAs will include polygenic risk score (PRS) information, as well as risk information, such as personal and family health history, environmental and social health determinants, and physical and lab measures. The GRA will aggregate these factors into a single score to identify those who would benefit from screening and other interventions. Substantial challenges must be addressed before genomic medicine is a part of standard medical care. We will collaborate to refine multi-ancestry GRAs and support the inclusion of non-genetic risk factors extracted from the electronic health record with innovative natural language processing approaches and apply them in a cohort enriched for Asian ancestry, and sexual and gender minorities. The specific aims of our proposal are designed to use an implementation science approach to advance the integration of genomic data into clinical practice, including evaluation of patient perspectives and economic outcomes, and broadening the impact of eMERGE through collaborations. The University of Washington Medicine dedication to preventative health in a learning health system and broad expertise across genomics, statistical, ethical, informatic, implementation, outcomes and economic disciplines will support this multi-site clinical trial. Specific Aims: Aim 1: Refine GRA scores and outcomes measures for five high impact conditions, considering stakeholder input, for implementation in the electronic health record. The conditions are: colorectal cancer, breast cancer, osteoporosis, coronary artery disease, and glaucoma. Aim 2: Integrate 15 GRA scores and electronic clinical decision support for management into clinical care and the EHR and capture clinical outcomes. Aim 3: Evaluate the implementation, effectiveness, and economic utility of GRA result return. Project Narrative As part of the eMERGE IV (E4) Network clinical trial, we propose to develop 5, and investigate the implementation of 15, “genomic risk assessment” (GRA) scores in a large set of diverse participants. These GRAs will include genetic and non-genetic information. We specifically propose study of implementation and outcomes of GRA scores for colorectal cancer, breast cancer, osteoporosis, coronary artery disease, and glaucoma in the electronic health record.",eMERGE IV Northwest: A partnership to evaluate the use of genomic information in the health care of diverse participants,10207713,U01HG008657,"['3-Dimensional', 'Address', 'Adopted', 'Adult', 'Alaska Native', 'Asians', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials Network', 'Collaborations', 'Colorectal Cancer', 'Coronary Arteriosclerosis', 'Data', 'Dedications', 'Development', 'Discipline', 'Disease', 'Economics', 'Education', 'Effectiveness', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environmental Risk Factor', 'Ethics', 'Ethnic group', 'Evaluation', 'Family', 'Family health status', 'Genetic', 'Genetic Risk', 'Genomic medicine', 'Genomics', 'Genotype', 'Glaucoma', 'Health', 'Health system', 'Healthcare', 'Informatics', 'Intervention', 'Leadership', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medicine', 'Methods', 'Mission', 'Morbidity - disease rate', 'Multi-Institutional Clinical Trial', 'Native Americans', 'Natural Language Processing', 'Osteoporosis', 'Outcome', 'Outcome Measure', 'Pacific Island Americans', 'Participant', 'Pathogenicity', 'Patients', 'Penetrance', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Population', 'Population Heterogeneity', 'Primary Health Care', 'Process', 'Provider', 'Publishing', 'Recording of previous events', 'Risk', 'Risk Assessment', 'Risk Factors', 'Risk Management', 'Sexual and Gender Minorities', 'Site', 'Underrepresented Populations', 'Universities', 'Variant', 'Washington', 'base', 'clinical care', 'clinical decision support', 'clinical practice', 'cohort', 'data curation', 'design', 'economic outcome', 'economic value', 'ethical legal social implication', 'genetic risk assessment', 'genome wide association study', 'genome-wide', 'genomic data', 'high risk', 'implementation evaluation', 'implementation outcomes', 'implementation science', 'improved', 'innovation', 'malignant breast neoplasm', 'medical specialties', 'mortality', 'non-genetic', 'novel', 'online resource', 'outreach', 'polygenic risk score', 'prevent', 'racial and ethnic', 'risk prediction', 'screening', 'social health determinants', 'support tools', 'tool']",NHGRI,UNIVERSITY OF WASHINGTON,U01,2021,1682350
"Center of Excellence in Environmental Toxicology OVERALL : ABSTRACT This is the third competing continuation for an accomplished Environmental Health Sciences Core Center (EHS CC), The Center of Excellence in Environmental Toxicology (CEET) at the University of Pennsylvania (Penn). The Director is Trevor M. Penning, PhD (The Thelma Brown and Henry Charles Molinoff Professor of Pharmacology) and the Deputy Director is Rebecca A. Simmons, MD (The Hallam Hurt Endowed Professor in Pediatrics). The Center is comprised of 71 members from 18 Departments and 5 Schools, with almost equal representation of basic and clinician-scientists drawn from the Perelman School of Medicine (PSOM) and Children’s Hospital of Philadelphia (CHOP). The CEET has built an institutional, regional and national identity in environmental health sciences (EHS) in the absence of a School of Public Health and Department of EHS at Penn. The synergistic combination of basic and clinician-scientists within the CEET promotes translational environmental health research that addresses fundamental questions and translates knowledge into action to have a major impact on human health and disease consistent with the NIEHS Strategic Plan. The CEET mission is to “elucidate the mechanistic links between environmental exposures and human disease, and translate findings into action to improve the health of vulnerable individuals, and local, national, and global communities”. This mission is accomplished through five aims. In Aim 1: We use a flexible thematic area structure to conduct translational environmental health research to improve precision public health. Our current themes are in Air Pollution & Lung Health; Environmental Exposures & Cancer; Windows-of- Susceptibility; and Environmental Neuroscience. Each thematic area integrates the pillars or exposure science, adverse outcome constructs (pathways and networks) to explain the phenome with translation to communities and human subjects. In Aim 2: We conduct bi-directional communication with communities in S.E and N.E. Pennsylvania and use community engagement to set the research agenda for the CEET. In Aim 3: We provide a facility core structure to promote precision public health. Our Integrative Health Sciences Facility Core is adept in human subject study design and in conducting population exposure services, using cartographic modeling, GIS tools and biosensors. Biomarkers of exposure and effect are measured in our Translational Biomarker Core which conducts mass spectrometric assays at a level of precision and accuracy difficult to emulate elsewhere. The Exposure Biology Informatics Core brings to bear the power of computation, machine learning and AI to predict the toxicity of unknowns and integrate Big-data sets to recognize patterns in “omics” data and predict adverse outcomes. In Aim 4: We build capacity in environmental health sciences by funding pilot projects to Early Stage Investigators (ESI) and to senior investigators conducting environmental health research for the first time. In Aim 5: We cultivate the careers of ESI through a transformative Environmental Health Scientist Support Program that provides mentoring, grant proposal review, environmental health and Facility Core workshops. OVERALL : NARRATIVE The Center of Excellence in Environmental Toxicology (CEET) conducts research that links environmental exposures, to adverse outcomes and translates its findings to human subjects and communities to identify the most vulnerable and improve prevention, intervention and treatment through precision public health. Bi- directional communication through the Community Engagement Core helps set the research agenda of the CEET and inform public health decision making.",Center of Excellence in Environmental Toxicology,10189586,P30ES013508,"['Address', 'Air Pollution', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Asbestos', 'Award', 'Beer', 'Big Data', 'Biological Assay', 'Biological Markers', 'Biology', 'Biosensor', 'Cities', 'Communication', 'Communities', 'Community Healthcare', 'Complement', 'Core Facility', 'Data', 'Data Set', 'Decision Making', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Environmental Exposure', 'Environmental Health', 'Exposure to', 'Funding', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Home environment', 'Human', 'Human Subject Research', 'Individual', 'Informatics', 'Integrative Medicine', 'Knowledge', 'Laboratories', 'Link', 'Lung', 'Machine Learning', 'Measures', 'Mentors', 'Mission', 'Modeling', 'National Institute of Environmental Health Sciences', 'Neurosciences', 'Pathway interactions', 'Pattern', 'Pediatric Hospitals', 'Pediatrics', 'Pennsylvania', 'Pharmacology', 'Philadelphia', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive Intervention', 'Public Health', 'Public Health Schools', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Schools', 'Science', 'Scientist', 'Services', 'Strategic Planning', 'Structure', 'Superfund', 'Time', 'Toxic effect', 'Toxicology', 'Training Programs', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Ursidae Family', 'Vulnerable Populations', 'adverse outcome', 'career', 'career development', 'cheminformatics', 'environment related cancer', 'environmental toxicology', 'exposed human population', 'flexibility', 'health science research', 'human disease', 'human subject', 'improved', 'lead exposure', 'medical schools', 'member', 'next generation', 'phenome', 'professor', 'programs', 'recruit', 'response', 'skills', 'tool', 'urban area', 'wasting']",NIEHS,UNIVERSITY OF PENNSYLVANIA,P30,2021,1606329
"Bioinformatics Strategies for Genome-Wide Association Studies One promise of precision medicine for Alzheimer’s disease is to edit a patient’s DNA and/or administer therapeutics targeting etiologic molecules that prevent or reverse the disease process using a tailored design. All of this happens at the level of the individual and requires precision knowledge of that patient’s biology. In stark contrast, much of the knowledge we possess about genomic risk factors comes from statistical measures of association in subjects ascertained with and without Alzheimer’s. The conceptual and practical disconnect between the populations we study and the individuals we want to treat is a major source of confusion about how to move forward in an era driven by genome technology. The primary goal of this proposal is to develop novel informatics methodology and software to facilitate precision medicine for Alzheimer’s by connecting population and individual genomic phenomena. We propose here a Virtual Genomic Medicine (VGMed) workbench where clinicians can carry out thought experiments about the treatment of individual Alzheimer’s patients using models of disease risk derived from population-level studies. This will be accomplished by first developing a novel Genomics-guided Automated Machine Learning (GAML) algorithm for deriving risk models from real data that is accessible to Alzheimer’s clinicians (AIM 1). We will then develop a novel simulation approach that is able to generate artificial Alzheimer’s data that preserves the distribution of genetic effects observed in the real data while maintaining other characteristics such as genotype frequencies (AIM 2). This will generate open data allowing anyone to perform virtual interventions on Alzheimer’s patients derived from a population-level risk distribution. The workbench will allow editing of individual genotypes and simulate the administration of drugs by editing machine learning parameters in the simulation model (AIM 3). The change in risk and Alzheimer’s disease status for the specific patient will be tracked in real time. Finally, we provide a feature in the workbench that will allow the Alzheimer’s clinician to generate specific hypotheses about individual genetic variants that can then be validated using integrated Alzheimer’s knowledge sources that include databases such as PubMed and ClinVar thus giving the user immediate feedback (AIM 4). All methods and software will be provided as open-source to the Alzheimer’s disease research community (AIM 5). Most genetic studies of Alzheimer’s disease result in statistical summaries of risk derived from human populations. These statistical summaries are not that helpful for determining the health of an individual. This proposal will create new computer algorithms and software help Alzheimer’s clinicians and researchers connect population-level statistics with individual level genetic effects to advance our understanding of how to treat Alzheimer’s patients based on their own unique genetic makeup.",Bioinformatics Strategies for Genome-Wide Association Studies,10284977,R01LM010098,"['Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Bioinformatics', 'Biology', 'Characteristics', 'ClinVar', 'Communities', 'Computational algorithm', 'Computer software', 'Confusion', 'DNA', 'Data', 'Databases', 'Disease', 'Disease model', 'Etiology', 'Feedback', 'Frequencies', 'Genetic', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Study', 'Process', 'PubMed', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Source', 'Technology', 'Time', 'base', 'data preservation', 'design', 'disorder risk', 'experimental study', 'genetic makeup', 'genetic variant', 'genome wide association study', 'machine learning algorithm', 'models and simulation', 'novel', 'open data', 'open source', 'precision medicine', 'prevent', 'simulation', 'statistics', 'therapeutic target', 'virtual', 'virtual intervention']",NLM,UNIVERSITY OF PENNSYLVANIA,R01,2021,391879
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,10164857,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'ClinVar', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data standards', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'patient health information', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,399965
"Trio Analysis of Recurrent Pregnancy Loss Integrated Bioinformatics Genomics Study (TRIOS) PROJECT SUMMARY Recurrent pregnancy loss (RPL) affects up to 5% of couples, yet nearly half of cases remain unexplained by current testing recommendations. Euploid pregnancy loss, in the setting of unexplained RPL, is particularly frustrating for patients and providers because there is no clear explanation or any proven therapies to mitigate risk of subsequent miscarriages. As clinical presentation and subsequent pregnancy outcomes vary widely, this complex disorder will ultimately require a precision health approach. While more than 3000 human genes are conserved and likely essential for early development, remarkably little is known about their contribution to RPL and current genetic databases are essentially devoid of RPL entries. Moreover, there is currently no database that annotates phenotypes and genotypes of these essential genes. This proposal aims to define genetic determinants of RPL through clinical and molecular phenotyping and genomic sequencing of a large RPL cohort, combined with novel bioinformatics and machine learning approaches to derive predictive risk algorithms. A comprehensive approach to identify genomic markers of pregnancy loss by whole genome sequencing of well- characterized RPL trios (mother-father-pregnancy loss) will be undertaken in Aim 1. These genetics efforts will be paired in Aim 2 with metabolomic, lipidomic and single cell transcriptomic profiling preconception and in early pregnancy. Leveraged with innovative machine learning strategies in Aim 3, this approach will significantly advance understanding of the genetic underpinnings of unexplained RPL. A clinical ‘intolerome’ database will be constructed in Aim 4 to facilitate worldwide collaboration and curation of genotypes and associated phenotypes, making the genetics and omics data and results available to the public as well as other funded teams. This multidisciplinary team includes leaders in RPL, genetics, genomics, prenatal diagnosis, bioinformatics and machine learning at Stanford, UCSF and OHSU. Combined we have a substantial cohort of RPL patients that will serve as a robust recruitment source, along with a collaboration with the unique UK Pregnancy Baby BioBank of existing trios to accomplish project goals. The proposed study is anticipated to have significant clinical and research impact by identifying the genomic contribution to RPL in a large and well phenotyped cohort and building improved risk predictions based on machine learning incorporating clinical, genetic, and molecular data. This work will lay the foundation for precision medicine-based interventions for RPL couples who are difficult to diagnose and have few proven treatments. PROJECT NARRATIVE Given that there are very few proven treatments for unexplained recurrent pregnancy loss, uncovering genetic mechanisms is crucial for identifying individuals at risk and initiating targeted, patient-centered treatments. The proposed work will provide unprecedented machine learning analysis to define the spectrum of genomic and clinical indicators for recurrent pregnancy loss, unparalleled molecular phenotyping through metabolomics and single cell RNA sequencing, and development of a publicly-available “intolerome” database which will provide the foundation for a future prenatal OMIM.",Trio Analysis of Recurrent Pregnancy Loss Integrated Bioinformatics Genomics Study (TRIOS),10225966,R01HD105256,"['Affect', 'Algorithms', 'Anatomy', 'Bioinformatics', 'Biological', 'Blood Circulation', 'Catalogs', 'Cells', 'Clinical', 'Clinical Research', 'Collaborations', 'Communities', 'Complex', 'Couples', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Essential Genes', 'Etiology', 'Fathers', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Databases', 'Genetic Determinism', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Hematology', 'Heritability', 'Human', 'Immune', 'Individual', 'Intervention', 'Machine Learning', 'Medical Genetics', 'Molecular', 'Molecular Profiling', 'Mothers', 'Multiomic Data', 'Online Mendelian Inheritance In Man', 'Parents', 'Pathway interactions', 'Patients', 'Phenotype', 'Precision Health', 'Pregnancy', 'Pregnancy Outcome', 'Pregnancy loss', 'Prenatal Diagnosis', 'Provider', 'Recommendation', 'Recurrence', 'Regulator Genes', 'Risk', 'Seminal', 'Source', 'Spontaneous abortion', 'Structural Congenital Anomalies', 'Systems Biology', 'Testing', 'Work', 'adverse pregnancy outcome', 'base', 'biobank', 'clinical phenotype', 'cohort', 'data repository', 'early pregnancy', 'epidemiology study', 'exome sequencing', 'experience', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic biomarker', 'genomic locus', 'improved', 'innovation', 'insight', 'learning strategy', 'lipidomics', 'metabolomics', 'molecular marker', 'molecular phenotype', 'multidisciplinary', 'multiple omics', 'novel', 'patient oriented', 'phenotypic data', 'precision medicine', 'predictive modeling', 'prenatal', 'protein protein interaction', 'recruit', 'reproductive', 'risk prediction', 'risk variant', 'single-cell RNA sequencing', 'transcriptomics', 'treatment center', 'whole genome']",NICHD,STANFORD UNIVERSITY,R01,2021,1465292
"Advancing evolutionary genetic inference in humans and other taxa Project Summary/Abstract Background: A major challenge in evolutionary genomics is to characterize the forces shaping present-day patterns of genetic variation. For instance, the extent and manner in which natural selection affects genetic diversity remains highly controversial. Researchers have largely addressed this problem by developing statistical tests or summaries of genome sequence variation that provide insights into the evolutionary forces at play. However, because such approaches typically rely on a single univariate summary of the data, valuable discriminatory information present in the original dataset is lost. A more fruitful strategy would thus be to use multidimensional summaries of genomic data (e.g. a large vector of summary statistics) or even the totality of the input data (e.g. a matrix-representation of a sequence alignment) to make more accurate inferences. An even more powerful approach is to utilize data sets in which the same population is sampled at multiple time points, allowing one to observe evolutionary dynamics in action. Although such genomic time-series data are becoming more prevalent, the development of appropriate computational methodologies has lagged behind the proliferation of such data. Proposal: The Schrider Lab seeks to develop and apply powerful machine learning methods for evolutionary inference. Our work over the next five years will yield powerful software tools leveraging novel representations of genomic datasets, including time-series data. These efforts will dramatically improve researchers' ability to make accurate evolutionary inferences from both population genomic and phylogenetic data. Indeed, preliminary results demonstrate that our methods vastly outperform current approaches in evolutionary genetics. More importantly, we will use these tools to answer pressing evolutionary questions. In particular, our use of time-series data will reveal loci responsible for recent adaptation with much greater confidence than currently possible. Our efforts will help to resolve the controversy over the role of adaptation in shaping patterns of diversity across the human genome. This research has important implications for public health as well, as genes underlying recent adaptations are enriched for disease-associations. Moreover, we are constructing a time-series dataset in the mosquito vector species Aedes aegypti and Aedes albopictus. We will interrogate these data for evidence of recent and ongoing adaptation—this work will reveal loci responsible for the evolution of resistance to insecticides and other control efforts. Encouraging preliminary data also suggest that our work in phylogenetics will substantially improve inferential power in this important research area. More broadly, the success of the novel approaches described in this proposal has the potential to transform the methodological landscape of evolutionary genomic data analysis. Project Narrative The work proposed here seeks to develop and apply powerful machine-learning based software tools for evolutionary genetic inference in humans, mosquito vectors, and other species. Such efforts have important health implications, as they can identify genes involved in adaptation, which in humans are often associated with disease and in mosquitos are often associated with resistance to insecticides and other control efforts.",Advancing evolutionary genetic inference in humans and other taxa,10207692,R35GM138286,"['Address', 'Aedes', 'Affect', 'Area', 'Computing Methodologies', 'Culicidae', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Health', 'Human', 'Human Genome', 'Insecticides', 'Machine Learning', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phylogenetic Analysis', 'Play', 'Population', 'Public Health', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Sampling', 'Sequence Alignment', 'Series', 'Shapes', 'Software Tools', 'Testing', 'Time', 'Variant', 'Work', 'base', 'genomic data', 'improved', 'insight', 'machine learning method', 'novel', 'novel strategies', 'statistics', 'success', 'time use', 'tool', 'vector', 'vector mosquito']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2021,382894
"Scalable tools to effectively translate genomic discoveries into the clinic PROJECT SUMMARY We are in the midst of a genomic revolution; more than 250,000 human genomes have been sequenced, generating over a petabase of genomic data. While these new data hold great promise to impact health, there is a disconnect between genomic discovery and clinical care. Providers frequently misinterpret genomic information, patients often don't understand their own test results, and genomic information about disease risk is infrequently shared between patients and family members. Importantly, ineffective communication and data misinterpretation has devastating consequences- including unnecessary organ removal, missed disease prevention opportunities, and premature death. We are addressing these genomic care gaps by developing and testing tools that optimize the integration of whole-exome and whole-genome sequencing (WES, WGS) for general clinical practice. My vision for improving genomic medicine is based on my work within multidisciplinary consortia and addresses the National Human Genome Research Institute's priority research area of improving the effectiveness of healthcare. In the proposed work we will test the effectiveness of a multilevel genomic e-Health intervention in cancer (Aim 1). Our intervention 1) educates physicians and patients about genomics, 2) enables direct-to-patient return-of- results, 3) provides physicians with patient-specific results and resources for interpretation, and 4) facilitates sharing of genomic results within families. We hypothesize that intervention use will result in higher rates of uptake of high-quality, genetically guided care. We will test our hypothesis in a randomized controlled trial among academic and community physicians who use WES for their patients. Next, we will use an iterative process, with stakeholder engagement, to adapt and pilot test our tool for Spanish and Mandarin speaking patients and for patients who have diabetes (Aim 2). Finally, we will create and assess new, moderated, social networks as a platform for genomic information sharing (Aim 3). Our hypothesis is that providers, patients and family members will engage with the genomic information sharing social networks and find them to be highly useful. Our general approach includes 1) creating the secure social networks, 2) integrating the networks into our e-Health intervention, and 3) using complementary methods, such as interviews and natural language processing, to assess stakeholders' network-related attitudes and network information quality. If successful, we will be well positioned to widely disseminate our e-Health tools. In sum, this work stands to transform how people obtain, process and share genomic information in the context of clinical care. Our tools reconceive genetic communication to allow for multi-directional flow of information, connects multiple stakeholders with one another, and integrates high-quality dynamic web-based resources to improve genomic care. In creating and deploying tools that both respond to and leverage the complexities of our information environment, we intend to transform genomic research and clinical practice. PROJECT NARRATIVE/ RELEVANCE OF PROJECT TO RESEARCH AND PUBLIC HEALTH Widespread utilization of genomic sequencing in medicine creates an urgent need to educate providers and patients. Currently, providers frequently misinterpret genomic information and patients often don't understand their own test results. In order to address this critical need, we propose to design and test multiple e-Health communication tools that will help providers and patients to better understand genomic data, lead to higher quality patient care, and facilitate genomic information sharing within families.",Scalable tools to effectively translate genomic discoveries into the clinic,10204071,R35HG010721,"['Address', 'Area', 'Attitude', 'Caring', 'Cessation of life', 'Clinic', 'Communication', 'Communication Tools', 'Community Physician', 'Data', 'Diabetes Mellitus', 'Effectiveness', 'Environment', 'Excision', 'Family', 'Family member', 'Genetic', 'Genome', 'Genomic medicine', 'Genomics', 'Health', 'Healthcare', 'Human Genome', 'Information Networks', 'Intervention', 'Interview', 'Lead', 'Malignant Neoplasms', 'Medicine', 'Methods', 'National Human Genome Research Institute', 'Natural Language Processing', 'Organ', 'Patient Care', 'Patients', 'Physicians', 'Positioning Attribute', 'Process', 'Provider', 'Public Health', 'Randomized Controlled Trials', 'Research', 'Research Priority', 'Resources', 'Secure', 'Social Network', 'Sum', 'Test Result', 'Testing', 'Translating', 'Vision', 'Work', 'base', 'clinical care', 'clinical practice', 'design', 'disorder prevention', 'disorder risk', 'eHealth', 'effectiveness testing', 'exome', 'genome sequencing', 'genomic data', 'genomic platform', 'improved', 'multidisciplinary', 'online resource', 'premature', 'tool', 'uptake', 'whole genome']",NHGRI,BECKMAN RESEARCH INSTITUTE/CITY OF HOPE,R35,2021,527496
"Fast and flexible Bayesian phylogenetics via modern machine learning Project Abstract/Summary The SARS-CoV-2 pandemic underlines both our susceptibility to and the toll of a global pathogen outbreak. Phylogenetic analysis of viral genomes provides key insight into disease pathophysiology, spread and po- tential control. However, if these methods are to be used in a viral control strategy they must reliably account for uncertainty and be able to perform inference on 1,000s of genomes in actionable time. Scaling Bayesian phylogenet- ics to meet this need is a grand challenge that is unlikely to be met by optimizing existing algorithms.  We will meet this challenge with a radically new approach: Bayesian variational inference for phylogenet- ics (VIP) using ﬂexible distributions on phylogenetic trees that are ﬁt using gradient-based methods analogous to how one efﬁciently trains massive neural networks. By taking a variational approach we will also be able to integrate phylogenetic analysis into very powerful open-source modeling frameworks such as TensorFlow and PyTorch. This will open up new classes of models, such as neural network models, to integrate data such as sampling location and migration patterns with phylogenetic inference. These ﬂexible models will inform strategies for viral control.  In Aim 1 we will develop the theory necessary for scalable and reliable VIP, including subtree marginal- ization, local gradient updates needed for online algorithms, convergence diagnostics, and parameter support estimates. We will implement these algorithms in our C++ foundation library for VIP. In Aim 2 we will develop a ﬂexible TensorFlow-based modeling platform for phylogenetics, enabling a whole new realm of phylogenetic models based on neural networks to learn phylodynamic heterogeneity with minimal program- ming effort. We will provide efﬁcient gradients to this implementation via our C++ library. In Aim 3 we will use the fact that VIP posteriors are durable and extensible descriptions of the full data posterior to enable dynamic online computation of variational posteriors, including divide-and-conquer Bayesian phylogenetics. This work will enable a cloud-based viral phylogenetics solution to rapidly update our current estimate of the posterior distribution when new data arrive or the model is modiﬁed. 1 Project Narrative We have seen in the current SARS-CoV-2 pandemic, as for all major pathogen outbreaks in the last decade, how phylogenetic (i.e. evolutionary tree) methods are required to use viral genomic information to under- stand large-scale transmission patterns. However, current phylogenetic methods have two major limitations as a tool for viral control: ﬁrst, rigorous Bayesian probabilistic methods cannot scale to 1,000s of genomes, and second, models incorporating phylogenetic trees must be expressed in specialized phylogenetics pack- ages, making modern machine-learning approaches impossible. In this proposal, we develop variational ap- proaches to phylogenetics, which will allow fast inference and procedures to rapidly update inferences when new data arrives, as well as making phylogenetic trees a ﬁrst-class inferential object in major machine-learning packages. 1",Fast and flexible Bayesian phylogenetics via modern machine learning,10266670,R01AI162611,"['Age', 'Algorithms', 'Back', 'Bayesian Method', 'COVID-19 pandemic', 'Code', 'Collection', 'Complex', 'Computational Biology', 'Custom', 'Data', 'Data Set', 'Diagnostic', 'Discipline', 'Disease', 'Disease Outbreaks', 'Epidemic', 'Foundations', 'Functional disorder', 'Genome', 'Graph', 'Heterogeneity', 'Learning', 'Libraries', 'Location', 'Machine Learning', 'Markov chain Monte Carlo methodology', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Nature', 'Neural Network Simulation', 'Pattern', 'Phylogenetic Analysis', 'Predisposition', 'Procedures', 'Public Health', 'Research Personnel', 'Sampling', 'Statistical Models', 'Structural Models', 'Structure', 'Technology', 'TensorFlow', 'Time', 'Training', 'Trees', 'Uncertainty', 'Update', 'Variant', 'Viral', 'Viral Genome', 'Work', 'base', 'cloud based', 'data modeling', 'epidemiologic data', 'flexibility', 'genomic data', 'high dimensionality', 'insight', 'knowledge base', 'mathematical algorithm', 'mathematical methods', 'migration', 'neural network', 'novel strategies', 'open source', 'pathogen', 'prevent', 'scale up', 'social exclusion', 'theories', 'tool', 'transmission process', 'user-friendly', 'viral genomics', 'viral transmission']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,797370
"Clinical Research Education in Genome Science (CREiGS) Project Summary/Abstract  The sensitivity and availability of omic technologies have enabled the genomic, transcriptomic and proteomic characterization of disease phenotypes, at the tissue and even the single cell level. This has allowed development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. Patients of providers who have participated in these educational initiatives also benefit as it allows for more rapid integration of genomic study findings into the clinical care setting. Thus, in response to PAR-19-185, we propose to develop and implement the Clinical Research Education in Genome Science (CREiGS) program that will not only focus on the analysis of genomic data, but also on gene-expression data, the integration of these two data types, as well as introductory theory and application of statistical and machine learning methods. Specifically we propose to accomplish the following specific aims: 1. Develop and successfully implement the online and in-person phases of CREiGS to increase the methodologic ingenuity by which researchers tackle important genomics-related clinical problems. 2. Establish a Diversity Recruitment External Advisory Board to ensure that the most effective strategies are employed to recruit URM doctoral students, postdoctoral fellows, and faculty from academic institutions nationwide into CREiGS. 3. Enhance the dissemination phase of CREiGS by packaging and uploading the asynchronous lectures and the online critical thinking/problem solving assessments with solutions for publicly available, online teaching resources. 4. Implement effective methods to evaluate the efficacy of CREiGS by examining:1) the participants' grasp of the CREiGS core competencies, 2) the clarity and quality of the curriculum, 3) program logistics and operation, and 4) the participants' short-term and long-term success attributed to participation in CREiGS. In summary, we posit that CREiGS will provide participants with a solid foundation in genomics science to answer complex, clinical questions. We believe that CREiGS supports the mission of the NHGRI by providing researchers with rigorous training to “accelerate medical breakthroughs that improve human health.” Project Narrative The sensitivity and availability of omic technologies have allowed for the development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. The overall goal of the Clinical Research Education in Genome Science program is to increase the methodologic ingenuity of students, postdoctoral fellows, and faculty from academic institutions nationwide through a solid foundation in genomics science to answer complex, clinical research questions and improve patient care.",Clinical Research Education in Genome Science (CREiGS),10147746,R25HG011021,"['Area', 'Biomedical Research', 'Cells', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Critical Thinking', 'Data', 'Data Analyses', 'Development', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genetic', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Hour', 'Human', 'Hybrids', 'Institution', 'Knowledge', 'Logistics', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Human Genome Research Institute', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Play', 'Postdoctoral Fellow', 'Problem Solving', 'Proteomics', 'Provider', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Role', 'Single Nucleotide Polymorphism', 'Solid', 'Statistical Methods', 'Students', 'Technology', 'Tissues', 'Training', 'Translational Research', 'Treatment outcome', 'Underrepresented Minority', 'Underserved Population', 'Update', 'cancer therapy', 'clinical care', 'computerized tools', 'data integration', 'data management', 'disease phenotype', 'disorder subtype', 'doctoral student', 'education research', 'efficacy evaluation', 'genetic analysis', 'genome sciences', 'genomic data', 'grasp', 'health disparity', 'improved', 'individual patient', 'innovation', 'lectures', 'machine learning method', 'operation', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'response', 'statistical and machine learning', 'success', 'theories', 'therapy development', 'tool', 'transcriptomics', 'treatment optimization', 'virtual']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R25,2021,162000
"Racial disparities in biomarkers, tobacco cessation, and smoking relapse in association with electronic cigarette use Project Summary Although enormous progress has been made in reducing cigarette smoking in the United States, large disparities remain across subpopulations such as racial minorities. Quitting smoking can greatly reduce the risk of disease and early death. However, African Americans (AA) are less likely to quit smoking successfully than are non-Hispanic Whites, and they are also three times more likely to smoke menthol cigarettes than Whites. There is a remarkable variation in the incidence of lung cancer due to cigarette smoking among racial/ethnic groups in the United States, and African Americans have significantly greater risks than Whites at lower levels of smoking. Tobacco use landscape is changing among U.S. adults with an estimated 4.5% of adults aged 18 years and older reporting current use of electronic cigarettes (EC). Evidence suggests that e-cigarette aerosol is substantially less toxic than combustible cigarette smoking, but e-cigarette use may also post elevated risk for former smokers to relapse back to combustible cigarette smoking. Biomarker can play an important role in assessing the potential health effects of tobacco products and studies have found that AA have higher levels of serum cotinine per cigarette smoked, higher urinary amount of TNE and NNAL than Whites. However, evidence on the racial disparities of biomarker outcomes of EC use is scarce, especially whether and to what extent they are different from use of various EC devices, flavors, and transitions in EC ↔ cigarettes. The overarching goal of this study is to examine the racial disparities in biomarkers of exposure and toxicants in association with EC use by analyzing the restricted Population Assessment of Tobacco and Health (PATH) Wave 1-4 biomarker data. We will link the biomarker data with the PATH adult surveys to identify the between- person and within-person differences in biomarkers by use of different vaping products, flavors, and transition in EC and combustible cigarettes across different waves (Aim 1). We will further leverage machine learning algorithms to develop a composite bio (biomarker)-socio (socio-demographics) -psycho (psychosocial factors) risk index score for each racial/ethnic group to predict subsequent abstinence from cigarette smoking and relapse to cigarette smoking since these 2 outcomes represent the most meaningful transitions from a public health perspective. This study is innovative in its focus on racial disparities of biomarkers by leveraging the nationally longitudinal data, and on using machine learning algorithms to predict future smoking cessation and relapse behaviors in EC ↔ cigarette transition. Fulfillment of these aims will build a scientific base for maximizing the value of existing biospecimen collections. Findings from this R21 study are expected to inform regulatory strategies to reduce tobacco-related morbidity and mortality and set the stage for a future R01 application that will develop personalized intervention strategies that incorporate biomarker measures to reduce racial disparities in tobacco use and improve health outcomes. 1 Project Narrative The proposed study seeks to examine racial disparities in biomarkers of e-cigarette use by linking the PATH Waves 1-4 restricted biomarker data and adult survey data. The study will extend our knowledge on the heterogeneity in biomarkers of exposure and toxicants across racial and ethnic groups, including use of different vaping products, flavors, and transition between e-cigarettes and cigarettes. We will further develop a bio-socio-psycho risk index score to predict abstinence from cigarette smoking, relapse to cigarette use, and tobacco-related health outcomes using machine learning algorithms across racial and ethnic groups.","Racial disparities in biomarkers, tobacco cessation, and smoking relapse in association with electronic cigarette use",10232728,R21DA054818,"['18 year old', '4-(methylnitrosamino)-1-(3-pyridyl)-1-butanol', 'Abstinence', 'Adult', 'African American', 'Back', 'Behavior', 'Biological Markers', 'Cessation of life', 'Characteristics', 'Cigarette', 'Cigarette Smoker', 'Clinical', 'Collection', 'Communities', 'Cotinine', 'Data', 'Devices', 'Electronic cigarette', 'Ethnic group', 'Future', 'Goals', 'Health', 'Heterogeneity', 'Hispanics', 'Incidence', 'Intervention', 'Knowledge', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measures', 'Menthol', 'Metals', 'Morbidity - disease rate', 'Nicotine', 'Not Hispanic or Latino', 'Observational Study', 'Outcome', 'Oxidative Stress', 'Pattern', 'Persons', 'Play', 'Population Analysis', 'Population Assessment of Tobacco and Health', 'Psychosocial Factor', 'Public Health', 'Race', 'Recording of previous events', 'Relapse', 'Reporting', 'Research', 'Respiratory Signs and Symptoms', 'Risk', 'Role', 'Serum', 'Smoke', 'Smoker', 'Smoking', 'Surveys', 'Techniques', 'Time', 'Tobacco', 'Tobacco Use Cessation', 'Tobacco use', 'United States', 'Urine', 'Validation', 'Variant', 'base', 'behavioral outcome', 'cigarette smoke', 'cigarette smoking', 'cigarette user', 'combustible cigarette', 'disorder risk', 'e-cigarette aerosols', 'electronic cigarette use', 'electronic cigarette user', 'former smoker', 'high risk', 'improved', 'indexing', 'innovation', 'machine learning algorithm', 'mortality', 'personalized intervention', 'psychosocial', 'racial and ethnic', 'racial disparity', 'racial minority', 'reduce tobacco use', 'smoking cessation', 'smoking relapse', 'sociodemographics', 'tobacco exposure', 'tobacco products', 'tobacco toxicant', 'toxicant', 'urinary', 'vaping']",NIDA,UNIVERSITY OF NEBRASKA MEDICAL CENTER,R21,2021,204739
"An Agent-Based Modeling Platform for Environmental Biotechnology Hazardous pollutants in the environment continue to threaten public health and environmental  safety. Human exposure to major contaminant classes, such as polyfluorinated compounds  (PFCs), hazardous organic compounds (HOCs), and heavy metals, has been linked to a variety of  diseases and is subject to stringent State and Federal environmental regulations.  Bioremediation is a low-cost and environmentally friendly approach with many successful  use-cases; however, conventional bioremediation technologies can suffer from unreliability, low  degradation rates, and incomplete degradation. As stakeholders to Superfund sites and other sites  with water or soil pollution urgently demand more efficient, less costly and more reliable  remediation technologies, it is critical to look to advancements in computational  modeling to develop next-generation, precision-engineered bioremediation technologies. The proposed project builds on successful outcomes from Phase I in which a new computational  platform was designed and validated to accurately predict the bioremediation kinetics of  a multi-organism microcosm degrading a combination of HOCs in groundwater. The basis of  this platform is an approach called agent-based modeling (ABM), where the functions of  individual components (e.g. microorganisms) within complex ecosystems are used to predict and  optimize system-level properties (e.g. bioremediation kinetics). In this Phase II project, the novel computational platform developed in Phase I is  further improved with a machine learning component that leverages bioinformatics  databases to develop rationally tailored microbiomes for degrading complex pollutant  mixtures. Iterative experimental validation of model outputs is conducted using an innovative  materials science platform that maintains the relative concentration of different species in the  microbiome constant within the multi-zone treatment barrier (in-situ) or multi-zone bioreactor  (ex-situ). The project includes focused development of a prototype for one bioremediation use-case,  which is directly compared to a conventional (non-precision) bioremediation system treating   actual contaminated groundwater. This will be performed in order to assess and quantify  the expected technical and economic benefits of harnessing the project's novel computational  platform in biotechnology development. The broad, long-term impact of the proposed project will be to transform the development and  implementation of bioremediation by integrating advancements in computational modeling, machine  learning, bioinformatics, and materials science. By leveraging novel tools across disciplines, the  project will accelerate the development of more precise, reliable and inexpensive technologies for  environmental remediation. The successful outcome of the proposed project will also provide new  collaborative opportunities for industry and academia to more rapidly address the remediation of  high-priority pollutants in the environment, and ultimately help mitigate the effects of hazardous  pollutants on communities impacted by the presence of environmental contamination. PROJECT NARRATIVE Contaminated soils and waters continue to threaten public health and safety. This project builds on the development of a novel computational platform for predicting the complex, dynamic interactions between microbial ecosystems and hazardous contaminants-of-concern in the environment, and to utilize this information to develop improved engineered remediation biotechnologies.",An Agent-Based Modeling Platform for Environmental Biotechnology,10158243,R44ES026541,"['Academia', 'Address', 'Biodegradation', 'Bioinformatics', 'Bioreactors', 'Bioremediations', 'Biotechnology', 'Chemicals', 'Classification', 'Colorado', 'Communities', 'Complex', 'Computer Models', 'Data', 'Databases', 'Development', 'Discipline', 'Disease', 'Economics', 'Ecosystem', 'Engineering', 'Environment', 'Environmental Monitoring', 'Environmental Pollution', 'Enzymes', 'Exposure to', 'Ginkgo biloba', 'Goals', 'Growth', 'Heavy Metals', 'In Situ', 'Indiana', 'Individual', 'Industry', 'Kinetics', 'Laboratories', 'Learning Module', 'Letters', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Molecular', 'Municipalities', 'Organism', 'Outcome', 'Output', 'Phase', 'Polymers', 'Process', 'Property', 'Public Health', 'Regulation', 'Research', 'Safety', 'Side', 'Site', 'Soil', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Water', 'Water Pollution', 'base', 'computational platform', 'cost', 'design', 'economic evaluation', 'enzyme pathway', 'exposed human population', 'ground water', 'improved', 'innovation', 'laboratory experiment', 'materials science', 'microbial', 'microbiome', 'microorganism', 'next generation', 'novel', 'pollutant', 'prototype', 'remediation', 'research and development', 'soil pollution', 'success', 'superfund site', 'tool']",NIEHS,"MICROVI BIOTECH, INC.",R44,2021,630992
"Classifying addictions using machine learning analysis of multidimensional data ABSTRACT This Independent Scientist Award will significantly enhance my research capabilities, enabling me to become a leading quantitative investigator in the field of substance use disorders (SUDs). Specifically, it will allow me to increase my knowledge in the areas of SUD phenotypes, treatment and genetics. SUDs are clinically and etiologically heterogeneous and their classification has been difficult. This application reflects my ongoing commitment to developing an innovative and interdisciplinary research program on the classification of SUDs through quantitative analysis of multidimensional data. My extensive training in computational science and prior research on biomedical informatics have provided me with the skills to design, implement and evaluate advanced algorithms and sophisticated analyses to solve challenging problems in classifying SUDs. My ongoing NIDA-funded R01 employs a large (n=~12,000) sample aggregated from multiple genetic studies of cocaine, opioid, and alcohol dependence to develop and evaluate novel statistical models to generate clinical SUD subtypes that are optimized for gene finding. This K02 proposal extends that work to evaluate treatment outcome in refined subgroups of SUD populations using data from treatment studies for cocaine, opioid, alcohol and multiple substance dependence. This project will integrate data from diagnostic behavioral variables and genotypes, as well as biological/neurobiological features of the disorders and repeated measures of treatment outcome. The primary career development goals of this application are to: (1) understand the reliability, validity and functional mechanisms of various phenotyping methods; (2) to continue training in the genetics of addictions; and (3) to gain greater knowledge of different treatment approaches and their efficacy. A solid foundation in these areas will enhance my ability to realize the full potential of the data collected and aggregated from multiple dimensions, and to use the data to design the most clinically useful analysis and generate innovative solutions to diagnostic and predictive challenges in SUD research. Through formal coursework, directed readings, individual tutoring and intensive multidisciplinary collaboration with a diverse team of world-renowned researchers, I will receive training and collect pilot data for future R01 projects by examining (Aim I): whether clinically-defined highly heritable subtypes derived in my current R01 project predict differential treatment response; (Aim II) whether new statistical models that directly combine treatment data with behavioral, biological, and genomic data identify refined subtypes with confirmatory multilevel evidence; and (Aim III) whether there are genetic and social moderators of treatment outcome by subtype. The overall goal of this proposal is to further my independent and multidisciplinary research program in the development of statistical methods for refined classification of SUDs. The K02 award will provide me with the protected time necessary to fully engage in the training activities described that will enhance my knowledge and skills to enable me to make important, novel contributions to the genetics and treatment of SUD. PROJECT NARRATIVE This project will develop novel statistical and quantitative tools to identify homogeneous subtypes of substance use disorders (SUDs) and other complex diseases to enhance gene finding and treatment matching. The proposed project will perform secondary analyses of existing data from treatment studies of cocaine, opioid, alcohol, and mixed SUDs. The proposed novel approaches are expected to advance precision medicine approaches to SUDs by enabling treatment matching and a more refined SUD classification to gene finding.",Classifying addictions using machine learning analysis of multidimensional data,10087504,K02DA043063,"['Adherence', 'Aftercare', 'Alcohol dependence', 'Alcohols', 'Algorithms', 'Area', 'Behavioral', 'Biological', 'Biological Markers', 'Biosensor', 'Characteristics', 'Classification', 'Clinical', 'Cluster Analysis', 'Cocaine', 'Cocaine Dependence', 'Collaborations', 'Combined Modality Therapy', 'Complex', 'Computational Science', 'DSM-IV', 'DSM-V', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic and Statistical Manual of Mental Disorders', 'Dimensions', 'Disease', 'Drug Use Disorder', 'Electroencephalography', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic study', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'Heterogeneity', 'Independent Scientist Award', 'Individual', 'Interdisciplinary Study', 'Investigation', 'Joints', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Neurobiology', 'Opiate Addiction', 'Opioid', 'Patients', 'Pattern', 'Pharmacogenetics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Reading', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk Factors', 'Sampling', 'Scientist', 'Signs and Symptoms', 'Solid', 'Statistical Methods', 'Statistical Models', 'Subgroup', 'Substance Addiction', 'Substance Use Disorder', 'Surveys', 'Symptoms', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Work', 'addiction', 'alcohol use disorder', 'biomarker performance', 'biomedical informatics', 'career development', 'cocaine use', 'contingency management', 'design', 'disease classification', 'disorder subtype', 'endophenotype', 'genetic association', 'genomic data', 'imaging genetics', 'improved', 'innovation', 'multidimensional data', 'neural correlate', 'novel', 'novel strategies', 'opioid use disorder', 'outcome prediction', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'secondary analysis', 'skills', 'social', 'substance use treatment', 'tool', 'treatment planning', 'treatment response', 'tutoring']",NIDA,UNIVERSITY OF CONNECTICUT STORRS,K02,2021,158923
"Methods for Evolutionary Genomics Analysis Summary/Abstract Continuing advances in nucleotide sequencing have resulted in the assembly of datasets containing large numbers of species, genes, and genomic segments. Phylogenomic analyses of these data are essential to progress in understanding evolutionary patterns across the tree of life, and are finding increasing numbers of applications in practical analyses that require understanding of how patterns change over time. The sheer size of phylogenomic datasets limits the practical utility of available methods due to excessive time and memory requirements. We have developed many high impact methods and tools for comparative analysis of molecular sequences, a tradition we propose to continue through this MIRA project by developing innovative methods that address new challenges in phylogenomics. We will focus on pattern-based approaches of machine learning with sparsity constraint (SL) applied to phylogenomics, as a complement to traditional model-based methods in molecular evolution and phylogenetics. In the proposed SL in Phylogenomics (SLiP) framework, we will build models that best explain the biological trait or evolutionary hypothesis of interest, with genomic loci, such as genes, proteins, and genomic segments, serving as model parameters. Preliminary results from two example applications establish the premise and promise of a general SLiP framework. In one, SLiP successfully detected loci whose inclusion in a phylogenomic dataset overtakes a consistent and contrasting signal from hundreds of other loci when inferring phylogenetic relationships. In the other example, SLiP revealed loci and biological functional categories that harbor convergent sequence evolutionary patterns associated with the emergence of the same trait in distinct evolutionary lineages. In all of these analyses, SLiP required only a small fraction of the computational time and memory demanded by traditional methods, and it enabled better evolutionary contrasts with fewer assumptions. Consequently, the successful development of SLiP will improve the feasibility, rigor, and reproducibility of large-scale data analysis. It will also democratize big data analytics via shortened analysis time and a relatively small memory footprint, and encourage the development of a new class of methods for phylogenomic analysis. This framework will be accessed from a free library of SLiP functions, which will be directly useable via command line and available in a graphical interface through integration with the MEGA software. Narrative The long-term goal of my research program is to develop methods and tools for comparative analysis of molecular sequences. In this project, we will develop a new class of phylogenomic methods based on sparse machine learning and benchmark their absolute and relative performance. New techniques and their software implementation will greatly facilitate data analyses that are vital for evolutionary and functional genomics.",Methods for Evolutionary Genomics Analysis,10086181,R35GM139540,"['Address', 'Benchmarking', 'Big Data Methods', 'Biological', 'Categories', 'Complement', 'Computer software', 'Data Analyses', 'Data Set', 'Development', 'Gene Proteins', 'Genes', 'Genomic Segment', 'Genomics', 'Goals', 'Libraries', 'Life', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular Analysis', 'Molecular Evolution', 'Nucleotides', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Reproducibility', 'Research', 'Signal Transduction', 'Techniques', 'Time', 'Trees', 'base', 'comparative', 'functional genomics', 'genomic locus', 'graphical user interface', 'improved', 'innovation', 'interest', 'large scale data', 'programs', 'tool', 'trait']",NIGMS,TEMPLE UNIV OF THE COMMONWEALTH,R35,2021,396250
"Experimentally guided modeling and simulation for cholera dynamics Project Summary/Abstract Coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), remains a global pandemic at present. Quantitative research is urgently needed to clarify the impacts of the current vaccination campaign on the pandemic evolution and economic growth, and to guide future policy development. The overall objective of this proposal is to establish a new computational modeling framework for an investigation of the COVID-19 vaccination campaign in the US, and to incorporate real data to assess the impacts of COVID-19 vaccination on public health and the economy. To achieve this objective, the team will pursue three specific aims: (1) Modeling the transmission and spread of COVID-19 under the impact of vaccination; (2) Modeling the economic impact of COVID-19 vaccination; (3) Conducting a case study for the Chattanooga region in the state of Tennessee. The proposed research is significant because it will incorporate detailed characteristics and potential limitations of the current vaccination campaign (such as the vaccine efficacy, phased allocation schemes, public resistance to vaccination, and vaccine breakthrough due to new variants of SARS- CoV-2) into a sophisticated modeling framework, which will enable us to make more accurate forecasts on the progression and long-term evolution of the pandemic. As such, the project is expected to advance the current understanding of COVID-19 transmission and to quantify the interaction between epidemic spreading, economic growth, and disease prevention and intervention under the impact of COVID-19 vaccination, all of which are important for the control and management of the pandemic. The approach is innovative in the development of a computational framework that integrates novel mechanistic and machine learning models and that connects the epidemic and economic aspects of COVID-19. The innovation of this project is also reflected by the integration of sophisticated computational modeling, rigorous mathematical analysis, intensive numerical simulation, and detailed data validation. The project represents an interdisciplinary collaboration among an applied and computational mathematician with long-term interest in infectious disease modeling (Wang), an epidemiologist with extensive working experiences at CDC and a current member of the regional COVID-19 task force (Heath), a business and management professor with a background in public heath (Mullen), and a statistician with expertise in machine learning and biomedical data analytics (Ma). The success of this project will not only build a solid knowledge base for the complex transmission dynamics of SARS-CoV-2 and the health and economic impacts of COVID-19 vaccination, but also provide important guidelines for the government agencies and public health administrations in pandemic management and policy development. Project Narrative The proposed project is relevant to public health because a deep understanding of the COVID-19 vaccination campaign and its health and economic impacts will help to inform the pandemic management and improve the current practice in disease prevention and intervention. The mathematical and machine learning models developed in this project will improve such understanding and make new knowledge discovery. This research effort aligns with part of NIH's mission to reduce public health burdens of infectious diseases.",Experimentally guided modeling and simulation for cholera dynamics,10376956,R15GM131315,"['2019-nCoV', 'Address', 'Advisory Committees', 'Attention', 'Businesses', 'COVID-19', 'COVID-19 vaccination', 'Case Study', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Cholera', 'Clinical Research', 'Collaborations', 'Communicable Diseases', 'Complement', 'Complex', 'Computer Models', 'Computer Simulation', 'Country', 'County', 'Coupled', 'Data', 'Data Analytics', 'Data Set', 'Development', 'Differential Equation', 'Economic Factors', 'Economic Models', 'Economics', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evolution', 'Foundations', 'Future', 'Goals', 'Government Agencies', 'Growth', 'Guidelines', 'Health', 'Investigation', 'Joints', 'Knowledge Discovery', 'Machine Learning', 'Mathematics', 'Mission', 'Modeling', 'Persons', 'Phase', 'Policy Developments', 'Preventive Intervention', 'Public Health', 'Public Health Administration', 'Research', 'Resistance', 'Route', 'SARS-CoV-2 transmission', 'SARS-CoV-2 variant', 'Scheme', 'Schools', 'Science', 'Solid', 'Techniques', 'Tennessee', 'Theoretical Studies', 'Unemployment', 'United States National Institutes of Health', 'Vaccination', 'Vaccines', 'Validation', 'computer framework', 'disorder prevention', 'dynamic system', 'economic impact', 'economic indicator', 'experience', 'experimental study', 'health economics', 'improved', 'infectious disease model', 'innovation', 'interdisciplinary collaboration', 'interest', 'knowledge base', 'mathematical analysis', 'mathematical learning', 'mathematical model', 'member', 'models and simulation', 'novel', 'pandemic disease', 'professor', 'programs', 'simulation', 'success', 'transmission process', 'vaccine efficacy']",NIGMS,UNIVERSITY OF TENNESSEE CHATTANOOGA,R15,2021,122580
