text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,10147906,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2021,417279
"Deep learning for renal tumor characterization Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning for renal tumor characterization,10116348,R03CA249554,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,RHODE ISLAND HOSPITAL,R03,2021,80500
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10256621,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2021,447500
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876
"Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization PROJECT SUMMARY Assisted Reproduction Technology (ART) is a clinical treatment for infertile couples who want to achieve a pregnancy. In ART, embryologists fertilize eggs retrieved from the patient or a donor, culture the resulting embryos in vitro, and then transfer the selected embryo(s) to the mother's uterus. While ART is responsible for 1.9% of babies born in the United States as of 2018, selecting which embryo to transfer is a signiﬁcant challenge. The difﬁculty comes from the complexity of confounding factors and the lack of understanding of human pre-implantation embryo development. Because of this difﬁculty, multiple embryos are often transferred to increases the potential of success, resulting in multiple pregnancy rates of nearly 20%, which can lead to signiﬁcant morbidity and medical expenses to patients. The ideal is to transfer only a single embryo, but this necessitates the ability to select the best embryo from a cohort. Here, we propose to create a clinical decision support system to improve embryo selection in ART. To this end, we will develop novel deep learning models for robust embryo feature extraction and interactive data visualization methods for human-in-the-loop analysis. We will ﬁrst extract and analyze visual features from routinely collected images of embryos. We will then combine these visual features with patients' electronic health record (EHR) data to develop interpretable computation models that score embryos on their viability. We plan to integrate our machine learning solutions into an easily accessible cloud service platform that will be adaptable across clinics to improve ART embryo selection and clinical data analysis. Our research goals will be achieved by novel machine learning-based models for morphological feature extrac- tion and importance estimation of each confounding factor and a clinical decision support system for ART. For morphological feature extraction, we plan to conduct semi-supervised learning of convolutional neural networks to minimize manual labeling that requires extensive human effort. Our feature extraction model will be the ﬁrst comprehensive classiﬁcation and segmentation method for ART. To aid in embryo selection, we will develop novel deep learning-based models to predict probabilities of achieving pregnancy by accepting visual features and EHR data as the input. We will also develop visual analytic tools that allow analysts to better understand and steer these deep learning models. We will estimate the importance of each input interpretable factor in embryo selection to explain the prediction to embryologists. Finally, we will develop EmbryoProﬁler, a clinical decision support system for ART, that combines our machine learning-based models with a user-facing suite of visual analytic tools to support user guidance and clinical decision making. EmbryoProﬁler will help facilitate daily operation in clinics, foster human-guided decision making, enrich data-driven embryo analysis, and enhance the ability to select the developmentally most competent embryo for transfer to improve ART success rates. Our project will create state-of-the-art analysis approaches for ART clinicians. PROJECT NARRATIVE Assisted Reproductive Technology (ART) is a widespread treatment for infertility, over 300,000 treatment cycles were performed in the US in 2018, but success rates remain low. In this project, we will develop novel machine learning algorithms and a clinical decision support system to assist embryologists in embryo selection. Our tools will also enable embryologists and biologists to obtain new information on the earliest stages of human embryo development, which will advance the fundamental science of human biology and lead to further improvements in ART practice.",Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization,10185936,R01HD104969,"['Adopted', 'Age', 'Assisted Reproductive Technology', 'Back', 'Cell Lineage', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Cloud Service', 'Communities', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Computers', 'Couples', 'Data', 'Data Analyses', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Making', 'Detection', 'Development', 'Discipline', 'E-learning', 'Electronic Health Record', 'Embryo', 'Embryo Transfer', 'Embryonic Development', 'Fostering', 'Goals', 'Human', 'Human Biology', 'Image', 'Image Analysis', 'In Vitro', 'Judgment', 'Knowledge', 'Label', 'Lead', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Mothers', 'Multiple Pregnancy', 'Obesity', 'Patients', 'Pattern', 'Physiological', 'Pre-implantation Embryo Development', 'Pregnancy', 'Pregnancy Rate', 'Privacy', 'Probability', 'Research', 'Science', 'Scientist', 'Secure', 'Security', 'Text', 'Time', 'Trees', 'United States', 'Ursidae Family', 'Uterus', 'Visual', 'Visualization', 'Visualization software', 'analytical tool', 'base', 'blastocyst', 'clinical decision-making', 'clinical practice', 'cloud based', 'cohort', 'convolutional neural network', 'data cleaning', 'data curation', 'data management', 'data visualization', 'deep learning', 'embryo cell', 'embryo monitoring', 'feature extraction', 'human-in-the-loop', 'implantation', 'improved', 'infertility treatment', 'insight', 'large scale data', 'machine learning algorithm', 'microscopic imaging', 'model design', 'multi-task learning', 'multimodality', 'novel', 'operation', 'predictive modeling', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'zygote']",NICHD,HARVARD UNIVERSITY,R01,2021,730410
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,10145719,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'in silico', 'indexing', 'learning strategy', 'machine learning method', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2021,378183
"Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology PROJECT SUMMARY/ABSTRACT Candidate: Atalie Carina Thompson, MD, MPH is a current glaucoma fellow and Heed fellow with a long-term career goal of becoming an independent clinician-scientist and leader in the field of glaucoma and public health. She has a long-standing interest in addressing healthcare disparities in medicine, and in improving the diagnosis of glaucoma and other ophthalmic diseases through imaging technology. While obtaining a medical degree at Stanford, she received a fellowship to complete a master’s degree in public health with additional higher-level coursework in biostatistics and epidemiology. Her immediate goal in this proposal is to refine and validate a deep learning (DL) algorithm capable of quantifying neuroretinal damage on optic disc photographs and then to apply it in a pilot teleophthalmology program. With a K23 Mentored Patient-Oriented Research Career Development Award, she will acquire additional didactic training and mentored research experience in glaucoma imaging, machine learning, biostatistics, clinical research, and the responsible conduct of research. Environment: The mentorship and expertise of the advisory committee, the extensive resources at the Duke Eye Center and Departments of Biostatistics and Biomedical Engineering, and the significant institutional commitment will provide her with the support needed to transition successfully into an independent clinician-scientist. Research: This proposal will test the hypothesis that a DL algorithm trained with SDOCT detects glaucoma on optic disc photographs with greater accuracy than human graders. In Specific Aim 1, a DL algorithm that quantifies neuroretinal damage on optic disc photographs will be refined. The main hypothesis is that the quantitative output provided by the DL algorithm will allow accurate discrimination of eyes at different stages of the disease according to standard automated perimetry, and will generate cut-offs suitable for use in a screening setting. In Specific Aim 2, the short-term repeatability and reproducibility of the DL algorithm in optic disc photographs acquired over a time period of several weeks will be determined. The hypothesis is that the test-retest variability of the predictions from the DL algorithm will be similar to the original measurements acquired by SDOCT. In Specific Aim 3, the DL algorithm will be applied to optic disc photographs obtained during a pilot screening teleophthalmology program in primary care clinics and assisted living facilities. The hypothesis is that the DL algorithm will be more accurate than human graders when a full ophthalmic examination is used as the gold standard. This work will constitute the basis of an R01 grant and will advance our understanding of the application of deep learning algorithms in glaucoma and teleophthalmology. PROJECT NARRATIVE Glaucoma is the leading cause of irreversible blindness in the world. However, since the disease can be asymptomatic until later stages, many patients with glaucoma will not know they have glaucoma until they suffer substantial and irreversible visual field loss. This study seeks to refine and validate a deep learning algorithm for early diagnosis of glaucoma on optic disc photographs and subsequently test it in a pilot teleophthalmology program.",Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology,10105327,K23EY030897,"['Address', 'Adult', 'Advisory Committees', 'Agreement', 'Algorithms', 'Artificial Intelligence', 'Assisted Living Facilities', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Dependence', 'Detection', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Environment', 'Epidemiology', 'Evaluation', 'Eye', 'Eye diseases', 'Fellowship', 'Frequencies', 'Fundus', 'Fundus photography', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Human', 'Image', 'Imaging technology', 'Improve Access', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Masks', 'Master&apos', 's Degree', 'Measurement', 'Medical', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Nature', 'Optic Disk', 'Optical Coherence Tomography', 'Output', 'Patients', 'Perimetry', 'Primary Health Care', 'Public Health', 'Reference Standards', 'Reproducibility', 'Research', 'Research Priority', 'Research Proposals', 'Resources', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Severity of illness', 'Specialist', 'Suspect Glaucomas', 'Technology', 'Testing', 'Thick', 'Time', 'Training', 'Validation', 'Visual Fields', 'Visual impairment', 'Width', 'Work', 'algorithm training', 'career', 'carina', 'cohort', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experience', 'eye center', 'health care disparity', 'high risk', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'learning network', 'neural network', 'novel', 'novel diagnostics', 'population based', 'programs', 'prospective', 'public health intervention', 'responsible research conduct', 'retinal nerve fiber layer', 'screening', 'tool']",NEI,DUKE UNIVERSITY,K23,2021,193774
"Dialysis access monitoring using a digital stethoscope-based deep learning system Project Summary/Abstract This SBIR Phase I project will develop a deep learning-based algorithm to analyze the sound of blood flow in mature arterio-venous (AV) fistulas used for hemodialysis access. This monitoring tool can help to identify fistulas with impending failure in patients who are in need of surgical intervention to ensure patency of the patient’s hemodialysis access. The specific aims of the study are (1) to create the world’s first deep learning-scale database of mature AV fistula sounds paired with ultrasound imaging from hemodialysis patients, and (2) develop and evaluate the performance of a deep learning classification model trained via semi-supervised learning to discriminate between patients with patent fistulas and patients with failing fistulas. By integrating this deep learning algorithm into Eko’s mobile and cloud software platform, we anticipate this algorithm will enable better monitoring for failing fistulas. During Phase I of the project we will recruit study subjects in vascular surgery and interventional radiology clinics at Columbia University Medical Center. The follow-up SBIR Phase II project will extend our algorithm to account for (1) broader forms of hemodialysis access including AV grafts, which often fail more frequently than fistulas, and premature fistulas, which are often abandoned, and (2) longitudinal collection and analysis of hemodialysis access sounds at commercial dialysis centers and in patients’ homes. SBIR Project Narrative In creating the world’s largest annotated dataset of mature AV fistula sounds and corresponding ultrasounds, Eko will gain unprecedented insights into fistula blood flow. We expect this to advance our scientific understanding of the fluid dynamics of fistulas, and help explain how and why hemodialysis access fails at such a high rate over time. A clinical decision support algorithm trained from this dataset can help healthcare systems detect fistula failures earlier, leading to more timely interventions that can avert costly complications, prolong life expectancy, and improve quality of life for hemodialysis patients as their care transitions from clinic to home care.",Dialysis access monitoring using a digital stethoscope-based deep learning system,10255460,R43DK129107,"['Academic Medical Centers', 'Algorithms', 'Arteriovenous fistula', 'Artificial Intelligence', 'Auscultation', 'Blood Vessels', 'Blood flow', 'Bluetooth', 'Caring', 'Cellular Phone', 'Classification', 'Clinic', 'Collection', 'Data', 'Data Set', 'Databases', 'Detection', 'Dialysis procedure', 'Distal', 'Early Intervention', 'Educational process of instructing', 'Eko', 'End stage renal failure', 'Enrollment', 'Ensure', 'Failure', 'Fistula', 'Goals', 'Health', 'Healthcare Systems', 'Heart Sounds', 'Hemodialysis', 'Home environment', 'Internet', 'Intervention', 'Interventional radiology', 'Lead', 'Legal patent', 'Life Expectancy', 'Liquid substance', 'Location', 'Maintenance', 'Measurement', 'Medicare', 'Meta-Analysis', 'Modeling', 'Monitor', 'Nephrology', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Physical Examination', 'Positioning Attribute', 'Procedures', 'Quality of life', 'Renal Replacement Therapy', 'Research Design', 'Small Business Innovation Research Grant', 'Standardization', 'Stenosis', 'Stethoscopes', 'Study Subject', 'Survival Rate', 'System', 'Tablet Computer', 'Time', 'Training', 'Transplantation', 'Ultrasonography', 'Validation', 'algorithm training', 'analog', 'base', 'clinical database', 'clinical decision support', 'clinically relevant', 'cloud based', 'cloud software', 'commercialization', 'convolutional neural network', 'cost', 'data streams', 'deep learning', 'deep learning algorithm', 'deep neural network', 'digital', 'evaluation/testing', 'experience', 'follow-up', 'improved', 'innovation', 'insight', 'patient home care', 'premature', 'recruit', 'skills', 'sound', 'standard of care', 'supervised learning', 'systematic review', 'tool']",NIDDK,"EKO DEVICES, INC.",R43,2021,299358
"Deep Learning Assessment of the Right Ventricle: Function, Etiology, and Prognosis ABSTRACT Heart failure imposes a tremendous burden of morbidity and mortality, costing the United States in excess of $31 billion annually. An increasingly recognized major determinant of outcomes in heart failure is right ventricular (RV) dysfunction. However, the nature and character of RV contribution to cardiovascular outcomes remains poorly understood, largely due to the imprecision of imaging and interpretation of RV morphology and function. Echocardiography, with its high temporal resolution and low cost of acquisition, serves as frontline cardiovascular imaging and a mainstay in approaches to assessing RV morphology and function. However, echocardiographic imaging of the RV is limited by factors that include technical variation in image acquisition and heterogeneity in image assessment as well as overall interpretation. We postulate that deep learning based phenotyping can offer the ability to not only more precisely characterize RV function but also classify RV imaging phenotypes according to etiologic disease states and, even further, refine prognostic evaluations of future cardiovascular risk. Therefore, in Aim 1, we will use video-based deep learning segmentation models to assess RV function, evaluate its cross-sectional relation with a range of expert-measured parameters, and examine its variation in the context of patient characteristics derived from large hospital-based cohorts. In Aim 2, we will use video-based deep learning models to produce imaging-based classification of RV disease and assess the ability of unsupervised approaches to classify RV dysfunction into various categories of disease etiology. In Aim 3, we will use models developed in part from training in Aims 1 and 2 to predict major cardiovascular outcomes including heart failure in addition to coronary artery disease, stroke, and cardiovascular death in both hospital- based and community-based cohorts. The overarching goal of this proposal is to improve the precision and standardization of RV phenotyping and determine the extent to which deep learning models can augment human assessment of the RV. This research will be accomplished in the setting of a comprehensive career development program designed to provide the candidate with the skills needed to become an independent physician-scientist in cardiovascular medicine and translational imaging science. An advisory committee of established scientists/mentors in the fields of cardiac imaging, deep learning, data science, and translational science will guide the candidate in his transition to scientific independence over the course of the award period. PUBLIC HEALTH RELEVANCE STATEMENT Heart failure imposes a tremendous morbidity and mortality burden, costing the U.S. healthcare system over $31 billion per year. An under-recognized and yet important contributor to heart failure outcomes is right ventricular dysfunction, which remains understudied due to technical issues that have historically challenged conventional approaches to cardiovascular imaging. We will examine how deep learning models can precisely evaluate right ventricular function – and enable earlier, more accurate assessments of its contributions to cardiovascular risk.","Deep Learning Assessment of the Right Ventricle: Function, Etiology, and Prognosis",10185865,K99HL157421,"['Address', 'Advisory Committees', 'Architecture', 'Arrhythmogenic Right Ventricular Dysplasia', 'Award', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Cohort Studies', 'Communities', 'Computer Vision Systems', 'Coronary Arteriosclerosis', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Diagnosis', 'Disease', 'Disease Outcome', 'Dissection', 'Early Diagnosis', 'Echocardiography', 'Engineering', 'Epidemiology', 'Etiology', 'Evaluation', 'Framingham Heart Study', 'Future', 'Goals', 'Health system', 'Healthcare', 'Healthcare Systems', 'Heart failure', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Medicine', 'Mentors', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Motion', 'Multi-Ethnic Study of Atherosclerosis', 'Nature', 'Outcome', 'Participant', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physicians', 'Program Development', 'Prospective cohort', 'Pulmonary Embolism', 'Research', 'Research Personnel', 'Right Ventricular Dysfunction', 'Right Ventricular Function', 'Right ventricular structure', 'Risk', 'Risk Factors', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Standardization', 'Stroke', 'Techniques', 'Training', 'Translational Research', 'United States', 'Validation', 'Variant', 'Ventricular', 'base', 'cardiovascular imaging', 'cardiovascular risk factor', 'career', 'career development', 'cohort', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'hands on research', 'healthcare community', 'heart imaging', 'improved', 'mortality', 'neural network', 'neural network architecture', 'novel', 'outcome forecast', 'outcome prediction', 'performance tests', 'population based', 'predictive modeling', 'prognostic', 'programs', 'public health relevance', 'pulmonary arterial hypertension', 'skills', 'spatiotemporal', 'statistics', 'study population', 'success', 'temporal measurement']",NHLBI,CEDARS-SINAI MEDICAL CENTER,K99,2021,154780
"Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at managing the optimal care for individual cases due to difficulties of accurately assessing the potential progression and its speed and magnitude. These difficulties are due to a variety of causes that change over the course of the disease, including large inter-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we propose novel agnostic data-driven deep learning approaches to detect glaucoma and accurately forecast its progression that are optimized to each individual case. We will use state- of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. Instead of relying on the conventional knowledge-based approaches (e.g. quantifying tissues known to be significantly associated with glaucoma such as retinal nerve fiber layer), the proposed cutting-edge agnostic deep learning approaches determine the features responsible for future structural and functional changes out of thousands of features autonomously by learning from the provided large longitudinal dataset. This program will advance the use of structural and functional information obtained in the clinics with a substantial impact on the clinical management of subjects with glaucoma. Furthermore, the developed methods have potentials to be applied to various clinical applications beyond glaucoma and ophthalmology. Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies using agnostic deep learning approaches that will substantially improve detection of glaucoma and its progression forecasting and monitoring in order to prevent blindness.",Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes,10089451,R01EY030929,"['3-Dimensional', 'Area', 'Atlases', 'Blindness', 'Brain', 'Caring', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Management', 'Collaborations', 'Color', 'Complex', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Disease model', 'Early Diagnosis', 'Eye', 'Future', 'Glaucoma', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurable', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Ophthalmology', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Performance', 'Research', 'Research Proposals', 'Retina', 'Sampling', 'Series', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Vision', 'Visit', 'Visual Fields', 'analytical method', 'base', 'case-by-case basis', 'clinical application', 'clinical practice', 'cohort', 'computerized', 'cost', 'deep learning', 'falls', 'feature selection', 'follow-up', 'image processing', 'imaging modality', 'improved', 'in vivo', 'individual patient', 'innovation', 'insight', 'knowledge base', 'longitudinal analysis', 'longitudinal dataset', 'machine learning method', 'novel', 'ocular imaging', 'personalized approach', 'personalized medicine', 'personalized predictions', 'predictive modeling', 'preservation', 'prevent', 'programs', 'retinal nerve fiber layer', 'theories', 'tool', 'treatment planning', 'trend']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,376028
"Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors Project Summary Scientific understanding of adaptive immune receptors (i.e. antibodies and T cell receptors) has the potential to revolutionize prophylaxis, diagnosis, and treatment of disease. High‐throughput DNA sequencing and functional experiments have now brought the study of adaptive immune receptors into the big‐data era. To realize this potential of these data they must be matched with appropriately powerful analytical techniques. Existing probabilistic and mechanistic models are insufficient to capture the complexities of these data, while a naïve application of machine learning cannot leverage our profound existing knowledge of the immune system. The goal of this project is to blend deep learning with mechanistic modeling in order to predict and understand the evolution and function of adaptive immune receptors. Aim 1: Develop generative models of immune receptor sequences that capture the complexity of real adaptive immune receptor repertoires. These will combine deep learning along with our knowledge of VDJ recombination, and provide a rigorous platform for detailed repertoire comparison. Aim 2: Develop quantitative mechanistic models of antibody somatic hypermutation that incorporate the underlying biochemical processes. Estimate intractable likelihoods using deep learning to infer important latent variables, and validate models using knock‐out experiments in cell lines. Aim 3: Develop hybrid deep learning models to predict binding properties from sequence data, combining large experimentally‐derived binding data with even larger sets of immune sequences from human immune memory samples. Incorporate structural information via 3D convolution or distance‐based penalties. These tools will reveal the full power of immune repertoire data for medical applications. We will obtain more rigorous comparisons of repertoires via their distribution in a relevant space. These will reveal the effects of immune perturbations such as vaccination and disease, allowing us to pick out sequences that are impacted by these perturbations. We will have a greater quantitative understanding of somatic hypermutation in vivo, and statistical models that appropriately capture long‐range effects of collections of mutations. We will also have algorithms that will be able to combine repertoire data and sparse binding data to predict binding properties. Put together, these advances will enable rational vaccine design, treatment for autoimmune disease, and identification of T cells that are promising candidates for cancer immunotherapy. Project Narrative Adaptive immune receptors (i.e. antibodies and T cell receptors) enable our body to fight off disease, “remember” pathogens, and train the immune system through vaccination. Immunologists have learned via high‐throughput sequencing that adaptive immune receptors have a truly remarkable diversity. In this proposal, we develop machine‐learning methods for these sequence data, which will allow us to predict the maturation, statistical distribution, and binding properties of adaptive immune receptors, and thus to better design vaccinations, autoimmune disease treatment, and immunotherapy treatment for cancer.",Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors,10159730,R01AI146028,"['3-Dimensional', 'Algorithms', 'Animal Model', 'Antibodies', 'Antibody Affinity', 'Antigens', 'Architecture', 'Autoimmune Diseases', 'Automobile Driving', 'Big Data', 'Binding', 'Biochemical', 'Biochemical Process', 'Categories', 'Cell Line', 'Characteristics', 'Collection', 'Complement', 'Complex', 'Data', 'Data Set', 'Dependence', 'Diagnosis', 'Disease', 'Entropy', 'Evolution', 'Exposure to', 'Foundations', 'Gene Conversion', 'Generations', 'Goals', 'High-Throughput DNA Sequencing', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Immune', 'Immune response', 'Immune system', 'Immunoglobulin Somatic Hypermutation', 'Immunologic Memory', 'Immunologic Receptors', 'Immunological Models', 'Immunologics', 'Immunologist', 'Immunology', 'Immunotherapy', 'In Vitro', 'Individual', 'Knock-out', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Pathway interactions', 'Population', 'Procedures', 'Process', 'Property', 'Prophylactic treatment', 'Resolution', 'Sampling', 'Science', 'Statistical Distributions', 'Statistical Methods', 'Statistical Models', 'Structure', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'V(D)J Recombination', 'Vaccination', 'Vaccine Design', 'Vaccines', 'Validation', 'Work', 'algorithm training', 'analytical tool', 'base', 'biochemical model', 'cancer immunotherapy', 'cancer therapy', 'complex data', 'deep learning', 'deep neural network', 'deep sequencing', 'design', 'experimental study', 'fighting', 'functional group', 'in vivo', 'insertion/deletion mutation', 'large datasets', 'machine learning method', 'markov model', 'pathogen', 'progenitor', 'receptor', 'repaired', 'response', 'success', 'three dimensional structure', 'tool']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,689648
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10226322,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data repository', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2021,220287
"Interpretable deep learning models for translational medicine Understanding the state of cellular signaling systems provides insights to how cells behave under physiological and pathological conditions. Cellular signaling systems are organized as hierarchy (cascade) and signals of a molecular is often compositionally encoded to control cellular processes, such as gene expression. This project aims to develop advanced deep learning models (DLMs) to simulate cellular signaling systems based on gene expression data. In last 3 years, the project has made significant progresses, but the challenges remain. Importantly, contemporary DLMs behave as “black boxes”, in that it is difficult to interpret how signals are encoded and how to interpret which signal a hidden node represent in a DLM. This black-box nature prevents researchers from gaining biological insights using DLMs, even though these models can be much superior in modeling data than other types of models in many tasks, e.g., predicting drug sensitivity of cancer cells. In this competitive renewal, we propose to develop novel DLMs and innovative inference algorithms to train “interpretable” DLMs and apply them in translational research. The proposed research is innovative and of high significance in several perspectives: 1) Our novel DLMs and algorithms take advantage of big data resulting from systematic chemical/genetic perturbations of cellular signaling machinery, so that we can use the perturbation condition as side information to reveal how signals are encoded in a DLM. 2) We integrate principles of causal inference and information theory with deep learning method to make DLMs interpretable. As results, that researchers can gain mechanistic insights from such models. 3) Innovative application of interpretable DLMs will advance translational research. For example, we will train interpretable DLMs to model cellular signaling at the level of single cells and use this information investigate inter-cellular interactions among cells in tumor microenvironment to shed light on immune evasion mechanisms of cancers. We will also use information derived from interpretable DLMs to predict cancer cell drug sensitivity. We anticipate that our study will bring forth significant advances not only in deep learning methodology but also in precision medicine. This project aims to develop advance machine learning methods, referred to as deep learning models, to simulate cellular signaling systems, at both multiple cell and single cell levels. Success of these models will enable researchers to investigate cellular behaviors under physiological and pathological condition, and such information can be used to guide therapy of cancer patients.",Interpretable deep learning models for translational medicine,10171908,R01LM012011,"['Affect', 'Algorithms', 'Antineoplastic Agents', 'Big Data', 'Biological', 'Cancer Patient', 'Cancer cell line', 'Cell model', 'Cell physiology', 'Cells', 'Data', 'Disease', 'Event', 'Gene Expression', 'Genetic', 'Genetic Transcription', 'Grain', 'Human', 'Immune Evasion', 'Immunotherapy', 'Individual', 'Information Theory', 'Intervention', 'Knowledge', 'Learning', 'Libraries', 'Light', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'MicroRNAs', 'Mining', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Network-based', 'Organoids', 'Outcome', 'Paper', 'Pathologic', 'Pathway interactions', 'Patients', 'Pharmacology', 'Phenotype', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Side', 'Signal Pathway', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'The Cancer Genome Atlas', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Yeasts', 'base', 'biological systems', 'cancer cell', 'cancer therapy', 'cell behavior', 'chemical genetics', 'data modeling', 'deep field survey', 'deep learning', 'deep learning algorithm', 'design', 'drug sensitivity', 'experience', 'genome-wide', 'innovation', 'inquiry-based learning', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'novel', 'patient response', 'pre-clinical', 'precision medicine', 'precision oncology', 'predicting response', 'prevent', 'response', 'single-cell RNA sequencing', 'success', 'theories', 'tool', 'transcription factor', 'transcriptome', 'transcriptomics', 'translational impact', 'translational medicine', 'translational model', 'tumor', 'tumor microenvironment']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,309404
"Development of End-To-End Clinical Decision Support Tools To Prevent Cardiotoxic Drug Response SUMMARY Drug-induced cardiac toxicity, in the form of QT prolongation and torsade de pointes, is an uncommon but devastating side effect of over one hundred currently marketed drugs. The ubiquity of drug-induced QT prolongation (diLQTS) across medical specialties and conditions creates a challenge for providers seeking to prescribe known QT-prolonging medications, particularly for non-cardiac conditions. Work by our group to develop automated clinical decision support (CDS) tools that alert providers of patient risk has shown promise towards reducing the number of prescriptions to at-risk individuals. However, these tools rely on a history of an electrocardiogram (ECG) with QT prolongation to identify at-risk patients, and thus exclude a large number of potentially at-risk individuals who have not had an ECG within our system. Through a unique institutional partnership with Google, in which a copy of our entire electronic health record (EHR) is stored on the Google Cloud Platform (GCP), we have developed preliminary deep-learning models to predict risk of diLQTS. We have also validated the genetic association with the QT interval and diLQTS across several real-world populations using an aggregate polygenic risk score. Through creation of an institutional biobank with certification for clinical application of results, as well as cloud-based integration of EHR data with genetic data, we have the capability to leverage our existing infrastructure to study the role of deep learning and genetics to reduce the risk of diLQTS. This investigation will combine our unique research and clinical infrastructure on the University of Colorado Anschutz Medical Campus with our investigative team composed of experts in the study of pharmacogenomics and medical informatics to develop and study an end-to-end CDS tool incorporating genetics and deep learning to predict risk of diLQTS. The specific aims of this application include the following: (1) develop and test a cloud-based, deep-learning model using EHR data on in- and outpatients to predict risk of diLQTS; (2) validate genetic predictors of diLQTS using institutional biobank samples, and a multi-ethnic external population; and (3) develop and test CDS tools using these advanced methods to reduce the risk of diLQTS. We will use a common data model (Observational Medical Outcomes Partnership) mapped from EHR data, as well as a custom DNA array (Multi-Ethnic Genotyping Array) designed for imputation across a variety of non-European ancestries, to ensure that the our prediction model and findings from this study can be replicated in other institutions and populations in the future. In such a way, this investigation will not only provide insight into the use of machine learning and genetics for risk prediction of diLQTS, but it will also create a blueprint for future advanced CDS development for other conditions. PROJECT NARRATIVE The goal of this project is the development of a clinical decision support tool that can be used to predict the risk of drug-induced QT prolongation based on deep learning and genetics. This tool could be used to prevent potentially fatal side effects of medications when alternatives are available, or increase vigilance when safer alternatives are not available. This study is specifically designed so that the models created can be directly applied across other institutional medical record systems beyond the study population.",Development of End-To-End Clinical Decision Support Tools To Prevent Cardiotoxic Drug Response,10088467,R01HL146824,"['Adherence', 'Adverse drug effect', 'Arrhythmia', 'Artificial Intelligence', 'Automated Clinical Decision Support', 'Benefits and Risks', 'Biometry', 'Cardiotoxicity', 'Certification', 'Clinical', 'Cluster randomized trial', 'Colorado', 'Custom', 'DNA', 'Data', 'Data Science', 'Decision Analysis', 'Development', 'Electrocardiogram', 'Electronic Health Record', 'Ensure', 'Excision', 'Future', 'Genetic', 'Genetic Risk', 'Genotype', 'Goals', 'Health Technology', 'Health system', 'Heritability', 'Hospitals', 'Individual', 'Information Technology', 'Infrastructure', 'Inpatients', 'Institution', 'Investigation', 'Long QT Syndrome', 'Machine Learning', 'Maps', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Modeling', 'Outcome', 'Outpatients', 'Participant', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Population', 'Protocols documentation', 'Provider', 'Recording of previous events', 'Relative Risks', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sample Size', 'Sampling', 'Science', 'System', 'Technology', 'Testing', 'Time', 'Torsades de Pointes', 'Toxic effect', 'Universities', 'Validation', 'Variant', 'Work', 'analytical tool', 'base', 'biobank', 'classification algorithm', 'clinical application', 'clinical decision support', 'clinical implementation', 'clinical infrastructure', 'cloud based', 'cloud platform', 'cloud storage', 'data modeling', 'data warehouse', 'deep learning', 'design', 'disorder risk', 'drug market', 'electronic data', 'experience', 'genetic association', 'genetic epidemiology', 'genetic information', 'genetic predictors', 'genetic variant', 'genome wide association study', 'health data', 'improved', 'innovation', 'insight', 'machine learning method', 'medical schools', 'medical specialties', 'patient safety', 'personalized medicine', 'polygenic risk score', 'practical application', 'predictive modeling', 'prevent', 'primary outcome', 'response', 'risk prediction', 'risk stratification', 'secondary outcome', 'side effect', 'study population', 'support tools', 'tool', 'trend', 'vigilance']",NHLBI,UNIVERSITY OF COLORADO DENVER,R01,2021,777314
"Virtual Biopsy with Tissue-level Accuracy in Glioma Project Summary This is a Bioengineering Research Grant (BRG) proposal in response to PAR-19-158 to further develop and validate a non-invasive panel of the most critical glioma molecular markers (IDH, 1p/19q, MGMT) using standard clinical MRI T2-weighted images and deep learning, and extend the performance to tissue-level accuracies. Currently, the only reliable way of obtaining molecular marker status is through direct tissue sampling of the tumor, requiring either a craniotomy and stereotactic biopsy or a large open surgical resection. Noninvasive determination of molecular markers with tissue-level accuracy would be transformational in the management of gliomas, reducing or eliminating the risks and costs associated with a neurosurgical procedure, accelerating the time to definitive treatment, improving patient experience and ultimately patient outcomes and survival time. Artificial intelligence such as deep learning has emerged as a powerful method for classification of imaging data that can exceed human performance. Preliminary work using our novel voxel-wise classification-segmentation approach with the NIH/NCI TCIA glioma database has outperformed any prior noninvasive methods for determination of IDH, 1p/19q, and MGMT methylation, achieving accuracies of 97%, 93%, and 95%, respectively. The approach however, needs to be validated beyond the TCIA and accuracies need to be extended in order to achieve tissue level performance. This will be accomplished by using our top-performing voxel-wise classification framework, leveraging marker-specific targeted sample sizes, and gaining a final boost from deep-learning artifact correction networks. In Aim 1 we will curate a database of over 2000 gliomas including 500 subjects from our institution, 1200 subjects from our external collaborators, and over 300 subjects from the TCIA. We will train our voxel-wise deep learning classifiers to determine molecular status based on clinical T2-weighted MR images with target accuracies of 97%. In Aim 2 we will rigorously evaluate the motion and noise sensitivity of the networks and create an artifact correction network with the goals of 1) recovering accuracies in the setting of large amounts of motion/noise and 2) further boosting accuracy to tissue-level performance even in the absence of visible artifact. In Aim 3 we will deploy a complete end-to-end clinical workflow and evaluate real-world live performance of the AI tool on 300 prospectively acquired brain tumor cases and 300 subjects from our external collaborators. The AI tool will be made available for deployment at other medical centers. The developed framework can also be extended to additional markers in a straightforward fashion. In summary, this BRG proposal will further develop, refine and validate a non-invasive MRI-based method for determining the most critical glioma molecular markers rivaling tissue-level accuracies to significantly reduce and in many cases eliminate the need for stereotactic biopsy. Project Narrative Knowledge of molecular status for a variety of markers in gliomas has moved to the forefront in clinical decision- making. This requires direct tissue sampling either from an invasive brain biopsy or open surgical resection. In this Bioengineering Research Grant proposal in response to PAR-19-158, we will develop and validate a non- invasive method to determine a panel of the most critical molecular markers (IDH, 1p/19q and MGMT methylation) with near tissue-level accuracies using routine T2-weighted (T2w) MR images and deep learning algorithms to significantly reduce and in many cases eliminate the need for stereotactic biopsy in glioma.",Virtual Biopsy with Tissue-level Accuracy in Glioma,10226632,R01CA260705,"['19q', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Automation', 'Biology', 'Biomedical Engineering', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Classification', 'Clinical', 'Computerized Medical Record', 'Craniotomy', 'Data', 'Data Set', 'Databases', 'Digital Imaging and Communications in Medicine', 'Excision', 'Glioma', 'Goals', 'Human', 'Hyperacusis', 'Image', 'Institution', 'Knowledge', 'MGMT gene', 'Magnetic Resonance Imaging', 'Manuals', 'Medical center', 'Methods', 'Methylation', 'Molecular', 'Molecular Analysis', 'Morphologic artifacts', 'Motion', 'Neurosurgical Procedures', 'Noise', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Process', 'Prospective cohort', 'Reporting', 'Research Project Grants', 'Resources', 'Risk', 'Sample Size', 'Sensitivity and Specificity', 'T2 weighted imaging', 'Testing', 'The Cancer Genome Atlas', 'The Cancer Imaging Archive', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Tumor Tissue', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'clinical decision-making', 'clinical implementation', 'clinical translation', 'contrast imaging', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'large datasets', 'learning classifier', 'learning strategy', 'molecular marker', 'motion sensitivity', 'mutational status', 'novel', 'outcome forecast', 'prospective', 'response', 'surgical risk', 'tool', 'tumor', 'virtual biopsy']",NCI,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,655597
"Ultra-Fast Knee MRI with Deep Learning ABSTRACT Fast, robust and reliable quantitative knee joint MR imaging would be a significant step forward in studying joint degeneration, injury and osteoarthritis (OA). Automation of compositional and morphological feature extraction of the tissues in the knee it is an essential step for translation to clinical practice of promising quantitative techniques. It would enable the analysis of large patient cohorts and assist the radiologist/clinician in augmenting the value of MRI. Automation of several human tasks has been achieved in the last few years by the usage of Deep Learning techniques. With the availability of large amounts of annotated data and processing power, using the concepts of transforming data to knowledge by the observation of examples, supervised learning can today accomplish challenges never demonstrated before. In addition to image analysis and interpretation, Deep Learning is revolutionizing the acquisition and reconstruction aspects of the pipeline. Models can learn a direct mapping between under sampled k-space and image domain. While Deep Learning application to musculoskeletal imaging showed promising results when applied in a controlled setting, it is well understood that generalization beyond the statistical distribution of the training set is still an unmet challenge. In MRI this translates into poor performances when trained models are tested on different imaging protocols or images acquired on different MRI systems. With this proposal, we aim to leverage on this recent advancement and filling the existing gaps. We aim to study novel integrated models able to simultaneously accelerate MRI acquisition and automate the image processing that can overcome the limitation of single domain application. Fast image acquisition and accurate image post processing are typically considered to be separate problems. However, the neural networks optimization design gives us an opportunity to integrate the two to maximize both acceleration and machine-based image processing and interpretation. We will use both publicly available benchmark dataset (FastMRI) and internally collected dataset to build deep learning models able to accurately reconstruct under sampled MRI acquisitions. We will use a dataset prospectively acquired during the course of this study to validate the clinical applicability of the developed methods. Specifically, we will test the hypothesis that the proposed integrated pipeline can be applied in clinical setting for a fast and intelligent knee scan obtaining image quality comparable to standard acquisition and automated processing accuracy comparable with human reproducibility. Additionally, we propose to make our annotated image datasets and trained models a shared resource, a centralized, open evaluation platform for MRI reconstruction and image post processing techniques. NARRATIVE This study aims to use Deep Learning to simultaneously accelerate knee MRI acquisition and automate post processing pipelines including multi tissue segmentation, detection and severity staging of osteoarthritis degenerative changes. The proposed study builds a novel translational platform to revolutionize knee MR images in research studies, but also is paradigm-shifting in that it may provide a first step towards on real time automatic image inspection and personalized imaging protocolling.",Ultra-Fast Knee MRI with Deep Learning,10177641,R01AR078762,"['3-Dimensional', 'Acceleration', 'Area', 'Automation', 'Bayesian Modeling', 'Benchmarking', 'Cartilage', 'Characteristics', 'Clinical', 'Collection', 'Complement', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Ensure', 'Evaluation', 'Human', 'Image', 'Image Analysis', 'Injury', 'Intelligence', 'Knee', 'Knee joint', 'Label', 'Lead', 'Learning', 'Licensing', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Morphology', 'Patient Triage', 'Patients', 'Performance', 'Probability', 'Process', 'Protocols documentation', 'Protons', 'Radiology Specialty', 'Reader', 'Reading', 'Reproducibility', 'Research', 'Resolution', 'Resource Sharing', 'Sampling', 'Scanning', 'Severities', 'Signal Transduction', 'Staging', 'Standardization', 'Statistical Distributions', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translating', 'Translations', 'Uncertainty', 'Vendor', 'base', 'clinical application', 'clinical practice', 'clinical translation', 'clinically relevant', 'cohort', 'computerized data processing', 'convolutional neural network', 'data space', 'data to knowledge', 'deep learning', 'density', 'design', 'domain mapping', 'experimental study', 'feature extraction', 'heterogenous data', 'image processing', 'image reconstruction', 'imaging system', 'joint destruction', 'learning ability', 'musculoskeletal imaging', 'neural network', 'new technology', 'novel', 'open source', 'preservation', 'prospective', 'radiologist', 'reconstruction', 'recruit', 'research study', 'sensor', 'supervised learning', 'tool', 'validation studies']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,574344
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,10143171,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,655746
"Quantification of Liver Fibrosis with MRI and Deep Learning Project Summary/Abstract  Chronic liver disease (CLD) is a common cause of morbidity and mortality in the U.S. and throughout the world. In 2017, CLD had an age-adjusted death rate of 10.9/100,000 total population and an estimated lifetime cost of fatty liver disease alone in the U.S. of ~$222 billion. Liver fibrosis (LF) is the most important and only histologic feature known to predict outcomes from CLD. The current standard for assessing LF is biopsy, which is costly, prone to sampling error, and invasive with poor patient acceptance. Thus, there is an urgent unmet need for noninvasive, highly accurate and precise diagnostic technologies for detection and quantification of LF. Our overarching objective is to apply Deep Learning (DL) methods using conventional non-elastographic magnetic resonance (MR) images, MR elastography (MRE), and clinical data to accurately detect and measure LF in children and adults with CLD, using biopsy-derived histologic data as the reference standard. In this project, we will dedicate our efforts to accomplishing the following specific aims. In Aim 1, we will develop and validate a DL framework to accurately segment liver and spleen in order to extract radiomic (gray-scale signal intensity distribution, shape and morphology, volumetry, and inter-voxel signal intensity pattern and texture) and deep features (complex abstractions of patterns non-linearly constructed throughout the transformation estimated by data-driven DL training procedures) from conventional multiparametric MRI. These features allow detection of liver and spleen structural abnormalities/tissue aberrations. In Aim 2, we will develop and validate an “ensemble” DL model (LFNet) to predict biopsy-derived LF stage and LF percentage using the integration of conventional multimodal MRI radiomic and deep features, MRE data, as well as clinical data. In Aim 3, we will develop and validate a DL model (LSNet) to quantify MRE-derived liver stiffness (LS) using conventional multiparametric MRI radiomic and deep features as well as clinical data. The proposed models will help physicians to more accurately detect and follow CLD by 1) quantifying LS from conventional MR imaging without the need for MRE; and, more importantly, 2) predicting histologic LF stage and LF percentage without the need for biopsy, while avoiding inter- radiologist variability, reducing radiologist workload, and ultimately reducing healthcare costs. We will validate the models using both internal and independent external data from various scanners and sites. The techniques we develop are expected to improve medical diagnosis and prognostication in the same way as DL has revolutionized other fields. This study will significantly impact public health because it will allow physicians and researchers to more accurately diagnose and quantify CLD and LF as well as permit more frequent assessments in a noninvasive, patient-centric manner, thus potentially improving patient outcomes while lowering healthcare costs. The techniques we develop also can be readily extended for the prediction of other important liver-related clinical outcomes, including impending complications such as portal hypertension, time to liver transplant/transplant listing, and mortality risk, among others. Project Narrative  Chronic liver disease (CLD) is a common cause of illness and death worldwide, and it is a significant healthcare and financial burden. Liver fibrosis (LF) is a measurable feature of CLD that is important to assess the severity of disease, evaluate for progression and therapy response, and predict outcomes. We propose to apply artificial intelligence methods to noninvasive conventional magnetic resonance images and readily- available clinical data for accurate detection and quantification of LF, thus significantly impacting public health by facilitating personalized therapies without the need for liver biopsy, improved outcomes, and lower healthcare costs.",Quantification of Liver Fibrosis with MRI and Deep Learning,10096229,R01EB030582,"['Address', 'Adult', 'Age', 'American', 'Appearance', 'Artificial Intelligence', 'Bilirubin', 'Biopsy', 'Body mass index', 'Cessation of life', 'Characteristics', 'Child', 'Childhood', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Complex', 'Computer-Assisted Diagnosis', 'Crowding', 'Data', 'Data Set', 'Databases', 'Death Rate', 'Decision Making', 'Descriptor', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Evaluation', 'Eye', 'Fatty Liver', 'Financial Hardship', 'Goals', 'Health Care Costs', 'Health Expenditures', 'Healthcare', 'Histologic', 'Human', 'Image', 'Individual', 'Institution', 'Laboratories', 'Length of Stay', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Magnetic Resonance Elastography', 'Magnetic Resonance Imaging', 'Maps', 'Mathematics', 'Measurable', 'Measures', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Population', 'Portal Hypertension', 'Procedures', 'Property', 'Public Health', 'Reference Standards', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Risk Factors', 'Running', 'Sampling Errors', 'Series', 'Severity of illness', 'Shapes', 'Signal Transduction', 'Site', 'Spleen', 'Staging', 'Structural defect', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissues', 'Training', 'Transplantation', 'Vendor', 'Viral hepatitis', 'Visual', 'Workload', 'accurate diagnosis', 'accurate diagnostics', 'chronic liver disease', 'classification algorithm', 'clinical risk', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'diagnostic technologies', 'elastography', 'hospital readmission', 'hospitalization rates', 'improved', 'improved outcome', 'learning strategy', 'life time cost', 'liver biopsy', 'liver transplantation', 'mortality', 'mortality risk', 'multimodality', 'multitask', 'non-linear transformation', 'outcome prediction', 'personalized diagnostics', 'personalized medicine', 'predictive modeling', 'prognostic', 'radiologist', 'radiomics', 'response', 'sex']",NIBIB,CINCINNATI CHILDRENS HOSP MED CTR,R01,2021,628266
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10269008,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data repository', 'data reuse', 'data sharing', 'data visualization', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2021,617911
"Leveraging deep learning for markerless motion management in radiation therapy Leveraging deep learning for markerless motion management in radiation therapy Project Summary Organ motion is a predominant limiting factor for the maximum exploitation of modern radiation therapy (RT). Adverse influence of the organ motion is aggravated in hypofractionated treatment because of protracted dose delivery. Current image guided RT often relies on the use of implanted fiducial markers (FMs) for online/offline target localization, which is invasive and costly, and introduces possible bleeding, infection and discomfort of the patient. In this project, we harness the enormous potential of deep learning and investigate a novel markerless localization strategy by combined use of a pre-trained deep learning model and kV X-ray projection or cone beam CT images. We hypothesize that incorporation of deep layers of image information allows us to visualize otherwise invisible target in real-time and greatly reduce the uncertainties in beam targeting. Specific aims of the project are to: (1) Develop a DL-based tumor target localization framework for image guided RT (IGRT); (2) Apply the DL-based strategy to localize prostate target on 2D kV X-ray projection and 3D CBCT images; and (3) Evaluate the potential clinical impact of the DL strategy for pancreatic IGRT. This study brings up, for the first time, highly accurate markerless target localization based on deep learning and provides a clinically sensible solution for IGRT of prostate and pancreas cancers or other types of cancers. Successful completion of this investigation will significantly advance the current beam targeting technique and provide radiation oncology discipline a powerful way to safely and reliably escalate the radiation dose for precision RT. Given its significant promise to optimally cater for inter- and intra-fractional uncertainties, the study should lead to substantial improvement in patient care and enables us to utilize maximally the technical capability of modern RT such as IMRT and VMAT. Given the dose responsive nature of various cancers and that the proposed method requires no hardware modification, this research should lead to a widespread impact on the management of neoplasmic diseases affected by organ motion. Leveraging deep learning for markerless motion management in radiation therapy Project Narrative This project is aimed at establishing a deep learning-based image guidance strategy for motion management in prostate and pancreas radiation therapy. Successful completion of this investigation will significantly advance the current beam targeting technique and provide radiation oncology discipline a powerful way to safely and reliably escalate the radiation dose for precision radiation therapy. The research should thus lead to a widespread impact on the management of various neoplasmic diseases affected by organ motion.",Leveraging deep learning for markerless motion management in radiation therapy,10235308,R01CA256890,"['3-Dimensional', 'Affect', 'Brain', 'Clinical', 'Complication', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Disease', 'Dose', 'Duodenum', 'Felis catus', 'Head and neck structure', 'Hemorrhage', 'Image', 'Implant', 'Infection', 'Intensity-Modulated Radiotherapy', 'Investigation', 'Lead', 'Learning', 'Liver', 'Location', 'Lung', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Malignant neoplasm of prostate', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Monitor', 'Motion', 'Nature', 'Neoplasms', 'Normal tissue morphology', 'Organ', 'Pancreas', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Prostate', 'Radiation Dose Unit', 'Radiation Oncology', 'Radiation therapy', 'Radiosurgery', 'Research', 'Retrospective Studies', 'Roentgen Rays', 'Site', 'System', 'Techniques', 'Time', 'Training', 'Uncertainty', 'Vertebral column', 'X-Ray Computed Tomography', 'base', 'cancer type', 'cone-beam computed tomography', 'conventional therapy', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'experimental study', 'image guided', 'image guided intervention', 'image guided radiation therapy', 'improved', 'indexing', 'learning strategy', 'novel', 'pancreas imaging', 'predictive modeling', 'real time model', 'respiratory', 'treatment planning', 'tumor']",NCI,STANFORD UNIVERSITY,R01,2021,442403
"Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope Abstract This SBIR Phase II project will develop a deep learning-based clinical decision support algorithm for detecting and diagnosing valvular heart disease based on heart sounds recorded using the Eko Core and Eko Duo Digital Stethoscopes. This screening tool will help to decrease the number of patients with valvular heart disease that remain undertreated simply because their condition is not diagnosed. Auscultation is commonly the method by which valvular heart disease is first detected, but cases often fail to be referred to echocardiography for diagnosis because clinicians fail to detect heart murmurs, particularly in noisy or rushed environments. To address this challenge, Eko had developed the Core, a digital stethoscope attachment that can be added in-line to a clinician’s existing stethoscope that amplifies heart sounds and Duo, a digital stethoscope in a handheld form factor with built-in single lead electrocardiogram. Both devices are designed to stream digitized phonocardiograms to a smartphone, tablet or personal computer. There, the signal can be analyzed with the decision support algorithm we will develop as part of this project. The specific aims of this study are: (1) to collect a database with condition- specific recording labels to enable deep learning for heart sounds though clinical data collection at six clinical sites, and (2) to develop and evaluate a collection of deep convolutional neural network-based algorithms trained on the database. These algorithms will (2a) distinguish between systolic, diastolic and continuous murmurs, (2b) classify aortic stenosis (AS), mitral regurgitation (MR), tricuspid regurgitation (TR), and innocent murmurs (2c) assess the severity of AS, MR and TR. By integrating these deep learning algorithms into Eko's mobile and cloud software platform, currently used by clinicians at over 1000 institutions worldwide, we anticipate this algorithm will enable more accurate screening for valvular heart disease in adult patients, leading to earlier diagnosis and better patient outcomes. Public Health Relevance Valvular heart disease is becoming an increasingly prevalent manifestation of poor cardiovascular health in both the developed and developing world. A highly-accurate clinical decision support algorithm that is able to detect and classify valvular heart disease will impact public health by reducing unnecessary referrals for echocardiography and promoting early and accurate diagnosis in underserved areas with limited access to specialty care.",Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope,10215611,R44HL144297,"['Address', 'Adopted', 'Adult', 'Algorithms', 'Aortic Valve Stenosis', 'Auscultation', 'Cardiac', 'Caring', 'Cellular Phone', 'Clinic', 'Clinical', 'Clinical Data', 'Collection', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Detection', 'Device Designs', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Echocardiography', 'Eko', 'Electrocardiogram', 'Enrollment', 'Environment', 'Goals', 'Gold', 'Health Personnel', 'Heart Sounds', 'Heart Valve Diseases', 'Heart murmur', 'Institution', 'Label', 'Lead', 'Medical Device', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Network-based', 'Outcome Study', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Prevalence', 'Primary Health Care', 'Public Health', 'Reporting', 'Resources', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Site', 'Small Business Innovation Research Grant', 'Specificity', 'Stethoscopes', 'Stream', 'Supervision', 'System', 'Tablet Computer', 'Testing', 'Training', 'Tricuspid Valve Insufficiency', 'accurate diagnosis', 'algorithm training', 'automated algorithm', 'base', 'cardiovascular health', 'clinical decision support', 'clinical development', 'clinical research site', 'clinically significant', 'cloud software', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'diagnosis standard', 'digital', 'experience', 'innovation', 'learning strategy', 'medical specialties', 'point of care', 'public health relevance', 'screening', 'sound', 'underserved area']",NHLBI,"EKO DEVICES, INC.",R44,2021,920184
"Deep Learning with Neuroimaging Genetic Data for Alzheimer's Disease Summary  Alzheimer's disease (AD) affects over 44 million individuals worldwide, and the number is projected to triple by 2050. However, currently there is no cure for AD. This project aims to develop and apply novel statistical methods, especially deep learning, to advance neuroimaging genetics for AD. It involves novel methodological developments in Aims 1-4, cost-effective applications to the large-scale UK Biobank neuroimaging genetic data for AD (Aim 5), and software development (Aim 6). All four Aims for the methods development tackle emerging impor- tant topics in deep learning with their applications to neuroimaging genetics for AD; although the other three Aims deal with independent topics with their own other broad applications, they in turn serve for Aim 1: 1) Aim 1 applies manually searched deep learning models for automatic feature extraction/phenotyping from neuroimages, by which both the statistical power and biological interpretation of subsequent genome-wide association studies (GWAS) are expected to be enhanced; 2) Aim 2 employs (automatic) neural architecture search (NAS) to more efﬁciently identify better deep learning models, which are then applied to Aim 1 for enhancing feature extraction/phenotyping and thus boosting the power of GWAS; 3) Aim 3 focuses on explainable deep learning, offering biological insights by localizing and highlighting the most important features extracted by deep learning models that can be used for Aim 1; 4) Aim 4 develops a novel inferential theory for deep learning, which is then applied to rigorously test for the statistical signiﬁcance of any selected/highlighted features used in Aim 1. In Aim 5, these new methods will be applied to the UK Biobank neuroimaging and GWAS data to identify novel genetic loci and neuroimaging features for AD. As a byproduct, we will develop and distribute software implementing the proposed methods in Aim 6. Project Narrative  This proposed research is to develop new statistical estimation and inference methods for deep learning with their applications to neuroimaging genetics for Alzheimer's disease (AD), which is expected to contribute to the elucidation of genetic components and etiology of AD with potential applications to other common diseases, thus facilitating their prevention, early diagnosis and therapeutic development.",Deep Learning with Neuroimaging Genetic Data for Alzheimer's Disease,10267714,R01AG069895,"['Advocate', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Architecture', 'Atlases', 'Biological', 'Brain', 'Classification', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Disease', 'Documentation', 'Early Diagnosis', 'Entropy', 'Environment', 'Etiology', 'Genetic', 'Genotype', 'Hand', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Nature', 'Noise', 'Outcome', 'Performance', 'Phenotype', 'Prevention', 'Process', 'Proxy', 'Psychological reinforcement', 'Public Domains', 'Publishing', 'Pythons', 'Research', 'Speed', 'Statistical Computing', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'base', 'biobank', 'combinatorial', 'convolutional neural network', 'cost', 'cost effective', 'deep learning', 'endophenotype', 'feature extraction', 'feature selection', 'genetic association', 'genetic variant', 'genome wide association study', 'genomic locus', 'high dimensionality', 'improved', 'insight', 'interest', 'method development', 'model building', 'neural network architecture', 'neuroimaging', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'relating to nervous system', 'software development', 'success', 'theories', 'therapeutic development', 'tool', 'trait', 'web site']",NIA,UNIVERSITY OF MINNESOTA,R01,2021,667791
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,10137892,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated algorithm', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'risk prediction', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,482108
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,10168666,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'aggressive therapy', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'disability', 'disability risk', 'improved', 'improved outcome', 'intervention effect', 'large datasets', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,555363
"Nonlinear performance analysis and prediction for robust low dose lung CT 1 PROJECT SUMMARY / ABSTRACT  2 Nonlinear algorithms such as model-based reconstruction (MBR) and deep learning (DL) reconstruction have  3 sparked tremendous research interest in recent years. Compared to traditional linear approaches, the nonline-  4 arity of these algorithm transcends traditional signal-to-noise requirement and offer flexibility to draw information  5 from a variety of sources (e.g., statistical model, prior image, dictionary, training data). MBR has enabled numer-  6 ous advancements including low-dose CT and advanced scanning protocols. Deep learning algorithms are rap-  7 idly emerging and have demonstrated superior dose vs. image quality tradeoffs in research settings. However,  8 widespread clinical adoption of nonlinear algorithms has been impeded by the lack of a lack of systematic, quan-  9 titative methods for performance analysis. Nonlinear methods come with numerous dependencies on the imag- 10 ing techniques, the imaging target, and the prior information, and the data itself. The relationship between these 11 dependencies and image quality is often opaque. Furthermore, improper selection of algorithmic parameters can 12 lead to erroneous features (e.g., smaller lesions, texture) in the reconstruction. Therefore, methods to quantify 13 and predict performance permit efficient and quantifiable performance evaluation to provide the robust control 14 and understanding of imaging output necessary for reliable clinical application and regulatory oversight. 15 We propose to establish a robust, predictive framework for performance assessment and optimization that can 16 be generalized to any reconstruction method. We quantify performance in turns of the perturbation response and 17 covariance as a function of imaging techniques, system configurations, patient anatomy, and, importantly, the 18 perturbation itself. The perturbation response quantifies the appearance (e.g., biases, blurs, distortions), and, 19 together with the covariance, allows the computation of more complex metrics such as task-based performance 20 and radiomic measures including size, shape, and texture information. We illustrate utility of the approach in lung 21 imaging with the following specific aims: Aim 1: Develop a lesion library and generate perturbations encom- 22 passing clinically relevant features. We will extract lesions from public databases and develop methods lesion 23 emulation in for realistic CT simulation and physical data via 3D printing technology. Aim 2: Develop a gener- 24 alized prediction framework for perturbation response and covariance. Using analytical and neural network 25 modeling, we will establish a framework that predicts perturbation response and covariance across imaging 26 scenarios for classes of algorithms with increasing data-dependence including MBR with a Huber penalty, MBR 27 with dictionary regularization, and a deep learning reconstructor. Aim 3: Develop assessment and optimiza- 28 tion strategies to drive robust, low dose lung screening CT methods. We will optimize and adapt nonlinear 29 algorithms and protocols for lung cancer screening to achieve faithful representations of clinical features. This 30 work has the potential to drive much-needed quantitative assessment standards that directly relate image quality 31 to diagnostic performance and optimal strategies for robust, reliable clinical deployment of nonlinear algorithms. 32 PROJECT NARRATIVE Major research efforts have been devoted to the development of nonlinear reconstruction algorithms – from model-based reconstruction to deep learning, these algorithms have demonstrated many advantages such as improved image quality, reduced radiation dose, and additional diagnostic information that are not achievable with traditional linear reconstructions. However, only a disproportionately small number has reach the clinic due to the lack of a predictive image quality analysis framework to quantify diagnostic performance, control algorithm behavior, and ensure consistent performance for robust clinical deployment. The propose effort use a combination of analytic and machine learning approaches to drive much-needed quantitative assessment standards that directly relate image quality to diagnostic performance and establish optimal strategies for robust, reliable clinical deployment of nonlinear algorithms.",Nonlinear performance analysis and prediction for robust low dose lung CT,10121056,R01CA249538,"['3D Print', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Appearance', 'Beauty', 'Behavior', 'Biological Models', 'Clinic', 'Clinical', 'Complex', 'Data', 'Databases', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Dictionary', 'Digital Libraries', 'Dimensions', 'Dose', 'Ensure', 'Evaluation', 'Genes', 'Image', 'Image Analysis', 'Imaging Techniques', 'Lead', 'Lesion', 'Libraries', 'Lung', 'Lung CAT Scan', 'Lung nodule', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Nodule', 'Noise', 'Non-linear Models', 'Outcome', 'Output', 'Patients', 'Performance', 'Play', 'Predictive Analytics', 'Property', 'Protocols documentation', 'Radiation Dose Unit', 'Research', 'Role', 'Sampling', 'Scanning', 'Scheme', 'Shapes', 'Signal Transduction', 'Source', 'Statistical Models', 'System', 'Techniques', 'Technology', 'Texture', 'Training', 'Transcend', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinical translation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'exhaustion', 'flexibility', 'imaging system', 'improved', 'insight', 'interest', 'low dose computed tomography', 'lung cancer screening', 'machine learning method', 'neural network', 'novel', 'predicting response', 'quantitative imaging', 'radiomics', 'reconstruction', 'response', 'screening', 'shape analysis', 'simulation', 'success', 'targeted imaging']",NCI,JOHNS HOPKINS UNIVERSITY,R01,2021,512567
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,10054168,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Image Analysis', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Visualization', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'detection sensitivity', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,120631
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10256071,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2021,339505
"Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues Summary Fast, accurate, and scalable testing has been recognized unanimously as crucial for mitigating the impact of COVID-19 and future pandemics. We propose a technology that allows rapid (~2 minutes) testing for SARS CoV-2. Our technology combines novel label-free imaging and dedicated deep-learning algorithms to detect and classify viral populations in exhaled air. If successful, this project will result in a device based on quantitative phase imaging and integrated AI tools, which will detect the unlabeled virus acquired by the patient’s breath condensed on a microscope slide. Toward this goal, we will advance Spatial Light Interference Microscopy (SLIM), an ultrasensitive label-free imaging technique, proven to measure structures down to the sub-nanometer scale. SLIM was developed in the PI’s Lab at UIUC, its original publication received 490 citations to date, and has been commercialized by Phi Optics (Research Park, UIUC), with sales across the world in both academia and industry. Applying the computed fluorescence maps back to the QPI data, we propose to measure nanoscale features of viral particles, with high specificity, minimal preparation time, and independent of clinical infrastructure. As a result, the new technology will eventually be ideal for point-of-care settings, surveillance screening and as a home monitoring device. We anticipate that our approach will be scalable to other viruses, with new imaging and training data. Narrative We propose a breath test using label-free imaging and AI: an individual exhales on a microscope slide, which is fed into a SLIM microscope equipped with a computer that runs deep-learning pre-trained algorithms for SARS CoV-2 identification. The result is displayed in real time, with the entire procedure requiring < 2min.",Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues,10249738,R01CA238191,"['2019-nCoV', 'Academia', 'Air', 'Artificial Intelligence', 'Back', 'Bedside Testings', 'Biology', 'Breath Tests', 'COVID-19', 'COVID-19 testing', 'Cancer Prognosis', 'Chemicals', 'Classification', 'Clinical', 'Clinical Microbiology', 'Computer software', 'Computers', 'Data', 'Devices', 'Exhalation', 'Fluorescence', 'Fluorescence Microscopy', 'Future', 'Glass', 'Goals', 'Histopathology', 'Home environment', 'Image', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Industry', 'Influenza', 'Infrastructure', 'Interference Microscopy', 'Label', 'Light', 'Maps', 'Measures', 'Microscope', 'Modification', 'Morphologic artifacts', 'Nature', 'Optics', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Phototoxicity', 'Population', 'Preparation', 'Procedures', 'Publications', 'Research', 'Running', 'Sales', 'Slide', 'Specificity', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Stains', 'Training', 'Viral', 'Virus', 'Virus Diseases', 'algorithm training', 'base', 'clinical infrastructure', 'coronavirus disease', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'imaging system', 'instrument', 'monitoring device', 'nanoscale', 'new technology', 'novel', 'operation', 'pandemic disease', 'particle', 'point of care', 'prototype', 'screening', 'tool']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,576268
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,10162578,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'learning classifier', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2021,753275
"Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse Project Summary/ Abstract Expiratory central airway collapse (ECAC), defined by >50% collapse of large airways during expiration, resulting from either cartilaginous weakening or redundancy of the posterior membranous wall of the trachea, is an increasingly recognized disorder associated with cigarette smoking and chronic obstructive pulmonary disease (COPD). Airflow obstruction in smokers primarily arises from increased resistance to airflow in the small distal conducting airways <2 mm in diameter. It is plausible that in a subset of smokers with and without COPD, central airway collapse results in additional resistance to airflow, resulting in substantial respiratory morbidity. Ninety-two million adults in the Unites States are active or past smokers, and ECAC is present in approximately 5% of current and former smokers. The presence of ECAC is associated with greater dyspnea, worse respiratory-quality of life and greater frequency of exacerbations after adjustment for underlying lung disease. Whether these patients will benefit from interventional therapies such as stenting or tracheopexy depends on whether the airflow resistance caused by ECAC contributes to symptoms, and this in turn depends on the relative contribution of central and small airways to overall airflow resistance. If the overall airflow resistance is primarily due to distal small airways obstruction in a given patient with ECAC, treating central airway collapse is unlikely to benefit such a patient. Our central hypothesis is that ECAC results in additional airflow obstruction beyond that incurred in the small airways, and that in a subset of patients the central airways are the major site of airflow obstruction and hence are amenable to therapy. The complex interplay of proximal and distal airway resistances and transpulmonary pressures does not lend itself to direct measurements in human subjects across a range of physiological pressure and flow changes. We propose a combination of CT-derived imaging and patient-personalized benchtop model and deep learning to answer these questions with the following specific aims. Aim 1 of this application will be to derive personalized patient- specific information on airway geometry and resistance using airway segmentation from computed tomography (CT) scans. We will calculate airway resistances in central and small airways using standard formulae. The goal of Aim 2 is to create bench-top simulations to understand the complex interplay between the resistance of small and large airways. In Aim 3, we will use deep learning to derive probability scores for clinically substantial ECAC from segmented airway images on computed tomography. The results of our study will enable patient-specific personalized therapies for ECAC. The mechanistic insights gained from this study will help identify patients with clinically significant ECAC and hence most likely to benefit from therapeutic interventions. PROJECT NARRATIVE Expiratory central airway collapse (ECAC), greater than 50% collapse of the large airways during expiration, is present in 5% of chronic smokers, and is associated with substantial respiratory morbidity disproportionate to underlying lung disease. Resistance to airflow in smokers is thought to primarily occur in the small conducting airways. By using benchtop models and deep learning to determine the effect of central airway collapse on overall airway resistance and its contribution to airflow obstruction relative to small airway resistance, the proposed project will identify patients with ECAC who will benefit from intervention, and cause a paradigm shift in the therapy of these patients.",Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse,10149998,R21EB027891,"['3-Dimensional', '3D Print', 'Adult', 'Affect', 'Age', 'Air Movements', 'Airway Resistance', 'Area', 'Body mass index', 'Breathing', 'Caliber', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Disease', 'Distal', 'Dyspnea', 'Exhalation', 'Forced expiratory volume function', 'Frequencies', 'Generations', 'Geometry', 'Goals', 'Image', 'Individual', 'Intervention', 'Length', 'Liquid substance', 'Lung diseases', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Neural Network Simulation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Probability', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quality of life', 'Race', 'Resistance', 'Scanning', 'Site', 'Smoker', 'Smoking', 'Smoking History', 'Spirometry', 'Stents', 'Symptoms', 'Testing', 'Therapeutic Intervention', 'Trachea', 'Training', 'Translations', 'Tube', 'United States', 'Visualization', 'X-Ray Computed Tomography', 'airway obstruction', 'base', 'cartilaginous', 'cigarette smoking', 'clinical application', 'clinical predictors', 'clinically significant', 'convolutional neural network', 'deep learning', 'expiration', 'former smoker', 'human subject', 'individual patient', 'insight', 'patient subsets', 'personalized medicine', 'pressure', 'respiratory', 'respiratory morbidity', 'response', 'sex', 'simulation', 'three-dimensional modeling']",NIBIB,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R21,2021,185497
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10188526,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2021,388359
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,10164762,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Duodenum', 'Environmental Risk Factor', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Multiomic Data', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Small Intestines', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Villous Atrophy', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'dietary', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'epithelium regeneration', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'systemic inflammatory response', 'tissue injury', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2021,192552
