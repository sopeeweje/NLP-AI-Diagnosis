text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Tools for modeling state-dependent sensory encoding by neural populations across spatial and temporal scales Project Summary Throughout life, humans and other animals learn statistical regularities in the natural acoustic environment. They adapt their hearing to emphasize the features of sound that are important for making behavioral decisions. Normal-hearing humans are able to perceive important sounds in crowded noisy scenes and to understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. A better understanding of the function of the healthy and impaired auditory system will support new treatments for these deficits. This project will develop computational tools to study central auditory processing. A software library will support fitting and evaluating a large number of encoding models to describe the functional relationship between a time-varying natural auditory stimulus and the corresponding neural response. Many such models have been proposed, but relatively few direct comparisons have been made between them. This project will enable their comparison, allowing identification of the key features that contribute positively to their performance. The system will have a modular design so that useful elements from different models can be combined into comprehensive models with even greater explanatory power. The software will be open source and will support data from multiple recording modalities, including small-scale single unit electrophysiological and calcium imaging data, as well as large-scale local field and magnetoencephalography data. In addition to building on existing hypotheses about neural coding, the system will support machine learning methods for fitting artificial neural network models using the same datasets. These large, data-driven models have proven valuable for wide ranging signal processing problems, but their value and relation to existing models for neural sensory processing remain to be explored. Sensory processing involves coherent activity of large neural populations. To study coding at the population level, the system will support models that characterize the simultaneous activity of multiple neural signals and identifies latent subspaces of population activity related to sound encoding. Sensory coding is also influenced by behavioral context, reflecting changes in behavioral demands and the more general environment. The system will incorporate behavioral state variables into models, where encoding properties can be modulated by changes in behavioral context. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particularly in challenging noisy environments. We seek to understand how the neural populations in the healthy brain represent complex natural sounds. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Tools for modeling state-dependent sensory encoding by neural populations across spatial and temporal scales,9774688,R01EB028155,"['Acoustics', 'Algorithms', 'Animals', 'Architecture', 'Area', 'Arousal', 'Attention', 'Auditory', 'Auditory Perceptual Disorders', 'Auditory system', 'Behavioral', 'Biological Models', 'Brain', 'Calcium', 'Calcium Signaling', 'Code', 'Communities', 'Complex', 'Computer software', 'Crowding', 'Data', 'Data Set', 'Development', 'Devices', 'Dimensions', 'Electrophysiology (science)', 'Elements', 'Environment', 'Foundations', 'Goals', 'Hearing', 'Hearing problem', 'Human', 'Image', 'Imagery', 'Impairment', 'Individual', 'Judgment', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Magnetoencephalography', 'Measurement', 'Metadata', 'Methods', 'Modality', 'Modeling', 'Motion', 'Neural Network Simulation', 'Neurons', 'Non-linear Models', 'Patients', 'Performance', 'Peripheral', 'Population', 'Problem Solving', 'Property', 'Publications', 'Publishing', 'Pythons', 'Reproducibility', 'Sensory', 'Sensory Process', 'Signal Transduction', 'Speech', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Visual system structure', 'artificial neural network', 'auditory processing', 'auditory stimulus', 'base', 'behavior influence', 'computerized tools', 'data format', 'deep neural network', 'design', 'experimental study', 'graphical user interface', 'hearing impairment', 'insight', 'learning strategy', 'nervous system disorder', 'neural model', 'neurophysiology', 'neurotransmission', 'normal hearing', 'novel', 'online repository', 'open source', 'receptive field', 'reconstruction', 'relating to nervous system', 'response', 'sensory stimulus', 'sensory system', 'signal processing', 'sound', 'tool']",NIBIB,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,794000,0.1900068366799838
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9803507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Simulation', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'learning strategy', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,334599,0.13795659737398352
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9735214,R01DC015138,"['Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Behavior', 'Biological', 'Biomedical Engineering', 'Brain', 'Catalogs', 'Categories', 'Cells', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing Aids', 'Human', 'Individual', 'Industrialization', 'Inferior Colliculus', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Psychology', 'Research', 'Research Personnel', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'awake', 'base', 'computational neuroscience', 'data warehouse', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'normal hearing', 'novel', 'novel strategies', 'online repository', 'online resource', 'programs', 'relating to nervous system', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'summer internship', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2019,268961,0.206253688248554
"Shifting auditory spatial attention: cognitive and neural mechanisms ﻿    DESCRIPTION (provided by applicant): Hearing can serve as an early warning system because it can panoramically monitor the environment for events happening at a distance or out of sight. These ecological considerations make the auditory system particularly useful for studying mechanisms for shifting spatial attention. The focus of this project is on the interplay between top-down and bottom-up spatial attention biases that govern shifting auditory attention to distractors during performance of a simple spatial attention task. The overall goal of this proposal is to use an interdisciplinary approach to better understand at the cognitive and neural levels of analysis how auditory attention is distributed over space. We will test the hypothesis that the spatial distribution of auditory attentional emerges from interactions among two basic factors. The first factor is a voluntary (top-down) attention bias that weakens with distance from the current focus of attention. Conversely, the second factor is an automatic (bottom-up) bias that is tuned to shift attention to unexpected events away from the current focus of attention. The first aim tests a computational model of top-down and bottom-up attention bias in shifting auditory spatial attention. Different aspects of the model will be quantitatively tested against findings from behavioral experiments, and observations will be used to further develop the model. The computational model will incorporate artificial intelligence methods to represent human cognitive processes. The second aim uses transcranial magnetic stimulation to test the role of key right hemisphere cortical areas in shifting of auditory spatial attention. We focus on neural mechanisms of bottom-up attentional bias. The third aim tests whether auditory attention gradients become less focused over time. This will determine how gradients relate to cognitive resources and neural blood flow measures that are known to decline with extended vigilance. This project will help advance knowledge in the field of auditory attention and cognitive hearing, and also addresses general issues in attention research such as top-down and bottom-up processes, vigilance, and their relations to neurobiological attention networks. Outcomes will have practical significance because shifting auditory attention is vital for avoiding accidents at ll ages, maintaining independent living at older ages, and is applicable to neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). PUBLIC HEALTH RELEVANCE: The project outcomes could have clinical in neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). The project will examine mechanisms of normal cognitive aging using computational modeling, which can inform the early detection, differential diagnosis, and treatment monitoring of age-related neurodegenerative disorders such as Alzheimer's disease. Knowledge from the transcranial magnetic and electrical DC stimulation experiments may have translational applications for rehabilitation following brain injuries.",Shifting auditory spatial attention: cognitive and neural mechanisms,9718188,R01DC014736,"['Accidents', 'Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Attention', 'Attention Deficit Disorder', 'Auditory', 'Auditory system', 'Behavioral', 'Blood flow', 'Brain Injuries', 'Clinical', 'Cognitive', 'Cognitive aging', 'Computer Simulation', 'Dementia', 'Differential Diagnosis', 'Diffuse', 'Dimensions', 'Early Diagnosis', 'Electroencephalography', 'Environment', 'Event', 'Goals', 'Hearing', 'Human', 'Impairment', 'Independent Living', 'Individual Differences', 'Inferior', 'Knowledge', 'Learning', 'Left', 'Location', 'Loudness', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Music', 'Neurobiology', 'Obstruction', 'Outcome', 'Parietal', 'Performance', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Probability', 'Process', 'Property', 'Reaction Time', 'Rehabilitation therapy', 'Reproduction', 'Research', 'Resources', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Site', 'Spatial Distribution', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Transcranial magnetic stimulation', 'Vision', 'Work', 'age related neurodegeneration', 'alpha-SNAP', 'attentional bias', 'attentional control', 'base', 'behavior measurement', 'cognitive process', 'cost shifting', 'experimental study', 'fighting', 'image guided', 'indexing', 'information processing', 'interdisciplinary approach', 'nervous system disorder', 'neural correlate', 'neural stimulation', 'neuroimaging', 'neuromechanism', 'normal aging', 'prefrontal lobe', 'public health relevance', 'relating to nervous system', 'response', 'sound', 'theories', 'vector', 'vigilance']",NIDCD,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2019,263449,0.16010755783104158
"Decoding parametric attributes of auditory working memories from human brain activity Decoding parametric attributes of auditory working memories from human brain activity Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Auditory WM dysfunctions are evidenced in individuals with speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as central auditory processing disorders (CAPD). Better understanding of auditory WM would help develop more precise biomarkers and targeted interventions for these deficits. Evidence for neuronal activation related to auditory WM patterns have been found in laboratory animals as well as in non- invasive human neuroimaging studies, both in auditory cortices (AC) and elsewhere in the brain. Recent human fMRI data also provide some evidence on item-specific activation patterns in ACs and frontal cortices. However, exactly where in the brain auditory WM content is stored and, more importantly, how the memorized information is represented is still unclear.  This research program pursues a better understanding of human auditory WM by attempting to infer its contents from the brain: Using state-of-the-art non-invasive neuroimaging and advanced signal-analysis methods we will search for cortical activation patterns that would predict item-specific WM information. We will examine brain function non-invasively with magneto- and electroencephalography (MEG/EEG), transcranial magnetic stimulation (TMS), and functional MRI (fMRI), and validate the findings using intracranial EEG (iEEG) measurements in presurgical patients. Recent studies suggest that, instead of persistent activation patterns, WM is supported by short-term synaptic facilitation, i.e., ""activity-silent"" population-level mechanisms. We hypothesize that these activity-silent representations could be decoded by analyzing the aftereffects of generic auditory ""impulse stimuli"" or TMS, which are utilized to ""ping"" the underlying cortical network during memory maintenance. We also hypothesize that although auditory WM likely involves co-operation of multiple brain regions, which are involved in articulatory-motor functions, perceptual categorization, or semantic processing, the retention of auditory-sensory attributes such as spectrotemporal modulation patterns critically depends on ACs. To examine WM of such auditory attributes, we will use tasks with dynamic ripple sound stimuli, which are spectrotemporally similar to human vocalizations but resist non-auditory processing strategies.  The major significance of this project is that it will increase the understanding of auditory WM, a crucial cognitive function whose neuronal bases have remained elusive. The results may also help develop more precise tools for characterizing auditory WM dysfunctions in hearing and communication deficits as well as in disorders such as dyslexia, attention deficit/hyperactivity disorder (ADHD), and schizophrenia. Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Our research program pursues a better theoretical understanding of this crucial cognitive function using advanced multimodal neuroimaging methods, validated using intracranial recordings in pre-surgical patients. Our results may also help develop more precise tools for characterizing auditory WM dysfunctions in speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as attention deficit/hyperactivity disorder (ADHD) and schizophrenia.",Decoding parametric attributes of auditory working memories from human brain activity,9654724,R01DC016915,"['Attention deficit hyperactivity disorder', 'Auditory', 'Auditory area', 'Biological Markers', 'Brain', 'Brain region', 'Central Auditory Processing Disorder', 'Cognition', 'Communication', 'Data', 'Disease', 'Dyslexia', 'Electroencephalography', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Hearing', 'Human', 'Impairment', 'Individual', 'Intervention', 'Laboratory Animals', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measurement', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Motor', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perceptual Disorders', 'Population', 'Principal Component Analysis', 'Problem Solving', 'Reading', 'Research', 'Schizophrenia', 'Sensory', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Speech Perception', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Transcranial magnetic stimulation', 'base', 'cognitive function', 'cortex mapping', 'electric field', 'experimental study', 'frontal lobe', 'multimodality', 'neuroimaging', 'operation', 'programs', 'semantic processing', 'sound', 'tool', 'vocalization']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,601029,0.22802035297058035
"Top-down control of auditory processing in the cortico-collicular network Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network,9634046,R01DC014950,"['Acoustics', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory Perceptual Disorders', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Non-linear Models', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory processing', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'experimental study', 'hearing impairment', 'insight', 'nervous system disorder', 'neurophysiology', 'normal hearing', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,327250,0.3013511700476788
"Auditory precursors of language delay in toddlers with autism spectrum disorders Abstract Language delay and impairments are common in autism spectrum disorders (ASDs), as are sensory (including auditory) anomalies. Since acquisition of spoken language relies on the integrity of the auditory system, language delay and impairments may be related to sound processing abnormalities that are frequently observed in children with ASDs (despite normal peripheral hearing). However, it is not understood if and how early auditory brain anomalies may developmentally contribute to impaired language development.  This project will examine the maturation of auditory and language systems in the brain across early childhood, during the critical period for language acquisition. We will employ a longitudinal design and multimodal neuroimaging, including high-resolution anatomical, diffusion, and functional magnetic resonance imaging (MRI), with added frequent and extensive behavioral and neuropsychological assessments. Our central hypothesis is that early disruptions to cortical sound processing precede and predict language impairments in ASDs and may thus be considered causal contributors – a hypothesis that has been frequently considered in the literature, but never tested at the neural level.  Our aims are to thoroughly characterize the structural integrity and functional differentiation of the cortical auditory and language systems (Aim 1) and their maturational trajectories (Aim 2) in toddlers with ASDs and age-matched typically developing peers. This will allow us to establish whether neural abnormalities in cortical processing of complex sounds in toddlers are predictive of language development and social behavior at the pre-school age (Aim 3). The rationale and translational significance of this project are that identification of alterations in brain development linked to language delay and impairment in the first years of life will allow for more targeted interventions in the auditory domain at a time when they are most effective. Project narrative The project aims to find causes of language impairment in children with autism spectrum disorders by studying the brain organization of the auditory system in toddlers at the very earliest age of provisional diagnosis. The overarching hypothesis is that atypical auditory processing contributes to language delay and impairment. Pinpointing auditory causes of language problems in children with ASDs may inform early interventions.",Auditory precursors of language delay in toddlers with autism spectrum disorders,9716468,R01DC017736,"['Age', 'Anatomy', 'Animal Model', 'Anisotropy', 'Auditory', 'Auditory area', 'Auditory system', 'Basic Science', 'Behavioral', 'Brain', 'Brain region', 'Child', 'Complex', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Early Intervention', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Imaging Techniques', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Length', 'Life', 'Link', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Morphology', 'Neurites', 'Neuropsychology', 'Nursery Schools', 'Organizational Change', 'Pattern', 'Peripheral', 'Radial', 'Research', 'Research Priority', 'Resolution', 'Risk', 'Sensory', 'Sleep', 'Social Behavior', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'TEP1 gene', 'Techniques', 'Testing', 'Thalamic structure', 'Thick', 'Time', 'Toddler', 'auditory processing', 'autism spectrum disorder', 'autistic children', 'base', 'critical period', 'density', 'early childhood', 'gray matter', 'indexing', 'language impairment', 'learning strategy', 'longitudinal design', 'molecular modeling', 'multimodality', 'myelination', 'neuroimaging', 'novel', 'peer', 'phonology', 'recruit', 'relating to nervous system', 'response', 'sound', 'theories', 'translational impact']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2019,619763,0.1876368707386896
"Computational Cognitive Neuroscience of Human Auditory Cortex PROJECT SUMMARY Humans with normal hearing excel at deriving information about the world from sound. Our auditory abilities represent stunning computational feats that only recently have been replicated to any extent in machine systems. And yet our auditory abilities are highly vulnerable, being greatly compromised in listeners with hearing impairment, cochlear implants, and auditory neurodevelopmental disorders, particularly in the presence of noise. Difficulties in recognition often lead to frustration and social isolation, and are not adequately addressed by current hearing aids, implants, and remediation strategies. The long-term goal of the proposed research is to reveal the basis of auditory recognition and to provide insights that will facilitate improved prosthetic devices and therapeutic interventions. The development of more effective devices and therapies is currently limited by an incomplete understanding of the factors that underlie real-world recognition by normal-hearing listeners. In particular, although responses to sound in subcortical auditory pathways are relatively well studied, little is known about the transformations that occur within the auditory cortex to create representations of meaningful sound structure. We propose to enrich the understanding of auditory recognition with three sets of experiments that examine the cortical representation of real-world sounds in human listeners, combining functional magnetic resonance imaging (fMRI) with computational modeling of the underlying representations. Aim 1 develops artificial neural network models of speech and music processing and compares their representations to those in the auditory cortex, synthesizing and then measuring brain responses to sounds that generate the same response in a model, and probing the time scale of the auditory analysis of speech and music. Aim 2 develops and tests models of pitch perception in noise, exploring the hypothesis that pitch perception is constrained both by the statistics of natural sounds and the frequency selectivity of the cochlea. Aim 3 develops and tests models that jointly localize and recognize sounds, and probes the brain representations of sound identity and location using fMRI. The results will reveal the mechanisms underlying robust sound recognition by the healthy auditory system and will set the stage for investigations of the cortical consequences of hearing impairment and auditory developmental disorders, hopefully suggesting new strategies for remediation. PROJECT NARRATIVE: People with normal hearing are typically able to recognize, understand and localize sounds of interest, but this ability is often compromised in listeners with hearing disorders. The proposed research will enrich the understanding of the neural mechanisms underlying auditory recognition and localization in normal listeners. The results will likely provide insight into the brain processes whose alteration in hearing disorders underlies listening difficulties, potentially leading to improved remediation strategies.",Computational Cognitive Neuroscience of Human Auditory Cortex,9797408,R01DC017970,"['Address', 'Adopted', 'Auditory', 'Auditory Perception', 'Auditory area', 'Auditory system', 'Behavioral', 'Biological Assay', 'Brain', 'Brain region', 'Characteristics', 'Child', 'Cochlea', 'Cochlear Implants', 'Computer Simulation', 'Data', 'Development', 'Devices', 'Drops', 'Ear', 'Floor', 'Frequencies', 'Frustration', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing Aids', 'Hearing problem', 'Human', 'Implant', 'Investigation', 'Lead', 'Location', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Noise', 'Pathway interactions', 'Peripheral', 'Persons', 'Pitch Perception', 'Population', 'Process', 'Property', 'Prosthesis', 'Psychophysics', 'Research', 'Rest', 'Social isolation', 'Sound Localization', 'Source', 'Speech', 'Stimulus', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Visual Pathways', 'artificial neural network', 'auditory pathway', 'cognitive neuroscience', 'computational basis', 'deep learning', 'deep neural network', 'developmental disease', 'experimental study', 'hearing impairment', 'improved', 'insight', 'interest', 'network architecture', 'neural network', 'neuromechanism', 'neurophysiology', 'normal hearing', 'novel', 'relating to nervous system', 'remediation', 'response', 'sound', 'sound frequency', 'speech processing', 'statistics']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2019,337875,0.28451728740823146
"The Nanoscale Connectome of the Cochlear Nucleus The cochlear nucleus is the gateway for central nervous system processing of auditory information in mammals. It has been proposed that parallel processing channels are set up in the CN, and these form the basis for further computation at higher stations of the auditory system. Despite decades of study, enumeration of CN cell types is incomplete and CN circuitry is described only superficially. In neuroscience generally, classification and naming of neurons has relied primarily upon qualitative approaches based upon human observational capabilities. We have implemented and in some cases developed novel high-throughput and unbiased techniques for labeling, segmenting and classifying neurons in 3D, generated from large-scale electron microscopy image volumes. We propose to deliver a nanoscale map, or connectome, of the mouse CN with enumerated and localized cell types and their synaptic connections. This effort is unbiased because all neurons will be sampled. To achieve this goal, we bring together four parallel modes of tissue analysis for neuron classification: morphology, connectivity, molecular identity and function. We propose that connectivity analysis will define long-proposed parallel processing circuits that will be tested functionally using realistic biophysical models of identified cell types. Notably, the cochlear nucleus contains both amorphous and layered organizations of cells, which serve as templates for all other brain regions. By investigating the fundamental structure of this sensory center, we will establish principles of neural computation and methods for structural and functional phenotyping that will apply to other brain regions regardless of their particular neural architecture. Relevance to Public Health The goal of this project is to deliver to the auditory research community the connectome of the mouse cochlear nucleus. In the process we will refine and develop comprehensive and high throughput methods to catalogue cell types and their connections in any brain region, and will provide molecular phenotypes for cochlear nucleus cell types that may be useful in their targeted manipulation for research and therapeutic purposes. This work forms a basis to study central alterations following noise- induced hearing loss or other cochlear pathology, and gain deeper understanding of all auditory structures from brainstem to cortex.",The Nanoscale Connectome of the Cochlear Nucleus,9660864,R01DC015901,"['3-Dimensional', 'Acoustic Nerve', 'Acoustics', 'Adult', 'Architecture', 'Auditory', 'Auditory system', 'Automobile Driving', 'Axon', 'Biophysics', 'Birds', 'Brain Stem', 'Brain region', 'CNS processing', 'Catalogs', 'Cell model', 'Cells', 'Cellular Structures', 'Censuses', 'Classification', 'Cochlea', 'Cochlear nucleus', 'Communities', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Development', 'Electron Microscopy', 'Experimental Designs', 'Frequencies', 'Future', 'Gene Expression', 'Genetic', 'Goals', 'Graph', 'Hearing', 'Hearing problem', 'Human', 'Image', 'Knowledge', 'Label', 'Learning', 'Link', 'Location', 'Mammals', 'Maps', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Names', 'Nerve', 'Nerve Fibers', 'Neurons', 'Neurosciences', 'Noise-Induced Hearing Loss', 'Octopus', 'Pathology', 'Pattern', 'Peripheral', 'Phenotype', 'Process', 'Public Health', 'Research', 'Resolution', 'Sampling', 'Scanning Electron Microscopy', 'Sensory', 'Shapes', 'Skeleton', 'Specific qualifier value', 'Standardization', 'Structure', 'Supervision', 'Synapses', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Tissues', 'Work', 'afferent nerve', 'auditory processing', 'base', 'biophysical model', 'cell type', 'cellular targeting', 'connectome', 'experimental study', 'fluorescence imaging', 'granule cell', 'health goals', 'human error', 'human model', 'microscopic imaging', 'molecular phenotype', 'molecular scale', 'nanoscale', 'nerve supply', 'neural circuit', 'neural model', 'novel', 'parallel processing', 'prevent', 'programs', 'recombinase', 'relating to nervous system', 'sensory system', 'sound', 'tool', 'transcription factor', 'unsupervised learning', 'virtual reality']",NIDCD,UNIVERSITY OF SOUTH FLORIDA,R01,2019,657527,0.06861889480170472
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9526901,R01DC015138,"['Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory area', 'Auditory system', 'Behavior', 'Biological', 'Biomedical Engineering', 'Brain', 'Catalogs', 'Categories', 'Cells', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Devices', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing', 'Human', 'Individual', 'Industrialization', 'Inferior Colliculus', 'Internships', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Prosthesis', 'Psychology', 'Research', 'Research Personnel', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'awake', 'base', 'computational neuroscience', 'data warehouse', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'novel', 'novel strategies', 'online repository', 'online resource', 'programs', 'relating to nervous system', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2018,281216,0.206253688248554
"Shifting auditory spatial attention: cognitive and neural mechanisms ﻿    DESCRIPTION (provided by applicant): Hearing can serve as an early warning system because it can panoramically monitor the environment for events happening at a distance or out of sight. These ecological considerations make the auditory system particularly useful for studying mechanisms for shifting spatial attention. The focus of this project is on the interplay between top-down and bottom-up spatial attention biases that govern shifting auditory attention to distractors during performance of a simple spatial attention task. The overall goal of this proposal is to use an interdisciplinary approach to better understand at the cognitive and neural levels of analysis how auditory attention is distributed over space. We will test the hypothesis that the spatial distribution of auditory attentional emerges from interactions among two basic factors. The first factor is a voluntary (top-down) attention bias that weakens with distance from the current focus of attention. Conversely, the second factor is an automatic (bottom-up) bias that is tuned to shift attention to unexpected events away from the current focus of attention. The first aim tests a computational model of top-down and bottom-up attention bias in shifting auditory spatial attention. Different aspects of the model will be quantitatively tested against findings from behavioral experiments, and observations will be used to further develop the model. The computational model will incorporate artificial intelligence methods to represent human cognitive processes. The second aim uses transcranial magnetic stimulation to test the role of key right hemisphere cortical areas in shifting of auditory spatial attention. We focus on neural mechanisms of bottom-up attentional bias. The third aim tests whether auditory attention gradients become less focused over time. This will determine how gradients relate to cognitive resources and neural blood flow measures that are known to decline with extended vigilance. This project will help advance knowledge in the field of auditory attention and cognitive hearing, and also addresses general issues in attention research such as top-down and bottom-up processes, vigilance, and their relations to neurobiological attention networks. Outcomes will have practical significance because shifting auditory attention is vital for avoiding accidents at ll ages, maintaining independent living at older ages, and is applicable to neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). PUBLIC HEALTH RELEVANCE: The project outcomes could have clinical in neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). The project will examine mechanisms of normal cognitive aging using computational modeling, which can inform the early detection, differential diagnosis, and treatment monitoring of age-related neurodegenerative disorders such as Alzheimer's disease. Knowledge from the transcranial magnetic and electrical DC stimulation experiments may have translational applications for rehabilitation following brain injuries.",Shifting auditory spatial attention: cognitive and neural mechanisms,9513308,R01DC014736,"['Accidents', 'Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Attention', 'Attention Deficit Disorder', 'Auditory', 'Auditory system', 'Behavioral', 'Blood flow', 'Brain Injuries', 'Clinical', 'Cognitive', 'Cognitive aging', 'Computer Simulation', 'Dementia', 'Differential Diagnosis', 'Diffuse', 'Dimensions', 'Early Diagnosis', 'Electroencephalography', 'Environment', 'Event', 'Goals', 'Hearing', 'Human', 'Impairment', 'Independent Living', 'Individual Differences', 'Inferior', 'Knowledge', 'Learning', 'Left', 'Location', 'Loudness', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Music', 'Neurobiology', 'Obstruction', 'Outcome', 'Parietal', 'Performance', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Probability', 'Process', 'Property', 'Reaction Time', 'Rehabilitation therapy', 'Reproduction', 'Research', 'Resources', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Site', 'Spatial Distribution', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Transcranial magnetic stimulation', 'Vision', 'Work', 'age related neurodegeneration', 'alpha-SNAP', 'attentional bias', 'attentional control', 'base', 'behavior measurement', 'cognitive process', 'cost shifting', 'experimental study', 'fighting', 'image guided', 'indexing', 'information processing', 'interdisciplinary approach', 'nervous system disorder', 'neural correlate', 'neural stimulation', 'neuroimaging', 'neuromechanism', 'normal aging', 'prefrontal lobe', 'public health relevance', 'relating to nervous system', 'response', 'sound', 'theories', 'vector', 'vigilance']",NIDCD,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2018,262412,0.16010755783104158
"Decoding parametric attributes of auditory working memories from human brain activity Decoding parametric attributes of auditory working memories from human brain activity Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Auditory WM dysfunctions are evidenced in individuals with speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as central auditory processing disorders (CAPD). Better understanding of auditory WM would help develop more precise biomarkers and targeted interventions for these deficits. Evidence for neuronal activation related to auditory WM patterns have been found in laboratory animals as well as in non- invasive human neuroimaging studies, both in auditory cortices (AC) and elsewhere in the brain. Recent human fMRI data also provide some evidence on item-specific activation patterns in ACs and frontal cortices. However, exactly where in the brain auditory WM content is stored and, more importantly, how the memorized information is represented is still unclear.  This research program pursues a better understanding of human auditory WM by attempting to infer its contents from the brain: Using state-of-the-art non-invasive neuroimaging and advanced signal-analysis methods we will search for cortical activation patterns that would predict item-specific WM information. We will examine brain function non-invasively with magneto- and electroencephalography (MEG/EEG), transcranial magnetic stimulation (TMS), and functional MRI (fMRI), and validate the findings using intracranial EEG (iEEG) measurements in presurgical patients. Recent studies suggest that, instead of persistent activation patterns, WM is supported by short-term synaptic facilitation, i.e., ""activity-silent"" population-level mechanisms. We hypothesize that these activity-silent representations could be decoded by analyzing the aftereffects of generic auditory ""impulse stimuli"" or TMS, which are utilized to ""ping"" the underlying cortical network during memory maintenance. We also hypothesize that although auditory WM likely involves co-operation of multiple brain regions, which are involved in articulatory-motor functions, perceptual categorization, or semantic processing, the retention of auditory-sensory attributes such as spectrotemporal modulation patterns critically depends on ACs. To examine WM of such auditory attributes, we will use tasks with dynamic ripple sound stimuli, which are spectrotemporally similar to human vocalizations but resist non-auditory processing strategies.  The major significance of this project is that it will increase the understanding of auditory WM, a crucial cognitive function whose neuronal bases have remained elusive. The results may also help develop more precise tools for characterizing auditory WM dysfunctions in hearing and communication deficits as well as in disorders such as dyslexia, attention deficit/hyperactivity disorder (ADHD), and schizophrenia. Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Our research program pursues a better theoretical understanding of this crucial cognitive function using advanced multimodal neuroimaging methods, validated using intracranial recordings in pre-surgical patients. Our results may also help develop more precise tools for characterizing auditory WM dysfunctions in speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as attention deficit/hyperactivity disorder (ADHD) and schizophrenia.",Decoding parametric attributes of auditory working memories from human brain activity,9498505,R01DC016915,"['Attention deficit hyperactivity disorder', 'Auditory', 'Auditory area', 'Biological Markers', 'Brain', 'Brain region', 'Central Auditory Processing Disorder', 'Cognition', 'Communication', 'Data', 'Disease', 'Dyslexia', 'Electroencephalography', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Generic Drugs', 'Hearing', 'Human', 'Impairment', 'Individual', 'Intervention', 'Laboratory Animals', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measurement', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Motor', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perceptual Disorders', 'Population', 'Principal Component Analysis', 'Problem Solving', 'Reading', 'Research', 'Schizophrenia', 'Sensory', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Speech Perception', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Transcranial magnetic stimulation', 'base', 'cognitive function', 'cortex mapping', 'electric field', 'experimental study', 'frontal lobe', 'multimodality', 'neuroimaging', 'operation', 'programs', 'semantic processing', 'sound', 'tool', 'vocalization']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,602418,0.22802035297058035
"Top-down control of auditory processing in the cortico-collicular network Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network,9408628,R01DC014950,"['Acoustics', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Disease', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Income', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Non-linear Models', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory processing', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'experimental study', 'hearing impairment', 'insight', 'nervous system disorder', 'neurophysiology', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,327250,0.3013511700476788
"Neurophysiology of auditory emotion recognition in the human brain Summary/Abstract:  Auditory emotion recognition (AER) is the process of extracting emotional content out of the acoustic features of speech, and is disrupted in many neuropsychiatric disorders including autism and schizophrenia. Both the encoding of this information in the auditory cortex as well as the knowledge of which brain areas participate in the circuit that underlies AER are not known. With a unique access to invasive intracranial neurophysiology in awake, behaving humans, we propose to study the neural basis of AER in patients undergoing invasive electrode monitoring as part of staged epilepsy surgery protocols. These subjects will perform an AER task while brain responses are recorded in an effort to decipher the neural processes that identify emotion and while specific areas of their brain are stimulated in order to causally link focal activation of AER circuit components to perception.  In Aim 1, we will identify the neuronal mechanisms underlying emotion recognition using a task that breaks down AER into three sequential steps: encoding, integration and judgment. First, we will identify the encoding of emotionally relevant acoustic cues by examining how sensory features such as pitch, intensity and modulation are encoded by neuronal responses in the auditory cortex and other brain areas involved in emotional processing such as the amygdala, insula and prefrontal cortex. Second, we will examine how these acoustic cues are integrated into an emergent emotional percept by measuring activity in putative areas as well as the interaction among these areas after relevant sensory input while subjects consider possible responses. Finally, we will examine the subjects’ response to the AER task and correlate the judgment of emotion with the extent to which it can be predicted by neuronal activity in different brain regions of interest. While most analyses will focus on intraindividual data, differences in brain activity as it relates to AER will be compared in males versus females in order to examine biological differences in AER between sexes. In aim 2, we will determine the effect of neural stimulation on AER. We will apply focal single pulse stimulation to brain areas at those critical time windows identified in aim 1 in order to bias emotional decisions. This type of stimulation results in very focal and temporally restricted disruption of function and can be used to determine a brain area’s causal role in perception.  We seek to build a detailed neurobiological model of the AER. This would be a precursor to designing individualized therapeutic approaches to treat deficits in auditory emotional processing as well as identifying putative targets to treat affective disorders in general. Narrative: Identifying emotion in speech is a critical brain process required for social interaction and is impaired in many neuropsychiatric diseases. We will study how the brain codes the emotional content of speech and how stimulating specific brain areas can potentially improve this process. !",Neurophysiology of auditory emotion recognition in the human brain,9520422,R21MH114166,"['Acoustics', 'Affect', 'Amygdaloid structure', 'Animal Model', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Autistic Disorder', 'Behavioral', 'Biological', 'Brain', 'Brain region', 'Clinical Protocols', 'Code', 'Cognitive', 'Communication', 'Comprehension', 'Cues', 'Data', 'Disease', 'Electric Stimulation', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Emotional', 'Emotions', 'Engineering', 'Epilepsy', 'Evaluation', 'Female', 'Functional Magnetic Resonance Imaging', 'Human', 'Impairment', 'Individual', 'Insula of Reil', 'Judgment', 'Knowledge', 'Link', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mental Depression', 'Methods', 'Modeling', 'Monitor', 'Mood Disorders', 'Neurobiology', 'Neurons', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Perception', 'Performance', 'Personal Communication', 'Physiologic pulse', 'Physiological', 'Physiology', 'Play', 'Population', 'Prefrontal Cortex', 'Process', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Public Health', 'Research', 'Resolution', 'Role', 'Scalp structure', 'Schizophrenia', 'Sensory', 'Social Interaction', 'Speech', 'Speech Pathologist', 'Speed', 'Stimulus', 'Stream', 'Structure', 'Superior temporal gyrus', 'Testing', 'Therapeutic', 'Time', 'Transcranial magnetic stimulation', 'Woman', 'Work', 'autism spectrum disorder', 'awake', 'behavioral study', 'computer studies', 'design', 'experimental study', 'human subject', 'improved', 'innovation', 'interest', 'learning strategy', 'male', 'men', 'neural model', 'neural stimulation', 'neuroimaging', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'physical property', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'sex', 'social', 'social skills', 'spatiotemporal', 'temporal measurement']",NIMH,FEINSTEIN INSTITUTE FOR MEDICAL RESEARCH,R21,2018,202112,0.029287795188455177
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology No abstract available Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,9681144,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2018,58282,0.1593313546956044
"User-driven fitting of hearing aids and other assistive hearing devices Hearing aids are the principal tool today for ameliorating age-related hearing loss and its significant social, cognitive and functional costs to patients and society at large. However, many individuals who are prescribed hearing aids do not use them at all, or use them only occasionally. Most reasons behind the “hearing aid in the drawer” phenomenon relate to the characteristics of the sound produced, and could, in theory, be addressed with the correct signal processing strategy. The problem persists despite the increased complexity and power of new devices, for three reasons: (a) The hearing aid parameters, as set in the clinic, introduce distortion or render audible many sounds that the hearing impaired user had become accustomed to not hearing. The novelty is often so uncomfortable for the user as to discard the device. (b) The optimum parameters vary depending on the listening task and environment. Under some conditions, a device with parameters designed for a different condition will perform worse than no device at all. (c) The clinical fitting is derived from a non-ideal way to assess auditory function (the pure- tone audiogram). The optimum parameters for the actual impairment may be different from those of the prescribed fitting. Although it is true that the physiological mechanisms make it impossible to process sound so as to completely reverse the effect of sensorineural hearing loss, a device that delivers some benefit at all times is likely to be used all the time. The goal is to develop a hearing aid that can adaptively change its parameters to address the problems above, and will be accomplished with a novel fitting approach that rapidly presents a number of parameter settings to the user and lets the user guide the system toward the optimal settings for each listening situation. This requires the development of machine-learning algorithms to effectively search the parameter space and user interface devices and instructions that are easy for the patient to use. The focus of this Phase I proposal is the development of the algorithms and the adaptive user-driven fitting program, and to compare the proposed fitting with the traditional audiogram-based fitting across measures of functional hearing (ability to recognize speech in noise) and subjective preference. A hearing aid user is often dissatisfied with the sound quality of their device, despite its sophistication and adjustment by a trained audiologist. The problem can be mitigated by letting the user fine-tune the device for maximum comfort in everyday use. We will apply modern machine learning methods to develop a program for efficient user-driven fitting of hearing assistive devices.",User-driven fitting of hearing aids and other assistive hearing devices,9409910,R43DC016251,"['Address', 'Algorithms', 'Audiometry', 'Auditory', 'Back', 'Books', 'Cellular Phone', 'Characteristics', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Computer software', 'Development', 'Devices', 'Environment', 'Future', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Impairment', 'Individual', 'Instruction', 'Intuition', 'Knowledge', 'Likelihood Functions', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Music', 'Noise', 'Outcome', 'Patients', 'Performance', 'Phase', 'Physiological', 'Presbycusis', 'Process', 'Protocols documentation', 'Psychology', 'Psychophysics', 'Relaxation', 'Reproducibility', 'Self-Help Devices', 'Sensorineural Hearing Loss', 'Societies', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Time', 'Training', 'Update', 'base', 'cohort', 'cost', 'design', 'hearing impairment', 'improved', 'learning strategy', 'models and simulation', 'novel', 'performance tests', 'preference', 'programs', 'response', 'signal processing', 'simulation', 'social', 'sound', 'success', 'theories', 'tool', 'vector']",NIDCD,"CARAWAY SOFTWARE, INC.",R43,2017,224966,0.11576985528975407
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9301514,R01DC015138,"['Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory area', 'Auditory system', 'Behavior', 'Biological', 'Biomedical Engineering', 'Brain', 'Catalogs', 'Categories', 'Cells', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Devices', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing', 'Human', 'Individual', 'Industrialization', 'Inferior Colliculus', 'Internships', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Prosthesis', 'Psychology', 'Research', 'Research Personnel', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'awake', 'base', 'computational neuroscience', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'novel', 'novel strategies', 'online repository', 'online resource', 'programs', 'relating to nervous system', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2017,293470,0.206253688248554
"Shifting auditory spatial attention: cognitive and neural mechanisms ﻿    DESCRIPTION (provided by applicant): Hearing can serve as an early warning system because it can panoramically monitor the environment for events happening at a distance or out of sight. These ecological considerations make the auditory system particularly useful for studying mechanisms for shifting spatial attention. The focus of this project is on the interplay between top-down and bottom-up spatial attention biases that govern shifting auditory attention to distractors during performance of a simple spatial attention task. The overall goal of this proposal is to use an interdisciplinary approach to better understand at the cognitive and neural levels of analysis how auditory attention is distributed over space. We will test the hypothesis that the spatial distribution of auditory attentional emerges from interactions among two basic factors. The first factor is a voluntary (top-down) attention bias that weakens with distance from the current focus of attention. Conversely, the second factor is an automatic (bottom-up) bias that is tuned to shift attention to unexpected events away from the current focus of attention. The first aim tests a computational model of top-down and bottom-up attention bias in shifting auditory spatial attention. Different aspects of the model will be quantitatively tested against findings from behavioral experiments, and observations will be used to further develop the model. The computational model will incorporate artificial intelligence methods to represent human cognitive processes. The second aim uses transcranial magnetic stimulation to test the role of key right hemisphere cortical areas in shifting of auditory spatial attention. We focus on neural mechanisms of bottom-up attentional bias. The third aim tests whether auditory attention gradients become less focused over time. This will determine how gradients relate to cognitive resources and neural blood flow measures that are known to decline with extended vigilance. This project will help advance knowledge in the field of auditory attention and cognitive hearing, and also addresses general issues in attention research such as top-down and bottom-up processes, vigilance, and their relations to neurobiological attention networks. Outcomes will have practical significance because shifting auditory attention is vital for avoiding accidents at ll ages, maintaining independent living at older ages, and is applicable to neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). PUBLIC HEALTH RELEVANCE: The project outcomes could have clinical in neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). The project will examine mechanisms of normal cognitive aging using computational modeling, which can inform the early detection, differential diagnosis, and treatment monitoring of age-related neurodegenerative disorders such as Alzheimer's disease. Knowledge from the transcranial magnetic and electrical DC stimulation experiments may have translational applications for rehabilitation following brain injuries.",Shifting auditory spatial attention: cognitive and neural mechanisms,9285756,R01DC014736,"['Accidents', 'Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Attention', 'Attention Deficit Disorder', 'Auditory', 'Auditory system', 'Behavioral', 'Blood flow', 'Brain Injuries', 'Clinical', 'Cognitive', 'Cognitive aging', 'Computer Simulation', 'Dementia', 'Differential Diagnosis', 'Diffuse', 'Dimensions', 'Early Diagnosis', 'Electroencephalography', 'Environment', 'Event', 'Goals', 'Hearing', 'Human', 'Impairment', 'Independent Living', 'Individual Differences', 'Inferior', 'Knowledge', 'Learning', 'Left', 'Location', 'Loudness', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Music', 'Neurobiology', 'Neurodegenerative Disorders', 'Obstruction', 'Outcome', 'Parietal', 'Performance', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Probability', 'Process', 'Property', 'Reaction Time', 'Rehabilitation therapy', 'Reproduction', 'Research', 'Resources', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Site', 'Spatial Distribution', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Transcranial magnetic stimulation', 'Vision', 'Work', 'age related', 'alpha-SNAP', 'attentional bias', 'attentional control', 'base', 'behavior measurement', 'cognitive process', 'cost shifting', 'experimental study', 'fighting', 'image guided', 'indexing', 'information processing', 'interdisciplinary approach', 'nervous system disorder', 'neural correlate', 'neural stimulation', 'neuroimaging', 'neuromechanism', 'normal aging', 'prefrontal lobe', 'public health relevance', 'relating to nervous system', 'response', 'sound', 'theories', 'vector', 'vigilance']",NIDCD,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2017,237742,0.16010755783104158
"Top-down control of auditory processing in the cortico-collicular network (Administrative Supplement) Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network (Administrative Supplement),9385957,R01DC014950,"['Acoustics', 'Administrative Supplement', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Disease', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Income', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Non-linear Models', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory processing', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'experimental study', 'hearing impairment', 'insight', 'nervous system disorder', 'neurophysiology', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,131801,0.29645644473926874
"Top-down control of auditory processing in the cortico-collicular network Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network,9207441,R01DC014950,"['Acoustics', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Disease', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Income', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Non-linear Models', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory processing', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'experimental study', 'hearing impairment', 'insight', 'nervous system disorder', 'neurophysiology', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,327250,0.3013511700476788
"Neurophysiology of auditory emotion recognition in the human brain Summary/Abstract:  Auditory emotion recognition (AER) is the process of extracting emotional content out of the acoustic features of speech, and is disrupted in many neuropsychiatric disorders including autism and schizophrenia. Both the encoding of this information in the auditory cortex as well as the knowledge of which brain areas participate in the circuit that underlies AER are not known. With a unique access to invasive intracranial neurophysiology in awake, behaving humans, we propose to study the neural basis of AER in patients undergoing invasive electrode monitoring as part of staged epilepsy surgery protocols. These subjects will perform an AER task while brain responses are recorded in an effort to decipher the neural processes that identify emotion and while specific areas of their brain are stimulated in order to causally link focal activation of AER circuit components to perception.  In Aim 1, we will identify the neuronal mechanisms underlying emotion recognition using a task that breaks down AER into three sequential steps: encoding, integration and judgment. First, we will identify the encoding of emotionally relevant acoustic cues by examining how sensory features such as pitch, intensity and modulation are encoded by neuronal responses in the auditory cortex and other brain areas involved in emotional processing such as the amygdala, insula and prefrontal cortex. Second, we will examine how these acoustic cues are integrated into an emergent emotional percept by measuring activity in putative areas as well as the interaction among these areas after relevant sensory input while subjects consider possible responses. Finally, we will examine the subjects’ response to the AER task and correlate the judgment of emotion with the extent to which it can be predicted by neuronal activity in different brain regions of interest. While most analyses will focus on intraindividual data, differences in brain activity as it relates to AER will be compared in males versus females in order to examine biological differences in AER between sexes. In aim 2, we will determine the effect of neural stimulation on AER. We will apply focal single pulse stimulation to brain areas at those critical time windows identified in aim 1 in order to bias emotional decisions. This type of stimulation results in very focal and temporally restricted disruption of function and can be used to determine a brain area’s causal role in perception.  We seek to build a detailed neurobiological model of the AER. This would be a precursor to designing individualized therapeutic approaches to treat deficits in auditory emotional processing as well as identifying putative targets to treat affective disorders in general. Narrative: Identifying emotion in speech is a critical brain process required for social interaction and is impaired in many neuropsychiatric diseases. We will study how the brain codes the emotional content of speech and how stimulating specific brain areas can potentially improve this process. !",Neurophysiology of auditory emotion recognition in the human brain,9373513,R21MH114166,"['Acoustics', 'Affect', 'Amygdaloid structure', 'Animal Model', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Autistic Disorder', 'Behavioral', 'Biological', 'Brain', 'Brain region', 'Clinical Protocols', 'Code', 'Cognitive', 'Communication', 'Comprehension', 'Cues', 'Data', 'Disease', 'Electric Stimulation', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Emotional', 'Emotions', 'Engineering', 'Epilepsy', 'Evaluation', 'Female', 'Functional Magnetic Resonance Imaging', 'Human', 'Impairment', 'Individual', 'Insula of Reil', 'Judgment', 'Knowledge', 'Link', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mental Depression', 'Methods', 'Modeling', 'Monitor', 'Mood Disorders', 'Neurobiology', 'Neurons', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Perception', 'Performance', 'Personal Communication', 'Physiologic pulse', 'Physiological', 'Physiology', 'Play', 'Population', 'Prefrontal Cortex', 'Process', 'Protocols documentation', 'Psychiatrist', 'Psychologist', 'Public Health', 'Research', 'Resolution', 'Role', 'Scalp structure', 'Schizophrenia', 'Sensory', 'Social Interaction', 'Speech', 'Speech Pathologist', 'Speed', 'Stimulus', 'Stream', 'Structure', 'Superior temporal gyrus', 'Testing', 'Therapeutic', 'Time', 'Transcranial magnetic stimulation', 'Woman', 'Work', 'autism spectrum disorder', 'awake', 'behavioral study', 'computer studies', 'design', 'experimental study', 'human subject', 'improved', 'innovation', 'interest', 'learning strategy', 'male', 'men', 'neural model', 'neural stimulation', 'neuroimaging', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'physical property', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'sex', 'social', 'social skills', 'spatiotemporal', 'temporal measurement']",NIMH,FEINSTEIN INSTITUTE FOR MEDICAL RESEARCH,R21,2017,253863,0.029287795188455177
"Neural mechanisms of auditory temporal pattern perception Project Summary/Abstract: Processing acoustic communication signals is among the most difficult, yet vital capabilities that the auditory system must achieve. These abilities lie at the heart of language and speech processing, and their success or failure can have profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, as well as improving diagnoses and treatments for learning disabilities and communication disorders such as auditory processing disorder, dyslexia, and specific language impairment. While much has been learned about the loci of language-related processing using non-invasive neuroscience techniques in humans, these techniques cannot answer how individual neurons and neural circuits implement language-relevant computations. As a result, the explicit cellular circuit-level and neuro-computational mechanisms that support acoustic communication signal processing are poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language, in particular the processing of temporal patterns within communication signals. The experiments outlined in this proposal investigate the neural mechanisms of auditory temporal pattern processing. In humans, the transition statistics between adjacent speech sounds (phonemes) can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Sensitivity to transition statistics is not exclusive to speech signals however, but reflects general auditory processes shared by many animals. In Aim 1 we investigate the categorical perception of complex auditory objects in populations of cortical neurons in an animal model, and ask how these neural representations are effected by temporal context. In addition to which elements occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Studies in Aim 2 focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. In Aim 3, we propose a basic circuit in which population level representations of auditory objects could be differentially modulated by patterning rules, and test this proposed pattern processing circuit using direct, casual manipulations. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Neural mechanisms of auditory temporal pattern perception,9527903,R56DC016408,"['Acoustics', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Biological Assay', 'Biological Models', 'Birds', 'Categories', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computational Technique', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrophysiology (science)', 'Elements', 'Environment', 'Failure', 'Foundations', 'Goals', 'Heart', 'Human', 'Individual', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Nuclear', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Population Dynamics', 'Process', 'Property', 'Quality of life', 'Research', 'Role', 'Services', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Structure', 'Sturnus vulgaris', 'Superior temporal gyrus', 'System', 'Systems Development', 'Techniques', 'Testing', 'Time', 'Training', 'Transition Elements', 'Work', 'auditory processing', 'bird song', 'cognitive process', 'experimental study', 'hearing impairment', 'improved', 'language processing', 'microstimulation', 'model development', 'neural circuit', 'neural patterning', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R56,2017,363607,0.1431137767649926
"Experimental and Clinical Studies of Presbycusis DESCRIPTION (provided by applicant): The focus of this research is age-related hearing loss (presbycusis). Currently, more than 28 million Americans have impaired hearing and approximately 75% of these persons are over the age of 55. The prevalence of presbycusis will increase substantially with the aging of the population. To meet the challenges of this most common chronic condition of aging, improved diagnostic methods, treatment approaches, and prevention strategies will be of great importance. To meet these objectives, four research projects are proposed. Project 1 assesses age-related changes in human cochlear and neural function related to metabolic, sensory, and neural pathologies. Project 2 examines the impact of metabolic and sensory presbycusis and aging on brain structure and functional networks that support speech recognition. Project 3 identifies genetic variations causing an increased susceptibility to age-related hearing loss using DNA samples from older adults in our study and defines their pathological consequences in human temporal bones. Project 4 studies adult stem cell dependency on the cochlear extracellular matrix (ECM) microenvironment using animal models of metabolic presbycusis and ECM deficiency, and observations of cochlear tissues from human temporal bones. A central goal is to relate changes observed in animal models of metabolic presbycusis to declines in hearing in older humans. In parallel with this goal, results from the large battery of tests obtained from participants in our longitudinal study (Human Subjects Core) will be analyzed to further define and validate phenotypes of age-related hearing loss. Thus, four interrelated research projects, supported by large numbers of well-characterized human subjects and a detailed database of cross-sectional and longitudinal data, form a cohesive program that addresses fundamental questions on human presbycusis. The Clinical Research Center is unique in several respects, including its 25-year longitudinal study of  hearing in older persons, the diversity of basic, translational, and clinical approaches, and its focus on a disorder that contributes to poor communication abilities and reduced quality of life for millions of older adults. PUBLIC HEALTH RELEVANCE: The Clinical Research Center leverages the multidisciplinary and wide-ranging expertise in each project, and the wealth of information available in the human subject database, to generate new knowledge on the high prevalence public health problem of age-related hearing loss. Our goals are to reduce its prevalence, slow its progression, and develop new prevention, diagnostic, and treatments strategies to improve communication and quality of life of older adults.      Subproject 1  Defining Phenotypes of Age-Related Hearing Loss  Lead Investigator: Judy R. Dubno, Ph.D.    DESCRIPTION (provided by applicant): The complex genetic and environmental factors affecting human hearing over the lifespan contribute to a large variation in audiometric profiles and suprathreshold measures of auditory function. As a result, determining mechanisms of age-related hearing loss in older adults is challenging because genetic, age, noise history, injury, disease, medication, diet, and other factors can work independently and jointly to alter human auditory function. Although morphologic findings from older humans are limited to postmortem data, experimental procedures with animals of known heredity can disrupt specific cochlear systems, model certain pathologic conditions, and introduce or minimize environmental exposures, while measuring subsequent changes in auditory function. Consistent with results from animal models linking audiometric profiles to specific cochlear pathologies, such as metabolic or sensory loss, audiograms from the Clinical Research Center's human subject database (Core B) were classified into four audiometric phenotypes, which provided a means to characterize the pathophysiology of hearing loss in older humans. Audiometric phenotypes determined using supervised machine learning classifiers were consistent with expected demographic and noise history patterns that segregate with patterns of hearing loss. Project 1 will refine and further validate these phenotyping methods using suprathreshold measures of cochlear and neural function beyond the audiogram that characterize metabolic and sensory presbyacusis, and the additive effects of morphologic and functional neural loss. To meet this goal Aim 1.1 tests the hypothesis that older adults with metabolic and sensory presbyacusis differ in cochlear nonlinearities and lower frequency suprathreshold auditory function. Aim 1.2 tests the hypothesis that changes in auditory nerve activity result in unique and additive effects in older adults with metabolic and sensory presbyacusis. Thus, Project 1 will assess age- related changes in auditory function related to metabolic, sensory, and neural pathologies and link findings to Project 2, focused on central auditory and cortical changes, and to translational Projects 3 and 4, which will determine the genetic and cellular mechanisms of age-related hearing loss using humans and human tissue. With these approaches, morphologic and physiologic changes characterizing metabolic, sensory, and neural presbyacusis provide a framework for assessing and interpreting age-related changes in human auditory function.    PUBLIC HEALTH RELEVANCE: Knowledge of the variations in pathophysiology underlying human age-related hearing loss may dictate different diagnostic test batteries, hearing-aid fitting  algorithms, auditory-training regimens, and recommendations for communication strategies. This new information will lead to better diagnosis and treatments for this high-prevalence public health concern, and improved communication and quality of life for millions of older adults.",Experimental and Clinical Studies of Presbycusis,9205503,P50DC000422,"['Acoustic Nerve', 'Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'American', 'Animal Model', 'Animals', 'Audiometry', 'Auditory', 'Autopsy', 'Brain', 'Chronic', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'DNA', 'Data', 'Databases', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Diet', 'Disease', 'Doctor of Philosophy', 'Elderly', 'Environmental Exposure', 'Environmental Risk Factor', 'Extracellular Matrix', 'Frequencies', 'Functional disorder', 'Genetic', 'Genetic Variation', 'Goals', 'Hearing', 'Hearing Aids', 'Heredity', 'High Prevalence', 'Human', 'Injury', 'Knowledge', 'Lead', 'Link', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Morphology', 'Neurophysiology - biologic function', 'Noise', 'Participant', 'Pathologic', 'Pathology', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical shape', 'Physiological', 'Population', 'Predisposition', 'Presbycusis', 'Prevalence', 'Prevention', 'Prevention strategy', 'Procedures', 'Public Health', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Sensory', 'Structure', 'Supervision', 'System', 'Temporal bone structure', 'Testing', 'Training', 'Variant', 'Work', 'adult stem cell', 'age related', 'cohesion', 'experimental study', 'hearing impairment', 'human subject', 'human tissue', 'improved', 'multidisciplinary', 'programs', 'public health relevance', 'relating to nervous system', 'speech recognition', 'support network', 'treatment strategy']",NIDCD,MEDICAL UNIVERSITY OF SOUTH CAROLINA,P50,2017,2137301,0.13449758506472695
"Micromachined microphones with in-plane and out-of-plane directivity Project Summary We aim to introduce to the hearing-assistive device industry directional microphones with high signal-to-noise ratio, and the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or “window” of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired “rocking” style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. We aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete  -axis pressure gradient sensor. Project Narrative Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the “cocktail party” effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified – making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.",Micromachined microphones with in-plane and out-of-plane directivity,9098683,R44DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Hearing', 'Hearing Aids', 'Industry', 'Laboratories', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R44,2016,490980,0.1443969165148067
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9090040,R01DC015138,"['Accounting', 'Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory area', 'Auditory system', 'Behavior', 'Biomedical Engineering', 'Brain', 'Cataloging', 'Catalogs', 'Categories', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Devices', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing', 'Human', 'Individual', 'Inferior Colliculus', 'Internships', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Neurosciences', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Process', 'Prosthesis', 'Psychology', 'Reading', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'Work', 'awake', 'base', 'computational neuroscience', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'novel', 'novel strategies', 'online repository', 'programs', 'relating to nervous system', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2016,293470,0.206253688248554
"Top-down control of auditory processing in the cortico-collicular network Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network,9005185,R01DC014950,"['Accounting', 'Acoustics', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Disease', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Sensory Process', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'hearing impairment', 'insight', 'meetings', 'nervous system disorder', 'neurophysiology', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'research study', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2016,327250,0.3013511700476788
"Experimental and Clinical Studies of Presbycusis DESCRIPTION (provided by applicant): The focus of this research is age-related hearing loss (presbycusis). Currently, more than 28 million Americans have impaired hearing and approximately 75% of these persons are over the age of 55. The prevalence of presbycusis will increase substantially with the aging of the population. To meet the challenges of this most common chronic condition of aging, improved diagnostic methods, treatment approaches, and prevention strategies will be of great importance. To meet these objectives, four research projects are proposed. Project 1 assesses age-related changes in human cochlear and neural function related to metabolic, sensory, and neural pathologies. Project 2 examines the impact of metabolic and sensory presbycusis and aging on brain structure and functional networks that support speech recognition. Project 3 identifies genetic variations causing an increased susceptibility to age-related hearing loss using DNA samples from older adults in our study and defines their pathological consequences in human temporal bones. Project 4 studies adult stem cell dependency on the cochlear extracellular matrix (ECM) microenvironment using animal models of metabolic presbycusis and ECM deficiency, and observations of cochlear tissues from human temporal bones. A central goal is to relate changes observed in animal models of metabolic presbycusis to declines in hearing in older humans. In parallel with this goal, results from the large battery of tests obtained from participants in our longitudinal study (Human Subjects Core) will be analyzed to further define and validate phenotypes of age-related hearing loss. Thus, four interrelated research projects, supported by large numbers of well-characterized human subjects and a detailed database of cross-sectional and longitudinal data, form a cohesive program that addresses fundamental questions on human presbycusis. The Clinical Research Center is unique in several respects, including its 25-year longitudinal study of  hearing in older persons, the diversity of basic, translational, and clinical approaches, and its focus on a disorder that contributes to poor communication abilities and reduced quality of life for millions of older adults. PUBLIC HEALTH RELEVANCE: The Clinical Research Center leverages the multidisciplinary and wide-ranging expertise in each project, and the wealth of information available in the human subject database, to generate new knowledge on the high prevalence public health problem of age-related hearing loss. Our goals are to reduce its prevalence, slow its progression, and develop new prevention, diagnostic, and treatments strategies to improve communication and quality of life of older adults.      Subproject 1  Defining Phenotypes of Age-Related Hearing Loss  Lead Investigator: Judy R. Dubno, Ph.D.    DESCRIPTION (provided by applicant): The complex genetic and environmental factors affecting human hearing over the lifespan contribute to a large variation in audiometric profiles and suprathreshold measures of auditory function. As a result, determining mechanisms of age-related hearing loss in older adults is challenging because genetic, age, noise history, injury, disease, medication, diet, and other factors can work independently and jointly to alter human auditory function. Although morphologic findings from older humans are limited to postmortem data, experimental procedures with animals of known heredity can disrupt specific cochlear systems, model certain pathologic conditions, and introduce or minimize environmental exposures, while measuring subsequent changes in auditory function. Consistent with results from animal models linking audiometric profiles to specific cochlear pathologies, such as metabolic or sensory loss, audiograms from the Clinical Research Center's human subject database (Core B) were classified into four audiometric phenotypes, which provided a means to characterize the pathophysiology of hearing loss in older humans. Audiometric phenotypes determined using supervised machine learning classifiers were consistent with expected demographic and noise history patterns that segregate with patterns of hearing loss. Project 1 will refine and further validate these phenotyping methods using suprathreshold measures of cochlear and neural function beyond the audiogram that characterize metabolic and sensory presbyacusis, and the additive effects of morphologic and functional neural loss. To meet this goal Aim 1.1 tests the hypothesis that older adults with metabolic and sensory presbyacusis differ in cochlear nonlinearities and lower frequency suprathreshold auditory function. Aim 1.2 tests the hypothesis that changes in auditory nerve activity result in unique and additive effects in older adults with metabolic and sensory presbyacusis. Thus, Project 1 will assess age- related changes in auditory function related to metabolic, sensory, and neural pathologies and link findings to Project 2, focused on central auditory and cortical changes, and to translational Projects 3 and 4, which will determine the genetic and cellular mechanisms of age-related hearing loss using humans and human tissue. With these approaches, morphologic and physiologic changes characterizing metabolic, sensory, and neural presbyacusis provide a framework for assessing and interpreting age-related changes in human auditory function.    PUBLIC HEALTH RELEVANCE: Knowledge of the variations in pathophysiology underlying human age-related hearing loss may dictate different diagnostic test batteries, hearing-aid fitting  algorithms, auditory-training regimens, and recommendations for communication strategies. This new information will lead to better diagnosis and treatments for this high-prevalence public health concern, and improved communication and quality of life for millions of older adults.",Experimental and Clinical Studies of Presbycusis,9012784,P50DC000422,"['Acoustic Nerve', 'Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'American', 'Animal Model', 'Animals', 'Audiometry', 'Auditory', 'Autopsy', 'Biological Models', 'Brain', 'Chronic', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'DNA', 'Data', 'Databases', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Diet', 'Disease', 'Doctor of Philosophy', 'Elderly', 'Environmental Exposure', 'Environmental Risk Factor', 'Extracellular Matrix', 'Frequencies', 'Functional disorder', 'Genetic', 'Genetic Variation', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Heredity', 'High Prevalence', 'Human', 'Injury', 'Knowledge', 'Lead', 'Link', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Neurophysiology - biologic function', 'Noise', 'Participant', 'Pathologic', 'Pathology', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical shape', 'Physiological', 'Predisposition', 'Presbycusis', 'Prevalence', 'Prevention', 'Prevention strategy', 'Procedures', 'Public Health', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Sensory', 'Structure', 'Temporal bone structure', 'Testing', 'Training', 'Variant', 'Work', 'adult stem cell', 'age related', 'aging population', 'hearing impairment', 'human subject', 'human tissue', 'improved', 'meetings', 'multidisciplinary', 'programs', 'relating to nervous system', 'research study', 'speech recognition', 'support network', 'treatment strategy']",NIDCD,MEDICAL UNIVERSITY OF SOUTH CAROLINA,P50,2016,2214679,0.13449758506472695
"Micromachined microphones with in-plane and out-of-plane directivity Project Summary We aim to introduce to the hearing-assistive device industry directional microphones with high signal-to-noise ratio, and the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or “window” of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired “rocking” style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. We aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete  -axis pressure gradient sensor. Project Narrative Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the “cocktail party” effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified – making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.",Micromachined microphones with in-plane and out-of-plane directivity,8981015,R44DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Hearing', 'Hearing Aids', 'Industry', 'Laboratories', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R44,2015,508997,0.1443969165148067
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9047911,R01DC015138,"['Accounting', 'Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory area', 'Auditory system', 'Behavior', 'Biomedical Engineering', 'Brain', 'Cataloging', 'Catalogs', 'Categories', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Devices', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing', 'Human', 'Individual', 'Inferior Colliculus', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Neurosciences', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Process', 'Prosthesis', 'Psychology', 'Reading', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'Work', 'awake', 'base', 'computational neuroscience', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'novel', 'novel strategies', 'programs', 'relating to nervous system', 'repository', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2015,311320,0.206253688248554
"Shifting auditory spatial attention: cognitive and neural mechanisms ﻿    DESCRIPTION (provided by applicant): Hearing can serve as an early warning system because it can panoramically monitor the environment for events happening at a distance or out of sight. These ecological considerations make the auditory system particularly useful for studying mechanisms for shifting spatial attention. The focus of this project is on the interplay between top-down and bottom-up spatial attention biases that govern shifting auditory attention to distractors during performance of a simple spatial attention task. The overall goal of this proposal is to use an interdisciplinary approach to better understand at the cognitive and neural levels of analysis how auditory attention is distributed over space. We will test the hypothesis that the spatial distribution of auditory attentional emerges from interactions among two basic factors. The first factor is a voluntary (top-down) attention bias that weakens with distance from the current focus of attention. Conversely, the second factor is an automatic (bottom-up) bias that is tuned to shift attention to unexpected events away from the current focus of attention. The first aim tests a computational model of top-down and bottom-up attention bias in shifting auditory spatial attention. Different aspects of the model will be quantitatively tested against findings from behavioral experiments, and observations will be used to further develop the model. The computational model will incorporate artificial intelligence methods to represent human cognitive processes. The second aim uses transcranial magnetic stimulation to test the role of key right hemisphere cortical areas in shifting of auditory spatial attention. We focus on neural mechanisms of bottom-up attentional bias. The third aim tests whether auditory attention gradients become less focused over time. This will determine how gradients relate to cognitive resources and neural blood flow measures that are known to decline with extended vigilance. This project will help advance knowledge in the field of auditory attention and cognitive hearing, and also addresses general issues in attention research such as top-down and bottom-up processes, vigilance, and their relations to neurobiological attention networks. Outcomes will have practical significance because shifting auditory attention is vital for avoiding accidents at ll ages, maintaining independent living at older ages, and is applicable to neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia).         PUBLIC HEALTH RELEVANCE: The project outcomes could have clinical in neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). The project will examine mechanisms of normal cognitive aging using computational modeling, which can inform the early detection, differential diagnosis, and treatment monitoring of age-related neurodegenerative disorders such as Alzheimer's disease. Knowledge from the transcranial magnetic and electrical DC stimulation experiments may have translational applications for rehabilitation following brain injuries.                ",Shifting auditory spatial attention: cognitive and neural mechanisms,8946229,R01DC014736,"['Accidents', 'Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Attention', 'Attention Deficit Disorder', 'Auditory', 'Auditory system', 'Behavioral', 'Blood flow', 'Brain Injuries', 'Clinical', 'Cognitive', 'Cognitive aging', 'Computer Simulation', 'Dementia', 'Differential Diagnosis', 'Diffuse', 'Early Diagnosis', 'Electroencephalography', 'Environment', 'Event', 'Goals', 'Hearing', 'Human', 'Impairment', 'Independent Living', 'Individual Differences', 'Inferior', 'Knowledge', 'Learning', 'Left', 'Location', 'Loudness', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Music', 'Neurobiology', 'Neurodegenerative Disorders', 'Obstruction', 'Outcome', 'Parietal', 'Performance', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Probability', 'Process', 'Property', 'Reaction Time', 'Rehabilitation therapy', 'Relative (related person)', 'Reproduction', 'Research', 'Resources', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Site', 'Spatial Distribution', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Transcranial magnetic stimulation', 'Vision', 'Work', 'age related', 'attentional bias', 'base', 'behavior measurement', 'cognitive process', 'cost shifting', 'fighting', 'image guided', 'indexing', 'information processing', 'interdisciplinary approach', 'nervous system disorder', 'neural correlate', 'neural stimulation', 'neuroimaging', 'neuromechanism', 'normal aging', 'prefrontal lobe', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'sound', 'theories', 'vector', 'vigilance']",NIDCD,TULANE UNIVERSITY OF LOUISIANA,R01,2015,283560,0.16010755783104158
"Experimental and Clinical Studies of Presbycusis DESCRIPTION (provided by applicant): The focus of this research is age-related hearing loss (presbycusis). Currently, more than 28 million Americans have impaired hearing and approximately 75% of these persons are over the age of 55. The prevalence of presbycusis will increase substantially with the aging of the population. To meet the challenges of this most common chronic condition of aging, improved diagnostic methods, treatment approaches, and prevention strategies will be of great importance. To meet these objectives, four research projects are proposed. Project 1 assesses age-related changes in human cochlear and neural function related to metabolic, sensory, and neural pathologies. Project 2 examines the impact of metabolic and sensory presbycusis and aging on brain structure and functional networks that support speech recognition. Project 3 identifies genetic variations causing an increased susceptibility to age-related hearing loss using DNA samples from older adults in our study and defines their pathological consequences in human temporal bones. Project 4 studies adult stem cell dependency on the cochlear extracellular matrix (ECM) microenvironment using animal models of metabolic presbycusis and ECM deficiency, and observations of cochlear tissues from human temporal bones. A central goal is to relate changes observed in animal models of metabolic presbycusis to declines in hearing in older humans. In parallel with this goal, results from the large battery of tests obtained from participants in our longitudinal study (Human Subjects Core) will be analyzed to further define and validate phenotypes of age-related hearing loss. Thus, four interrelated research projects, supported by large numbers of well-characterized human subjects and a detailed database of cross-sectional and longitudinal data, form a cohesive program that addresses fundamental questions on human presbycusis. The Clinical Research Center is unique in several respects, including its 25-year longitudinal study of  hearing in older persons, the diversity of basic, translational, and clinical approaches, and its focus on a disorder that contributes to poor communication abilities and reduced quality of life for millions of older adults. PUBLIC HEALTH RELEVANCE: The Clinical Research Center leverages the multidisciplinary and wide-ranging expertise in each project, and the wealth of information available in the human subject database, to generate new knowledge on the high prevalence public health problem of age-related hearing loss. Our goals are to reduce its prevalence, slow its progression, and develop new prevention, diagnostic, and treatments strategies to improve communication and quality of life of older adults.      Subproject 1  Defining Phenotypes of Age-Related Hearing Loss  Lead Investigator: Judy R. Dubno, Ph.D.    DESCRIPTION (provided by applicant): The complex genetic and environmental factors affecting human hearing over the lifespan contribute to a large variation in audiometric profiles and suprathreshold measures of auditory function. As a result, determining mechanisms of age-related hearing loss in older adults is challenging because genetic, age, noise history, injury, disease, medication, diet, and other factors can work independently and jointly to alter human auditory function. Although morphologic findings from older humans are limited to postmortem data, experimental procedures with animals of known heredity can disrupt specific cochlear systems, model certain pathologic conditions, and introduce or minimize environmental exposures, while measuring subsequent changes in auditory function. Consistent with results from animal models linking audiometric profiles to specific cochlear pathologies, such as metabolic or sensory loss, audiograms from the Clinical Research Center's human subject database (Core B) were classified into four audiometric phenotypes, which provided a means to characterize the pathophysiology of hearing loss in older humans. Audiometric phenotypes determined using supervised machine learning classifiers were consistent with expected demographic and noise history patterns that segregate with patterns of hearing loss. Project 1 will refine and further validate these phenotyping methods using suprathreshold measures of cochlear and neural function beyond the audiogram that characterize metabolic and sensory presbyacusis, and the additive effects of morphologic and functional neural loss. To meet this goal Aim 1.1 tests the hypothesis that older adults with metabolic and sensory presbyacusis differ in cochlear nonlinearities and lower frequency suprathreshold auditory function. Aim 1.2 tests the hypothesis that changes in auditory nerve activity result in unique and additive effects in older adults with metabolic and sensory presbyacusis. Thus, Project 1 will assess age- related changes in auditory function related to metabolic, sensory, and neural pathologies and link findings to Project 2, focused on central auditory and cortical changes, and to translational Projects 3 and 4, which will determine the genetic and cellular mechanisms of age-related hearing loss using humans and human tissue. With these approaches, morphologic and physiologic changes characterizing metabolic, sensory, and neural presbyacusis provide a framework for assessing and interpreting age-related changes in human auditory function.    PUBLIC HEALTH RELEVANCE: Knowledge of the variations in pathophysiology underlying human age-related hearing loss may dictate different diagnostic test batteries, hearing-aid fitting  algorithms, auditory-training regimens, and recommendations for communication strategies. This new information will lead to better diagnosis and treatments for this high-prevalence public health concern, and improved communication and quality of life for millions of older adults.",Experimental and Clinical Studies of Presbycusis,8786533,P50DC000422,"['Acoustic Nerve', 'Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'American', 'Animal Model', 'Animals', 'Audiometry', 'Auditory', 'Autopsy', 'Biological Models', 'Brain', 'Chronic', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'DNA', 'Data', 'Databases', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Diet', 'Disease', 'Doctor of Philosophy', 'Elderly', 'Environmental Exposure', 'Environmental Risk Factor', 'Extracellular Matrix', 'Frequencies', 'Functional disorder', 'Genetic', 'Genetic Variation', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Heredity', 'High Prevalence', 'Human', 'Injury', 'Knowledge', 'Lead', 'Link', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Neurophysiology - biologic function', 'Noise', 'Participant', 'Pathologic', 'Pathology', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical shape', 'Physiological', 'Population', 'Predisposition', 'Presbycusis', 'Prevalence', 'Prevention', 'Prevention strategy', 'Procedures', 'Public Health', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Sensory', 'Structure', 'Temporal bone structure', 'Testing', 'Training', 'Variant', 'Work', 'adult stem cell', 'age related', 'hearing impairment', 'human subject', 'human tissue', 'improved', 'meetings', 'multidisciplinary', 'programs', 'relating to nervous system', 'research study', 'speech recognition', 'treatment strategy']",NIDCD,MEDICAL UNIVERSITY OF SOUTH CAROLINA,P50,2015,2302752,0.13449758506472695
"Micromachined microphones with in-plane and out-of-plane directivity  Project Summary We aim to introduce to the hearing-assistive device industry the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or ""window"" of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired ""rocking"" style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. In Phase II, we aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete 3-axis pressure gradient sensor. PUBLIC HEALTH RELEVANCE: Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the ""cocktail party"" effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified - making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.            ",Micromachined microphones with in-plane and out-of-plane directivity,8648777,R43DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Goals', 'Hearing', 'Hearing Aids', 'Industry', 'Investigation', 'Laboratories', 'Microfabrication', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Phase', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Structure', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'public health relevance', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R43,2014,149828,0.14254456645565072
"Experimental and Clinical Studies of Presbycusis DESCRIPTION (provided by applicant): The focus of this research is age-related hearing loss (presbycusis). Currently, more than 28 million Americans have impaired hearing and approximately 75% of these persons are over the age of 55. The prevalence of presbycusis will increase substantially with the aging of the population. To meet the challenges of this most common chronic condition of aging, improved diagnostic methods, treatment approaches, and prevention strategies will be of great importance. To meet these objectives, four research projects are proposed. Project 1 assesses age-related changes in human cochlear and neural function related to metabolic, sensory, and neural pathologies. Project 2 examines the impact of metabolic and sensory presbycusis and aging on brain structure and functional networks that support speech recognition. Project 3 identifies genetic variations causing an increased susceptibility to age-related hearing loss using DNA samples from older adults in our study and defines their pathological consequences in human temporal bones. Project 4 studies adult stem cell dependency on the cochlear extracellular matrix (ECM) microenvironment using animal models of metabolic presbycusis and ECM deficiency, and observations of cochlear tissues from human temporal bones. A central goal is to relate changes observed in animal models of metabolic presbycusis to declines in hearing in older humans. In parallel with this goal, results from the large battery of tests obtained from participants in our longitudinal study (Human Subjects Core) will be analyzed to further define and validate phenotypes of age-related hearing loss. Thus, four interrelated research projects, supported by large numbers of well-characterized human subjects and a detailed database of cross-sectional and longitudinal data, form a cohesive program that addresses fundamental questions on human presbycusis. The Clinical Research Center is unique in several respects, including its 25-year longitudinal study of  hearing in older persons, the diversity of basic, translational, and clinical approaches, and its focus on a disorder that contributes to poor communication abilities and reduced quality of life for millions of older adults. PUBLIC HEALTH RELEVANCE: The Clinical Research Center leverages the multidisciplinary and wide-ranging expertise in each project, and the wealth of information available in the human subject database, to generate new knowledge on the high prevalence public health problem of age-related hearing loss. Our goals are to reduce its prevalence, slow its progression, and develop new prevention, diagnostic, and treatments strategies to improve communication and quality of life of older adults.      Subproject 1  Defining Phenotypes of Age-Related Hearing Loss  Lead Investigator: Judy R. Dubno, Ph.D.    DESCRIPTION (provided by applicant): The complex genetic and environmental factors affecting human hearing over the lifespan contribute to a large variation in audiometric profiles and suprathreshold measures of auditory function. As a result, determining mechanisms of age-related hearing loss in older adults is challenging because genetic, age, noise history, injury, disease, medication, diet, and other factors can work independently and jointly to alter human auditory function. Although morphologic findings from older humans are limited to postmortem data, experimental procedures with animals of known heredity can disrupt specific cochlear systems, model certain pathologic conditions, and introduce or minimize environmental exposures, while measuring subsequent changes in auditory function. Consistent with results from animal models linking audiometric profiles to specific cochlear pathologies, such as metabolic or sensory loss, audiograms from the Clinical Research Center's human subject database (Core B) were classified into four audiometric phenotypes, which provided a means to characterize the pathophysiology of hearing loss in older humans. Audiometric phenotypes determined using supervised machine learning classifiers were consistent with expected demographic and noise history patterns that segregate with patterns of hearing loss. Project 1 will refine and further validate these phenotyping methods using suprathreshold measures of cochlear and neural function beyond the audiogram that characterize metabolic and sensory presbyacusis, and the additive effects of morphologic and functional neural loss. To meet this goal Aim 1.1 tests the hypothesis that older adults with metabolic and sensory presbyacusis differ in cochlear nonlinearities and lower frequency suprathreshold auditory function. Aim 1.2 tests the hypothesis that changes in auditory nerve activity result in unique and additive effects in older adults with metabolic and sensory presbyacusis. Thus, Project 1 will assess age- related changes in auditory function related to metabolic, sensory, and neural pathologies and link findings to Project 2, focused on central auditory and cortical changes, and to translational Projects 3 and 4, which will determine the genetic and cellular mechanisms of age-related hearing loss using humans and human tissue. With these approaches, morphologic and physiologic changes characterizing metabolic, sensory, and neural presbyacusis provide a framework for assessing and interpreting age-related changes in human auditory function.    PUBLIC HEALTH RELEVANCE: Knowledge of the variations in pathophysiology underlying human age-related hearing loss may dictate different diagnostic test batteries, hearing-aid fitting  algorithms, auditory-training regimens, and recommendations for communication strategies. This new information will lead to better diagnosis and treatments for this high-prevalence public health concern, and improved communication and quality of life for millions of older adults.",Experimental and Clinical Studies of Presbycusis,8617361,P50DC000422,"['Acoustic Nerve', 'Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'American', 'Animal Model', 'Animals', 'Audiometry', 'Auditory', 'Autopsy', 'Biological Models', 'Brain', 'Chronic', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'DNA', 'Data', 'Databases', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Diet', 'Disease', 'Doctor of Philosophy', 'Elderly', 'Environmental Exposure', 'Environmental Risk Factor', 'Extracellular Matrix', 'Frequencies', 'Functional disorder', 'Genetic', 'Genetic Variation', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Heredity', 'High Prevalence', 'Human', 'Injury', 'Knowledge', 'Lead', 'Link', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Neurophysiology - biologic function', 'Noise', 'Participant', 'Pathologic', 'Pathology', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical shape', 'Physiological', 'Population', 'Predisposition', 'Presbycusis', 'Prevalence', 'Prevention', 'Prevention strategy', 'Procedures', 'Public Health', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Sensory', 'Structure', 'Temporal bone structure', 'Testing', 'Training', 'Variant', 'Work', 'adult stem cell', 'age related', 'hearing impairment', 'human subject', 'human tissue', 'improved', 'meetings', 'multidisciplinary', 'programs', 'relating to nervous system', 'research study', 'speech recognition', 'treatment strategy']",NIDCD,MEDICAL UNIVERSITY OF SOUTH CAROLINA,P50,2014,2047726,0.13449758506472695
"Individualized Signal Processing Strategy to Reduce Hearing Health Care Cost/Disp  This project describes a novel approach to automate and individualize the signal processing strategy for hearing aids that can result in improved speech intelligibility in background noise, greater user satisfaction and acceptance for hearing aids, and reduce barriers to affordable hearing health care. The proposed Individualized Signal Processing Strategy (ISPS) is based upon individual performance on categorical perception tasks for speech stimuli. This differs from traditional methods based on sophisticated gain models built upon average perception, performance, and preference data. The ability to determine one's ISPS automatically, rapidly and remotely results in dramatic cost-savings and greater accessibility to hearing health care for patients who cannot afford it or for those who lack easy access to the necessary expertise. These technical achievements have the potential to radically change the hearing aid sales and delivery models yet can also be implemented within existing business models by replacing contemporary hearing aid fitting methods (e.g. adjusting to gain-frequency targets followed by subjective fine tuning) with individualized speech-based parameter adjustment. Successful implementation of the ISPS technology will impact several barriers identified in RFA-DC-12-004 including physical, infrastructure and knowledge barriers (by allowing remote or self-fitting hearing aids and minimizing the need for highly skilled expertise), economic barriers (by reducing overall costs) and cultural barriers (by providing easy access to hearing aid fitting for patients who tend to avoid seeking professional help). This Phase I project will demonstrate the feasibility for the ISPS approach by (1) implementing the ISPS on a standard personal computer, (2) integrating the ISPS with a commercially available hearing aid, and (3) completing a pilot clinical study comparing outcomes with ISPS fitting to those achieved with traditional prescriptive gain fitting within the same subjects. Following successful demonstration of these objectives, a Phase II project will be proposed to enable extension of the technology to a wide range of hearing aids, patient characteristics and listening environments, including innovations supporting the use for remote and self-fitting applications. PUBLIC HEALTH RELEVANCE: This project seeks to develop, implement and test a novel approach for fitting hearing aids using an individual's speech perception abilities. This automated approach can improved listener performance while significant reducing costs of hearing health care. The automation of the fitting procedure can dramatically increase accessibility of hearing health care.                ",Individualized Signal Processing Strategy to Reduce Hearing Health Care Cost/Disp,8626066,R43DC013623,"['Achievement', 'Acoustics', 'Artificial Intelligence', 'Audiology', 'Automation', 'Behavioral', 'Businesses', 'Canada', 'Characteristics', 'Clinical Research', 'Cochlear Implants', 'Collection', 'Computer software', 'Cost Savings', 'Crossover Design', 'Data', 'Devices', 'Economics', 'Effectiveness', 'Environment', 'Frequencies', 'Generations', 'Goals', 'Graph', 'Health Care Costs', 'Healthcare', 'Hearing', 'Hearing Aids', 'Individual', 'Knowledge', 'Learning', 'Letters', 'Manufacturer Name', 'Maps', 'Measures', 'Methods', 'Metric', 'Modeling', 'Modification', 'Noise', 'Outcome', 'Output', 'Patients', 'Pattern', 'Perception', 'Performance', 'Personal Computers', 'Persons', 'Phase', 'Pilot Projects', 'Procedures', 'Process', 'Randomized', 'Research', 'Research Infrastructure', 'Sales', 'Services', 'Solutions', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Stimulus', 'Technology', 'Testing', 'Time', 'Training', 'Translations', 'Work', 'base', 'cost', 'design', 'experience', 'implantable device', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'preference', 'public health relevance', 'satisfaction', 'signal processing', 'sound', 'success', 'theories']",NIDCD,"SECURBORATION, INC.",R43,2014,149994,0.04166102120908342
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.        PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8723146,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2014,341462,0.31779046705636393
"Coding of auditory space in the avian brain DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding. The proposed research will test hypotheses based on human models, of how the auditory system computes  sound direction. This approach has the potential of providing new avenues for better understanding disorders  of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering,  mathematical formulations of brain processes can advance technology related to artificial intelligence and  neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea  could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8521234,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2013,324389,0.3076216884684013
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.       PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8305642,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2012,341462,0.31779046705636393
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.       PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8196019,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2011,24900,0.31779046705636393
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.       PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8265019,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2011,341462,0.31779046705636393
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.       PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8040464,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2010,352750,0.31779046705636393
"Auditory constraints on infant language learning    DESCRIPTION (provided by applicant): The goal of the current research is to investigate auditory constraints on general learning mechanisms (GLMs) underlying infant language acquisition. There have been numerous demonstrations of the importance of GLMs in word segmentation, and more recently this approach has been extended to phoneme acquisition. The primary critique of GLMs is that they are too computationally powerful. Without constraints, it would be difficult to extract only meaningful regularities, making the task of language acquisition a potentially intractable problem. Auditory constraints may provide a good framework on which GLMs can operate, facilitating the task of language acquisition. The first Specific Aim of the research proposed in this application is to examine the relationships between auditory sensitivities and distributional learning during phoneme acquisition. 7.5-month-old infants will be exposed to either a unimodal or a bimodal distribution of speech sounds. A habituation procedure will be used to test the hypothesis that the presence of a region of increased auditory sensitivity at a category boundary will facilitate phoneme acquisition. The second Specific Aim is to investigate the relationship between rhythmic grouping biases and statistical learning during word segmentation from fluent speech. Following familiarization to an artificial language that contains both statistical and rhythmic cues to words boundaries, 6.5- and 8.5-month-old infants are expected to mis-segment the statistical words in the language if the statistics and the perceived rhythmic grouping are inconsistent. Age effects are expected only if linguistic experience is necessary for auditory rhythmic grouping biases to emerge. The third Specific Aim is to assess the domain generality of the mechanisms described in the first and second aims. Non-speech stimuli will be used to assess the generality of distributional and statistical learning in the same types of category learning and segmentation tasks. The goal of this research is to understand how the auditory system of a typically developing infant structures language learning. In some atypical populations, it is unclear whether language acquisition is delayed because the auditory system is compromised or because the mechanisms responsible for learning are compromised. Future studies will use these tasks to assess learning in atypical language learners (e.g., young children with phonological disorders, toddlers with cochlear implants, infants at risk for language impairments), with the eventual goal of developing new interventions for use in clinical populations.           n/a",Auditory constraints on infant language learning,7600444,F32HD055703,"['Address', 'Adult', 'Affect', 'Area', 'Attention', 'Auditory', 'Auditory system', 'Categories', 'Child', 'Clinical', 'Cochlear Implants', 'Critiques', 'Cues', 'Discrimination', 'Disease', 'Elements', 'Exposure to', 'Future', 'Goals', 'Grouping', 'Human Characteristics', 'Impairment', 'Infant', 'Intervention', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Methods', 'Pattern', 'Phonetics', 'Population', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Risk', 'Role', 'Signal Transduction', 'Specificity', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Structure', 'Testing', 'Toddler', 'age effect', 'experience', 'natural language', 'phonology', 'programs', 'research study', 'sound', 'statistics', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2009,22393,0.11920264344584806
"Auditory constraints on infant language learning    DESCRIPTION (provided by applicant): The goal of the current research is to investigate auditory constraints on general learning mechanisms (GLMs) underlying infant language acquisition. There have been numerous demonstrations of the importance of GLMs in word segmentation, and more recently this approach has been extended to phoneme acquisition. The primary critique of GLMs is that they are too computationally powerful. Without constraints, it would be difficult to extract only meaningful regularities, making the task of language acquisition a potentially intractable problem. Auditory constraints may provide a good framework on which GLMs can operate, facilitating the task of language acquisition. The first Specific Aim of the research proposed in this application is to examine the relationships between auditory sensitivities and distributional learning during phoneme acquisition. 7.5-month-old infants will be exposed to either a unimodal or a bimodal distribution of speech sounds. A habituation procedure will be used to test the hypothesis that the presence of a region of increased auditory sensitivity at a category boundary will facilitate phoneme acquisition. The second Specific Aim is to investigate the relationship between rhythmic grouping biases and statistical learning during word segmentation from fluent speech. Following familiarization to an artificial language that contains both statistical and rhythmic cues to words boundaries, 6.5- and 8.5-month-old infants are expected to mis-segment the statistical words in the language if the statistics and the perceived rhythmic grouping are inconsistent. Age effects are expected only if linguistic experience is necessary for auditory rhythmic grouping biases to emerge. The third Specific Aim is to assess the domain generality of the mechanisms described in the first and second aims. Non-speech stimuli will be used to assess the generality of distributional and statistical learning in the same types of category learning and segmentation tasks. The goal of this research is to understand how the auditory system of a typically developing infant structures language learning. In some atypical populations, it is unclear whether language acquisition is delayed because the auditory system is compromised or because the mechanisms responsible for learning are compromised. Future studies will use these tasks to assess learning in atypical language learners (e.g., young children with phonological disorders, toddlers with cochlear implants, infants at risk for language impairments), with the eventual goal of developing new interventions for use in clinical populations.           n/a",Auditory constraints on infant language learning,7486009,F32HD055703,"['Address', 'Adult', 'Affect', 'Area', 'Attention', 'Auditory', 'Auditory system', 'Categories', 'Child', 'Clinical', 'Cochlear Implants', 'Critiques', 'Cues', 'Discrimination', 'Disease', 'Elements', 'Exposure to', 'Future', 'Goals', 'Grouping', 'Human Characteristics', 'Impairment', 'Infant', 'Intervention', 'Language', 'Language Development', 'Learning', 'Linguistics', 'Loudness', 'Machine Learning', 'Methods', 'Numbers', 'Pattern', 'Phonetics', 'Population', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Risk', 'Role', 'Signal Transduction', 'Specificity', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Structure', 'Testing', 'Toddler', 'age effect', 'experience', 'phonology', 'programs', 'research study', 'sound', 'statistics', 'theories']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,F32,2008,49646,0.11920264344584806
"Neural network model of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using radial basis function neural network (RBFNN) that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The RBFNN model will be fed training data from our existing database (chinchilla) consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals. Once trained, the model will be able to predict the auditory consequences of exposure to any noise environment characterized by ten noise metrics and five biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/histological data are available (Year 2). The training period will be an iterative process in which the RBFNN will be modified as training proceeds. The prediction model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a RBFNN to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Neural network model of noise-induced hearing loss,6941215,R03OH008175,"['artificial intelligence', 'chinchilla', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'disease /disorder model', 'environmental exposure', 'model design /development', 'noise biological effect', 'noise induced deafness']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R03,2005,71735,0.12205276991802756
"Model for prediction of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using a statistical learning machine (SLM), which includes an artificial neural network (ANN), a support vector machine (SVM), and a hybrid of ANN and SVM, that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The SLM model will be fed training data from our existing database consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals.  Once trained, the SLM model will be able to predict the auditory consequences of exposure to any noise environment characterized by the noise metrics and biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/ histological data are available (Year 2). The training period will be an iterative process in which the SLM will be modified as training proceeds. The predictions of the SLM model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a statistical learning machine to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Model for prediction of noise-induced hearing loss,6878561,R01OH007801,"['chinchilla', 'computational neuroscience', 'computer program /software', 'computer system design /evaluation', 'mathematical model', 'model design /development', 'noise induced deafness', 'noise pollution']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R01,2005,139799,0.12260796909243334
"Neural network model of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using radial basis function neural network (RBFNN) that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The RBFNN model will be fed training data from our existing database (chinchilla) consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals. Once trained, the model will be able to predict the auditory consequences of exposure to any noise environment characterized by ten noise metrics and five biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/histological data are available (Year 2). The training period will be an iterative process in which the RBFNN will be modified as training proceeds. The prediction model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a RBFNN to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Neural network model of noise-induced hearing loss,6820323,R03OH008175,"['artificial intelligence', 'chinchilla', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'disease /disorder model', 'environmental exposure', 'model design /development', 'noise biological effect', 'noise induced deafness']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R03,2004,71000,0.12205276991802756
"Model for prediction of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using a statistical learning machine (SLM), which includes an artificial neural network (ANN), a support vector machine (SVM), and a hybrid of ANN and SVM, that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The SLM model will be fed training data from our existing database consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals.  Once trained, the SLM model will be able to predict the auditory consequences of exposure to any noise environment characterized by the noise metrics and biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/ histological data are available (Year 2). The training period will be an iterative process in which the SLM will be modified as training proceeds. The predictions of the SLM model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a statistical learning machine to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Model for prediction of noise-induced hearing loss,6753927,R01OH007801,"['chinchilla', 'computational neuroscience', 'computer program /software', 'computer system design /evaluation', 'mathematical model', 'model design /development', 'noise induced deafness', 'noise pollution']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R01,2004,138439,0.12260796909243334
"SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN) PROJECT SUMMARY/ABSTRACT In recent years, human cognitive auditory neuroscience has made rapid strides due to advances in human neuroimaging, the advent of innovative machine learning/big data analytic approaches, and a greater mechanistic understanding of cognitive-sensory interactions in animal models. The dynamic landscape of this emergent field necessitates a highly interdisciplinary, human and translation-centric symposium that brings together expertise across academia and industry. This application requests partial funding for the Symposium on Cognitive Auditory Neuroscience (SCAN) to be hosted in Pittsburgh, PA in July 2020 and 2022, as a joint venture between Carnegie Mellon University (CMU) and University of Pittsburgh (Pitt). As a biennial meeting, SCAN aims to become the premiere intellectual and professional venue for current research in the emerging field of human cognitive auditory neuroscience. SCAN will incorporate elements typical to academic conferences (research talks, posters) as well as novel ideas that promote ‘blue sky’ thinking in this rapidly evolving field. SCAN will assiduously and innovatively work towards inclusivity and creating an atmosphere that encourages intellectual and professional engagement from women, underrepresented minorities, and individuals with disabilities. Another critical aim of the SCAN is to foster industry-academic partnerships with an eye towards translation of basic research and fostering career opportunities for trainees. Pittsburgh is uniquely situated to launch SCAN. With an enviable concentration of co-located auditory neuroscience expertise, Pittsburgh is also an intellectual hub for industries/start-ups engaged in in machine learning, natural language processing, and speech recognition. SCAN will leverage these advantages to foster growth and innovation tied to core missions of the National Institutes of Deafness and Communication Disorders. PROJECT NARRATIVE The Symposium on Cognitive Auditory Neuroscience (SCAN) has a strong connection to deafness and communication disorders through its focus on the basic science of human cognitive auditory neuroscience, and its translation. SCAN will establish an intellectual home for dissemination of cutting-edge research in human cognitive auditory neuroscience, support the development of the next generation of scientists, build a vibrant and inclusive community that engages with the grand challenges in the field, and forge new academia-industry partnerships.",SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN),9914387,R13DC018243,"['Academia', 'Acoustics', 'Address', 'Affect', 'Americas', 'Animal Model', 'Atmosphere', 'Attention', 'Auditory', 'Auditory Perception', 'BRAIN initiative', 'Base of the Brain', 'Basic Science', 'Behavioral', 'Big Data Methods', 'Brain', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communities', 'Complex', 'Development', 'Disabled Persons', 'Disease', 'Ear', 'Educational workshop', 'Elements', 'Environment', 'Eye', 'Fertilization', 'Fostering', 'Funding', 'Geographic Locations', 'Goals', 'Growth', 'Hearing', 'Home environment', 'Human', 'Industry', 'Influentials', 'Institutes', 'Joint Ventures', 'Learning', 'Life', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Mission', 'Natural Language Processing', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Otolaryngology', 'Participant', 'Perception', 'Peripheral', 'Problem Solving', 'Process', 'Request for Applications', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Seeds', 'Sensory', 'Societies', 'Speech', 'Thinking', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'analytical tool', 'base', 'career', 'cognitive neuroscience', 'deafness', 'industry partner', 'innovation', 'interest', 'meetings', 'millisecond', 'neuroimaging', 'new technology', 'next generation', 'novel', 'open data', 'posters', 'pressure', 'relating to nervous system', 'sensory input', 'sound', 'speech recognition', 'symposium', 'virtual reality']",NIDCD,CARNEGIE-MELLON UNIVERSITY,R13,2020,36183,0.1221466557667558
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9939507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Models', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'machine learning method', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,334688,0.13795659737398352
"Revealing the organization and functional significance of neural timescales in auditory cortex Project Summary People are remarkably adept at making sense of the world through sound: understanding speech in a noisy restaurant, picking out the voice of a family member, or recognizing a familiar melody. Although we take these abilities for granted, they reflect impressive computational feats of biological engineering that are remarkably difficult to replicate in machine systems. The long-term goal of my research program is to develop computational and experimental methods to reverse-engineer how the brain codes natural sounds like speech and to exploit these advances to understand and aid in the treatment of hearing impairment. One of the central challenges of coding natural sounds is that they are structured at many different timescales from milliseconds to seconds and even minutes. How does the brain integrate across these diverse timescales to derive meaning from sound? Answering this question has been challenging because there are no general-purpose methods for measuring neural timescales in the brain. As a consequence, we know relatively little about how neural timescales are organized in auditory cortex and how this organization enables the coding of natural sounds. To overcome these limitations, we develop a simple experimental paradigm (the “temporal context invariance” or TCI paradigm) for estimating the temporal integration period of any sensory response: the time window during which stimuli alter the response. We apply the TCI method to human electrocorticography (ECoG) and animal physiology recordings to reveal the organization of neural timescales at both the region and single-cell level (Aim I). Pilot data from our analyses reveal that timescales are organized hierarchically, with higher-order regions showing substantially longer integration periods. To explore the functional significance of this timescale hierarchy, we couple TCI with computational techniques well-suited for characterizing natural sounds (Aim II). We test whether increased integration periods enable a more noise-robust representation of speech (Aim IIA), whether regions with longer integration periods code higher-order properties of natural sounds (Aim IIB&IIC), whether there are dedicated integration periods for important sounds categories like speech or music (Aim IID), and whether cortical integration periods can be explained by the duration of the features they respond to (Aim IIE). In the process of conducting this research, I will be trained in two critical areas: (1) ECoG, which is the only method with the spatial and temporal precision to understand how neural timescales are organized in the human brain (2) deep neural networks (DNN) which are the only models able to perform challenging perceptual tasks at human levels and predict neural responses in higher-order cortical regions. After completing this training, I will have a unique set of experimental (fMRI, ECoG, psychophysics) and computational skills (data-driven statistical modeling and hypothesis-driven DNN modeling), which will facilitate my transition to an independent investigator. Project Narrative Natural sounds like speech contain information at many different timescales (e.g. phonemes, syllables, words), but how the human brain extracts this information remains unclear. Understanding this process is critical to understanding how hearing impairment degrades speech perception. The proposed research will reveal the organization of neural timescales in the brain, and how this organization facilitates the coding of natural sounds like speech, which is a critical first step in understanding how this code is impaired by hearing loss.",Revealing the organization and functional significance of neural timescales in auditory cortex,9977571,K99DC018051,"['Address', 'Animals', 'Area', 'Auditory area', 'Biological', 'Brain', 'Categories', 'Cells', 'Code', 'Collaborations', 'Communication', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Data', 'Electrocorticogram', 'Engineering', 'Family member', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Hearing', 'Human', 'Learning', 'Measures', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurosciences', 'Noise', 'Physiology', 'Population', 'Process', 'Property', 'Psychophysics', 'Reaction Time', 'Research', 'Research Personnel', 'Research Training', 'Restaurants', 'Sensory', 'Speech', 'Speech Perception', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'Voice', 'Work', 'clinically significant', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'millisecond', 'neuromechanism', 'programs', 'relating to nervous system', 'response', 'skills', 'sound', 'theories']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,K99,2020,125442,0.04311278951825969
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology Project Summary Listening in noise is a core problem in everyday hearing. Sound sources of interest routinely occur amid irrelevant distractors, as when you talk with someone in a bustling coffee shop. This background “noise” distorts the pattern of spikes in the auditory nerve, often to a profound degree. Thus, to recognize sources of interest, the auditory system must somehow separate or suppress the effects of the background. Typical human hearing is remarkably noise-robust, but listeners with age-related hearing loss or other forms of impaired hearing struggle in noisy environments – and are not much helped by contemporary hearing aids. Previous work on the neural basis of noise robustness has typically employed simple, synthetic noise sources, which lack the structure present in real-world sounds, and this work has focused on subcortical regions or on primary auditory cortex. Reasoning that real-world conditions might necessitate more complicated solutions, in the applicant's doctoral work, he considered everyday sources of noise, and leveraged the large-scale coverage afforded by fMRI to examine noise robustness throughout human auditory cortex. Real-world “background noise” was operationalized as a natural sound with statistical properties that are stable over time (i.e., are stationary), conveying little new information about the world (e.g., swamp insects, an air conditioner, rain on pavement). The applicant measured fMRI responses in human listeners to a broad set of natural sounds presented in quiet, as well as embedded in the real-world background noises. Primary auditory cortical responses were substantially altered by the background, but non-primary responses were substantially more robust. This effect was not seen for simple synthetic backgrounds as had been used in previous work, suggesting that becoming robust to real-world background noises require different mechanisms. The applicant's thesis work demonstrates where noise invariance arises, but understanding how will require data with finer spatial and temporal resolution, and thus the proposed postdoctoral research will consist of training in single-unit electrophysiology using marmosets. Aim 1A builds on previous work examining single- unit noise robustness in artificial conditions, extending such work to real-world noise. Aim 1B leverages texture models to probe what aspects of real-world backgrounds disrupt the encoding of foregrounds. Aim 2A deploys linear reconstruction techniques to probe population representations. Aim 2B involves optimizing deep neural networks for noise invariance tasks, and using them as an encoding model to predict single-unit responses. Furthermore, such networks will be deployed as nonlinear decoding algorithms, reconstructing stimuli from neuronal populations. Throughout all aims, the work will characterize neuronal responses in non-primary areas, and in particular in parabelt, which is understudied in primates. The proposed work may enable improvements in hearing aid algorithms or neural prosthetics. Lastly, this training will lay the groundwork for the applicant's long-term goal of developing a marmoset model for hearing loss. Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,10104430,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Quality of life', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'algorithm training', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2020,64926,0.1843068048940191
"Computational Cognitive Neuroscience of Human Auditory Cortex PROJECT SUMMARY Humans with normal hearing excel at deriving information about the world from sound. Our auditory abilities represent stunning computational feats that only recently have been replicated to any extent in machine systems. And yet our auditory abilities are highly vulnerable, being greatly compromised in listeners with hearing impairment, cochlear implants, and auditory neurodevelopmental disorders, particularly in the presence of noise. Difficulties in recognition often lead to frustration and social isolation, and are not adequately addressed by current hearing aids, implants, and remediation strategies. The long-term goal of the proposed research is to reveal the basis of auditory recognition and to provide insights that will facilitate improved prosthetic devices and therapeutic interventions. The development of more effective devices and therapies is currently limited by an incomplete understanding of the factors that underlie real-world recognition by normal-hearing listeners. In particular, although responses to sound in subcortical auditory pathways are relatively well studied, little is known about the transformations that occur within the auditory cortex to create representations of meaningful sound structure. We propose to enrich the understanding of auditory recognition with three sets of experiments that examine the cortical representation of real-world sounds in human listeners, combining functional magnetic resonance imaging (fMRI) with computational modeling of the underlying representations. Aim 1 develops artificial neural network models of speech and music processing and compares their representations to those in the auditory cortex, synthesizing and then measuring brain responses to sounds that generate the same response in a model, and probing the time scale of the auditory analysis of speech and music. Aim 2 develops and tests models of pitch perception in noise, exploring the hypothesis that pitch perception is constrained both by the statistics of natural sounds and the frequency selectivity of the cochlea. Aim 3 develops and tests models that jointly localize and recognize sounds, and probes the brain representations of sound identity and location using fMRI. The results will reveal the mechanisms underlying robust sound recognition by the healthy auditory system and will set the stage for investigations of the cortical consequences of hearing impairment and auditory developmental disorders, hopefully suggesting new strategies for remediation. PROJECT NARRATIVE: People with normal hearing are typically able to recognize, understand and localize sounds of interest, but this ability is often compromised in listeners with hearing disorders. The proposed research will enrich the understanding of the neural mechanisms underlying auditory recognition and localization in normal listeners. The results will likely provide insight into the brain processes whose alteration in hearing disorders underlies listening difficulties, potentially leading to improved remediation strategies.",Computational Cognitive Neuroscience of Human Auditory Cortex,9944496,R01DC017970,"['Address', 'Adopted', 'Auditory', 'Auditory Perception', 'Auditory area', 'Auditory system', 'Behavioral', 'Biological Assay', 'Brain', 'Brain region', 'Characteristics', 'Child', 'Cochlea', 'Cochlear Implants', 'Computer Models', 'Data', 'Development', 'Devices', 'Drops', 'Ear', 'Floor', 'Frequencies', 'Frustration', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing Aids', 'Hearing Tests', 'Hearing problem', 'Human', 'Implant', 'Investigation', 'Lead', 'Location', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Noise', 'Pathway interactions', 'Peripheral', 'Persons', 'Pitch Perception', 'Population', 'Process', 'Property', 'Prosthesis', 'Psychophysics', 'Research', 'Rest', 'Social isolation', 'Sound Localization', 'Source', 'Speech', 'Stimulus', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Visual Pathways', 'artificial neural network', 'auditory pathway', 'cognitive neuroscience', 'computational basis', 'deep learning', 'deep neural network', 'developmental disease', 'experimental study', 'hearing impairment', 'improved', 'insight', 'interest', 'network architecture', 'neural network', 'neuromechanism', 'neurophysiology', 'normal hearing', 'novel', 'relating to nervous system', 'remediation', 'response', 'sound', 'sound frequency', 'speech processing', 'statistics']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,337875,0.28451728740823146
"Decoding parametric attributes of auditory working memories from human brain activity Decoding parametric attributes of auditory working memories from human brain activity Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Auditory WM dysfunctions are evidenced in individuals with speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as central auditory processing disorders (CAPD). Better understanding of auditory WM would help develop more precise biomarkers and targeted interventions for these deficits. Evidence for neuronal activation related to auditory WM patterns have been found in laboratory animals as well as in non- invasive human neuroimaging studies, both in auditory cortices (AC) and elsewhere in the brain. Recent human fMRI data also provide some evidence on item-specific activation patterns in ACs and frontal cortices. However, exactly where in the brain auditory WM content is stored and, more importantly, how the memorized information is represented is still unclear.  This research program pursues a better understanding of human auditory WM by attempting to infer its contents from the brain: Using state-of-the-art non-invasive neuroimaging and advanced signal-analysis methods we will search for cortical activation patterns that would predict item-specific WM information. We will examine brain function non-invasively with magneto- and electroencephalography (MEG/EEG), transcranial magnetic stimulation (TMS), and functional MRI (fMRI), and validate the findings using intracranial EEG (iEEG) measurements in presurgical patients. Recent studies suggest that, instead of persistent activation patterns, WM is supported by short-term synaptic facilitation, i.e., ""activity-silent"" population-level mechanisms. We hypothesize that these activity-silent representations could be decoded by analyzing the aftereffects of generic auditory ""impulse stimuli"" or TMS, which are utilized to ""ping"" the underlying cortical network during memory maintenance. We also hypothesize that although auditory WM likely involves co-operation of multiple brain regions, which are involved in articulatory-motor functions, perceptual categorization, or semantic processing, the retention of auditory-sensory attributes such as spectrotemporal modulation patterns critically depends on ACs. To examine WM of such auditory attributes, we will use tasks with dynamic ripple sound stimuli, which are spectrotemporally similar to human vocalizations but resist non-auditory processing strategies.  The major significance of this project is that it will increase the understanding of auditory WM, a crucial cognitive function whose neuronal bases have remained elusive. The results may also help develop more precise tools for characterizing auditory WM dysfunctions in hearing and communication deficits as well as in disorders such as dyslexia, attention deficit/hyperactivity disorder (ADHD), and schizophrenia. Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Our research program pursues a better theoretical understanding of this crucial cognitive function using advanced multimodal neuroimaging methods, validated using intracranial recordings in pre-surgical patients. Our results may also help develop more precise tools for characterizing auditory WM dysfunctions in speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as attention deficit/hyperactivity disorder (ADHD) and schizophrenia.",Decoding parametric attributes of auditory working memories from human brain activity,9870791,R01DC016915,"['Attention deficit hyperactivity disorder', 'Auditory', 'Auditory area', 'Biological Markers', 'Brain', 'Brain region', 'Central Auditory Processing Disorder', 'Cognition', 'Communication', 'Data', 'Disease', 'Dyslexia', 'Electroencephalography', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Hearing', 'Human', 'Impairment', 'Individual', 'Intervention', 'Laboratory Animals', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measurement', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Motor', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perceptual Disorders', 'Population', 'Principal Component Analysis', 'Problem Solving', 'Reading', 'Research', 'Schizophrenia', 'Sensory', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Speech Perception', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Transcranial magnetic stimulation', 'base', 'cognitive function', 'cortex mapping', 'electric field', 'experimental study', 'frontal lobe', 'multimodality', 'neuroimaging', 'operation', 'programs', 'semantic processing', 'sound', 'tool', 'vocalization']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,601029,0.22802035297058035
"Behavioral and neural algorithms for decision confidence Project Summary/Abstract The long-term goal of our investigations is to understand how neural circuits in the frontal cortex support decision- making. Orbitofrontal cortex (OFC) plays a key role in decision-making under uncertainty and is thought to enable humans and other animals to make predictions about outcomes more accurately. The objective of this proposal is to determine the algorithms responsible for confidence-guided behaviors and their neural basis in the mammalian brain.  Previous work from our laboratory has shown that `decision confidence', a cognitive variable, is encoded in single OFC neurons and OFC inactivation specifically impairs a confidence-guided behavior, time investment. The proposed experiments are designed to determine the computational and neural algorithms responsible for two confidence-guided behaviors: time investment and choice strategy updating (learning). Our central hypothesis is that OFC generates an abstract representation of decision confidence, independent of sensory evidence, that supports multiple confidence-guided behaviors. To test this idea, we have designed a quantitative psychophysical task for rats, adapted from human and primate work, that enable behavioral readouts of confidence, as a post-decision temporal wager. Simply, after each perceptual decision (olfactory or auditory) rats invest time waiting for a delayed, uncertain reward. These graded- duration time investments serve as a behavioral report of confidence that the perceptual decision just made will result in the success of the perceptual decision. First, we will develop computational algorithms to explain confidence-guided time investment and learning, and second we will identify neural substrates of these algorithms in the OFC. Third, we will determine if OFC representations are sensory-modality and behavioral-output general and test the causal role of OFC using inactivations. Finally, we will map a sensory route for auditory information to inform OFC representations and test the hypothesis that auditory cortex lesions lead to deaf-hearing, the ability to discriminate sounds without perceptual confidence.  These contributions are significant, in our opinion, because they will provide critical missing information about the algorithmic and neural foundations of decision confidence, a key cognitive variable. Our approach is innovative, chiefly because we have developed a computational and behavioral framework to study confidence in rats. Beyond these mechanistic studies, the proposed work will advance knowledge about the frontal cortical logic of cognitive variable representations and inform an improved framework for understanding how impairments in a single brain area can lead to a wide range of psychiatric disorders, as seen in depression, obsessive- compulsive and psychotic disorders. Project narrative This proposal aims to identify the computational algorithms of two confidence-guided behaviors, time investment and choice strategy updating, and the neural processes underlying these. We will use a combination of electrophysiology, viral tracing, optogenetics in a quantitative confidence-reporting behavior in rats, interpreted with computational modeling and statistical analysis. We aim to test our central hypothesis that OFC generates an abstract representation of decision confidence that supports multiple confidence-guided behavioral processes.",Behavioral and neural algorithms for decision confidence,10058676,R01MH097061,"['Algorithms', 'Animals', 'Anxiety', 'Area', 'Auditory', 'Auditory area', 'Awareness', 'Behavior', 'Behavioral', 'Behavioral trial', 'Belief', 'Brain', 'Cognitive', 'Complex', 'Computational algorithm', 'Computer Models', 'Data', 'Decision Making', 'Electrophysiology (science)', 'Foundations', 'Goals', 'Hearing', 'Human', 'Impairment', 'Investigation', 'Investments', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Lesion', 'Logic', 'Maps', 'Mental Depression', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Monkeys', 'Neurons', 'Obsessive compulsive behavior', 'Outcome', 'Output', 'Pathologic', 'Play', 'Population', 'Primates', 'Process', 'Psychophysics', 'Psychotic Disorders', 'Rattus', 'Reporting', 'Rewards', 'Rodent', 'Role', 'Route', 'Sensory', 'Statistical Data Interpretation', 'Stream', 'Testing', 'Time', 'Uncertainty', 'Update', 'Viral', 'Vision', 'Visual', 'Visual Cortex', 'Wages', 'Work', 'base', 'blind', 'deaf', 'design', 'experimental study', 'falls', 'frontal lobe', 'improved', 'innovation', 'machine learning method', 'neural circuit', 'neuropsychiatry', 'novel', 'optogenetics', 'relating to nervous system', 'sensory cortex', 'sound', 'success']",NIMH,WASHINGTON UNIVERSITY,R01,2020,500079,0.06616241157293289
"Auditory precursors of language delay in toddlers with autism spectrum disorders Abstract Language delay and impairments are common in autism spectrum disorders (ASDs), as are sensory (including auditory) anomalies. Since acquisition of spoken language relies on the integrity of the auditory system, language delay and impairments may be related to sound processing abnormalities that are frequently observed in children with ASDs (despite normal peripheral hearing). However, it is not understood if and how early auditory brain anomalies may developmentally contribute to impaired language development.  This project will examine the maturation of auditory and language systems in the brain across early childhood, during the critical period for language acquisition. We will employ a longitudinal design and multimodal neuroimaging, including high-resolution anatomical, diffusion, and functional magnetic resonance imaging (MRI), with added frequent and extensive behavioral and neuropsychological assessments. Our central hypothesis is that early disruptions to cortical sound processing precede and predict language impairments in ASDs and may thus be considered causal contributors – a hypothesis that has been frequently considered in the literature, but never tested at the neural level.  Our aims are to thoroughly characterize the structural integrity and functional differentiation of the cortical auditory and language systems (Aim 1) and their maturational trajectories (Aim 2) in toddlers with ASDs and age-matched typically developing peers. This will allow us to establish whether neural abnormalities in cortical processing of complex sounds in toddlers are predictive of language development and social behavior at the pre-school age (Aim 3). The rationale and translational significance of this project are that identification of alterations in brain development linked to language delay and impairment in the first years of life will allow for more targeted interventions in the auditory domain at a time when they are most effective. Project narrative The project aims to find causes of language impairment in children with autism spectrum disorders by studying the brain organization of the auditory system in toddlers at the very earliest age of provisional diagnosis. The overarching hypothesis is that atypical auditory processing contributes to language delay and impairment. Pinpointing auditory causes of language problems in children with ASDs may inform early interventions.",Auditory precursors of language delay in toddlers with autism spectrum disorders,9913498,R01DC017736,"['Age', 'Anatomy', 'Animal Model', 'Anisotropy', 'Auditory', 'Auditory area', 'Auditory system', 'Basic Science', 'Behavioral', 'Brain', 'Brain region', 'Child', 'Complex', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Early Intervention', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Imaging Techniques', 'Impairment', 'Individual', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Length', 'Life', 'Link', 'Literature', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Morphology', 'Neurites', 'Neuropsychology', 'Nursery Schools', 'Organizational Change', 'Pattern', 'Peripheral', 'Radial', 'Research', 'Research Priority', 'Resolution', 'Risk', 'Sensory', 'Sleep', 'Social Behavior', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'TEP1 gene', 'Techniques', 'Testing', 'Thalamic structure', 'Thick', 'Time', 'Toddler', 'auditory processing', 'autism spectrum disorder', 'autistic children', 'base', 'critical period', 'density', 'early childhood', 'gray matter', 'indexing', 'language impairment', 'longitudinal design', 'machine learning method', 'molecular modeling', 'multimodality', 'myelination', 'neuroimaging', 'novel', 'peer', 'phonology', 'recruit', 'relating to nervous system', 'response', 'sound', 'theories', 'translational impact']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2020,592142,0.1876368707386896
"Auditory brain-computer interface for communication Project Summary  A fundamental end-goal of brain-computer interfaces (BCI) is to enable communication in individuals with severe motor paralysis. BCIs decode the neural signals and accomplish the intended goal via an effector, such as a computer cursor or a robotic limb. The BCI user relies on the realtime feedback of the effector's performance to modulate their neural strategy to control the external device. To date, this feedback is predominantly visual. However patients with the most severe paralysis resulting from amyotrophic lateral sclerosis (ALS), some forms of stroke and traumatic brain injuries can have severe visual impairments including oculomotor fatigue, nystagmus and ophthalmoparesis - that make the reliable use of a visual-based BCI impossible. This puts a premium on developing novel solutions that can leverage sensory modalities that are intact. In this research, I will develop and test the feasibility of an auditory-based interface to establish BCI control in motor-impaired patients with severe neurological insults  In Aim 1, I propose to implement a novel paradigm using auditory cues in lieu of visual signals, and test its feasibility in controlling an effector (ie, computer cursor) to perform a cued target-acquisition task in healthy participants. This will validate the range of parameter values of the four tested auditory input signals: 1) frequency, 2) amplitude, 3) spatial azimuth and 4) spatial elevation. This approach is distinct from most binary class auditory BCI solutions, since it relies on both the natural ability of humans to localize sounds, and the ability to associate new tones to a virtual space, thus allowing a truly multi-class auditory approach. In Aim 2, I propose to implement the auditory interface into the realtime xPC used for visual presentation in clinical trial participants with intracortical BCIs, and test their performance on the cued target-acquisition task. Although much success has been demonstrated in this task using visual feedback, this auditory approach will permit BCI use by people with visual impairments further compounding their paralysis. Finally in Aim 3, I will test the feasibility of BrainGate BCI users to utilize an auditory BCI speller to perform a copy-typing task and free- typing task.  The accomplishment of the goals of this research will be a critical step towards enabling severely paralyzed individuals with visual impairments to re-establish communication independently, continuously and reliably. Project Narrative Brain-computer interfaces enable motor-impaired individuals to communicate using an effector such as a neural cursor or a robotic arm. The successful completion of the proposed project will develop a unique technology that enables a real-time auditory-reliant BCI for communication in severely paralyzed individuals resulting from stroke, amyotrophic lateral sclerosis and severe brain injuries. Study results will advance our knowledge of developing neurotechnologies that leverage non-visual sensory modalities, as well as provide much insight into the cortical neural activities that underpin motor intention and movement.",Auditory brain-computer interface for communication,9851289,F32MH118709,"['Adult', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Auditory', 'Auditory system', 'Base of the Brain', 'Brain Injuries', 'Brain Stem Infarctions', 'Clinical Trials', 'Communication', 'Computers', 'Cues', 'Data', 'Development', 'Devices', 'Eye Movements', 'Family Caregiver', 'Fatigue', 'Feedback', 'Frequencies', 'Functional disorder', 'Future Generations', 'Goals', 'Hearing Tests', 'Human', 'Impairment', 'Individual', 'Infrastructure', 'Institution', 'Intention', 'Joystick', 'Knowledge', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Manuals', 'Measures', 'Modality', 'Motor', 'Movement', 'Mus', 'Neurologic', 'Ophthalmopareses', 'Paralysed', 'Participant', 'Pathologic Nystagmus', 'Pathway interactions', 'Patients', 'Performance', 'Positioning Attribute', 'Psyche structure', 'Quadriplegia', 'Quality of life', 'Research', 'Resources', 'Robotics', 'Sensory', 'Signal Transduction', 'Social Interaction', 'Sound Localization', 'Speech', 'Spinal cord injury', 'Stroke', 'System', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Traumatic Brain Injury', 'Universities', 'User-Computer Interface', 'Vision', 'Visual', 'Visual Fields', 'Visual impairment', 'Workload', 'Writing', 'arm', 'auditory feedback', 'base', 'brain computer interface', 'clinical trial participant', 'engineering design', 'improved', 'insight', 'motor impairment', 'neurotechnology', 'neurotransmission', 'novel', 'oculomotor', 'relating to nervous system', 'speech synthesis', 'spelling', 'success', 'usability', 'virtual', 'visual feedback', 'way finding']",NIMH,BROWN UNIVERSITY,F32,2020,74810,0.10949896474895009
"The Nanoscale Connectome of the Cochlear Nucleus The cochlear nucleus is the gateway for central nervous system processing of auditory information in mammals. It has been proposed that parallel processing channels are set up in the CN, and these form the basis for further computation at higher stations of the auditory system. Despite decades of study, enumeration of CN cell types is incomplete and CN circuitry is described only superficially. In neuroscience generally, classification and naming of neurons has relied primarily upon qualitative approaches based upon human observational capabilities. We have implemented and in some cases developed novel high-throughput and unbiased techniques for labeling, segmenting and classifying neurons in 3D, generated from large-scale electron microscopy image volumes. We propose to deliver a nanoscale map, or connectome, of the mouse CN with enumerated and localized cell types and their synaptic connections. This effort is unbiased because all neurons will be sampled. To achieve this goal, we bring together four parallel modes of tissue analysis for neuron classification: morphology, connectivity, molecular identity and function. We propose that connectivity analysis will define long-proposed parallel processing circuits that will be tested functionally using realistic biophysical models of identified cell types. Notably, the cochlear nucleus contains both amorphous and layered organizations of cells, which serve as templates for all other brain regions. By investigating the fundamental structure of this sensory center, we will establish principles of neural computation and methods for structural and functional phenotyping that will apply to other brain regions regardless of their particular neural architecture. Relevance to Public Health The goal of this project is to deliver to the auditory research community the connectome of the mouse cochlear nucleus. In the process we will refine and develop comprehensive and high throughput methods to catalogue cell types and their connections in any brain region, and will provide molecular phenotypes for cochlear nucleus cell types that may be useful in their targeted manipulation for research and therapeutic purposes. This work forms a basis to study central alterations following noise- induced hearing loss or other cochlear pathology, and gain deeper understanding of all auditory structures from brainstem to cortex.",The Nanoscale Connectome of the Cochlear Nucleus,9898347,R01DC015901,"['3-Dimensional', 'Acoustic Nerve', 'Acoustics', 'Adult', 'Architecture', 'Auditory', 'Auditory system', 'Automobile Driving', 'Axon', 'Biophysics', 'Birds', 'Brain Stem', 'Brain region', 'CNS processing', 'Catalogs', 'Cell model', 'Cells', 'Cellular Structures', 'Censuses', 'Classification', 'Cochlea', 'Cochlear nucleus', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Electron Microscopy', 'Experimental Designs', 'Frequencies', 'Future', 'Gene Expression', 'Genetic', 'Goals', 'Graph', 'Hearing', 'Hearing problem', 'Human', 'Image', 'Knowledge', 'Label', 'Learning', 'Link', 'Location', 'Mammals', 'Maps', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Names', 'Nerve', 'Nerve Fibers', 'Neurons', 'Neurosciences', 'Noise-Induced Hearing Loss', 'Octopus', 'Pathology', 'Pattern', 'Peripheral', 'Phenotype', 'Process', 'Public Health', 'Research', 'Resolution', 'Sampling', 'Scanning Electron Microscopy', 'Sensory', 'Shapes', 'Skeleton', 'Specific qualifier value', 'Standardization', 'Structure', 'Supervision', 'Synapses', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Tissues', 'Work', 'afferent nerve', 'auditory processing', 'automated segmentation', 'base', 'biophysical model', 'cell type', 'cellular targeting', 'connectome', 'experimental study', 'fluorescence imaging', 'granule cell', 'health goals', 'human error', 'in silico', 'microscopic imaging', 'molecular phenotype', 'molecular scale', 'nanoscale', 'nerve supply', 'neural circuit', 'neural model', 'novel', 'parallel processing', 'prevent', 'programs', 'recombinase', 'relating to nervous system', 'sensory system', 'sound', 'tool', 'transcription factor', 'unsupervised learning', 'virtual reality']",NIDCD,UNIVERSITY OF SOUTH FLORIDA,R01,2020,620597,0.06861889480170472
