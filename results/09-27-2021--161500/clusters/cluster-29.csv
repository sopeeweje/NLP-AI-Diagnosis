text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"MRI and machine learning to improve early prognosis and clinical management after spinal cord injury PROJECT SUMMARY/ABSTRACT Purpose/Hypothesis: Spinal cord injury (SCI) causes substantial social, economic, and health burden.1 For individuals with motor incomplete SCI, some basic ability to stand or walk is expected during the recovery process,2 and this is a top priority in rehabilitative programs.3 However, establishing a prognosis for recovering community walking ability is extremely difficult.4 Within 72 hours after SCI,5 edema develops within the damaged spinal cord. This edema is a hallmark of spinal cord injury, expressed as signal hyperintensity using T2 magnetic resonance imaging (MRI).6 Correlations between the sagittal length of this spinal cord edema and walking ability are generally poor.7,8 However, advanced but available high resolution axial T2-weighted MRI to quantify spinal cord edema in people in the acute stage of SCI may improve prediction of walking ability.9,10 The early clinical management and targeted rehabilitation of these individuals could be drastically enhanced, optimizing recovery and rehabilitation outcomes. The main objective of this research project is to use early axial spinal cord MRI sequences as neuroprognostic biomarkers to improve the prediction of residual motor function. This objective will be realized by the implementing the following specific aims: Aim 1: To establish to what extent the axial damage ratio biomarker, measured by high-resolution axial T2-weighted structural imaging, can predict residual function in persons with SCI. Previously-collected axial T2-weighted spinal cord structural MRI data of 200 people with SCI from the US Model SCI System at Craig Hospital will be used to quantify cord damage. This metric will be related to the primary 1-year status-post injury outcome measures, which are clinical records of walking ability and function. Multivariate statistical analyses will be applied to create exploratory models to determine the prognostic value of the MRI measures. We hypothesize that the axial damage ratio can be used in the acute stage as an accurate and objective neuroprognostic biomarker of residual motor function. Aim 2: To identify the relationship between damage to specific spinal cord regions and specific motor and sensory deficits. MRI data from Aim 1 will be used. Spinal cord regional damage analysis will be related to right and left upper and lower extremity motor and sensory scores. Correlational statistical analyses will be applied to analyze relationships between specific tract damage and motor/sensory deficits. We hypothesize that damage to descending lateral corticospinal motor regions is related to ipsilesional motor deficits, and that similar findings exist for ascending sensory regions and sensory deficits. For both Aims, we will compare our manual damage quantification to our machine learning approach to automatically detect spinal cord damage. Aim 3: Develop, test, and distribute a machine-learning based analysis pipeline for spinal cord damage measures. We will use functions included in the Spinal Cord Toolbox and the open-source NiftyNet deep-learning platform to develop the machine-learning based analysis pipeline. The processing steps will include spinal cord detection, spinal cord damage segmentation, registration to the spinal cord template, and the calculation and output of the axial damage ratio and regional damage biomarkers. Significance: Successful completion of these Aims will advance the NIH/NICHD NCMRR aim: “to enhance the health, productivity, independence, and quality of life of people with physical disabilities.” The significance of this outcome relates directly to improving the clinical management of SCI. This research may inform clinicians, patients, and families, regarding the percentage chance of regaining walking ability. The healthcare team will be able to determine, early-on, which people will optimally respond to locomotor training. This work will significantly improve the prognosis for recovery of walking and specific motor/sensory function based on early imaging of the damaged spinal cord. PROJECT NARRATIVE The purpose of this research project is to use early axial MRI measures of spinal cord damage as objective biomarkers to improve the prediction of walking recovery and specific motor return of individuals following SCI. This research will provide patients with a quantified sense of expectations regarding their chances of walking recovery, and will help guide the healthcare team on the best options for clinical management and rehabilitation (i.e. focusing on neuroplasticity and restoration of walking versus compensatory strategies). Ultimately, this research aims to improve the lives and wellbeing of those suffering from spinal cord injury. Successful completion of this research will advance the NIH/NICHD NCMRR aim: “to enhance the health, productivity, independence, and quality of life of people with physical disabilities.” ! 1!",MRI and machine learning to improve early prognosis and clinical management after spinal cord injury,9674165,R03HD094577,"['Acute', 'Biological Markers', 'Biological Models', 'Chronic', 'Classification', 'Clinical', 'Clinical Management', 'Communities', 'Correlation Studies', 'Corticospinal Tracts', 'Data', 'Data Set', 'Detection', 'Development', 'Economics', 'Edema', 'Event', 'Family', 'Foundations', 'Future', 'Health', 'Health Care Costs', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Individual', 'Injury', 'International', 'Investigation', 'Lateral', 'Left', 'Length', 'Life Expectancy', 'Linear Regressions', 'Link', 'Location', 'Locomotor training', 'Lower Extremity', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Medical Care Team', 'Modeling', 'Motor', 'Motor output', 'National Institute of Child Health and Human Development', 'Neurologic', 'Neuronal Plasticity', 'Outcome', 'Outcome Measure', 'Output', 'Participant', 'Patients', 'Personal Satisfaction', 'Persons', 'Physical Function', 'Physically Handicapped', 'Probability', 'Process', 'Productivity', 'Prognostic Marker', 'Quality of life', 'Records', 'Recovery', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Residual state', 'Resolution', 'Retrospective Studies', 'Rogaine', 'Sensory', 'Signal Transduction', 'Spinal Cord', 'Spinal cord damage', 'Spinal cord injury', 'Statistical Data Interpretation', 'Structure', 'System', 'T2 weighted imaging', 'Testing', 'United States', 'United States National Institutes of Health', 'Upper Extremity', 'Walking', 'Work', 'analysis pipeline', 'base', 'deep learning', 'design', 'dorsal column', 'early detection biomarkers', 'expectation', 'functional independence', 'imaging Segmentation', 'improved', 'learning strategy', 'magnetic resonance imaging biomarker', 'motor deficit', 'motor function recovery', 'motor recovery', 'novel', 'open source', 'outcome forecast', 'primary outcome', 'prognostic value', 'programs', 'prospective', 'rehabilitation strategy', 'restoration', 'secondary outcome', 'social', 'spinal cord imaging']",NICHD,REGIS UNIVERSITY,R03,2019,96034,0.021961144529046277
"Ethical Considerations for Language Modeling within Brain-Computer Interfaces Project Summary Machine learning (ML) and Natural Language Processing (NLP) have the potential to transform communication for patients with neurodegenerative disease through personalized and real-time augmentative and alternative communication (AAC) devices. Individuals with severe communication impairments who can no longer control their daily conversations or participate in previous life roles want AAC devices. And they want them to work – to be reliable, effective, and fast. ML and NLP are emerging as promising tools to bridge current technology and next generation devices for individuals with the most severe speech and physical impairments, like the RSVP Keyboard™, a brain-computer interface (BCI) being developed by the parent grant. BCI systems for communication are referred to as AAC-BCIs. NLP efforts to combine large public data sets with private data sets, such as personal email messages, promise to give individuals with communication impairments their own personalized language models, models that are sufficiently robust to get closer to real-time communication. The focus on getting AAC-BCIs to work with machine learning, however, has led to a critical oversight in the field: an inadequate understanding of why individuals want next-generation devices and what trade-offs they are willing to make for faster and more personalized communication. The turn to ML brings this oversight into sharp relief. Individuals should provide input about the data sets used to construct their personal language models, but this raises important ethical questions about what individuals value, how they understand their identity, and what trade-offs they are willing to make relative to their personalized communication data. The goal of this supplement is to fill this gap in understanding so that researchers can implement ML into next generation AAC-BCI systems in a way that is sensitive to the ethical concerns of future users. There are four components to this ethics supplement: (1) to design a toolbox of ethics vignettes tailored to ethical concerns raised by both BCI communication and ML; (2) to administer monthly vignette-based online ethics surveys to individuals with severe communication impairments due to motor neuron disease (e.g., ALS) (n=25) or movement disorders (e.g., Parkinson's disease) (n=25); (3) to conduct semi-structured vignette-based interviews with individuals with pre- clinical or mild communication impairment due to motor neuron disease (n=10) or movement disorder (n=10). Components (2) and (3) will employ an iterative, parallel mixed-method approach. Trends in Likert-style online responses to ethics vignettes in the severe communication impairment cohort will be used to inform and modify the semi-structured interview prompts asked of the pre-clinical or mild impairment cohort. In parallel, themes emerging from direct content analysis of interviews will be used to refine online survey questions. Results of this iterative, mix-methods approach will be used (4) to outline a framework of core ethical domains and preliminary tools (vignettes and discussion prompts) that AAC-BCI researchers can use to assess ethical concerns while developing and iteratively refining communication technology for personalized language models. Project Narrative The populations of US citizens with severe speech and physical impairments secondary to neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies. Bioethical issues about privacy, agency and identity must be included in technology development and implementation as the parent grant implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Ethical Considerations for Language Modeling within Brain-Computer Interfaces,9929337,R01DC009834,"['Address', 'Administrative Supplement', 'Affect', 'Attention', 'Attitude', 'Augmentative and Alternative Communication', 'Award', 'Bioethical Issues', 'Bioethics', 'Clinical', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Development', 'Devices', 'Disease', 'Electroencephalography', 'Electronic Mail', 'Encapsulated', 'Engineering', 'Ensure', 'Ethical Analysis', 'Ethical Issues', 'Ethics', 'Foundations', 'Future', 'Goals', 'Home environment', 'Impairment', 'Individual', 'Informed Consent', 'Interview', 'Language', 'Letters', 'Life', 'Link', 'Literature', 'Locked-In Syndrome', 'Machine Learning', 'Medical', 'Medical Technology', 'Methods', 'Modeling', 'Monkeys', 'Motor Neuron Disease', 'Movement', 'Movement Disorders', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Oregon', 'Outcome', 'Parents', 'Parkinson Disease', 'Participant', 'Patient advocacy', 'Patients', 'Population', 'Privacy', 'Privatization', 'Public Health', 'Reporting', 'Research Personnel', 'Review Literature', 'Role', 'Secondary to', 'Self-Help Devices', 'Source', 'Speech', 'Structure', 'Surveys', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Voice', 'Work', 'advocacy organizations', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'cohort', 'communication device', 'computer science', 'design', 'expectation', 'informant', 'neurophysiology', 'next generation', 'novel', 'parent grant', 'pre-clinical', 'recruit', 'research and development', 'response', 'signal processing', 'skills', 'spelling', 'technology development', 'technology validation', 'tool', 'trend', 'uptake']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,153834,-0.01300128383316441
"Machine-learning based control of functional electrical stimulation PROJECT SUMMARY/ABSTRACT Functional electrical stimulation involves artificial activation of paralyzed muscles with implanted electrodes and has been used successfully to improve the ability of tetraplegics to perform movements important for daily activities. The range of motor behaviors that can be generated by functional electrical stimulation, however, is limited to a relatively small set of preprogrammed movements such as hand grasp and release. A broader range of movements has not been implemented because of the substantial challenge associated with identifying the patterns of muscle stimulation needed to elicit specified movements. To address this limitation, we have developed machine-learning based algorithms that can predict patterns of muscle activity associated with a wide range of complex limb movements. In addition, we have devised a method whereby predicted patterns of muscle activity can then be transformed into stimulus pulse patterns needed to evoke movements in paralyzed limbs. Our goal for this project is to determine whether these approaches, when applied to temporarily paralyzed non-human primates, can be used to produce: 1) a wide range of movements of the hand throughout peri-personal reach space, and 2) configuration of the hand and fingers into a variety of shapes needed to interact with diverse objects in the environment. If successful, this approach would greatly expand the repertoire of motor behaviors available to individuals paralyzed because of spinal cord injury or stroke. Furthermore, this system ultimately might serve as the requisite interface between brain-derived trajectory information and functional electrical stimulation systems needed to realize a self-contained and self- controlled upper limb neuroprosthetic. PROJECT NARRATIVE The goal of this project is to develop methods to artificially activate and control paralyzed muscles with electrodes implanted in muscles. This effort will contribute to the restoration of voluntary limb movements in individuals paralyzed because of spinal cord injury or stroke.",Machine-learning based control of functional electrical stimulation,9699018,R01NS102259,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Animals', 'Back', 'Behavior', 'Brain', 'Chronic', 'Complement', 'Complex', 'Data', 'Digit structure', 'Elbow', 'Electrodes', 'Elements', 'Environment', 'Error Sources', 'Experimental Models', 'Feedback', 'Fingers', 'Forearm', 'Goals', 'Hand', 'Health Benefit', 'Human', 'Implanted Electrodes', 'Individual', 'Intramuscular', 'Joints', 'Lifting', 'Limb structure', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Motor', 'Movement', 'Muscle', 'Muscle Contraction', 'Muscle Fatigue', 'Output', 'Paralysed', 'Patients', 'Pattern', 'Personal Space', 'Physiologic pulse', 'Quadriplegia', 'Shapes', 'Shoulder', 'Signal Transduction', 'Skeletal Muscle', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Training', 'Upper Extremity', 'Wrist', 'arm', 'artificial neural network', 'awake', 'base', 'brain machine interface', 'design', 'experience', 'finger movement', 'functional electrical stimulation', 'grasp', 'hand grasp', 'human subject', 'improved', 'insight', 'kinematics', 'limb movement', 'machine learning algorithm', 'neuroprosthesis', 'nonhuman primate', 'response', 'restoration', 'robotic device', 'scapula']",NINDS,UNIVERSITY OF ARIZONA,R01,2019,329650,0.02230006072403384
"User-driven Retrospectively Supervised Classification Updating (RESCU) systemfor robust upper limb prosthesis control ABSTRACT Approximately 41,000 individuals live with upper-limb loss (loss of at least one hand) in the US. Fortunately, prosthetic devices have advanced considerably in the past decades with the development of dexterous, anthropomorphic hands. However, potentially the most promising used control strategy, myoelectric control, lacks a correspondingly high-level of performance and hence the use of dexterous hands remains highly limited. The need for a complete overhaul in upper limb prosthesis control is well highlighted by the abandonment rates of myoelectric devices, which can reach up to 40% in the case of trans-humeral amputees. The area of research that has received the most focus over the past decade has been “pattern recognition,” which is a signal processing based control method that uses multi-channel surface electromyography as the control input. While pattern recognition provides intuitive operation of multiple prosthetic degrees of freedom, it lacks robustness and requires frequent, often daily calibration. Thus, it has not yet achieved the desired clinical acceptance. Our team proposes clinical translation of a novel highly adaptive upper limb prosthesis control system that incorporates two major advances: 1) machine learning (robust classification by implementing a non-boundary based algorithm), and 2) training by retrospectively incorporating user data from activities of daily living (ADL). The proposed system will enable machine intelligence with user input for prosthesis control. Our work is organized as follows: Phase I: (a) First, we will implement a fundamentally new machine intelligence technique, Extreme Learning Machine with Adaptive Sparse Representation Classification (EASRC), that is more resilient to untrained noisy conditions that users may encounter in the real-world and requires less data than traditional myoelectric signal processing. (b) In parallel, we will implement an adaptive learning algorithm, Nessa, which allows users to relabel misclassified data recorded during use and then update the EASRC classifier to adapt to any major extrinsic or intrinsic changes in the signals. Taken together, EASRC and Nessa comprise the Retrospectively Supervised Classification Updating (RESCU) system. Once, the RESCU implementation is complete, we will optimize the system through a joint effort with Johns Hopkins University, and complete an iterative benchtop RESCU evaluation with a focus group of 3 amputee subjects and their prosthetists. Our milestones for Phase I are as follows:  Milestone 1.1: Extreme Learning Machine with Adaptively Sparse Representation (EASRC) algorithm  successfully implemented and verified  Milestone 1.2: Implementation of Nessa adaptive learning algorithm and smartwatch interface  Milestone 1.3: User Needs and Design Inputs locked as a result of Focus Group testing  Milestone 1.4: Hold a pre-submission meeting with FDA for feedback on device classification and  planned product performance testing  Milestone 1.5: Hold a Scientific Steering Group (SSG) meeting  Milestone 1.6: Convene a Study Monitoring Committee (SMC) and hold an initial meeting to review  clinical plans.  Milestone 1.7: Develop Clinical Study Protocol  Milestone 1.8: Register the study on www.clinicaltrials.gov. PROJECT NARRATIVE In this project, we aim to empower the user by bringing them into the control loop of their prosthesis and improve the stability of their control strategy over time. Specifically, we implement to a robust classifier, an adaptive learning algorithm, and a smartwatch interface, which allows the user to teach their device when it misunderstands the commands that the user is sending to control the prosthesis. This will result in improved control without cumbersome or time-consuming effort on the part of the user and, more importantly, we hope that it will give the user a greater sense of empowerment and ownership over their prosthesis.",User-driven Retrospectively Supervised Classification Updating (RESCU) systemfor robust upper limb prosthesis control,9779227,U44NS108894,"['Activities of Daily Living', 'Algorithms', 'Amputees', 'Area', 'Artificial Intelligence', 'Calibration', 'Classification', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Development', 'Devices', 'Electromyography', 'Evaluation', 'Feedback', 'Focus Groups', 'Freedom', 'Group Meetings', 'Hand', 'Individual', 'Intuition', 'Joints', 'Machine Learning', 'Methods', 'Monitor', 'Ownership', 'Pattern Recognition', 'Performance', 'Phase', 'Prosthesis', 'Protocols documentation', 'Research', 'Signal Transduction', 'Supervision', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'Upper Extremity', 'Work', 'adaptive learning', 'base', 'clinical translation', 'design', 'empowerment', 'improved', 'learning algorithm', 'meetings', 'myoelectric control', 'novel', 'operation', 'performance tests', 'prosthesis control', 'signal processing', 'smart watch']",NINDS,"INFINITE BIOMEDICAL TECHNOLOGIES, LLC",U44,2019,79250,0.027531767519598883
"Human and Machine Learning for Customized Control of Assistive Robots PROJECT SUMMARY This application will result in a technological platform that re-empowers persons with severe paralysis, by allowing them to independently control a wide spectrum of robotic actions. Severe paralysis is devastating, and chronic—and reliance on caregivers is persistent. Assistive machines such as wheelchairs and robotic arms offer a groundbreaking path to independence: where control over their environment and interactions is returned to the person.  However, to operate complex machines like robotic arms and hands typically poses a difﬁcult learning challenge and requires complex control signals—and the commercial control interfaces accessible to persons with severe paralysis (e.g. sip-and-puff, switch-based head arrays) are not adequate. As a result, assistive robotic arms remain largely inaccessible to those with severe paralysis—arguably the population who would beneﬁt from them most.  The purpose of the proposed study is to provide people with tetraplegia with the means to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. Control interfaces that generate a unique map from a user's body motions to control signals for a machine offer a customized interaction, however these interfaces have only been used to issue low-dimensional (2-D) control signals whereas more complex machines require higher-dimensional (e.g. 6-D) signals. We propose an approach that leverages robotics autonomy and machine learning in order to aid the end-user in learning how to issue effective higher-dimensional control signals through body motions. Speciﬁcally, initially the human issues a lower- dimensional control signal and robotics autonomy is used to bridge the gap by taking over whatever is not covered by the human's control signal. Help from the robotics autonomy is then progressively scaled back, automatically, to cover fewer and fewer control dimensions as the user becomes more skilled.  The ﬁrst piece to our approach deals with how to extract control signals from the human, using the body-machine interface. The development and optimization of decoding procedures for controlling a robotic arm using residual body motions will be addressed under Speciﬁc Aim 1. The second piece to our approach deals with how to interpret control signals from a human within a paradigm that shares control between the human and robotics autonomy. To identify which shared-control formulations most effectively utilize the human's control signals will be the topic of Speciﬁc Aim 2. The ﬁnal piece to our approach deals with how to adapt the shared-control paradigm so that more control is transferred to the human over time. This adaptation is necessary for the human's learning process, since the goal in the end is for the human to be able to fully control the robotic arm him/herself, and will be assessed under Speciﬁc Aim 3.  At the completion of this project, tetraplegic end-users will be able to operate a robotic arm using their residual body motions, through an interface that both promotes the use of residual body motions (and thus also recovery of motor skill) and adapts with the human as their abilities change over time. By leveraging adaptive robotics autonomy, our application moreover provides a safe mechanism to facilitate learning how to operate the robotic platform. Frequently the more severe a person's motor impairment, the less able they are to operate the very assistive machines, like powered wheelchairs and robotic arms, which might enhance their quality of life. The purpose of the proposed study is to provide people with tetraplegia with the means, through non-invasive technologies, to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. We propose and study an approach that leverages robot machine learning and autonomy in order to facilitate human motor learning of how to operate a robotic arm using a customized interface, in order to make powered assisted manipulation more accessible to people with severe paralysis. 1",Human and Machine Learning for Customized Control of Assistive Robots,9773039,R01EB024058,"['3-Dimensional', 'Activities of Daily Living', 'Address', 'Affect', 'Algorithms', 'Back', 'Caregivers', 'Cerebral Palsy', 'Chronic', 'Complex', 'Computers', 'Custom', 'Data', 'Development', 'Devices', 'Dimensions', 'Eating', 'Effectiveness', 'Environment', 'Exercise', 'Formulation', 'Fostering', 'Freedom', 'Future', 'Goals', 'Hand', 'Head', 'Health Benefit', 'Human', 'Learning', 'Left', 'Limb structure', 'Machine Learning', 'Maintenance', 'Maps', 'Mental Depression', 'Mental Health', 'Motion', 'Motivation', 'Motor', 'Motor Skills', 'Movement', 'Multiple Sclerosis', 'Neurologic', 'Paralysed', 'Patients', 'Performance', 'Persons', 'Population', 'Posture', 'Powered wheelchair', 'Procedures', 'Process', 'Quadriplegia', 'Quality of life', 'Rehabilitation therapy', 'Residual state', 'Robot', 'Robotics', 'Self-Help Devices', 'Shoulder', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Spinal cord injured survivor', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Wheelchairs', 'Work', 'arm', 'assistive robot', 'base', 'body-machine interface', 'brain machine interface', 'empowerment', 'feeding', 'high dimensionality', 'improved', 'machine learning algorithm', 'motor impairment', 'motor learning', 'motor recovery', 'n-dimensional', 'novel strategies', 'physical conditioning', 'psychologic', 'robot control', 'sensor', 'two-dimensional']",NIBIB,REHABILITATION INSTITUTE OF CHICAGO D/B/A SHIRLEY RYAN ABILITYLAB,R01,2019,329494,0.012165947452235664
"User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control ABSTRACT Approximately 41,000 individuals live with upper-limb loss (loss of at least one hand) in the US. Fortunately, prosthetic devices have advanced considerably in the past decades with the development of dexterous, anthropomorphic hands. However, potentially the most promising used control strategy, myoelectric control, lacks a correspondingly high-level of performance and hence the use of dexterous hands remains highly limited. The need for a complete overhaul in upper limb prosthesis control is well highlighted by the abandonment rates of myoelectric devices, which can reach up to 40% in the case of trans-humeral amputees. The area of research that has received the most focus over the past decade has been “pattern recognition,” which is a signal processing based control method that uses multi-channel surface electromyography as the control input. While pattern recognition provides intuitive operation of multiple prosthetic degrees of freedom, it lacks robustness and requires frequent, often daily calibration. Thus, it has not yet achieved the desired clinical acceptance. Our team proposes clinical translation of a novel highly adaptive upper limb prosthesis control system that incorporates two major advances: 1) machine learning (robust classification by implementing a non-boundary based algorithm), and 2) training by retrospectively incorporating user data from activities of daily living (ADL). The proposed system will enable machine intelligence with user input for prosthesis control. Our work is organized as follows: Phase I: (a) First, we will implement a fundamentally new machine intelligence technique, Extreme Learning Machine with Adaptive Sparse Representation Classification (EASRC), that is more resilient to untrained noisy conditions that users may encounter in the real-world and requires less data than traditional myoelectric signal processing. (b) In parallel, we will implement an adaptive learning algorithm, Nessa, which allows users to relabel misclassified data recorded during use and then update the EASRC classifier to adapt to any major extrinsic or intrinsic changes in the signals. Taken together, EASRC and Nessa comprise the Retrospectively Supervised Classification Updating (RESCU) system. Once, the RESCU implementation is complete, we will optimize the system through a joint effort with Johns Hopkins University, and complete an iterative benchtop RESCU evaluation with a focus group of 3 amputee subjects and their prosthetists. Phase II: Verification and validation of RESCU will be completed, culminating in third-party validation testing and certification. Finally, we will complete a clinical assessment including self-reporting subjective measures, and real-world usage metrics in a long-term clinical study. PROJECT NARRATIVE In this project, we aim to empower the user by bringing them into the control loop of their prosthesis and improve the stability of their control strategy over time. Specifically, we implement to a robust classifier, an adaptive learning algorithm, and a smartwatch interface, which allows the user to teach their device when it misunderstands the commands that the user is sending to control the prosthesis. This will result in improved control without cumbersome or time-consuming effort on the part of the user and, more importantly, we hope that it will give the user a greater sense of empowerment and ownership over their prosthesis.",User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control,10013405,U44NS108894,"['Activities of Daily Living', 'Adoption', 'Algorithms', 'Amputees', 'Area', 'Artificial Intelligence', 'Calibration', 'Certification', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Communication', 'Consumption', 'Data', 'Development', 'Devices', 'Electromyography', 'Evaluation', 'Focus Groups', 'Freedom', 'Goals', 'Hand', 'Individual', 'Intuition', 'Joints', 'Label', 'Limb Prosthesis', 'Machine Learning', 'Measures', 'Methods', 'Outcome', 'Ownership', 'Patient Self-Report', 'Pattern Recognition', 'Performance', 'Phase', 'Prosthesis', 'Research', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Supervision', 'Surface', 'Surveys', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'Upper Extremity', 'Validation', 'Work', 'adaptive learning', 'base', 'clinical translation', 'empowerment', 'functional improvement', 'improved', 'innovation', 'learning algorithm', 'myoelectric control', 'novel', 'operation', 'programs', 'prospective', 'prosthesis control', 'satisfaction', 'signal processing', 'smart watch', 'verification and validation']",NINDS,"INFINITE BIOMEDICAL TECHNOLOGIES, LLC",U44,2019,735600,0.026917327541462074
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user's location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user's location by recognizing standard informational signs present in the environment, tracking the user's trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9934891,R01EY029033,"['Adoption', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Environment', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Medical center', 'Process', 'Research', 'Schools', 'System', 'Tactile', 'Time', 'Travel', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'interest', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,105337,0.0057228543458006645
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9663319,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,416374,0.0057228543458006645
"Improved AD/ADRD Assessment Sensitivities Using a Novel In-Situ Sensor System Project Summary/Abstract  Accurate assessment of daily functions for individuals at risk for and with AD/ADRD, is fundamental to detection, diagnosis, and characterization of its progression and prescribed treatments. Current assessment techniques typically rely on non- continuous, discreet observations provided from a third party and covering single or limited performance domains. With significantly larger portions of American’s choosing to age in place, any assessment technology must be able to be in-situ (low-cost, ubiquitous) and operate without user interface (autonomous) to provide objective, cross-domain, and continuous daily function measurements and reporting.  The primary objective of this fast track SBIR project is to demonstrate the feasibility and effectiveness of using the Birkeland Current Sovrin IoT system to continuously and accurately assess daily functions, ADLs, and IADLs, for persons experiencing cognitive decline in a home or assisted care settings. This includes direct comparison with an accepted assessment technique, ADCS-ADL/23. Machine learning and artificial intelligent techniques will be employed to identify novel subfactors for improved sensitivities from available sensor data combinations. Secondary objectives include establishing a significant data set of detailed daily actions (<10 sec resolution) for 100+ individuals with AD/ADRD. Long-term goals support future intervention studies through improved assessment tools with enhanced sensitivity to early and mid-stage decline.  The Birkeland Current Sovrin IoT system makes use of patented proximity-based energy monitoring and control sensors, data analytics and change detection algorithms to continuously monitor activities of individuals in a home or assisted care environment. Intelligent power-strips and battery-based sensors located throughout the home or facility, monitor real time absolute location of individuals, caregivers, and devices they interact with. Correlation of high-fidelity data allows accurate determination of activities, attribution to a specific individual, mobility measurement, and behavior assessment across traditional and novel ADL/IADL categories. Birkeland Current is teamed with Texas A&M Center for Population Health and Aging, Georgia, Tech Institute for People and Technology, Baylor Scott and White Division of Gerontology, and multiple home-care and assisted-care facilities, in the development of the study approach, implementation plan, analytics tools, and applications to aging populations and future intervention studies. Project Narrative  The proposed research would utilize novel, ubiquitous Internet-of-Things sensors and automated analytics to demonstrate enhanced sensitivity and future utility of continuous in-situ IADL/ADL data for dementia research and its effectiveness in characterizing interventions for Alzheimer’s and related dementias of aging populations in support of NIA stated priorities.",Improved AD/ADRD Assessment Sensitivities Using a Novel In-Situ Sensor System,9846881,R44AG065118,"['Address', 'Adoption', 'Aging', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'American', 'Artificial Intelligence', 'Assessment tool', 'Behavior assessment', 'Behavioral Symptoms', 'Caregivers', 'Caring', 'Categories', 'Centers for Population Health', 'Classification', 'Communities', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Dementia', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Early Diagnosis', 'Early identification', 'Effectiveness', 'Environment', 'Future', 'Gerontology', 'Goals', 'Grouping', 'Health care facility', 'Home environment', 'Impaired cognition', 'In Situ', 'Individual', 'Industry', 'Institutes', 'Intelligence', 'Internet of Things', 'Intervention', 'Intervention Studies', 'Legal patent', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Monitor', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Problem Solving', 'Protocols documentation', 'Publishing', 'Recommendation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Risk', 'Series', 'Small Business Innovation Research Grant', 'System', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Texas', 'Time', 'Training', 'United States National Institutes of Health', 'Use Effectiveness', 'aging in place', 'aging population', 'analytical tool', 'base', 'cost', 'daily functioning', 'data acquisition', 'data integration', 'database structure', 'design', 'experience', 'improved', 'insight', 'instrumental activity of daily living', 'learning algorithm', 'novel', 'off-patent', 'patient home care', 'personalized care', 'real time monitoring', 'sensor', 'symposium', 'tool']",NIA,BIRKELAND CURRENT LLC,R44,2019,350000,-0.010115058097635144
"SCH: Multimodal,Task-Aware Movement Assessment and Control: Clinic to Home We propose to develop a novel, distributed sensor platform that continuously assesses movement in the background of one's life with the goal of helping people age in place and avoid expensive and lengthy hospitalizations. On the one hand, the platform will combine measurements from a heterogeneous and  complementary set of inertial, physiological , and vision sensors with state-of-the-art techniques from robotics and machine learning, together with clinically informed dynamic models of human motion. On the other hand, the platform will use these data to target the prompt detection of the mobility deficits that often precipitate the onset of frailty, with the goal of facilitating personalized caregiver alerts if a decline in functional status is detected. Moreover, the platform will provide context-aware control inputs to facilitate unconstrained use of powered assistive technologies in the home. This project has three main thrusts: assessment, control, and home intervention. In the assessment component, our work will extend well-proven techniques of multi-modal sensor fusion for mapping and localization of robots to home-based movement monitoring and intervention. The novelty of this work lies in the tight integration of machine learning modules for real-time activity recognition and movement dysfunction diagnosis. In the control component, our work will push the boundaries of what is possible with current powered assistive devices by developing novel control mechanisms that take advantage of the new capabilities provided by the estimation component (e.g., adapting control to changes in activities and environmental contexts). In the home intervention component, we will collect data that will refine the sensing and control algorithms and involve caregivers in alerts. A patient-in-the-loop development approach will be utilized where domain-informed protocols will generate the data necessary to train and evaluate our system, both in the clinic and in the home. By enabling timely detection of movement dysfunction and facilitating unconstrained use of powered assistive technologies, this foundational technology has paradigm-disrupting potential to prevent the onset of frailty and alter the treatment options for frail individuals. In parallel, the estimation component of the system could be used in clinical settings to automate and standardize time-intensive and highly subjective functional movement assessments, allowing more accurate diagnoses while freeing clinicians for other important tasks. RELEVANCE (See instructions): Frail older adults constitute the sickest, most expensive, and fastest growing segment of the US population. Home-based technologies that facilitate aging in place and reduce high-cost, hospital- and institution-based interventions are desperately needed. Our proposed distributed sensor platform has the potential to address this need by enabling the timely detection of the mobility deficits that often precipitate the onset of frailty and proactive caregiver and technological interventions that can delay, or prevent, mobility loss. n/a","SCH: Multimodal,Task-Aware Movement Assessment and Control: Clinic to Home",9976771,R01AG067394,"['Address', 'Adult', 'Algorithms', 'Awareness', 'Caregivers', 'Clinic', 'Clinical', 'Communities', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Distant', 'Emerging Technologies', 'Environment', 'Evaluation', 'Event', 'Foundations', 'Frail Elderly', 'Functional disorder', 'Goals', 'Healthcare Systems', 'Home environment', 'Hospitalization', 'Hospitals', 'Impairment', 'Independent Living', 'Individual', 'Institution', 'Instruction', 'Intervention', 'Laboratories', 'Learning Module', 'Life', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Muscle', 'Patients', 'Physical activity', 'Physiological', 'Population', 'Protocols documentation', 'Robot', 'Robotics', 'Self-Help Devices', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Vision', 'Walking', 'Work', 'accurate diagnosis', 'aging in place', 'base', 'cost', 'frailty', 'functional decline', 'functional electrical stimulation', 'functional status', 'human model', 'loss of function', 'multimodality', 'neuroprosthesis', 'next generation', 'novel', 'prevent', 'recruit', 'response', 'sensor', 'technology development', 'tool', 'wearable device']",NIA,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2019,299863,0.015506700463595483
"Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time Project Summary Lower limb assistive robotic devices, such as active prosthesis, orthoses, and exoskeletons have the potential to restore function for the millions of Americans who experience mobility challenges due to injury and disability. Since individuals with mobility challenges have an increased energetic cost of transport, the benefit of such assistive devices is commonly assessed via the reduction in the metabolic work rate of the individual who is using the device. Currently, metabolic work rate can only be obtained in a laboratory environment, using breath-by-breath measurements of respiratory gas analysis. To obtain a single steady state data point of metabolic work rate, multiple minutes of data must be collected, since the signals are noisy, sparsely sampled, and dynamically delayed. In addition, the user has to wear a mask and bulky equipment, further restricting the applicability of the method on a larger scale. We propose an improved way to obtain such estimates of metabolic work rate in real-time. Aim 1 will determine salient signal features and characterize the dynamics of sensing metabolic work rate from a variety of physiological sensor signals. Aim 2 will use advanced sensor fusion and machine learning techniques to accurately predict instantaneous energy cost in real-time from multiple physiological signals without relying on a metabolic mask. Aim 3 will use the obtained real-time estimates to optimize push-off timing for an active robotic prosthesis. The resulting methods will enable an automated and continuous evaluation of assistive robotic devices that can be realized outside the laboratory and with simple wearable sensors. This automated evaluation will enable devices, such as active prostheses, orthoses, or exoskeletons, that can self-monitor their performance, optimize their own behavior, and continuously adapt to changing circumstances. This will open up a radically new way of human-robot- interaction for assistive devices. It will greatly increase their clinical viability and enable novel advanced controllers and algorithms that can improve device performance on a subject specific basis. Project Narrative A common way of evaluating assistive robotic devices, such as active prostheses or exoskeletons, is by measuring the reduction in effort that they bring to an individual walking in them. The proposed project will develop ways to perform this evaluation automatically and in real-time by the device itself, which will be used in the future to develop prostheses and exoskeletons that automatically adapt themselves to their users. This project supports the NIH's stated mission of reducing disability by improving patient outcomes with new prosthetic and orthotic devices.",Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time,9668174,R03HD092639,"['Algorithms', 'American', 'Amputation', 'Amputees', 'Ankle', 'Behavior', 'Clinical', 'Data', 'Devices', 'Electromyography', 'Energy Metabolism', 'Environment', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Heart Rate', 'Indirect Calorimetry', 'Individual', 'Injury', 'Laboratories', 'Linear Regressions', 'Lower Extremity', 'Machine Learning', 'Masks', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Noise', 'Orthotic Devices', 'Patient-Focused Outcomes', 'Performance', 'Persons', 'Physiological', 'Population', 'Prosthesis', 'Reference Values', 'Robotics', 'Sampling', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'cost', 'disability', 'exoskeleton', 'experience', 'functional restoration', 'human-robot interaction', 'improved', 'light weight', 'neural network', 'novel', 'respiratory gas', 'robotic device', 'sensor', 'wearable device']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2019,78000,0.028721549365881872
"Inferential methods for functional data from wearable devices Project Summary/Abstract This is a project to develop new statistical methods for comparing groups of subjects in terms of health outcomes that are assessed using data from wearable devices. Inexpensive wearable sensors for health monitoring are now capable of generating massive amounts of data collected longitudinally, up to months at a time. The project will develop inferential methods that can deal with the complexity of such data. A serious challenge is the presence of unmeasured time-dependent confounders (e.g., circadian and dietary patterns), making direct comparisons or borrowing strength across subjects untenable unless the studies are carried out in controlled experimental con- ditions. Generic data mining and machine learning tools have been widely used to provide predictions of health status from such data. However, such tools cannot be used for signiﬁcance testing of covariate effects, which is necessary for designing precision medicine interventions, for example, without taking the inherent model selection or the presence of the unmeasured confounders into account. To overcome these difﬁculties, a systematic de- velopment of inferential methods for functional outcome data obtained from wearable devices will be carried out. There are three speciﬁc aims: 1) Develop metrics for functional outcome data from wearable devices, 2) Develop nonparametric estimation and testing methods for activity proﬁles and a screening method for predictors of activity proﬁles, 3) Implement the methods in an R package and carry out two case studies using accelerometer data. For Aim 1, the approach is to reduce the sensor data to occupation time proﬁles (e.g., as a function of activity level), and formulate the statistical modeling in terms of these proﬁles using survival and functional data analytic meth- ods. This will have a number of advantages, the principal one being that time-dependent confounders become less problematic because the effect of differences in temporal alignment across subjects is mitigated. In addition, survival analysis methods can be applied by viewing the occupation time as a time-to-event outcome indexed by activity level. For Aim 2, nonparametric methods will be used to compare and order occupation time distributions between groups of subjects that are speciﬁed in terms of baseline covariate levels or treatment groups. Further, a new method of post-selection inference based on marginal screening for function-on-scalar regression will be developed to identify and formally test whether covariates are signiﬁcantly associated with activity proﬁles. Aim 3 will develop an R-package implementation, and as a test-bed for the proposed methods they will be applied to two Columbia-based clinical studies: to the study of physical activity in children enrolled in New York City Head Start, and to the study of experimental drugs for the treatment of mitochondrial depletion syndrome. Project Narrative The relevance of the project to public health is that it will develop statistical methods for the physiological eval- uation of patients on the basis of data collected by inexpensive wearable sensors (e.g., accelerometers). By introducing methods for the rigorous comparison of healthcare status among groups of patients observed longi- tudinally over time using such devices, treatment decisions that can beneﬁt targeted populations of patients in terms of continuously-assessed health outcomes will become possible.",Inferential methods for functional data from wearable devices,9658873,R01AG062401,"['Acceleration', 'Accelerometer', 'Beds', 'Bypass', 'Case Study', 'Characteristics', 'Child', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Dietary Practices', 'Drug Combinations', 'Enrollment', 'Evaluation', 'Event', 'Grant', 'Head Start Program', 'Health', 'Health Status', 'Healthcare', 'Intervention', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Monitor', 'Motivation', 'Nature', 'New York City', 'Obesity', 'Occupations', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmacotherapy', 'Physical activity', 'Physiological', 'Preschool Child', 'Process', 'Proxy', 'Public Health', 'Recording of previous events', 'Regimen', 'Signal Transduction', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Stochastic Processes', 'Survival Analysis', 'Syndrome', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Work', 'analytical method', 'base', 'circadian', 'data mining', 'design', 'experimental study', 'functional outcomes', 'indexing', 'interest', 'lower income families', 'novel', 'patient population', 'precision medicine', 'screening', 'sensor', 'theories', 'time use', 'tool', 'treatment group', 'wearable device']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,317858,0.0016796700429976515
"Sensor-based Just-in Time Adaptive Interventions (JITAIs) Targeting Eating Behavior PROJECT SUMMARY/ABSTRACT Long-term weight control is difficult to achieve and requires permanent changes in eating behavior. Emerging wearable sensor technology enables accurate and objective measurement of ingestive behavior, and real-time analysis of the sensor data paves the way for development of individually tailored and immediately delivered intervention (just-in-time adaptive Intervention; JITAI) to change eating behavior. Grounded in empirically and theoretically supported behavior change strategies for weight control, the proposed project relies on the synergy of wearable sensor technology, machine learning, behavioral science, personalized medicine, and nutrition to deliver and test such JITAIs. We previously developed a wearable sensor, the Automatic Ingestion Monitor (AIM), that automatically and accurately detects eating and characterizes meal microstructure (e.g., eating duration, rate of ingestion). These data can also be used to accurately estimate energy intake. The goals of this project are to: 1) use the AIM to study two common behavioral patterns observed among individuals with overweight/obesity, namely, excessive total daily energy intake (EI) and fast eating rate; 2) define the optimal personalized triggering metrics for two JITAIs targeting these behaviors; and 3) evaluate JITAIs’ effects on daily energy intake and targeted behaviors. In fulfillment of these goals, we will first conduct a study to characterize the target eating behaviors, then simulate and define triggering metrics for personalized JITAIs to change targeted eating behaviors and decrease EI. The JITAIs are rooted in self-regulation theory (SRT): setting a behavioral goal and monitoring progress toward that goal, with feedback to reinforce success. To enable the SRT-informed JITAIs, we will first use the AIM to collect data about ingestive behaviors quantified by objective, sensor-measured metrics from 90 adults with overweight/obesity who will wear the device for one week in free living conditions. Second, using the collected dataset, we will: a) analyze individual curves of cumulative daily EI and rate of eating within eating episodes to define triggering parameters for personalized JITAI delivery, and b) numerically simulate JITAI delivery and effects. We will then conduct a second study to evaluate the immediate effect of JITAIs on EI and ingestive behavior in free living participants. We will conduct a within-subjects trial with 128 adults wearing the AIM for 7 weeks. To personalize JITAIs, the AIM will learn individual eating patterns over a 1-week run-in period. Each JITAI will be delivered for two weeks (weeks 2-3 and 5-6) in a randomized crossover design with the resulting daily EI and ingestive behavior compared to baseline and the acceptability of the JITAIs assessed via questionnaire. On washout weeks 4 and 7, participants will continue to wear the AIM (no JITAIs) to assess persistence of intervention effects. The proposed project is the first step in demonstrating that AIM-based JITAIs can alter a variety of eating behaviors associated with excess EI. PROJECT NARRATIVE Achievement of changes in eating behaviors that facilitate long-term weight loss and maintenance is elusive. Emerging wearable sensor technology allows for accurate and objective measurement of ingestive behavior. Real-time analysis of the sensor data paves the way for individually tailored just-in-time adaptive interventions (JITAIs) based on empirically and theoretically supported behavior change strategies for healthy eating and weight control. The proposed project relies on synergy of wearable sensor technology, machine learning, behavioral science, personalized medicine, and nutrition to test two such JITAIs driven by the Automatic Ingestion Monitor (AIM), a device that automatically detects and characterize eating behavior in real-time. The information provided by the AIM will be used to implement and test personalized, adaptable behavioral interventions aimed at the reduction of energy intake.",Sensor-based Just-in Time Adaptive Interventions (JITAIs) Targeting Eating Behavior,9818246,R01DK122473,"['Achievement', 'Adult', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Behavioral Sciences', 'Body Weight decreased', 'Cellular Phone', 'Child', 'Crossover Design', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetes Mellitus', 'Eating', 'Eating Behavior', 'Eating Disorders', 'Elderly', 'Energy Intake', 'Feedback', 'Feeding behaviors', 'Food', 'Future', 'Goals', 'Healthy Eating', 'Image', 'Individual', 'Informal Social Control', 'Ingestion', 'Intervention', 'Learning', 'Liquid substance', 'Machine Learning', 'Mastication', 'Measurement', 'Measures', 'Monitor', 'Obesity', 'Overweight', 'Participant', 'Patient Self-Report', 'Pattern', 'Plant Roots', 'Population', 'Questionnaires', 'Randomized', 'Running', 'Sampling', 'Testing', 'Time', 'Weight', 'Weight maintenance regimen', 'Work', 'adaptive intervention', 'base', 'behavior change', 'clinical practice', 'cost', 'healthy weight', 'increased appetite', 'innovation', 'intervention effect', 'nutrition', 'personalized intervention', 'personalized medicine', 'sensor', 'simulation', 'success', 'sucking', 'synergism', 'theories', 'wearable device', 'wearable sensor technology', 'weight maintenance']",NIDDK,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R01,2019,663683,0.006838340412141487
"Device to control circadian-effective light in Alzheimer's disease environments Project Summary This proposed project will develop and field-test a device that accurately monitors and controls the circadian stimulus (CS) for Alzheimer disease (AD) and Alzheimer-disease-related dementia (ADRD) patients in nursing homes. Human biology has evolved to have two distinct optical systems: the visual system, by which we see and process images, and the circadian system, which regulates our biological clock and associated biological systems. These two systems have significantly different spectral and temporal responses to optical input. Specifically, circadian stimulation peaks at 460 nm and responds after several minutes of optical activation, while the visual system peaks at 555 nm and responds nearly instantaneously to inputs. All lighting systems are designed and installed in buildings with consideration only given to the photopic (visual) system and all light meters used to characterize lighting buildings are calibrated to measure photopic light, not CS. While a broad and growing body of research has documented the impacts of the circadian system on human health, including regulating sleep and improving cognition in AD/ADRD patients, research on the CS experienced by AD/ADRD patients is extremely limited. Researchers at the Lighting Research Center at Rensselaer Polytechnic Institute developed the Daysimeter, a calibrated light meter that measures circadian light and circadian stimulus. In Phase I of this project, researchers modified an existing workstation-based lighting control system they previously developed for the visual system to include Daysimeter technology, allowing this control system to record CS measurements. The accuracy of these CS measurements was confirmed in the laboratory and field-testing of 20 of devices is currently ongoing in AD/ADRD nursing homes. In this Phase II application, researchers propose adding control features to this device so that lighting can be controlled to optimize CS dosages in AD/ADRD patient environments. Machine learning-based lighting control algorithms will be driven by continuous light level and spectrum measurements as well as periodic (e.g., daily) patient health data. Data from these devices would be wirelessly transmitted to researchers via an Internet gateway and associated cloud-based data management systems. These data would be of immediate value for gaining a better understanding of AD/ADRD patients' CS exposure and could ultimately result in new lighting systems and/or building codes that consider both our visual and circadian systems. Following the development phase, 30 CS-enabled lighting control systems will be field tested over a 22-week test period. Researchers aim to commercialize this CS-enabled lighting control system shortly after the completion of this field test and the Phase II project specifically targeting AD/ADRD nursing home applications. Project Narrative A growing body of research has demonstrated how light impacts human circadian systems and how these impacts can affect sleep, alertness, cognition and agitation in people with Alzheimer's disease (AD) and Alzheimer's-disease-related dementia (ADRD). Still, significant knowledge gaps exist in determining how much circadian stimulation is typically provided to AD/ADRD patients and there are no commercial products designed to control lighting in AD/ADRD environments in ways that promote circadian-related health. This project aims to fill in these gaps by developing and testing a device specifically designed to measure and control the circadian stimulation experienced by AD/ADRD patients in nursing homes.",Device to control circadian-effective light in Alzheimer's disease environments,9907480,R44AG060857,"['Affect', 'Agitation', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Back', 'Behavior', 'Biological Clocks', 'Building Codes', 'Characteristics', 'Clinical Trials', 'Cognition', 'Data', 'Database Management Systems', 'Development', 'Device or Instrument Development', 'Devices', 'Dose', 'Effectiveness', 'Elderly', 'Environment', 'Feeds', 'Health', 'Hour', 'Human', 'Human Biology', 'Image', 'Institutes', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Measures', 'Monitor', 'Moods', 'Nursing Homes', 'Optics', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Phototherapy', 'Planet Earth', 'Population', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Rotation', 'Running', 'Sleep', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Visual', 'Visual system structure', 'Wakefulness', 'Wireless Technology', 'Work', 'active control', 'alertness', 'appropriate dose', 'awake', 'base', 'biological systems', 'circadian', 'circadian pacemaker', 'cloud based', 'commercialization', 'design', 'dosage', 'experience', 'falls', 'feeding', 'field study', 'health data', 'improved', 'interest', 'meter', 'next generation', 'novel', 'prototype', 'residence', 'response', 'success', 'therapy design']",NIA,"ERIK PAGE AND ASSOCIATES, INC.",R44,2019,1240470,-0.03496869627843222
"Graphene-based Nanosensor Device for Rapid, Onsite Detection of Total Lead in Tap Water PROJECT SUMMARY Detrimental health impacts of lead are largely attributed to long-term exposures to undetected lead, which are particularly troublesome and problematic because of the neurological damage to children, a situation that should not be tolerated by an advanced society like the U.S. The Flint Water Crisis and many other water catastrophes could have been avoided if early warning can be made possible through timely detection of lead in drinking water at the point of use. Our extensive customer interviews unambiguously suggest that current options for lead detection are unsatisfactory for on-site testing, as they represent two extremes: one being accurate but expensive, slow, and hard to use; and the other being low-cost, fast, and easy to use but inaccurate. NanoAffix Science LLC (NAFX) proposes to address the above unmet need and niche market product gap by empowering water users (particularly those in economically disadvantaged communities) and water service providers with a low-cost, easy-to-use, and accurate handheld tester for rapid detection of total lead in the tap water, right from the kitchen sink. The handheld lead tester combines a novel proprietary micro-sized sensor chip embedded in a proprietary test cell with a portable digital meter for direct readout of testing results. The Phase I project has successfully established the feasibility for detection of soluble lead in the tap water using an earlier version of the prototype handheld tester. The Phase II project will continue to develop the handheld tester toward total lead detection, better device uniformity, pilot scale-up manufacturing, and accurate calibration. At the end of the Phase II project, NAFX plans to produce 20 beta units of the handheld lead tester meeting all performance specifications for field validation by 10 initial customers (e.g., schools/daycares, end water users, and well water drillers). Major innovations of the proposed approach include accurate prediction of the particulate lead through partial digestion based on lead digestion kinetics, and strategic and synergistic improvement of the ultimate sensor prediction accuracy by (1) improving the physical sensor device uniformity (both intra-wafer and inter-wafer) through innovative device configuration and rigorous quality control; and (2) improving the calibration accuracy through innovative theoretical equilibrium chemistry modeling and machine learning data analytics. The NAFX handheld lead tester is the first of its kind to (1) offer all three features sought by customers: accurate, cheap, and fast; and (2) to simultaneously report all three types of lead: total lead (indicative of overall toxicity), soluble lead (indicative of slow leaching of lead), and particulate lead (indicative of sporadic flaking of lead), which thus can not only alert customers to the lead hazard in their drinking water but also enable customers to identify possible causes and most effective solutions to mitigate the lead contamination. Therefore, the project will result in not only considerable economic impact but also immense societal impact. The regular use of NAFX handheld tester - even if intermittently - will virtually eliminate the chance of chronic exposure to undetected lead, thereby accruing significant and predictable public health impact, especially in locations with the highest risk. PROJECT NARRATIVE The NanoAffix Phase II project aims to continue the development of a handheld lead tester for accurate and low- cost onsite detection of total lead in tap water by untrained users, based on the success of the Phase I project. The project will contribute to enhancing the public health by offering an accessible tool for quantitative monitoring of all three types of lead: total lead (indicative of overall toxicity), soluble lead (indicative of slow leaching of lead), and particulate lead (indicative of sporadic flaking of lead) in tap water. The regular use of NanoAffix handheld tester - even if intermittently - will virtually eliminate the chance of chronic exposure to undetected lead, thereby accruing significant and predictable public health impact, especially in locations with the highest risk.","Graphene-based Nanosensor Device for Rapid, Onsite Detection of Total Lead in Tap Water",9847052,R44ES028656,"['Address', 'Algorithms', 'Calibration', 'Cations', 'Cells', 'Chemistry', 'Child', 'Chronic', 'Communication', 'Communities', 'Complex', 'Contracts', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Digestion', 'Disinfection', 'Economically Deprived Population', 'Equilibrium', 'Equipment', 'Exposure to', 'Goals', 'Gold', 'Health', 'International', 'Interview', 'Kinetics', 'Laboratories', 'Lead', 'Lead Poisoning', 'Location', 'Machine Learning', 'Measurement', 'Michigan', 'Modeling', 'Monitor', 'Nervous System Trauma', 'Paper', 'Particulate', 'Performance', 'Phase', 'Procedures', 'Process', 'Public Health', 'Quality Control', 'Reporting', 'Research', 'Schools', 'Science', 'Site', 'Societies', 'Specialist', 'System', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Validation', 'Variant', 'Water', 'Water Supply', 'Wireless Technology', 'aqueous', 'base', 'cost', 'digital', 'drinking water', 'economic impact', 'empowered', 'graphene', 'hazard', 'high risk', 'improved', 'innovation', 'lead concentration', 'lead contamination', 'manufacturing scale-up', 'meetings', 'meter', 'nanosensors', 'novel', 'operation', 'portability', 'prototype', 'rapid detection', 'real time monitoring', 'response', 'sample collection', 'sensor', 'service providers', 'success', 'tool', 'virtual', 'water quality', 'well water']",NIEHS,"NANOAFFIX SCIENCE, LLC",R44,2019,565059,0.0099166918031187
"Characterizing Activity Patterns in Functional Mobility After Spinal Cord Injury Abstract  My career and research interests have centered on the science of movement and factors that maximize mobility. Whether this is through injury prevention, assistive technology, or biomechanical optimization, it is critical to clinical practice that these processes be well understood so that we can provide the most informed patient treatments. In order to carry out more effective clinically-based studies that inform patient care, it is my desire to continue my training through practical experiences with both formal coursework and a oversight by a strong mentoring team in the following domains: (1) activity-based data collection and analysis and (2) use of advanced statistical methods to investigate multiple factors. Through the K23, I will also gain experience specifically focused on my transition to independence; this will include grantsmanship and lab management, leading the design and implementation of clinical and translational studies, management of personnel and meetings, and pursuit of tenure and an R01. This continued training will be completed in the context of a research study that characterizes activity patterns in functional mobility after spinal cord injury (SCI).  Aim 1 of this study is to predict mobility at discharge and at 1-year post-discharge, based upon patient characteristics and activity during IPR. Mobility outcomes can be challenging to predict, particularly for individuals with moderate strength and sensory impairments. Selecting appropriate training is increasingly important with shrinking lengths of stay and there are potential opportunity costs and adverse consequences on quality of life and participation for individuals who do not receive appropriate interventions. Additional activity measures that we can collect early in the IPR stay, by utilizing low-cost sensors, have the potential to provide rich data sets that we can examine to garner insight into outcomes with little administrative burden. Using a machine learning approach, we will investigate patient characteristics and activity-monitoring data to improve predictive models of patient mobility based on data acquired early in the rehab stay. Achieving these aims will improve patient and clinician understanding of anticipated changes in mobility in the year following SCI to appropriately target expectations and interventions to maximize functional outcomes.  Aim 2 of this proposal is to quantitatively evaluate functional mobility changes (i.e., wheeling walking or changes in activity within mode) in the first year post injury and their impact on quality of life and participation. There are factors following discharge that challenge or enhance the sustainability of walking for functional mobility including energy costs, neurologic recovery and biopsychosocial factors such as resilience, self-efficacy, environment, and caregiver support. The association between these factors and post-discharge changes in mobility are not well understood. Using wearable sensors we will quantify time spent walking and wheeling to identify transitions between walking and wheeling, identify factors that contribute to these transitions and investigate their impact on participation. Project Narrative In the context of steadily decreasing lengths of stay for inpatient rehabilitation, and in conjunction with therapy caps in outpatient therapy settings that have led to an overall decrease in patient time spent within a clinical context, it is becoming ever more critical that rehabilitation interventions appropriately target functional mobility (walking or wheeling). Unfortunately, the needed data on how mobility changes following discharge and those factors that most accurately predict patient outcomes is lacking. This proposal seeks to improve patient and clinician understanding of anticipated changes in mobility in the year following SCI so that expectations and interventions can be appropriately targeted to maximize functional outcomes through the following aims: (1) predict mobility at 1 year post-discharge based on patient characteristics, biopyschosocial factors, and activity during inpatient rehabilitation and (2) quantitatively evaluate functional mobility changes in the first year post injury and their impact on quality of life and participation.",Characterizing Activity Patterns in Functional Mobility After Spinal Cord Injury,9821055,K23HD096134,"['Address', 'Biomechanics', 'Caregiver support', 'Caring', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Coin', 'Cost efficiency', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Dose', 'Environment', 'Esthesia', 'Exertion', 'Foundations', 'Future', 'Goals', 'Impairment', 'Individual', 'Injury', 'Inpatients', 'Intervention', 'Joints', 'Kinesiology', 'Length of Stay', 'Machine Learning', 'Measures', 'Mentors', 'Modeling', 'Monitor', 'Movement', 'Outcome', 'Outpatients', 'Pain', 'Pathology', 'Patient Care', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Personnel Management', 'Physical activity', 'Predictive Factor', 'Probability', 'Process', 'Quality of life', 'Rehabilitation therapy', 'Research', 'Resource Allocation', 'Resources', 'Secondary to', 'Self Efficacy', 'Self-Help Devices', 'Sensory', 'Spinal cord injury', 'Statistical Methods', 'Therapeutic Intervention', 'Time', 'Training', 'Upper Extremity', 'Walking', 'Wheelchairs', 'adverse outcome', 'base', 'biopsychosocial', 'career', 'clinical care', 'clinical implementation', 'clinical practice', 'community setting', 'cost', 'design', 'evidence base', 'expectation', 'experience', 'functional outcomes', 'gait rehabilitation', 'improved', 'improved mobility', 'injury prevention', 'innovation', 'inpatient service', 'insight', 'interest', 'meetings', 'muscle strength', 'neurological recovery', 'opportunity cost', 'patient mobility', 'person centered', 'predictive modeling', 'preservation', 'research study', 'resilience', 'sensor', 'translational study', 'wearable device']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K23,2019,136420,0.01695534429738523
"I-Corps Program Application for Market Assessment of Non-invasive Imaging Device to Improve Outcomes of Amputations Surgery in Critical Limb Ischemia. 1. Executive Summary Nearly 150,000 patients in the US undergo lower extremity amputations annually secondary to peripheral arterial disease (PAD) complicated by critical limb ischemia (CLI).1,2,3 To increase a patient’s post-operative quality of life, surgeons attempt to salvage as much limb tissue as possible while also considering the likelihood of primary wound healing at a given level of amputation (LOA).4 The principal challenge in this decision is that surgeons overestimate the likelihood of healing at the selected LOA. Therefore, in the first year, 10% to 35% of amputations eventually require re-amputation to a more proximal level.5-7 This additional treatment prolongs the patient’s return to walking, worsening their condition and deteriorating their mental health. The burden to the healthcare system is immense. The average cost for each amputation is over $70,000, as evidenced by a recent publication that shows diabetic foot ulcer complications, mainly attributed to amputation, cost more than the five most costly forms of cancer.8 Despite these facts, there are no objective studies for selection of LOA in patients with PAD. To address this critical problem, Spectral MD (SMD) has developed a point-of-care imaging device (DeepView), which simultaneously performs multispectral imaging (MSI) and Photoplethysmography (PPG) imaging across the visible and infrared spectrum to obtain a quantitative microvascular tissue assessment. These optical measurements are integrated using artificial intelligence (AI) algorithms to provide a quantitative aid to the physician’s determination of tissue viability at a proposed amputation site. If used for routine assessment prior to amputation, SMD expects DeepView to reduce the rate of re- amputation by 70%, resulting in up to 38,000 fewer re-amputations per year while improving quality of life for amputees and reducing associated health costs. The central objective for SMD’s Phase I SBIR is to perform a feasibility clinical study to demonstrate the DeepView device will achieve greater than 90% accuracy in identifying the healing potential of tissue at the amputation site. This hypothesis will be tested by the following specific aims: Aim 1: Complete a Feasibility Study creating a database of pre-amputation images. This data will be used for construction of the AI algorithm to predict amputation site healing potential. Aim 2: Identify MSI and PPG features that can accurately predict amputation site healing potential. Aim 3: Using Aim I clinical data, finalize the AI algorithm architecture and estimate sample size needed for a Phase II Pivotal Study in which the necessary training data to achieve at least 90% sensitivity and 90% specificity will be obtained. As of this Supplement request, SMD has initiated a clinical study for feasibility and enrolled the first subject. Through collaboration with the clinical study site Principal Investigator (PI), Dr. Dennis Gable, SMD developed the protocol and trained his research staff at the study site, Baylor Medical Center Plano, in the use of the DeepView device. SMD anticipates enrollment of five subjects each month over the next 6 months. The I-Corps team will consist of the following members: Michael DiMaio, MD – Role: C-Level Corporate Officer. Dr. DiMaio, MD is Founder and Chief Executive Officer of SMD and has led SMD in obtaining over $30M in non-dilutive government funding and private investments. His distinguished career includes extensive experience as an entrepreneur, clinician, and scientist. With over 20 years’ experience as a cardiovascular surgeon, Dr. DiMaio has a widespread network of physicians and hospitals from which to draw contacts for customer interviews. Jeffrey Thatcher, PhD – Role: PI. Dr. Thatcher is the Chief Scientist at SMD and is a leader in the development of diagnostic imaging for soft tissue diseases. He led SMD in conceptualizing and inventing SMD’s core imaging technology undergoing clinical trials in three wound diagnostics applications including: burns; diabetic ulcers; and amputation. Wensheng Fan, MS – Role: Industry Expert. Wensheng Fan is Executive Vice President and Chief Technology Officer at SMD. He is an executive, entrepreneur, and innovator with over 20 years of experience in natural speech recognition and real time imaging systems. At SMD, he leads market engagement, strategic financial planning, and device development. Narrative In patients with peripheral arterial disease, reported rates of re-amputation due to non-healing of a primary amputation are very significant—approximately 20% of below-the-knee amputations require eventual revision, with even higher rates established for amputations at the level of the foot. There are no gold-standard tests for selection of level of amputation (LOA) to aid clinical judgment. To address this critical problem, SpectralMD is developing the DeepView-Gen2 imaging device that integrates multispectral imaging and a machine learning algorithm to quantitatively measure microvascular blood flow and tissue healing potential to assist in the clinical selection of LOA and minimize the incidence of re-amputation and its associated morbidity and mortality.",I-Corps Program Application for Market Assessment of Non-invasive Imaging Device to Improve Outcomes of Amputations Surgery in Critical Limb Ischemia.,9827388,R43HL142428,"['Address', 'Algorithms', 'Amputation', 'Amputees', 'Architecture', 'Artificial Intelligence', 'Blood flow', 'Burn injury', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Data', 'Databases', 'Development', 'Device or Instrument Development', 'Devices', 'Diabetic Foot Ulcer', 'Diabetic ulcer', 'Diagnostic', 'Diagnostic Imaging', 'Doctor of Philosophy', 'Enrollment', 'Feasibility Studies', 'Funding', 'Gold', 'Government', 'Health Care Costs', 'Healthcare Systems', 'Hospitals', 'Image', 'Imaging Device', 'Imaging technology', 'Incidence', 'Industry', 'Innovation Corps', 'Interview', 'Investments', 'Ischemia', 'Judgment', 'Knee', 'Limb structure', 'Lower Extremity', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Medical center', 'Mental Health', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Peripheral arterial disease', 'Phase', 'Photoplethysmography', 'Physicians', 'Postoperative Period', 'Principal Investigator', 'Privatization', 'Protocols documentation', 'Publications', 'Quality of life', 'Reporting', 'Research Training', 'Role', 'S Phase', 'Sample Size', 'Scientist', 'Secondary to', 'Site', 'Small Business Innovation Research Grant', 'Soft Tissue Disorder', 'Specificity', 'Surgeon', 'Technology', 'Testing', 'Tissue Viability', 'Tissues', 'Training', 'Walking', 'Wound Healing', 'career', 'cost', 'experience', 'foot', 'healing', 'imaging system', 'improved', 'improved outcome', 'innovation', 'machine learning algorithm', 'member', 'mortality', 'non-invasive imaging', 'point of care', 'programs', 'real-time images', 'speech recognition', 'wound']",NHLBI,"SPECTRAL MD, INC.",R43,2019,54976,0.004348300826987531
"Healthcare Impact of Consumer-Driven Atrial Fibrillation Detection PROJECT SUMMARY/ABSTRACT  Companies are increasingly marketing mobile technologies as FDA-cleared medical devices, yet we do not know the consequences of these devices on healthcare utilization, cost, and outcomes. Recently, Apple released the Apple Watch Series 4 as an FDA-cleared medical device. The device includes an alert for the presence of atrial fibrillation (AF) and allows anyone to monitor their heart rhythm for the presence of AF. Apple has an enormous global audience, and the number of people who will use this (and other similar devices) to self-diagnose or monitor AF will be substantial. On one hand, the device may allow new diagnoses that result in treatment, improved quality of life, fewer AF related complications. On the other hand, the device may result in false positives in otherwise healthy people, resulting in more testing and treatments with associated harms. In fact, the U.S. Preventative Task Force recommends against routine surveillance for AF in the general population, citing lack of evidence and possible harm. We have an urgent need for a population-based infrastructure to ensure that technologies entering the market as medical devices are beneficial and safe.  The overall goal of this project is to measure the uptake and effect of the Apple Watch 4 release on healthcare utilization among first-time and known AF patients. Dr. Shah is an early stage investigator with a K08 Career Development Award from the NHLBI. As part of the K08, she has developed a detailed cohort of contemporary AF patients, including clinical notes. Along with a team, she will use real world data, as proposed by the FDA, to generate evidence about risks and benefits of consumer-driven AF detection. She will use natural language processing to leverage the notes and identify AF patients who seek care due to the medical device, and evaluate downstream healthcare utilization, such as additional clinic visits, cardioversions, additional remote monitoring, and cost. The goals of this project will be accomplished through the following Specific Aims: 1) Estimate the proportion of first-time AF patient visits attributable to a mobile device before and after FDA clearance of the Apple Watch 4, and characterize device accuracy and downstream healthcare utilization in this population; and 2) Evaluate healthcare utilization patterns among prevalent AF patients who use mobile devices with AF alerts.  In 2017, Apple sold 17.7 million smart watches, in a device market that continues to grow. Extrapolating from prior annual sales and conservatively assuming a 5% increase in users each year, almost 60 million people will have an Apple Watch by the end of 2020 (not accounting for non-Apple devices with similar functionality). Thus, even in this short period of time, uptake will be substantial and warrant immediate feedback. The results of this project will provide preliminary data for a long-term, multicenter study that evaluates the benefits (improved quality of life, fewer strokes) and harms (increased treatment complications, increased cost) of consumer-driven AF detection. PROJECT NARRATIVE The consequence of mobile technologies marketed as medical devices are unknown, including devices that provide alerts for the presence of atrial fibrillation. The goal of this project is to evaluate the benefits and harm associated with consumer-driven atrial fibrillation detection.",Healthcare Impact of Consumer-Driven Atrial Fibrillation Detection,9809717,R03HL148372,"['Adult', 'Advisory Committees', 'Affect', 'Apple', 'Apple watch', 'Arrhythmia', 'Atrial Fibrillation', 'Benefits and Risks', 'Cardiovascular system', 'Caring', 'Case-Control Studies', 'Clinic Visits', 'Clinical', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Electric Countershock', 'Ensure', 'Feedback', 'General Population', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Hemorrhage', 'Holter Electrocardiography', 'Infrastructure', 'Interruption', 'Intervention', 'K-Series Research Career Programs', 'Lead', 'Marketing', 'Measures', 'Medical Device', 'Monitor', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Outcome', 'Patients', 'Pattern', 'Population', 'Prevalence', 'Preventive', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sales', 'Series', 'Sinus', 'Stroke', 'Technology', 'Testing', 'Text', 'Time', 'United States Food and Drug Administration', 'Universities', 'Utah', 'Visit', 'base', 'care seeking', 'cohort', 'cost', 'cost outcomes', 'cryptogenic stroke', 'design', 'follow-up', 'handheld mobile device', 'health care service utilization', 'heart rhythm', 'improved', 'mobile computing', 'population based', 'routine screening', 'self diagnosis', 'smart watch', 'uptake']",NHLBI,UNIVERSITY OF UTAH,R03,2019,76250,-0.0004991690683765299
"An Intracortical Brain-Computer Interface Model for High Efficiency Development of Closed-Loop Neural Decoding Algorithms An intracortical brain-computer interface (iBCI) is used to record electrical signals directly from a person's brain, predict their intention from those signals, then control an assistive device (e.g., a computer cursor, prosthetic limb, or powered wheelchair) according to those intentions. This technology enables severely paralyzed people to interact with the world. However, designing robust algorithms to extract intent from recordings of single neurons is extremely challenging, in large part because of the very limited access to humans, or even monkeys, from whom these invasive recordings can be made. In this project, we will develop a model iBCI system that generates real-time biomimetic neural data by capturing the high-degree-of-freedom finger movements of able-bodied human subjects. To accomplish this, we will construct a modular recurrent neural network (RNN). The RNN will be trained to predict the motor cortex activity of a monkey from the monkey's own finger kinematics. Small modules of the RNN will be interchanged according the particular animal or recording session to model the high inter-session variability present in motor cortex. Once the modular RNN is trained, its weights will be fixed and human finger kinematics will be used as the RNN inputs, which will generate subject-controlled emulated neural activity. The emulated neural activity can be passed to iBCI decoding algorithms that control computer cursors or other physical devices, allowing human subjects to interact directly with decoders in real time, closed-loop conditions. We call this model system the jaBCI. The jaBCI is low cost and noninvasive, making it possible to rapidly test and design novel iBCI decoders using statistically rigorous sample sizes. The project will be executed in close collaboration with intracortical microelectrode array data expert Dr. Lee Miller at Northwestern University. Dr. Miller's lab, with the help of our consultant Dr. Mathis, will obtain simultaneous finger kinematics and neural activity of monkey subjects that will serve as the training data for the RNN component of the iBCI model. We will validate the emulated neural data generated by the jaBCI across many measures to ensure the model captures as many features of intracortical data as possible. These include comparing the model and actual iBCI in subject performance, learning rates, control strategies, neural variation across days, neural firing rate distributions, and low-dimensional neural dynamics. With the validated model, we will undertake a study to rigorously evaluate the highest performing, current state-of-the-art iBCI decoders. This will yield useful insight into the features of decoders that yield the greatest performance gains, overcoming the current impossibility to compare iBCI decoders in well-controlled studies using more than two or three naïve human subjects. We will also use the iBCI model to evaluate novel decoder designs, and to determine the features of neural dynamics that are consistent across common iBCI tasks to help focus decoder development on those features. Narrative Brain-computer interfaces are systems that translate the electrical neural signatures of thought into instructions for a personal computer or powered wheelchair, which is an incredibly useful technology to help paralyzed people regain some independence and ability to communicate. This work would develop a tool that scientists can use to design, test, and optimize the sophisticated computer programs that translate brain signals into device instructions without having to implant electrodes into a person's brain until the program is completed and rigorously tested. This tool could increase the pace of discovery and development of brain-computer interfaces.",An Intracortical Brain-Computer Interface Model for High Efficiency Development of Closed-Loop Neural Decoding Algorithms,9817780,R01NS109257,"['Address', 'Algorithms', 'Animals', 'Biological Models', 'Biomimetics', 'Brain', 'Collaborations', 'Communities', 'Computers', 'Controlled Study', 'Data', 'Data Set', 'Development', 'Devices', 'Dimensions', 'Electroencephalography', 'Ensure', 'Exhibits', 'Feedback', 'Finger joint structure', 'Fingers', 'Freedom', 'Hand', 'Human', 'Human body', 'Implant', 'Implanted Electrodes', 'Industry Standard', 'Injury', 'Instruction', 'Intention', 'Joints', 'Learning', 'Limb Prosthesis', 'Limb structure', 'Literature', 'Measures', 'Methods', 'Microelectrodes', 'Modeling', 'Monkeys', 'Motor Cortex', 'Muscle', 'Neurons', 'Operating System', 'Operative Surgical Procedures', 'Paralysed', 'Patients', 'Performance', 'Personal Computers', 'Personal Power', 'Persons', 'Posture', 'Powered wheelchair', 'Protocols documentation', 'Reporting', 'Reproducibility', 'Robotics', 'Rotation', 'Sample Size', 'Scientist', 'Self-Help Devices', 'Series', 'Signal Transduction', 'Structure', 'System', 'Task Performances', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Validation', 'Variant', 'Weight', 'Work', 'brain computer interface', 'cohort', 'comparative', 'computer program', 'cost', 'design', 'finger movement', 'head-to-head comparison', 'high dimensionality', 'human subject', 'human-in-the-loop', 'innovation', 'insight', 'invention', 'kinematics', 'nervous system disorder', 'neurotransmission', 'novel', 'programs', 'recurrent neural network', 'relating to nervous system', 'skill acquisition', 'success', 'tool']",NINDS,FLORIDA INTERNATIONAL UNIVERSITY,R01,2019,367007,0.025296449521446513
"Using Wearable and Mobile Data to Diagnose and Monitor Movement Disorders The long-term goal of the proposed work is to develop a tool to help diagnose and monitor movement disorders. Due to increasing and aging world population, more people are living with these disorders. As there is already a shortage of neurologists, and more specifically, movement disorder specialists that have the training to adequately diagnose and manage these disorders, there is a large number of patients that are not receiving optimal treatment. We propose to use a smartphone-based platform to assess the severity of symptoms that are common across different movement disorders in order to achieve our long-term goal. To that end, the current study proposes to tackle 4 specific aims. The first aim will be to develop a mobile application to quantify common symptoms of movement disorders. We will develop a new mobile application that will enable the quantification of symptom severity; namely rest tremor, postural tremor, intention tremor, kinetic tremor, upper-limb coordination, bradykinesia, balance, gait, and cognitive impairments. The data collected from the smartphone-embedded sensors will be transmitted to a secure server where data can be visualized and analyzed. The second aim will be to collect data using the mobile application from healthy individuals as well as individuals with different movement disorders. We will collect data from 30 healthy controls, 30 individuals with Essential tremor (ET), 30 individuals with Parkinson's disease (PD), 30 individuals with Huntington's disease (HD), 30 individuals with primary focal dystonia (PFD) of the upper-limb, 30 individuals with spinocerebellar ataxia (SCA, and 30 individuals with functional movement disorder (FMD). This dataset will enable us to develop algorithms (Aim 3) that will be used to assess symptom severity and differentiate the movement disorders according to the smartphone data. The third aim will be to develop algorithms to estimate symptom severity and distinguish the different movement disorders from one another. Using the data from the smartphone-embedded sensors, we will utilize machine learning approaches to estimate symptom severity (i.e. tremor, bradykinesia, gait impairment, etc.). Then, based on the symptom severity estimation as well as from features extracted from the sensor data, we will classify the subjects in groups according to their clinical diagnosis. This will enable us to differentiate the selected movement disorders. Finally, the fourth aim will be to assess the usability of the smartphone platform for long-term monitoring of patients. Subjects of patients recruited for Aim 2 will be asked to use the smartphone application at home for 8 weeks in order to determine compliance with its use and its stability over time. This study will provide a novel tool to assess motor and non-motor symptoms that could be used in other areas of research. It will provide a large database of movement, cognitive, demographic, and medical history data of individuals with different movement disorders. Most importantly, it will help in the differentiation and monitoring of movement disorders to improve the clinical management of individuals with these disorders. The prevalence of movement disorders is on the rise due to the expanding and aging world population while there is a lack of trained specialists in, and especially outside, of developed urban centers to adequately diagnose and manage those individuals. We propose that the ubiquity of smartphones could be leveraged to help non- specialists in the diagnosis, monitoring, and management of movement disorders that often exhibit overlapping symptoms such as Essential tremor, Parkinson's disease, Huntington's disease, primary focal dystonia, spinocerebllar ataxia, and functional movement disorders. We will develop a smartphone application that will collect data during different tasks to help differentiate these disorders and monitor them over time.",Using Wearable and Mobile Data to Diagnose and Monitor Movement Disorders,9655625,R15NS109741,"['Abnormal coordination', 'Address', 'Adult', 'Affect', 'Aging', 'Algorithms', 'Area', 'Ataxia', 'Behavior', 'Bilateral', 'Bradykinesia', 'Cellular Phone', 'Clinical', 'Clinical Management', 'Cognitive', 'Complex', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Disease Management', 'Dystonia', 'Economics', 'Equilibrium', 'Essential Tremor', 'Exhibits', 'Eye Movements', 'Focal Dystonias', 'Gait', 'Genetic Diseases', 'Goals', 'Hand', 'Health Status', 'Home environment', 'Huntington Disease', 'Impaired cognition', 'Impairment', 'Individual', 'Intention Tremor', 'Kinetics', 'Laboratories', 'Lead', 'Life Expectancy', 'Limb structure', 'Machine Learning', 'Medical History', 'Monitor', 'Motor', 'Movement', 'Movement Disorders', 'Muscle Contraction', 'Nature', 'Neurodegenerative Disorders', 'Neurologic', 'Neurologist', 'Parkinson Disease', 'Patient Monitoring', 'Patient Recruitments', 'Patients', 'Persons', 'Population', 'Posture', 'Prevalence', 'Primary Dystonias', 'Process', 'Psychological Factors', 'Quality of life', 'Questionnaires', 'Research', 'Rest Tremor', 'Secure', 'Severities', 'Smooth Muscle', 'Specialist', 'Speech', 'Spinocerebellar Ataxias', 'Symptoms', 'System', 'Testing', 'Time', 'Training', 'Tremor', 'Upper Extremity', 'Work', 'base', 'clinical Diagnosis', 'common symptom', 'equilibration disorder', 'functional disability', 'handheld mobile device', 'improved', 'mobile application', 'mobile computing', 'motor symptom', 'non-motor symptom', 'novel', 'optimal treatments', 'progressive neurodegeneration', 'recruit', 'sensor', 'smartphone Application', 'symptom management', 'tool', 'usability', 'wearable device']",NINDS,RBHS-SCHOOL/ HEALTH RELATED PROFESSIONS,R15,2019,399532,0.015332630874134091
" SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track) The overall objective of this Fast-Track SBIR contract project is to develop DigiBioMarCTM (Digital BioMarkers for Clinical Impact), a scalable and flexible cloud-based platform to capture and analyze wearable, implantable, or external device data. This platform also provides an informatics tool for automated data aggregation, integration, and machine learning algorithms. It is based on the scalable user-centered Medable platform, which implements standardization and normalization of patient-generated data to drive health insights. DigiBioMarCTM will compare and combine disparate data streams to understand contextualized patient physiology in real time in order to identify disease and/or detect changes in disease/health status. It also will support cohort and clinical studies, particularly those testing digital biomarkers from wearable sensor technologies. This Fast-Track project will focus on product development with an ultimate aim of a product that improves cancer research data and clinical trials, enhances clinical care, and that can be used to engage patients in preventive health behaviors and treatment adherence. The Phase I goal is to develop a data-agnostic DigiBioMarCTM prototype for validation in Phase II. The Phase 1 Go/No-Go decision point to proceed to Phase II will be a working prototype with specified features for further development and validation in Phase II. n/a", SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track),9952269,61201800010C,"['Biological Markers', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Computer software', 'Contracts', 'Data', 'Data Aggregation', 'Development', 'Devices', 'Disease', 'Documentation', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Patients', 'Phase', 'Physiology', 'Preventive', 'Publishing', 'Reporting', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Standardization', 'Stream', 'System', 'Testing', 'Time', 'Validation', 'anticancer research', 'base', 'behavioral adherence', 'clinical care', 'cloud based', 'digital', 'flexibility', 'graphical user interface', 'improved', 'informatics\xa0tool', 'insight', 'knowledge base', 'machine learning algorithm', 'product development', 'prototype', 'sensor', 'skills', 'tool', 'treatment adherence', 'wearable sensor technology']",NCI,"MEDABLE, INC.",N43,2019,1499800,0.020152018189868542
"Enabling of a Wireless and Remotely Monitored Deep Brain Stimulation System through the Internet of Medical Things for Parkinson's Disease Patients Project Summary The objective of this project is to demonstrate feasibility of a novel platform technology using ultrasonic waves for wireless bidirectional real-time communication and powering of a Bilateral Deep Brain Stimulation (DBS) system with remote patient monitoring. DBS has become an established neurosurgical procedure with over 160,000 patients treated worldwide. DBS has been shown to improve Parkinson's disease (PD) patient quality of life, increase long term tremor control, reduce dyskinesia, and reduce hyperdopaminergic behavioral symptoms. Some of the most common complications associated with this procedure are injury caused by wire/lead tunneling, erosions or infections of the tunneled wires, lead failure/migration, and tethering of extension cables. None of the current solutions are leadless and allow for remote monitoring due to limitations of wireless interconnected devices in the body. Bionet Sonar's software-defined UsWB proprietary technology is capable of transmitting energy and data via ultrasonic waves through tissue, bone, and fluids at penetration depths significantly higher than RF waves and with greater reliability. The Bionet platform includes: i) Reprogrammable wireless stimulation leads; ii) Rechargeable system controller to coordinate with, recharge, and reprogram other implantable elements of the network through the ultrasonic interface; iii) External recharging and communication patch to act as a power/data gateway to interconnect the intra-body network with the Internet. An intelligent DBS device that can be monitored by clinicians and provide feedback control to optimize therapy using remote continuous real-time data will lead to improved PD treatment options and informed treatment decisions individualized for each patient (point-of-care). In this Phase I study, feasibility for wireless power and remote monitoring with the Bionet system will be demonstrated by completing the following Specific Aims: Specific Aim 1. Demonstrate in vitro feasibility of controlled deep brain stimulation, recharging and remote monitoring components using ultrasonic waves at typical implantable tissue depths. Specific Aim 2. Demonstrate in vivo, data and energy transmission for the systems during controlled stimulation of the brain. In vivo experiments in minipig models (n=3) will be used to demonstrate the ability of the system to transmit data and energy from the subcutaneous controller to the pacing nodes using closed loop control based on real time electrical sensing. This proposal leverages the strengths of Bionet Sonar Inc. and the University of Louisville. Our long-term goal is to successfully translate the Bionet Sonar system into clinical practice. The core platform technology may also be applied to other networked systems for the treatment of diverse etiologies opening a new frontier in multimodal patient treatment and use of Artificial Intelligence for patient care. Project Narrative Through this proposal a wireless remotely monitored deep brain stimulation system will be developed using new core technology for the Internet of Medical Things. Ultrasonic wideband technology will be used to enable wireless communication and recharging of the different implantable elements, allowing for miniaturization and energy efficiency. This technology will not only improve the outcomes and healthcare economics of the Parkinson's disease patient population, but may also enable other innovative therapies in other populations.",Enabling of a Wireless and Remotely Monitored Deep Brain Stimulation System through the Internet of Medical Things for Parkinson's Disease Patients,9908204,R43NS115226,"['Acute', 'Address', 'Adoption', 'Architecture', 'Artificial Intelligence', 'Award', 'Behavioral Symptoms', 'Bilateral', 'Biomedical Engineering', 'Brain', 'Cadaver', 'Clinical', 'Clinical Engineering', 'Communication', 'Computer software', 'Data', 'Deep Brain Stimulation', 'Development', 'Devices', 'Dopa-Responsive Dystonia', 'Drops', 'Dyskinetic syndrome', 'Elements', 'Engineering', 'Epilepsy', 'Essential Tremor', 'Etiology', 'Failure', 'Feedback', 'Freezing', 'Frequencies', 'Geometry', 'Goals', 'Health Care Costs', 'Hospitals', 'Human', 'In Vitro', 'Industry', 'Infection', 'Injury', 'Innovative Therapy', 'Institutes', 'Intelligence', 'International', 'Internet', 'Intervention', 'Intrabody', 'Lead', 'Limb Prosthesis', 'Link', 'Liquid substance', 'Manic', 'Medical', 'Miniature Swine', 'Miniaturization', 'Modeling', 'Monitor', 'Neurosurgical Procedures', 'Obsessive-Compulsive Disorder', 'Parkinson Disease', 'Patient Care', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Penetration', 'Performance', 'Peripheral Nerves', 'Population', 'Procedures', 'Quality of life', 'Research Personnel', 'Signal Transduction', 'Site', 'Stomach', 'Structure of subthalamic nucleus', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Tremor', 'Ultrasonic wave', 'Ultrasonics', 'Universities', 'Wireless Technology', 'base', 'bone', 'clinical practice', 'clinically relevant', 'cost', 'data exchange', 'design', 'efficacy testing', 'experimental study', 'frontier', 'health care economics', 'implantable device', 'improved', 'improved outcome', 'in vitro Model', 'in vitro testing', 'in vivo', 'innovation', 'migration', 'monitoring device', 'multimodality', 'neuroregulation', 'novel', 'patient population', 'personalized decision', 'phase 1 study', 'phase 2 study', 'point of care', 'preclinical efficacy', 'product development', 'radio frequency', 'safety testing', 'software development', 'sonar', 'subcutaneous', 'transmission process', 'treatment optimization', 'verification and validation', 'wireless communication']",NINDS,BIONET SONAR,R43,2019,328562,-0.008964874728392542
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9750520,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Personal Satisfaction', 'Persons', 'Phase', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'manufacturability', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2019,507856,0.024595227226277484
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9650545,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Infrastructure', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Research', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Text Messaging', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'recruit', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,655251,-0.05213281438464142
"Neural dynamics and adaption for brain machine interface control Project Summary/Abstract  Millions of people suffer from some form of paralysis. In most of these cases the connection between the brain and the spinal cord is damaged, however, the motor cortex is healthy and intact. Thus, for these individuals, brain-machine interfaces (BMIs) hold significant promise for improving quality of life. BMIs decode an individual's intention to move by utilizing statistical models of neural activity patterns recorded from the motor cortex using implanted electrode arrays. While these methods have been encouraging in preclinical experiments and clinical trials for controlling thought-driven 2D computer cursors, they suffer from poor performance when applied to higher degrees-of-freedom (e.g., robotic limbs), and are not robust to the inevitable degradation of the electrode array. In order to address these clinical needs, this project starts from the recent observation that just as some behaviors are easier to learn, some patterns of neural activity, termed neural states, are also easier to generate. The overarching goal of this project is to elucidate if these “easy to generate” neural states can be used to robustly control a prosthetic arm. This is a significant departure from current decoding methods, which incorporate little to no information about the motor system, especially its ability to learn and adapt. The first major aim of this work is to develop experiments and analysis methods in order to find these “easy to generate” neural states in the non- human primate (i.e., rhesus monkey) motor system. Here “easy to generate” can be understood as the monkey's ability to volitionally generate that particular neural state. The second major aim of this work is to characterize the properties of the motor system that enable some states to be more easily generated than others. Prior work in our lab has shown that motor cortical population activity has well-defined structure, as predicted by dynamical system theory. These dynamics cause neural states to evolve in lawful ways through time. The work here will extend these findings by characterizing the dynamics associated with a monkey learning to generate a neural state. Finally, the third major aim of this work is to determine if neural states that monkeys can volitionally generate can be utilized for robust control of a prosthetic arm. The central hypothesis of this work is that building a model that only utilizes firing patterns that can be easily generated (as determined experimentally) will enable robust and high-performance control of a prosthetic arm. If successful, this study could have significant clinical impact by presenting a new paradigm to enable robust control of a prosthesis. Project Narrative  Millions of people worldwide suffer from neurological injuries or neurodegenerative diseases that result in considerable movement impairment. Brain machine interfaces (BMIs) hold considerable promise in drastically improving the quality of life for these individuals, who otherwise have very limited treatment options. This work will investigate the motor system's ability to learn and adapt, and directly use these insights to build robust high degree-of-freedom BMIs for clinical applications.",Neural dynamics and adaption for brain machine interface control,9765066,F31NS103409,"['Address', 'Area', 'Artificial Arm', 'Automobile Driving', 'Behavior', 'Brain', 'Clinical', 'Clinical Trials', 'Complex', 'Computers', 'Coupled', 'Data', 'Dimensions', 'Electrodes', 'Freedom', 'Generations', 'Goals', 'Implanted Electrodes', 'Individual', 'Intention', 'Joint Prosthesis', 'Joints', 'Learning', 'Limb Prosthesis', 'Limb structure', 'Link', 'Literature', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Neurodegenerative Disorders', 'Neurons', 'Paralysed', 'Pattern', 'Performance', 'Population', 'Property', 'Prosthesis', 'Quality of life', 'Rehabilitation device', 'Robotics', 'Spinal Cord', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Systems Theory', 'Techniques', 'Technology', 'Time', 'Training', 'Visual', 'Volition', 'Work', 'arm', 'arm movement', 'brain machine interface', 'clinical application', 'dynamic system', 'experimental study', 'falls', 'high dimensionality', 'improved', 'insight', 'motor impairment', 'neural model', 'neural patterning', 'neurophysiology', 'neuroregulation', 'nonhuman primate', 'pre-clinical', 'prosthesis control', 'rehearsal', 'relating to nervous system']",NINDS,STANFORD UNIVERSITY,F31,2019,34556,0.022716180006616647
"Customized Health Alerts and Consumer-Centered Interfaces Using In-Home and Wearable Sensors In-home sensing technologies hold enormous potential for early detection of health changes that can dramatically affect the experiences of aging: enabling functional independence, improving self-management of chronic or acute conditions, and improving quality of life. Chronic diseases especially affect older adults. Problems in chronic disease management are often the cause of losing independence for aging Americans. In 2012, 1 in 2 American adults (117 million) had at least one chronic condition, and 26% of the population had multiple chronic conditions, accounting for 84% of US health care costs. Early illness recognition and early treatment is key to improving health status with rapid recovery after an exacerbation of a chronic illness or acute illness, and also key to reducing morbidity and mortality in older adults and controlling health care costs.  In previous work, the team developed a health alert system that captures and analyzes data from sensors embedded in the home. Sensor data are captured passively and continuously in the home. In a pilot NIH R21 study, significant differences in health outcomes were shown with health alerts from motion and bed sensor data, based on bed restlessness and low, normal, and high pulse and respiration rates. The system actually detected changes in chronic diseases or acute illnesses on average 10 days to 2 weeks before usual assessment methods or self-reports of illness. For this project, the team will expand from the clinician-focused system to a consumer-focused system by incorporating more finely grained sensing (gait and quantitative pulse and respiration), with new improved algorithms that integrate individual health status and medication use, and track trajectories of health changes, for more sensitive, and more personalized health alerts with fewer false alarms. A recently developed bed sensor will be incorporated to passively capture quantitative pulse, respiration, and restlessness while the subject is resting. Gait parameters (e.g., in-home walking speed, stride time and stride length) will also be captured using depth images that show shadowy silhouettes. In addition, the team will solicit the consumer perspective on customized health alerts and a user interface for displaying sensor and alert information. The views of seniors and their family members will be used to inform the development of the new customized alert algorithms and drive the development of a consumer-focused interface that will provide empowering tools for self-management of chronic illnesses. In addition, the use of commercially available wrist-worn sensors will be explored for the purpose of recognizing health changes. The study will include a retrospective analysis of sensor data collected in 13 senior housing sites in Missouri. New participants will be recruited in 5 senior housing sites in Columbia, MO to investigate the consumer perspective. The important process of engaging consumers in this work is the next step in translating these systems into clinical practice for self-managing chronic health conditions, supporting seniors living independently. PROJECT NARRATIVE We will build on our current work using intelligent, in-home sensor systems with automated health alerts to investigate new health alert algorithms that are more sensitive and more customized to the individual. These will be tested with data from 13 senior housing sites in Missouri using clinician feedback and actual health trajectories for evaluation. We will also recruit subjects in independent living housing to solicit the views of consumers on wearable sensors, health alerts, and user interfaces that allow seniors and their family members to view the health alert information in a way that empowers them to better self-manage their own health.",Customized Health Alerts and Consumer-Centered Interfaces Using In-Home and Wearable Sensors,9623369,R01NR016423,"['Accounting', 'Acute', 'Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Aging', 'Agitation', 'Algorithms', 'American', 'Beds', 'Caregivers', 'Chronic', 'Chronic Disease', 'Complex', 'Custom', 'Data', 'Data Analyses', 'Development', 'Disease Management', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Family', 'Family member', 'Feedback', 'Gait', 'Grain', 'Health', 'Health Care Costs', 'Health Status', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Housing', 'Image', 'Independent Living', 'Individual', 'Intelligence', 'Length', 'Length of Stay', 'Machine Learning', 'Methods', 'Missouri', 'Monitor', 'Morbidity - disease rate', 'Motion', 'Nursing Homes', 'Outcome', 'Participant', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevention', 'Privacy', 'Process', 'Quality of life', 'Recovery', 'Respiration', 'Rest', 'Retrospective Studies', 'Self Management', 'Site', 'System', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Walking', 'Work', 'Wrist', 'active control', 'base', 'clinical practice', 'clinically relevant', 'cost', 'design', 'empowered', 'experience', 'fall risk', 'fitness', 'functional independence', 'health assessment', 'health difference', 'improved', 'information display', 'mortality', 'multiple chronic conditions', 'preference', 'recruit', 'sensor', 'sensor technology', 'tool', 'walking speed', 'wearable device']",NINR,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2019,100000,-0.009135386249535138
SCH: INT: A Context-aware Cuff-less Wearable Ambulatory Blood Pressure Monitor using a Bio-Impedance Sensor Array No abstract provided n/a,SCH: INT: A Context-aware Cuff-less Wearable Ambulatory Blood Pressure Monitor using a Bio-Impedance Sensor Array,9791169,R01EB028106,"['Address', 'Adult', 'Affect', 'Aging', 'Algorithms', 'Ambulatory Blood Pressure Monitoring', 'American', 'American Heart Association', 'Arteries', 'Awareness', 'Biological Markers', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood Vessels', 'Calibration', 'Cardiology', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Caring', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Frequencies', 'Funding', 'Grain', 'Guidelines', 'Health Sciences', 'Home environment', 'Hour', 'Human Resources', 'Hypertension', 'Institutes', 'Institution', 'International', 'Intervention Trial', 'Investigation', 'Laboratories', 'Left ventricular structure', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Phenotype', 'Physicians', 'Physiologic pulse', 'Physiological', 'Play', 'Positioning Attribute', 'Posture', 'Preventive Intervention', 'Reading', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Site', 'Skin', 'Source', 'Specific qualifier value', 'Speed', 'Sphygmomanometers', 'System', 'Technology', 'Testing', 'Texas', 'Time', 'Tissues', 'Travel', 'United States National Institutes of Health', 'Universities', 'Validation', 'Wearable Computer', 'Wrist', 'base', 'blood perfusion', 'cardiovascular disorder risk', 'clinical practice', 'cohesion', 'college', 'cost', 'design', 'disability-adjusted life years', 'disorder prevention', 'electric impedance', 'health disparity', 'hypertension control', 'learning strategy', 'minority health', 'novel', 'novel strategies', 'patient population', 'sensor', 'signal processing', 'therapy development', 'validation studies', 'wearable device']",NIBIB,TEXAS ENGINEERING EXPERIMENT STATION,R01,2019,289428,0.022878279132992466
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9707897,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,641907,0.0008201762125645231
"Multiple timescales of motor planning and execution in mouse cortex Project Summary/Abstract: For animals to execute complicated behaviors, successful motor planning and execution is essential. Moreover, the sequence of events leading to successful goal-based behavior takes place over a wide range of timescales. For example, when walking from home to work, one must first make an abstract, long-timescale decision to go to work, which much then be translated into a sequence of shorter-timescale right-left turning decisions, which are translated into the finely fluctuating electrical patterns that control the muscles. How motor planning and execution occur simultaneously over many timescales in populations of motor cortex neurons is not well understood. Much work in humans and nonhuman primates have shown that visual and auditory stimuli integrate over multiple timescales. This work has shown that early sensory regions, like primary visual cortex, respond to fast fluctuations in the environment. This information is integrated to longer-timescale information in secondary cortical regions, with the longest- timescale information in frontal and association areas. We therefore hypothesize that secondary motor cortex (M2) neurons control behavior over longer timescales than primary motor cortex (M1) neurons. To study this phenomenon, I have built a setup in which head-fixed mice navigate in virtual reality to a rewarded location. In this setup, I can record video from all sides of the animal for high spatiotemporal resolution measurement of motor behaviors. I have developed machine learning algorithms to extract 3D pose data from these videos. In Aim 1, I will use calcium imaging to record large numbers of neurons in mouse M1 and M2 to correlate the activity of individual neurons and populations to the animal’s ongoing pose kinematics. We will supplement with targeted silicon probe recordings to capture fast neural responses. In Aim 2, I will compare the calcium dynamics in populations of M1 and M2 neurons in mice trained to perform a virtual motor planning task versus mice that have not been trained. We hypothesize that training to plan motor actions increases the timescale of M1/M2 neural activity. In Aim 3, we will use optogenetic silencing in specific regions of cortex to perturb the animal’s motor behavior. We hypothesize that the duration of the perturbed movements will be longer when M2 is perturbed than M1. In this way, we will study how different cortical regions relate to behavior over many timescales. This proposal will broaden our knowledge of cortical processing in general, and motor planning and execution in particular. Patients with mental illness, such as ADHD, autism, and Asperger’s disorder show impaired ability to plan upcoming movements. The first step to successfully treating these illnesses is to better understand how motor planning occurs in general. Project Narrative: This proposal will elucidate how motor planning and execution take place simultaneously, over many timescales, and across brain regions. Better understanding motor planning will help generate new treatments for diseases that affect motor planning, like attention deficit hyperactivity disorder and autism.",Multiple timescales of motor planning and execution in mouse cortex,9752759,F31NS108450,"['3-Dimensional', 'Affect', 'Animal Behavior', 'Animals', 'Area', 'Asperger Syndrome', 'Attention deficit hyperactivity disorder', 'Behavior', 'Behavior Control', 'Brain region', 'Calcium', 'Code', 'Communication', 'Cues', 'Data', 'Dimensions', 'Disease', 'Ensure', 'Environment', 'Event', 'Future', 'Goals', 'Head', 'Home environment', 'Human', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Laser Scanning Microscopy', 'Lasers', 'Left', 'Light', 'Location', 'Measurement', 'Measures', 'Memory', 'Mental disorders', 'Modeling', 'Motor', 'Motor Cortex', 'Movement', 'Mus', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Population', 'Research', 'Resolution', 'Rewards', 'Running', 'Sensory', 'Short-Term Memory', 'Side', 'Silicon', 'Stereotyping', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Vision', 'Walking', 'Work', 'area striata', 'auditory stimulus', 'autism spectrum disorder', 'base', 'frontal lobe', 'kinematics', 'machine learning algorithm', 'neuromechanism', 'nonhuman primate', 'novel', 'optogenetics', 'prevent', 'relating to nervous system', 'response', 'sensory cortex', 'sensory stimulus', 'spatiotemporal', 'theories', 'two-photon', 'virtual', 'virtual reality', 'visual stimulus']",NINDS,HARVARD MEDICAL SCHOOL,F31,2019,38053,-0.02625848593864341
"Adaptive & Individualized AAC The heterogeneity of the more than 1.3% of Americans who suffer from severe physical impairments (SPIs) preclude the use of common augmentative or alternative communication (AAC) solutions such as manual signs, gestures or dexterous interaction with a touchscreen for communication. While efforts to develop alternative access methods through eye or head tracking have provided some communication advancements for these individuals, all current technologies suffer from the same fundamental limitation: existing AAC devices require patients to conform to generic communication access methods and interfaces rather than the device conforming to the user. Consequently, AAC users are forced to settle for interventions that require excessive training and cognitive workload only to deliver extremely slow information transfer rates (ITRs) and recurrent communication errors that ultimately deprive them of the fundamental human right of communication. To meet this health need, we propose the first smart-AAC system designed using individually adaptive access methods and AAC interfaces to accommodate the unique manifestations of motor impairments specific to each user. Preliminary research by our team of speech researchers at Madonna Rehabilitation Hospital (Communication Center Lab) and Boston University (STEPP Lab), utilizing wearable sensors developed by our group (Altec, Inc) have already demonstrated that metrics based on surface electromyographic (sEMG) and accelerometer measures of muscle activity and movement for head-mediated control can be combined with optimizable AAC interfaces to improve ITRs when compared with traditional unoptimized AAC devices. Leveraging this pilot work, our team is now proposing a Phase I project to demonstrate the proof-of-concept that a single sEMG/IMU hybrid sensor worn on the forehead can provide improvements in ITR and communication accuracy when integrated with an AAC interface that is optimized through machine learning algorithms. The prototype system will be tested and compared to a conventional (non-adaptable) interface in subjects with SPI at a collaborative clinical site. Assistance by our speech and expert-AAC collaborators will ensure that all phases of technology development are patient-centric and usable in the context of clinical care. In Phase II we will build upon this proof-of-concept to design a smart-AAC system with automated optimization software that achieves dynamic learning which adapts to intra-individual changes in function through disease progression or training as well as inter-individual differences in motor impairments for a diverse set of users with spinal cord injury, traumatic brain injury, cerebral palsy, ALS, and other SPIs. The innovation is the first and only AAC technology that combines advancements in wearable-sensor access with interfaces that are autonomously optimized to the user, thereby reducing the resources and training needed to achieve effective person-centric communication in SPI, through improved HMI performance and reduced workload. This project addresses the fundamental mission of NIDCD (National Institute for Deafness and Communication Disorders) to provide a direct means of assisting communication for people with severe physical impairments caused by stroke, high level spinal cord injury, neural degeneration, or neuromuscular disease. Leveraging wearable access technology (which has barely been explored for AAC users), we will develop a first-of-its-kind adaptive tablet interface tailored to individual users through advanced movement classification algorithms. Through these efforts, we aim to provide an improved Human Machine Interface (HMI) that is able to accommodate varying degrees of inter- and intra-subject residual motor function and context dependent impairments to provide individuals with SPI the opportunity for improved societal integration and quality of life.",Adaptive & Individualized AAC,9907832,R43DC018437,"['Accelerometer', 'Address', 'American', 'Boston', 'Cerebral Palsy', 'Child', 'Cognitive', 'Communication', 'Communication Methods', 'Communication impairment', 'Computer software', 'Custom', 'Development', 'Devices', 'Diagnosis', 'Disease Progression', 'Ensure', 'Eye', 'Facial Muscles', 'Fatigue', 'Forehead', 'Gestures', 'Goals', 'Head', 'Head Movements', 'Health', 'Heterogeneity', 'Hospitals', 'Human Rights', 'Hybrids', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Individual Differences', 'Institutes', 'Intervention', 'Intuition', 'Learning', 'Linguistics', 'Manuals', 'Measures', 'Mediating', 'Methods', 'Mission', 'Motor', 'Motor Manifestations', 'Movement', 'Muscle', 'National Institute on Deafness and Other Communication Disorders', 'Nerve Degeneration', 'Neuromuscular Diseases', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Population Heterogeneity', 'Quality of life', 'Recurrence', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Resources', 'Series', 'Signal Transduction', 'Speech', 'Spinal cord injury', 'Stroke', 'Surface', 'System', 'Tablets', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Traumatic Brain Injury', 'United States National Aeronautics and Space Administration', 'Universities', 'User-Computer Interface', 'Variant', 'Work', 'Workload', 'alternative communication', 'base', 'classification algorithm', 'clinical care', 'clinical research site', 'communication device', 'deafness', 'design', 'experimental study', 'improved', 'innovation', 'kinematics', 'machine learning algorithm', 'mathematical model', 'motor impairment', 'novel', 'prototype', 'rehabilitation engineering', 'rehabilitation science', 'sensor', 'sensor technology', 'signal processing', 'technology development', 'touchscreen', 'two-dimensional', 'wearable device']",NIDCD,"ALTEC, INC.",R43,2019,224701,0.009830675669284554
"Dense life-log health analytics from wearable senors using functional analysis and Riemannian geometry The growth and acceptance of wearable devices (e.g., accelerometers) and personal technologies (e.g., smartphones), coupled with larger storage capacities, waterproofing, and more unobtrusive wear locations, has made long-term monitoring of behaviors throughout the 24-hour spectrum more feasible. Wearable devices relevant for human activity (e.g., GENEActiv accelerometer) contain several complementary sensors (accelerometers, gyro, heart- rate monitor etc.) and sample at high rates (e.g., 100Hz for accelerometer). These high-sampling rates and the long duration of capture result in life-log data that truly qualifies as multimodal and big time-series data. The challenges and opportunities involved in fully harvesting these types of data, for widely applicable interventions, suggest that an interdisciplinary approach spanning mathematical sciences, signal processing, and health is needed. Our innovation includes the use of functional-data analysis tools to represent and process the dense time-series data. Functional data analysis is then integrated into machine learning and pattern discovery algorithms for activity classification, prediction of attributes, and discovery of new activity classes. We anticipate that the proposed framework will lead to new insights about human activity and its impact on health outcomes. This interdisciplinary project builds on several research activities of the team. Our past work includes: a) new mathematical developments for computing statistics on time-series data viewed as elements of a function-spaces, b) algorithms for activity recognition that integrate the function-space techniques, and c) data from long-term observational studies of human activity from multimodal sensors. The new work we propose addresses the unique mathematical and computational challenges posed by densely multimodal, long-term, densely-sampled Iifelog big-data in a comprehensive framework. The fusion of ideas from human activity modeling, functional-analysis, geometric metrics, and algorithmic machine learning, present unique opportunities for fundamental advancement of the state-of-the-art in objective measurement and quantification of behavioral markers from wearable devices. The proposed approach also brings to fore: a) new mathematical developments of elastic metrics over multi-modal time-series data, b) comparing sequences evolving on different feature manifolds, c) estimation of quasi- periodicities, d) and a new generation of machine-learning and pattern discovery algorithms. The mathematical and algorithmic tools proposed have the potential to significantly advance how wearable data from contemporary devices with high-sampling rates and large storage capabilities are represented, processed, and transformed into accurate inferences about human activity. Wearable devices are becoming more widely adopted in recent years for general health and recreational uses by the broad populace. This research will result in improved algorithms to process the data available from such wearable devices. The long-term goal of the research is to enable personalized home-based physical activity regimens for conditions such as stroke and diabetes. n/a",Dense life-log health analytics from wearable senors using functional analysis and Riemannian geometry,9903672,R01GM135927,"['Accelerometer', 'Activity Cycles', 'Algorithms', 'Arrhythmia', 'Awareness', 'Behavior', 'Behavior monitoring', 'Big Data', 'Body Temperature', 'Cellular Phone', 'Chemotherapy-Oncologic Procedure', 'Collection', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Devices', 'Dust', 'Encapsulated', 'Energy Metabolism', 'Geometry', 'Glean', 'Goals', 'Growth', 'Health', 'Health Status', 'Healthcare', 'Heart', 'Heart Rate', 'Home environment', 'Hour', 'Human', 'Individual', 'Lead', 'Life', 'Location', 'Mathematics', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Movement', 'National Institute of General Medical Sciences', 'Outcome', 'Participant', 'Pattern', 'Periodicity', 'Physical activity', 'Population', 'Research', 'Research Project Grants', 'Rest', 'Sampling', 'Series', 'Signal Transduction', 'Swimming', 'System', 'Techniques', 'Time', 'United States National Institutes of Health', 'Vision', 'Walking', 'Water', 'Work', 'base', 'circadian', 'design', 'diaries', 'health related quality of life', 'heart rate monitor', 'insight', 'interest', 'mathematical methods', 'metastatic colorectal', 'multimodality', 'personalized intervention', 'post stroke', 'programs', 'sensor', 'statistics', 'tool', 'wearable device']",NIGMS,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,316425,0.007558217446197705
"Development/Commercialization of a Sensing Device to Detect Vaping Development/Commercialization of a Sensing Device to Detect Vaping Summary The use of e-cigarettes or vaping has been steadily increasing since its introduction. While potentially a tool to wean cigarette smokers from combustible tobacco, one consequence of the introduction of these devices has been the adoption of vaping by adolescents. While companies that offer vaping instruments for sale note that their material is directed to adults and intended as an aid for smoking cessation, recent reports have demonstrated that middle school and high school students in many countries, some as young as thirteen, have taken to vaping. Data analysis from a 2015 study in the U.S. indicated that 16% of high school students and 5% of middle school students reported vaping in the past thirty days. Most researchers speculated that the number of users would increase from these baselines and evidence indicates that this prediction is correct. Anecdotal evidence indicates that vaping in middle school and high school bathrooms is a major problem. FreshAir Sensor currently sells tobacco and marijuana smoking sensors along with 24/7 monitoring of the devices. The company has leveraged the knowledge of sensor development to produce preliminary components of an early stage sensing system capable of detecting vaping. Preliminary data to demonstrate this accomplishment is provided. The fast track research described in this proposal will enable the optimization of the sensor as well as commercialization of the resulting instrument in minimal time. The need to reduce and eventually eliminate adolescent vaping is urgent. The deployment of the proposed device in schools and other educational institutions will eliminate vaping during school hours and will, therefore, contribute to improvements in the overall health of adolescents by curtailing nicotine intake. Narrative Vaping has become a problem in schools with students, in steadily increasing numbers, using bathrooms and other less monitored spaces to indulge in the use of the newest vaping hardware. FreshAir Sensor is developing a sensor to detect vaping in otherwise unmonitored spaces. The use of this sensing system has the potential to reduce and, eventually, eliminate vaping behavior in schools, thereby reducing the harmful effects of nicotine in adolescents.",Development/Commercialization of a Sensing Device to Detect Vaping,9838650,R44DA049595,"['Adolescent', 'Adoption', 'Adult', 'Air', 'Algorithms', 'Behavior', 'Chemicals', 'Cigarette Smoker', 'Country', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Dose', 'Effectiveness', 'Electronic cigarette', 'Electronics', 'Engineering', 'Environmental Risk Factor', 'Event', 'Exposure to', 'Fatigue', 'Film', 'Goals', 'High School Student', 'Hour', 'Humidity', 'Institution', 'Intake', 'Knowledge', 'Laboratories', 'Longevity', 'Marijuana', 'Marijuana Smoking', 'Methods', 'Middle School Student', 'Minor', 'Modality', 'Monitor', 'Morphology', 'Neurotoxins', 'Nicotine', 'Phase', 'Polymers', 'Production', 'Property', 'Public Housing', 'Reporting', 'Research', 'Research Personnel', 'Sales', 'Schools', 'Science', 'Smoking', 'Specificity', 'Students', 'System', 'Temperature', 'Testing', 'Time', 'Tobacco', 'Tobacco smoking behavior', 'Weaning', 'adolescent health', 'base', 'commercialization', 'design', 'detector', 'electronic cigarette use', 'high school', 'instrument', 'junior high school', 'machine learning algorithm', 'monitoring device', 'prototype', 'research and development', 'response', 'sensor', 'sensor technology', 'smoking cessation', 'tool', 'vaping', 'vapor']",NIDA,FRESHAIR SENSOR CORPORATION,R44,2019,225000,0.016038133817669498
"Independent Exoskeleton-Use through Robust Stand-to-Sit Safety Project Summary/Abstract Innovative Design Labs (IDL) proposes to create a system for the sensing and control of stand-to-sit motions of a wearable bionics suit. Currently 5.6 million people in the US have impaired mobility from a number of different causes. The primary means of mobility for many of these patients is the wheelchair as it has been for most of the last 50 years. Despite all the benefits introduced by widespread use of the wheelchair, it remains a less than ideal mobility solution. Exoskeleton suits have the potential to empower individuals with impaired mobility with an alternative to wheelchairs that allows them to stand up and walk independently within their home and community has the potential to more fully reintegrate these individuals into society while also further improving their health and quality of life. For exoskeletons to gain acceptance in every-day independent home and community use, many control and safety related functionalities still need to be addressed. Our proposal seeks to address one of the gaps in allowing for independent use of exoskeletons in the home and community, namely, functionality to transition from standing to sitting in a safe manner. The proposed work will provide exoskeleton users with the new ability to independently sit down without assistance and confidence in being able to do so without falling and risking possible injuries. It aims to significantly change the way exoskeletons work thereby facilitating their adoption into the market and directly impacting the lives of individuals with disabilities. Project Narrative Exoskeletons can provide patients with SCI, stroke, and other types of impaired mobility access to extended duration, gravity dependent ambulation that can directly combat the risks associated with physical deconditioning. There are benefits for exoskeleton-use to gain widespread acceptance in every-day, independent home and community settings. Currently, exoskeletons are not approved for independent-use because functionalities like transferring from standing-to-sitting requires continuous assistance from caregivers.",Independent Exoskeleton-Use through Robust Stand-to-Sit Safety,9560683,R44AG057267,"['3-Dimensional', 'Activities of Daily Living', 'Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Area', 'Bionics', 'Caliber', 'Caregivers', 'Chicago', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Country', 'Custom', 'Development', 'Disabled Persons', 'Emerging Technologies', 'Engineering', 'Environment', 'Evaluation', 'Fall injury', 'Feedback', 'Force of Gravity', 'Gait', 'Health', 'Height', 'Home environment', 'Hospitals', 'Imaging technology', 'Impairment', 'Individual', 'Injury', 'Institutes', 'Letters', 'Mechanics', 'Metric System', 'Motion', 'Patients', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Production', 'Quality of life', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Rest', 'Risk', 'Robotics', 'Safety', 'Scientist', 'Small Business Innovation Research Grant', 'Societies', 'Spinal cord injury patients', 'Stroke', 'Surface', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Validation', 'Walking', 'Wheelchairs', 'Work', 'blind', 'combat', 'community setting', 'critical period', 'deconditioning', 'design', 'exoskeleton', 'experience', 'fall risk', 'falls', 'human study', 'improved', 'innovation', 'member', 'prototype', 'rehabilitation technology', 'robot exoskeleton', 'stroke patient']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2019,806285,-0.002413129457819139
"Active Sensation during Odor-Guided Navigation in Mice PROJECT SUMMARY We often consider our movements a result of sensory processing – sensation guides behavior. However, animals selectively shape future sensory input through their own actions in a process known as active sampling. Thus, action and sensation are inextricably linked. Despite this, much of the research done on sensory processing restricts movement, most commonly via head fixation. To access sensorimotor processing during more natural behavior, we will study olfactory navigation in freely-moving mice. The olfactory system is ideal for studying sensory sampling, because of its ethological relevance for mammalian foraging and the dynamic nature of airborne odor stimuli. The proposed research will determine the sampling strategies of olfactory search and reveal the underlying circuitry that connects sensation with motion. Aim 1. It is unknown how rodents navigate dynamic plumes of odorant towards an odor source. In this aim, we will identify, analyze, and model active sensing behaviors that occur during increasingly difficult navigation tasks and with single nostrils occluded. These experiments will test the hypothesis that olfactory navigation works as a sensorimotor closed-loop system, where animals optimize sampling behaviors for the current stimulus conditions. These behavioral studies will lay the foundation for investigations of sensorimotor processing in dynamic olfactory scenes. Aim 2. To determine how sampling movements shape sensation, we will monitor neural activity during active sensory behavior. During odor tracking, we will electrophysiologically record in the olfactory bulb, a bottleneck through which all sensory input passes. We will determine the sensory history dependence of active sampling and, in doing so, reveal part of the underlying circuitry that connects motion with sensation. These experiments will test the hypothesis that sampling movements are sensory history dependent. To our knowledge, sampling movements and sensory activity have never been simultaneously recorded during olfactory navigation. This research will advance our understanding of the interplay between sensation and motion during natural behavior. PROJECT NARRATIVE Deficits in sensory motor communication are a major contributor to prevalent neurological disorders such as schizophrenia and Parkinson's disease. Our assay of olfactory navigation will model the interaction between sensation and movement and identify the circuitry through which movements are decided by sensory input. Discovering mechanisms of sensorimotor integration are the key to a better understanding of sensory processing in these disorders, since sensation and action are inextricably linked.",Active Sensation during Odor-Guided Navigation in Mice,9764342,F31DC016799,"['Animals', 'Anterior nares', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Biological Assay', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Disease', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Foundations', 'Future', 'Genetic', 'Head', 'Implant', 'Intake', 'Intervention Studies', 'Investigation', 'Link', 'Modeling', 'Monitor', 'Motion', 'Motor', 'Movement', 'Mus', 'Nature', 'Neurons', 'Nose', 'Odors', 'Olfactory Pathways', 'Output', 'Parkinson Disease', 'Pattern', 'Perception', 'Positioning Attribute', 'Process', 'Recording of previous events', 'Research', 'Respiration', 'Rewards', 'Rodent', 'Sampling', 'Schizophrenia', 'Sensory', 'Shapes', 'Smell Perception', 'Source', 'Stereotyping', 'Stimulus', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Vertebrates', 'Work', 'base', 'behavioral study', 'design', 'experimental study', 'insight', 'machine vision', 'nervous system disorder', 'olfactory bulb', 'olfactory stimulus', 'relating to nervous system', 'sample fixation', 'sensory input', 'sensory stimulus', 'sensory system', 'tool']",NIDCD,UNIVERSITY OF OREGON,F31,2019,34022,-0.005959853994788
"Intuitive, complete neural control of tablet computers for communication Project Summary Conventional augmentative and alternative communication (AAC) devices for people with severe speech and motor impairments (SSMI) rely on residual motor function, inherently limiting communication throughput. Commercially available AAC solutions require daily caregiver setup, need frequent recalibration often from a technically savvy caregiver, are often unable to be used in dark lighting conditions, and can encumber or fatigue important remaining physical abilities. Furthermore, for people with progressive motor dysfunction due to amyotrophic lateral sclerosis (ALS), even the most well-designed AAC devices will eventually fail as movements become unreliable. For people with brainstem stroke, ALS, and other disorders causing locked-in syndrome (LIS) or SSMI, brain-computer interfaces (BCIs) hold promise as a method of enabling communication that does not rely upon speech or voluntary movement. In prior NIDCD-supported research, our BrainGate research team provided early proofs of principle of a powerful intracortical brain-computer interface (iBCI) that decodes movement intentions directly from brain activity. This technology has allowed people to control a cursor on a computer screen for communication simply by imagining movements of their own arm. The proposed NIDCD U01 clinical research will further the development and testing of a fully implanted iBCI that could provide robust, intuitive control of industry-grade communication apps for people with LIS or SSMI. By leveraging the ongoing pilot clinical trials of the investigational BrainGate system, we aim to (1) improve the robustness and accuracy of neurally actuated point-and click, in part through the translation of neuronal activity from human premotor and motor cortex, (2) expand the number of input dimensions to tablet computers available via neural activity, allowing intended hand gesture commands to control communication apps on touch-screen tablet computers, and (3) rigorously compare the performance of the investigational BrainGate system to trial participants’ conventional AAC systems with respect to communication competence, information throughput, user preference and outcomes measures. By incorporating the feedback of six individual participants with paralysis, this feasibility trial will optimize a powerful iBCI for communication and will establish the metrics needed for a subsequent pivotal trial of a fully implanted, always-available iBCI communication system for people with SSMI. Project Narrative People with brainstem stroke, advanced amyotrophic lateral sclerosis (ALS, also known as Lou Gehrig’s disease), or other disorders can become unable to move or speak despite being awake and alert. In this project, we seek to further translate knowledge about interpreting brain signals related to movement, and to further develop an intracortical brain-computer interface (iBCI) that could restore rapid and intuitive use of communication apps on tablet computers by people with paralysis.","Intuitive, complete neural control of tablet computers for communication",9729335,U01DC017844,"['Amyotrophic Lateral Sclerosis', 'Augmentative and Alternative Communication', 'BRAIN initiative', 'Brain', 'Brain Stem Infarctions', 'Caregivers', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communication', 'Competence', 'Computer software', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Family Caregiver', 'Fatigue', 'Feedback', 'Friends', 'Gestures', 'Hand', 'Home environment', 'Human', 'Human Activities', 'Implant', 'Individual', 'Industry', 'Injury', 'Intention', 'Interactive Communication', 'Intuition', 'Investigation', 'Knowledge', 'Language', 'Lighting', 'Location', 'Locked-In Syndrome', 'Methods', 'Modeling', 'Modernization', 'Motor', 'Motor Cortex', 'Movement', 'Mus', 'National Institute on Deafness and Other Communication Disorders', 'Neurons', 'Outcome Measure', 'Paralysed', 'Participant', 'Pattern', 'Performance', 'Research', 'Research Support', 'Residual state', 'Signal Transduction', 'Speech', 'Speed', 'Surveys', 'System', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Translating', 'Translations', 'United States National Institutes of Health', 'Wireless Technology', 'arm', 'awake', 'base', 'brain computer interface', 'communication device', 'deep learning', 'design', 'expectation', 'experience', 'feasibility trial', 'first-in-human', 'flexibility', 'improved', 'innovation', 'long short term memory network', 'motor disorder', 'motor impairment', 'neural implant', 'neuroregulation', 'nonhuman primate', 'novel', 'phrases', 'preference', 'relating to nervous system', 'tool', 'touchscreen', 'two-dimensional']",NIDCD,BROWN UNIVERSITY,U01,2019,837287,-0.015107124011290335
"Lightweight optoimpedance sensors enabling early detection of the physiological response to injury and illness Abstract Early detection of ongoing hemorrhage (OH) before onset of shock is a universally acknowledged great unmet need, and particularly important after trauma. Delays in the detection of OH are associated with a “failure to rescue” and a dramatic deterioration in prognosis once the onset of clinically frank shock has occurred. While uniplex noninvasive technologies have failed to detect or diagnose complex disease states, we have demonstrated the superiority of multiplex approaches in silico. The goal of this STTR project is to develop a commercially viable optoimpedance sensor-based system that combines state-of-the-art noninvasive sensing technologies and advanced multivariable statistical algorithms. Phase I will involve three Aims: 1) D​esign, Fabricate and Test Opto-Impedance oPiic sensors, 2) Develop of Mobile App, Data and ML Pipeline on Secure Cloud, and 3) Evaluate oPiics on an Unanesthetized Upright Porcine Hemorrhage Model. By derisking the hardware challenges, we will be well-positioned for a Phase II application to optimize oPiic design and manufacturing, fold-in predictive algorithms under current development with DOD support, and validate with a clinical trial in critical care setting. Project Narrative We have demonstrated that a multiplex approach is superior to predicting shock compared to single clinical devices alone. During a mass-casualty event, a predictive tool would need to be deployed widely, since only a fraction of individuals will have ongoing hemorrhage that will progress to decompensated shock. Optical and bioimpedance signals are critical indicators of muscle hemodynamics and electrolyte balance likely to be modified in the period leading up to shock. No commercial device exists that provides continuous, low-power, low-cost monitoring of these signals with characteristics suitable for integration with the multiplexing approach. This STTR application seeks Phase I funding to commercialize an opto-impedance sensor, called the ‘oPiic’, that will address this unmet need.",Lightweight optoimpedance sensors enabling early detection of the physiological response to injury and illness,9909081,R41EB029284,"['Address', 'Adhesives', 'Algorithms', 'Animals', 'Back', 'Benchmarking', 'Cardiovascular Physiology', 'Caring', 'Characteristics', 'Classification', 'Clinical', 'Clinical Trials', 'Complex', 'Computer Simulation', 'Computer software', 'Conscious', 'Critical Care', 'Data', 'Data Set', 'Detection', 'Deterioration', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'Disasters', 'Disease', 'Early Diagnosis', 'Electrolyte Balance', 'Event', 'Faculty', 'Failure', 'Family suidae', 'Fiber Optics', 'Funding', 'General anesthetic drugs', 'Goals', 'Hemorrhage', 'Human', 'Hydration status', 'Individual', 'Injury', 'Intensive Care', 'Learning', 'Life', 'Location', 'Measurement', 'Medical', 'Medical Device', 'Metabolism', 'Military Personnel', 'Modality', 'Modeling', 'Monitor', 'Muscle', 'Noise', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Patients', 'Phase', 'Physiological', 'Positioning Attribute', 'Postoperative Care', 'Protocols documentation', 'Resolution', 'Risk', 'Sampling', 'Secure', 'Shock', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specialist', 'Spectrum Analysis', 'Statistical Algorithm', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'Triage', 'Trust', 'Validation', 'Vertebrates', 'analog', 'base', 'clinical development', 'clinically relevant', 'college', 'cost', 'deep learning', 'design', 'effective intervention', 'electric impedance', 'electrical property', 'hemodynamics', 'instrument', 'light weight', 'mass casualty', 'member', 'miniaturize', 'mobile application', 'optical sensor', 'optimal treatments', 'outcome forecast', 'performance tests', 'portability', 'prediction algorithm', 'predictive tools', 'preservation', 'programs', 'response', 'response to injury', 'sensor', 'sensor technology', 'tissue oxygenation', 'wearable device']",NIBIB,"MULTIVARIATE SYSTEMS, INC.",R41,2019,155282,0.02522622015377376
"A Novel, Low-Cost Device to Guide Peripherally Inserted Central Catheter (PICC) Line Placement Abstract In the United States alone, more than three million peripherally inserted central catheters (PICCs) are placed each year to provide IV therapies, where navigation through the venous system is typically performed blind, or without navigation guidance. Improper PICC placement is relatively common, is costly, and has serious complications for critically-ill patients. Unfortunately, under blind placement 30-55% of PICC tips are not optimally placed on the first attempt and require repositioning, which has an average direct cost of $223 per patient and often necessitates the removal and reinsertion of the catheter line that carries a 4-6% risk of pneumothorax. Moreover, approximately 17% of these improperly positioned PICCs are placed into the right atrium, which is associated with a multitude of life-threatening complications. Improper placement of PICCs also often requires referral to an interventional radiologist for fluoroscopic-guided central line placement, which is expensive ($1,000) and requires more radiation exposure for the patient. Not surprisingly, over half of all PICCs are administered to patients over the age of 60. Therefore, safe and accurate PICC placement is critical for providing high-quality care to older Americans. Despite serious adverse events associated with blind placement of PICC lines, current vascular access systems have not been widely adopted. The Teleflex ARROW® G4 VPS and the Bard Sherlock 3CG® TCS are PICC guidance systems that employ ECG for positioning the PICC tip into the correct location: the region that includes the lower superior vena cava (SVC) and cavoatrial junction (CAJ). While these procedures often limit the need for a confirmatory X-ray, they have poor and variable successful placement rates (44-84%), are 30-70% more expensive than standard PICCs, require skilled staff, and have significantly longer procedure times as compared to standard, blind PICC placement. Additionally, these guidance systems rely on the use of ECG, which is ineffective for patients with cardiac arrhythmias, a condition that affects approximately 16% of all patients requiring a PICC line. To address the need for accurate, safe, and cost- effective PICC placement, Piccolo Medical has developed the Smart PICC™ system, a point-of-care catheter system that uses unique hemodynamic signatures of different vascular regions for real-time vascular access guidance into the SVC/CAJ. The goals of this Phase II proposal are to validate the accuracy of the Piccolo Smart PICC™ for navigation and placement of a PICC tip into the SVC or CAJ for adult patients with and without cardiac arrhythmias. First, we will verify the sensitivity of the Smart PICC™ system algorithm to identify correct PICC placement in adult patients with both normal and altered cardiac rhythms (Aim 1). Second, we will compare the accuracy of the Smart PICC™ system to the most widely used catheter navigation system (BD’s Sherlock 3CG® TCS) in a head-to-head superiority study (Aim 2).The data obtained will support FDA 510(k) clearance and will allow us to commercialize the system within ~2.5 years of the funding of this proposal. Narrative Peripherally inserted central catheters (PICCs) are widely used to provide life-sustaining intravenous therapies, where navigation through the venous system is typically performed blind, or without navigation guidance. Commercially available PICC navigation systems can be effective, but have limitations that have impeded adoption into the clinic. We propose an inexpensive, easily operated catheter system for real-time vascular access guidance that addresses the limitations of current systems.","A Novel, Low-Cost Device to Guide Peripherally Inserted Central Catheter (PICC) Line Placement",9919215,R44AG060793,"['Address', 'Adopted', 'Adoption', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'American', 'Anatomy', 'Area Under Curve', 'Arrhythmia', 'Automobile Driving', 'Blinded', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Catheters', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Critical Illness', 'Data', 'Detection', 'Devices', 'Direct Costs', 'Distal', 'EKG P Wave', 'Electrocardiogram', 'Excision', 'Family suidae', 'Funding', 'Future', 'Goals', 'Head', 'Heart Atrium', 'Heart Valves', 'Infusion procedures', 'Intervention', 'Intravenous', 'Lead', 'Life', 'Location', 'Measures', 'Medical', 'Modeling', 'Multi-Institutional Clinical Trial', 'Myocardial', 'Navigation System', 'Nurses', 'Patients', 'Perforation', 'Performance', 'Peripheral', 'Phase', 'Pneumothorax', 'Positioning Attribute', 'Procedures', 'Quality of Care', 'Radiation exposure', 'Randomized', 'Real-Time Systems', 'Receiver Operating Characteristics', 'Research', 'Resolution', 'Right atrial structure', 'Risk', 'Roentgen Rays', 'Savings', 'Serious Adverse Event', 'Signal Transduction', 'Superior vena cava structure', 'System', 'Technology', 'Thermodilution', 'Thoracic Radiography', 'Thrombus', 'Time', 'Training', 'United States', 'Venous system', 'Work', 'base', 'blind', 'cohort', 'cost', 'cost effective', 'follow-up', 'heart rhythm', 'hemodynamics', 'improved', 'in vivo', 'innovation', 'machine learning algorithm', 'novel', 'point of care', 'pre-clinical', 'radiologist', 'sensor']",NIA,"PICCOLO MEDICAL, INC.",R44,2019,915143,-0.00035839262110112433
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9507909,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Grain', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'cognitive development', 'computerized', 'cost', 'deep learning', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'sensor technology', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2018,203125,-0.010903167913208972
"Smartphone phenotype collection for diagnostic screening of mild cognitive impairment Project Summary This project addresses a critical need for early detection of mild cognitive impairment (MCI) and other Alzheimer's-related dementias (ADRD). Advances in smartphone hardware, computer vision, and machine learning have enabled the possibility of producing smartphone-based cognitive testing applications able to collect electronic sensor data and transform it into highly informative phenotypes that can serve as early indicators of future disease progression. In this project, we aim to develop a revolutionary new smartphone- based cognitive testing platform, called CTX, that will enable the rapid development and deployment of smartphone-based tests that can capture raw sensor streams in a synchronized fashion, subsample and compress the combined streams, and transmit them to a cloud server for subsequent analysis and modeling. CTX will provide a high-level application development framework that will significantly reduce the time and technical knowledge required to produce a smartphone-based cognitive testing application by providing an application programming interface (API) that enables developers to simply declare what sensor data should be collected and when. The framework will handle all the details of collecting the sensor data, synchronizing it, and transmitting it to a back-end server. The API will also have a variety of other high-level features to facilitate development of cognitive test apps. To demonstrate the feasibility of our vision for CTX, in Aim 1 of this project we will develop the software framework, back-end server software and a prototype smartphone app to exercise and validate many of the platform's features. For Aim 2, we will develop three different tests for this app to test saccade (eye movement) latency, verbal recall, and wrist mobility, each collecting a different type of sensor data (video, audio, and inertial measurement). These tests were selected because their results have been been shown to be predictive of MCI. We will implement phenotype extraction pipelines that employ advanced signal processing, machine learning, and computer vision algorithms to extract the target phenotypes from the sensor data collected for these tests and demonstrate they operate with sufficient accuracy to replicate published experimental designs. Successful completion of this project will eliminate the need for expensive and cumbersome phenotype collection equipment (e.g., eye tracking stations) and create the possibility of generating data from which MCI onset can be predicted. Data collected in Phase II via these and other such tests will enable us to apply our machine learning expertise to produce models able to predict transition to MCI that are both sensitive and specific, transforming any smartphone into an MCI risk assessment tool available for at-home use by millions of people. Project Narrative This NIH Phase I project will address the critical need for early detection of Alzheimer's Disease (AD) and Alzheimer's-related dementias (ADRD) by developing a revolutionary new smartphone-based cognitive testing platform that will provide individuals with an ongoing status of their cognitive health. Doctors who are given access to the results of these tests will be able to monitor patients more closely and provide more timely diagnoses. By studying test results from many people, researchers may someday be able to identify patterns that can distinguish mild cognitive impairment from normative age-related cognitive decline.",Smartphone phenotype collection for diagnostic screening of mild cognitive impairment,9679400,R43AG062072,"['Achievement', 'Address', 'Adult', 'Age', 'Age-associated memory impairment', 'Algorithms', 'Alzheimer disease detection', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Apple', 'Assessment tool', 'Back', 'Big Data', 'Cellular Phone', 'Cognitive', 'Collection', 'Computer Vision Systems', 'Computer software', 'Cyclophosphamide', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic tests', 'Disease Progression', 'Early Diagnosis', 'Elderly', 'Emotional', 'Equipment', 'Exercise', 'Exhibits', 'Experimental Designs', 'Eye', 'Eye Movements', 'Face', 'Facial Expression', 'Forearm', 'Frequencies', 'Future', 'Genetic Risk', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Image', 'Individual', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Memory impairment', 'Methods', 'Modeling', 'Monitor', 'Patient Monitoring', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Publishing', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Risk Assessment', 'Rotation', 'Saccades', 'Scanning', 'Secure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Software Framework', 'Software Tools', 'Stream', 'Tablets', 'Telephone', 'Test Result', 'Testing', 'Time', 'United States National Institutes of Health', 'Vision', 'Visuospatial', 'Work', 'Wrist', 'Yang', 'age related', 'age related cognitive change', 'application programming interface', 'base', 'cloud platform', 'cognitive development', 'cognitive task', 'cognitive testing', 'cohort', 'cost', 'crowdsourcing', 'data modeling', 'diagnostic screening', 'interest', 'markov model', 'mild cognitive impairment', 'predictive modeling', 'prototype', 'response', 'screening', 'sensor', 'signal processing', 'smartphone Application', 'software development', 'success']",NIA,"PARABON NANOLABS, INC.",R43,2018,394297,-0.013565804841888606
"Machine-learning based control of functional electrical stimulation PROJECT SUMMARY/ABSTRACT Functional electrical stimulation involves artificial activation of paralyzed muscles with implanted electrodes and has been used successfully to improve the ability of tetraplegics to perform movements important for daily activities. The range of motor behaviors that can be generated by functional electrical stimulation, however, is limited to a relatively small set of preprogrammed movements such as hand grasp and release. A broader range of movements has not been implemented because of the substantial challenge associated with identifying the patterns of muscle stimulation needed to elicit specified movements. To address this limitation, we have developed machine-learning based algorithms that can predict patterns of muscle activity associated with a wide range of complex limb movements. In addition, we have devised a method whereby predicted patterns of muscle activity can then be transformed into stimulus pulse patterns needed to evoke movements in paralyzed limbs. Our goal for this project is to determine whether these approaches, when applied to temporarily paralyzed non-human primates, can be used to produce: 1) a wide range of movements of the hand throughout peri-personal reach space, and 2) configuration of the hand and fingers into a variety of shapes needed to interact with diverse objects in the environment. If successful, this approach would greatly expand the repertoire of motor behaviors available to individuals paralyzed because of spinal cord injury or stroke. Furthermore, this system ultimately might serve as the requisite interface between brain-derived trajectory information and functional electrical stimulation systems needed to realize a self-contained and self- controlled upper limb neuroprosthetic. PROJECT NARRATIVE The goal of this project is to develop methods to artificially activate and control paralyzed muscles with electrodes implanted in muscles. This effort will contribute to the restoration of voluntary limb movements in individuals paralyzed because of spinal cord injury or stroke.",Machine-learning based control of functional electrical stimulation,9593999,R01NS102259,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Animals', 'Back', 'Behavior', 'Brain', 'Chronic', 'Complement', 'Complex', 'Data', 'Digit structure', 'Elbow', 'Electric Stimulation', 'Electrodes', 'Elements', 'Environment', 'Error Sources', 'Experimental Models', 'Feedback', 'Fingers', 'Forearm', 'Goals', 'Hand', 'Health Benefit', 'Human', 'Implanted Electrodes', 'Individual', 'Intramuscular', 'Joints', 'Lifting', 'Limb structure', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Motor', 'Movement', 'Muscle', 'Muscle Contraction', 'Muscle Fatigue', 'Output', 'Paralysed', 'Patients', 'Pattern', 'Personal Space', 'Physiologic pulse', 'Quadriplegia', 'Shapes', 'Shoulder', 'Signal Transduction', 'Skeletal Muscle', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Training', 'Upper Extremity', 'Wrist', 'arm', 'artificial neural network', 'awake', 'base', 'brain machine interface', 'design', 'experience', 'finger movement', 'grasp', 'hand grasp', 'human subject', 'improved', 'insight', 'kinematics', 'limb movement', 'neuroprosthesis', 'nonhuman primate', 'response', 'restoration', 'robotic device', 'scapula']",NINDS,UNIVERSITY OF ARIZONA,R01,2018,293386,0.02230006072403384
"User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control ABSTRACT Approximately 41,000 individuals live with upper-limb loss (loss of at least one hand) in the US. Fortunately, prosthetic devices have advanced considerably in the past decades with the development of dexterous, anthropomorphic hands. However, potentially the most promising used control strategy, myoelectric control, lacks a correspondingly high-level of performance and hence the use of dexterous hands remains highly limited. The need for a complete overhaul in upper limb prosthesis control is well highlighted by the abandonment rates of myoelectric devices, which can reach up to 40% in the case of trans-humeral amputees. The area of research that has received the most focus over the past decade has been “pattern recognition,” which is a signal processing based control method that uses multi-channel surface electromyography as the control input. While pattern recognition provides intuitive operation of multiple prosthetic degrees of freedom, it lacks robustness and requires frequent, often daily calibration. Thus, it has not yet achieved the desired clinical acceptance. Our team proposes clinical translation of a novel highly adaptive upper limb prosthesis control system that incorporates two major advances: 1) machine learning (robust classification by implementing a non-boundary based algorithm), and 2) training by retrospectively incorporating user data from activities of daily living (ADL). The proposed system will enable machine intelligence with user input for prosthesis control. Our work is organized as follows: Phase I: (a) First, we will implement a fundamentally new machine intelligence technique, Extreme Learning Machine with Adaptive Sparse Representation Classification (EASRC), that is more resilient to untrained noisy conditions that users may encounter in the real-world and requires less data than traditional myoelectric signal processing. (b) In parallel, we will implement an adaptive learning algorithm, Nessa, which allows users to relabel misclassified data recorded during use and then update the EASRC classifier to adapt to any major extrinsic or intrinsic changes in the signals. Taken together, EASRC and Nessa comprise the Retrospectively Supervised Classification Updating (RESCU) system. Once, the RESCU implementation is complete, we will optimize the system through a joint effort with Johns Hopkins University, and complete an iterative benchtop RESCU evaluation with a focus group of 3 amputee subjects and their prosthetists. Phase II: Verification and validation of RESCU will be completed, culminating in third-party validation testing and certification. Finally, we will complete a clinical assessment including self-reporting subjective measures, and real-world usage metrics in a long-term clinical study. PROJECT NARRATIVE In this project, we aim to empower the user by bringing them into the control loop of their prosthesis and improve the stability of their control strategy over time. Specifically, we implement to a robust classifier, an adaptive learning algorithm, and a smartwatch interface, which allows the user to teach their device when it misunderstands the commands that the user is sending to control the prosthesis. This will result in improved control without cumbersome or time-consuming effort on the part of the user and, more importantly, we hope that it will give the user a greater sense of empowerment and ownership over their prosthesis.",User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control,9622537,U44NS108894,"['Activities of Daily Living', 'Adoption', 'Algorithms', 'Amputees', 'Area', 'Artificial Intelligence', 'Calibration', 'Certification', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Communication', 'Data', 'Development', 'Devices', 'Electromyography', 'Evaluation', 'Focus Groups', 'Freedom', 'Goals', 'Hand', 'Individual', 'Intuition', 'Joints', 'Label', 'Limb Prosthesis', 'Machine Learning', 'Measures', 'Methods', 'Outcome', 'Ownership', 'Patient Self-Report', 'Pattern Recognition', 'Performance', 'Phase', 'Prosthesis', 'Research', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Supervision', 'Surface', 'Surveys', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'Upper Extremity', 'Validation', 'Work', 'adaptive learning', 'base', 'clinical translation', 'empowerment', 'functional improvement', 'improved', 'innovation', 'myoelectric control', 'novel', 'operation', 'programs', 'prospective', 'prosthesis control', 'satisfaction', 'signal processing', 'verification and validation']",NINDS,"INFINITE BIOMEDICAL TECHNOLOGIES, LLC",U44,2018,216724,0.026917327541462074
"PostureCheck: A vision-based compensatory-posture-detection tool to enhance performance of the BURT® upper-extremity stroke-therapy device Summary / Abstract  This Small Business Innovation Research (SBIR) Phase-I project proposes the development of an image- processing-based tool, named PostureCheck™, aimed at automatically detecting when patients perform undesirable compensatory movements during robot-assisted upper-limb rehabilitation exercises. The system will be based on a standard video camera (e.g., GoPro) that will be used to capture the movements of the subject.  The automatic detection of undesirable compensatory movements is especially important when patients use a rehabilitation robotic system with minimum supervision, i.e. when a single therapist oversees the therapeutic sessions of multiple patients simultaneously. In this context, PostureCheck™ may be capable of tracking robot-assisted rehabilitation exercises and enable feedback modalities to discourage the performance of undesirable compensatory movements.  Our long-term goal is to integrate PostureCheck™ with the Barrett Upper-extremity Robotic Trainer - BURT®, which we developed with special emphasis on stroke rehabilitation. The combination of PostureCheck™ with the BURT® device would be ideally suited for deployment in “Robotic Gyms”, where a single therapist oversees the therapeutic sessions of several patients simultaneously, thus allowing rehabilitation centers to offer high-dosage, high-intensity interventions despite the limited number of therapists currently available in the US.  To demonstrate the feasibility of the proposed concept, we will develop PostureCheck™ to detect the most common compensatory movements automatically. To achieve this goal, we will rely on recently developed artificial intelligence (AI) methods referred to as Deep Learning. These methods have recently broken records in the human-posture analysis, joint-skeleton detection, and recognition of human activities using a single inexpensive camera. The proposed video-based PostureCheck™ tool will be the first system to exploit the capabilities of hybrid Deep Neural Networks, for real-time detection of compensatory movements during robot- assisted rehabilitation.  The proposed SBIR Phase-I activities are organized in three aims. In Aim 1, feedback from rehabilitation experts at Spaulding Rehabilitation Hospital will be used to collect video data and to label compensatory movements observed during the performance of robot-assisted rehabilitation exercises by using the BURT® system. In Aim 2, Deep Learning techniques will be used to develop a robust detection of undesirable compensatory movements during the performance of robot-assisted rehabilitation exercises. Finally, in Aim 3, the algorithms developed in Aim 2 will be optimized. Specifically, we will test implementations that are suitable to generate real-time feedback. Computationally efficient implementations of the algorithms will enable - in future studies - the development of new modalities of control of the rehabilitation robot with the objective of discouraging undesirable compensatory movements. Project Narrative  Each year, nearly 800,000 Americans suffer from a type of stroke that particularly weakens one side of the body. During upper-limb rehabilitation, appropriate feedback from a therapist to discourage stroke survivors from performing undesirable compensatory movements results in better motor recovery and - eventually - improved function. This proposal aims to develop a novel video-based tool, named PostureCheck™, to detect undesirable compensatory movements and enable automatic corrective feedback to the patient during robot- assisted upper-limb therapy.",PostureCheck: A vision-based compensatory-posture-detection tool to enhance performance of the BURT® upper-extremity stroke-therapy device,9678997,R43EB027525,"['Algorithms', 'American', 'Architecture', 'Artificial Intelligence', 'Clinical', 'Clinical Research', 'Data', 'Detection', 'Development', 'Devices', 'Environment', 'Exercise', 'Feedback', 'Future', 'Generations', 'Goals', 'Hospitals', 'Human', 'Human Activities', 'Hybrids', 'Impaired cognition', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Label', 'Laboratories', 'Lateral', 'Methods', 'Modality', 'Motion', 'Motor', 'Movement', 'Names', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physical therapy', 'Physiological', 'Posture', 'Records', 'Rehabilitation Centers', 'Rehabilitation therapy', 'Research Personnel', 'Robot', 'Robotics', 'Series', 'Severities', 'Shoulder', 'Side', 'Skeleton', 'Small Business Innovation Research Grant', 'Specialist', 'Stroke', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Upper Extremity', 'Validation', 'Video Recording', 'Videotape', 'Vision', 'base', 'clinical efficacy', 'deep learning', 'deep neural network', 'design', 'dosage', 'efficacy evaluation', 'exercise rehabilitation', 'experience', 'image processing', 'improved', 'improved functioning', 'interest', 'meetings', 'monocular', 'motor impairment', 'motor recovery', 'network architecture', 'novel', 'phase 1 study', 'phase 2 study', 'recruit', 'restoration', 'robot assistance', 'robot rehabilitation', 'robotic device', 'stroke rehabilitation', 'stroke survivor', 'stroke therapy', 'tool', 'usability']",NIBIB,"BARRETT TECHNOLOGY, LLC",R43,2018,223752,-0.04618735206190756
"Human and Machine Learning for Customized Control of Assistive Robots PROJECT SUMMARY This application will result in a technological platform that re-empowers persons with severe paralysis, by allowing them to independently control a wide spectrum of robotic actions. Severe paralysis is devastating, and chronic—and reliance on caregivers is persistent. Assistive machines such as wheelchairs and robotic arms offer a groundbreaking path to independence: where control over their environment and interactions is returned to the person.  However, to operate complex machines like robotic arms and hands typically poses a difﬁcult learning challenge and requires complex control signals—and the commercial control interfaces accessible to persons with severe paralysis (e.g. sip-and-puff, switch-based head arrays) are not adequate. As a result, assistive robotic arms remain largely inaccessible to those with severe paralysis—arguably the population who would beneﬁt from them most.  The purpose of the proposed study is to provide people with tetraplegia with the means to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. Control interfaces that generate a unique map from a user's body motions to control signals for a machine offer a customized interaction, however these interfaces have only been used to issue low-dimensional (2-D) control signals whereas more complex machines require higher-dimensional (e.g. 6-D) signals. We propose an approach that leverages robotics autonomy and machine learning in order to aid the end-user in learning how to issue effective higher-dimensional control signals through body motions. Speciﬁcally, initially the human issues a lower- dimensional control signal and robotics autonomy is used to bridge the gap by taking over whatever is not covered by the human's control signal. Help from the robotics autonomy is then progressively scaled back, automatically, to cover fewer and fewer control dimensions as the user becomes more skilled.  The ﬁrst piece to our approach deals with how to extract control signals from the human, using the body-machine interface. The development and optimization of decoding procedures for controlling a robotic arm using residual body motions will be addressed under Speciﬁc Aim 1. The second piece to our approach deals with how to interpret control signals from a human within a paradigm that shares control between the human and robotics autonomy. To identify which shared-control formulations most effectively utilize the human's control signals will be the topic of Speciﬁc Aim 2. The ﬁnal piece to our approach deals with how to adapt the shared-control paradigm so that more control is transferred to the human over time. This adaptation is necessary for the human's learning process, since the goal in the end is for the human to be able to fully control the robotic arm him/herself, and will be assessed under Speciﬁc Aim 3.  At the completion of this project, tetraplegic end-users will be able to operate a robotic arm using their residual body motions, through an interface that both promotes the use of residual body motions (and thus also recovery of motor skill) and adapts with the human as their abilities change over time. By leveraging adaptive robotics autonomy, our application moreover provides a safe mechanism to facilitate learning how to operate the robotic platform. Frequently the more severe a person's motor impairment, the less able they are to operate the very assistive machines, like powered wheelchairs and robotic arms, which might enhance their quality of life. The purpose of the proposed study is to provide people with tetraplegia with the means, through non-invasive technologies, to control robotic arms with their available body mobility, while concurrently promoting the exercise of available body motions and the maintenance of physical health. We propose and study an approach that leverages robot machine learning and autonomy in order to facilitate human motor learning of how to operate a robotic arm using a customized interface, in order to make powered assisted manipulation more accessible to people with severe paralysis. 1",Human and Machine Learning for Customized Control of Assistive Robots,9448794,R01EB024058,"['3-Dimensional', 'Activities of Daily Living', 'Address', 'Affect', 'Algorithms', 'Back', 'Caregivers', 'Cerebral Palsy', 'Chronic', 'Complex', 'Computers', 'Custom', 'Data', 'Development', 'Devices', 'Dimensions', 'Eating', 'Effectiveness', 'Environment', 'Exercise', 'Formulation', 'Fostering', 'Freedom', 'Future', 'Goals', 'Hand', 'Head', 'Health Benefit', 'Human', 'Learning', 'Left', 'Limb structure', 'Machine Learning', 'Maintenance', 'Maps', 'Mental Depression', 'Mental Health', 'Motion', 'Motivation', 'Motor', 'Motor Skills', 'Movement', 'Multiple Sclerosis', 'Neurologic', 'Paralysed', 'Patients', 'Performance', 'Persons', 'Population', 'Posture', 'Powered wheelchair', 'Procedures', 'Process', 'Quadriplegia', 'Quality of life', 'Rehabilitation therapy', 'Residual state', 'Robot', 'Robotics', 'Self-Help Devices', 'Shoulder', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Spinal cord injured survivor', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Wheelchairs', 'Work', 'arm', 'base', 'body-machine interface', 'brain machine interface', 'empowerment', 'feeding', 'high dimensionality', 'improved', 'motor impairment', 'motor learning', 'motor recovery', 'n-dimensional', 'novel strategies', 'physical conditioning', 'psychologic', 'robot control', 'sensor', 'two-dimensional']",NIBIB,REHABILITATION INSTITUTE OF CHICAGO D/B/A SHIRLEY RYAN ABILITYLAB,R01,2018,331851,0.012165947452235664
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9499823,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Research Infrastructure', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radiofrequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2018,416374,0.0057228543458006645
"IGF::OT::IGF SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track) The overall objective of this Fast-Track SBIR contract project is to develop DigiBioMarCTM (Digital BioMarkers for Clinical Impact), a scalable and flexible cloud-based platform to capture and analyze wearable, implantable, or external device data. This platform also provides an informatics tool for automated data aggregation, integration, and machine learning algorithms. It is based on the scalable user-centered Medable platform, which implements standardization and normalization of patient-generated data to drive health insights. DigiBioMarCTM will compare and combine disparate data streams to understand contextualized patient physiology in real time in order to identify disease and/or detect changes in disease/health status. It also will support cohort and clinical studies, particularly those testing digital biomarkers from wearable sensor technologies. This Fast-Track project will focus on product development with an ultimate aim of a product that improves cancer research data and clinical trials, enhances clinical care, and that can be used to engage patients in preventive health behaviors and treatment adherence. The Phase I goal is to develop a data-agnostic DigiBioMarCTM prototype for validation in Phase II. The Phase 1 Go/No-Go decision point to proceed to Phase II will be a working prototype with specified features for further development and validation in Phase II. n/a",IGF::OT::IGF SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track),9788845,61201800010C,"['Algorithms', 'Biological Markers', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Computer software', 'Contracts', 'Data', 'Data Aggregation', 'Development', 'Devices', 'Disease', 'Documentation', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Informatics', 'Machine Learning', 'Patients', 'Phase', 'Physiology', 'Preventive', 'Publishing', 'Reporting', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Standardization', 'Stream', 'System', 'Testing', 'Time', 'Validation', 'anticancer research', 'base', 'clinical care', 'cloud based', 'digital', 'flexibility', 'graphical user interface', 'improved', 'insight', 'knowledge base', 'product development', 'prototype', 'sensor', 'skills', 'tool', 'treatment adherence', 'wearable sensor technology']",NCI,"MEDABLE, INC.",N01,2018,224294,0.020152018189868542
"Wireless Movement Sensing System for People with Severe Disabilities Abstract The ability of people with severe physical impairment to participate in family life, communication, work, or recreation is severely restricted without access to assistive technology (AT). Yet, as disability severity increases, so does the challenge to finding (1) an access movement that a person can perform to control AT and (2) an access technology that can detect the access movement. We propose to create a wireless movement sensing system that can learn a user’s access movement and then recognize that movement in order to wirelessly control assistive devices. Once we complete the technology development, we will measure the sensitivity and specificity of our wireless movement sensing system using the movements of ten people with SPI. We will present our results to AT experts during a focus group session and determine the perceived strengths and weaknesses of the technology. This Phase 1 research is proposed by a multidisciplinary research team consisting of AT engineers, AT clinicians, and a machine learning expert. Project Narrative The proposed movement sensing system adapts to the abilities of people with severe physical impairment and enables them to better control smart devices (e.g., computers, smartphones, etc.).",Wireless Movement Sensing System for People with Severe Disabilities,9554167,R43DC017791,"['Address', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Android', 'Arkansas', 'Beds', 'Bluetooth', 'Brain Stem Infarctions', 'Cellular Phone', 'Cerebral Palsy', 'Communication', 'Computer software', 'Computers', 'Custom', 'Data', 'Devices', 'Digit structure', 'Engineering', 'Etiology', 'Exhibits', 'Family', 'Fingers', 'Focus Groups', 'Generations', 'Hand', 'Hospitals', 'Impairment', 'Interdisciplinary Study', 'Learning', 'Life', 'Machine Learning', 'Measures', 'Movement', 'Output', 'Participant', 'Performance', 'Persons', 'Phase', 'Positioning Attribute', 'Records', 'Recreation', 'Rehabilitation therapy', 'Research', 'Scanning', 'Self-Help Devices', 'Sensitivity and Specificity', 'Severities', 'Speech', 'Spinal cord injury', 'System', 'Tablets', 'Technology', 'Thumb structure', 'Training', 'Universities', 'Wheelchairs', 'Wireless Technology', 'Woman', 'Work', 'cost', 'disability', 'effectiveness measure', 'prototype', 'sensor', 'technology development', 'wearable device']",NIDCD,"INVOTEK, INC.",R43,2018,222217,0.018168968240596186
"Quantitative Handwriting Assessment Tool for Healthy and Impaired Children No technology currently exists for objective assessment of handwriting, even though over 3 million individuals in the United States suffer from disorders that affect handwriting, including 2.7 million children with dyspraxia and over 300,000 older adults with Parkinson's disease. This lack of assessment technology creates a barrier to effective care, because occupational therapists cannot easily distinguish motor disorders from non- motor causes of handwriting disability, a necessary step toward developing appropriate treatment plans. Our goal is to develop Write to Hand, the first quantitative digital assessment of the motor skills that underlie handwriting.  In partnership with Washington University in St. Louis, PlatformSTL is uniquely suited to address the handwriting assessment gap. Our team is led by a neuroscientist who developed the Precision Drawing Task, a laboratory research tool with an established history of successful assessment and training of writing-related motor skills. The Precision Drawing Task will serve as the basis for Write to Hand. Our Phase I objective is to develop a fully functional prototype of Write to Hand, and demonstrate scientific validity in children grades 4-5. Data analysis will include an initial application of a machine learning approach, which will test its feasibility in advance of its primary role in Phase II.  Aim 1 of this STTR is to develop the Write to Hand iPad app, which must meet seven specific criteria including: high-precision data collection with a fine-point stylus; rapid calculation of movement speed, smoothness, straightness, and error rate; and data anonymization that meets HIPAA and IRB standards. Aim 2 will demonstrate validity by comparing Write to Hand performance against a handwriting benchmark in 56 children grades 4-5. We expect that movement smoothness will significantly and meaningfully (r2 > 0.25) predict handwriting skill, and we will use a machine learning approach (Generalized Factorial Method) determine the most predictive classifier for handwriting skill, identify task features that optimize handwriting prediction, and demonstrate feasibility of our machine learning approach to characterize and classify Write to Hand data.  Our product will transform therapy for individuals with handwriting disabilities, by providing educators, therapists, and researchers with a gold standard for assessment and quantification of handwriting's underlying motor control skills. This will, for the first time, allow objective identification of motor impairment in local and tele-health settings. In Phase II we will collect data across participant ages to train our machine learning algorithm so Write to Hand can label performance with easy-to-interpret grade level ratings. Our commercialization plan focuses on occupational therapists and educators who serve children with motor disabilities. Therapists currently have no objective tools to measure handwriting in children or impaired adults. This project will develop an iPad app to measure the movement skills that support effective handwriting. With this tool, therapists will be able to identify when handwriting disability arises from a movement problem, and develop treatment plans accordingly.",Quantitative Handwriting Assessment Tool for Healthy and Impaired Children,9679822,R41HD097833,"['Address', 'Adult', 'Affect', 'Age', 'Algorithms', 'Apraxias', 'Area', 'Assessment tool', 'Benchmarking', 'Caring', 'Child', 'Collection', 'Consensus', 'Data', 'Data Analyses', 'Data Collection', 'Disease', 'Elderly', 'Face', 'Fingers', 'Goals', 'Gold', 'Hand', 'Handwriting', 'Health Insurance Portability and Accountability Act', 'Impairment', 'Individual', 'Institutional Review Boards', 'Intuition', 'Label', 'Laboratories', 'Laboratory Research', 'Learning', 'Linear Regressions', 'Machine Learning', 'Measures', 'Methods', 'Modernization', 'Motor', 'Motor Skills', 'Movement', 'Neurosciences Research', 'Occupational Therapist', 'Paper', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Persons', 'Phase', 'Positioning Attribute', 'Preparation', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'School-Age Population', 'Small Business Technology Transfer Research', 'Societies', 'Speed', 'Standardization', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'United States', 'Universities', 'Upper Extremity', 'Washington', 'Writing', 'analytical method', 'barrier to care', 'base', 'commercial application', 'commercialization', 'design', 'digital', 'disability', 'elementary school', 'falls', 'innovation', 'motor control', 'motor disorder', 'motor impairment', 'prototype', 'skills', 'teacher', 'telehealth', 'tool', 'treatment planning']",NICHD,"NEWVENTUREIQ, LLC",R41,2018,240711,-0.010788373568043394
"A Customizable Real-Time Biosensor for Continuous Monitoring of Water Contaminants Ensuring access to clean water for generations to come will involve developing novel ap- proaches to determining the safety and composition of potable water that are practical and afford- able. Arsenic, mercury, and cadmium are three of the top priorities among hazardous substances commonly found at Superfund sites, as they are linked to health problems in people exposed to them in drinking water, yet the current real-time monitoring methods for these and other contam- inants are either extremely costly or nonexistent, making it difﬁcult to monitor water quality with high spatial or temporal resolution. QBiSci is developing a biosensor that uses synthetic micro- bial sensor strains that ﬂuoresce in response to speciﬁc toxins to continuously monitor water for contamination. The platform will substantially improve upon currently available technologies for toxin detection, making monitoring more affordable, continuous, and ﬁeld-deployable. Speciﬁc Aim 1: To fully characterize three synthetic E. coli strains that speciﬁcally detect ar- senic, mercury, and cadmium in a continuous water stream. For a real-time sensor to be maxi- mally effective, it must be able to report accurate toxin concentrations in real-time. Focusing on three of the highest priority contaminants as a proof of feasibility, comprehensive data will be acquired to train a machine learning algorithm to be able classify real-world samples in real-time. Speciﬁc Aim 2: To develop and train a classiﬁcation algorithm to recognize the type and amount of each contaminant present in a continuous water stream. The ability to analyze and interpret data in real-time from a constantly ﬂuctuating water source will require an extensive classiﬁcation train- ing effort. QBiSci's existing machine learning framework will be trained and tested using many contamination induction scenarios, ranging from sudden pulses to subtly varying concentrations. Speciﬁc Aim 3: To develop a microﬂuidic cartridge system that reduces device complexity and enables sensor deployment with minimal intervention. QBiSci will develop a swappable car- tridge system using devices that are pre-loaded with biologically-stable strains and can simply be “plugged in” to the sensor platform to achieve repeatable results in a user-friendly manner. The development of a method for thermoplastic device fabrication will enable the more precise connections required for a cartridge clamping system that will require little operational expertise.  A successful outcome of this proposal will lead to a biosensor capable of real-time quantiﬁca- tion of arsenic, mercury, and cadmium in a continuous water input. A future Phase II proposal would focus on real-world performance evaluations of our sensors via deployment in areas of con- cern and comparison of our results to standard techniques as well as an expansion of the platform to detect other contaminants quantitatively and continuously. 1 Access to clean, reliable water supplies is critical to our quality of life and our economy, yet across the country over 100,000 hazardous waste sites are so heavily contaminated that the un- derlying groundwater doesn't meet drinking water standards. While there is a wide range of toxins found at these sites, arsenic, mercury, and cadmium are among the most common offend- ers, all of which have been linked to a variety of health problems ranging from cancer to dia- betes as well as behavior and neurological disorders. We are developing a customizable real-time biosensor that will enable contamination monitoring to become more affordable, continuous, and ﬁeld-deployable and will facilitate improved management decisions aimed at reducing toxin con- centrations in the environment, tracking the progression of contamination plums, and targeting investments in remediation efforts. 1",A Customizable Real-Time Biosensor for Continuous Monitoring of Water Contaminants,9467134,R43ES028993,"['Algorithms', 'Area', 'Arsenic', 'Behavior Disorders', 'Biological', 'Biosensor', 'Cadmium', 'Classification', 'Closure by clamp', 'Country', 'Data', 'Detection', 'Development', 'Devices', 'Diabetes Mellitus', 'Ensure', 'Environment', 'Escherichia coli', 'Evaluation', 'Exposure to', 'Fluorescence', 'Future', 'Generations', 'Goals', 'Hazardous Substances', 'Hazardous Waste Sites', 'Health', 'Intervention', 'Investments', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mercury', 'Methods', 'Microfluidics', 'Monitor', 'Outcome', 'Performance', 'Phase', 'Physiologic pulse', 'Plug-in', 'Plum', 'Quality of life', 'Reporting', 'Research', 'Research Infrastructure', 'Risk', 'Safety', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Water', 'Water Supply', 'contaminated water', 'cost', 'drinking water', 'ground water', 'improved', 'innovation', 'microbial', 'nervous system disorder', 'novel', 'novel strategies', 'operation', 'real time monitoring', 'remediation', 'response', 'sensor', 'simulation', 'superfund site', 'temporal measurement', 'user-friendly', 'water quality']",NIEHS,"QUANTITATIVE BIOSCIENCES, INC.",R43,2018,162205,0.01557275065656601
"Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time Project Summary Lower limb assistive robotic devices, such as active prosthesis, orthoses, and exoskeletons have the potential to restore function for the millions of Americans who experience mobility challenges due to injury and disability. Since individuals with mobility challenges have an increased energetic cost of transport, the benefit of such assistive devices is commonly assessed via the reduction in the metabolic work rate of the individual who is using the device. Currently, metabolic work rate can only be obtained in a laboratory environment, using breath-by-breath measurements of respiratory gas analysis. To obtain a single steady state data point of metabolic work rate, multiple minutes of data must be collected, since the signals are noisy, sparsely sampled, and dynamically delayed. In addition, the user has to wear a mask and bulky equipment, further restricting the applicability of the method on a larger scale. We propose an improved way to obtain such estimates of metabolic work rate in real-time. Aim 1 will determine salient signal features and characterize the dynamics of sensing metabolic work rate from a variety of physiological sensor signals. Aim 2 will use advanced sensor fusion and machine learning techniques to accurately predict instantaneous energy cost in real-time from multiple physiological signals without relying on a metabolic mask. Aim 3 will use the obtained real-time estimates to optimize push-off timing for an active robotic prosthesis. The resulting methods will enable an automated and continuous evaluation of assistive robotic devices that can be realized outside the laboratory and with simple wearable sensors. This automated evaluation will enable devices, such as active prostheses, orthoses, or exoskeletons, that can self-monitor their performance, optimize their own behavior, and continuously adapt to changing circumstances. This will open up a radically new way of human-robot- interaction for assistive devices. It will greatly increase their clinical viability and enable novel advanced controllers and algorithms that can improve device performance on a subject specific basis. Project Narrative A common way of evaluating assistive robotic devices, such as active prostheses or exoskeletons, is by measuring the reduction in effort that they bring to an individual walking in them. The proposed project will develop ways to perform this evaluation automatically and in real-time by the device itself, which will be used in the future to develop prostheses and exoskeletons that automatically adapt themselves to their users. This project supports the NIH's stated mission of reducing disability by improving patient outcomes with new prosthetic and orthotic devices.",Evaluating and Improving Assistive Robotic Devices Continuously and in Real-time,9529742,R03HD092639,"['Algorithms', 'American', 'Amputation', 'Amputees', 'Ankle', 'Behavior', 'Biological Neural Networks', 'Clinical', 'Data', 'Devices', 'Electromyography', 'Energy Metabolism', 'Environment', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Gray unit of radiation dose', 'Heart Rate', 'Indirect Calorimetry', 'Individual', 'Injury', 'Laboratories', 'Linear Regressions', 'Lower Extremity', 'Machine Learning', 'Masks', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Noise', 'Orthotic Devices', 'Patient-Focused Outcomes', 'Performance', 'Persons', 'Physiological', 'Population', 'Prosthesis', 'Reference Values', 'Robotics', 'Sampling', 'Self-Help Devices', 'Shapes', 'Signal Transduction', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'cost', 'disability', 'exoskeleton', 'experience', 'functional restoration', 'human-robot interaction', 'improved', 'light weight', 'novel', 'respiratory gas', 'robotic device', 'sensor', 'wearable device']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2018,77959,0.028721549365881872
"Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor Summary The principal goal of this proposal is to increase the accuracy and precision of a low-cost autorefraction device called the QuickSee, in order to improve access to refractive eye care for underserved populations. Poor vision due to a lack of eyeglasses is highly prevalent in low-resource settings throughout the world and significantly reduces quality of life, education, and productivity. The existing QuickSee only extracts the lower- order aberration information contained within a wavefront profile of the eye, to roughly estimate an eyeglass prescription. This proposal will further improve the accuracy of the QuickSee device by exploiting both the lower- and higher-order aberrations contained within the complete wavefront. To realize this goal, we will enroll 300 subjects (600 eyes) in Baltimore, MD, and will obtain subjective refraction and visual acuity (VA) measurements and will use machine learning on this large dataset of wavefront profiles to optimize the wavefront-to-refraction algorithm of the QuickSee device. The main output of this project will be a robust and improved-accuracy next-generation QuickSee device that will increase efficiency of and decrease the training requirements of eye care professionals, and potentially dispense refractive correction that provides similar or better VA than correction from an eye care professional. Successful completion of this work will be an important step towards dramatically improving eyeglass accessibility for health disparity populations in the USA and internationally in low-resource settings. Upon completion of this proposal, we will apply for a Phase II award proposing to work with Wilmer Eye Institute research faculty to assess widespread deployment of the next-generation QuickSee with minimally-trained personnel in order to accurately and reliably provide thousands of pairs of low-cost corrective eyeglasses to underserved communities. Project Narrative This project proposal seeks to develop a novel technology that will disruptively increase the accessibility of refractive eye care for health disparity populations in low-resource settings. Specifically, sophisticated algorithms will be developed that improve the accuracy of the QuickSee device so that it can improve the efficiency of and reduce the training barriers for eye care professionals, and potentially provide refractive correction without the need for refinement by a trained eye care professional. Our goal is to develop a low- cost, easy-to-use, scalable solution to increase accessibility to vision correction globally.","Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor",9711194,R43EB024299,"['Algorithms', 'Award', 'Baltimore', 'Brazil', 'Businesses', 'Caliber', 'Calibration', 'Caring', 'Communities', 'Country', 'Data', 'Data Set', 'Developed Countries', 'Developing Countries', 'Development', 'Devices', 'Diagnostic', 'Education', 'Educational Status', 'Enrollment', 'Eye', 'Eyeglasses', 'Feedback', 'Geometry', 'Goals', 'Gold', 'Guatemala', 'Hospitals', 'Human Resources', 'Impairment', 'Improve Access', 'Income', 'India', 'Institutes', 'International', 'Machine Learning', 'Mali', 'Measurement', 'Measures', 'Modeling', 'Noise', 'Ophthalmic examination and evaluation', 'Optometrist', 'Output', 'Patient Schedules', 'Patients', 'Phase', 'Population', 'Prevalence', 'Procedures', 'Productivity', 'Pupil', 'Quality of life', 'Refractive Errors', 'Research Institute', 'Resources', 'Spottings', 'Testing', 'Time', 'Training', 'Underserved Population', 'Universities', 'Validation', 'Vision', 'Visual Acuity', 'Work', 'base', 'cost', 'faculty research', 'health care disparity', 'health disparity', 'improved', 'lens', 'new technology', 'next generation', 'novel strategies', 'success', 'vector']",NIBIB,"PLENOPTIKA, INC.",R43,2018,99914,-0.013872600864896074
"Non-invasive device to assist selecting the level-of-amputation in patients with peripheral arterial disease 1 Abstract  2  3 This is a Phase I SBIR proposal to develop a non-contact and non-invasive imaging device for assisting clinicians  4 in selecting the appropriate level-of-amputation (LOA) in limbs with peripheral arterial disease (PAD). Surgeons  5 prefer to salvage as much limb tissue as possible during amputation to increase patient mobility while decreasing  6 morbidity and mortality. However, clinicians must balance this preference against the likelihood of primary wound  7 healing at a given level of amputation (LOA), which decreases with more distal amputations. There are no gold-  8 standard tests to aid clinicians in selecting the LOA in patients with PAD, therefore reported rates of re-  9 amputation in current practice are substantial. Up to 20% percent of above-the-knee amputations to 35% of 10 foot amputations require revision to a more proximal level. Furthermore, physician awareness of the risk for 11 re-amputation may lead to overly aggressive selection of LOA to more proximal levels in some cases. Indeed, 12 certain patients may receive amputations at a level more proximal than is necessary because their surgeon could 13 not confidently predict a high likelihood of healing at a more distal level. 14 15 In current practice, selection of LOA is determined qualitatively by clinical judgment of the surgeon using patient 16 history and physical exam. Others have developed quantitative tests that assess local microcirculation. These 17 technologies have not superseded clinical judgement. To address this critical problem, SpectralMD is 18 developing an imaging device that integrates multispectral imaging with a machine learning algorithm 19 to provide a quantitative assessment of the healing potential of a selected LOA whereas current clinical 20 practice is only capable of qualitative assessment. 21 22 We have proof-of-concept of our technology’s ability to characterize microvascular blood flow changes in a 23 patient with critical limb ischemia. In this proposal, we intend to establish the utility of our device for predicting 24 the healing potential of a clinician selected LOA by demonstrating the effectiveness of DeepView assessment 25 on a large set of pre-amputation images. To this end we will conduct a Phase I pilot study for the use of our 26 device in predicting the healing potential of a clinician selected LOA. This clinical study will develop a data set 27 for training the algorithm, and deliver a clear demonstration of feasibility for completing the development on an 28 algorithm that has high accuracy in predicting the healing potential of the proposed amputation site. Following 29 this work, we will apply for a Phase II proposal intended to finalize algorithm training, validate the algorithm 30 developed in Phase I, and establish a successful regulatory and commercialization pathway. Narrative In patients with peripheral arterial disease, reported rates of re-amputation due to non-healing of a primary amputation are very significant—approximately 20% of below-the-knee amputations require eventual revision, with even higher rates established for amputations at the level of the foot. There are no gold-standard tests for selection of level of amputation (LOA) to aid clinical judgment. To address this critical problem, SpectralMD is developing the DeepView-Gen2 imaging device that integrates multispectral imaging and a machine learning algorithm to quantitatively measure microvascular blood flow and tissue healing potential to assist in the clinical selection of LOA and minimize the incidence of re-amputation and its associated morbidity and mortality.",Non-invasive device to assist selecting the level-of-amputation in patients with peripheral arterial disease,9622035,R43HL142428,"['Address', 'Algorithms', 'Amputation', 'Ankle', 'Architecture', 'Awareness', 'Blood flow', 'Clinical', 'Clinical Data', 'Clinical Research', 'Contracts', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Devices', 'Distal', 'Effectiveness', 'Elements', 'Equilibrium', 'Goals', 'Gold', 'Image', 'Imaging Device', 'Incidence', 'Investigation', 'Ischemia', 'Judgment', 'Knee', 'Lead', 'Limb structure', 'Lower Extremity', 'Machine Learning', 'Measures', 'Medical History', 'Microcirculation', 'Morbidity - disease rate', 'Pathway interactions', 'Patients', 'Peripheral arterial disease', 'Phase', 'Physicians', 'Pilot Projects', 'Postoperative Period', 'Practice Guidelines', 'Quality of life', 'Recording of previous events', 'Reporting', 'Risk', 'Sample Size', 'Secondary to', 'Site', 'Skin Tissue', 'Small Business Innovation Research Grant', 'Specificity', 'Standardization', 'Surgeon', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'Wound Healing', 'base', 'clinical practice', 'clinical risk', 'commercialization', 'design', 'foot', 'healing', 'indexing', 'mortality', 'non-invasive imaging', 'patient mobility', 'phase 1 study', 'preference', 'standard of care', 'success', 'wound']",NHLBI,"SPECTRAL MD, INC.",R43,2018,196561,0.016832240709362033
"Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI DESCRIPTION (provided by applicant):  In the first 5-year period of our BRP we had two major objectives:  1) to determine whether we could improve motor function of the lower limbs by neuromodulating the spinal lumbosacral circuitry with epidural stimulation and 2) to begin to develop and improve the technologies associated with electrode arrays and chronic implantable stimulation devices to maximize the neuromodulatory potential.  These new technologies have the potential to fine tune the epidural stimulation parameters, to help in understanding some of the underlying mechanisms of epidural stimulation., to examine synergistic effects of epidural stimulation, pharmacological modulation, and examine activity-dependent interventions that might affect the level of recovery of motor function after complete paralysis.  We have demonstrated that an adult rat with a complete, mid-thoracic spinal cord transection can regain full weight-bearing stepping over a range of speeds, loads, and even directions when the spinal cord is stimulated tonically to increase the excitability of the lumbosacral locomotor circuitry.  Furthermore, we learned that load-bearing sensory information can serve as the controller of these complex motor tasks and that the performance of these tasks can be improved even further with combinations of epidural stimulation, pharmacological, and motor training interventions.  We have shown that four humans with a motor complete spinal injury have regained independent standing, assisted stepping, and even a significant level of voluntary control of the lower limbs in the presence of epidural stimulation, with one subject now even having some volitional control without stimulation.  Improvement in bladder control, blood pressure, temperature regulation, and even sexual function has been realized.  Thus, our present challenge is to develop the capability to selectively activate combinations of neural networks that can enable standing, and probably stepping, by improving the technologies needed to make this intervention available in the clinic and in the home of individuals with complete motor paralysis using a chronic epidural electrode implant.  Specifically, we will further improve the electrode array stimulation technology needed for fine-tune control in rats and humans and transform the present hardwired technology for rats to a wireless capability to stimulate and record evoked potentials along the brain-spinal cord-muscle axis in the rat.  To advance the clinical potential, we will continue to develop, refine and validate our machine-learning strategies which automatically optimize stimulation parameters for standing, stepping, and voluntary control.  We will develop an improved interface between the devices implanted in our present subjects and the control devices for defining the specific stimulation parameters needed for a given subject to perform a motor task in the clinic or at home. PUBLIC HEALTH RELEVANCE:  We now have demonstrated that the human lumbosacral spinal cord can be neuromodulated with epidural stimulation to enable recovery of standing and volitional control of the lower limbs and return of some autonomic function after complete motor paralysis.  Therefore, our objectives are now to develop the technologies needed to more fully capitalize on this clinical potential and develop home-use technologies to do so.",Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI,9572928,U01EB007615,"['Adult', 'Affect', 'Algorithms', 'Animals', 'Behavior', 'Bilateral', 'Biological Neural Networks', 'Bladder Control', 'Blood Pressure', 'Brain', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Complex', 'Data', 'Devices', 'Dorsal', 'Educational Intervention', 'Electrodes', 'Evaluation', 'Evoked Potentials', 'Experimental Designs', 'Frequencies', 'Gaussian model', 'Home environment', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Internet', 'Intervention', 'Intramuscular', 'Learning', 'Locomotor training', 'Lower Extremity', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Muscle', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Pharmacology', 'Physiological', 'Posture', 'Procedures', 'Process', 'Rattus', 'Recovery', 'Regulation', 'Research', 'Robotics', 'Sensory', 'Sex Functioning', 'Signal Transduction', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord Contusions', 'Spinal Cord transection injury', 'Spinal Injuries', 'Spinal cord injury', 'Stimulus', 'System', 'Task Performances', 'Technology', 'Temperature', 'Testing', 'Thoracic spinal cord structure', 'Training', 'Volition', 'Weight-Bearing state', 'Wireless Technology', 'base', 'density', 'design', 'implantable device', 'improved', 'in vivo', 'learning strategy', 'motor control', 'motor function improvement', 'motor function recovery', 'neuroregulation', 'new technology', 'next generation', 'novel', 'public health relevance', 'somatosensory', 'treadmill', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2018,1060180,0.04173526953974432
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9465330,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,503162,-0.011416440332453369
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9698505,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,50000,-0.011416440332453369
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research PROJECT SUMMARY This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0™ that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud™ Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb’s DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently. PROJECT NARRATIVE PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9741597,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Communications Media', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Internet of Things', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Modernization', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'Transact', 'United States National Institutes of Health', 'analytical tool', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'experimental study', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'service learning', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2018,99999,-0.000690885118269462
"Advancing a novel portable detection method for cannabis intoxication Intoxication from marijuana (MJ) impairs psychomotor performance and at least doubles the risk of motor vehicle accidents. The ongoing wave of legalization of MJ has brought increasing prevalence of driving while intoxicated with MJ. However, there is no quantitative biologic test that can accurately determine whether an individual is acutely impaired from MJ intoxication. Assays of the primary intoxicating substance in MJ, THC, in body fluids has a high false negative rate as THC is cleared from blood within 15 minutes, long before impairment is resolved. And assays of THC metabolites yield a high false positive rate because clearance of these metabolites can take weeks. Thus there is now no nor is there likely to ever be a test of blood, breath or body fluids that can accurately detect MJ intoxication. In response to this significant knowledge gap, this project aims to develop an accurate, portable method for detection of impairment due to MJ intoxication using functional near-infrared spectroscopy (fNIRS). fNIRS is a non-invasive, safe brain imaging technique that capitalizes on differences in the light absorption spectra of deoxygenated and oxygenated hemoglobin (Hb), that allows the measurement of relative changes in Hb concentration that reflect brain activity. fNIRS can be performed in natural environments at low cost, and thus can be used in real-world settings. In Phase I, we will develop an algorithm for individual-level detection of impairment from THC using fNIRS measurements. To do so, we will assess the effect of oral THC (or placebo) on fNIRS measurements, self-reported intoxication, and impairment as defined by the gold standard field sobriety test conducted by a Drug Recognition Expert (DRE) in 40 healthy MJ users. fNIRS assessments will examine (1) the effect of THC exposure on resting state and task-based activation in the prefrontal cortex, (2) the extent to which impairment in psychomotor functioning with THC administration correlates with THC-induced change in hemodynamic responses detected with fNIRS, and (3) the sensitivity and specificity and area under the ROC curve of fNIRS measurements and field sobriety test determinants of impairment. Milestone: Should machine learning applications to the data generate an algorithm that predicts impairment with >80% accuracy compared with a gold standard field sobriety test, we will proceed to Phase II. In Phase II, we will conduct fNIRS testing in 150 individuals under THC/placebo as in Phase I and in 50 individuals in a THC plus alcohol/placebo condition in order to further refine the algorithm for MJ impairment detection such that fNIRS detection concurs with field sobriety testing with >90% specificity. It is anticipated that this level of specificity could be used in legal definitions of impairment. This will warrant commercialization, which will be followed by prototype development and field testing. An accurate, quantitative, biological test that is user-friendly and enables law enforcement to detect impairment from MJ has the potential to dramatically change practice of law enforcement across the country and the world and thus has enormous commercial potential, as outlined in the Commercialization Plan and in accompanying letters of support. The goal of this project is to develop, test, and refine a method to accurately and reliably detect marijuana (MJ) impairment using a portable, user-friendly, non-invasive, brain-based modality. MJ doubles the chance of motor vehicle accidents, yet, there now exists no valid, biologically based method to detect whether an individual is acutely impaired from MJ. The development of a reliable, quantitative biological marker that enables law enforcement officers to screen individuals whom they suspect are impaired from MJ will have highly significant public health importance and enormous commercial potential.",Advancing a novel portable detection method for cannabis intoxication,9541180,R42DA043977,"['Acute', 'Adult', 'Age', 'Alcohols', 'Algorithms', 'Area', 'Base of the Brain', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Blood', 'Blood Circulation', 'Blood Tests', 'Body Fluids', 'Brain', 'Brain imaging', 'Cannabis', 'Collaborations', 'Comorbidity', 'Country', 'Cross-Over Trials', 'Data', 'Detection', 'Development', 'Devices', 'Dose', 'Double-Blind Method', 'Driving While Intoxicated', 'Drug Kinetics', 'Ensure', 'Environment', 'Equipment', 'Evaluation', 'Formulation', 'Future', 'Goals', 'Gold', 'Hemoglobin', 'Hour', 'Human Resources', 'Imaging Techniques', 'Impairment', 'Individual', 'Intoxication', 'Knowledge', 'Law Enforcement', 'Law Enforcement Officers', 'Legal', 'Letters', 'Licensing', 'Light', 'Machine Learning', 'Marijuana', 'Measurement', 'Methods', 'Modality', 'Near-Infrared Spectroscopy', 'Oral', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Placebos', 'Population', 'Prefrontal Cortex', 'Prevalence', 'Property', 'Psychomotor Impairments', 'Psychomotor Performance', 'Public Health', 'ROC Curve', 'Randomized', 'Readiness', 'Rest', 'Risk', 'Sensitivity and Specificity', 'Source', 'Specificity', 'System', 'THC exposure', 'Testing', 'Tetrahydrocannabinol', 'United States', 'Urine', 'Vendor', 'absorption', 'alcohol exposure', 'base', 'behavior test', 'commercialization', 'cost', 'density', 'detector', 'driving under influence', 'drug testing', 'field sobriety tests', 'field study', 'functional disability', 'hemodynamics', 'interest', 'marijuana legalization', 'marijuana use', 'marijuana user', 'novel', 'novel strategies', 'portability', 'prediction algorithm', 'prototype', 'response', 'spectroscopic imaging', 'tool', 'user-friendly', 'vehicular accident']",NIDA,"HIGHLIGHTI, INC",R42,2018,731789,0.0027478793525067178
"A Hybrid Neural-Machine Interface for Volitional Control of a Powered Lower Limb Prosthesis Project Summary  The goal of the proposed work is to develop a robust hybrid neural-machine interface (NMI), combining brain and muscle signals, to improve overall control of a lower limb prosthetic device during activities of daily living. Limb amputation affects over 600,000 individuals annually in the US, and is a major cause of physical disability that causes activities of daily living to become difficult or impossible for the amputee. The limitations of current lower-limb prostheses are associated with limited volitional control, reduced mobility, and chronic gait abnormalities, which have been linked to exhaustion from increased energy expenditure, increased risk of falling, and degenerative bone and joint disorders in both the intact and amputated limb. In this study, EMG signals from both residual and intact lower limbs and EEG signals from the cortex are leveraged to decode transitions to and from various modes of locomotion modes in able-bodied individuals and transfemoral amputees, and to provide a global understanding of movement at the cortical, muscular, and kinematic level in amputees. Specifically, time and frequency domain features are leveraged to create a prediction algorithm capable of identifying upcoming terrain transitions in advance. In lower limb amputees, this hybrid NMI paradigm translates to volitional control of a powered lower-limb prosthesis, which allows for seamless transitions between various movement conditions. The high-level of control is expected to result in significant increases in level of activity and overall improvements in gait. Previous studies have demonstrated the feasibility of EEG or EMG based NMIs for orthotic and prosthetic devices; however, no study to date has integrated EEG and EMG in a NMI for powered lower limb prostheses. This study is motivated by the need to explore advanced neural control sources for intuitive control of artificial limbs.  This project aligns directly with the Mission & Goals of the NIH, the Brain Initiative, and NIH’s Blueprint Program by expanding fundamental knowledge of neuroscience, human, health and wellness; by utilizing an innovative research strategy; and ultimately returning the knowledge to the public through the development of a highly advanced medical technology. Furthermore, the technology developed through this work has implications beyond the amputee population in the treatment of many neurological conditions and injuries, such as in neurorehabilitation after stroke. The innovation of this project lies in the novel approach of using multimodal neural signals and movement synergies as a framework for interpreting movement of the lower limb. The scientific impact is realized by a greater understanding of the neural correlates of movement after lower-limb amputation. The direct clinical significance for the patient can be measured directly through improved gait performance and walking confidence, leading to increased mobility and a reduced risk of falling, exhaustion, and bone and joint disorders. Project Narrative  The development of a hybrid neural-machine interface that incorporates muscle and brain signaling for communication with robotic systems is important to public health because it allows for robust volitional control of powered prostheses and exoskeletons during activities of daily living. This will directly benefit the amputee population by allowing better control of their prosthesis during locomotion, especially when navigating complex terrains, such as stairs and inclines. The implications of this technology can be used beyond the amputee population to further understand the effect of neurological injuries on the brain, and for improving rehabilitation paradigms associated with their treatment.",A Hybrid Neural-Machine Interface for Volitional Control of a Powered Lower Limb Prosthesis,9604145,F99NS105210,"['Activities of Daily Living', 'Affect', 'Amputees', 'Ankle', 'Artificial Intelligence', 'Award', 'BRAIN initiative', 'Body Image', 'Bone Diseases', 'Brain', 'Brain imaging', 'Chronic', 'Communication', 'Complex', 'Detection', 'Development', 'Electroencephalography', 'Electromyography', 'Electronic Mail', 'Energy Metabolism', 'Engineering', 'Frequencies', 'Funding Agency', 'Future Teacher', 'Gait', 'Gait abnormality', 'Goals', 'Grant', 'Health', 'Human', 'Hybrids', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Individual', 'Injury', 'International', 'Intuition', 'Joints', 'Knee', 'Knowledge', 'Leadership', 'Limb Prosthesis', 'Link', 'Locomotion', 'Lower Extremity', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Mentors', 'Mentorship', 'Metabolic', 'Methods', 'Mission', 'Motion', 'Movement', 'Muscle', 'Nervous System Trauma', 'Neurologic', 'Neurologic Effect', 'Neurorehabilitation', 'Neurosciences', 'Oral', 'Orthotic Devices', 'Patients', 'Pattern', 'Performance', 'Physically Handicapped', 'Population', 'Positioning Attribute', 'Prosthesis', 'Public Health', 'Ramp', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Residual state', 'Robotics', 'Scalp structure', 'Signal Transduction', 'Social Network', 'Source', 'Stroke', 'Surface', 'System', 'Teacher Professional Development', 'Technical Expertise', 'Technology', 'Telephone', 'Time', 'Training Programs', 'Translating', 'United States', 'United States National Institutes of Health', 'Upper Extremity', 'Visual Cortex', 'Volition', 'Walking', 'Work', 'arthropathies', 'base', 'clinically significant', 'exhaustion', 'exoskeleton', 'experience', 'fall risk', 'improved', 'injured', 'innovation', 'instrument', 'kinematics', 'limb amputation', 'limb movement', 'multimodality', 'neural correlate', 'neuroregulation', 'neurotransmission', 'novel strategies', 'posters', 'powered prosthesis', 'prediction algorithm', 'programs', 'rehabilitation paradigm', 'relating to nervous system', 'robot control', 'robot exoskeleton', 'robot rehabilitation', 'sensor', 'signal processing', 'skills', 'stroke rehabilitation', 'symposium', 'synergism', 'undergraduate student', 'visual motor']",NINDS,UNIVERSITY OF HOUSTON,F99,2018,36509,0.011076039629232657
"Understanding the Neural Basis of Volitional State through Continuous Recordings in Humans ABSTRACT In the course of a day we naturally make multiple shifts in our overall cognitive state and in our aims and intents. We go from sleep to awake, from internal dialogue to external communication, from relative immobility to planned complex movements. The neural activity which distinguishes these different high-level states is unknown and yet is a fundamental aspect to understanding overall cognitive processes. It is also a baseline substrate that is adversely impacted by a wide range of neuropsychiatric diseases. Our understanding of human cortical neurophysiology is almost entirely based on cognitive processes examined within the constraints of experimentally controlled tasks with time-locked, stimulus-driven behaviors. However, brain activity is fluid and continuous; much of our essential cognitive activity is not externally triggered but internally generated. The overarching goal of this research is to create platforms which allow for continuous acquisition of high-fidelity neural ensemble activity synchronized with behavioral data and contextual information to allow investigations into volitional changes in focus and intent. Data will be acquired from two groups of patients: those undergoing intracranial exploration for treatment of their epilepsy and patients implanted with multi- electrode arrays as part of the BrainGate clinical trial to restore communication and mobility to people with paralysis. Using this novel paradigm for investigation, we will explore the neural basis for changes in state which are dominated by receptive activities, internal thought and external interaction. We initially focus on motor behavior with a traditional task construction constraining the participant to watch, imagine and then attempt or actually move. We expand this to spontaneous activity in Aim 2. Finally, we move toward more general and abstracted investigations of volitional state by looking at an analogous task and spontaneous behavior with respect to language and communication (Aim 3). At each stage we will employ spectral, functional connectivity and data mining techniques to understand the neural underpinnings of these different states as well as the temporal dynamics that portend changes in state. Supporting all of these aims will be improvements and expansions in state-of-the-art human micro- and mesoscale neural recording environments to enable the study of continuous, real-time neural activity underlying state changes. Across aims we will explore the extent to which motor cortex alone contains the information which may be present in more widespread and higher order cortical regions. Our hypothesis is that motor cortex, does in fact, encode significant information about state in ways which encapsulate or summarize the information available in more wide spread regions. Most importantly, the questions inherent in this research are key to understanding human thought patterns at a fundamental level. This understanding has important implications not just for basic cognitive neuroscience but for our understanding of the processes which are altered in a wide range of neuropsychiatric disorders such as epilepsy, the dementias, depression, and psychosis. The results of these studies are also essential for the practical instantiation of effective brain-machine interfaces which would allow patients to act autonomously. Narrative: From simple decisions to more significant and complex thoughts, we constantly shift our aims and intentions and the degree to which we are interacting externally or internally. Understanding these shifts is key to the development of truly autonomous brain-computer interfaces and neuroprosthetics as well as to understanding how these kinds of alterations can be compromised in a wide variety of neuropsychiatric diseases. In this project we go beyond routine cognitive studies based on constrained stimulus response designs and instead utilize continuous recordings of neural activity during spontaneous behavior to decode changes in volitional state during motor activity and communication.",Understanding the Neural Basis of Volitional State through Continuous Recordings in Humans,9551101,U01NS098968,"['Area', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Classification', 'Clinical Trials', 'Cognitive', 'Communication', 'Complex', 'Data', 'Dementia', 'Development', 'Dimensions', 'Encapsulated', 'Environment', 'Epilepsy', 'Evaluation', 'Evoked Potentials', 'Goals', 'Hearing', 'Human', 'Implant', 'Intention', 'Investigation', 'Language', 'Liquid substance', 'Machine Learning', 'Measures', 'Mediator of activation protein', 'Mental Depression', 'Microelectrodes', 'Motor', 'Motor Activity', 'Motor Cortex', 'Movement', 'Nature', 'Neurocognitive', 'Neurons', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Paralysed', 'Parietal', 'Participant', 'Pathologic', 'Patients', 'Pattern', 'Process', 'Psychotic Disorders', 'Research', 'Response to stimulus physiology', 'Sleep', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thinking', 'Time', 'Volition', 'Work', 'Writing', 'analytical tool', 'awake', 'base', 'brain computer interface', 'brain machine interface', 'cognitive neuroscience', 'cognitive process', 'data mining', 'design', 'expectation', 'experimental study', 'insight', 'multi-electrode arrays', 'neural circuit', 'neuromechanism', 'neurophysiology', 'neuroprosthesis', 'neuropsychiatric disorder', 'novel', 'relating to nervous system', 'sensor']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,U01,2018,1528951,-0.008443190541631392
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions Project Summary/Abstract People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. Project Narrative People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9644103,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Personal Satisfaction', 'Persons', 'Phase', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'manufacturability', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2018,519349,0.024595227226277484
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9432500,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'recruit', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,651980,-0.05213281438464142
"Customized Health Alerts and Consumer-Centered Interfaces Using In-Home and Wearable Sensors In-home sensing technologies hold enormous potential for early detection of health changes that can dramatically affect the experiences of aging: enabling functional independence, improving self-management of chronic or acute conditions, and improving quality of life. Chronic diseases especially affect older adults. Problems in chronic disease management are often the cause of losing independence for aging Americans. In 2012, 1 in 2 American adults (117 million) had at least one chronic condition, and 26% of the population had multiple chronic conditions, accounting for 84% of US health care costs. Early illness recognition and early treatment is key to improving health status with rapid recovery after an exacerbation of a chronic illness or acute illness, and also key to reducing morbidity and mortality in older adults and controlling health care costs.  In previous work, the team developed a health alert system that captures and analyzes data from sensors embedded in the home. Sensor data are captured passively and continuously in the home. In a pilot NIH R21 study, significant differences in health outcomes were shown with health alerts from motion and bed sensor data, based on bed restlessness and low, normal, and high pulse and respiration rates. The system actually detected changes in chronic diseases or acute illnesses on average 10 days to 2 weeks before usual assessment methods or self-reports of illness. For this project, the team will expand from the clinician-focused system to a consumer-focused system by incorporating more finely grained sensing (gait and quantitative pulse and respiration), with new improved algorithms that integrate individual health status and medication use, and track trajectories of health changes, for more sensitive, and more personalized health alerts with fewer false alarms. A recently developed bed sensor will be incorporated to passively capture quantitative pulse, respiration, and restlessness while the subject is resting. Gait parameters (e.g., in-home walking speed, stride time and stride length) will also be captured using depth images that show shadowy silhouettes. In addition, the team will solicit the consumer perspective on customized health alerts and a user interface for displaying sensor and alert information. The views of seniors and their family members will be used to inform the development of the new customized alert algorithms and drive the development of a consumer-focused interface that will provide empowering tools for self-management of chronic illnesses. In addition, the use of commercially available wrist-worn sensors will be explored for the purpose of recognizing health changes. The study will include a retrospective analysis of sensor data collected in 13 senior housing sites in Missouri. New participants will be recruited in 5 senior housing sites in Columbia, MO to investigate the consumer perspective. The important process of engaging consumers in this work is the next step in translating these systems into clinical practice for self-managing chronic health conditions, supporting seniors living independently. PROJECT NARRATIVE We will build on our current work using intelligent, in-home sensor systems with automated health alerts to investigate new health alert algorithms that are more sensitive and more customized to the individual. These will be tested with data from 13 senior housing sites in Missouri using clinician feedback and actual health trajectories for evaluation. We will also recruit subjects in independent living housing to solicit the views of consumers on wearable sensors, health alerts, and user interfaces that allow seniors and their family members to view the health alert information in a way that empowers them to better self-manage their own health.",Customized Health Alerts and Consumer-Centered Interfaces Using In-Home and Wearable Sensors,9355893,R01NR016423,"['Accounting', 'Acute', 'Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Aging', 'Agitation', 'Algorithms', 'American', 'Beds', 'Caregivers', 'Chronic', 'Chronic Disease', 'Complex', 'Custom', 'Data', 'Data Analyses', 'Development', 'Disease Management', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Family', 'Family member', 'Feedback', 'Gait', 'Grain', 'Health', 'Health Care Costs', 'Health Status', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Housing', 'Image', 'Independent Living', 'Individual', 'Length', 'Length of Stay', 'Machine Learning', 'Methods', 'Missouri', 'Monitor', 'Morbidity - disease rate', 'Motion', 'Nursing Homes', 'Outcome', 'Participant', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevention', 'Privacy', 'Process', 'Quality of life', 'Recovery', 'Respiration', 'Rest', 'Retrospective Studies', 'Self Management', 'Site', 'System', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Walking', 'Work', 'Wrist', 'active control', 'base', 'clinical practice', 'clinically relevant', 'cost', 'design', 'empowered', 'experience', 'fall risk', 'fitness', 'health assessment', 'health difference', 'improved', 'information display', 'mortality', 'multiple chronic conditions', 'preference', 'recruit', 'sensor', 'sensor technology', 'tool', 'walking speed', 'wearable device']",NINR,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2018,92000,-0.009135386249535138
"Neural dynamics and adaption for brain machine interface control Project Summary/Abstract  Millions of people suffer from some form of paralysis. In most of these cases the connection between the brain and the spinal cord is damaged, however, the motor cortex is healthy and intact. Thus, for these individuals, brain-machine interfaces (BMIs) hold significant promise for improving quality of life. BMIs decode an individual's intention to move by utilizing statistical models of neural activity patterns recorded from the motor cortex using implanted electrode arrays. While these methods have been encouraging in preclinical experiments and clinical trials for controlling thought-driven 2D computer cursors, they suffer from poor performance when applied to higher degrees-of-freedom (e.g., robotic limbs), and are not robust to the inevitable degradation of the electrode array. In order to address these clinical needs, this project starts from the recent observation that just as some behaviors are easier to learn, some patterns of neural activity, termed neural states, are also easier to generate. The overarching goal of this project is to elucidate if these “easy to generate” neural states can be used to robustly control a prosthetic arm. This is a significant departure from current decoding methods, which incorporate little to no information about the motor system, especially its ability to learn and adapt. The first major aim of this work is to develop experiments and analysis methods in order to find these “easy to generate” neural states in the non- human primate (i.e., rhesus monkey) motor system. Here “easy to generate” can be understood as the monkey's ability to volitionally generate that particular neural state. The second major aim of this work is to characterize the properties of the motor system that enable some states to be more easily generated than others. Prior work in our lab has shown that motor cortical population activity has well-defined structure, as predicted by dynamical system theory. These dynamics cause neural states to evolve in lawful ways through time. The work here will extend these findings by characterizing the dynamics associated with a monkey learning to generate a neural state. Finally, the third major aim of this work is to determine if neural states that monkeys can volitionally generate can be utilized for robust control of a prosthetic arm. The central hypothesis of this work is that building a model that only utilizes firing patterns that can be easily generated (as determined experimentally) will enable robust and high-performance control of a prosthetic arm. If successful, this study could have significant clinical impact by presenting a new paradigm to enable robust control of a prosthesis. Project Narrative  Millions of people worldwide suffer from neurological injuries or neurodegenerative diseases that result in considerable movement impairment. Brain machine interfaces (BMIs) hold considerable promise in drastically improving the quality of life for these individuals, who otherwise have very limited treatment options. This work will investigate the motor system's ability to learn and adapt, and directly use these insights to build robust high degree-of-freedom BMIs for clinical applications.",Neural dynamics and adaption for brain machine interface control,9573606,F31NS103409,"['Address', 'Area', 'Artificial Arm', 'Automobile Driving', 'Behavior', 'Brain', 'Clinical', 'Clinical Trials', 'Complex', 'Computers', 'Coupled', 'Data', 'Devices', 'Dimensions', 'Electrodes', 'Freedom', 'Generations', 'Goals', 'Implanted Electrodes', 'Individual', 'Intention', 'Joint Prosthesis', 'Joints', 'Learning', 'Limb Prosthesis', 'Limb structure', 'Link', 'Literature', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Neurodegenerative Disorders', 'Neurons', 'Paralysed', 'Pattern', 'Performance', 'Population', 'Property', 'Prosthesis', 'Quality of life', 'Rehabilitation therapy', 'Robotics', 'Spinal Cord', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Systems Theory', 'Techniques', 'Technology', 'Time', 'Training', 'Visual', 'Volition', 'Work', 'arm', 'arm movement', 'brain machine interface', 'clinical application', 'dynamic system', 'experimental study', 'falls', 'high dimensionality', 'improved', 'insight', 'motor impairment', 'neural model', 'neural patterning', 'neurophysiology', 'neuroregulation', 'nonhuman primate', 'pre-clinical', 'prosthesis control', 'rehearsal', 'relating to nervous system']",NINDS,STANFORD UNIVERSITY,F31,2018,34064,0.022716180006616647
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9517057,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'International', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Radiology Specialty', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Screening procedure', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging study', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'perfusion imaging', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'single photon emission computed tomography', 'skills', 'success', 'validation studies', 'virtual', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2018,169609,-0.03170440075110493
"An evaluation of sensor technology to monitor and report compliance with an evidence-based intervention to prevent ventilator-associated pneumonia ﻿    DESCRIPTION (provided by applicant):  The candidate, Nishi Rawat, is a Critical Care physician and Assistant Professor in the Department of Anesthesiology and Critical Care Medicine at Johns Hopkins. Her goal is to become an independent investigator focused on advancing the field of quality improvement to improve the quality of health care delivered to Americans, while simultaneously reducing costs, with an emphasis on the application of information technology to evaluate performance, minimize waste and eliminate redundancies.  The candidate's preliminary work as a co-investigator for two collaboratives to reduce ventilator-associated pneumonia (VAP) suggests that there is a strong drive to eliminate preventable harms such as VAP, but weak available methodologies and resources to do so. There is a dire need for an effective and inexpensive methodology to track the delivery of evidence-based interventions for the purpose of quality improvement. The proposed research intends to fill this measurement gap. In this proposal, she evaluates the utility of the sensor approach for measuring and improving quality of care, focusing on VAP prevention intervention performance.  The aims propose: evaluate the utility of the sensor approach for measuring compliance with a VAP prevention intervention by comparing VAP process measure performance estimates captured by sensor technology to estimates obtained by traditional manual data collection (Aim 1); design and pilot a strategy to provide real-time feedback of sensor process measure compliance to providers (Aim 2); evaluate the impact of the sensor approach on VAP process measure compliance by comparing compliance before and after the implementation of the real-time feedback strategy (Aim 3). The proposed work could fundamentally change how healthcare monitors and reports important care interventions, and has the potential to make quality improvement more efficient, inexpensive and scalable.  The candidate is uniquely qualified to undertake the proposed work. She is double-board certified in Critical Care and Emergency Medicine, and has completed a Patient Safety and Quality fellowship. She has led multiple local quality improvement initiatives, and worked to decrease ICU costs as part of a national task force, and is currently co-investigator of large national infection prevention collaborative. It isher determination, enthusiasm and strong work ethic which have enabled her to balance these research activities with a heavy clinical commitment. She now needs protected time for research and career development to become an independent investigator. PUBLIC HEALTH RELEVANCE: The goal of this proposal is to improve quality of care by using low-cost, off-the-shelf, and non-invasive sensor technology to automate the measurement and feedback of data regarding whether patients receive an evidence-based intervention, patient mobilization, to prevent ventilator-associated pneumonia.",An evaluation of sensor technology to monitor and report compliance with an evidence-based intervention to prevent ventilator-associated pneumonia,9391190,K23HL125982,"['Adherence', 'Adverse event', 'Advisory Committees', 'American', 'Anesthesiology', 'Big Data', 'Caring', 'Charge', 'Childhood', 'Clinical', 'Critical Care', 'Data', 'Data Collection', 'Data Science', 'Emergency Medicine', 'Engineering', 'Environment', 'Equilibrium', 'Evaluation', 'Event', 'Evidence based intervention', 'Feedback', 'Fellowship', 'Focus Groups', 'Frustration', 'Funding', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Human', 'Infection prevention', 'Information Technology', 'Intervention', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Nosocomial Infections', 'Nurses', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physician Assistants', 'Prevention', 'Prevention Measures', 'Preventive Intervention', 'Process', 'Process Measure', 'Provider', 'Quality of Care', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Techniques', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States Dept. of Health and Human Services', 'United States National Institutes of Health', 'Work', 'Work Ethic', 'base', 'care delivery', 'career development', 'cost', 'design', 'health care quality', 'improved', 'innovation', 'multi-component intervention', 'novel', 'patient mobility', 'patient safety', 'preference', 'pressure', 'prevent', 'professor', 'prospective', 'public health relevance', 'research and development', 'response', 'sensor', 'sensor technology', 'tool', 'ventilator-associated pneumonia', 'wasting']",NHLBI,JOHNS HOPKINS UNIVERSITY,K23,2018,197848,0.009717168293769318
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9504668,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2018,727051,0.0008201762125645231
SCH: INT: A Context-aware Cuff-less Wearable Ambulatory Blood Pressure Monitor using a Bio-Impedance Sensor Array  n/a,SCH: INT: A Context-aware Cuff-less Wearable Ambulatory Blood Pressure Monitor using a Bio-Impedance Sensor Array,9756906,R01EB028106,"['Address', 'Adult', 'Affect', 'Aging', 'Algorithms', 'Ambulatory Blood Pressure Monitoring', 'American', 'American Heart Association', 'Arteries', 'Awareness', 'Biological Markers', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood Vessels', 'Calibration', 'Cardiology', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Caring', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Frequencies', 'Funding', 'Grain', 'Guidelines', 'Health Sciences', 'Home environment', 'Hour', 'Human Resources', 'Hypertension', 'Institutes', 'Institution', 'International', 'Intervention Trial', 'Investigation', 'Laboratories', 'Left ventricular structure', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Patients', 'Pattern', 'Phenotype', 'Physicians', 'Physiologic pulse', 'Physiological', 'Play', 'Positioning Attribute', 'Posture', 'Preventive Intervention', 'Reading', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Site', 'Skin', 'Source', 'Specific qualifier value', 'Speed', 'Sphygmomanometers', 'System', 'Technology', 'Testing', 'Texas', 'Time', 'Tissues', 'Travel', 'United States National Institutes of Health', 'Universities', 'Validation', 'Wearable Computer', 'Wrist', 'base', 'blood perfusion', 'cardiovascular disorder risk', 'clinical practice', 'cohesion', 'college', 'cost', 'design', 'disability-adjusted life years', 'disorder prevention', 'electric impedance', 'health disparity', 'hypertension control', 'learning strategy', 'minority health', 'novel', 'novel strategies', 'patient population', 'sensor', 'signal processing', 'therapy development', 'validation studies', 'wearable device']",NIBIB,TEXAS ENGINEERING EXPERIMENT STATION,R01,2018,299998,0.022878279132992466
"Controlling Locomotion over Continuously Varying Activities for Agile Powered Prosthetic Legs PROJECT ABSTRACT Above-knee amputees often struggle to perform the varying activities of daily life with conventional prostheses. Emerging powered knee-ankle prostheses have motors that can restore normative biomechanics, but these devices are limited to a small set of pre-defined activities that must be tuned to the user by technical experts over several hours. The overall goal of this project is to model and control human locomotion over continuously varying tasks for the design of agile, powered prostheses that require little to no tuning. The universal use of different task-specific controllers in current powered legs is a direct consequence of the prevailing paradigm for viewing human locomotion as a discrete set of activities. There is a fundamental gap in knowledge about how to analyze, model, and control continuously varying locomotion, which greatly limits the adaptability and agility of powered prostheses. The central hypothesis of this project is that continuously varying activities can be represented by a single mathematical model based on measureable physical quantities called task variables. The proposed project will be scientifically significant to understanding how humans continuously adapt to varying activities and environments, technologically significant to the design of agile, user-synchronized powered prosthetic legs, and clinically significant to the adoption of powered knee-ankle prostheses for improved community ambulation. The proposed model of human locomotion will enable new prosthetic strategies for controlling and adapting to the environment, which aligns with the missions of the NICHD/NCMRR Devices and Technology Development program area and the NIBIB Mathematical Modeling, Simulation, and Analysis program. The innovation of this work is encompassed in 1) a continuous paradigm for variable locomotor activities that challenges the existing discrete paradigm, 2) a unified task control methodology that drastically improves the agility of powered prosthetic legs, and 3) a partially automated tuning process that significantly reduces the time and technical expertise required to configure powered knee- ankle prostheses. This continuous task paradigm will provide new methods and models for studying human locomotion across tasks and task transitions. This innovation will address a key roadblock in control technology that currently restricts powered legs to a small set of activities that do not generalize well across users. The adaptability of the proposed control paradigm across users and activities will transform the prosthetics field with a new generation of “plug-and-play” powered legs for community ambulation. PROJECT NARRATIVE The proposed research is relevant to public health because the clinical application of variable-activity powered prosthetic legs can significantly improve community mobility and therefore quality of life for nearly a million American amputees. Recently developed powered knee-ankle prostheses are limited to a small set of pre- defined activities that require several hours of expert tuning for each user. This project will model and control human locomotion over continuously varying tasks for the design of agile, powered prostheses that require little to no tuning, which aligns with the missions of the Devices and Technology Development program area of the NICHD National Center for Medical Rehabilitation Research and the Mathematical Modeling, Simulation, and Analysis program of the NIBIB.",Controlling Locomotion over Continuously Varying Activities for Agile Powered Prosthetic Legs,9596236,R01HD094772,"['Address', 'Adoption', 'American', 'Amputees', 'Ankle', 'Area', 'Artificial Leg', 'Biomechanics', 'Clinical', 'Communities', 'Computer Simulation', 'Data', 'Degree program', 'Device or Instrument Development', 'Devices', 'Doctor of Philosophy', 'Electrical Engineering', 'Environment', 'Gait', 'Gait speed', 'Generations', 'Goals', 'Gray unit of radiation dose', 'Hand', 'Home environment', 'Hour', 'Human', 'Human body', 'Joints', 'Knee', 'Knowledge', 'Lead', 'Leg', 'Life', 'Locomotion', 'Lower Extremity', 'Machine Learning', 'Measurable', 'Measures', 'Mechanics', 'Medical center', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motor', 'Motor Activity', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'Orthotic Devices', 'Outcome', 'Phase', 'Play', 'Process', 'Program Development', 'Prosthesis', 'Public Health', 'Quality of life', 'Rehabilitation Research', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Speed', 'Spinal cord injury', 'Stroke', 'Study models', 'System', 'Technical Expertise', 'Technology', 'Time', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'clinical application', 'clinically significant', 'design', 'exoskeleton', 'experience', 'human data', 'human model', 'improved', 'innovation', 'kinematics', 'mathematical model', 'multidisciplinary', 'orthotics', 'powered prosthesis', 'programs', 'prosthesis control', 'robot control', 'sensor', 'success', 'technology development', 'temporal measurement', 'trend']",NICHD,UNIVERSITY OF TEXAS DALLAS,R01,2018,474602,0.012340721156814165
"Psychophysics of Reading - Normal and Low Vision DESCRIPTION (provided by applicant):  Psychophysics of Reading - Normal and Low Vision Abstract Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  Difficulty in accessing print imposes obstacles to education, employment, social interaction and recreation.  The ongoing transition to the production and distribution of digital documents brings about new opportunities for people with visual impairment.  Digital documents on computers and mobile devices permit easy manipulation of print size, contrast polarity, font, page layout and other attributes of text.  In short, we now hae unprecedented opportunities to adapt text format to meet the needs of visually impaired readers.  In recent years, our laboratory and others in the vision-science community have made major strides in understanding the impact of different forms of low vision on reading, and the dependence of reading performance on key text properties such as character size and contrast.  But innovations in reading technology have outstripped our knowledge about low-vision reading.  A major gap still exists in translating these laboratory findings into methods for customizing text displays for people with low vision.  The broad aim of the current proposal is to apply our knowledge about the impact of vision impairment on reading to provide tools and methods for enhancing reading accessibility in the modern world of digital reading technology.  Our research plan has three specific goals:   1) To develop and validate an electronic version of the MNREAD test of reading vision, to extend this technology to important text variables in addition to print size, and to develop methods for customizing the selection of text properties for low-vision readers.  MNREAD is the most widely used test of reading in vision research and was originally developed in our laboratory with NIH support.  2) To investigate the ecology of low-vision reading in order to better understand how modern technologies, such as iPad and Kindle are being used by people with low vision.  We plan to evaluate the feasibility of using internet methods to survey low-vision individuals concerning their reading behavior and goals, and of collecting approximate measures of visual function over the internet.  We also plan to develop an ""accessibility checker"" to help low-vision computer users and their families to evaluate the accessibility of specific text displays.  3) To enhance reading accessibility by developing methods for enlarging the visual span (the number of adjacent letters that can be recognized without moving the eyes).  A reduced visual span is thought to be a major factor limiting reading in low vision, especially for people with central-field loss from macular degeneration.  We have already demonstrated methods for enlarging the visual span in peripheral vision.  We plan to develop a more effective perceptual training method for enlarging the visual span, with the goal of improving reading performance for people with central-vision loss. PUBLIC HEALTH RELEVANCE:  Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  The ongoing transition to the use of digital documents on computers and mobile devices brings about new opportunities for customizing text for people with visual impairment.  We propose to apply findings from basic vision science on low vision and reading to develop tools and methods for enhancing reading accessibility for digital text.",Psychophysics of Reading - Normal and Low Vision,9474120,R01EY002934,"['American', 'Attention', 'Auditory', 'Behavior', 'Blindness', 'Books', 'Caring', 'Central Scotomas', 'Characteristics', 'Clinical Research', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Custom', 'Dependence', 'Development', 'Devices', 'Ecology', 'Education', 'Employment', 'Eye', 'Family', 'Galaxy', 'Goals', 'Government', 'Guidelines', 'Habits', 'Health', 'Individual', 'Internet', 'Knowledge', 'Laboratories', 'Laboratory Finding', 'Leg', 'Length', 'Letters', 'Life', 'Macular degeneration', 'Mainstreaming', 'Maps', 'Marshal', 'Measures', 'Methods', 'Modernization', 'Optics', 'Paper', 'Participant', 'Patients', 'Perceptual learning', 'Performance', 'Peripheral', 'Play', 'Policies', 'Printing', 'Production', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysics', 'Reader', 'Reading', 'Recreation', 'Reporting', 'Research', 'Resources', 'Role', 'Self-Help Devices', 'Social Interaction', 'Surveys', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Work', 'analog', 'base', 'design', 'digital', 'essays', 'handheld mobile device', 'improved', 'innovation', 'invention', 'large print', 'literate', 'public health relevance', 'reading difficulties', 'sound', 'symposium', 'tool', 'vision science', 'web-accessible']",NEI,UNIVERSITY OF MINNESOTA,R01,2018,364257,-0.02090116883455783
"Multi-scale network dynamics of human upper limb movements: characterization and translation to neuroprosthetics DESCRIPTION (provided by applicant):  The overall project goals are to study the cortical network dynamics of human upper limb motor control spanning two distinct spatial scales recorded with electrocorticography (ECoG), and to demonstrate that these dynamics can be estimated in real-time and used to control the JHU Applied Physics Lab Modular Prosthetic Limb (MPL) during execution of functionally useful complex action sequences.  Our human subjects will be instructed to perform complete functional movements characteristic of activities of daily living.  We will analyze the task-related temporal evolution in the strength and pattern of interactions among large-scale cortical networks known to be recruited in visually-guided reach-to-grasp tasks.  Using multi-scale subdural ECoG with combinations of routine clinical macro-electrodes (2.3 mm diameter, 1 cm spacing) recording activity of broadly spread elements/nodes of neural networks, and inset arrays of microelectrodes (75 μm diameter, 0.9 mm spacing) recording the activity of local sub-networks, we will test our overall hypothesis that there is a functional hierarchy between the two scales (Aim 1).  More specifically, we hypothesize that large-scale network dynamics involving premotor/motor cortex reflect the evolution of sensory-motor processing demands during complex action sequences, while micro-scale population activity and network dynamics in motor cortex reflect the low-level kinematics of these tasks.  We will utilize methods of estimating dynamic effective connectivity developed by our team to study interactions between these scales and test whether there exists a spatially heterogeneous and hierarchical structure within the macro-micro scale networks.  The results of these analyses have wide-ranging clinical implications for both the optimal scale of functional mapping for clinical diagnostic purposes and the extent of implantations for neuroprosthetic control.  We will exploit multi-scale ECoG recordings and online estimates of the dynamics of neural activation and large-scale/local network interactions to achieve control of the MPL during functionally useful tasks (Aim 2).  This approach will go beyond traditional paradigms that have developed neural control over individual degrees of freedom.  We will do this by embedding low-level control within an innovative framework whereby knowledge of task goals supplement direct kinematic decoding.  This project will build on our team's previous successes in implementing a system for semi-autonomous ECoG control of the MPL, employing machine vision and route-planning algorithms, during complex interactions with objects requiring the coordination of multiple joints.  This system will be able to leverage for the first time the rich complexity of temporally and spatially resolved network dynamics correlated with high-level goals to achieve functionally useful control of an advanced neuroprosthetic limb. PUBLIC HEALTH RELEVANCE:  For ""Multi-scale network dynamics of human upper limb movements:  characterization and translation in neuroprosthetics"" This project will use recordings from the surface of the human brain to study how brain networks control arm and hand movements.  We will also test whether information about these networks can be used to control an advanced robotic prosthetic arm.  This could have a profound long-term impact on future generations of patients seeking to restore lost upper limb function with a lifelike prosthesis.",Multi-scale network dynamics of human upper limb movements: characterization and translation to neuroprosthetics,9503791,R01NS088606,"['Activities of Daily Living', 'Algorithms', 'Area', 'Artificial Arm', 'Attention', 'Biological Neural Networks', 'Brain', 'Caliber', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complex', 'Computer Assisted', 'Computer Vision Systems', 'Cues', 'Eating', 'Electrocorticogram', 'Electrodes', 'Elements', 'Epilepsy', 'Evolution', 'Freedom', 'Future Generations', 'Goals', 'Hand', 'Human', 'Human body', 'Individual', 'Joints', 'Knowledge', 'Limb Prosthesis', 'Limb structure', 'Location', 'Measures', 'Mediating', 'Methods', 'Microelectrodes', 'Modeling', 'Modification', 'Motor', 'Motor Cortex', 'Movement', 'Neurosciences', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Performance', 'Physics', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Prosthesis', 'Resolution', 'Robotics', 'Route', 'Sampling', 'Sensory', 'Signal Transduction', 'Site', 'Structure', 'Surface', 'System', 'Testing', 'Time', 'Training', 'Translations', 'Upper Extremity', 'Upper limb movement', 'Vision', 'arm', 'clinical diagnostics', 'drinking', 'grasp', 'human subject', 'implantation', 'innovation', 'joint mobilization', 'kinematics', 'motor control', 'multisensory', 'neuroprosthesis', 'neuroregulation', 'public health relevance', 'recruit', 'relating to nervous system', 'success', 'temporal measurement', 'time use', 'translational impact']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2018,354375,0.014994853177007926
"Active Sensation during Odor-Guided Navigation in Mice PROJECT SUMMARY We often consider our movements a result of sensory processing – sensation guides behavior. However, animals selectively shape future sensory input through their own actions in a process known as active sampling. Thus, action and sensation are inextricably linked. Despite this, much of the research done on sensory processing restricts movement, most commonly via head fixation. To access sensorimotor processing during more natural behavior, we will study olfactory navigation in freely-moving mice. The olfactory system is ideal for studying sensory sampling, because of its ethological relevance for mammalian foraging and the dynamic nature of airborne odor stimuli. The proposed research will determine the sampling strategies of olfactory search and reveal the underlying circuitry that connects sensation with motion. Aim 1. It is unknown how rodents navigate dynamic plumes of odorant towards an odor source. In this aim, we will identify, analyze, and model active sensing behaviors that occur during increasingly difficult navigation tasks and with single nostrils occluded. These experiments will test the hypothesis that olfactory navigation works as a sensorimotor closed-loop system, where animals optimize sampling behaviors for the current stimulus conditions. These behavioral studies will lay the foundation for investigations of sensorimotor processing in dynamic olfactory scenes. Aim 2. To determine how sampling movements shape sensation, we will monitor neural activity during active sensory behavior. During odor tracking, we will electrophysiologically record in the olfactory bulb, a bottleneck through which all sensory input passes. We will determine the sensory history dependence of active sampling and, in doing so, reveal part of the underlying circuitry that connects motion with sensation. These experiments will test the hypothesis that sampling movements are sensory history dependent. To our knowledge, sampling movements and sensory activity have never been simultaneously recorded during olfactory navigation. This research will advance our understanding of the interplay between sensation and motion during natural behavior. PROJECT NARRATIVE Deficits in sensory motor communication are a major contributor to prevalent neurological disorders such as schizophrenia and Parkinson's disease. Our assay of olfactory navigation will model the interaction between sensation and movement and identify the circuitry through which movements are decided by sensory input. Discovering mechanisms of sensorimotor integration are the key to a better understanding of sensory processing in these disorders, since sensation and action are inextricably linked.",Active Sensation during Odor-Guided Navigation in Mice,9563948,F31DC016799,"['Animals', 'Anterior nares', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Biological Assay', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Disease', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Foundations', 'Future', 'Genetic', 'Head', 'Implant', 'Intake', 'Intervention Studies', 'Investigation', 'Link', 'Modeling', 'Monitor', 'Motion', 'Motor', 'Movement', 'Mus', 'Nature', 'Neurons', 'Nose', 'Odors', 'Olfactory Pathways', 'Output', 'Parkinson Disease', 'Pattern', 'Perception', 'Positioning Attribute', 'Process', 'Recording of previous events', 'Research', 'Respiration', 'Rewards', 'Rodent', 'Sampling', 'Schizophrenia', 'Sensory', 'Shapes', 'Smell Perception', 'Source', 'Stereotyping', 'Stimulus', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Vertebrates', 'Vision', 'Work', 'base', 'behavioral study', 'design', 'experimental study', 'insight', 'nervous system disorder', 'olfactory bulb', 'olfactory stimulus', 'relating to nervous system', 'sample fixation', 'sensory input', 'sensory stimulus', 'sensory system', 'tool']",NIDCD,UNIVERSITY OF OREGON,F31,2018,33530,-0.005959853994788
"Auditory brain-computer interface for communication No abstract available Project Narrative Brain-computer interfaces enable motor-impaired individuals to communicate using an effector such as a neural cursor or a robotic arm. The successful completion of the proposed project will develop a unique technology that enables a real-time auditory-reliant BCI for communication in severely paralyzed individuals resulting from stroke, amyotrophic lateral sclerosis and severe brain injuries. Study results will advance our knowledge of developing neurotechnologies that leverage non-visual sensory modalities, as well as provide much insight into the cortical neural activities that underpin motor intention and movement.",Auditory brain-computer interface for communication,9668360,F32MH118709,"['Adult', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Auditory', 'Auditory system', 'Base of the Brain', 'Brain Injuries', 'Brain Stem Infarctions', 'Clinical Trials', 'Communication', 'Computers', 'Cues', 'Data', 'Development', 'Devices', 'Eye Movements', 'Family Caregiver', 'Fatigue', 'Feedback', 'Frequencies', 'Functional disorder', 'Future Generations', 'Goals', 'Human', 'Impairment', 'Individual', 'Institution', 'Intention', 'Joystick', 'Knowledge', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Manuals', 'Measures', 'Modality', 'Motor', 'Movement', 'Mus', 'Neurologic', 'Ophthalmopareses', 'Paralysed', 'Participant', 'Pathologic Nystagmus', 'Pathway interactions', 'Patients', 'Performance', 'Positioning Attribute', 'Psyche structure', 'Quadriplegia', 'Quality of life', 'Research', 'Research Infrastructure', 'Resources', 'Robotics', 'Sensory', 'Signal Transduction', 'Social Interaction', 'Sound Localization', 'Speech', 'Spinal cord injury', 'Stroke', 'System', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Traumatic Brain Injury', 'Universities', 'User-Computer Interface', 'Vision', 'Visual', 'Visual Fields', 'Visual impairment', 'Workload', 'Writing', 'arm', 'auditory feedback', 'base', 'brain computer interface', 'engineering design', 'improved', 'insight', 'motor impairment', 'neurotechnology', 'neurotransmission', 'novel', 'oculomotor', 'relating to nervous system', 'spelling', 'success', 'usability', 'virtual', 'visual feedback', 'way finding']",NIMH,BROWN UNIVERSITY,F32,2018,68154,-0.044185758800324125
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning. PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,9133939,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Awareness', 'Behavior', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Conscious', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Foundations', 'GTP-Binding Protein alpha Subunits, Gs', 'Hand functions', 'Head', 'Head Movements', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Research', 'Robot', 'Robotics', 'Subconscious', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'public health relevance', 'robot control', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2017,133916,0.01455418001975286
"Adaptive Prediction of Blood Glucose Levels using Wearable Physiological Sensors ﻿    DESCRIPTION (provided by applicant): Type 1 diabetes is a chronic disease, which presently cannot be prevented or cured. It is treated with insulin therapy and actively managed through blood glucose (BG) control. To avoid serious diabetic complications, patients must monitor their BG levels throughout the day, striving to avoid both hyperglycemia (high BG levels) and hypoglycemia (low BG levels). While continuous glucose monitoring (CGM) sensors and insulin pumps with ﬂexible dosing may aid in achieving good BG control, management of diabetes is still difﬁcult and laborious for patients and physicians. It is complicated by a wide variability among individual patients in terms of physiological responses to treatment as well as to life events such as stress, exercise, or changes in schedule and sleep. New portable sensing technologies have been recently developed for providing almost continuous measure- ments of an array of physiological parameters that include heart rate, skin conductance, skin temperature, and properties of body movements such as acceleration. The main research objective of this project is to leverage data acquired from wearable physiological sensors to build accurate, personalized blood glucose level prediction models for diabetes management. Predicting BG control problems before they occur would give patients time to intervene and prevent these problems. This would enhance patient safety and contribute to improved overall control, with its concomitant reduction in costly complications. Blood glucose level prediction is  very complex problem. Recent advances in unsupervised feature learning and deep learning have made it possible to learn complex models from data using simple algorithms. Inspired by these signiﬁcant developments in Artiﬁcial Intelligence (AI), we propose to employ unsupervised feature learn- ing and deep learning techniques in order to build an architecture for modeling blood glucose behavior that can seamlessly incorporate data coming from any number of physiological sensors. A recurrent neu- ral network (RNN) will be trained to capture dependencies among the input physiological parameters that are relevant to BG prediction. To account for individual patient differences, a predictive model will be developed for each patient by training on the features discovered by the RNN. The primary impact of this work would be to improve the overall health and quality of life for the 1.25 million Americans with type 1 diabetes. Accurate prediction models would enable practical applications ranging from alerts of impending problems to decision support tools for evaluating the effects of different food or lifestyle choice. Additionally, the wealth of patient and sensor data collected for this work will lead to the creatin of de-identiﬁed datasets to be used by the research community in evaluating approaches to blood glucose prediction. The new approaches developed for this complex domain may aid in the development of time series forecasting models for a broad array of sensor-enabled applications in other health and wellness domains. PUBLIC HEALTH RELEVANCE: To aid in diabetes management, machine learning models will be built to predict future blood glucose levels based on wearable sensor data from commercially available fitness bands in addition to blood glucose, insulin and meal data. These models could help the over one million Americans with type 1 diabetes to anticipate and prevent blood glucose control problems before they occur. This would enhance patient safety and contribute to improved overall blood glucose control, with its associated reduction in costly complications.",Adaptive Prediction of Blood Glucose Levels using Wearable Physiological Sensors,9272400,R21EB022356,"['Acceleration', 'Algorithms', 'American', 'Amputation', 'Architecture', 'Area', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Blindness', 'Blood Glucose', 'Carbohydrates', 'Chronic Disease', 'Communities', 'Complex', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Decision Support Systems', 'Dependency', 'Development', 'Diabetes Mellitus', 'Dose', 'Engineering', 'Equation', 'Event', 'Exercise', 'Expenditure', 'Food', 'Future', 'Galvanic Skin Response', 'Health', 'Health Care Costs', 'Heart Rate', 'Hyperglycemia', 'Hypoglycemia', 'Individual', 'Insulin', 'Insulin Infusion Systems', 'Insulin-Dependent Diabetes Mellitus', 'Intelligence', 'Intervention', 'Kidney Failure', 'Knowledge', 'Learning', 'Life', 'Life Style', 'Machine Learning', 'Manuals', 'Mathematics', 'Measurement', 'Modeling', 'Monitor', 'Movement', 'Myocardial Infarction', 'Patient Education', 'Patients', 'Performance', 'Physicians', 'Physiological', 'Property', 'Quality of life', 'Recurrence', 'Research', 'Schedule', 'Scientist', 'Series', 'Signal Transduction', 'Skin Temperature', 'Sleep', 'Speed', 'Stress', 'Stroke', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Work', 'base', 'blood glucose regulation', 'collected works', 'cost', 'data modeling', 'diabetes management', 'direct application', 'fitness', 'flexibility', 'glucose monitor', 'improved', 'individual patient', 'multidisciplinary', 'novel strategies', 'patient safety', 'physiologic model', 'portability', 'practical application', 'predictive modeling', 'prevent', 'public health relevance', 'sensor', 'speech recognition', 'support tools', 'technology development', 'treatment response']",NIBIB,OHIO UNIVERSITY ATHENS,R21,2017,188594,-0.0010711097950013334
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9373088,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Cereals', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Darkness', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Technology', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'behavioral study', 'cognitive development', 'computerized', 'cost', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2017,243750,-0.010903167913208972
"Machine Learning-Based Control of Functional Electrical Stimulation Functional electrical stimulation involves artificial activation of paralyzed muscles with implanted electrodes and has been used successfully to improve the ability of quadriplegics to perform movements important for daily activities. The range of motor behaviors that can be generated by functional electrical stimulation, however, is limited to a relatively small set of preprogrammed movements such as hand grasp and release. A broader range of movements has not been implemented because of the substantial challenge associated with identifying the patterns of muscle stimulation needed to elicit specified movements. To address this limitation, we have developed machine-learning based algorithms that can predict patterns of muscle activity associated with a wide range of complex limb movements. In addition, we have devised a method whereby predicted patterns of muscle activity can then be transformed into stimulus pulse patterns needed to evoke movements in paralyzed limbs. Our goal for this project is to determine whether these approaches, when applied to temporarily paralyzed non-human primates, can be used to produce: 1) a wide range of movements of the hand throughout peri-personal reach space, and 2) configuration of the hand and fingers into a variety of shapes needed to interact with diverse objects in the environment. If successful, this approach would greatly expand the repertoire of motor behaviors available to individuals paralyzed because of spinal cord injury or stroke. Furthermore, this system ultimately might serve as the requisite interface between brain-derived trajectory information and functional electrical stimulation systems needed to realize a self-contained and self- controlled upper limb neuroprosthetic. The goal of this project is to develop methods to artificially activate and control paralyzed muscles with electrodes implanted in muscles. This effort will contribute to the restoration of voluntary limb movements in individuals paralyzed because of spinal cord injury or stroke.",Machine Learning-Based Control of Functional Electrical Stimulation,9436952,R56NS096064,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Animals', 'Behavior', 'Biological Neural Networks', 'Brain', 'Chronic', 'Complement', 'Complex', 'Data', 'Digit structure', 'Elbow', 'Electric Stimulation', 'Electrodes', 'Elements', 'Environment', 'Error Sources', 'Experimental Models', 'Fingers', 'Forearm', 'Goals', 'Hand', 'Health Benefit', 'Human', 'Implanted Electrodes', 'Individual', 'Intramuscular', 'Joints', 'Lifting', 'Limb structure', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Motor', 'Movement', 'Muscle', 'Muscle Contraction', 'Paralysed', 'Patients', 'Pattern', 'Personal Space', 'Physiologic pulse', 'Quadriplegia', 'Self-control as a personality trait', 'Shapes', 'Shoulder', 'Signal Transduction', 'Skeletal Muscle', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Training', 'Upper Extremity', 'Wrist', 'arm', 'awake', 'base', 'brain machine interface', 'design', 'experience', 'finger movement', 'grasp', 'hand grasp', 'human subject', 'improved', 'insight', 'kinematics', 'limb movement', 'neuroprosthesis', 'nonhuman primate', 'response', 'restoration', 'robotic device', 'scapula']",NINDS,UNIVERSITY OF ARIZONA,R56,2017,371219,0.02230006072403384
"Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor Summary The principal goal of this proposal is to increase the accuracy and precision of a low-cost autorefraction device called the QuickSee, in order to improve access to refractive eye care for underserved populations. Poor vision due to a lack of eyeglasses is highly prevalent in low-resource settings throughout the world and significantly reduces quality of life, education, and productivity. The existing QuickSee only extracts the lower- order aberration information contained within a wavefront profile of the eye, to roughly estimate an eyeglass prescription. This proposal will further improve the accuracy of the QuickSee device by exploiting both the lower- and higher-order aberrations contained within the complete wavefront. To realize this goal, we will enroll 300 subjects (600 eyes) in Baltimore, MD, and will obtain subjective refraction and visual acuity (VA) measurements and will use machine learning on this large dataset of wavefront profiles to optimize the wavefront-to-refraction algorithm of the QuickSee device. The main output of this project will be a robust and improved-accuracy next-generation QuickSee device that will increase efficiency of and decrease the training requirements of eye care professionals, and potentially dispense refractive correction that provides similar or better VA than correction from an eye care professional. Successful completion of this work will be an important step towards dramatically improving eyeglass accessibility for health disparity populations in the USA and internationally in low-resource settings. Upon completion of this proposal, we will apply for a Phase II award proposing to work with Wilmer Eye Institute research faculty to assess widespread deployment of the next-generation QuickSee with minimally-trained personnel in order to accurately and reliably provide thousands of pairs of low-cost corrective eyeglasses to underserved communities. Project Narrative This project proposal seeks to develop a novel technology that will disruptively increase the accessibility of refractive eye care for health disparity populations in low-resource settings. Specifically, sophisticated algorithms will be developed that improve the accuracy of the QuickSee device so that it can improve the efficiency of and reduce the training barriers for eye care professionals, and potentially provide refractive correction without the need for refinement by a trained eye care professional. Our goal is to develop a low- cost, easy-to-use, scalable solution to increase accessibility to vision correction globally.","Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor",9312420,R43EB024299,"['Algorithms', 'Award', 'Baltimore', 'Brazil', 'Businesses', 'Caliber', 'Calibration', 'Caring', 'Communities', 'Country', 'Data', 'Data Set', 'Developed Countries', 'Developing Countries', 'Development', 'Devices', 'Diagnostic', 'Education', 'Educational Status', 'Enrollment', 'Eye', 'Eyeglasses', 'Feedback', 'Geometry', 'Goals', 'Gold', 'Guatemala', 'Hospitals', 'Human Resources', 'Impairment', 'Improve Access', 'Income', 'India', 'Institutes', 'International', 'Machine Learning', 'Mali', 'Measurement', 'Measures', 'Modeling', 'Noise', 'Ophthalmic examination and evaluation', 'Optometrist', 'Output', 'Patient Schedules', 'Patients', 'Phase', 'Population', 'Prevalence', 'Procedures', 'Productivity', 'Pupil', 'Quality of life', 'Refractive Errors', 'Research Institute', 'Resources', 'Spottings', 'Testing', 'Time', 'Training', 'Underserved Population', 'Universities', 'Validation', 'Vision', 'Visual Acuity', 'Work', 'base', 'cost', 'faculty research', 'health care disparity', 'health disparity', 'improved', 'lens', 'new technology', 'next generation', 'novel strategies', 'success', 'vector']",NIBIB,"PLENOPTIKA, INC.",R43,2017,200225,-0.013872600864896074
"Crowd-Sourced Annotation of Longitudinal Sensor Data to Enhance Data-Driven Precision Medicine for Behavioral Health ﻿    DESCRIPTION (provided by applicant): Longitudinal sensor data collected passively from mobile phones and other wearable sensors will transform behavioral science by allowing researchers to use ""big data,"" but at the person-level, to understand how behavior and related environmental exposures impact health outcomes. Computers will analyze individual-level data streams to permit unprecedented, individual-level precision in research and intervention. This type of precision medicine enables targeting of science and medicine to a particular individual's genetic makeup, past and current situation, and behavioral health exposures. Mobile phones, smartwatches, and common fitness devices are already capable of generating rich data on behavior, but developing algorithms to interpret that raw data using the latest machine learning algorithms requires practical strategies to annotate large datasets. We propose to develop and test the feasibility and usability of a mobile and online crowdsource-based system for cleaning and annotating behavioral data collected from motion sensors, mobile phones, and other mobile devices. Our goal is to demonstrate how individuals playing mobile and online games - the ""crowd"" - can collectively, affordably, and incrementally clean and add important metadata to raw sensor data that has been passively collected from individuals, similar to that from population-scale surveillance studies (e.g., the National Health and Nutrition Examination Survey (NHANES) and UK Biobank) and those planned for studies such as the White House's Precision Medicine Initiative. The game-playing crowd will thereby dramatically improve the utility of the datasets collected for a variety of scientific studies. We will validate our prototye system on datasets collected from motion monitors used to study physical activity, sedentary behavior, and sleep, but we will demonstrate how the system could be extended for use on the increasingly rich datasets that are being collected with mobile devices and that include not only motion data, but also sensor data on location, light, audio, and person-to-person proximity. We will then refine the system, foster a community of crowd game players interested in citizen science, and release the source code to the system as an open source project so that other researchers can adapt the technique for their own work. PUBLIC HEALTH RELEVANCE: Longitudinal sensor data collected passively from wearable activity monitors and mobile phones will transform behavioral science by allowing researchers to use ""big data,"" but at the person-level, to understand how behavior and related environmental exposures impact health outcomes and personalize health intervention and research. We propose to develop and test a system that permits typical mobile application game players to help scientists improve this type of data, by adding additional annotations that enrich the data, making it more useful for behavioral science and more amenable to automatic processing. This will help researchers to better understand how individual-level behaviors relate to health outcomes in current research studies that collect personal-level sensor data such as NHANES and the Women's Health Study, and future big data ventures such as the new Precision Medicine Initiative.",Crowd-Sourced Annotation of Longitudinal Sensor Data to Enhance Data-Driven Precision Medicine for Behavioral Health,9357585,UH2EB024407,"['Accelerometer', 'Algorithms', 'American', 'Behavior', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Car Phone', 'Classification', 'Cohort Studies', 'Communities', 'Complex', 'Computers', 'Crowding', 'Data', 'Data Collection', 'Data Quality', 'Data Science', 'Data Set', 'Devices', 'Environmental Exposure', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Intervention', 'Interview', 'Label', 'Lead', 'Light', 'Location', 'Machine Learning', 'Manuals', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Monitor', 'Motion', 'National Health and Nutrition Examination Survey', 'Outcome', 'Output', 'Participant', 'Pathway Analysis', 'Pattern', 'Performance', 'Persons', 'Phonation', 'Physical activity', 'Play', 'Population', 'Precision Medicine Initiative', 'Process', 'Proteomics', 'Research', 'Research Personnel', 'Risk Behaviors', 'Sampling', 'Science', 'Scientist', 'Sleep', 'Source Code', 'Stream', 'System', 'Techniques', 'Telephone', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Visualization software', 'Women&apos', 's Health', 'Work', 'annotation  system', 'base', 'behavioral health', 'biobank', 'citizen science', 'crowdsourcing', 'design', 'experimental study', 'fitness', 'genetic makeup', 'handheld mobile device', 'improved', 'innovation', 'insight', 'instrument', 'interest', 'metabolomics', 'mobile application', 'mobile computing', 'novel', 'open source', 'precision medicine', 'prototype', 'public health relevance', 'research study', 'sedentary lifestyle', 'sensor', 'surveillance study', 'temporal measurement', 'tool', 'ubiquitous computing', 'usability']",NIBIB,NORTHEASTERN UNIVERSITY,UH2,2017,300665,-0.010325990792631095
"Enabling forelimb function with agonist drug and epidural stimulation in SCI DESCRIPTION (provided by applicant):  We have demonstrated that the physiological state of the lumbosacral spinal circuitry of spinal rats and cats can be modulated with spinal cord epidural stimulation (EDS) and/or administration of pharmacological agents to generate weight-bearing standing and stepping over a range of speeds, loads, and directions.  We have translated some of these results to humans by implanting 3 motor complete spinal cord injured (SCI) subjects about three years post-injury with an epidural electrode array over the lumbosacral spinal cord.  In less than one month post-electrode implant, the subjects could stand independently, and after up to 7 months of daily EDS and motor training, voluntary control of both legs was evident in the presence of EDS, whereas complete paralysis remained in absence of EDS.  We propose to employ a similar stimulation strategy for the recovery of upper limb function.  We will include extensive testing of spinal rats to guide our strategy to test for upper extremity improvement in human SCI subjects.  We will use off-the-shelf FDA approved pharmacological and stimulation modalities to:  1) Determine the optimal stimulation parameters, i.e., electrode placement and stimulation intensity, frequency and duration, for facilitating forelimb fine motor function in rats with a cervical SCI.  Using existing FDA-approved epidural electrodes, we will demonstrate in patients with a cervical SCI that cervical EDS can facilitate arm-hand function.  2) Identify an effective mode of administration, define the dose- response pharmacokinetics, and determine the effectiveness of a monoaminergic agonist to facilitate upper limb function after a cervical SCI.  We will assess the effectiveness of existing FDA-approved pharmacological agents (i.e., buspirone and as an alternative, bromocriptine), and determine their effectiveness in improving forelimb control in subjects with a cervical SCI.  3) Define the dose-response properties of monoaminergic agonists when combined with EDS in facilitating forelimb function in rats after a cervical SCI.  We will demonstrate the efficacy of ES in combination with a pharmacological intervention in facilitating arm and hand function in humans after a cervical SCI.  4) Determine whether motor training of spinal rats will further enhance the recovery of motor function when combined with pharmacological and/or EDS interventions.  5) Develop a protocol for machine learning to enable rapid selection of the optimal pharmacological and EDS parameters for motor recovery in rats and in human subjects.  If successful, this could represent the beginning of a paradigm shift in the use of minimally invasive strategies combined with rehabilitative approaches to realize significant improvement in upper limb function after paralysis. PUBLIC HEALTH RELEVANCE:  It now seems possible to apply three interventions (epidural stimulation, administration of pharmacological agents, and motor training) to control the excitability of localized neural circuits in humans with a cervical spinal cord injury (SCI), thus enabling these individuals to regain use of their arms and hands.  This enabling effect is similar to that observed with improved postural and locomotor function after a mid-thoracic SCI.  We will reach critical milestones that will provide the basis for a series of clinical trials for furter defining the efficacy of these interventions.",Enabling forelimb function with agonist drug and epidural stimulation in SCI,9358722,U01EB015521,"['Agonist', 'Algorithms', 'Ankle', 'Bromocriptine', 'Buspirone', 'Cervical', 'Cervical spinal cord injury', 'Cervical spinal cord structure', 'Chronic', 'Clinical Trials', 'Complement', 'Devices', 'Dose', 'Drug Kinetics', 'Effectiveness', 'Electrodes', 'FDA approved', 'Felis catus', 'Food', 'Forelimb', 'Frequencies', 'Goals', 'Hand', 'Hand functions', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Knee', 'Leg', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Methodology', 'Modality', 'Motor', 'Motor Skills', 'Oral', 'Paralysed', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Physiological', 'Posture', 'Preparation', 'Property', 'Protocols documentation', 'Rattus', 'Recovery', 'Rehabilitation therapy', 'Retrieval', 'Series', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Testing', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Translating', 'Treatment Efficacy', 'Upper Extremity', 'Weight-Bearing state', 'arm', 'arm function', 'design', 'human subject', 'improved', 'injured', 'learning strategy', 'minimally invasive', 'motor function recovery', 'motor recovery', 'neural circuit', 'neuroregulation', 'public health relevance', 'response']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2017,865006,0.020734129653831194
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability. PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.",Capti Screen Reading Assistant for Goal Directed Web Browsing,9199231,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2017,500000,-0.004244744306643634
"Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI DESCRIPTION (provided by applicant):  In the first 5-year period of our BRP we had two major objectives:  1) to determine whether we could improve motor function of the lower limbs by neuromodulating the spinal lumbosacral circuitry with epidural stimulation and 2) to begin to develop and improve the technologies associated with electrode arrays and chronic implantable stimulation devices to maximize the neuromodulatory potential.  These new technologies have the potential to fine tune the epidural stimulation parameters, to help in understanding some of the underlying mechanisms of epidural stimulation., to examine synergistic effects of epidural stimulation, pharmacological modulation, and examine activity-dependent interventions that might affect the level of recovery of motor function after complete paralysis.  We have demonstrated that an adult rat with a complete, mid-thoracic spinal cord transection can regain full weight-bearing stepping over a range of speeds, loads, and even directions when the spinal cord is stimulated tonically to increase the excitability of the lumbosacral locomotor circuitry.  Furthermore, we learned that load-bearing sensory information can serve as the controller of these complex motor tasks and that the performance of these tasks can be improved even further with combinations of epidural stimulation, pharmacological, and motor training interventions.  We have shown that four humans with a motor complete spinal injury have regained independent standing, assisted stepping, and even a significant level of voluntary control of the lower limbs in the presence of epidural stimulation, with one subject now even having some volitional control without stimulation.  Improvement in bladder control, blood pressure, temperature regulation, and even sexual function has been realized.  Thus, our present challenge is to develop the capability to selectively activate combinations of neural networks that can enable standing, and probably stepping, by improving the technologies needed to make this intervention available in the clinic and in the home of individuals with complete motor paralysis using a chronic epidural electrode implant.  Specifically, we will further improve the electrode array stimulation technology needed for fine-tune control in rats and humans and transform the present hardwired technology for rats to a wireless capability to stimulate and record evoked potentials along the brain-spinal cord-muscle axis in the rat.  To advance the clinical potential, we will continue to develop, refine and validate our machine-learning strategies which automatically optimize stimulation parameters for standing, stepping, and voluntary control.  We will develop an improved interface between the devices implanted in our present subjects and the control devices for defining the specific stimulation parameters needed for a given subject to perform a motor task in the clinic or at home. PUBLIC HEALTH RELEVANCE:  We now have demonstrated that the human lumbosacral spinal cord can be neuromodulated with epidural stimulation to enable recovery of standing and volitional control of the lower limbs and return of some autonomic function after complete motor paralysis.  Therefore, our objectives are now to develop the technologies needed to more fully capitalize on this clinical potential and develop home-use technologies to do so.",Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI,9360609,U01EB007615,"['Adult', 'Affect', 'Algorithms', 'Animals', 'Behavior', 'Bilateral', 'Biological Neural Networks', 'Bladder Control', 'Blood Pressure', 'Brain', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Complex', 'Data', 'Devices', 'Dorsal', 'Educational Intervention', 'Electrodes', 'Evaluation', 'Evoked Potentials', 'Experimental Designs', 'Frequencies', 'Gaussian model', 'Home environment', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Internet', 'Intervention', 'Intramuscular', 'Learning', 'Locomotor training', 'Lower Extremity', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Muscle', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Pharmacology', 'Physiological', 'Posture', 'Procedures', 'Process', 'Rattus', 'Recovery', 'Regulation', 'Research', 'Robotics', 'Sensory', 'Sex Functioning', 'Signal Transduction', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord Contusions', 'Spinal Cord transection injury', 'Spinal Injuries', 'Spinal cord injury', 'Stimulus', 'System', 'Task Performances', 'Technology', 'Temperature', 'Testing', 'Thoracic spinal cord structure', 'Training', 'Volition', 'Weight-Bearing state', 'Wireless Technology', 'base', 'density', 'design', 'implantable device', 'improved', 'in vivo', 'learning strategy', 'motor control', 'motor function improvement', 'motor function recovery', 'neuroregulation', 'new technology', 'next generation', 'novel', 'public health relevance', 'somatosensory', 'treadmill', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2017,457885,0.04173526953974432
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research ﻿    DESCRIPTION (provided by applicant): This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0(tm) that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud(tm) Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb's DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently. PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9354497,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Communications Media', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Internet of Things', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Modernization', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'Transact', 'United States National Institutes of Health', 'analytical tool', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'experimental study', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'service learning', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2017,739402,-0.0003880359215348624
"Advancing a novel portable detection method for cannabis intoxication Intoxication from marijuana (MJ) impairs psychomotor performance and at least doubles the risk of motor vehicle accidents. The ongoing wave of legalization of MJ has brought increasing prevalence of driving while intoxicated with MJ. However, there is no quantitative biologic test that can accurately determine whether an individual is acutely impaired from MJ intoxication. Assays of the primary intoxicating substance in MJ, THC, in body fluids has a high false negative rate as THC is cleared from blood within 15 minutes, long before impairment is resolved. And assays of THC metabolites yield a high false positive rate because clearance of these metabolites can take weeks. Thus there is now no nor is there likely to ever be a test of blood, breath or body fluids that can accurately detect MJ intoxication. In response to this significant knowledge gap, this project aims to develop an accurate, portable method for detection of impairment due to MJ intoxication using functional near-infrared spectroscopy (fNIRS). fNIRS is a non-invasive, safe brain imaging technique that capitalizes on differences in the light absorption spectra of deoxygenated and oxygenated hemoglobin (Hb), that allows the measurement of relative changes in Hb concentration that reflect brain activity. fNIRS can be performed in natural environments at low cost, and thus can be used in real-world settings. In Phase I, we will develop an algorithm for individual-level detection of impairment from THC using fNIRS measurements. To do so, we will assess the effect of oral THC (or placebo) on fNIRS measurements, self-reported intoxication, and impairment as defined by the gold standard field sobriety test conducted by a Drug Recognition Expert (DRE) in 40 healthy MJ users. fNIRS assessments will examine (1) the effect of THC exposure on resting state and task-based activation in the prefrontal cortex, (2) the extent to which impairment in psychomotor functioning with THC administration correlates with THC-induced change in hemodynamic responses detected with fNIRS, and (3) the sensitivity and specificity and area under the ROC curve of fNIRS measurements and field sobriety test determinants of impairment. Milestone: Should machine learning applications to the data generate an algorithm that predicts impairment with >80% accuracy compared with a gold standard field sobriety test, we will proceed to Phase II. In Phase II, we will conduct fNIRS testing in 150 individuals under THC/placebo as in Phase I and in 50 individuals in a THC plus alcohol/placebo condition in order to further refine the algorithm for MJ impairment detection such that fNIRS detection concurs with field sobriety testing with >90% specificity. It is anticipated that this level of specificity could be used in legal definitions of impairment. This will warrant commercialization, which will be followed by prototype development and field testing. An accurate, quantitative, biological test that is user-friendly and enables law enforcement to detect impairment from MJ has the potential to dramatically change practice of law enforcement across the country and the world and thus has enormous commercial potential, as outlined in the Commercialization Plan and in accompanying letters of support. The goal of this project is to develop, test, and refine a method to accurately and reliably detect marijuana (MJ) impairment using a portable, user-friendly, non-invasive, brain-based modality. MJ doubles the chance of motor vehicle accidents, yet, there now exists no valid, biologically based method to detect whether an individual is acutely impaired from MJ. The development of a reliable, quantitative biological marker that enables law enforcement officers to screen individuals whom they suspect are impaired from MJ will have highly significant public health importance and enormous commercial potential.",Advancing a novel portable detection method for cannabis intoxication,9334516,R42DA043977,"['Acute', 'Adult', 'Age', 'Alcohols', 'Algorithms', 'Area', 'Base of the Brain', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Blood', 'Blood Circulation', 'Blood Tests', 'Body Fluids', 'Brain', 'Brain imaging', 'Breath Tests', 'Cannabis', 'Collaborations', 'Comorbidity', 'Country', 'Cross-Over Trials', 'Data', 'Detection', 'Development', 'Devices', 'Dose', 'Double-Blind Method', 'Driving While Intoxicated', 'Drug Kinetics', 'Ensure', 'Environment', 'Equipment', 'Evaluation', 'Formulation', 'Future', 'Goals', 'Gold', 'Hemoglobin', 'Hour', 'Human Resources', 'Imaging Techniques', 'Impairment', 'Individual', 'Intoxication', 'Knowledge', 'Law Enforcement', 'Law Enforcement Officers', 'Legal', 'Letters', 'Licensing', 'Light', 'Machine Learning', 'Marijuana', 'Measurement', 'Methods', 'Modality', 'Near-Infrared Spectroscopy', 'Oral', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Placebo Control', 'Placebos', 'Population', 'Prefrontal Cortex', 'Prevalence', 'Property', 'Psychomotor Impairments', 'Psychomotor Performance', 'Public Health', 'ROC Curve', 'Randomized', 'Readiness', 'Rest', 'Risk', 'Sensitivity and Specificity', 'Source', 'Specificity', 'System', 'THC exposure', 'Testing', 'Tetrahydrocannabinol', 'United States', 'Urine', 'Vendor', 'absorption', 'alcohol exposure', 'base', 'behavior test', 'commercialization', 'cost', 'density', 'detector', 'driving under influence', 'drug testing', 'field sobriety tests', 'field study', 'functional disability', 'hemodynamics', 'interest', 'marijuana legalization', 'marijuana use', 'marijuana user', 'novel', 'novel strategies', 'portability', 'prediction algorithm', 'prototype', 'response', 'spectroscopic imaging', 'tool', 'user-friendly', 'vehicular accident']",NIDA,"HIGHLIGHTI, INC",R42,2017,224973,0.0027478793525067178
"A Hybrid Neural-Machine Interface for Volitional Control of a Powered Lower Limb Prosthesis Project Summary  The goal of the proposed work is to develop a robust hybrid neural-machine interface (NMI), combining brain and muscle signals, to improve overall control of a lower limb prosthetic device during activities of daily living. Limb amputation affects over 600,000 individuals annually in the US, and is a major cause of physical disability that causes activities of daily living to become difficult or impossible for the amputee. The limitations of current lower-limb prostheses are associated with limited volitional control, reduced mobility, and chronic gait abnormalities, which have been linked to exhaustion from increased energy expenditure, increased risk of falling, and degenerative bone and joint disorders in both the intact and amputated limb. In this study, EMG signals from both residual and intact lower limbs and EEG signals from the cortex are leveraged to decode transitions to and from various modes of locomotion modes in able-bodied individuals and transfemoral amputees, and to provide a global understanding of movement at the cortical, muscular, and kinematic level in amputees. Specifically, time and frequency domain features are leveraged to create a prediction algorithm capable of identifying upcoming terrain transitions in advance. In lower limb amputees, this hybrid NMI paradigm translates to volitional control of a powered lower-limb prosthesis, which allows for seamless transitions between various movement conditions. The high-level of control is expected to result in significant increases in level of activity and overall improvements in gait. Previous studies have demonstrated the feasibility of EEG or EMG based NMIs for orthotic and prosthetic devices; however, no study to date has integrated EEG and EMG in a NMI for powered lower limb prostheses. This study is motivated by the need to explore advanced neural control sources for intuitive control of artificial limbs.  This project aligns directly with the Mission & Goals of the NIH, the Brain Initiative, and NIH’s Blueprint Program by expanding fundamental knowledge of neuroscience, human, health and wellness; by utilizing an innovative research strategy; and ultimately returning the knowledge to the public through the development of a highly advanced medical technology. Furthermore, the technology developed through this work has implications beyond the amputee population in the treatment of many neurological conditions and injuries, such as in neurorehabilitation after stroke. The innovation of this project lies in the novel approach of using multimodal neural signals and movement synergies as a framework for interpreting movement of the lower limb. The scientific impact is realized by a greater understanding of the neural correlates of movement after lower-limb amputation. The direct clinical significance for the patient can be measured directly through improved gait performance and walking confidence, leading to increased mobility and a reduced risk of falling, exhaustion, and bone and joint disorders. Project Narrative  The development of a hybrid neural-machine interface that incorporates muscle and brain signaling for communication with robotic systems is important to public health because it allows for robust volitional control of powered prostheses and exoskeletons during activities of daily living. This will directly benefit the amputee population by allowing better control of their prosthesis during locomotion, especially when navigating complex terrains, such as stairs and inclines. The implications of this technology can be used beyond the amputee population to further understand the effect of neurological injuries on the brain, and for improving rehabilitation paradigms associated with their treatment.",A Hybrid Neural-Machine Interface for Volitional Control of a Powered Lower Limb Prosthesis,9470585,F99NS105210,"['Activities of Daily Living', 'Affect', 'Amputees', 'Ankle', 'Artificial Intelligence', 'Award', 'BRAIN initiative', 'Body Image', 'Bone Diseases', 'Brain', 'Brain imaging', 'Chronic', 'Communication', 'Complex', 'Detection', 'Development', 'Electroencephalography', 'Electromyography', 'Electronic Mail', 'Energy Metabolism', 'Engineering', 'Frequencies', 'Funding Agency', 'Future Teacher', 'Gait', 'Gait abnormality', 'Goals', 'Grant', 'Health', 'Human', 'Hybrids', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Individual', 'Injury', 'International', 'Intuition', 'Joints', 'Knee', 'Knowledge', 'Leadership', 'Limb Prosthesis', 'Link', 'Locomotion', 'Lower Extremity', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Mentors', 'Mentorship', 'Metabolic', 'Methods', 'Mission', 'Motion', 'Movement', 'Muscle', 'Nervous System Trauma', 'Neurologic', 'Neurologic Effect', 'Neurorehabilitation', 'Neurosciences', 'Oral', 'Orthotic Devices', 'Patients', 'Pattern', 'Performance', 'Physically Handicapped', 'Population', 'Positioning Attribute', 'Prosthesis', 'Public Health', 'Ramp', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Residual state', 'Robotics', 'Scalp structure', 'Signal Transduction', 'Social Network', 'Source', 'Stroke', 'Surface', 'System', 'Teacher Professional Development', 'Technical Expertise', 'Technology', 'Telephone', 'Time', 'Training Programs', 'Translating', 'United States', 'United States National Institutes of Health', 'Upper Extremity', 'Visual Cortex', 'Volition', 'Walking', 'Work', 'arthropathies', 'base', 'clinically significant', 'exhaustion', 'exoskeleton', 'experience', 'fall risk', 'improved', 'injured', 'innovation', 'instrument', 'kinematics', 'limb amputation', 'limb movement', 'multimodality', 'neural correlate', 'neuroregulation', 'neurotransmission', 'novel strategies', 'posters', 'powered prosthesis', 'prediction algorithm', 'programs', 'rehabilitation paradigm', 'relating to nervous system', 'robot control', 'robot exoskeleton', 'robot rehabilitation', 'sensor', 'signal processing', 'skills', 'stroke rehabilitation', 'symposium', 'synergism', 'undergraduate student', 'visual motor']",NINDS,UNIVERSITY OF HOUSTON,F99,2017,36029,0.011076039629232657
"Understanding the Neural Basis of Volitional State through Continuous Recordings in Humans ABSTRACT In the course of a day we naturally make multiple shifts in our overall cognitive state and in our aims and intents. We go from sleep to awake, from internal dialogue to external communication, from relative immobility to planned complex movements. The neural activity which distinguishes these different high-level states is unknown and yet is a fundamental aspect to understanding overall cognitive processes. It is also a baseline substrate that is adversely impacted by a wide range of neuropsychiatric diseases. Our understanding of human cortical neurophysiology is almost entirely based on cognitive processes examined within the constraints of experimentally controlled tasks with time-locked, stimulus-driven behaviors. However, brain activity is fluid and continuous; much of our essential cognitive activity is not externally triggered but internally generated. The overarching goal of this research is to create platforms which allow for continuous acquisition of high-fidelity neural ensemble activity synchronized with behavioral data and contextual information to allow investigations into volitional changes in focus and intent. Data will be acquired from two groups of patients: those undergoing intracranial exploration for treatment of their epilepsy and patients implanted with multi- electrode arrays as part of the BrainGate clinical trial to restore communication and mobility to people with paralysis. Using this novel paradigm for investigation, we will explore the neural basis for changes in state which are dominated by receptive activities, internal thought and external interaction. We initially focus on motor behavior with a traditional task construction constraining the participant to watch, imagine and then attempt or actually move. We expand this to spontaneous activity in Aim 2. Finally, we move toward more general and abstracted investigations of volitional state by looking at an analogous task and spontaneous behavior with respect to language and communication (Aim 3). At each stage we will employ spectral, functional connectivity and data mining techniques to understand the neural underpinnings of these different states as well as the temporal dynamics that portend changes in state. Supporting all of these aims will be improvements and expansions in state-of-the-art human micro- and mesoscale neural recording environments to enable the study of continuous, real-time neural activity underlying state changes. Across aims we will explore the extent to which motor cortex alone contains the information which may be present in more widespread and higher order cortical regions. Our hypothesis is that motor cortex, does in fact, encode significant information about state in ways which encapsulate or summarize the information available in more wide spread regions. Most importantly, the questions inherent in this research are key to understanding human thought patterns at a fundamental level. This understanding has important implications not just for basic cognitive neuroscience but for our understanding of the processes which are altered in a wide range of neuropsychiatric disorders such as epilepsy, the dementias, depression, and psychosis. The results of these studies are also essential for the practical instantiation of effective brain-machine interfaces which would allow patients to act autonomously. Narrative: From simple decisions to more significant and complex thoughts, we constantly shift our aims and intentions and the degree to which we are interacting externally or internally. Understanding these shifts is key to the development of truly autonomous brain-computer interfaces and neuroprosthetics as well as to understanding how these kinds of alterations can be compromised in a wide variety of neuropsychiatric diseases. In this project we go beyond routine cognitive studies based on constrained stimulus response designs and instead utilize continuous recordings of neural activity during spontaneous behavior to decode changes in volitional state during motor activity and communication.",Understanding the Neural Basis of Volitional State through Continuous Recordings in Humans,9356342,U01NS098968,"['Area', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Classification', 'Clinical Trials', 'Cognitive', 'Communication', 'Complex', 'Data', 'Dementia', 'Development', 'Dimensions', 'Encapsulated', 'Environment', 'Epilepsy', 'Evaluation', 'Evoked Potentials', 'Goals', 'Hearing', 'Human', 'Implant', 'Intention', 'Investigation', 'Language', 'Liquid substance', 'Machine Learning', 'Measures', 'Mediator of activation protein', 'Mental Depression', 'Microelectrodes', 'Motor', 'Motor Activity', 'Motor Cortex', 'Movement', 'Nature', 'Neurocognitive', 'Neurons', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Paralysed', 'Parietal', 'Participant', 'Pathologic', 'Patients', 'Pattern', 'Process', 'Psychotic Disorders', 'Research', 'Response to stimulus physiology', 'Sleep', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thinking', 'Time', 'Volition', 'Work', 'Writing', 'analytical tool', 'awake', 'base', 'brain computer interface', 'brain machine interface', 'cognitive neuroscience', 'cognitive process', 'data mining', 'design', 'expectation', 'experimental study', 'insight', 'multi-electrode arrays', 'neural circuit', 'neuromechanism', 'neurophysiology', 'neuroprosthesis', 'neuropsychiatric disorder', 'novel', 'relating to nervous system', 'sensor']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,U01,2017,1528951,-0.008443190541631392
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9233069,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,652111,-0.05213281438464142
"Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions Project Summary/Abstract People with mobility restrictions and limited to no upper extremity use depend on others to position the objects that they rely upon for health, communication, productivity, and general well-being. The technology developed in this project directly increases users’ independence by responding to them without another person’s intervention. The independence resulting from the proposed technology allows a user to perform activities related to self-care and communication. Eye tracking and head tracking access to speech devices, tablets, or computers requires very specific positioning. If the user’s position relative to the device are not aligned precisely, within a narrow operating window, the device will no longer detect the eyes or head, rendering the device inoperable. Auto-positioning technology uses computer vision and robotic positioning to automatically move devices to a usable position. The system moves without assistance from others, ensuring the user has continual access to communication. In a generalized application, the technology can target any area of the user’s body to position relevant equipment, such as for hydration or a head array for power wheelchair control. Research and development of the automatic positioning product will be accomplished through user-centered, iterative design, and design for manufacturing. Input from people with disabilities, their family members, therapists, and assistive technology professionals define the functional requirements of the technology and guide its evolution. Throughout technical development, prototype iterations are demonstrated and user-tested, providing feedback to advance the design. Design for manufacturability influences the outcomes to optimize the product pipeline, ensure high quality and deliver a cost effective product. Phase 1 Aims demonstrate the feasibility of 1) movement and control algorithms 2) face tracking algorithms and logic to maintain device positioning and 3) integration with commercial eye tracking device software development kits (SDK). Phase 2 Aims include technical, usability, and manufacturability objectives leading to development of a product for commercialization. Software development advances computer vision capabilities to recognize facial expressions and gestures. A new sensor module serves as a gesture switch or face tracker. App development provides the user interface, remote monitoring and technical support. Design of scaled down actuators and an enclosed three degree of freedom alignment module reduces the form factor, allowing for smaller footprint applications. Rigorous user testing by people with different diagnoses and end uses will ensure the product addresses a range of needs and is easy to use. Testing involves professionals and family members to evaluate ease of set-up, functionality, and customization. Extended user testing will investigate and measure outcomes and effects on their independence, access and health. Prototype tooling and design for cost-effective manufacturing will produce units for user and regulatory testing, and eventual sale. Project Narrative People who are essentially quadriplegic, with significant mobility impairments and limited to no upper extremity use, are dependent on others to maintain proper positioning for access to devices essential for their health, mobility and communication, such as eye gaze speech devices, call systems, phones, tablets, wheelchair controls, and hydration and suctioning tubes. Auto-positioning technology uses computer vision to detect specific targets, such as facial features, to control a robotic mounting and positioning system; automatically repositioning devices for best access without assistance from others, even when their position changes. This technology enables continuous access to communication, maintains one’s ability to drive a wheelchair and allows a person to drink or suction themselves, providing good hydration, respiratory health and hygiene.",Automatic Positioning of Communication Devices and other Essential Equipment for People with Mobility Restrictions,9407137,R44HD093467,"['Address', 'Advanced Development', 'Algorithms', 'Area', 'Articular Range of Motion', 'Beds', 'Caring', 'Cerebral Palsy', 'Communication', 'Computer Vision Systems', 'Computers', 'Custom', 'Data', 'Dependence', 'Development', 'Devices', 'Diagnosis', 'Disabled Persons', 'Duchenne muscular dystrophy', 'Ensure', 'Equipment', 'Evolution', 'Eye', 'Face', 'Facial Expression', 'Family', 'Family member', 'Feedback', 'Freedom', 'Gestures', 'Goals', 'Head', 'Head and neck structure', 'Health', 'Health Communication', 'Hydration status', 'Hygiene', 'Immunity', 'Impairment', 'Individual', 'Intervention', 'Intuition', 'Joints', 'Lighting', 'Logic', 'Methods', 'Monitor', 'Motor', 'Movement', 'Oral cavity', 'Outcome', 'Outcome Measure', 'Persons', 'Phase', 'Phonation', 'Positioning Attribute', 'Powered wheelchair', 'Productivity', 'Publishing', 'Quadriplegia', 'Quality of life', 'Research Design', 'Robotics', 'Safety', 'Sales', 'Saliva', 'Self Care', 'Self-Help Devices', 'Services', 'Signal Transduction', 'Spastic Tetraplegia', 'Speech', 'Spinal Muscular Atrophy', 'Spinal cord injury', 'Suction', 'System', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Tube', 'Update', 'Upper Extremity', 'Variant', 'Wheelchairs', 'Work', 'application programming interface', 'base', 'body system', 'commercialization', 'communication device', 'cost', 'cost effective', 'cost effectiveness', 'design', 'experience', 'gaze', 'improved', 'iterative design', 'meetings', 'product development', 'prototype', 'psychosocial', 'research and development', 'respiratory health', 'sensor', 'software development', 'tool', 'usability', 'user centered design']",NICHD,"BLUE SKY DESIGNS, INC.",R44,2017,159267,0.024595227226277484
"Neural dynamics and adaption for brain machine interface control Project Summary/Abstract  Millions of people suffer from some form of paralysis. In most of these cases the connection between the brain and the spinal cord is damaged, however, the motor cortex is healthy and intact. Thus, for these individuals, brain-machine interfaces (BMIs) hold significant promise for improving quality of life. BMIs decode an individual's intention to move by utilizing statistical models of neural activity patterns recorded from the motor cortex using implanted electrode arrays. While these methods have been encouraging in preclinical experiments and clinical trials for controlling thought-driven 2D computer cursors, they suffer from poor performance when applied to higher degrees-of-freedom (e.g., robotic limbs), and are not robust to the inevitable degradation of the electrode array. In order to address these clinical needs, this project starts from the recent observation that just as some behaviors are easier to learn, some patterns of neural activity, termed neural states, are also easier to generate. The overarching goal of this project is to elucidate if these “easy to generate” neural states can be used to robustly control a prosthetic arm. This is a significant departure from current decoding methods, which incorporate little to no information about the motor system, especially its ability to learn and adapt. The first major aim of this work is to develop experiments and analysis methods in order to find these “easy to generate” neural states in the non- human primate (i.e., rhesus monkey) motor system. Here “easy to generate” can be understood as the monkey's ability to volitionally generate that particular neural state. The second major aim of this work is to characterize the properties of the motor system that enable some states to be more easily generated than others. Prior work in our lab has shown that motor cortical population activity has well-defined structure, as predicted by dynamical system theory. These dynamics cause neural states to evolve in lawful ways through time. The work here will extend these findings by characterizing the dynamics associated with a monkey learning to generate a neural state. Finally, the third major aim of this work is to determine if neural states that monkeys can volitionally generate can be utilized for robust control of a prosthetic arm. The central hypothesis of this work is that building a model that only utilizes firing patterns that can be easily generated (as determined experimentally) will enable robust and high-performance control of a prosthetic arm. If successful, this study could have significant clinical impact by presenting a new paradigm to enable robust control of a prosthesis. Project Narrative  Millions of people worldwide suffer from neurological injuries or neurodegenerative diseases that result in considerable movement impairment. Brain machine interfaces (BMIs) hold considerable promise in drastically improving the quality of life for these individuals, who otherwise have very limited treatment options. This work will investigate the motor system's ability to learn and adapt, and directly use these insights to build robust high degree-of-freedom BMIs for clinical applications.",Neural dynamics and adaption for brain machine interface control,9395809,F31NS103409,"['Address', 'Area', 'Artificial Arm', 'Automobile Driving', 'Behavior', 'Brain', 'Clinical', 'Clinical Trials', 'Complex', 'Computers', 'Coupled', 'Data', 'Devices', 'Dimensions', 'Electrodes', 'Freedom', 'Generations', 'Goals', 'Implanted Electrodes', 'Individual', 'Intention', 'Joint Prosthesis', 'Joints', 'Learning', 'Limb Prosthesis', 'Limb structure', 'Link', 'Literature', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Neurodegenerative Disorders', 'Neurons', 'Paralysed', 'Pattern', 'Performance', 'Population', 'Property', 'Prosthesis', 'Quality of life', 'Rehabilitation therapy', 'Robotics', 'Spinal Cord', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Systems Theory', 'Techniques', 'Technology', 'Time', 'Training', 'Visual', 'Volition', 'Work', 'arm', 'arm movement', 'brain machine interface', 'clinical application', 'dynamic system', 'experimental study', 'falls', 'high dimensionality', 'improved', 'insight', 'motor impairment', 'neural model', 'neural patterning', 'neurophysiology', 'neuroregulation', 'nonhuman primate', 'pre-clinical', 'prosthesis control', 'rehearsal', 'relating to nervous system']",NINDS,STANFORD UNIVERSITY,F31,2017,33584,0.022716180006616647
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9300962,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'International', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'X-Ray Computed Tomography', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging study', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'perfusion imaging', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'success', 'tool', 'validation studies', 'virtual', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2017,169609,-0.03170440075110493
"An evaluation of sensor technology to monitor and report compliance with an evidence-based intervention to prevent ventilator-associated pneumonia ﻿    DESCRIPTION (provided by applicant):  The candidate, Nishi Rawat, is a Critical Care physician and Assistant Professor in the Department of Anesthesiology and Critical Care Medicine at Johns Hopkins. Her goal is to become an independent investigator focused on advancing the field of quality improvement to improve the quality of health care delivered to Americans, while simultaneously reducing costs, with an emphasis on the application of information technology to evaluate performance, minimize waste and eliminate redundancies.  The candidate's preliminary work as a co-investigator for two collaboratives to reduce ventilator-associated pneumonia (VAP) suggests that there is a strong drive to eliminate preventable harms such as VAP, but weak available methodologies and resources to do so. There is a dire need for an effective and inexpensive methodology to track the delivery of evidence-based interventions for the purpose of quality improvement. The proposed research intends to fill this measurement gap. In this proposal, she evaluates the utility of the sensor approach for measuring and improving quality of care, focusing on VAP prevention intervention performance.  The aims propose: evaluate the utility of the sensor approach for measuring compliance with a VAP prevention intervention by comparing VAP process measure performance estimates captured by sensor technology to estimates obtained by traditional manual data collection (Aim 1); design and pilot a strategy to provide real-time feedback of sensor process measure compliance to providers (Aim 2); evaluate the impact of the sensor approach on VAP process measure compliance by comparing compliance before and after the implementation of the real-time feedback strategy (Aim 3). The proposed work could fundamentally change how healthcare monitors and reports important care interventions, and has the potential to make quality improvement more efficient, inexpensive and scalable.  The candidate is uniquely qualified to undertake the proposed work. She is double-board certified in Critical Care and Emergency Medicine, and has completed a Patient Safety and Quality fellowship. She has led multiple local quality improvement initiatives, and worked to decrease ICU costs as part of a national task force, and is currently co-investigator of large national infection prevention collaborative. It isher determination, enthusiasm and strong work ethic which have enabled her to balance these research activities with a heavy clinical commitment. She now needs protected time for research and career development to become an independent investigator. PUBLIC HEALTH RELEVANCE: The goal of this proposal is to improve quality of care by using low-cost, off-the-shelf, and non-invasive sensor technology to automate the measurement and feedback of data regarding whether patients receive an evidence-based intervention, patient mobilization, to prevent ventilator-associated pneumonia.",An evaluation of sensor technology to monitor and report compliance with an evidence-based intervention to prevent ventilator-associated pneumonia,9115682,K23HL125982,"['Adherence', 'Adverse event', 'Advisory Committees', 'American', 'Anesthesiology', 'Big Data', 'Caring', 'Charge', 'Childhood', 'Clinical', 'Critical Care', 'Data', 'Data Collection', 'Data Science', 'Emergency Medicine', 'Engineering', 'Environment', 'Equilibrium', 'Evaluation', 'Event', 'Evidence based intervention', 'Feedback', 'Fellowship', 'Focus Groups', 'Frustration', 'Funding', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Human', 'Infection prevention', 'Information Technology', 'Intervention', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Nosocomial Infections', 'Nurses', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physician Assistants', 'Prevention', 'Prevention Measures', 'Preventive Intervention', 'Process', 'Process Measure', 'Provider', 'Quality of Care', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Techniques', 'Technology', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States Dept. of Health and Human Services', 'United States National Institutes of Health', 'Work', 'Work Ethic', 'base', 'care delivery', 'career development', 'cost', 'design', 'health care quality', 'improved', 'innovation', 'multi-component intervention', 'novel', 'patient safety', 'preference', 'pressure', 'prevent', 'professor', 'prospective', 'public health relevance', 'research and development', 'response', 'sensor', 'tool', 'ventilator-associated pneumonia', 'wasting']",NHLBI,JOHNS HOPKINS UNIVERSITY,K23,2017,198331,0.009717168293769318
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9277595,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2017,825202,0.0008201762125645231
"Active Power Exoskeleton Device for Spinal Cord Injury ! ABSTRACT Significance: Spinal cord injuries (SCI) cause costly and morbid chronic conditions such as lack of voluntary movement, increased chance of pressure sores, problematic spasticity, loss of bowel, bladder, and sexual function, and more physical impairments which result in a lower quality of life and lack of independence. Approximately 285,000 people in the U.S. have SCI with ~17,000 new patients added each year. Current treatment options include an array of electrical stimulation interventions or high-intensity fitness regimens, but all share one common limitation of being episodic in their treatment delivery. There is a compelling need for a treatment option that can be used daily, improves Activities of Daily Living (ADL’s), allows for in- home rehab and most importantly provides patient independence. Enabling technology exists, often proven in other medical device applications, that can facilitate the design of an upper limb orthotic system to deliver the functional performance required by SCI patients. The OlympEX Medical Actively Powered Exoskeleton (APEX) device can meet the functional movement requirements, will be designed for in-home use and be affordable to the user. Hypothesis: We hypothesize that the APEX orthotic system will achieve clinically meaningful improvement in a SCI patient’s range of motion (ROM) capability to perform ADL’s and to perform upper limb rehab in an in-home setting. Preliminary Work: The APEX orthotic system will be the third generation of orthotic device system to be developed by OlympEX Medical. Generations 1 and 2 are passively powered device systems that have provided the OlympEX design engineering team experience with mechanical apparatus requirements to elevate an upper limb. Likewise, the team has developed capabilities in advanced materials for the body chassis for these devices. The APEX orthotic system evolves from these product platforms to introduce system features in device guidance and user control only obtainable with an actively powered system. Specific Aims: This project entails the APEX hardware/electronic architecture development and the acute pre-clinical evaluation of the system on N=3 patients to evaluate patient safety and device feasibility. In Specific Aim 1 we will design, fabricate and evaluate the APEX mechanical design with electronic architecture. A subset of the APEX functional arm movements will be developed to demonstrate feasibility in performing a limited number of high priority ADL’s. In Specific Aim 2 we will evaluate the performance of this subset of ADL’s on 3 SCI patients. Success criteria will be Pass/Fail as evaluated by clinicians. In addition, an initial patient safety assessment will be completed. Safety factors including discomfort or pain before and after the fitting of the device and no uncontrolled arm movements will be evaluated. Together, these studies will demonstrate the feasibility of APEX device to guide arm movements required to complete ADL’s and therapeutic arm movements in an ambulatory setting. ! Project Narrative Those with cervical spinal cord injuries (SCI) have reduced ability to voluntarily move and use their arms and hands which results in the inability to accomplish many activities of daily living. OlympEX Medical proposes to develop and test an active powered upper extremity exoskeleton to help people with SCI and other neuromuscular conditions with their upper-limb function and rehabilitation. This will improve health, rehabilitative technology, quality of life, and independence for those with SCI.",Active Power Exoskeleton Device for Spinal Cord Injury,9465618,R43HD094440,"['Accelerometer', 'Activities of Daily Living', 'Acute', 'Address', 'Appointment', 'Architecture', 'Articular Range of Motion', 'Bladder', 'Cervical spinal cord injury', 'Chronic', 'Clinical', 'Computer software', 'Computers', 'Data', 'Decubitus ulcer', 'Development', 'Devices', 'Distal', 'Eating', 'Elbow', 'Electric Stimulation', 'Evaluation', 'Feedback', 'Generations', 'Grant', 'Hand', 'Head', 'Health', 'Health Care Costs', 'Home environment', 'Impairment', 'Individual', 'Institutes', 'Intervention', 'Intestines', 'Ions', 'Knowledge', 'Lithium', 'Longevity', 'Machine Learning', 'Mechanics', 'Medical', 'Medical Device', 'Monitor', 'Movement', 'Neuromuscular conditions', 'Orthotic Devices', 'Pain', 'Patients', 'Performance', 'Pilot Projects', 'Quality of life', 'Recruitment Activity', 'Regimen', 'Rehabilitation therapy', 'Safety', 'Sex Functioning', 'Shoulder', 'Source', 'Spastic', 'Spinal cord injury', 'Spinal cord injury patients', 'System', 'Technology', 'Testing', 'Textiles', 'Therapeutic', 'Upper Extremity', 'Voice', 'Weight Gain', 'Wheelchairs', 'Work', 'Wrist', 'arm', 'arm movement', 'cost', 'design', 'effective therapy', 'engineering design', 'exoskeleton', 'experience', 'fitness', 'improved', 'light weight', 'motor recovery', 'motor rehabilitation', 'operation', 'orthotics', 'patient safety', 'phase 2 study', 'phrases', 'pre-clinical', 'prevent', 'prototype', 'research clinical testing', 'spasticity', 'success', 'volunteer']",NICHD,"ABILITECH MEDICAL, INC.",R43,2017,239802,0.05233738340970931
"Independent Exoskeleton-Use through Robust Stand-to-Sit Safety Project Summary/Abstract Innovative Design Labs (IDL) proposes to create a system for the sensing and control of stand-to-sit motions of a wearable bionics suit. Currently 5.6 million people in the US have impaired mobility from a number of different causes. The primary means of mobility for many of these patients is the wheelchair as it has been for most of the last 50 years. Despite all the benefits introduced by widespread use of the wheelchair, it remains a less than ideal mobility solution. Exoskeleton suits have the potential to empower individuals with impaired mobility with an alternative to wheelchairs that allows them to stand up and walk independently within their home and community has the potential to more fully reintegrate these individuals into society while also further improving their health and quality of life. For exoskeletons to gain acceptance in every-day independent home and community use, many control and safety related functionalities still need to be addressed. Our proposal seeks to address one of the gaps in allowing for independent use of exoskeletons in the home and community, namely, functionality to transition from standing to sitting in a safe manner. The proposed work will provide exoskeleton users with the new ability to independently sit down without assistance and confidence in being able to do so without falling and risking possible injuries. It aims to significantly change the way exoskeletons work thereby facilitating their adoption into the market and directly impacting the lives of individuals with disabilities. Project Narrative Exoskeletons can provide patients with SCI, stroke, and other types of impaired mobility access to extended duration, gravity dependent ambulation that can directly combat the risks associated with physical deconditioning. There are benefits for exoskeleton-use to gain widespread acceptance in every-day, independent home and community settings. Currently, exoskeletons are not approved for independent-use because functionalities like transferring from standing-to-sitting requires continuous assistance from caregivers.",Independent Exoskeleton-Use through Robust Stand-to-Sit Safety,9409715,R44AG057267,"['Activities of Daily Living', 'Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Area', 'Bionics', 'Caliber', 'Caregivers', 'Chicago', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Country', 'Custom', 'Development', 'Disabled Persons', 'Emerging Technologies', 'Engineering', 'Environment', 'Evaluation', 'Fall injury', 'Feedback', 'Force of Gravity', 'Gait', 'Health', 'Height', 'Home environment', 'Hospitals', 'Imaging technology', 'Impairment', 'Individual', 'Injury', 'Institutes', 'Letters', 'Mechanics', 'Metric System', 'Motion', 'Patients', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Production', 'Quality of life', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Rest', 'Risk', 'Robotics', 'Safety', 'Scientist', 'Small Business Innovation Research Grant', 'Societies', 'Stroke', 'Surface', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Validation', 'Walking', 'Wheelchairs', 'Work', 'blind', 'combat', 'community setting', 'critical period', 'deconditioning', 'design', 'exoskeleton', 'experience', 'fall risk', 'falls', 'human study', 'improved', 'innovation', 'member', 'prototype', 'rehabilitation technology', 'robot exoskeleton']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2017,653843,-0.002413129457819139
"Psychophysics of Reading - Normal and Low Vision DESCRIPTION (provided by applicant):  Psychophysics of Reading - Normal and Low Vision Abstract Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  Difficulty in accessing print imposes obstacles to education, employment, social interaction and recreation.  The ongoing transition to the production and distribution of digital documents brings about new opportunities for people with visual impairment.  Digital documents on computers and mobile devices permit easy manipulation of print size, contrast polarity, font, page layout and other attributes of text.  In short, we now hae unprecedented opportunities to adapt text format to meet the needs of visually impaired readers.  In recent years, our laboratory and others in the vision-science community have made major strides in understanding the impact of different forms of low vision on reading, and the dependence of reading performance on key text properties such as character size and contrast.  But innovations in reading technology have outstripped our knowledge about low-vision reading.  A major gap still exists in translating these laboratory findings into methods for customizing text displays for people with low vision.  The broad aim of the current proposal is to apply our knowledge about the impact of vision impairment on reading to provide tools and methods for enhancing reading accessibility in the modern world of digital reading technology.  Our research plan has three specific goals:   1) To develop and validate an electronic version of the MNREAD test of reading vision, to extend this technology to important text variables in addition to print size, and to develop methods for customizing the selection of text properties for low-vision readers.  MNREAD is the most widely used test of reading in vision research and was originally developed in our laboratory with NIH support.  2) To investigate the ecology of low-vision reading in order to better understand how modern technologies, such as iPad and Kindle are being used by people with low vision.  We plan to evaluate the feasibility of using internet methods to survey low-vision individuals concerning their reading behavior and goals, and of collecting approximate measures of visual function over the internet.  We also plan to develop an ""accessibility checker"" to help low-vision computer users and their families to evaluate the accessibility of specific text displays.  3) To enhance reading accessibility by developing methods for enlarging the visual span (the number of adjacent letters that can be recognized without moving the eyes).  A reduced visual span is thought to be a major factor limiting reading in low vision, especially for people with central-field loss from macular degeneration.  We have already demonstrated methods for enlarging the visual span in peripheral vision.  We plan to develop a more effective perceptual training method for enlarging the visual span, with the goal of improving reading performance for people with central-vision loss. PUBLIC HEALTH RELEVANCE:  Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  The ongoing transition to the use of digital documents on computers and mobile devices brings about new opportunities for customizing text for people with visual impairment.  We propose to apply findings from basic vision science on low vision and reading to develop tools and methods for enhancing reading accessibility for digital text.",Psychophysics of Reading - Normal and Low Vision,9292314,R01EY002934,"['American', 'Attention', 'Auditory', 'Behavior', 'Blindness', 'Books', 'Caring', 'Central Scotomas', 'Characteristics', 'Clinical Research', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Custom', 'Dependence', 'Development', 'Devices', 'Ecology', 'Education', 'Employment', 'Eye', 'Family', 'Galaxy', 'Goals', 'Government', 'Guidelines', 'Habits', 'Health', 'Individual', 'Internet', 'Knowledge', 'Laboratories', 'Laboratory Finding', 'Leg', 'Length', 'Letters', 'Life', 'Macular degeneration', 'Mainstreaming', 'Maps', 'Marshal', 'Measures', 'Methods', 'Modernization', 'Optics', 'Paper', 'Participant', 'Patients', 'Perceptual learning', 'Performance', 'Peripheral', 'Play', 'Policies', 'Printing', 'Production', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysics', 'Reader', 'Reading', 'Recreation', 'Reporting', 'Research', 'Resources', 'Role', 'Self-Help Devices', 'Social Interaction', 'Surveys', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Work', 'analog', 'base', 'design', 'digital', 'essays', 'handheld mobile device', 'improved', 'innovation', 'invention', 'large print', 'literate', 'public health relevance', 'reading difficulties', 'sound', 'symposium', 'tool', 'vision science', 'web-accessible']",NEI,UNIVERSITY OF MINNESOTA,R01,2017,364423,-0.02090116883455783
"Multi-scale network dynamics of human upper limb movements: characterization and translation to neuroprosthetics DESCRIPTION (provided by applicant):  The overall project goals are to study the cortical network dynamics of human upper limb motor control spanning two distinct spatial scales recorded with electrocorticography (ECoG), and to demonstrate that these dynamics can be estimated in real-time and used to control the JHU Applied Physics Lab Modular Prosthetic Limb (MPL) during execution of functionally useful complex action sequences.  Our human subjects will be instructed to perform complete functional movements characteristic of activities of daily living.  We will analyze the task-related temporal evolution in the strength and pattern of interactions among large-scale cortical networks known to be recruited in visually-guided reach-to-grasp tasks.  Using multi-scale subdural ECoG with combinations of routine clinical macro-electrodes (2.3 mm diameter, 1 cm spacing) recording activity of broadly spread elements/nodes of neural networks, and inset arrays of microelectrodes (75 μm diameter, 0.9 mm spacing) recording the activity of local sub-networks, we will test our overall hypothesis that there is a functional hierarchy between the two scales (Aim 1).  More specifically, we hypothesize that large-scale network dynamics involving premotor/motor cortex reflect the evolution of sensory-motor processing demands during complex action sequences, while micro-scale population activity and network dynamics in motor cortex reflect the low-level kinematics of these tasks.  We will utilize methods of estimating dynamic effective connectivity developed by our team to study interactions between these scales and test whether there exists a spatially heterogeneous and hierarchical structure within the macro-micro scale networks.  The results of these analyses have wide-ranging clinical implications for both the optimal scale of functional mapping for clinical diagnostic purposes and the extent of implantations for neuroprosthetic control.  We will exploit multi-scale ECoG recordings and online estimates of the dynamics of neural activation and large-scale/local network interactions to achieve control of the MPL during functionally useful tasks (Aim 2).  This approach will go beyond traditional paradigms that have developed neural control over individual degrees of freedom.  We will do this by embedding low-level control within an innovative framework whereby knowledge of task goals supplement direct kinematic decoding.  This project will build on our team's previous successes in implementing a system for semi-autonomous ECoG control of the MPL, employing machine vision and route-planning algorithms, during complex interactions with objects requiring the coordination of multiple joints.  This system will be able to leverage for the first time the rich complexity of temporally and spatially resolved network dynamics correlated with high-level goals to achieve functionally useful control of an advanced neuroprosthetic limb. PUBLIC HEALTH RELEVANCE:  For ""Multi-scale network dynamics of human upper limb movements:  characterization and translation in neuroprosthetics"" This project will use recordings from the surface of the human brain to study how brain networks control arm and hand movements.  We will also test whether information about these networks can be used to control an advanced robotic prosthetic arm.  This could have a profound long-term impact on future generations of patients seeking to restore lost upper limb function with a lifelike prosthesis.",Multi-scale network dynamics of human upper limb movements: characterization and translation to neuroprosthetics,9319830,R01NS088606,"['Activities of Daily Living', 'Algorithms', 'Area', 'Artificial Arm', 'Attention', 'Biological Neural Networks', 'Brain', 'Caliber', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complex', 'Computer Assisted', 'Computer Vision Systems', 'Cues', 'Eating', 'Electrocorticogram', 'Electrodes', 'Elements', 'Epilepsy', 'Evolution', 'Freedom', 'Future Generations', 'Goals', 'Hand', 'Human', 'Human body', 'Individual', 'Joints', 'Knowledge', 'Limb Prosthesis', 'Limb structure', 'Location', 'Measures', 'Mediating', 'Methods', 'Microelectrodes', 'Modeling', 'Modification', 'Motor', 'Motor Cortex', 'Movement', 'Neurosciences', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Performance', 'Physics', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Prosthesis', 'Recruitment Activity', 'Resolution', 'Robotics', 'Route', 'Sampling', 'Sensory', 'Signal Transduction', 'Site', 'Structure', 'Surface', 'System', 'Testing', 'Time', 'Training', 'Translations', 'Upper Extremity', 'Upper limb movement', 'Vision', 'arm', 'clinical diagnostics', 'drinking', 'grasp', 'human subject', 'implantation', 'innovation', 'joint mobilization', 'kinematics', 'motor control', 'multisensory', 'neuroprosthesis', 'neuroregulation', 'public health relevance', 'relating to nervous system', 'success', 'temporal measurement', 'time use', 'translational impact']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2017,354375,0.014994853177007926
"Active Sensation during Odor-Guided Navigation in Mice PROJECT SUMMARY We often consider our movements a result of sensory processing – sensation guides behavior. However, animals selectively shape future sensory input through their own actions in a process known as active sampling. Thus, action and sensation are inextricably linked. Despite this, much of the research done on sensory processing restricts movement, most commonly via head fixation. To access sensorimotor processing during more natural behavior, we will study olfactory navigation in freely-moving mice. The olfactory system is ideal for studying sensory sampling, because of its ethological relevance for mammalian foraging and the dynamic nature of airborne odor stimuli. The proposed research will determine the sampling strategies of olfactory search and reveal the underlying circuitry that connects sensation with motion. Aim 1. It is unknown how rodents navigate dynamic plumes of odorant towards an odor source. In this aim, we will identify, analyze, and model active sensing behaviors that occur during increasingly difficult navigation tasks and with single nostrils occluded. These experiments will test the hypothesis that olfactory navigation works as a sensorimotor closed-loop system, where animals optimize sampling behaviors for the current stimulus conditions. These behavioral studies will lay the foundation for investigations of sensorimotor processing in dynamic olfactory scenes. Aim 2. To determine how sampling movements shape sensation, we will monitor neural activity during active sensory behavior. During odor tracking, we will electrophysiologically record in the olfactory bulb, a bottleneck through which all sensory input passes. We will determine the sensory history dependence of active sampling and, in doing so, reveal part of the underlying circuitry that connects motion with sensation. These experiments will test the hypothesis that sampling movements are sensory history dependent. To our knowledge, sampling movements and sensory activity have never been simultaneously recorded during olfactory navigation. This research will advance our understanding of the interplay between sensation and motion during natural behavior. PROJECT NARRATIVE Deficits in sensory motor communication are a major contributor to prevalent neurological disorders such as schizophrenia and Parkinson's disease. Our assay of olfactory navigation will model the interaction between sensation and movement and identify the circuitry through which movements are decided by sensory input. Discovering mechanisms of sensorimotor integration are the key to a better understanding of sensory processing in these disorders, since sensation and action are inextricably linked.",Active Sensation during Odor-Guided Navigation in Mice,9470632,F31DC016799,"['Animals', 'Anterior nares', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Biological Assay', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Disease', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Foundations', 'Future', 'Genetic', 'Head', 'Implant', 'Intake', 'Intervention Studies', 'Investigation', 'Link', 'Modeling', 'Monitor', 'Motion', 'Motor', 'Movement', 'Mus', 'Nature', 'Neurons', 'Nose', 'Odors', 'Olfactory Pathways', 'Output', 'Parkinson Disease', 'Pattern', 'Perception', 'Positioning Attribute', 'Process', 'Recording of previous events', 'Research', 'Respiration', 'Rewards', 'Rodent', 'Sampling', 'Schizophrenia', 'Sensory', 'Shapes', 'Smell Perception', 'Source', 'Stereotyping', 'Stimulus', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Vertebrates', 'Vision', 'Work', 'base', 'behavioral study', 'design', 'experimental study', 'insight', 'nervous system disorder', 'olfactory bulb', 'olfactory stimulus', 'relating to nervous system', 'sample fixation', 'sensory input', 'sensory stimulus', 'sensory system', 'tool']",NIDCD,UNIVERSITY OF OREGON,F31,2017,33050,-0.005959853994788
"Adaptive Prediction of Blood Glucose Levels using Wearable Physiological Sensors ﻿    DESCRIPTION (provided by applicant): Type 1 diabetes is a chronic disease, which presently cannot be prevented or cured. It is treated with insulin therapy and actively managed through blood glucose (BG) control. To avoid serious diabetic complications, patients must monitor their BG levels throughout the day, striving to avoid both hyperglycemia (high BG levels) and hypoglycemia (low BG levels). While continuous glucose monitoring (CGM) sensors and insulin pumps with ﬂexible dosing may aid in achieving good BG control, management of diabetes is still difﬁcult and laborious for patients and physicians. It is complicated by a wide variability among individual patients in terms of physiological responses to treatment as well as to life events such as stress, exercise, or changes in schedule and sleep. New portable sensing technologies have been recently developed for providing almost continuous measure- ments of an array of physiological parameters that include heart rate, skin conductance, skin temperature, and properties of body movements such as acceleration. The main research objective of this project is to leverage data acquired from wearable physiological sensors to build accurate, personalized blood glucose level prediction models for diabetes management. Predicting BG control problems before they occur would give patients time to intervene and prevent these problems. This would enhance patient safety and contribute to improved overall control, with its concomitant reduction in costly complications. Blood glucose level prediction is  very complex problem. Recent advances in unsupervised feature learning and deep learning have made it possible to learn complex models from data using simple algorithms. Inspired by these signiﬁcant developments in Artiﬁcial Intelligence (AI), we propose to employ unsupervised feature learn- ing and deep learning techniques in order to build an architecture for modeling blood glucose behavior that can seamlessly incorporate data coming from any number of physiological sensors. A recurrent neu- ral network (RNN) will be trained to capture dependencies among the input physiological parameters that are relevant to BG prediction. To account for individual patient differences, a predictive model will be developed for each patient by training on the features discovered by the RNN. The primary impact of this work would be to improve the overall health and quality of life for the 1.25 million Americans with type 1 diabetes. Accurate prediction models would enable practical applications ranging from alerts of impending problems to decision support tools for evaluating the effects of different food or lifestyle choice. Additionally, the wealth of patient and sensor data collected for this work will lead to the creatin of de-identiﬁed datasets to be used by the research community in evaluating approaches to blood glucose prediction. The new approaches developed for this complex domain may aid in the development of time series forecasting models for a broad array of sensor-enabled applications in other health and wellness domains.         PUBLIC HEALTH RELEVANCE: To aid in diabetes management, machine learning models will be built to predict future blood glucose levels based on wearable sensor data from commercially available fitness bands in addition to blood glucose, insulin and meal data. These models could help the over one million Americans with type 1 diabetes to anticipate and prevent blood glucose control problems before they occur. This would enhance patient safety and contribute to improved overall blood glucose control, with its associated reduction in costly complications.        ",Adaptive Prediction of Blood Glucose Levels using Wearable Physiological Sensors,9112492,R21EB022356,"['Acceleration', 'Accounting', 'Algorithms', 'American', 'Amputation', 'Architecture', 'Area', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Blindness', 'Blood Glucose', 'Carbohydrates', 'Chronic Disease', 'Communities', 'Complex', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Decision Support Systems', 'Dependency', 'Development', 'Diabetes Mellitus', 'Dose', 'Engineering', 'Equation', 'Event', 'Exercise', 'Expenditure', 'Food', 'Future', 'Galvanic Skin Response', 'Health', 'Health Care Costs', 'Heart Rate', 'Hyperglycemia', 'Hypoglycemia', 'Individual', 'Insulin', 'Insulin Infusion Systems', 'Insulin-Dependent Diabetes Mellitus', 'Intelligence', 'Intervention', 'Kidney Failure', 'Knowledge', 'Lead', 'Learning', 'Life', 'Life Style', 'Machine Learning', 'Manuals', 'Measurement', 'Modeling', 'Monitor', 'Movement', 'Myocardial Infarction', 'Patient Education', 'Patients', 'Performance', 'Physicians', 'Physiological', 'Property', 'Quality of life', 'Recurrence', 'Research', 'Schedule', 'Scientist', 'Series', 'Signal Transduction', 'Skin Temperature', 'Sleep', 'Speed', 'Stress', 'Stroke', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Work', 'base', 'blood glucose regulation', 'collected works', 'cost', 'data modeling', 'diabetes management', 'direct application', 'fitness', 'glucose monitor', 'improved', 'individual patient', 'multidisciplinary', 'novel strategies', 'patient safety', 'practical application', 'predictive modeling', 'prevent', 'public health relevance', 'sensor', 'speech recognition', 'support tools', 'technology development', 'treatment choice', 'treatment response']",NIBIB,OHIO UNIVERSITY ATHENS,R21,2016,225750,-0.0010711097950013334
"A Clinical 3D Movement Analysis System for Assessing Lower Extremity Injury Risk and Recovery in Athletes ﻿    DESCRIPTION (provided by applicant):  The mission of Bioniks is to develop and commercialize accurate, low-cost movement analysis systems for clinicians, ergonomists, athletic trainers, and other professionals interested in quantifying human movement. Our initial focus is on developing computer enhancements for inexpensive 3D cameras like the Microsoft Kinect. These enhancements surpass the accuracy limitations of state-of-the-art ""skeleton"" by combining established marker-based measurement protocols and advanced computer vision techniques, to generate clinical-quality 3D human motion data.  Difficult to obtain outside a laboratory setting, these kinematic data are inherently valuable for several NIH priority areas: 1) assessment of function and fatigability in older adults (NIA); 2) measurement of gait and posture biomechanics to monitor patients (NIAMS); 3) tools to enable mobile health and telemedicine by providing a means to monitor, evaluate, manage, track, train, and treat patients in underserved community settings and rural and remote locations (NIMHD, NINR); 4) tools for health informatics for clinical and translational research (NCATS); and 5) measurement of occupational health stressors in the workplace (NIOSH).  For this Phase I STTR, Bioniks' goal is to provide therapists with an affordable and easy-to-use 3D movement analysis system that quantifies an athlete's risk for, or recovery from, lower extremity injury. Our first aim is to show that the movement analysis system will not only be accurate and reliable (Aim 1), but also be practical and easy to use (Aim 2). We hypothesize that: 1) our kinematic measurements will agree with those from a gold-standard laboratory-based motion capture system (Vicon); and 2) that therapists will judge our system to be more useful and usable than current clinical tools, including traditional 2D video analyses. To test these hypotheses, we will conduct a validation study with healthy volunteers at the UCSF Human Performance Center as well as a pilot usability study with therapists and healthy volunteers and patients with history of ACL injury at the SF Sports and Spine Physical Therapy Clinic.         PUBLIC HEALTH RELEVANCE:  Because of the high cost and perceived ineffectiveness of traditional musculoskeletal care, there is growing pressure on health care professionals to provide more cost- effective treatments as well as to validate treatment effectiveness. Bioniks has the opportunity to be the first clinic-based tool that quantitatively and objectively assesses musculoskeletal function of patients over the course of treatment and rehabilitation. This STTR proposal focuses on quantification of an athlete's risk for, and recovery from, lower extremity injury.                ",A Clinical 3D Movement Analysis System for Assessing Lower Extremity Injury Risk and Recovery in Athletes,9046038,R41AR068202,"['Adoption', 'Adult', 'Algorithms', 'Ankle', 'Anterior Cruciate Ligament', 'Area', 'Athletic', 'Biomechanics', 'Boxing', 'Caring', 'Clinic', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Collection', 'Data Set', 'Drops', 'Dyskinetic syndrome', 'Elderly', 'Environment', 'Evaluation', 'Feasibility Studies', 'Feedback', 'Functional disorder', 'Gait', 'Goals', 'Gold', 'Health Professional', 'Human', 'Individual', 'Injury', 'Joints', 'Kinetics', 'Knee', 'Knee Injuries', 'Laboratories', 'Leg', 'Length', 'Limb structure', 'Location', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Mission', 'Monitor', 'Motion', 'Movement', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Nature', 'Occupational Health', 'Patient Monitoring', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physical therapy', 'Positioning Attribute', 'Posture', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recording of previous events', 'Recovery', 'Rehabilitation therapy', 'Research', 'Risk', 'Risk Factors', 'Rural', 'Series', 'Site', 'Skeleton', 'Small Business Technology Transfer Research', 'Sports', 'System', 'Techniques', 'Technology', 'Telemedicine', 'Testing', 'Time', 'Training', 'Translational Research', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Validation', 'Vertebral column', 'Video Games', 'Workplace', 'anterior cruciate ligament rupture', 'base', 'clinical practice', 'clinical research site', 'commercialization', 'community setting', 'cost', 'cost effective', 'design', 'healthy volunteer', 'interest', 'kinematics', 'ligament injury', 'mHealth', 'meetings', 'modifiable risk', 'movement analysis', 'neuromuscular function', 'physical therapist', 'pressure', 'public health relevance', 'research clinical testing', 'stressor', 'tool', 'usability', 'validation studies', 'volunteer']",NIAMS,"BIONIKS, INC.",R41,2016,215600,0.007136577790719934
"The neural workings of self-initiated and quasi-automatic movements ﻿    DESCRIPTION (provided by applicant): Uncovering the principles behind the generation of voluntary movements is a necessary first step in the development of technologies and treatments aimed at restoring motor abilities lost to neurological disease or trauma. The aim of this project is to shed light on the neural mechanisms of voluntary movement initiation. An essential component of voluntary movement is the choice of when to act. Under normal circumstances this decision can be time consuming usually taking up to a few hundreds of milliseconds, longer that the known delays in the nervous system. The area of the brain most associated with generating movements, the motor cortex, becomes very active just before and during the movement, however what exactly is happening during this time is still not well understood. Indeed, while much is known about the neural basis of generating movements, several open questions remain: does a movement generated deliberately with no time pressure, like a reach made to grab an object from a table, share the same neural underpinnings with a very fast reach to catch a falling object? Will the motor cortex be just as active before a quasi-automatic reach when time is of the essence? Or is pre-movement activity only present when there is enough time to deliberately plan the movement? During movement itself, is motor cortex involved in generating quasi-automatic reaches or is there is some reflex mechanism that bypasses motor cortex to generate urgent reaches? To begin answering these questions we have trained two monkeys to initiate a reach under three very different circumstances: sometimes monkeys move at a time of their own choosing with no imposed time constraints, other times monkeys must intercept a rapidly moving target on a screen, which elicits very short-latency reaches. In yet another set of trials monkeys must withhold a reach until given a go cue. The first aim of this project is to determine if these three movements (self-initiated, quasi-automatic and cue-initiated) share a common neural mechanism that does not depend on how the movement is initiated. To do this we will record the responses from a number of neurons in two key regions of the motor cortex: the primary motor and dorsal premotor cortex. In order to understand and interpret these responses, we will employ cutting edge machine learning techniques that will allow us to visualize and quantify the how neural activity evolves in time. Being able to visualize the evolution of neural activity is a key component in understanding the principles that govern how the neural activity translates to movement. The second aim of this project is to elucidate the role that higher cortical areas play in the generation of voluntar movements. We will record neural activity from areas upstream of motor cortex (supplementary motor area), which is heavily interconnected with the motor cortex and is suspected to play crucial a role in determining when a movement should be initiated. We will test record neural activity from this area and characterize its properties using the same cutting edge techniques developed in the first part of this project.         PUBLIC HEALTH RELEVANCE: Uncovering the principles behind the generation of voluntary movements is a necessary first step in the development of technologies and treatments aimed at restoring motor abilities lost to neurological disease or trauma. Arguably, one of the fundamental features of voluntary movement is that one chooses when to move. The main goal of the proposed project is to shed light on the neural mechanisms responsible for voluntary movement initiation.                ",The neural workings of self-initiated and quasi-automatic movements,9148079,F32NS092350,"['Area', 'Behavioral', 'Brain', 'Bypass', 'Cues', 'Data', 'Dependence', 'Dorsal', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Goals', 'Intercept', 'Life', 'Light', 'Link', 'Machine Learning', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Nervous system structure', 'Neurons', 'Pattern', 'Play', 'Population', 'Population Dynamics', 'Preparation', 'Process', 'Property', 'Property Rights', 'Reflex action', 'Role', 'Signal Transduction', 'Source', 'Staging', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'base', 'falls', 'grasp', 'millisecond', 'motor control', 'nervous system disorder', 'neuromechanism', 'pressure', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2016,21140,0.010863523915348925
"Crowd-Sourced Annotation of Longitudinal Sensor Data to Enhance Data-Driven Precision Medicine for Behavioral Health ﻿    DESCRIPTION (provided by applicant): Longitudinal sensor data collected passively from mobile phones and other wearable sensors will transform behavioral science by allowing researchers to use ""big data,"" but at the person-level, to understand how behavior and related environmental exposures impact health outcomes. Computers will analyze individual-level data streams to permit unprecedented, individual-level precision in research and intervention. This type of precision medicine enables targeting of science and medicine to a particular individual's genetic makeup, past and current situation, and behavioral health exposures. Mobile phones, smartwatches, and common fitness devices are already capable of generating rich data on behavior, but developing algorithms to interpret that raw data using the latest machine learning algorithms requires practical strategies to annotate large datasets. We propose to develop and test the feasibility and usability of a mobile and online crowdsource-based system for cleaning and annotating behavioral data collected from motion sensors, mobile phones, and other mobile devices. Our goal is to demonstrate how individuals playing mobile and online games - the ""crowd"" - can collectively, affordably, and incrementally clean and add important metadata to raw sensor data that has been passively collected from individuals, similar to that from population-scale surveillance studies (e.g., the National Health and Nutrition Examination Survey (NHANES) and UK Biobank) and those planned for studies such as the White House's Precision Medicine Initiative. The game-playing crowd will thereby dramatically improve the utility of the datasets collected for a variety of scientific studies. We will validate our prototye system on datasets collected from motion monitors used to study physical activity, sedentary behavior, and sleep, but we will demonstrate how the system could be extended for use on the increasingly rich datasets that are being collected with mobile devices and that include not only motion data, but also sensor data on location, light, audio, and person-to-person proximity. We will then refine the system, foster a community of crowd game players interested in citizen science, and release the source code to the system as an open source project so that other researchers can adapt the technique for their own work.         PUBLIC HEALTH RELEVANCE: Longitudinal sensor data collected passively from wearable activity monitors and mobile phones will transform behavioral science by allowing researchers to use ""big data,"" but at the person-level, to understand how behavior and related environmental exposures impact health outcomes and personalize health intervention and research. We propose to develop and test a system that permits typical mobile application game players to help scientists improve this type of data, by adding additional annotations that enrich the data, making it more useful for behavioral science and more amenable to automatic processing. This will help researchers to better understand how individual-level behaviors relate to health outcomes in current research studies that collect personal-level sensor data such as NHANES and the Women's Health Study, and future big data ventures such as the new Precision Medicine Initiative.        ",Crowd-Sourced Annotation of Longitudinal Sensor Data to Enhance Data-Driven Precision Medicine for Behavioral Health,9078547,UH2EB024407,"['Accelerometer', 'Algorithms', 'American', 'Behavior', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Car Phone', 'Classification', 'Cohort Studies', 'Communities', 'Complex', 'Computers', 'Crowding', 'Data', 'Data Collection', 'Data Quality', 'Data Science', 'Data Set', 'Devices', 'Environmental Exposure', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Genomics', 'Goals', 'Health', 'Housing', 'Human', 'Imagery', 'Individual', 'Intervention', 'Intervention Studies', 'Interview', 'Label', 'Lead', 'Light', 'Location', 'Machine Learning', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Monitor', 'Motion', 'National Health and Nutrition Examination Survey', 'Outcome', 'Output', 'Participant', 'Pathway Analysis', 'Pattern', 'Performance', 'Persons', 'Physical activity', 'Play', 'Population', 'Precision Medicine Initiative', 'Process', 'Proteomics', 'Research', 'Research Personnel', 'Risk Behaviors', 'Sampling', 'Science', 'Scientist', 'Sleep', 'Source Code', 'Stream', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Women&apos', 's Health', 'Work', 'base', 'behavioral health', 'biobank', 'citizen science', 'crowdsourcing', 'design', 'fitness', 'genetic makeup', 'handheld mobile device', 'improved', 'innovation', 'insight', 'instrument', 'interest', 'learning network', 'meetings', 'metabolomics', 'mobile application', 'mobile computing', 'novel', 'open source', 'precision medicine', 'prototype', 'public health relevance', 'research study', 'sedentary lifestyle', 'sensor', 'surveillance study', 'temporal measurement', 'tool', 'ubiquitous computing', 'usability']",NIBIB,NORTHEASTERN UNIVERSITY,UH2,2016,299438,-0.010325990792631095
"Enabling forelimb function with agonist drug and epidural stimulation in SCI DESCRIPTION (provided by applicant):  We have demonstrated that the physiological state of the lumbosacral spinal circuitry of spinal rats and cats can be modulated with spinal cord epidural stimulation (EDS) and/or administration of pharmacological agents to generate weight-bearing standing and stepping over a range of speeds, loads, and directions.  We have translated some of these results to humans by implanting 3 motor complete spinal cord injured (SCI) subjects about three years post-injury with an epidural electrode array over the lumbosacral spinal cord.  In less than one month post-electrode implant, the subjects could stand independently, and after up to 7 months of daily EDS and motor training, voluntary control of both legs was evident in the presence of EDS, whereas complete paralysis remained in absence of EDS.  We propose to employ a similar stimulation strategy for the recovery of upper limb function.  We will include extensive testing of spinal rats to guide our strategy to test for upper extremity improvement in human SCI subjects.  We will use off-the-shelf FDA approved pharmacological and stimulation modalities to:  1) Determine the optimal stimulation parameters, i.e., electrode placement and stimulation intensity, frequency and duration, for facilitating forelimb fine motor function in rats with a cervical SCI.  Using existing FDA-approved epidural electrodes, we will demonstrate in patients with a cervical SCI that cervical EDS can facilitate arm-hand function.  2) Identify an effective mode of administration, define the dose- response pharmacokinetics, and determine the effectiveness of a monoaminergic agonist to facilitate upper limb function after a cervical SCI.  We will assess the effectiveness of existing FDA-approved pharmacological agents (i.e., buspirone and as an alternative, bromocriptine), and determine their effectiveness in improving forelimb control in subjects with a cervical SCI.  3) Define the dose-response properties of monoaminergic agonists when combined with EDS in facilitating forelimb function in rats after a cervical SCI.  We will demonstrate the efficacy of ES in combination with a pharmacological intervention in facilitating arm and hand function in humans after a cervical SCI.  4) Determine whether motor training of spinal rats will further enhance the recovery of motor function when combined with pharmacological and/or EDS interventions.  5) Develop a protocol for machine learning to enable rapid selection of the optimal pharmacological and EDS parameters for motor recovery in rats and in human subjects.  If successful, this could represent the beginning of a paradigm shift in the use of minimally invasive strategies combined with rehabilitative approaches to realize significant improvement in upper limb function after paralysis. PUBLIC HEALTH RELEVANCE:  It now seems possible to apply three interventions (epidural stimulation, administration of pharmacological agents, and motor training) to control the excitability of localized neural circuits in humans with a cervical spinal cord injury (SCI), thus enabling these individuals to regain use of their arms and hands.  This enabling effect is similar to that observed with improved postural and locomotor function after a mid-thoracic SCI.  We will reach critical milestones that will provide the basis for a series of clinical trials for furter defining the efficacy of these interventions.",Enabling forelimb function with agonist drug and epidural stimulation in SCI,9147671,U01EB015521,"['Agonist', 'Algorithms', 'Ankle', 'Bromocriptine', 'Buspirone', 'Cervical', 'Cervical spinal cord injury', 'Cervical spinal cord structure', 'Chronic', 'Clinical Trials', 'Complement', 'Devices', 'Dose', 'Drug Kinetics', 'Effectiveness', 'Electrodes', 'FDA approved', 'Felis catus', 'Food', 'Forelimb', 'Frequencies', 'Goals', 'Hand', 'Hand functions', 'Health', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Knee', 'Leg', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Methodology', 'Modality', 'Motor', 'Motor Skills', 'Oral', 'Paralysed', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Preparation', 'Property', 'Protocols documentation', 'Rattus', 'Recovery', 'Rehabilitation therapy', 'Retrieval', 'Series', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Testing', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Translating', 'Treatment Efficacy', 'Upper Extremity', 'Weight-Bearing state', 'arm', 'arm function', 'base', 'design', 'human subject', 'improved', 'learning strategy', 'minimally invasive', 'motor function recovery', 'motor recovery', 'neural circuit', 'neuroregulation', 'response']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2016,104514,0.020734129653831194
"Enabling forelimb function with agonist drug and epidural stimulation in SCI DESCRIPTION (provided by applicant):  We have demonstrated that the physiological state of the lumbosacral spinal circuitry of spinal rats and cats can be modulated with spinal cord epidural stimulation (EDS) and/or administration of pharmacological agents to generate weight-bearing standing and stepping over a range of speeds, loads, and directions.  We have translated some of these results to humans by implanting 3 motor complete spinal cord injured (SCI) subjects about three years post-injury with an epidural electrode array over the lumbosacral spinal cord.  In less than one month post-electrode implant, the subjects could stand independently, and after up to 7 months of daily EDS and motor training, voluntary control of both legs was evident in the presence of EDS, whereas complete paralysis remained in absence of EDS.  We propose to employ a similar stimulation strategy for the recovery of upper limb function.  We will include extensive testing of spinal rats to guide our strategy to test for upper extremity improvement in human SCI subjects.  We will use off-the-shelf FDA approved pharmacological and stimulation modalities to:  1) Determine the optimal stimulation parameters, i.e., electrode placement and stimulation intensity, frequency and duration, for facilitating forelimb fine motor function in rats with a cervical SCI.  Using existing FDA-approved epidural electrodes, we will demonstrate in patients with a cervical SCI that cervical EDS can facilitate arm-hand function.  2) Identify an effective mode of administration, define the dose- response pharmacokinetics, and determine the effectiveness of a monoaminergic agonist to facilitate upper limb function after a cervical SCI.  We will assess the effectiveness of existing FDA-approved pharmacological agents (i.e., buspirone and as an alternative, bromocriptine), and determine their effectiveness in improving forelimb control in subjects with a cervical SCI.  3) Define the dose-response properties of monoaminergic agonists when combined with EDS in facilitating forelimb function in rats after a cervical SCI.  We will demonstrate the efficacy of ES in combination with a pharmacological intervention in facilitating arm and hand function in humans after a cervical SCI.  4) Determine whether motor training of spinal rats will further enhance the recovery of motor function when combined with pharmacological and/or EDS interventions.  5) Develop a protocol for machine learning to enable rapid selection of the optimal pharmacological and EDS parameters for motor recovery in rats and in human subjects.  If successful, this could represent the beginning of a paradigm shift in the use of minimally invasive strategies combined with rehabilitative approaches to realize significant improvement in upper limb function after paralysis. PUBLIC HEALTH RELEVANCE:  It now seems possible to apply three interventions (epidural stimulation, administration of pharmacological agents, and motor training) to control the excitability of localized neural circuits in humans with a cervical spinal cord injury (SCI), thus enabling these individuals to regain use of their arms and hands.  This enabling effect is similar to that observed with improved postural and locomotor function after a mid-thoracic SCI.  We will reach critical milestones that will provide the basis for a series of clinical trials for furter defining the efficacy of these interventions.",Enabling forelimb function with agonist drug and epidural stimulation in SCI,9126281,U01EB015521,"['Agonist', 'Algorithms', 'Ankle', 'Bromocriptine', 'Buspirone', 'Cervical', 'Cervical spinal cord injury', 'Cervical spinal cord structure', 'Chronic', 'Clinical Trials', 'Complement', 'Devices', 'Dose', 'Drug Kinetics', 'Effectiveness', 'Electrodes', 'FDA approved', 'Felis catus', 'Food', 'Forelimb', 'Frequencies', 'Goals', 'Hand', 'Hand functions', 'Health', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Knee', 'Leg', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Methodology', 'Modality', 'Motor', 'Motor Skills', 'Oral', 'Paralysed', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Preparation', 'Property', 'Protocols documentation', 'Rattus', 'Recovery', 'Rehabilitation therapy', 'Retrieval', 'Series', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Testing', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Translating', 'Treatment Efficacy', 'Upper Extremity', 'Weight-Bearing state', 'arm', 'arm function', 'base', 'design', 'human subject', 'improved', 'learning strategy', 'minimally invasive', 'motor function recovery', 'motor recovery', 'neural circuit', 'neuroregulation', 'response']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2016,1209467,0.020734129653831194
"Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI DESCRIPTION (provided by applicant):  In the first 5-year period of our BRP we had two major objectives:  1) to determine whether we could improve motor function of the lower limbs by neuromodulating the spinal lumbosacral circuitry with epidural stimulation and 2) to begin to develop and improve the technologies associated with electrode arrays and chronic implantable stimulation devices to maximize the neuromodulatory potential.  These new technologies have the potential to fine tune the epidural stimulation parameters, to help in understanding some of the underlying mechanisms of epidural stimulation., to examine synergistic effects of epidural stimulation, pharmacological modulation, and examine activity-dependent interventions that might affect the level of recovery of motor function after complete paralysis.  We have demonstrated that an adult rat with a complete, mid-thoracic spinal cord transection can regain full weight-bearing stepping over a range of speeds, loads, and even directions when the spinal cord is stimulated tonically to increase the excitability of the lumbosacral locomotor circuitry.  Furthermore, we learned that load-bearing sensory information can serve as the controller of these complex motor tasks and that the performance of these tasks can be improved even further with combinations of epidural stimulation, pharmacological, and motor training interventions.  We have shown that four humans with a motor complete spinal injury have regained independent standing, assisted stepping, and even a significant level of voluntary control of the lower limbs in the presence of epidural stimulation, with one subject now even having some volitional control without stimulation.  Improvement in bladder control, blood pressure, temperature regulation, and even sexual function has been realized.  Thus, our present challenge is to develop the capability to selectively activate combinations of neural networks that can enable standing, and probably stepping, by improving the technologies needed to make this intervention available in the clinic and in the home of individuals with complete motor paralysis using a chronic epidural electrode implant.  Specifically, we will further improve the electrode array stimulation technology needed for fine-tune control in rats and humans and transform the present hardwired technology for rats to a wireless capability to stimulate and record evoked potentials along the brain-spinal cord-muscle axis in the rat.  To advance the clinical potential, we will continue to develop, refine and validate our machine-learning strategies which automatically optimize stimulation parameters for standing, stepping, and voluntary control.  We will develop an improved interface between the devices implanted in our present subjects and the control devices for defining the specific stimulation parameters needed for a given subject to perform a motor task in the clinic or at home. PUBLIC HEALTH RELEVANCE:  We now have demonstrated that the human lumbosacral spinal cord can be neuromodulated with epidural stimulation to enable recovery of standing and volitional control of the lower limbs and return of some autonomic function after complete motor paralysis.  Therefore, our objectives are now to develop the technologies needed to more fully capitalize on this clinical potential and develop home-use technologies to do so.",Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI,9134137,U01EB007615,"['Adult', 'Affect', 'Algorithms', 'Animals', 'Behavior', 'Binding', 'Biological Neural Networks', 'Bladder Control', 'Blood Pressure', 'Brain', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Complex', 'Contusions', 'Data', 'Devices', 'Dorsal', 'Educational Intervention', 'Electrodes', 'Evaluation', 'Evoked Potentials', 'Experimental Designs', 'Frequencies', 'Health', 'Home environment', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Internet', 'Intervention', 'Intramuscular', 'Learning', 'Locomotor training', 'Lower Extremity', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Muscle', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Procedures', 'Process', 'Rattus', 'Recovery', 'Regulation', 'Research', 'Robotics', 'Sensory', 'Sex Functioning', 'Signal Transduction', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord transection injury', 'Spinal Injuries', 'Spinal cord injury', 'Stimulus', 'System', 'Task Performances', 'Technology', 'Temperature', 'Testing', 'Thoracic spinal cord structure', 'Training', 'Weight-Bearing state', 'Wireless Technology', 'base', 'density', 'design', 'implantable device', 'improved', 'in vivo', 'learning strategy', 'motor control', 'motor function improvement', 'motor function recovery', 'neuroregulation', 'new technology', 'next generation', 'novel', 'somatosensory', 'treadmill', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2016,1090691,0.04173526953974432
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability.         PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.        ",Capti Screen Reading Assistant for Goal Directed Web Browsing,9048176,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Learning', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'empowered', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2016,500000,-0.004244744306643634
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research ﻿    DESCRIPTION (provided by applicant): This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0(tm) that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud(tm) Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb's DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently.         PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.        ",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9138555,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'United States National Institutes of Health', 'Work', 'analytical tool', 'animal data', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'meetings', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'research study', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2016,750063,-0.0003880359215348624
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering. PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,9336584,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Health', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'rehabilitation engineering', 'robot rehabilitation', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2016,28000,0.013829362954416528
"NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired PROJECT SUMMARY (See instructions): The objective of the proposed research is to develop new technology for a Wearable Robotic Object Manipulation Aid (W-ROMA) for the visually impaired. The W-ROMA is a hand-worn assistive device that provides assistance to a visually impaired individual in effectively grasping an object. Thanks to the onboard computer vision methods, the W-ROMA is capable of detecting a target object, determining the hand-object misalignment, and conveying to the wearer, via natural human-device interfaces, the desired hand motion for hand-object alignment. The W-ROMA will contribute to the independent lives of the visually impaired in twofold: First, it helps the visually impaired with independent travel by enabling them to identify a movable obstacle and manipulate the obstacle to make a passage. Second, it assists the visually impaired in effectively grasping an object for non-navigational purpose. The PIs will involve graduate, undergraduate and high school students in the project and use the proposed project activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision and human-robot interaction methods that support accurate and effective object grasping for the visually impaired for their independent daily lives. These methods include: (1) a new real-time object recognition method; (2) an innovative hand-object alignment mechanism; (3) a novel hybrid tactile display system for object shape rendering; and (4) a computationally efficient device localization method. The proposed solutions can be encapsulated in a hand-worn robotic device. The W-ROMA will provide new co-robotic functions for the visually impaired. The PIs have performed proof of concept studies for the computer vision and tactile display methods and the results are promising. The broader impacts include: (1) the research will positively impact the large visually impaired community; (2) the proposed methods can be applied to other small robotic systems that have a wide range of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the PI's university and train graduate and undergraduate students for their future careers in science and engineering. RELEVANCE (See instructions): The project addresses a growing public health care issue--visual impairment. The research fits well into the NEI's Low Vision and Blindness Rehabilitation program that supports development of new technologies for minimizing the impact of visual impairment. The project addresses the NEI's mission by developing new assistive technology that will help the visually impaired to maintain a higher quality of life.",NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired,9136188,R01EY026275,"['Address', 'Blindness', 'Canes', 'Code', 'Communities', 'Companions', 'Computer Vision Systems', 'Data', 'Detection', 'Development', 'Devices', 'Encapsulated', 'Engineering', 'Environment', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'Hand', 'Healthcare', 'High School Student', 'Human', 'Hybrids', 'Image', 'Independent Living', 'Individual', 'Instruction', 'Law Enforcement', 'Maps', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'Motion', 'Movement', 'National Institute of Biomedical Imaging and Bioengineering', 'Performance', 'Persons', 'Polymers', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robotics', 'Rotation', 'Scheme', 'Science', 'Self-Help Devices', 'Solid', 'Speech', 'Speed', 'Students', 'System', 'Tactile', 'Testing', 'Thumb structure', 'Time', 'Training', 'Translations', 'Travel', 'United States National Institutes of Health', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'base', 'blind', 'career', 'design', 'experience', 'graduate student', 'grasp', 'human-robot interaction', 'improved', 'innovation', 'new technology', 'novel', 'object recognition', 'object shape', 'programs', 'research study', 'robotic device', 'tactile display', 'undergraduate student']",NEI,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2016,274076,-0.033824213201892134
"Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition ﻿    DESCRIPTION (provided by applicant): Non-invasive medical devices are fast emerging as powerful tools in providing quantitative, simple to parse data in assessing the health and wellness of users. These devices can provide information feedback to users on their state of health, and can potentially provide valuable real-time insight to doctors on the links between user consumption and activity on their respective health. Recently described epidermal electronics / multifunctional tattoos introduced from our lab and others have demonstrated sensing of biopressure, bioelectricity, analyte concentration, bacteria, and more. These structures potentially represent the evolution of wearable devices as they possess a negligible form factor and conform to any surface (such as skin or teeth), minimizing user impact. These devices also bypass more traditional, ""wearable"" gadgets that often require bulky mechanical fixtures or straps, require complex microfluidic systems or integrated electronics, cannot provide dynamic readout, and cannot be disposed of easily. Dielectric sensors are a class of structures that are able to probe the composition of a biofluid via their impedance spectrum, and can be configured for remote sensing via radio waves. These devices can be composed of isolated, thin film circuits, and are directly amenable to epidermal or tattoo formats. This measurement methodology is inherently tremendously powerful, as it can potentially measure multiple analytes at once by probing multiple resonance peaks, and can potentially be piggybacked onto existing RFID infrastructure for data readout. However, these capabilities have not yet been demonstrated, and under real-world applications dielectric sensors have often proven difficult to use. This is often due to simplistic readout (devices will directly correlate a single metric such s the real value of the impedance at a frequency to a biomarker) and are thus can be sensitive from user to user or to environmental conditions. Herein, the applicant will leverage the expertise and knowledge of the labs of Dr. Omenetto and colleagues to bring practical usability to these dielectric antennas, bridging the gap between laboratory measurement and real-time, and real-world health monitoring applications. The end-goal is to generate disposable, skin and teeth-mounted, dielectric sensors to remotely probe the presence of biomarkers in sweat, saliva, and potentially blood to draw definitive links between user nutrition and their health.         PUBLIC HEALTH RELEVANCE: This proposal seeks to create non-invasive, wireless sensor tattoos to be tagged onto the human body for probing the composition of saliva, sweat, or blood. These wireless sensors would present negligible impediment to the user, and would require next to no upkeep to maintain, potentially facilitating an unprecedented level of subject data collection and dissemination. Such data could yield conclusive links between diet, activity, biomarkers, and public health.            ","Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition",9148070,F32EB021159,"['Architecture', 'Bacteria', 'Behavior', 'Biocompatible Materials', 'Biological', 'Biological Markers', 'Blood', 'Bypass', 'Cells', 'Characteristics', 'Classification', 'Complex', 'Consumption', 'Data', 'Data Analyses', 'Data Collection', 'Detection', 'Development', 'Devices', 'Diet', 'Electronics', 'Evolution', 'Feedback', 'Film', 'Fingerprint', 'Frequencies', 'Goals', 'Health', 'Human body', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medical Device', 'Methodology', 'Microfluidics', 'Monitor', 'Nafion', 'Pattern', 'Performance', 'Principal Component Analysis', 'Public Health', 'Radio', 'Radio Waves', 'Reader', 'Research Infrastructure', 'Running', 'Saliva', 'Silk', 'Skin', 'Sodium', 'Stimulus', 'Structure', 'Surface', 'Sweat', 'Sweating', 'System', 'Tattooing', 'Testing', 'Time', 'Tooth structure', 'Training', 'Urea', 'Validation', 'Wireless Technology', 'World Health', 'bioelectricity', 'design', 'electric impedance', 'enzyme activity', 'flexibility', 'glucose monitor', 'improved', 'insight', 'non-invasive monitor', 'nutrition', 'public health relevance', 'real world application', 'remote sensing', 'response', 'saliva composition', 'sensor', 'tool', 'usability']",NIBIB,TUFTS UNIVERSITY MEDFORD,F32,2016,47190,0.03838441638563263
"Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings ﻿    DESCRIPTION (provided by applicant): ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the cost  of  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resoure  settings.  We propose to advance our previously developed low-cost, handheld device capable of automatically measuring the optical properties of the eye based on the technique of wavefront aberrometry.  The  proposed  work  will  specifically  focus  on  the development of optical and software systems will extend the device's measurement  range  to  work  on  a  larger  range  of  refractive  errors.  First,  optical  systems  with  no  moving  parts  will  be  developed  which  enable  the  device  to  work  on  subjects  with  severe  myopia  or  hyperopia  (<-­-6  diopters or  >6  diopters  of  refractive  error).  Second,  algorithms  that  make  the  device  easy  and  intuitive  to  use  will  be  implemented.  Third,  a  handheld  prototype  incorporating  these  improvements  will  be  constructed  and  validated  in  model  eye  systems.  The  output  of  this  project  will  be  a  functional,  extended-range  prototype  that  will  facilitate  the  fild-testing  and  commercialization  of  a  low-cost,  easy-to-use  device  to  dispense  eyeglass  prescriptions. PUBLIC HEALTH RELEVANCE: ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the  cost  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resource  settings.  Specifically,  optical  and  software  systems  will  be  developed  that  will  extend  the  measurement  range  of  a  low-cost  device  that  automatically  prescribes  eyeglasses  for patients with a large range of refractive errors.","Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings",9349858,R43EY025452,"['Adoption', 'Algorithms', 'Brazil', 'Caring', 'China', 'Client satisfaction', 'Clinical Trials', 'Communities', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Ensure', 'Eye', 'Eyeglasses', 'Feedback', 'Goals', 'Health', 'Hospitals', 'Human', 'Human Resources', 'Hyperopia', 'Image', 'India', 'Laser In Situ Keratomileusis', 'Letters', 'Licensing', 'Lighting', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Myopia', 'New England', 'Nurses', 'Operative Surgical Procedures', 'Optics', 'Optometrist', 'Optometry', 'Output', 'Patients', 'Performance', 'Pharmacists', 'Phase', 'Population', 'Positioning Attribute', 'Productivity', 'Property', 'Protocols documentation', 'Provider', 'Pupil', 'Quality of life', 'Refractive Errors', 'Resources', 'Rest', 'Retina', 'Source', 'Spottings', 'System', 'Target Populations', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Vision', 'Visual Acuity', 'Work', 'base', 'college', 'commercialization', 'cost', 'design', 'digital', 'disability', 'field study', 'handheld equipment', 'improved', 'lens', 'meetings', 'prototype', 'software systems', 'standard of care', 'success', 'usability']",NEI,"PLENOPTIKA, INC.",R43,2016,25000,-0.0028882514814155126
"Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography ﻿    DESCRIPTION (provided by applicant):  We propose a tonometry based solution to the problem of inexpensive, unencumbering and non- invasive measurement of blood pressure. The proposed solution will be useful in clinical as well as ambulatory blood pressure measurements. Specifically, we propose to develop a large (1cm x 5cm) two-dimensional array of pressure sensors with 0.2mm spacing (24x128 pressure-sensing elements), together with robust signal processing algorithms with a feedback controlled band-tightening mechanism in order to measure blood pressure at the wrist. The pressure sensor array together with a photoplethysmogram (PPG) sensor will be embedded in a band, and will provide signals through a multiplexed circuit designed. Signal conditioning techniques will be used to get the large amount of data in the form that can be efficiently processed on a microcontroller. The proposed two-dimensional array of pressure sensors will be built using flexible plastic and micro-fabrication techniques. The increased size of the sensor array will ensure proper contact and pressure application with arteries in the wrist for tonometric measurement of BP. The signals generated from the sensor array will be processed through advanced signal processing and optimization techniques to handle the huge amount of data and to mitigate noise. The PPG signals will be used at the wrist to improve the efficiency and accuracy of the system. The sensor array system will be embodied in the form of a band, which will be integrated in a wearable device such as smartwatch. The capabilities of the smartwatch will be used for data processing and analytics. a) Design, develop, and test a two-dimensional pressure sensor array on a polyimide flexible substrate b) Process large amount of analog data from sensor array using signal conditioning and processing techniques  to generate blood pressure estimates c) Design a user friendly prototype form factor, and perform a clinical trial to validate device performance  The engineering members of our multidisciplinary team have specialized in cardiac instrumentation, signal and image processing for medical applications, pressure and touch sensors, signal processing and robust optimization. The team members with clinical expertise have been engaged in blood pressure trials in US, and have been working with leading institutions in India engaged in cardiovascular research. This proposal brings together their unique expertise and experience to innovatively address this challenging problem through a joint effort. PUBLIC HEALTH RELEVANCE: Unmanaged hypertension is a major problem, and its management based on occasional measurement is known to be suboptimal. The ability to measure blood pressure using non- invasive techniques in an ambulatory setting has many significant benefits. We propose to research and develop a large (1cm x 5cm) two-dimensional array of pressure sensors based device together with robust signal processing algorithms with a feedback controlled to measure blood pressure at the wrist. The device will be test in a clinical trial based on the European Society of Hypertension International Protocol.",Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography,9145739,U01EB020589,"['Address', 'Algorithms', 'Area', 'Arteries', 'Blood Pressure', 'Blood Pressure Monitors', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Engineering', 'Clinical Trials', 'Data', 'Data Analytics', 'Devices', 'Elements', 'Engineering', 'Ensure', 'Environment', 'European', 'Fatigue', 'Feedback', 'Generations', 'Goals', 'Health', 'Hypertension', 'India', 'Institution', 'International', 'Joints', 'Lead', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Noise', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Photoplethysmography', 'Process', 'Protocols documentation', 'Research', 'Signal Transduction', 'Societies', 'Somatotype', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Touch sensation', 'Training', 'Untrained Personnel', 'Work', 'Wrist', 'analog', 'arterial tonometry', 'base', 'computerized data processing', 'conditioning', 'design', 'experience', 'field study', 'flexibility', 'image processing', 'improved', 'instrumentation', 'member', 'multidisciplinary', 'pressure', 'process optimization', 'prototype', 'rural area', 'sensor', 'signal processing', 'tonometry', 'two-dimensional', 'user-friendly']",NIBIB,NORTHWESTERN UNIVERSITY AT CHICAGO,U01,2016,355735,0.02683103379708547
"Understanding the Neural Basis of Volitional State through Continuous Recordings in Humans ABSTRACT In the course of a day we naturally make multiple shifts in our overall cognitive state and in our aims and intents. We go from sleep to awake, from internal dialogue to external communication, from relative immobility to planned complex movements. The neural activity which distinguishes these different high-level states is unknown and yet is a fundamental aspect to understanding overall cognitive processes. It is also a baseline substrate that is adversely impacted by a wide range of neuropsychiatric diseases. Our understanding of human cortical neurophysiology is almost entirely based on cognitive processes examined within the constraints of experimentally controlled tasks with time-locked, stimulus-driven behaviors. However, brain activity is fluid and continuous; much of our essential cognitive activity is not externally triggered but internally generated. The overarching goal of this research is to create platforms which allow for continuous acquisition of high-fidelity neural ensemble activity synchronized with behavioral data and contextual information to allow investigations into volitional changes in focus and intent. Data will be acquired from two groups of patients: those undergoing intracranial exploration for treatment of their epilepsy and patients implanted with multi- electrode arrays as part of the BrainGate clinical trial to restore communication and mobility to people with paralysis. Using this novel paradigm for investigation, we will explore the neural basis for changes in state which are dominated by receptive activities, internal thought and external interaction. We initially focus on motor behavior with a traditional task construction constraining the participant to watch, imagine and then attempt or actually move. We expand this to spontaneous activity in Aim 2. Finally, we move toward more general and abstracted investigations of volitional state by looking at an analogous task and spontaneous behavior with respect to language and communication (Aim 3). At each stage we will employ spectral, functional connectivity and data mining techniques to understand the neural underpinnings of these different states as well as the temporal dynamics that portend changes in state. Supporting all of these aims will be improvements and expansions in state-of-the-art human micro- and mesoscale neural recording environments to enable the study of continuous, real-time neural activity underlying state changes. Across aims we will explore the extent to which motor cortex alone contains the information which may be present in more widespread and higher order cortical regions. Our hypothesis is that motor cortex, does in fact, encode significant information about state in ways which encapsulate or summarize the information available in more wide spread regions. Most importantly, the questions inherent in this research are key to understanding human thought patterns at a fundamental level. This understanding has important implications not just for basic cognitive neuroscience but for our understanding of the processes which are altered in a wide range of neuropsychiatric disorders such as epilepsy, the dementias, depression, and psychosis. The results of these studies are also essential for the practical instantiation of effective brain-machine interfaces which would allow patients to act autonomously. Narrative: From simple decisions to more significant and complex thoughts, we constantly shift our aims and intentions and the degree to which we are interacting externally or internally. Understanding these shifts is key to the development of truly autonomous brain-computer interfaces and neuroprosthetics as well as to understanding how these kinds of alterations can be compromised in a wide variety of neuropsychiatric diseases. In this project we go beyond routine cognitive studies based on constrained stimulus response designs and instead utilize continuous recordings of neural activity during spontaneous behavior to decode changes in volitional state during motor activity and communication.",Understanding the Neural Basis of Volitional State through Continuous Recordings in Humans,9205859,U01NS098968,"['Area', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Classification', 'Clinical Trials', 'Cognitive', 'Communication', 'Complex', 'Data', 'Dementia', 'Development', 'Encapsulated', 'Environment', 'Epilepsy', 'Evaluation', 'Evoked Potentials', 'Goals', 'Hearing', 'Human', 'Implant', 'Intention', 'Investigation', 'Language', 'Liquid substance', 'Machine Learning', 'Measures', 'Mediator of activation protein', 'Mental Depression', 'Microelectrodes', 'Motor', 'Motor Activity', 'Motor Cortex', 'Movement', 'Nature', 'Neurocognitive', 'Neurons', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Paralysed', 'Parietal', 'Participant', 'Pathologic', 'Patients', 'Pattern', 'Process', 'Psychotic Disorders', 'Reading', 'Research', 'Response to stimulus physiology', 'Sleep', 'Staging', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thinking', 'Time', 'Volition', 'Work', 'Writing', 'abstracting', 'awake', 'base', 'brain computer interface', 'brain machine interface', 'cognitive neuroscience', 'cognitive process', 'data mining', 'design', 'driving behavior', 'expectation', 'insight', 'multi-electrode arrays', 'neural circuit', 'neuromechanism', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'relating to nervous system', 'research study', 'sensor', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,U01,2016,1443240,-0.008443190541631392
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9038348,R01DC009834,"['21 year old', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'P300 Event-Related Potentials', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'meetings', 'mindfulness meditation', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'research study', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2016,652362,-0.05213281438464142
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging. PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,9132242,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Health', 'Heart', 'Hybrids', 'Image', 'Individual', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Marketing', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'prevent', 'programs', 'prospective', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'skills training', 'success', 'tool', 'validation studies', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2016,169609,-0.03170440075110493
"Enabling access to printed text for blind people via assisted mobile OCR DESCRIPTION (provided by applicant): This application proposes new technology development and user studies aiming to facilitate the use of mobile Optical Character Recognition (OCR) for blind people. Mobile OCR systems, implemented as smartphones apps, have recently appeared on the market. This technology unleashes the power of modern computer vision algorithms to enable a blind person to hear (via synthetic speech) the content of printed text imaged by the smartphone's camera. Unlike traditional OCR, that requires scanning of a document with a flatbed scanner, mobile OCR apps enable access to text anywhere, anytime. Using their own smartphones, blind people can read store receipts, menus, flyers, business cards, utility bills, and many other printed documents of the type normally encountered in everyday life. Unfortunately, current mobile OCR systems suffer from a chicken-and-egg problem, which limits their usability. They require the user to take a well-framed snapshot of the document to be scanned, with the full text in view, and at a close enough distance that each character can be well resolved and thus readable by the machine. However, taking a good picture of a document is difficult without sight, and thus without the ability to look at the scene being imaged by the camera through the smartphone's screen. Anecdotal evidence, supported by results of preliminary studies conducted by the principal investigator's group, confirms that acquisition of an OCR-readable image of a document can indeed by very challenging for some blind users. We plan to address this problem by developing and testing a new technique of assisted mobile OCR. As the user aims the camera at the document, the system analyzes in real time the stream of images acquired by the camera, and determines how the camera position and orientation should be adjusted so that an OCR-readable image of the document can be acquired. This information is conveyed to the user via a specially designed acoustic signal. This acoustic feedback allows users to quickly adjust and reorient the camera or the document, resulting in reduced access time and in more satisfactory user experience. Multiple user studies with blind participants are planned with the purpose of selecting an appropriate acoustic interface and of evaluating the effectiveness of the proposed assisted mobile OCR modality. PUBLIC HEALTH RELEVANCE: This application is concerned with the development of new technology designed to facilitate use of mobile Optical Character Recognition (OCR) systems to access printed text without sight. Specifically, this exploratory research will develop and test a novel system that, by means of a specially designed acoustic interface, will help a blind person take a well-framed, well-resolved image of a document for OCR processing using a smartphone or wearable camera. If successful, this novel approach to assisted mobile OCR will reduce access time and improve user experience of blind mobile OCR users.",Enabling access to printed text for blind people via assisted mobile OCR,8989105,R21EY025077,"['Acoustics', 'Address', 'Algorithms', 'Augmented Reality', 'Businesses', 'Cellular Phone', 'Chest', 'Chickens', 'Clothing', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Education', 'Effectiveness', 'Employment', 'Environment', 'Eyeglasses', 'Feedback', 'Goals', 'Hand', 'Health', 'Hearing', 'Image', 'Knowledge', 'Life', 'Light', 'Location', 'Marketing', 'Modality', 'Monitor', 'Participant', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Printing', 'Process', 'Quality of life', 'Reading', 'Report (document)', 'Research', 'Resolution', 'Restaurants', 'Scanning', 'Series', 'Signal Transduction', 'Speech', 'Stream', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Development Study', 'Testing', 'Text', 'Time', 'Translating', 'Travel', 'Vision', 'Visual', 'Visually Impaired Persons', 'blind', 'design', 'egg', 'experience', 'handicapping condition', 'improved', 'new technology', 'novel', 'novel strategies', 'object recognition', 'optical character recognition', 'research study', 'technology development', 'usability', 'way finding']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2016,230563,0.0006227908275042461
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9177620,R01NS095251,"['Accounting', 'Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Investments', 'Learning', 'Left', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Records Controls', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'relating to nervous system', 'research study', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2016,891206,0.0008201762125645231
"Multi-scale network dynamics of human upper limb movements: characterization and DESCRIPTION (provided by applicant):  The overall project goals are to study the cortical network dynamics of human upper limb motor control spanning two distinct spatial scales recorded with electrocorticography (ECoG), and to demonstrate that these dynamics can be estimated in real-time and used to control the JHU Applied Physics Lab Modular Prosthetic Limb (MPL) during execution of functionally useful complex action sequences.  Our human subjects will be instructed to perform complete functional movements characteristic of activities of daily living.  We will analyze the task-related temporal evolution in the strength and pattern o interactions among large-scale cortical networks known to be recruited in visually-guided reach-to-grasp tasks.  Using multi-scale subdural ECoG with combinations of routine clinical macro-electrodes (2.3 mm diameter, 1 cm spacing) recording activity of broadly spread elements/nodes of neural networks, and inset arrays of microelectrodes (75 �m diameter, 0.9 mm spacing) recording the activity of local sub-networks, we will test our overall hypothesis that there is a functional hierarchy between the two scales (Aim 1).  More specifically, we hypothesize that large-scale network dynamics involving premotor/motor cortex reflect the evolution of sensory-motor processing demands during complex action sequences, while micro-scale population activity and network dynamics in motor cortex reflect the low-level kinematics of these tasks.  We will utilize methods of estimating dynamic effective connectivity developed by our team to study interactions between these scales and test whether there exists a spatially heterogeneous and hierarchical structure within the macro-micro scale networks.  The results of these analyses have wide-ranging clinical implications for both the optimal scale of functional mapping for clinical diagnostic purposes and the extent of implantations for neuroprosthetic control.  We will exploit multi-scale ECoG recordings and online estimates of the dynamics of neural activation and large-scale/local network interactions to achieve control of the MPL during functionally useful tasks (Aim 2).  This approach will go beyond traditional paradigms that have developed neural control over individual degrees of freedom.  We will do this by embedding low-level control within an innovative framework whereby knowledge of task goals supplement direct kinematic decoding.  This project will build on our team's previous successes in implementing a system for semi-autonomous ECoG control of the MPL, employing machine vision and route-planning algorithms, during complex interactions with objects requiring the coordination of multiple joints.  This system will be able to leverage for the first time the rich complexity of temporally and spatially resolved network dynamics correlated with high-level goals to achieve functionally useful control of an advanced neuroprosthetic limb. PUBLIC HEALTH RELEVANCE:  For ""Multi-scale network dynamics of human upper limb movements:  characterization and translation in neuroprosthetics"" This project will use recordings from the surface of the human brain to study how brain networks control arm and hand movements.  We will also test whether information about these networks can be used to control an advanced robotic prosthetic arm.  This could have a profound long-term impact on future generations of patients seeking to restore lost upper limb function with a lifelike prosthesis.",Multi-scale network dynamics of human upper limb movements: characterization and,9096272,R01NS088606,"['Activities of Daily Living', 'Algorithms', 'Area', 'Artificial Arm', 'Attention', 'Biological Neural Networks', 'Brain', 'Caliber', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complex', 'Computer Vision Systems', 'Cues', 'Diagnostic', 'Eating', 'Electrocorticogram', 'Electrodes', 'Elements', 'Epilepsy', 'Evolution', 'Freedom', 'Future Generations', 'Goals', 'Hand', 'Health', 'Human', 'Individual', 'Joints', 'Knowledge', 'Limb Prosthesis', 'Limb structure', 'Location', 'Maps', 'Measures', 'Mediating', 'Methods', 'Microelectrodes', 'Modeling', 'Modification', 'Motor', 'Motor Cortex', 'Movement', 'Neurosciences', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Performance', 'Physics', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Process', 'Prosthesis', 'Recruitment Activity', 'Resolution', 'Robotics', 'Route', 'Sampling', 'Sensory', 'Signal Transduction', 'Site', 'Staging', 'Structure', 'Surface', 'System', 'Testing', 'Time', 'Training', 'Translations', 'Upper Extremity', 'Upper limb movement', 'Vision', 'arm', 'drinking', 'grasp', 'human subject', 'implantation', 'innovation', 'joint mobilization', 'kinematics', 'motor control', 'neuroprosthesis', 'neuroregulation', 'relating to nervous system', 'success', 'temporal measurement', 'time use']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2016,354375,0.015124937798913225
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning. PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,8914675,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Behavior', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Glass', 'Hand', 'Head', 'Head Movements', 'Health', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Research', 'Robot', 'Robotics', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2015,136355,0.01455418001975286
"The neural workings of self-initiated and quasi-automatic movements ﻿    DESCRIPTION (provided by applicant): Uncovering the principles behind the generation of voluntary movements is a necessary first step in the development of technologies and treatments aimed at restoring motor abilities lost to neurological disease or trauma. The aim of this project is to shed light on the neural mechanisms of voluntary movement initiation. An essential component of voluntary movement is the choice of when to act. Under normal circumstances this decision can be time consuming usually taking up to a few hundreds of milliseconds, longer that the known delays in the nervous system. The area of the brain most associated with generating movements, the motor cortex, becomes very active just before and during the movement, however what exactly is happening during this time is still not well understood. Indeed, while much is known about the neural basis of generating movements, several open questions remain: does a movement generated deliberately with no time pressure, like a reach made to grab an object from a table, share the same neural underpinnings with a very fast reach to catch a falling object? Will the motor cortex be just as active before a quasi-automatic reach when time is of the essence? Or is pre-movement activity only present when there is enough time to deliberately plan the movement? During movement itself, is motor cortex involved in generating quasi-automatic reaches or is there is some reflex mechanism that bypasses motor cortex to generate urgent reaches? To begin answering these questions we have trained two monkeys to initiate a reach under three very different circumstances: sometimes monkeys move at a time of their own choosing with no imposed time constraints, other times monkeys must intercept a rapidly moving target on a screen, which elicits very short-latency reaches. In yet another set of trials monkeys must withhold a reach until given a go cue. The first aim of this project is to determine if these three movements (self-initiated, quasi-automatic and cue-initiated) share a common neural mechanism that does not depend on how the movement is initiated. To do this we will record the responses from a number of neurons in two key regions of the motor cortex: the primary motor and dorsal premotor cortex. In order to understand and interpret these responses, we will employ cutting edge machine learning techniques that will allow us to visualize and quantify the how neural activity evolves in time. Being able to visualize the evolution of neural activity is a key component in understanding the principles that govern how the neural activity translates to movement. The second aim of this project is to elucidate the role that higher cortical areas play in the generation of voluntar movements. We will record neural activity from areas upstream of motor cortex (supplementary motor area), which is heavily interconnected with the motor cortex and is suspected to play crucial a role in determining when a movement should be initiated. We will test record neural activity from this area and characterize its properties using the same cutting edge techniques developed in the first part of this project.         PUBLIC HEALTH RELEVANCE: Uncovering the principles behind the generation of voluntary movements is a necessary first step in the development of technologies and treatments aimed at restoring motor abilities lost to neurological disease or trauma. Arguably, one of the fundamental features of voluntary movement is that one chooses when to move. The main goal of the proposed project is to shed light on the neural mechanisms responsible for voluntary movement initiation.                ",The neural workings of self-initiated and quasi-automatic movements,9051023,F32NS092350,"['Area', 'Behavioral', 'Brain', 'Bypass', 'Cues', 'Data', 'Dependence', 'Dorsal', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Goals', 'Intercept', 'Life', 'Light', 'Link', 'Machine Learning', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Nervous system structure', 'Neurons', 'Pattern', 'Play', 'Population', 'Population Dynamics', 'Preparation', 'Process', 'Property', 'Property Rights', 'Reflex action', 'Role', 'Signal Transduction', 'Source', 'Staging', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'base', 'falls', 'grasp', 'millisecond', 'motor control', 'nervous system disorder', 'neuromechanism', 'pressure', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2015,57962,0.010863523915348925
"Wrist/Grasp Muscle Activity Patterns for EMG-neural Interface Prosthesis Control DESCRIPTION (provided by applicant):    Simultaneous wrist/hand control (where a person simultaneously moves his/her wrist while grasping or  releasing), is essential in activities of daiy living, but cannot be performed by amputees using clinical surface  electromyography (sEMG) based neural interfaces (myoelectric control). Transradial amputees, who make up 40% of major amputations (proximal to the wrist), cite simultaneous control as a necessary element to improve upper-limb prostheses. Our long-term goal is to develop a clinically viable EMG-based neural interface for transradial amputees that is suitable for restoring simultaneous control of prosthetic wrist/hand movements.   One proposed method for intuitive simultaneous wrist/hand prosthesis control uses intramuscular EMG  (imEMG) amplitude estimates from multiple agonist/ antagonist forearm muscle pairs to control physiologically  appropriate degrees of freedom DOFs (e.g. flexor digitorum profundus / extensor digitorum control  grasp/release). Known as 'direct control', this approach does not require burdensome levels of machine  learning algorithm training, as is required for experimental sEMG-based simultaneous control methods.  However, this method assumes independently modulated muscle activation patterns for each DOF - that the activation patterns of muscles controlling a DOF (i.e. finger flexors/extensors for grasp/release) do not change when a second DOF is simultaneously attempted (simultaneous pronation/supination and grasp/release). The biologic foundation of such an assumption has not been explored to date. Little is known of how the central nervous system (CNS) coordinates wrist and extrinsic hand muscle activation when independent of biomechanical effects and joint position feedback. Muscle activation patterns under such conditions are particularly relevant to amputee populations, who lack distal joints. Therefore, the objective of this research is to better understand how the CNS coordinates muscle activation patterns in healthy individuals to produce simultaneous wrist/grasp torques when independent of the biomechanical effects of joint movement. We will then apply this information to develop an imEMG simultaneous myoelectric prosthesis controller.  imEMG patterns will be measured as healthy subjects produce single-DOF and simultaneous multi-DOF (SMD) wrist and/or grasp/release torques in isometric, neutral posture conditions. Multivariate models predicting imEMG activity from measured wrist/grasp torques will be developed and will suggest which DOFs have independently modulated muscle activation patterns. This information will then allow for the development of a 'biologically-inspired' simultaneous controller. DOFs with independently modulated muscle activation patterns will be controlled using direct control, while experimental pattern recognition algorithms currently used for sEMG-based simultaneous control will be used for all other DOFs. We will evaluate the performance of this hybrid controller in healthy subjects both offline and using online functional tests in a virtual environment. PUBLIC HEALTH RELEVANCE:    Various current prosthetic arms use the electrical signals produced when muscles contract to control prosthesis movement, but cannot provide simultaneous control of both the wrist and the hand. This study will investigate how the nervous system activates muscles to simultaneously control the wrist and hand in healthy individuals. This information can then be used to provide clinically viable methods of controlling simultaneous wrist and hand movements of prostheses to amputees.",Wrist/Grasp Muscle Activity Patterns for EMG-neural Interface Prosthesis Control,8806616,F31NS083166,"['Activities of Daily Living', 'Agonist', 'Algorithms', 'Amputation', 'Amputees', 'Anatomy', 'Artificial Arm', 'Biological', 'Biomechanics', 'Clinical', 'Contracts', 'Data', 'Development', 'Distal', 'Educational Status', 'Electromyography', 'Elements', 'Environment', 'Feedback', 'Fingers', 'Flexor', 'Forearm', 'Foundations', 'Freedom', 'Goals', 'Hand', 'Health', 'Human', 'Hybrids', 'Individual', 'Intramuscular', 'Isometric Exercise', 'Joints', 'Knowledge', 'Life', 'Limb Prosthesis', 'Literature', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Movement', 'Muscle', 'Muscle Contraction', 'Myoelectric prosthesis', 'Nervous system structure', 'Neuraxis', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Persons', 'Population', 'Positioning Attribute', 'Posture', 'Pronation', 'Prosthesis', 'Rehabilitation therapy', 'Research', 'Signal Transduction', 'Supination', 'Surface', 'Testing', 'Torque', 'Training', 'Upper Extremity', 'Work', 'Wrist', 'arm', 'base', 'design', 'extensor digitorum', 'grasp', 'improved', 'joint mobilization', 'myoelectric control', 'prosthesis control', 'prosthetic hand', 'relating to nervous system', 'residual limb', 'success', 'virtual']",NINDS,NORTHWESTERN UNIVERSITY,F31,2015,6800,0.024019632288791698
"In-home monitoring system for assessing gait using wall-mounted RF transceivers ﻿    DESCRIPTION (provided by applicant): The goal of this project is to develop and evaluate a new system called GaitRF that can measure walking speed and other detailed gait parameters passively within the home. The ability to move is a critical function that underlies the quality of life for elders as well as those suffering from neurologic or physical ailments. Changes in aspects of gait such as walking speed, stride length, stride imbalance, etc. have been shown to correlate with changes in physical and cognitive health. Gait is typically measured periodically within a clinical setting. In-home monitoring offers the advantage of continuous and ongoing measurements providing significantly more information about changes in a patient's health under real life conditions. Ongoing accurate estimation of gait within the home can help to guide caregivers about the need for transitioning older adults to higher levels of care. Accurate in-home gait monitoring also has the potential to encourage older adults to maintain independence later into their lives by enabling family members and friends to monitor health status remotely.  The proposed system makes use of novel wireless technology being developed at EmbedRF. An array of tiny transceivers are positioned in either a hallway or doorframe and configured to wirelessly send radio frequency (RF) signals between each other. As a person walks past the transceivers, their body disrupts the RF signal strength allowing for the estimation of gait metric without the need for the person to wear any monitoring device. Preliminary results using only 2 or 4 transceivers have already demonstrated the ability to accurately estimate walking speed. Preliminary results also show the unique ability to discriminate between individuals for use in a multi-resident home or to exclude data when a caregiver or friend visits. Specific aims in this proposal will 1) further develop prototype systems for walking speed estimation using transceiver pairs, 2) research and develop use of an array of sensors placed at base-board height in order to extract more detailed gait metrics; a second transceiver pair will be placed at approximate head height to provide multi-person discrimination capability, and 3) perform preliminary in-home evaluations of the GaitRF system. Advanced machine learning and tracking algorithms will be utilized to process the RF signals to extract gait metrics. We will evaluate the performance of GaitRF in both a laboratory setting and within single-resident and multi- resident homes of seniors.  If successful, this new system has the advantage of being low-cost, unobtrusive, and easy to install, while still providing accurate and detailed gait metrics. The system can be used as a stand-alone gait monitor or incorporated into more general health monitoring systems. Application of the technology will support independent living and may also be used in clinical trials of drugs or procedures that affect mobility.         PUBLIC HEALTH RELEVANCE: The ability to move is a critical function that underlies the quality of life for elders as well as individuals suffering from cognitive or physical impairment. Changes in aspects of gait such as walking speed, stride length, stride imbalance, etc. have been shown to correlate with changes in physical and cognitive health. We propose to develop a low cost system called GaitRF that can passively and unobtrusively measure detailed gait metrics in the home to support monitoring of seniors living independently or at an assisted living facility.            ",In-home monitoring system for assessing gait using wall-mounted RF transceivers,8904402,R43AG049573,"['Address', 'Affect', 'Age', 'Algorithms', 'Assisted Living Facilities', 'Caregivers', 'Caring', 'Clinic', 'Clinical', 'Clinical Trials', 'Cognitive', 'Couples', 'Data', 'Development', 'Discrimination', 'Elderly', 'Engineering', 'Evaluation', 'Family member', 'Feasibility Studies', 'Friends', 'Gait', 'Goals', 'Head', 'Health', 'Health Status', 'Height', 'Home environment', 'Homes for the Aged', 'Impairment', 'Independent Living', 'Individual', 'Laboratories', 'Leg', 'Length', 'Life', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Movement', 'Neurologic', 'Patients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Procedures', 'Process', 'Protocols documentation', 'Quality of life', 'Recruitment Activity', 'Research', 'Shapes', 'Signal Transduction', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Validation', 'Visit', 'Walking', 'Width', 'Wireless Technology', 'Work', 'base', 'cohort', 'cost', 'design', 'improved', 'monitoring device', 'novel', 'particle', 'physical conditioning', 'prototype', 'public health relevance', 'radio frequency', 'sensor', 'signal processing']",NIA,"EMBEDRF, LLC",R43,2015,225000,-0.018263672962827982
"Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI DESCRIPTION (provided by applicant):  In the first 5-year period of our BRP we had two major objectives:  1) to determine whether we could improve motor function of the lower limbs by neuromodulating the spinal lumbosacral circuitry with epidural stimulation and 2) to begin to develop and improve the technologies associated with electrode arrays and chronic implantable stimulation devices to maximize the neuromodulatory potential.  These new technologies have the potential to fine tune the epidural stimulation parameters, to help in understanding some of the underlying mechanisms of epidural stimulation., to examine synergistic effects of epidural stimulation, pharmacological modulation, and examine activity-dependent interventions that might affect the level of recovery of motor function after complete paralysis.  We have demonstrated that an adult rat with a complete, mid-thoracic spinal cord transection can regain full weight-bearing stepping over a range of speeds, loads, and even directions when the spinal cord is stimulated tonically to increase the excitability of the lumbosacral locomotor circuitry.  Furthermore, we learned that load-bearing sensory information can serve as the controller of these complex motor tasks and that the performance of these tasks can be improved even further with combinations of epidural stimulation, pharmacological, and motor training interventions.  We have shown that four humans with a motor complete spinal injury have regained independent standing, assisted stepping, and even a significant level of voluntary control of the lower limbs in the presence of epidural stimulation, with one subject now even having some volitional control without stimulation.  Improvement in bladder control, blood pressure, temperature regulation, and even sexual function has been realized.  Thus, our present challenge is to develop the capability to selectively activate combinations of neural networks that can enable standing, and probably stepping, by improving the technologies needed to make this intervention available in the clinic and in the home of individuals with complete motor paralysis using a chronic epidural electrode implant.  Specifically, we will further improve the electrode array stimulation technology needed for fine-tune control in rats and humans and transform the present hardwired technology for rats to a wireless capability to stimulate and record evoked potentials along the brain-spinal cord-muscle axis in the rat.  To advance the clinical potential, we will continue to develop, refine and validate our machine-learning strategies which automatically optimize stimulation parameters for standing, stepping, and voluntary control.  We will develop an improved interface between the devices implanted in our present subjects and the control devices for defining the specific stimulation parameters needed for a given subject to perform a motor task in the clinic or at home. PUBLIC HEALTH RELEVANCE:  We now have demonstrated that the human lumbosacral spinal cord can be neuromodulated with epidural stimulation to enable recovery of standing and volitional control of the lower limbs and return of some autonomic function after complete motor paralysis.  Therefore, our objectives are now to develop the technologies needed to more fully capitalize on this clinical potential and develop home-use technologies to do so.",Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI,8932000,U01EB007615,"['Adult', 'Affect', 'Algorithms', 'Animals', 'Behavior', 'Binding', 'Biological Neural Networks', 'Bladder Control', 'Blood Pressure', 'Brain', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Complex', 'Contusions', 'Data', 'Devices', 'Dorsal', 'Educational Intervention', 'Electrodes', 'Evaluation', 'Evoked Potentials', 'Experimental Designs', 'Frequencies', 'Health', 'Home environment', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Internet', 'Intervention', 'Intramuscular', 'Learning', 'Locomotor training', 'Lower Extremity', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Muscle', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Procedures', 'Process', 'Rattus', 'Recovery', 'Regulation', 'Research', 'Robotics', 'Sensory', 'Sex Functioning', 'Signal Transduction', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord transection injury', 'Spinal Injuries', 'Spinal cord injury', 'Stimulus', 'System', 'Task Performances', 'Technology', 'Temperature', 'Testing', 'Thoracic spinal cord structure', 'Training', 'Weight-Bearing state', 'Wireless Technology', 'base', 'density', 'design', 'implantable device', 'improved', 'in vivo', 'motor control', 'motor function improvement', 'motor function recovery', 'neuroregulation', 'new technology', 'next generation', 'novel', 'somatosensory', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2015,1085849,0.04173526953974432
"Enabling forelimb function with agonist drug and epidural stimulation in SCI DESCRIPTION (provided by applicant):  We have demonstrated that the physiological state of the lumbosacral spinal circuitry of spinal rats and cats can be modulated with spinal cord epidural stimulation (EDS) and/or administration of pharmacological agents to generate weight-bearing standing and stepping over a range of speeds, loads, and directions.  We have translated some of these results to humans by implanting 3 motor complete spinal cord injured (SCI) subjects about three years post-injury with an epidural electrode array over the lumbosacral spinal cord.  In less than one month post-electrode implant, the subjects could stand independently, and after up to 7 months of daily EDS and motor training, voluntary control of both legs was evident in the presence of EDS, whereas complete paralysis remained in absence of EDS.  We propose to employ a similar stimulation strategy for the recovery of upper limb function.  We will include extensive testing of spinal rats to guide our strategy to test for upper extremity improvement in human SCI subjects.  We will use off-the-shelf FDA approved pharmacological and stimulation modalities to:  1) Determine the optimal stimulation parameters, i.e., electrode placement and stimulation intensity, frequency and duration, for facilitating forelimb fine motor function in rats with a cervical SCI.  Using existing FDA-approved epidural electrodes, we will demonstrate in patients with a cervical SCI that cervical EDS can facilitate arm-hand function.  2) Identify an effective mode of administration, define the dose- response pharmacokinetics, and determine the effectiveness of a monoaminergic agonist to facilitate upper limb function after a cervical SCI.  We will assess the effectiveness of existing FDA-approved pharmacological agents (i.e., buspirone and as an alternative, bromocriptine), and determine their effectiveness in improving forelimb control in subjects with a cervical SCI.  3) Define the dose-response properties of monoaminergic agonists when combined with EDS in facilitating forelimb function in rats after a cervical SCI.  We will demonstrate the efficacy of ES in combination with a pharmacological intervention in facilitating arm and hand function in humans after a cervical SCI.  4) Determine whether motor training of spinal rats will further enhance the recovery of motor function when combined with pharmacological and/or EDS interventions.  5) Develop a protocol for machine learning to enable rapid selection of the optimal pharmacological and EDS parameters for motor recovery in rats and in human subjects.  If successful, this could represent the beginning of a paradigm shift in the use of minimally invasive strategies combined with rehabilitative approaches to realize significant improvement in upper limb function after paralysis. PUBLIC HEALTH RELEVANCE:  It now seems possible to apply three interventions (epidural stimulation, administration of pharmacological agents, and motor training) to control the excitability of localized neural circuits in humans with a cervical spinal cord injury (SCI), thus enabling these individuals to regain use of their arms and hands.  This enabling effect is similar to that observed with improved postural and locomotor function after a mid-thoracic SCI.  We will reach critical milestones that will provide the basis for a series of clinical trials for furter defining the efficacy of these interventions.",Enabling forelimb function with agonist drug and epidural stimulation in SCI,8889256,U01EB015521,"['Agonist', 'Algorithms', 'Ankle', 'Bromocriptine', 'Buspirone', 'Cervical', 'Cervical spinal cord injury', 'Cervical spinal cord structure', 'Chronic', 'Clinical Trials', 'Complement', 'Devices', 'Dose', 'Drug Kinetics', 'Effectiveness', 'Electrodes', 'FDA approved', 'Felis catus', 'Food', 'Forelimb', 'Frequencies', 'Goals', 'Hand', 'Hand functions', 'Health', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Knee', 'Leg', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Methodology', 'Modality', 'Motor', 'Motor Skills', 'Oral', 'Paralysed', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Preparation', 'Property', 'Protocols documentation', 'Rattus', 'Recovery', 'Rehabilitation therapy', 'Retrieval', 'Series', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Testing', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Translating', 'Treatment Efficacy', 'Upper Extremity', 'Weight-Bearing state', 'arm', 'arm function', 'base', 'design', 'human subject', 'improved', 'minimally invasive', 'motor function recovery', 'motor recovery', 'neural circuit', 'neuroregulation', 'response']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2015,828196,0.020734129653831194
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering. PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8920573,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Health', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'rehabilitation engineering', 'robot rehabilitation', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2015,3412,0.013829362954416528
"NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired PROJECT SUMMARY (See instructions): The objective of the proposed research is to develop new technology for a Wearable Robotic Object Manipulation Aid (W-ROMA) for the visually impaired. The W-ROMA is a hand-worn assistive device that provides assistance to a visually impaired individual in effectively grasping an object. Thanks to the onboard computer vision methods, the W-ROMA is capable of detecting a target object, determining the hand-object misalignment, and conveying to the wearer, via natural human-device interfaces, the desired hand motion for hand-object alignment. The W-ROMA will contribute to the independent lives of the visually impaired in twofold: First, it helps the visually impaired with independent travel by enabling them to identify a movable obstacle and manipulate the obstacle to make a passage. Second, it assists the visually impaired in effectively grasping an object for non-navigational purpose. The PIs will involve graduate, undergraduate and high school students in the project and use the proposed project activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision and human-robot interaction methods that support accurate and effective object grasping for the visually impaired for their independent daily lives. These methods include: (1) a new real-time object recognition method; (2) an innovative hand-object alignment mechanism; (3) a novel hybrid tactile display system for object shape rendering; and (4) a computationally efficient device localization method. The proposed solutions can be encapsulated in a hand-worn robotic device. The W-ROMA will provide new co-robotic functions for the visually impaired. The PIs have performed proof of concept studies for the computer vision and tactile display methods and the results are promising. The broader impacts include: (1) the research will positively impact the large visually impaired community; (2) the proposed methods can be applied to other small robotic systems that have a wide range of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the PI's university and train graduate and undergraduate students for their future careers in science and engineering. RELEVANCE (See instructions): The project addresses a growing public health care issue--visual impairment. The research fits well into the NEI's Low Vision and Blindness Rehabilitation program that supports development of new technologies for minimizing the impact of visual impairment. The project addresses the NEI's mission by developing new assistive technology that will help the visually impaired to maintain a higher quality of life.",NRI: A Wearable Robotic Object Manipulation Aid for the Visually Impaired,9050942,R01EY026275,"['Address', 'Blindness', 'Canes', 'Code', 'Communities', 'Companions', 'Computer Vision Systems', 'Data', 'Detection', 'Development', 'Devices', 'Encapsulated', 'Engineering', 'Environment', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'Hand', 'Healthcare', 'High School Student', 'Human', 'Hybrids', 'Image', 'Independent Living', 'Individual', 'Instruction', 'Law Enforcement', 'Maps', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'Motion', 'Movement', 'National Institute of Biomedical Imaging and Bioengineering', 'Performance', 'Persons', 'Polymers', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Rotation', 'Scheme', 'Science', 'Self-Help Devices', 'Solid', 'Solutions', 'Speech', 'Speed', 'Students', 'System', 'Tactile', 'Testing', 'Thumb structure', 'Time', 'Training', 'Translations', 'Travel', 'United States National Institutes of Health', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'base', 'blind', 'career', 'design', 'experience', 'graduate student', 'grasp', 'improved', 'innovation', 'new technology', 'novel', 'object recognition', 'object shape', 'programs', 'research study', 'robotic device', 'tactile display', 'undergraduate student']",NEI,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2015,280721,-0.033824213201892134
"Providing Access to Appliance Displays for Visually Impaired Users DESCRIPTION (provided by applicant):  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays.  This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment.  No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents.  Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image.  For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast.  These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view.  Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users.  Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures.  The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.",Providing Access to Appliance Displays for Visually Impaired Users,8916115,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Health', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'contrast enhanced', 'contrast imaging', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2015,368560,0.018883558992268814
"Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings ﻿    DESCRIPTION (provided by applicant): ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the cost  of  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resoure  settings.  We propose to advance our previously developed low-cost, handheld device capable of automatically measuring the optical properties of the eye based on the technique of wavefront aberrometry.  The  proposed  work  will  specifically  focus  on  the development of optical and software systems will extend the device's measurement  range  to  work  on  a  larger  range  of  refractive  errors.  First,  optical  systems  with  no  moving  parts  will  be  developed  which  enable  the  device  to  work  on  subjects  with  severe  myopia  or  hyperopia  (<-­-6  diopters or  >6  diopters  of  refractive  error).  Second,  algorithms  that  make  the  device  easy  and  intuitive  to  use  will  be  implemented.  Third,  a  handheld  prototype  incorporating  these  improvements  will  be  constructed  and  validated  in  model  eye  systems.  The  output  of  this  project  will  be  a  functional,  extended-range  prototype  that  will  facilitate  the  fild-testing  and  commercialization  of  a  low-cost,  easy-to-use  device  to  dispense  eyeglass  prescriptions.                 PUBLIC HEALTH RELEVANCE: ""Development of a low-cost, extended-range, autorefractor""    This  project  proposal  seeks  to  develop  technologies  that  will  lower  the  cost  and  increase  the  accessibility  of  refractive  eye  care,  especially  in  low-resource  settings.  Specifically,  optical  and  software  systems  will  be  developed  that  will  extend  the  measurement  range  of  a  low-cost  device  that  automatically  prescribes  eyeglasses  for patients with a large range of refractive errors.             ","Development of a low-cost, portable autorefractor for the measuring of refractive errors in low-resource settings",8981552,R43EY025452,"['Adoption', 'Algorithms', 'Brazil', 'Caring', 'China', 'Client satisfaction', 'Clinical Trials', 'Communities', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Ensure', 'Eye', 'Eyeglasses', 'Feedback', 'Goals', 'Health', 'Hospitals', 'Human', 'Human Resources', 'Hyperopia', 'Image', 'India', 'Laser In Situ Keratomileusis', 'Letters', 'Licensing', 'Lighting', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Myopia', 'New England', 'Nurses', 'Operative Surgical Procedures', 'Optics', 'Optometrist', 'Optometry', 'Output', 'Patients', 'Performance', 'Pharmacists', 'Phase', 'Population', 'Positioning Attribute', 'Productivity', 'Property', 'Protocols documentation', 'Provider', 'Pupil', 'Quality of life', 'Refractive Errors', 'Resources', 'Rest', 'Retina', 'Source', 'Spottings', 'System', 'Target Populations', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Vision', 'Visual Acuity', 'Work', 'base', 'college', 'commercialization', 'cost', 'design', 'digital', 'disability', 'improved', 'lens', 'meetings', 'prototype', 'software systems', 'success', 'usability']",NEI,"PLENOPTIKA, INC.",R43,2015,149265,-0.0028882514814155126
"Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition ﻿    DESCRIPTION (provided by applicant): Non-invasive medical devices are fast emerging as powerful tools in providing quantitative, simple to parse data in assessing the health and wellness of users. These devices can provide information feedback to users on their state of health, and can potentially provide valuable real-time insight to doctors on the links between user consumption and activity on their respective health. Recently described epidermal electronics / multifunctional tattoos introduced from our lab and others have demonstrated sensing of biopressure, bioelectricity, analyte concentration, bacteria, and more. These structures potentially represent the evolution of wearable devices as they possess a negligible form factor and conform to any surface (such as skin or teeth), minimizing user impact. These devices also bypass more traditional, ""wearable"" gadgets that often require bulky mechanical fixtures or straps, require complex microfluidic systems or integrated electronics, cannot provide dynamic readout, and cannot be disposed of easily. Dielectric sensors are a class of structures that are able to probe the composition of a biofluid via their impedance spectrum, and can be configured for remote sensing via radio waves. These devices can be composed of isolated, thin film circuits, and are directly amenable to epidermal or tattoo formats. This measurement methodology is inherently tremendously powerful, as it can potentially measure multiple analytes at once by probing multiple resonance peaks, and can potentially be piggybacked onto existing RFID infrastructure for data readout. However, these capabilities have not yet been demonstrated, and under real-world applications dielectric sensors have often proven difficult to use. This is often due to simplistic readout (devices will directly correlate a single metric such s the real value of the impedance at a frequency to a biomarker) and are thus can be sensitive from user to user or to environmental conditions. Herein, the applicant will leverage the expertise and knowledge of the labs of Dr. Omenetto and colleagues to bring practical usability to these dielectric antennas, bridging the gap between laboratory measurement and real-time, and real-world health monitoring applications. The end-goal is to generate disposable, skin and teeth-mounted, dielectric sensors to remotely probe the presence of biomarkers in sweat, saliva, and potentially blood to draw definitive links between user nutrition and their health.         PUBLIC HEALTH RELEVANCE: This proposal seeks to create non-invasive, wireless sensor tattoos to be tagged onto the human body for probing the composition of saliva, sweat, or blood. These wireless sensors would present negligible impediment to the user, and would require next to no upkeep to maintain, potentially facilitating an unprecedented level of subject data collection and dissemination. Such data could yield conclusive links between diet, activity, biomarkers, and public health.            ","Development of epidermal, wireless sensor tattoos for non-invasive monitoring of biofluid composition",8980210,F32EB021159,"['Architecture', 'Bacteria', 'Behavior', 'Biocompatible Materials', 'Biological', 'Biological Markers', 'Blood', 'Bypass', 'Cells', 'Characteristics', 'Classification', 'Complex', 'Consumption', 'Data', 'Data Analyses', 'Data Collection', 'Detection', 'Development', 'Devices', 'Diet', 'Electronics', 'Evolution', 'Feedback', 'Film', 'Fingerprint', 'Frequencies', 'Goals', 'Health', 'Human body', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Medical Device', 'Methodology', 'Microfluidics', 'Monitor', 'Nafion', 'Pattern', 'Performance', 'Principal Component Analysis', 'Public Health', 'Radio', 'Radio Waves', 'Reader', 'Research Infrastructure', 'Running', 'Saliva', 'Silk', 'Skin', 'Sodium', 'Solutions', 'Stimulus', 'Structure', 'Surface', 'Sweat', 'Sweating', 'System', 'Tattooing', 'Testing', 'Time', 'Tooth structure', 'Training', 'Urea', 'Validation', 'Wireless Technology', 'World Health', 'bioelectricity', 'design', 'electric impedance', 'enzyme activity', 'flexibility', 'glucose monitor', 'improved', 'insight', 'non-invasive monitor', 'nutrition', 'public health relevance', 'real world application', 'remote sensing', 'response', 'saliva composition', 'sensor', 'tool', 'usability']",NIBIB,TUFTS UNIVERSITY MEDFORD,F32,2015,56042,0.03838441638563263
"Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography ﻿    DESCRIPTION (provided by applicant):  We propose a tonometry based solution to the problem of inexpensive, unencumbering and non- invasive measurement of blood pressure. The proposed solution will be useful in clinical as well as ambulatory blood pressure measurements. Specifically, we propose to develop a large (1cm x 5cm) two-dimensional array of pressure sensors with 0.2mm spacing (24x128 pressure-sensing elements), together with robust signal processing algorithms with a feedback controlled band-tightening mechanism in order to measure blood pressure at the wrist. The pressure sensor array together with a photoplethysmogram (PPG) sensor will be embedded in a band, and will provide signals through a multiplexed circuit designed. Signal conditioning techniques will be used to get the large amount of data in the form that can be efficiently processed on a microcontroller. The proposed two-dimensional array of pressure sensors will be built using flexible plastic and micro-fabrication techniques. The increased size of the sensor array will ensure proper contact and pressure application with arteries in the wrist for tonometric measurement of BP. The signals generated from the sensor array will be processed through advanced signal processing and optimization techniques to handle the huge amount of data and to mitigate noise. The PPG signals will be used at the wrist to improve the efficiency and accuracy of the system. The sensor array system will be embodied in the form of a band, which will be integrated in a wearable device such as smartwatch. The capabilities of the smartwatch will be used for data processing and analytics. a) Design, develop, and test a two-dimensional pressure sensor array on a polyimide flexible substrate b) Process large amount of analog data from sensor array using signal conditioning and processing techniques  to generate blood pressure estimates c) Design a user friendly prototype form factor, and perform a clinical trial to validate device performance  The engineering members of our multidisciplinary team have specialized in cardiac instrumentation, signal and image processing for medical applications, pressure and touch sensors, signal processing and robust optimization. The team members with clinical expertise have been engaged in blood pressure trials in US, and have been working with leading institutions in India engaged in cardiovascular research. This proposal brings together their unique expertise and experience to innovatively address this challenging problem through a joint effort.         PUBLIC HEALTH RELEVANCE: Unmanaged hypertension is a major problem, and its management based on occasional measurement is known to be suboptimal. The ability to measure blood pressure using non- invasive techniques in an ambulatory setting has many significant benefits. We propose to research and develop a large (1cm x 5cm) two-dimensional array of pressure sensors based device together with robust signal processing algorithms with a feedback controlled to measure blood pressure at the wrist. The device will be test in a clinical trial based on the European Society of Hypertension International Protocol.                ",Unassisted Blood Pressure Monitoring Using Arterial Tonometry and Photoplethysmography,8936340,U01EB020589,"['Address', 'Algorithms', 'Area', 'Arteries', 'Blood Pressure', 'Blood Pressure Monitors', 'Cardiac', 'Cardiovascular system', 'Clinical', 'Clinical Engineering', 'Clinical Trials', 'Data', 'Devices', 'Elements', 'Engineering', 'Ensure', 'Environment', 'European', 'Fatigue', 'Feedback', 'Generations', 'Goals', 'Hypertension', 'India', 'Institution', 'International', 'Joints', 'Lead', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Noise', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Photoplethysmography', 'Plastics', 'Process', 'Protocols documentation', 'Research', 'Signal Transduction', 'Societies', 'Solutions', 'Somatotype', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Touch sensation', 'Training', 'Untrained Personnel', 'Work', 'Wrist', 'analog', 'arterial tonometry', 'base', 'computerized data processing', 'conditioning', 'design', 'experience', 'flexibility', 'image processing', 'improved', 'instrumentation', 'member', 'multidisciplinary', 'pressure', 'process optimization', 'prototype', 'public health relevance', 'rural area', 'sensor', 'signal processing', 'tonometry', 'two-dimensional', 'user-friendly']",NIBIB,NORTHWESTERN UNIVERSITY,U01,2015,362070,0.02683103379708547
"Low-Cost, Compact, and Portable Robot for Autonomous Intravenous Access using Nea DESCRIPTION (provided by applicant): Peripheral venous access is pivotal to a wide range of clinical interventions and is consequently the leading cause of medical injury in the U.S. Complications associated with the procedure are exacerbated in difficult settings, where the rate of success depends heavily on the patient's physiology and the practitioner's experience. My dissertation thesis pertains to the development of imaging and robotic technologies to improve the accuracy and speed of blood draws and IV's. The core technology is an image-guided robotic device that accurately and autonomously introduces a cannula for venous access. The device operates by mapping in real-time the 3D structure of peripheral veins in order to robotically direct a needle into a selected vein. A working prototype has been developed and validated in several studies, the results of which are described in two journal publications. The device combines a 3D near-infrared vein imager, a robot, and computer vision software; these three components form the basis of the three Specific Aims described in this proposal. The Aims fit into the overall dissertation by 1) incorporating the current imaging hardware into a standalone, handheld imaging device; 2) introducing software for the imaging device that assists in selecting suitable cannulation sites; and 3) integrating the imaging device and software with a miniaturized version of the current robot. The outcome of this work will be a compact and low-cost system that is suited for beta-stage development. PUBLIC HEALTH RELEVANCE: Blood draws and IV therapies are one of the most commonly performed medical routines in hospitals and clinics. Injuries to doctors and patients happen frequently because of how difficult it can be to find veins and accurately insert the needle. We are developing a portable and lightweight medical robot to perform the procedure in situations where the doctor is unable to successfully access the veins. This device may greatly improve the safety and accuracy of venous access, and has wide applications in many clinical areas.","Low-Cost, Compact, and Portable Robot for Autonomous Intravenous Access using Nea",8832591,F31EB018191,"['Algorithms', 'Anatomy', 'Area', 'Benchmarking', 'Blood', 'Cannulas', 'Cannulations', 'Catheters', 'Childhood', 'Clinical', 'Clinics and Hospitals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cues', 'Custom', 'Development', 'Device Safety', 'Devices', 'Emergency Care', 'Evaluation', 'Failure', 'Goals', 'Graph', 'Health', 'Healthcare Systems', 'Human', 'Image', 'Imaging Device', 'In Vitro', 'Injury', 'Institutional Review Boards', 'Intervention', 'Intravenous', 'Journals', 'Knowledge', 'Literature', 'Location', 'Maps', 'Medical', 'Motivation', 'Needles', 'Neonatal', 'Outcome', 'Patients', 'Peripheral', 'Physiology', 'Pilot Projects', 'Population', 'Population Sizes', 'Positioning Attribute', 'Procedures', 'Publications', 'Reporting', 'Robot', 'Robotics', 'Safety', 'Site', 'Speed', 'Sprague-Dawley Rats', 'Staging', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Veins', 'Venous', 'Visual', 'Weight', 'Work', 'arm', 'base', 'cost', 'design', 'experience', 'image guided', 'imaging software', 'imaging system', 'improved', 'in vivo', 'meetings', 'miniaturize', 'pre-clinical', 'prototype', 'robotic device', 'skeletal', 'success', 'three dimensional structure', 'three-dimensional modeling', 'tissue phantom', 'visual motor']",NIBIB,"RUTGERS, THE STATE UNIV OF N.J.",F31,2015,32250,0.034042694605892994
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002).         PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.                ",Clinic Interactions of a Brain-Computer Interface for Communication,8876473,R01DC009834,"['21 year old', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'P300 Event-Related Potentials', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'improved', 'innovation', 'intervention program', 'literacy', 'meetings', 'mindfulness meditation', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'research study', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2015,665012,-0.05213281438464142
"Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging ﻿    DESCRIPTION (provided by applicant): During medical imaging, patient motion is virtually unavoidable presenting a significant source of image degradation and artifacts, which in turn, can impact the quality of care received by many patients. One method used to address patient motion is to employ visual tracking systems (VTS), which involves placing a small number of reflective markers on the patient that can be located and tracked in 3D space using stereo cameras. The tracked markers can then be used as a surrogate to a structure of interest, such as the heart. The tracked surrogate provides a quantifiable measure that can be directly correlated with the motion of the target structure, which can then be used for prospective or retrospective motion correction. However, the markers add complexity to patient workflow, provide only a sparse sampling of the patient's surface, and the optimal number and placement of markers is unknown. This project addresses the shortcomings of marker-based VTS systems by proposing to develop and test a novel low-cost marker-less VTS system for tracking patient motion within a hybrid imaging system. The primary barrier for successfully tracking the patient's body surface using marker-less VTS is that clothing prevents an unobstructed view of the patient's body. The candidate, Dr. Lindsay, is proposing to incorporate a translational method using computational approaches to compensate for garments within the proposed marker-less VTS system. Dr. Lindsay has received training in computer science and computer vision and previously has focused on the computational aspects of capturing, modeling, and rendering of physical phenomena such as light and is proposing to extend this knowledge to the medical imaging field. Dr. Lindsay's goals for this proposal are to acquire the necessary training and skills that will allow him to translate his expertise and existing computational skills to an area f research with medical relevance: namely, detecting and tracking patient motion for the purpose of improving motion correction for hybrid- imaging. Dr. Lindsay's long-term career goal is to become an accomplished independent investigator focusing on solving significant problems in medical imaging by translating advances in Computer Science. The proposed work will take place the University of Massachusetts Medical Center (UMass) in Worcester, MA under the primary mentorship of Dr. Michael King, an internationally known expert in the area of medical imaging and medical physics in Nuclear Medicine. Drs. Gennert, Sullivan, Licho have expertise in computer vision, mechanical engineering and medical imaging, and radiology and Nuclear Medicine, respectively will also serve as co-mentors.  The specific aims of the proposed project are to: 1) develop a novel marker-less VTS, which we call PT- Cam, using low-cost using state-of-the-art camera technology, 2) model surface motion as a surrogate for internal motion of the heart, and 3) conduct tests of the PT-Cam system, in order to determine the acceptability and feasibility of clinical usage, on patients undergoing clinical MPI PET/CT imaging. Thus, the main objective of this program of research is to develop a clinically viable method for motion tracking patients undergoing hybrid-imaging studies by using a novel marker-less surface-tracking method that can compensate for clothing and provide modeling of interior motion of structures from surface tracking. If successful, not only will this project provide an innovative, marker-less VTS system for low-cost surface tracking for motion compensation during hybrid imaging but it will also give the candidate the necessary training needed to become an independent investigator in the medical field and potentially a leader in the field of medical imaging.         PUBLIC HEALTH RELEVANCE: It is estimated that 7.2 million people per year die world-wide from coronary artery disease (CAD), and myocardial perfusion imaging (MPI) has become a critical tool for screening, diagnosis, prognosis, and monitoring treatment of CAD. During medical imaging such as MPI, patient motion is virtually unavoidable and presents a significant source of image degradation and it has been suggested that upwards of 40% of cardiac studies in PET are effected by some type of motion with similar findings for SPECT. The proposed project will directly address the shortcomings of previous methods for tracking patient motion by developing and testing a novel low-cost marker-less visual tracking system for patient motion within hybrid imaging.                ",Body Surface Tracking of Complex Motion with Obstructed Viewing in Hybrid Imaging,8968015,K25EB019032,"['Address', 'Area', 'Award', 'Body Surface', 'Cardiac', 'Clinical', 'Clothing', 'Complex', 'Computer Graphics', 'Computer Vision Systems', 'Computer software', 'Coronary Arteriosclerosis', 'Coupled', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Elements', 'Engineering', 'Ensure', 'Financial compensation', 'Goals', 'Heart', 'Hybrids', 'Image', 'Individual', 'K-Series Research Career Programs', 'Knowledge', 'Lasers', 'Light', 'Lighting', 'Magnetic Resonance Imaging', 'Marketing', 'Massachusetts', 'Measures', 'Mechanics', 'Medical', 'Medical Imaging', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Myocardial perfusion', 'National Institute of Biomedical Imaging and Bioengineering', 'Optics', 'PET/CT scan', 'Patients', 'Physics', 'Positron-Emission Tomography', 'Property', 'Quality of Care', 'Research', 'Research Personnel', 'Respiration', 'Sampling', 'Security', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Work', 'base', 'career', 'computer science', 'cost', 'follow-up', 'heart motion', 'imaging system', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'novel marker', 'outcome forecast', 'prevent', 'programs', 'prospective', 'public health relevance', 'research and development', 'respiratory', 'screening', 'single photon emission computed tomography', 'skills', 'skills training', 'success', 'tool', 'validation studies', 'visual tracking', 'volunteer']",NIBIB,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K25,2015,169609,-0.03170440075110493
"Enabling access to printed text for blind people via assisted mobile OCR     DESCRIPTION (provided by applicant): This application proposes new technology development and user studies aiming to facilitate the use of mobile Optical Character Recognition (OCR) for blind people. Mobile OCR systems, implemented as smartphones apps, have recently appeared on the market. This technology unleashes the power of modern computer vision algorithms to enable a blind person to hear (via synthetic speech) the content of printed text imaged by the smartphone's camera. Unlike traditional OCR, that requires scanning of a document with a flatbed scanner, mobile OCR apps enable access to text anywhere, anytime. Using their own smartphones, blind people can read store receipts, menus, flyers, business cards, utility bills, and many other printed documents of the type normally encountered in everyday life. Unfortunately, current mobile OCR systems suffer from a chicken-and-egg problem, which limits their usability. They require the user to take a well-framed snapshot of the document to be scanned, with the full text in view, and at a close enough distance that each character can be well resolved and thus readable by the machine. However, taking a good picture of a document is difficult without sight, and thus without the ability to look at the scene being imaged by the camera through the smartphone's screen. Anecdotal evidence, supported by results of preliminary studies conducted by the principal investigator's group, confirms that acquisition of an OCR-readable image of a document can indeed by very challenging for some blind users. We plan to address this problem by developing and testing a new technique of assisted mobile OCR. As the user aims the camera at the document, the system analyzes in real time the stream of images acquired by the camera, and determines how the camera position and orientation should be adjusted so that an OCR-readable image of the document can be acquired. This information is conveyed to the user via a specially designed acoustic signal. This acoustic feedback allows users to quickly adjust and reorient the camera or the document, resulting in reduced access time and in more satisfactory user experience. Multiple user studies with blind participants are planned with the purpose of selecting an appropriate acoustic interface and of evaluating the effectiveness of the proposed assisted mobile OCR modality.         PUBLIC HEALTH RELEVANCE: This application is concerned with the development of new technology designed to facilitate use of mobile Optical Character Recognition (OCR) systems to access printed text without sight. Specifically, this exploratory research will develop and test a novel system that, by means of a specially designed acoustic interface, will help a blind person take a well-framed, well-resolved image of a document for OCR processing using a smartphone or wearable camera. If successful, this novel approach to assisted mobile OCR will reduce access time and improve user experience of blind mobile OCR users.                ",Enabling access to printed text for blind people via assisted mobile OCR,8812658,R21EY025077,"['Acoustics', 'Address', 'Algorithms', 'Businesses', 'Cellular Phone', 'Chest', 'Chickens', 'Clothing', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Education', 'Effectiveness', 'Employment', 'Environment', 'Eyeglasses', 'Feedback', 'Goals', 'Hand', 'Hearing', 'Image', 'Knowledge', 'Life', 'Light', 'Location', 'Marketing', 'Modality', 'Monitor', 'Participant', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Printing', 'Process', 'Quality of life', 'Reading', 'Report (document)', 'Research', 'Resolution', 'Restaurants', 'Scanning', 'Series', 'Signal Transduction', 'Solutions', 'Speech', 'Stream', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Development Study', 'Testing', 'Text', 'Time', 'Translating', 'Travel', 'Vision', 'Visual', 'Visually Impaired Persons', 'blind', 'design', 'egg', 'experience', 'handicapping condition', 'improved', 'new technology', 'novel', 'novel strategies', 'object recognition', 'optical character recognition', 'public health relevance', 'research study', 'technology development', 'usability', 'way finding']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2015,191510,0.0006227908275042461
"An evaluation of sensor technology to monitor and report compliance with an evidence-based intervention to prevent ventilator-associated pneumonia ﻿    DESCRIPTION (provided by applicant):  The candidate, Nishi Rawat, is a Critical Care physician and Assistant Professor in the Department of Anesthesiology and Critical Care Medicine at Johns Hopkins. Her goal is to become an independent investigator focused on advancing the field of quality improvement to improve the quality of health care delivered to Americans, while simultaneously reducing costs, with an emphasis on the application of information technology to evaluate performance, minimize waste and eliminate redundancies.  The candidate's preliminary work as a co-investigator for two collaboratives to reduce ventilator-associated pneumonia (VAP) suggests that there is a strong drive to eliminate preventable harms such as VAP, but weak available methodologies and resources to do so. There is a dire need for an effective and inexpensive methodology to track the delivery of evidence-based interventions for the purpose of quality improvement. The proposed research intends to fill this measurement gap. In this proposal, she evaluates the utility of the sensor approach for measuring and improving quality of care, focusing on VAP prevention intervention performance.  The aims propose: evaluate the utility of the sensor approach for measuring compliance with a VAP prevention intervention by comparing VAP process measure performance estimates captured by sensor technology to estimates obtained by traditional manual data collection (Aim 1); design and pilot a strategy to provide real-time feedback of sensor process measure compliance to providers (Aim 2); evaluate the impact of the sensor approach on VAP process measure compliance by comparing compliance before and after the implementation of the real-time feedback strategy (Aim 3). The proposed work could fundamentally change how healthcare monitors and reports important care interventions, and has the potential to make quality improvement more efficient, inexpensive and scalable.  The candidate is uniquely qualified to undertake the proposed work. She is double-board certified in Critical Care and Emergency Medicine, and has completed a Patient Safety and Quality fellowship. She has led multiple local quality improvement initiatives, and worked to decrease ICU costs as part of a national task force, and is currently co-investigator of large national infection prevention collaborative. It isher determination, enthusiasm and strong work ethic which have enabled her to balance these research activities with a heavy clinical commitment. She now needs protected time for research and career development to become an independent investigator.         PUBLIC HEALTH RELEVANCE: The goal of this proposal is to improve quality of care by using low-cost, off-the-shelf, and non-invasive sensor technology to automate the measurement and feedback of data regarding whether patients receive an evidence-based intervention, patient mobilization, to prevent ventilator-associated pneumonia.             ",An evaluation of sensor technology to monitor and report compliance with an evidence-based intervention to prevent ventilator-associated pneumonia,8967301,K23HL125982,"['Adherence', 'Adverse event', 'Advisory Committees', 'American', 'Anesthesiology', 'Big Data', 'Caring', 'Charge', 'Childhood', 'Clinical', 'Critical Care', 'Data', 'Data Collection', 'Emergency Medicine', 'Environment', 'Equilibrium', 'Ethics', 'Evaluation', 'Event', 'Evidence based intervention', 'Feedback', 'Fellowship', 'Focus Groups', 'Frustration', 'Funding', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Hospitals', 'Human Engineering', 'Infection prevention', 'Information Technology', 'Intervention', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Nosocomial Infections', 'Nurses', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Physician Assistants', 'Prevention', 'Prevention Measures', 'Preventive Intervention', 'Process', 'Process Measure', 'Provider', 'Qualifying', 'Quality of Care', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Science', 'State Hospitals', 'Techniques', 'Technology', 'Time', 'United States Agency for Healthcare Research and Quality', 'United States Dept. of Health and Human Services', 'United States National Institutes of Health', 'Work', 'base', 'care delivery', 'career development', 'cost', 'design', 'health care quality', 'improved', 'innovation', 'multi-component intervention', 'novel', 'patient safety', 'preference', 'pressure', 'prevent', 'professor', 'public health relevance', 'research and development', 'response', 'sensor', 'tool', 'ventilator-associated pneumonia', 'wasting']",NHLBI,JOHNS HOPKINS UNIVERSITY,K23,2015,159057,0.009717168293769318
"Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics DESCRIPTION (provided by applicant): Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Often the disability is so severe that it is not possible to feed oneself or readily communicate. A new class of medical system termed brain-machine interfaces (BMIs) has emerged from research labs in the past decade and is now poised to dramatically improve these patients' quality of life. BMIs ""read out"" neural electrical activity directly from motor structures in the brain and decode these electrical impulses in order to determine the intended movement. Initial versions of BMI systems that control a computer cursor are now in FDA Phase-I clinical trials, and numerous agencies are actively engaged in clinical translation (e.g., NIH, DARPA, VA). Creating control signals to enable an amputee to feed himself with a prosthetic (robotic) arm and hand will require decoding signals from thousands of electrodes, rather than the hundred or so signals current systems read, as well as encoding thousands of sensor signals from the arm and hand into thousands of artificial neural signals to be ""written into"" the brain, which has not yet been attempted. The lack of low-power (so that it can be implanted) electronic circuitry needed to run BMIs' encoding and decoding algorithms (termed codecs) is a fundamental barrier to successful clinical translation. The technologies available until now are too power-hungry (digital) or too algorithmically inflexible (analog) to meet the challenge. Recent advances in neuromorphic engineering make it now possible to build a fully implantable and programmable codec chip. This innovative approach combines digital's and analog's best features-programmability and efficiency-while offering far greater robustness than either. Meanwhile recent advances in neuroscience techniques make it now possible to obtain the knowledge needed to design the right algorithms to run on our codec chip. Optogenetic stimulaton can now be used to drive neurons in macaque cortex and computer vision can now be used to track freely moving monkeys while recording wirelessly. We propose to leverage these recent advances to dramatically increase prosthetic performance through the principled design of: (1) An entirely new class of encoders that can spatio-temporally pattern neural activity via optogenetic techniques. (2) An entirely new class of decoders that can operate in the real world with animals moving freely around in far less constrained settings. (3) An entirely new class of implantable programmable electronics that achieves the level of energy- efficiency required to run these complex algorithms. We will demonstrate our success by having a freely moving primate, with a 96-microelectrode recording array and a 9-channel optogenetic stimulator implanted in its premotor and somatosensory cortex, respectively, control a human-like robotic arm. Our ultimate goal is to realize the neuromorphic engineer's dream: Helping untold millions with neurological injury by replacing damaged neural tissue with chips that work like the brain. Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Brain-machine interfaces (BMIs) ""read out"" neural electrical activity directly from motor structures in the brain and decodes these signals in order to execute the intended movement with a robotic arm. This project seeks to increase BMI performance dramatically by leveraging recent advances in systems neuroscience and neuromorphic engineering.",Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics,8849996,R01NS076460,"['Address', 'Adopted', 'Algorithms', 'Amplifiers', 'Amputees', 'Animals', 'Axon', 'Behavioral', 'Brain', 'Budgets', 'Clinical', 'Clinical Paths', 'Cochlea', 'Complex', 'Computer Vision Systems', 'Computers', 'Disabled Persons', 'Dreams', 'Electrodes', 'Electronics', 'Engineering', 'Goals', 'Hand', 'Human', 'Implant', 'Knowledge', 'Macaca', 'Medical', 'Microelectrodes', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Neurons', 'Neurosciences', 'Patients', 'Performance', 'Phase I Clinical Trials', 'Primates', 'Prosthesis', 'Quality of life', 'Reading', 'Research', 'Robotics', 'Running', 'Sensory', 'Signal Transduction', 'Silicon', 'Solutions', 'Somatosensory Cortex', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Translating', 'Translations', 'United States National Institutes of Health', 'Walking', 'Work', 'Writing', 'analog', 'arm', 'base', 'brain machine interface', 'cranium', 'design', 'digital', 'disability', 'feeding', 'grasp', 'improved', 'innovation', 'interest', 'meetings', 'millisecond', 'motor impairment', 'nervous system disorder', 'neural patterning', 'neural prosthesis', 'neurotransmission', 'optogenetics', 'prosthetic hand', 'relating to nervous system', 'research study', 'sensor', 'sensory cortex', 'spatiotemporal', 'success']",NINDS,STANFORD UNIVERSITY,R01,2015,879670,0.029013752914225463
"Rapid Detection of Common Failure Modes for Knee Prosthetics ﻿    DESCRIPTION (provided by applicant):  Bruin Biometrics' proposes to develop the Joint Health Monitor (JHM), an innovative low risk device capable of detecting artificial joint implant failure prior to all currently available diagnostic devices. Artificial joint replacements have demonstrated excellent clinical performance. However, failures do occur due to a multitude of factors including, aseptic loosening, wear, dislocation, osteolysis, and adverse local tissue reactions (ALTR), including pseudotumors and extensive tissue damage. Recent catastrophic failures associated with specific implant designs, and increasing concern over the severe clinical consequences of ALTR, have raised the attention of both consumer advocacy groups and regulatory agencies, in the US and abroad. It is evident that current diagnostic tools have failed to predict early enough complications associated with some implant designs and/or patient's characteristics. Rather than be predictive, current diagnostic methods usually do not detect joint degradation until bone and tissue damage have already occurred, increasing morbidity, mortality and severity of revision surgeries. Bruin Biometrics has developed an innovative monitoring device that will allow effective monitoring of an artificial joint functionality and eary detection of at risk patients, implant designs and reduction of the number or at least the severity of revision surgeries. Early detection should also enable physicians to prescribe exercise regimens, dietary supplements, medication, early revision surgery or other measures to protect against further damage. Moreover, the existence of an effective monitoring device would provide invaluable feedback, enabling unprecedented quantification and evaluation of treatment efficacy including drugs. The objectives of this proposal are to demonstrate the technical feasibility of this device to detect specific failure modes. This will be accomplished using an in vitro test rig set up and an in vivo human subject pilot study. Our overall goal is to rapidly delier a wearable system capable of monitoring the status of artificial joints and provide surgeons with more accurate and earlier diagnoses.         PUBLIC HEALTH RELEVANCE:  Hip and Knee replacement procedures will continue to increase dramatically over the next twenty years and the rate of revision surgery is expected to remain stable around 17-18%. This will increase the burden on orthopaedic surgeons, operating room capacity, and healthcare cost. In 2007 dollars, this volume of total joint replacement would generate costs exceeding $100 billion, or 1% of the gross domestic product (GDP). If successful, the new monitoring device object of this proposal named ""Joint Health Monitor"" will have an immediate impact on managing joint degradation, reducing complicated revision surgeries and allowing more effective patient surveillance avoiding catastrophic failure; this in turn will increase patient confidence in regulatory agencies and industry.            ",Rapid Detection of Common Failure Modes for Knee Prosthetics,8906609,R43AR067048,"['Acoustics', 'Algorithms', 'Architecture', 'Arithmetic', 'Attention', 'Biometry', 'Bone Tissue', 'Characteristics', 'Classification', 'Clinical', 'Consumer Advocacy', 'Controlled Environment', 'Data', 'Degenerative polyarthritis', 'Dependence', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic radiologic examination', 'Discrimination', 'Dislocations', 'Early Diagnosis', 'Evaluation', 'Exercise', 'Failure', 'Feedback', 'Goals', 'Health', 'Health Care Costs', 'Hip region structure', 'Implant', 'In Vitro', 'Industry', 'Joints', 'Knee', 'Knee Prosthesis', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methodology', 'Methods', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Names', 'Operating Rooms', 'Operative Surgical Procedures', 'Orthopedics', 'Osteolysis', 'Outcome', 'Patient risk', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Pilot Projects', 'Procedures', 'Prosthesis', 'Radiation', 'Reaction', 'Regimen', 'Replacement Arthroplasty', 'Risk', 'Severities', 'Signal Transduction', 'Surgeon', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Treatment Efficacy', 'Trust', 'Visit', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'adverse outcome', 'attenuation', 'base', 'cohort', 'cost', 'design', 'dietary supplements', 'follow-up', 'hip replacement arthroplasty', 'human subject', 'in vitro testing', 'in vivo', 'innovation', 'knee replacement arthroplasty', 'monitoring device', 'mortality', 'public health relevance', 'rapid detection', 'sample fixation', 'tool']",NIAMS,"BRUIN BIOMETRICS, LLC",R43,2015,149685,-0.02421824072753577
"Context Understanding Technology to improve internet accessibility for users with DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization. PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.",Context Understanding Technology to improve internet accessibility for users with,8795182,R44EY020082,"['Advertisements', 'Area', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Government', 'Grouping', 'Health', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Persons', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2015,195445,0.013896510479965237
"Multi-scale network dynamics of human upper limb movements: characterization and DESCRIPTION (provided by applicant):  The overall project goals are to study the cortical network dynamics of human upper limb motor control spanning two distinct spatial scales recorded with electrocorticography (ECoG), and to demonstrate that these dynamics can be estimated in real-time and used to control the JHU Applied Physics Lab Modular Prosthetic Limb (MPL) during execution of functionally useful complex action sequences.  Our human subjects will be instructed to perform complete functional movements characteristic of activities of daily living.  We will analyze the task-related temporal evolution in the strength and pattern o interactions among large-scale cortical networks known to be recruited in visually-guided reach-to-grasp tasks.  Using multi-scale subdural ECoG with combinations of routine clinical macro-electrodes (2.3 mm diameter, 1 cm spacing) recording activity of broadly spread elements/nodes of neural networks, and inset arrays of microelectrodes (75 �m diameter, 0.9 mm spacing) recording the activity of local sub-networks, we will test our overall hypothesis that there is a functional hierarchy between the two scales (Aim 1).  More specifically, we hypothesize that large-scale network dynamics involving premotor/motor cortex reflect the evolution of sensory-motor processing demands during complex action sequences, while micro-scale population activity and network dynamics in motor cortex reflect the low-level kinematics of these tasks.  We will utilize methods of estimating dynamic effective connectivity developed by our team to study interactions between these scales and test whether there exists a spatially heterogeneous and hierarchical structure within the macro-micro scale networks.  The results of these analyses have wide-ranging clinical implications for both the optimal scale of functional mapping for clinical diagnostic purposes and the extent of implantations for neuroprosthetic control.  We will exploit multi-scale ECoG recordings and online estimates of the dynamics of neural activation and large-scale/local network interactions to achieve control of the MPL during functionally useful tasks (Aim 2).  This approach will go beyond traditional paradigms that have developed neural control over individual degrees of freedom.  We will do this by embedding low-level control within an innovative framework whereby knowledge of task goals supplement direct kinematic decoding.  This project will build on our team's previous successes in implementing a system for semi-autonomous ECoG control of the MPL, employing machine vision and route-planning algorithms, during complex interactions with objects requiring the coordination of multiple joints.  This system will be able to leverage for the first time the rich complexity of temporally and spatially resolved network dynamics correlated with high-level goals to achieve functionally useful control of an advanced neuroprosthetic limb. PUBLIC HEALTH RELEVANCE:  For ""Multi-scale network dynamics of human upper limb movements:  characterization and translation in neuroprosthetics"" This project will use recordings from the surface of the human brain to study how brain networks control arm and hand movements.  We will also test whether information about these networks can be used to control an advanced robotic prosthetic arm.  This could have a profound long-term impact on future generations of patients seeking to restore lost upper limb function with a lifelike prosthesis.",Multi-scale network dynamics of human upper limb movements: characterization and,8853351,R01NS088606,"['Activities of Daily Living', 'Algorithms', 'Area', 'Artificial Arm', 'Attention', 'Biological Neural Networks', 'Brain', 'Caliber', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complex', 'Computer Vision Systems', 'Cues', 'Diagnostic', 'Eating', 'Electrocorticogram', 'Electrodes', 'Elements', 'Epilepsy', 'Evolution', 'Freedom', 'Future Generations', 'Goals', 'Hand', 'Health', 'Human', 'Individual', 'Joints', 'Knowledge', 'Limb Prosthesis', 'Limb structure', 'Location', 'Maps', 'Measures', 'Mediating', 'Methods', 'Microelectrodes', 'Modeling', 'Modification', 'Motor', 'Motor Cortex', 'Movement', 'Neurosciences', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Performance', 'Physics', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Process', 'Prosthesis', 'Recruitment Activity', 'Resolution', 'Robotics', 'Route', 'Sampling', 'Sensory', 'Signal Transduction', 'Site', 'Staging', 'Structure', 'Surface', 'System', 'Testing', 'Time', 'Training', 'Translations', 'Upper Extremity', 'Upper limb movement', 'Vision', 'arm', 'drinking', 'grasp', 'human subject', 'implantation', 'innovation', 'joint mobilization', 'kinematics', 'motor control', 'neuroprosthesis', 'neuroregulation', 'relating to nervous system', 'success', 'temporal measurement', 'time use']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2015,354375,0.015124937798913225
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair     DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning.          PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.             ",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,8838311,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Behavior', 'Build-it', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Glass', 'Hand', 'Head', 'Head Movements', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Reliance', 'Research', 'Robot', 'Robotics', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'public health relevance', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2014,155663,0.01455418001975286
"A Software Platform for Sensor-based Movement Disorder Recognition     DESCRIPTION (provided by applicant): The overall objective of this SBIR project is to develop a pre-commercial prototype system capable of continuously monitoring involuntary movement disorders from a wide spectrum of neurological conditions. The impact of this innovation will enhance the availability of advanced brain and behavior research tools [PA- 11-134] by providing a continuous means of tracking the presence and severity of movement disorders during normal daily activities. This project will transform our unique movement disorder recognition algorithms into custom software that analyzes movement disorders for specific neurological conditions. The information obtained from body worn sensors will provide an accurate and objective means for assessing the complex and changeable nature of movement disorders. This goal cannot by realized using the current method of self-report questionnaires.  The research strategy for Phase I will establish the merit and feasibility of this effort by developing an Application Generation (AG) software platform using a framework of configurable signal processing modules to generate custom applications for movement disorder analysis (Aim 1). This approach reduces the effort and enhances the flexibility of designing and testing software solutions for these applications. The AG Platform will be developed using C++ software to implement signal processing and machine-learning software modules that operate within a knowledge-based framework that we have previously developed. In Aim 2 we will utilize the AG platform to generate movement disorder analysis software to evaluate a challenging test-case application: freezing-of-gait in Parkinson's disease (PD). The goal is to attain performance metrics for freezing that are comparable to those we have achieved for tremor and dyskinesia in previous efforts.  Phase II will refine the capabilities of the AG platform developed in Phase I. We will augment it with the means to automatically design and train the machine learning algorithms, improve the user-interface, and provide options for viewing and summarizing the results. The improved AG platform will be used to develop customized disorder-analysis software that encompasses the full complement of movement disorders associated with PD (e.g. dystonia, bradykinesia, Parkinsonian gait, tremor, dyskinesia), as well as for other neurological condition, such as Essential Tremor (ET). Firmware will be developed for each custom application to efficiently integrate the analytic software with our existing Trigno wireless sensor data acquisition hardware, which needs to be streamlined for this application. This combined system will be evaluated under research use-case scenarios in Neurology. Phase II will deliver an ambulatory Movement Disorder Monitoring system that not only succeeds in providing state-of-the-art monitoring solutions for PD and Essential Tremor, but has proven technology to develop monitoring solutions for a wide variety of neurological conditions. Future development will transfer this technology to a clinical version of this system.         PUBLIC HEALTH RELEVANCE: The project is intended to improve the accuracy and reduce the burden of researchers and clinicians when assessing motor outcomes for patients with involuntary movement disorders. The proposed technology will provide a means for evaluating new treatment options, and expedite the delivery of care. The attainment of these goals should increase the effectiveness of research, the time required for these research advancements to reach the consumer, and help control the rising costs of clinical care among the estimated 45 million Americans who have neurological disorders resulting in involuntary movements. The resulting improvements in motor function will ultimately lead to greater independence and productivity for this growing segment of the population.            ",A Software Platform for Sensor-based Movement Disorder Recognition,8734495,R43NS083098,"['Affect', 'Algorithms', 'American', 'Bradykinesia', 'Clinical', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Custom', 'Data', 'Development', 'Disease', 'Dyskinetic syndrome', 'Dystonia', 'Early Diagnosis', 'Essential Tremor', 'Freezing', 'Future', 'Gait', 'Generations', 'Goals', 'Health Care Sector', 'Health Professional', 'Home environment', 'Involuntary Movements', 'Lead', 'Learning Module', 'Left', 'Lower Extremity', 'Machine Learning', 'Methods', 'Metric', 'Miniaturization', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Neurologic', 'Neurology', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Process', 'Productivity', 'Quality of life', 'Questionnaires', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training', 'Tremor', 'Video Recording', 'Wireless Technology', 'Work', 'Writing', 'advanced system', 'base', 'brain behavior', 'care delivery', 'clinical care', 'cost', 'data acquisition', 'design', 'disorder control', 'effectiveness research', 'flexibility', 'handheld mobile device', 'human subject', 'improved', 'innovation', 'knowledge base', 'motor disorder', 'nervous system disorder', 'novel therapeutics', 'prototype', 'public health relevance', 'research study', 'response', 'sensor', 'signal processing', 'software development', 'tool']",NINDS,"ALTEC, INC.",R43,2014,417876,0.030099701557488326
"Wrist/Grasp Muscle Activity Patterns for EMG-neural Interface Prosthesis Control     DESCRIPTION (provided by applicant):    Simultaneous wrist/hand control (where a person simultaneously moves his/her wrist while grasping or  releasing), is essential in activities of daiy living, but cannot be performed by amputees using clinical surface  electromyography (sEMG) based neural interfaces (myoelectric control). Transradial amputees, who make up 40% of major amputations (proximal to the wrist), cite simultaneous control as a necessary element to improve upper-limb prostheses. Our long-term goal is to develop a clinically viable EMG-based neural interface for transradial amputees that is suitable for restoring simultaneous control of prosthetic wrist/hand movements.   One proposed method for intuitive simultaneous wrist/hand prosthesis control uses intramuscular EMG  (imEMG) amplitude estimates from multiple agonist/ antagonist forearm muscle pairs to control physiologically  appropriate degrees of freedom DOFs (e.g. flexor digitorum profundus / extensor digitorum control  grasp/release). Known as 'direct control', this approach does not require burdensome levels of machine  learning algorithm training, as is required for experimental sEMG-based simultaneous control methods.  However, this method assumes independently modulated muscle activation patterns for each DOF - that the activation patterns of muscles controlling a DOF (i.e. finger flexors/extensors for grasp/release) do not change when a second DOF is simultaneously attempted (simultaneous pronation/supination and grasp/release). The biologic foundation of such an assumption has not been explored to date. Little is known of how the central nervous system (CNS) coordinates wrist and extrinsic hand muscle activation when independent of biomechanical effects and joint position feedback. Muscle activation patterns under such conditions are particularly relevant to amputee populations, who lack distal joints. Therefore, the objective of this research is to better understand how the CNS coordinates muscle activation patterns in healthy individuals to produce simultaneous wrist/grasp torques when independent of the biomechanical effects of joint movement. We will then apply this information to develop an imEMG simultaneous myoelectric prosthesis controller.  imEMG patterns will be measured as healthy subjects produce single-DOF and simultaneous multi-DOF (SMD) wrist and/or grasp/release torques in isometric, neutral posture conditions. Multivariate models predicting imEMG activity from measured wrist/grasp torques will be developed and will suggest which DOFs have independently modulated muscle activation patterns. This information will then allow for the development of a 'biologically-inspired' simultaneous controller. DOFs with independently modulated muscle activation patterns will be controlled using direct control, while experimental pattern recognition algorithms currently used for sEMG-based simultaneous control will be used for all other DOFs. We will evaluate the performance of this hybrid controller in healthy subjects both offline and using online functional tests in a virtual environment.            PUBLIC HEALTH RELEVANCE:    Various current prosthetic arms use the electrical signals produced when muscles contract to control prosthesis movement, but cannot provide simultaneous control of both the wrist and the hand. This study will investigate how the nervous system activates muscles to simultaneously control the wrist and hand in healthy individuals. This information can then be used to provide clinically viable methods of controlling simultaneous wrist and hand movements of prostheses to amputees.                 ",Wrist/Grasp Muscle Activity Patterns for EMG-neural Interface Prosthesis Control,8702940,F31NS083166,"['Activities of Daily Living', 'Agonist', 'Algorithms', 'Amputation', 'Amputees', 'Anatomy', 'Biological', 'Biomechanics', 'Clinical', 'Contracts', 'Data', 'Development', 'Distal', 'Educational Status', 'Electromyography', 'Elements', 'Environment', 'Feedback', 'Fingers', 'Flexor', 'Forearm', 'Foundations', 'Freedom', 'Goals', 'Hand', 'Human', 'Hybrids', 'Individual', 'Intramuscular', 'Isometric Exercise', 'Joints', 'Knowledge', 'Life', 'Limb Prosthesis', 'Limb structure', 'Literature', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Movement', 'Muscle', 'Muscle Contraction', 'Myoelectric prosthesis', 'Nervous system structure', 'Neuraxis', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Persons', 'Population', 'Positioning Attribute', 'Posture', 'Pronation', 'Prosthesis', 'Rehabilitation therapy', 'Research', 'Residual state', 'Signal Transduction', 'Supination', 'Surface', 'Testing', 'Torque', 'Training', 'Upper Extremity', 'Work', 'Wrist', 'arm', 'base', 'design', 'extensor digitorum', 'grasp', 'improved', 'joint mobilization', 'public health relevance', 'relating to nervous system', 'success', 'virtual']",NINDS,NORTHWESTERN UNIVERSITY,F31,2014,47676,0.024019632288791698
"A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI     DESCRIPTION (provided by applicant): A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI NeuroEnabling Technologies, Inc. RESEARCH & RELATED Other Project Information 7. PROJECT SUMMARY Of the approximately 10 million people in the US living with paralysis, 15,000 are the result of spinal cord injury each year. The first year of care can range from $322,000-$986,000, with lifetime costs of $1.4-4M for someone injured at 25 years of age. In addition to potentially devastating sensorimotor disturbances, there is a huge financial cost, estimated to be $13.55B in medical care, therapy, and lost productivity nationwide. Until very recently, the recovery from spinal cord injury (SCI) was bleak, with little hope of restoring motor function. To address this we have demonstrated that the physiological state of the spinal circuitry of rats and cats can be modulated with epidural stimulation to generate voluntary limb motor function over a range of speeds, loads, and directions, a finding we have extended to humans. Three years post-injury, a motor complete spinal cord injured human subject was implanted with an epidural electrode array over the lumbosacral spinal cord. In less than one month after implantation, the subject could stand independently, and after 7 months of daily epidural stimulation and motor training, voluntary control of both legs was evident in the presence of epidural stimulation, whereas complete paralysis remained in absence of epidural stimulation. We will advance these discoveries with the use of non-invasive stimulation of the lumbosacral cord to improve lower limb function following SCI. Central to this proposal is our discovery of a painless electrical multi-channel (stimulation of multiple parts of the spinal cord) theranostic tool that can be applied to the surface of the skin, termed transcutaneous spinal cord electrical stimulation (TESCS), bypassing the need for a surgically-implanted electrode array. In the first phase of this proposal we will demonstrate proof-of-principle that stimulation of the lumbosacral spinal cord can assess spared spinal motor function by: 1) Testing responses to transcutaneous electrical stimulation in subjects with spinal cord injury; and 2) defining the operational parameters of electrical stimulation that that are most effective using a machine-learning protocol, and 3) produce a multi-channel commercial prototype. This commercial product will undergo testing similar to the proof-of- principle device. This device will then be tested in subjects with cervicothoracic spinal cord injury and evaluated with a machine-learning protocol. This Phase I proposal will deliver a device that can painlessly and non-invasively aid in the assessment and recovery of SCI by delivering a specific electrical stimulation paradigm to the lumbosacral cord that improves use of the lower limbs.         PUBLIC HEALTH RELEVANCE: A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI NeuroEnabling Technologies, Inc. PROJECT NARRATIVE It now seems possible to apply three interventions: transcutaneous stimulation, administration of pharmacological agents, and motor training, to assess and enable the excitability of spared neural circuits in humans with a thoracic spinal cord injury (SCI), thus enabling these individuals to regain use of their legs. This enabling effect is similar to that observed with improved postura and locomotor function after a mid-thoracic SCI in which epidural stimulation was used. We will build and demonstrate a multi-channel transcutaneous electrical spinal cord stimulation theranostic tool that we propose will allow assessment and enabling of lower limb function following a cervicothoracic spinal cord injury.                ",A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI,8735147,R43EB018232,"['Address', 'Age-Years', 'Algorithms', 'American', 'Ankle', 'Bypass', 'Caring', 'Cervical', 'Cervical spinal cord injury', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Diagnosis', 'Diagnostic', 'Electric Stimulation', 'Electrodes', 'Enrollment', 'Evaluation', 'Felis catus', 'Financial cost', 'Goals', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Joints', 'Knee', 'Leg', 'Life', 'Limb structure', 'Lower Extremity', 'Lumbar spinal cord structure', 'Machine Learning', 'Measurement', 'Medical', 'Modality', 'Motor', 'Movement', 'Nervous System Physiology', 'Neurologic', 'Neurostimulation procedures of spinal cord tissue', 'Outpatients', 'Painless', 'Paralysed', 'Paraplegia', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Productivity', 'Protocols documentation', 'Rattus', 'Recovery', 'Residual state', 'Site', 'Skin', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord Part', 'Spinal Injuries', 'Spinal cord injury', 'Spinal cord injury patients', 'Stroke', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Transcutaneous Electric Nerve Stimulation', 'Translating', 'Upper Extremity', 'Weight-Bearing state', 'design', 'human subject', 'human subject protection', 'implantation', 'improved', 'improved functioning', 'injured', 'life time cost', 'meetings', 'motor control', 'motor function improvement', 'neural circuit', 'neuroregulation', 'prototype', 'public health relevance', 'response', 'theranostics', 'tool', 'transcutaneous stimulation']",NIBIB,"NEUROENABLING TECHNOLOGIES, INC.",R43,2014,346207,0.04402790375714625
"Electrocorticography signals for human hand prosthetics    DESCRIPTION (provided by applicant):  Neurological injury (such as from stroke, traumatic brain injury, and spinal cord injury) is a major cause of permanent disability.  Recent advances in the field of neuroprosthetics hold enormous potential for the development of brain-computer interfaces to restore neurological function.  This project will lead to a system that can control a robotic hand using recordings from the surface of the brain.  Interfaces based directly from brain signals may allow for direct decoding of control signals for maximally efficient prosthetics.  This project, a collaboration between neurosurgery, computer science, and physics departments, will explore the brain signals underlying hand movement using electrocorticography, or ECoG.  We have previously shown that high frequency (>75Hz) components of the ECoG carry information about local brain activity.  In the first aim, we will expand our understanding of the high-frequency signal components that correlate with individual finger movements.  We will extract broadband changes in ECoG from non-specific alpha and beta rhythms using PCA and enhance finger classification with machine learning algorithms.  In the second aim, we will look for control signals reflecting different hand functions, rather than movement of different fingers.  For instance, we will examine if pinch and grasp behaviors give more separable high- frequency ECoG signals.  We will also examine the behavior of these movements at higher spatial resolution.  In the third aim, we will measure ECoG changes associated with imagined movement and how these changes are altered with visual feedback when applied to a robotic hand.  In the final aim, we will add tactile feedback to the control to optimize ECoG-based control of a hand prosthesis.  By increasingly advancing the complexity of the control signal, and the complexity of the robotic hand output, we will establish if ECoG is a viable source of control signal for a hand neuroprosthetic device.       PUBLIC HEALTH RELEVANCE:  The development of a hand neuroprosthetic, or artificial device that interacts with the nervous system could restore function to those afflicted by stroke, brain injury, spinal cord injury, or neurodegenerative diseases that have damaged the use of a hand or arm.  This project examines whether signals recorded directly from the human brain (during surgery for epilepsy) could be used to control a robotic hand.            ",Electrocorticography signals for human hand prosthetics,8645764,R01NS065186,"['Algorithms', 'Alpha Rhythm', 'Animals', 'Area', 'Behavior', 'Behavioral', 'Beta Rhythm', 'Brain', 'Brain Injuries', 'Classification', 'Collaborations', 'Coupling', 'Degenerative Disorder', 'Development', 'Devices', 'Digit structure', 'Dimensions', 'Disease', 'Distant', 'Electrocorticogram', 'Electrodes', 'Epilepsy', 'Feedback', 'Fingers', 'Frequencies', 'Future', 'Hand', 'Hand functions', 'Human', 'Image', 'Imagery', 'Individual', 'Lead', 'Left', 'Life', 'Limb structure', 'Machine Learning', 'Measures', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Physiology', 'Nervous System Trauma', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurologic', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Penetration', 'Phase', 'Physics', 'Population Dynamics', 'Positioning Attribute', 'Prosthesis', 'Resolution', 'Robotics', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Stroke', 'Surface', 'Survivors', 'System', 'Tactile', 'Technology', 'Thumb structure', 'Training', 'Traumatic Brain Injury', 'Upper Extremity', 'Visual', 'Work', 'arm', 'base', 'brain computer interface', 'brain machine interface', 'computer science', 'disability', 'functional restoration', 'grasp', 'improved', 'indexing', 'limb movement', 'neuroprosthesis', 'neurosurgery', 'public health relevance', 'tool', 'visual control', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2014,328704,0.022265898908949453
"Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI     DESCRIPTION (provided by applicant):  In the first 5-year period of our BRP we had two major objectives:  1) to determine whether we could improve motor function of the lower limbs by neuromodulating the spinal lumbosacral circuitry with epidural stimulation and 2) to begin to develop and improve the technologies associated with electrode arrays and chronic implantable stimulation devices to maximize the neuromodulatory potential.  These new technologies have the potential to fine tune the epidural stimulation parameters, to help in understanding some of the underlying mechanisms of epidural stimulation., to examine synergistic effects of epidural stimulation, pharmacological modulation, and examine activity-dependent interventions that might affect the level of recovery of motor function after complete paralysis.  We have demonstrated that an adult rat with a complete, mid-thoracic spinal cord transection can regain full weight-bearing stepping over a range of speeds, loads, and even directions when the spinal cord is stimulated tonically to increase the excitability of the lumbosacral locomotor circuitry.  Furthermore, we learned that load-bearing sensory information can serve as the controller of these complex motor tasks and that the performance of these tasks can be improved even further with combinations of epidural stimulation, pharmacological, and motor training interventions.  We have shown that four humans with a motor complete spinal injury have regained independent standing, assisted stepping, and even a significant level of voluntary control of the lower limbs in the presence of epidural stimulation, with one subject now even having some volitional control without stimulation.  Improvement in bladder control, blood pressure, temperature regulation, and even sexual function has been realized.  Thus, our present challenge is to develop the capability to selectively activate combinations of neural networks that can enable standing, and probably stepping, by improving the technologies needed to make this intervention available in the clinic and in the home of individuals with complete motor paralysis using a chronic epidural electrode implant.  Specifically, we will further improve the electrode array stimulation technology needed for fine-tune control in rats and humans and transform the present hardwired technology for rats to a wireless capability to stimulate and record evoked potentials along the brain-spinal cord-muscle axis in the rat.  To advance the clinical potential, we will continue to develop, refine and validate our machine-learning strategies which automatically optimize stimulation parameters for standing, stepping, and voluntary control.  We will develop an improved interface between the devices implanted in our present subjects and the control devices for defining the specific stimulation parameters needed for a given subject to perform a motor task in the clinic or at home.           PUBLIC HEALTH RELEVANCE:  We now have demonstrated that the human lumbosacral spinal cord can be neuromodulated with epidural stimulation to enable recovery of standing and volitional control of the lower limbs and return of some autonomic function after complete motor paralysis.  Therefore, our objectives are now to develop the technologies needed to more fully capitalize on this clinical potential and develop home-use technologies to do so.                  ",Spinal Epidural Electrode Array To Facilitate Standing and Stepping After SCI,8696689,U01EB007615,"['Adult', 'Affect', 'Algorithms', 'Animals', 'Behavior', 'Binding', 'Biological Neural Networks', 'Bladder Control', 'Blood Pressure', 'Brain', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Complex', 'Contusions', 'Data', 'Devices', 'Dorsal', 'Educational Intervention', 'Electrodes', 'Evaluation', 'Evoked Potentials', 'Experimental Designs', 'Frequencies', 'Home environment', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Internet', 'Intervention', 'Intramuscular', 'Learning', 'Locomotor training', 'Lower Extremity', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Muscle', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Procedures', 'Process', 'Rattus', 'Recovery', 'Regulation', 'Research', 'Robotics', 'Sensory', 'Sex Functioning', 'Signal Transduction', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord transection injury', 'Spinal Injuries', 'Spinal cord injury', 'Stimulus', 'System', 'Task Performances', 'Technology', 'Temperature', 'Testing', 'Thoracic spinal cord structure', 'Training', 'Weight-Bearing state', 'Wireless Technology', 'base', 'density', 'design', 'implantable device', 'improved', 'in vivo', 'motor control', 'motor function improvement', 'motor function recovery', 'new technology', 'next generation', 'novel', 'public health relevance', 'somatosensory', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2014,1152001,0.04173526953974432
"Enabling forelimb function with agonist drug and epidural stimulation in SCI     DESCRIPTION (provided by applicant):  We have demonstrated that the physiological state of the lumbosacral spinal circuitry of spinal rats and cats can be modulated with spinal cord epidural stimulation (EDS) and/or administration of pharmacological agents to generate weight-bearing standing and stepping over a range of speeds, loads, and directions.  We have translated some of these results to humans by implanting 3 motor complete spinal cord injured (SCI) subjects about three years post-injury with an epidural electrode array over the lumbosacral spinal cord.  In less than one month post-electrode implant, the subjects could stand independently, and after up to 7 months of daily EDS and motor training, voluntary control of both legs was evident in the presence of EDS, whereas complete paralysis remained in absence of EDS.  We propose to employ a similar stimulation strategy for the recovery of upper limb function.  We will include extensive testing of spinal rats to guide our strategy to test for upper extremity improvement in human SCI subjects.  We will use off-the-shelf FDA approved pharmacological and stimulation modalities to:  1) Determine the optimal stimulation parameters, i.e., electrode placement and stimulation intensity, frequency and duration, for facilitating forelimb fine motor function in rats with a cervical SCI.  Using existing FDA-approved epidural electrodes, we will demonstrate in patients with a cervical SCI that cervical EDS can facilitate arm-hand function.  2) Identify an effective mode of administration, define the dose- response pharmacokinetics, and determine the effectiveness of a monoaminergic agonist to facilitate upper limb function after a cervical SCI.  We will assess the effectiveness of existing FDA-approved pharmacological agents (i.e., buspirone and as an alternative, bromocriptine), and determine their effectiveness in improving forelimb control in subjects with a cervical SCI.  3) Define the dose-response properties of monoaminergic agonists when combined with EDS in facilitating forelimb function in rats after a cervical SCI.  We will demonstrate the efficacy of ES in combination with a pharmacological intervention in facilitating arm and hand function in humans after a cervical SCI.  4) Determine whether motor training of spinal rats will further enhance the recovery of motor function when combined with pharmacological and/or EDS interventions.  5) Develop a protocol for machine learning to enable rapid selection of the optimal pharmacological and EDS parameters for motor recovery in rats and in human subjects.  If successful, this could represent the beginning of a paradigm shift in the use of minimally invasive strategies combined with rehabilitative approaches to realize significant improvement in upper limb function after paralysis.         PUBLIC HEALTH RELEVANCE:  It now seems possible to apply three interventions (epidural stimulation, administration of pharmacological agents, and motor training) to control the excitability of localized neural circuits in humans with a cervical spinal cord injury (SCI), thus enabling these individuals to regain use of their arms and hands.  This enabling effect is similar to that observed with improved postural and locomotor function after a mid-thoracic SCI.  We will reach critical milestones that will provide the basis for a series of clinical trials for furter defining the efficacy of these interventions.                ",Enabling forelimb function with agonist drug and epidural stimulation in SCI,8690845,U01EB015521,"['Agonist', 'Algorithms', 'Ankle', 'Bromocriptine', 'Buspirone', 'Cervical', 'Cervical spinal cord injury', 'Cervical spinal cord structure', 'Chronic', 'Clinical Trials', 'Complement', 'Devices', 'Dose', 'Drug Kinetics', 'Effectiveness', 'Electrodes', 'FDA approved', 'Felis catus', 'Food', 'Forelimb', 'Frequencies', 'Goals', 'Hand', 'Hand functions', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Knee', 'Leg', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Methodology', 'Modality', 'Motor', 'Motor Skills', 'Oral', 'Paralysed', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Preparation', 'Property', 'Protocols documentation', 'Rattus', 'Recovery', 'Rehabilitation therapy', 'Retrieval', 'Series', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Testing', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Translating', 'Treatment Efficacy', 'Upper Extremity', 'Weight-Bearing state', 'arm', 'base', 'design', 'human subject', 'improved', 'minimally invasive', 'motor function recovery', 'neural circuit', 'neuroregulation', 'public health relevance', 'response']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2014,819964,0.020734129653831194
"Sensor Activity Monitoring, Feedback, and Outcome Measures, Stroke Rehabilitation     DESCRIPTION (provided by applicant): ""Technologies for Healthy Independent Living"" coincides with our goal to test and further develop inexpensive wireless sensors with communication and analysis platforms to monitor everyday activities, such as walking and exercise, in disabled persons. Our Medical Daily Activity Wireless Network (MDAWN) aims to enable researchers, trialists, and clinicians to acquire reliable data about daily physical activites in the home and community, rather than only during clinic and laboratory visits or by questionnaires. Novel machine-learning algorithms developed for each person from ankle accelerometers will identify the type, quantity and quality of exercise and walking on a continuous basis. In addition, we will test an inexpensive, instrumented, ergometric pedaler designed for disabled persons, called the UCFit, to promote home-based fitness exercise. The MDAWN and UFCFit sensors send data to an Android smartphone, then over the Internet to a UCLA server for analysis. We will nest further evaluation of the utility of these remote sensing devices within the real-world setting of a clinical trial of patients with recent disabling stroke,for whom formal rehabilitation often falls short of enabling functional walking and cardiovascular fitness. In a phase 2, randomized controlled trial, we will compare two levels of weekly telephonic feedback about daily performance, made possible for the first time by remote data acquisition. The high feedback group will receive everyday performance data that includes the number of bouts and minutes of pedaling plus rate/RPMs and forces used, as well as the number of bouts of walking, duration, and average speed and distance used in home and community. The minimal feedback group only hears about total daily UCFit exercise and walking time. After 4 months of encouraging up to four 30-min sessions per week of UCFit exercise, we will test for a 50% between-group difference in amount of daily exercise and walking time. Secondary outcomes examine change in level of fitness, walking speed, and physical functioning. The two groups then cross over to high or low feedback for 4 more months, before outcomes are reassessed. Then, no feedback is given and participants are tested for amount of exercise and fitness at 12 months. We will determine which form of feedback motivates better self-management to optimize fitness and walking. We will gather unique data about mobility in the transition from rehabilitation hospital to home; quantify gait training durin usual care; assess walking skills under more complex conditions than in a laboratory; and test the responsiveness of sensor data as a ratio scale outcome measurement during a time of expected gains. This study will be the first comprehensive demonstration of mHealth remote monitoring and outcome measures of daily physical activity!          Several important public health needs will be met by testing, within a clinical trial in the home and community, a system of wearable activity and exercise monitoring technologies that measure the type, quantity and quality of walking and exercise. Our trial aims to increase fitness and enable more functional levels of daily activities in disable persons after stroke, while providing a proof-of-principle for the utility of wireless health toolsto reliably monitor real-world physical functioning and to provide clinically meaningful outcome measures. These generic tools for daily care and research can be deployed across diseases and disabilities.            ","Sensor Activity Monitoring, Feedback, and Outcome Measures, Stroke Rehabilitation",8686617,R01HD071809,"['Address', 'Adherence', 'Aerobic', 'Aerobic Exercise', 'Algorithms', 'Ankle', 'Beds', 'California', 'Cardiovascular system', 'Caregivers', 'Caring', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Trials', 'Communication', 'Communities', 'Complex', 'Continuity of Patient Care', 'Data', 'Devices', 'Disabled Persons', 'Disease', 'Effectiveness', 'Evaluation', 'Event', 'Exercise', 'Feedback', 'Gait', 'Generic Drugs', 'Genetic Crossing Over', 'Glosso-Sterandryl', 'Goals', 'Health', 'Hearing', 'Home environment', 'Hospitals', 'Independent Living', 'Inpatients', 'Internet', 'Intervention', 'Laboratories', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Monitor', 'Movement', 'Outcome', 'Outcome Measure', 'Outpatients', 'Participant', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Physical Function', 'Physical activity', 'Pilot Projects', 'Procedures', 'Public Health', 'Questionnaires', 'Randomized', 'Randomized Clinical Trials', 'Randomized Controlled Trials', 'Regimen', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Resistance', 'Self Management', 'Speed', 'Staging', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Torque', 'Training', 'Universities', 'Visit', 'Walking', 'Wireless Technology', 'arm', 'base', 'conditioning', 'cost', 'data acquisition', 'design', 'disability', 'falls', 'fitness', 'improved', 'insight', 'instrument', 'mHealth', 'meetings', 'novel', 'post stroke', 'programs', 'randomized trial', 'remote sensing', 'remote sensor', 'secondary outcome', 'sensor', 'skills', 'spatiotemporal', 'stroke rehabilitation', 'tool', 'treatment as usual', 'wireless network']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2014,362910,-0.02537478100419937
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired     DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering.         PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8704450,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'public health relevance', 'rehabilitation engineering', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2014,51689,0.013829362954416528
"Sign Finding and Reading SFAR on GPU Accelerated Mobile Devices     DESCRIPTION (provided by applicant): The inability to access information on printed signs directly impacts the mobility independence of the over 1.2 million blind persons in the U.S. Many previously proposed technological solutions to this problem either required physical modifications to the environment (talking signs or the placement of coded markers) or required the user to carry around specialized computational equipment, which can be stigmatizing. A recently pursued strategy is to utilize the computational capabilities of smart phones and techniques from computer vision to allow blind persons to read signs at a distance using commercially available, non-stigmatizing, smart- phones. However, despite the fact that sophisticated algorithms exist to recognize and extract sign text from cluttered video input (as evidenced, for example, by mapping services such as Google Maps automatically locating and blurring out only license plate text in street-view maps) current mobile solutions for reading sign text at a distance perform relatively poorly. This poor performance is largely because until recently, smart-phone processors have simply not been able to execute state-of-the-art computer vision text extraction and recognition algorithms at real-time rates, which forced previous mobile sign readers to utilize older, simplistic, less effective algorithms. Next-generation smart-phones run on fundamentally different, hybrid processor architectures (such as the Tegra 4, Snapdragon 800, both released in 2013) with dedicated embedded graphical processing units (GPUs) and multi-core CPUs, which make them ideal for high-performance, vision-heavy computation. In this study, we propose to develop a smart-phone-based system for finding and reading signs at a distance which significantly outperforms previous such readers by implementing state-of-the-art text extraction algorithms on modern smart-phone hybrid GPU/CPU processor architectures. In Phase I, the proposed system will be developed and tested with blind users. In Phase II, feedback from user testing will be integrated into system design and the performance will be improved to permit operation in extremely challenging (such as low light) environments.         PUBLIC HEALTH RELEVANCE: Over 1.2 million people in the US are blind, and lack of safe and independent mobility substantially impacts the quality of life of this population. Printed textual signs, which are ubiquitously used in sighted navigation, are inaccessible to visually impaired persons, and this lack of access to environmental information contributes significantly to the mobility problem. This research would help develop a system whereby blind persons could use commercially available smart-phones to locate and read sign text at a distance.            ",Sign Finding and Reading SFAR on GPU Accelerated Mobile Devices,8779810,R43EY024800,"['Acceleration', 'Access to Information', 'Algorithms', 'Antirrhinum', 'Architecture', 'Back', 'Code', 'Computer Vision Systems', 'Distant', 'Environment', 'Equipment', 'Eye', 'Feedback', 'Hybrids', 'Licensing', 'Light', 'Literature', 'Maps', 'Modification', 'Performance', 'Phase', 'Population', 'Printing', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Research Institute', 'Risk', 'Running', 'SKI gene', 'Self-Help Devices', 'Services', 'Solutions', 'System', 'Techniques', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Vision', 'Visually Impaired Persons', 'assistive device/technology', 'authority', 'base', 'blind', 'design', 'experience', 'handheld mobile device', 'improved', 'next generation', 'operation', 'phase 1 study', 'public health relevance', 'volunteer']",NEI,"LYNNTECH, INC.",R43,2014,229742,0.0030866542671616846
"Providing Access to Appliance Displays for Visually Impaired Users     DESCRIPTION (provided by applicant):  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays.  This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment.  No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents.  Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image.  For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast.  These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view.  Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users.  Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures.  The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software.         PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.",Providing Access to Appliance Displays for Visually Impaired Users,8712492,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype', 'public health relevance']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2014,368560,0.018883558992268814
"Low-Cost, Compact, and Portable Robot for Autonomous Intravenous Access using Nea     DESCRIPTION (provided by applicant): Peripheral venous access is pivotal to a wide range of clinical interventions and is consequently the leading cause of medical injury in the U.S. Complications associated with the procedure are exacerbated in difficult settings, where the rate of success depends heavily on the patient's physiology and the practitioner's experience. My dissertation thesis pertains to the development of imaging and robotic technologies to improve the accuracy and speed of blood draws and IV's. The core technology is an image-guided robotic device that accurately and autonomously introduces a cannula for venous access. The device operates by mapping in real-time the 3D structure of peripheral veins in order to robotically direct a needle into a selected vein. A working prototype has been developed and validated in several studies, the results of which are described in two journal publications. The device combines a 3D near-infrared vein imager, a robot, and computer vision software; these three components form the basis of the three Specific Aims described in this proposal. The Aims fit into the overall dissertation by 1) incorporating the current imaging hardware into a standalone, handheld imaging device; 2) introducing software for the imaging device that assists in selecting suitable cannulation sites; and 3) integrating the imaging device and software with a miniaturized version of the current robot. The outcome of this work will be a compact and low-cost system that is suited for beta-stage development.          PUBLIC HEALTH RELEVANCE: Blood draws and IV therapies are one of the most commonly performed medical routines in hospitals and clinics. Injuries to doctors and patients happen frequently because of how difficult it can be to find veins and accurately insert the needle. We are developing a portable and lightweight medical robot to perform the procedure in situations where the doctor is unable to successfully access the veins. This device may greatly improve the safety and accuracy of venous access, and has wide applications in many clinical areas.            ","Low-Cost, Compact, and Portable Robot for Autonomous Intravenous Access using Nea",8718641,F31EB018191,"['Algorithms', 'Anatomy', 'Area', 'Benchmarking', 'Blood', 'Cannulas', 'Cannulations', 'Catheters', 'Childhood', 'Clinical', 'Clinics and Hospitals', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Cues', 'Custom', 'Development', 'Device Safety', 'Devices', 'Emergency Care', 'Evaluation', 'Failure', 'Goals', 'Graph', 'Healthcare Systems', 'Human', 'Image', 'Imaging Device', 'In Vitro', 'Injury', 'Institutional Review Boards', 'Intervention', 'Intravenous', 'Journals', 'Knowledge', 'Literature', 'Location', 'Maps', 'Medical', 'Motivation', 'Needles', 'Neonatal', 'Outcome', 'Patients', 'Peripheral', 'Physiology', 'Pilot Projects', 'Population', 'Population Sizes', 'Positioning Attribute', 'Procedures', 'Publications', 'Reporting', 'Robot', 'Robotics', 'Safety', 'Site', 'Speed', 'Sprague-Dawley Rats', 'Staging', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Veins', 'Venous', 'Visual', 'Weight', 'Work', 'arm', 'base', 'cost', 'design', 'experience', 'improved', 'in vivo', 'meetings', 'miniaturize', 'pre-clinical', 'prototype', 'public health relevance', 'robotic device', 'skeletal', 'success', 'three dimensional structure', 'three-dimensional modeling', 'tissue phantom', 'visual motor']",NIBIB,"RUTGERS, THE STATE UNIV OF N.J.",F31,2014,34424,0.034042694605892994
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.        PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.               ",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,8628880,R01NS066340,"['Algebraic Geometry', 'Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Geometry', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2014,494546,0.015645407738127715
"Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance     DESCRIPTION (provided by applicant): The neuromuscular disorders include a wide group of conditions ranging from relatively mild focal problems, such as carpal tunnel syndrome, to severe, generalized diseases, such as amyotrophic lateral sclerosis (ALS). Current methods for evaluating these disorders remain limited to a variety of tests and procedures that are either invasive or remarkably qualitative in nature. One newer technique, electrical impedance myography (EIM), offers the prospect of obtaining quantitative data on muscle condition painlessly and non-invasively. However, no commercial devices specifically tailored for EIM use exist, with nearly all previous EIM work relying upon off-the-shelf bioimpedance devices designed for ""whole-body"" rather than single-muscle assessment. In Phase 1 of this SBIR, Convergence Medical Devices, Inc (CMD) developed an initial prototype system to test proof-of-principle innovative concepts in circuit design and data acquisition to provide highly sensitive and accurate data at an extended frequency range (out to 10 MHz) and over multiple angles relative to the major muscle fiber direction. This work was followed by supplemental work that produced the first hand-held device with robust electronics capable of similar measurements with a detachable, interchangeable electrode array. In this 3-year Phase 2 SBIR, CMD proposes to further refine that technology so as to assist in disease diagnosis and for following disease progression, with a specific focus on amyotrophic lateral sclerosis. In Aim 1 of the proposed grant, testing of multiple electrode array designs will be performed on a group of normal subjects and those with ALS to determine which electrode array designs offer the greatest reproducibility and ability to discriminate healthy from diseased individuals. In Aim 2, the device and the 3 ""best"" array designs identified in Aim 1 will be tested in 30 ALS patients, 30 patients with syndromes mimicking ALS (e.g., polyradiculopathy and motor-predominant neuropathy), and 30 subjects with suspected/possible ALS to determine the single best array design for diagnosis and to determine its sensitivity and specificity. This study will take place at CMD and four external sites and will be managed by the Northeast ALS trials Consortium (NEALS), the premier organization for overseeing clinical trials in ALS. In Aim 3, the 30 suspected/possible ALS patients recruited in SA2 and 30 additional suspected/possible ALS patients will be assessed monthly using EIM and the 3 arrays identified in SA1. All subjects will also undergo standard measurements of disease progression including handheld dynamometry, ALS Functional Rating Scale, and spirometry. The best array design for assessing disease progression will be identified and compared to conventional markers of disease progression to determine EIM's sensitivity to disease status. Thus, at the conclusion of this research program, we anticipate having developed and vigorously tested an EIM device and associated electrode designs that together will serve as a powerful new diagnostic and monitoring tool for neuromuscular disease.          The neuromuscular disorders are a group of conditions that impact the lives of millions of people in the United States alone. In this study, Convergence Medical Devices, in collaboration with neurologists at several medical centers, will develop and test a new device based on the concept of electrical impedance myography, a technique that offers the promise of rapid and accurate disease assessment. With the completion of this study, a new, painless tool will be developed and studied that will assist in individual patient care and will speed drug testing in clinical trials in diseases ranging from amyotrophic lateral sclerosis and muscular dystrophy to radiculopathy and polyneuropathy.            ",Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance,8650344,R44NS070385,"['Amyotrophic Lateral Sclerosis', 'Area', 'Biological Markers', 'Biopsy', 'Businesses', 'Carpal Tunnel Syndrome', 'Clinical', 'Clinical Trials', 'Collaborations', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Electrodes', 'Electromyography', 'Electronics', 'Entrapment Neuropathies', 'Frequencies', 'Future', 'Genetic', 'Goals', 'Grant', 'Individual', 'Limb structure', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Measures', 'Medical Device', 'Medical center', 'Methods', 'Monitor', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Fibers', 'Muscular Dystrophies', 'Myography', 'Nature', 'Needles', 'Neurologist', 'Neuromuscular Diseases', 'Neuropathy', 'Outcome', 'Painless', 'Patient Care', 'Patients', 'Phase', 'Physicians', 'Polyneuropathy', 'Polyradiculopathy', 'Procedures', 'Radiculopathy', 'Recruitment Activity', 'Relative (related person)', 'Reproducibility', 'Research', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Spirometry', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Clinical Trial', 'Time', 'United States', 'Widespread Disease', 'Work', 'base', 'clinical care', 'commercial application', 'data acquisition', 'design', 'diagnosis design', 'disease diagnosis', 'drug testing', 'electric impedance', 'improved', 'indexing', 'innovation', 'muscle strength', 'muscular structure', 'neuromuscular', 'novel diagnostics', 'programs', 'prototype', 'pulmonary function', 'tool', 'validation studies']",NINDS,"MYOLEX, INC.",R44,2014,536206,0.019421392910925497
"Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics    DESCRIPTION (provided by applicant): Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Often the disability is so severe that it is not possible to feed oneself or readily communicate. A new class of medical system termed brain-machine interfaces (BMIs) has emerged from research labs in the past decade and is now poised to dramatically improve these patients' quality of life. BMIs ""read out"" neural electrical activity directly from motor structures in the brain and decode these electrical impulses in order to determine the intended movement. Initial versions of BMI systems that control a computer cursor are now in FDA Phase-I clinical trials, and numerous agencies are actively engaged in clinical translation (e.g., NIH, DARPA, VA). Creating control signals to enable an amputee to feed himself with a prosthetic (robotic) arm and hand will require decoding signals from thousands of electrodes, rather than the hundred or so signals current systems read, as well as encoding thousands of sensor signals from the arm and hand into thousands of artificial neural signals to be ""written into"" the brain, which has not yet been attempted. The lack of low-power (so that it can be implanted) electronic circuitry needed to run BMIs' encoding and decoding algorithms (termed codecs) is a fundamental barrier to successful clinical translation. The technologies available until now are too power-hungry (digital) or too algorithmically inflexible (analog) to meet the challenge. Recent advances in neuromorphic engineering make it now possible to build a fully implantable and programmable codec chip. This innovative approach combines digital's and analog's best features-programmability and efficiency-while offering far greater robustness than either. Meanwhile recent advances in neuroscience techniques make it now possible to obtain the knowledge needed to design the right algorithms to run on our codec chip. Optogenetic stimulaton can now be used to drive neurons in macaque cortex and computer vision can now be used to track freely moving monkeys while recording wirelessly. We propose to leverage these recent advances to dramatically increase prosthetic performance through the principled design of: (1) An entirely new class of encoders that can spatio-temporally pattern neural activity via optogenetic techniques. (2) An entirely new class of decoders that can operate in the real world with animals moving freely around in far less constrained settings. (3) An entirely new class of implantable programmable electronics that achieves the level of energy- efficiency required to run these complex algorithms. We will demonstrate our success by having a freely moving primate, with a 96-microelectrode recording array and a 9-channel optogenetic stimulator implanted in its premotor and somatosensory cortex, respectively, control a human-like robotic arm. Our ultimate goal is to realize the neuromorphic engineer's dream: Helping untold millions with neurological injury by replacing damaged neural tissue with chips that work like the brain.           Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Brain-machine interfaces (BMIs) ""read out"" neural electrical activity directly from motor structures in the brain and decodes these signals in order to execute the intended movement with a robotic arm. This project seeks to increase BMI performance dramatically by leveraging recent advances in systems neuroscience and neuromorphic engineering.                                ",Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics,8658487,R01NS076460,"['Address', 'Adopted', 'Algorithms', 'Amplifiers', 'Amputees', 'Animals', 'Axon', 'Behavioral', 'Brain', 'Budgets', 'Clinical', 'Clinical Paths', 'Cochlea', 'Complex', 'Computer Vision Systems', 'Computers', 'Disabled Persons', 'Dreams', 'Electrodes', 'Electronics', 'Engineering', 'Goals', 'Hand', 'Human', 'Impairment', 'Implant', 'Knowledge', 'Macaca', 'Medical', 'Microelectrodes', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Neurons', 'Neurosciences', 'Patients', 'Performance', 'Phase I Clinical Trials', 'Primates', 'Prosthesis', 'Quality of life', 'Reading', 'Research', 'Robotics', 'Running', 'Sensory', 'Signal Transduction', 'Silicon', 'Solutions', 'Somatosensory Cortex', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Translating', 'Translations', 'United States National Institutes of Health', 'Walking', 'Work', 'Writing', 'analog', 'arm', 'base', 'brain machine interface', 'cranium', 'design', 'digital', 'disability', 'feeding', 'grasp', 'improved', 'innovation', 'interest', 'meetings', 'millisecond', 'nervous system disorder', 'neural patterning', 'neural prosthesis', 'optogenetics', 'relating to nervous system', 'research study', 'sensor', 'sensory cortex', 'spatiotemporal', 'success']",NINDS,STANFORD UNIVERSITY,R01,2014,874214,0.029013752914225463
"Development of a Centralized Intelligence and Control AP Hub Device ﻿    DESCRIPTION (provided by applicant):  Despite major advances in pharmaceuticals and medical device technology, the ability to safely and effectively control blood glucose in patients with Type 1 diabetes has remained a recalcitrant challenge and a significant source of human suffering and economic cost. With the advent of continuous glucose monitoring (CGM), increasing effort has been focused on the development of artificial pancreas (AP) systems using CGM coupled with insulin pump via closed-loop control (CLC) algorithms. Integration of these disparate technologies and implementation in a commercial product has faced numerous challenges to date. TypeZero Technologies' objective is the commercialization of the robust and extensively tested Diabetes Assistant (DiAs) software platform and supporting technology into a commercial-grade device ""hub"" designed to organize and control a network of medical devices for the improved management of blood glucose in the context of Type 1 diabetes. The DiAs prototype has been extensively tested to date, and has generated over 24,000 hours of on- patient data. In numerous clinical trials, this technology has reduced dramatically the frequency of occurrence of severe hyper- and hypoglycemic events, reduced glycemic variability and improved patient's ""time-in-range"" (rate of euglycemia). DiAs and supporting technologies represent the core elements of a radically different treatment paradigm that integrates and maximizes the capabilities of existing and currently approved medical devices with a proprietary software platform and control technologies. The key characteristics of the TypeZero hub are:  "" Modular hub functionality residing optionally within and across available networked devices including the  patient's pump, meter, CGM, smartphone, or within cloud services;  "" Ability to accommodate any control strategy that is deemed optimal for a specific patient;  "" Inherently layered architecture, designed with an upward pathway of sequential module deployment;  "" Inherent safety, featuring a downward pathway of graceful degradation to a known system state in the  event of component failure; and  "" Local and Global modes of operation enabling the availability of certain processes and patient  interaction through the portable device; other services and remote monitoring of subject and system  state are available via telecommunication (e.g. 3G, WiFi, etc.). We envision that in the near future consumer electronics hardware equipped with appropriate software (e.g. DiAs) would gradually replace specialized CGM receivers or insulin pump controllers, merging into a single ultra-portable platform the functions of continuous monitoring, insulin delivery, and closed-loop control. In the near-term, we envision creating a dedicated hub controller that will host key functionalities of artificial pancreas as a critical step toward the future.     PUBLIC HEALTH RELEVANCE: The persistent challenge of safely and effectively managing blood glucose levels in the context of Type 1 diabetes indicates the inadequacy of currently approved and available medical device technologies. Artificial pancreas approaches to algorithm-based control of medical devices for improved patient safety and outcomes has been an active area of research for many years. TypeZero Technologies seeks to commercialize a proprietary suite of technologies that have been developed and extensively tested in clinical trial settings and shown to deliver significant improvements in safety and efficacy. The successful development of TypeZero's hub device will represent a novel integration of capabilities that will dramatically accelerate the commercial availability of artificial pancreas technologies.        ",Development of a Centralized Intelligence and Control AP Hub Device,8823176,R43DK104293,"['Adverse event', 'Algorithms', 'Architecture', 'Area', 'Artificial Pancreas', 'Blood Glucose', 'Carbohydrates', 'Cardiovascular system', 'Caring', 'Characteristics', 'Clinical', 'Clinical Trials', 'Communication', 'Complex', 'Computer software', 'Continuous Infusion', 'Contracts', 'Coupled', 'Data', 'Databases', 'Development', 'Devices', 'Diabetes Mellitus', 'Diagnostic', 'Drug Kinetics', 'Electronics', 'Elements', 'Environment', 'Event', 'Exercise', 'Exogenous Factors', 'Failure', 'Focus Groups', 'Frequencies', 'Future', 'Goals', 'Health Care Costs', 'Health Insurance Portability and Accountability Act', 'Hour', 'Human', 'Hyperglycemia', 'Hypoglycemia', 'Incidence', 'Insulin', 'Insulin Infusion Systems', 'Insulin-Dependent Diabetes Mellitus', 'Intelligence', 'Judgment', 'Kidney Failure', 'Licensing', 'Life', 'Machine Learning', 'Manufacturer Name', 'Medical Device', 'Metabolism', 'Modeling', 'Monitor', 'Neuropathy', 'Outcome', 'Pathway interactions', 'Patient Monitoring', 'Patients', 'Pharmacologic Substance', 'Phase', 'Phase II Clinical Trials', 'Preparation', 'Procedures', 'Process', 'Protocols documentation', 'Provider', 'Pump', 'Quality of life', 'Replacement Therapy', 'Research', 'Retinal Diseases', 'Running', 'Safety', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Solutions', 'Source', 'Supervision', 'System', 'Technology', 'Telecommunications', 'Telemedicine', 'Testing', 'Time', 'Transition Elements', 'Uncertainty', 'Universities', 'Virginia', 'Wireless Technology', 'base', 'cloud based', 'commercialization', 'design', 'economic cost', 'experience', 'glucose monitor', 'glucose sensor', 'glycemic control', 'graphical user interface', 'improved', 'meter', 'middleware', 'monitoring device', 'novel', 'operation', 'patient safety', 'prototype', 'public health relevance', 'safety testing', 'subcutaneous']",NIDDK,"TYPEZERO TECHNOLOGIES, LLC",R43,2014,224354,0.007496748140347561
"Context Understanding Technology to improve internet accessibility for users with DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a  web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization. PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.",Context Understanding Technology to improve internet accessibility for users with,8609036,R44EY020082,"['Advertisements', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Grouping', 'Health', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2014,357073,0.013896510479965237
"Multi-scale network dynamics of human upper limb movements: characterization and DESCRIPTION (provided by applicant): The overall project goals are to study the cortical network dynamics of human upper limb motor control spanning two distinct spatial scales recorded with electrocorticography (ECoG), and to demonstrate that these dynamics can be estimated in real-time and used to control the JHU Applied Physics Lab Modular Prosthetic Limb (MPL) during execution of functionally useful complex action sequences. Our human subjects will be instructed to perform complete functional movements characteristic of activities of daily living. We will analyze the task-related temporal evolution in the strength and pattern o interactions among large-scale cortical networks known to be recruited in visually-guided reach-to-grasp tasks. Using multi-scale subdural ECoG with combinations of routine clinical macro-electrodes (2.3 mm diameter, 1 cm spacing) recording activity of broadly spread elements/nodes of neural networks, and inset arrays of microelectrodes (75 μm diameter, 0.9 mm spacing) recording the activity of local sub-networks, we will test our overall hypothesis that there is a functional hierarchy between the two scales (Aim 1). More specifically, we hypothesize that large-scale network dynamics involving premotor/motor cortex reflect the evolution of sensory-motor processing demands during complex action sequences, while micro-scale population activity and network dynamics in motor cortex reflect the low-level kinematics of these tasks. We will utilize methods of estimating dynamic effective connectivity developed by our team to study interactions between these scales and test whether there exists a spatially heterogeneous and hierarchical structure within the macro-micro scale networks. The results of these analyses have wide-ranging clinical implications for both the optimal scale of functional mapping for clinical diagnostic purposes and the extent of implantations for neuroprosthetic control. We will exploit multi-scale ECoG recordings and online estimates of the dynamics of neural activation and large-scale/local network interactions to achieve control of the MPL during functionally useful tasks (Aim 2). This approach will go beyond traditional paradigms that have developed neural control over individual degrees of freedom. We will do this by embedding low-level control within an innovative framework whereby knowledge of task goals supplement direct kinematic decoding. This project will build on our team's previous successes in implementing a system for semi-autonomous ECoG control of the MPL, employing machine vision and route-planning algorithms, during complex interactions with objects requiring the coordination of multiple joints. This system will be able to leverage for the first time the rich complexity of temporally and spatially resolved network dynamics correlated with high-level goals to achieve functionally useful control of an advanced neuroprosthetic limb. PUBLIC HEALTH RELEVANCE: For ""Multi-scale network dynamics of human upper limb movements: characterization and translation in neuroprosthetics"" This project will use recordings from the surface of the human brain to study how brain networks control arm and hand movements. We will also test whether information about these networks can be used to control an advanced robotic prosthetic arm. This could have a profound long-term impact on future generations of patients seeking to restore lost upper limb function with a lifelike prosthesis.",Multi-scale network dynamics of human upper limb movements: characterization and,8764874,R01NS088606,"['Activities of Daily Living', 'Algorithms', 'Area', 'Attention', 'Biological Neural Networks', 'Brain', 'Caliber', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complex', 'Computer Vision Systems', 'Cues', 'Diagnostic', 'Eating', 'Electrocorticogram', 'Electrodes', 'Elements', 'Epilepsy', 'Evolution', 'Freedom', 'Future Generations', 'Goals', 'Hand', 'Health', 'Human', 'Individual', 'Joints', 'Knowledge', 'Limb structure', 'Location', 'Maps', 'Measures', 'Mediating', 'Methods', 'Microelectrodes', 'Modeling', 'Modification', 'Motor', 'Motor Cortex', 'Movement', 'Neurosciences', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Performance', 'Physics', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Process', 'Prosthesis', 'Recruitment Activity', 'Resolution', 'Robotics', 'Route', 'Sampling', 'Sensory', 'Signal Transduction', 'Site', 'Staging', 'Structure', 'Surface', 'System', 'Testing', 'Time', 'Training', 'Translations', 'Upper Extremity', 'Upper limb movement', 'Vision', 'arm', 'drinking', 'grasp', 'human subject', 'implantation', 'innovation', 'joint mobilization', 'kinematics', 'motor control', 'neuroprosthesis', 'neuroregulation', 'relating to nervous system', 'success', 'time use']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2014,354375,0.015124937798913225
"Smart Anatomic Recognition System to Guide Emergency Intubation and Resuscitation     DESCRIPTION (provided by applicant): Over 3 million emergency intubations are performed in the US every year and failure rates can be as high as 50% (3-5). Success is highly dependent on how frequently the responder performs this life-saving procedure on humans (6). Brio Device, LLC, an airway management medical device company, is addressing the need to decouple the success of the procedure from the experience of the user with their ""smart"" intubation device which integrates anatomic structure recognition algorithms and visual guidance feedback with an articulating stylet. Brio's intubation device is specifically designed fo the needs of emergency responders, such as paramedics, emergency department personnel, code teams in hospitals and military medics, who often arrive at the patient first. The smart intubation device will reduce failure rates by providing the user with visual instruction of the correct path to the trachea as he places the endotracheal tube. The guidance software uses machine learning and computer vision algorithms to recognize the anatomy and determine the path to insert the tube. Ultimately, the intubation device will include both a guidance display on an LCD screen and an optical stylet that has single-axis angulation control of the distal tip. For the purpose of this Phase I study, a laptop or desktop computer will be used for the image processing and the guidance display that accompanies the articulating stylet. The long-term goal is to create a device that is compact, light-weight and portable to suit the needs of ambulances and hospital crash carts.  The hypothesis for this study is that by incorporating a video guidance display with an articulating stylet, inexperienced users will be more successful in correctly placing the endotracheal tube using this device compared to direct laryngoscopy. To achieve this goal, image processing and machine learning algorithms will be developed to recognize key anatomic structures in the airway. Software will also be developed determine the path the tube should follow and to display this information for the user. Finally, the efficacy of the device will be validated in airway simulation mannequins with medical students serving as the inexperienced users. Phase II will focus on integrating the guidance software, articulating optical stylet and display into a portable device with embedded hardware and software contained within the stylet handle. At completion of Phase II, the device will be ready for clinica trials and FDA testing.  Brio will enter the $20 billion airway market with its intubation device. Initial sales will begin with anesthesiologists who are early adopters of new technology to assist with difficult airways. Brio will market its product to ~327,000 clinicians who use intubation devices. The U.S. addressable market for emergency intubation is ~$900M for the 41,000 ambulances and 5,800 emergency departments and hospital code teams.         PUBLIC HEALTH RELEVANCE: In this SBIR Phase I, Brio Device, LLC plans to create and evaluate a device that improves the success rate of emergency intubations by coupling a smart guidance display with a user-controlled single-axis articulating stylet. Emergency intubations are often performed in challenging situations by personnel who do the procedure infrequently. Since failure rates are as high as 50% and approximately 180,000 deaths occur each year from failed pre-hospital intubations, a device is needed to provide visual guidance information to assist the users and increase their success rates in emergency situations.            ",Smart Anatomic Recognition System to Guide Emergency Intubation and Resuscitation,8453607,R43HL114160,"['Accident and Emergency department', 'Address', 'Algorithms', 'Ambulances', 'Anatomic structures', 'Anatomy', 'Brain Death', 'Brain Injuries', 'Cessation of life', 'Clinical Trials', 'Code', 'Computer Vision Systems', 'Computer software', 'Computers', 'Coupling', 'Critical Care', 'Destinations', 'Devices', 'Distal', 'Emergency Situation', 'Failure', 'Feasibility Studies', 'Feedback', 'Goals', 'Hospitals', 'Human', 'Human Resources', 'Image', 'Imagery', 'Instruction', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Laryngoscopy', 'Left', 'Life', 'Light', 'Location', 'Lung', 'Machine Learning', 'Manikins', 'Marketing', 'Medical Device', 'Medical Students', 'Military Hospitals', 'Military Personnel', 'Optics', 'Outcome', 'Outcome Measure', 'Oxygen', 'Paramedical Personnel', 'Patients', 'Phase', 'Physicians', 'Procedures', 'Resuscitation', 'Sales', 'Small Business Innovation Research Grant', 'Structure', 'System', 'Testing', 'Time', 'Trachea', 'Tube', 'Visual', 'commercial application', 'design', 'endotracheal', 'experience', 'flexibility', 'image processing', 'improved', 'information display', 'laptop', 'light weight', 'new technology', 'novel', 'phase 1 study', 'public health relevance', 'secondary outcome', 'simulation', 'success']",NHLBI,"BRIO DEVICE, LLC",R43,2013,244710,0.021817655845326286
"CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation Interacting with the physical environment and manipulating objects is an essential part of daily life. This ability is lost in upper-limb amputees as well as patients with spinal cord injury, stroke, ALS and other movement disorders. These people know what they want to do as well as how they would do it if their arms were functional. If such knowledge is decoded and sent to a prosthetic arm (or to the patient's own arm fitted with functional electric stimulators) the lost motor function could be restored. The decoding is unlikely to be perfect however the brain can adapt to an imperfect decoder using real-time feedback. Several groups including ours have recently demonstrated that at least in principle this can be achieved. However, as is often the case in science, the initial work has been done in idealized conditions and its applicability to real-world usage scenarios remains an open question. The goal of this project is to bring movement control brain-machine interfaces (BMIs) closer to helping the people who need them, and at the same time exploit the rich datasets we collect in order to advance our understanding of sensorimotor control and learning. This will be accomplished by creating hybrid BMIs which exploit information from multiple sources, combined with modern algorithms from machine learning and automatic control. RELEVANCE (See instructions): Being able to interact with the physical environment and manipulate objects is an essential part of daily life. Brain-machine interfaces are one way to restore this ability to patients who have lost it. The proposed project will bring brain-machine interfaces closer to helping patients in real-worid object manipulation tasks.  n/a",CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8507287,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2013,240369,0.0002943081743665986
"A Software Platform for Sensor-based Movement Disorder Recognition     DESCRIPTION (provided by applicant): The overall objective of this SBIR project is to develop a pre-commercial prototype system capable of continuously monitoring involuntary movement disorders from a wide spectrum of neurological conditions. The impact of this innovation will enhance the availability of advanced brain and behavior research tools [PA- 11-134] by providing a continuous means of tracking the presence and severity of movement disorders during normal daily activities. This project will transform our unique movement disorder recognition algorithms into custom software that analyzes movement disorders for specific neurological conditions. The information obtained from body worn sensors will provide an accurate and objective means for assessing the complex and changeable nature of movement disorders. This goal cannot by realized using the current method of self-report questionnaires.  The research strategy for Phase I will establish the merit and feasibility of this effort by developing an Application Generation (AG) software platform using a framework of configurable signal processing modules to generate custom applications for movement disorder analysis (Aim 1). This approach reduces the effort and enhances the flexibility of designing and testing software solutions for these applications. The AG Platform will be developed using C++ software to implement signal processing and machine-learning software modules that operate within a knowledge-based framework that we have previously developed. In Aim 2 we will utilize the AG platform to generate movement disorder analysis software to evaluate a challenging test-case application: freezing-of-gait in Parkinson's disease (PD). The goal is to attain performance metrics for freezing that are comparable to those we have achieved for tremor and dyskinesia in previous efforts.  Phase II will refine the capabilities of the AG platform developed in Phase I. We will augment it with the means to automatically design and train the machine learning algorithms, improve the user-interface, and provide options for viewing and summarizing the results. The improved AG platform will be used to develop customized disorder-analysis software that encompasses the full complement of movement disorders associated with PD (e.g. dystonia, bradykinesia, Parkinsonian gait, tremor, dyskinesia), as well as for other neurological condition, such as Essential Tremor (ET). Firmware will be developed for each custom application to efficiently integrate the analytic software with our existing Trigno wireless sensor data acquisition hardware, which needs to be streamlined for this application. This combined system will be evaluated under research use-case scenarios in Neurology. Phase II will deliver an ambulatory Movement Disorder Monitoring system that not only succeeds in providing state-of-the-art monitoring solutions for PD and Essential Tremor, but has proven technology to develop monitoring solutions for a wide variety of neurological conditions. Future development will transfer this technology to a clinical version of this system.         PUBLIC HEALTH RELEVANCE: The project is intended to improve the accuracy and reduce the burden of researchers and clinicians when assessing motor outcomes for patients with involuntary movement disorders. The proposed technology will provide a means for evaluating new treatment options, and expedite the delivery of care. The attainment of these goals should increase the effectiveness of research, the time required for these research advancements to reach the consumer, and help control the rising costs of clinical care among the estimated 45 million Americans who have neurological disorders resulting in involuntary movements. The resulting improvements in motor function will ultimately lead to greater independence and productivity for this growing segment of the population.            ",A Software Platform for Sensor-based Movement Disorder Recognition,8521782,R43NS083098,"['Affect', 'Algorithms', 'American', 'Bradykinesia', 'Clinical', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Custom', 'Data', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Dystonia', 'Early Diagnosis', 'Essential Tremor', 'Freezing', 'Future', 'Gait', 'Generations', 'Goals', 'Health Care Sector', 'Health Professional', 'Home environment', 'Involuntary Movements', 'Lead', 'Left', 'Lower Extremity', 'Machine Learning', 'Methods', 'Metric', 'Miniaturization', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Neurologic', 'Neurology', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Process', 'Productivity', 'Quality of life', 'Questionnaires', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Severities', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training', 'Tremor', 'Video Recording', 'Wireless Technology', 'Work', 'Writing', 'advanced system', 'base', 'brain behavior', 'care delivery', 'clinical care', 'computerized data processing', 'cost', 'data acquisition', 'design', 'disorder control', 'effectiveness research', 'flexibility', 'human subject', 'improved', 'innovation', 'knowledge base', 'motor disorder', 'nervous system disorder', 'novel therapeutics', 'prototype', 'public health relevance', 'research study', 'response', 'sensor', 'software development', 'tool']",NINDS,"ALTEC, INC.",R43,2013,424766,0.030099701557488326
"Restoring arm and hand motor function with non-invasive spinal stimulation.     DESCRIPTION (provided by applicant):  Of the approximately 10 million people in the US living with paralysis, 15,000 are the result of spinal cord injury each year. The first year of car can range from $322,000-$986,000, with lifetime costs of $1.4-4M for someone injured at 25 years of age. In addition to potentially devastating sensorimotor disturbances, there is a huge financial cost, estimated to be $13.55B in medical care, therapy, and lost productivity nationwide. Until very recently, the recovery from spinal cord injury (SCI) was bleak, with little hope of restoring motor function. To address this we have demonstrated that the physiological state of the spinal circuitry of rats and cats can be modulated with epidural stimulation to generate voluntary limb motor function over a range of speeds, loads, and directions, a finding we have extended to humans. Three years post-injury, a motor complete spinal cord injured human subject was implanted with an epidural electrode array over the lumbosacral spinal cord. In less than one month after implantation, the subject could stand independently, and after 7 months of daily epidural stimulation and motor training, voluntary control of both legs was evident in the presence of epidural stimulation, whereas complete paralysis remained in absence of epidural stimulation. We will advance these discoveries with the use of non-invasive stimulation of the cervical cord to improve arm and hand function following SCI. Central to this proposal is our discovery of a painless electrical single-channel (stimulation of one part of the spinal cord) and dual-channel (stimulation of two different parts of the cord) paradigm that can be applied to the surface of the skin, termed transcutaneous electrical stimulation (TES), bypassing the need for a surgically-implanted electrode array. In the first phase of this proposal we will demonstrate proof-of-principle that stimulation of the cervical spinal cord can improve motor function by: 1) Testing responses to transcutaneous electrical stimulation in subjects with spinal cord injury; and 2) defining the operational parameters of electrical stimulation that that are most effective using a machine-learning protocol, and 3) produce a dual-channel commercial prototype. This commercial product will undergo testing similar to the proof- of-principle device. This device will then be tested in subjects with cervical spinal cord injury and evaluated with a machine-learning protocol. This Phase I proposal will deliver a device that can painlessly and non-invasively aid in the recovery of SCI by delivering a specific electrical stimulation paradigm to the cervical cord that improves use of the arms and hands.         PUBLIC HEALTH RELEVANCE:  Electrical modulation of the spinal cord can restore voluntary motor function in patients with spinal cord injury, a phenomenon we have demonstrated with both implantable electric devices and devices that provide electrical stimulation to the cord through the surface of the skin. Here, we propose to build and test a refined device that stimulates the skin above the spinal cord at two different locations to improve arm and hand motor function in spinal cord injury patients.                ",Restoring arm and hand motor function with non-invasive spinal stimulation.,8591945,R43EB017641,"['Address', 'Age-Years', 'Algorithms', 'Ankle', 'Back', 'Bypass', 'Caring', 'Cervical', 'Cervical spinal cord injury', 'Cervical spinal cord structure', 'Chronic', 'Clinic', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Electric Stimulation', 'Electrodes', 'Felis catus', 'Financial cost', 'Goals', 'Hand', 'Hand functions', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Knee', 'Leg', 'Life', 'Limb structure', 'Location', 'Lower Extremity', 'Lumbar spinal cord structure', 'Machine Learning', 'Measurement', 'Medical', 'Methods', 'Modality', 'Motor', 'Motor Skills', 'Muscle', 'Music', 'Neck', 'Neurostimulation procedures of spinal cord tissue', 'Outpatients', 'Painless', 'Paralysed', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Productivity', 'Protocols documentation', 'Rat-1', 'Rattus', 'Recovery', 'Recruitment Activity', 'Sensory', 'Site', 'Skin', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord Part', 'Spinal cord injury', 'Spinal cord injury patients', 'Stroke', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Toes', 'Training', 'Transcutaneous Electric Nerve Stimulation', 'Translating', 'Upper Extremity', 'Weight-Bearing state', 'arm', 'comparative efficacy', 'design', 'grasp', 'human subject', 'implantation', 'improved', 'improved functioning', 'injured', 'life time cost', 'motor function improvement', 'neuroregulation', 'prototype', 'public health relevance', 'response']",NIBIB,"NEUROENABLING TECHNOLOGIES, INC.",R43,2013,206411,0.053838060622603
"Wrist/Grasp Muscle Activity Patterns for EMG-neural Interface Prosthesis Control     DESCRIPTION (provided by applicant):    Simultaneous wrist/hand control (where a person simultaneously moves his/her wrist while grasping or  releasing), is essential in activities of daiy living, but cannot be performed by amputees using clinical surface  electromyography (sEMG) based neural interfaces (myoelectric control). Transradial amputees, who make up 40% of major amputations (proximal to the wrist), cite simultaneous control as a necessary element to improve upper-limb prostheses. Our long-term goal is to develop a clinically viable EMG-based neural interface for transradial amputees that is suitable for restoring simultaneous control of prosthetic wrist/hand movements.   One proposed method for intuitive simultaneous wrist/hand prosthesis control uses intramuscular EMG  (imEMG) amplitude estimates from multiple agonist/ antagonist forearm muscle pairs to control physiologically  appropriate degrees of freedom DOFs (e.g. flexor digitorum profundus / extensor digitorum control  grasp/release). Known as 'direct control', this approach does not require burdensome levels of machine  learning algorithm training, as is required for experimental sEMG-based simultaneous control methods.  However, this method assumes independently modulated muscle activation patterns for each DOF - that the activation patterns of muscles controlling a DOF (i.e. finger flexors/extensors for grasp/release) do not change when a second DOF is simultaneously attempted (simultaneous pronation/supination and grasp/release). The biologic foundation of such an assumption has not been explored to date. Little is known of how the central nervous system (CNS) coordinates wrist and extrinsic hand muscle activation when independent of biomechanical effects and joint position feedback. Muscle activation patterns under such conditions are particularly relevant to amputee populations, who lack distal joints. Therefore, the objective of this research is to better understand how the CNS coordinates muscle activation patterns in healthy individuals to produce simultaneous wrist/grasp torques when independent of the biomechanical effects of joint movement. We will then apply this information to develop an imEMG simultaneous myoelectric prosthesis controller.  imEMG patterns will be measured as healthy subjects produce single-DOF and simultaneous multi-DOF (SMD) wrist and/or grasp/release torques in isometric, neutral posture conditions. Multivariate models predicting imEMG activity from measured wrist/grasp torques will be developed and will suggest which DOFs have independently modulated muscle activation patterns. This information will then allow for the development of a 'biologically-inspired' simultaneous controller. DOFs with independently modulated muscle activation patterns will be controlled using direct control, while experimental pattern recognition algorithms currently used for sEMG-based simultaneous control will be used for all other DOFs. We will evaluate the performance of this hybrid controller in healthy subjects both offline and using online functional tests in a virtual environment.            PUBLIC HEALTH RELEVANCE:    Various current prosthetic arms use the electrical signals produced when muscles contract to control prosthesis movement, but cannot provide simultaneous control of both the wrist and the hand. This study will investigate how the nervous system activates muscles to simultaneously control the wrist and hand in healthy individuals. This information can then be used to provide clinically viable methods of controlling simultaneous wrist and hand movements of prostheses to amputees.                 ",Wrist/Grasp Muscle Activity Patterns for EMG-neural Interface Prosthesis Control,8526724,F31NS083166,"['Activities of Daily Living', 'Agonist', 'Algorithms', 'Amputation', 'Amputees', 'Anatomy', 'Biological', 'Biomechanics', 'Clinical', 'Contracts', 'Data', 'Development', 'Distal', 'Educational Status', 'Electromyography', 'Elements', 'Environment', 'Feedback', 'Fingers', 'Flexor', 'Forearm', 'Foundations', 'Freedom', 'Goals', 'Hand', 'Human', 'Hybrids', 'Individual', 'Intramuscular', 'Isometric Exercise', 'Joints', 'Knowledge', 'Life', 'Limb Prosthesis', 'Limb structure', 'Literature', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Movement', 'Muscle', 'Muscle Contraction', 'Myoelectric prosthesis', 'Nervous system structure', 'Neuraxis', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Persons', 'Population', 'Positioning Attribute', 'Posture', 'Pronation', 'Prosthesis', 'Rehabilitation therapy', 'Research', 'Residual state', 'Signal Transduction', 'Supination', 'Surface', 'Testing', 'Torque', 'Training', 'Upper Extremity', 'Work', 'Wrist', 'arm', 'base', 'design', 'extensor digitorum', 'grasp', 'improved', 'joint mobilization', 'public health relevance', 'relating to nervous system', 'success', 'virtual']",NINDS,NORTHWESTERN UNIVERSITY,F31,2013,47232,0.024019632288791698
"A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI  A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI NeuroEnabling Technologies, Inc. RESEARCH & RELATED Other Project Information 7. PROJECT SUMMARY Of the approximately 10 million people in the US living with paralysis, 15,000 are the result of spinal cord injury each year. The first year of care can range from $322,000-$986,000, with lifetime costs of $1.4-4M for someone injured at 25 years of age. In addition to potentially devastating sensorimotor disturbances, there is a huge financial cost, estimated to be $13.55B in medical care, therapy, and lost productivity nationwide. Until very recently, the recovery from spinal cord injury (SCI) was bleak, with little hope of restoring motor function. To address this we have demonstrated that the physiological state of the spinal circuitry of rats and cats can be modulated with epidural stimulation to generate voluntary limb motor function over a range of speeds, loads, and directions, a finding we have extended to humans. Three years post-injury, a motor complete spinal cord injured human subject was implanted with an epidural electrode array over the lumbosacral spinal cord. In less than one month after implantation, the subject could stand independently, and after 7 months of daily epidural stimulation and motor training, voluntary control of both legs was evident in the presence of epidural stimulation, whereas complete paralysis remained in absence of epidural stimulation. We will advance these discoveries with the use of non-invasive stimulation of the lumbosacral cord to improve lower limb function following SCI. Central to this proposal is our discovery of a painless electrical multi-channel (stimulation of multiple parts of the spinal cord) theranostic tool that can be applied to the surface of the skin, termed transcutaneous spinal cord electrical stimulation (TESCS), bypassing the need for a surgically-implanted electrode array. In the first phase of this proposal we will demonstrate proof-of-principle that stimulation of the lumbosacral spinal cord can assess spared spinal motor function by: 1) Testing responses to transcutaneous electrical stimulation in subjects with spinal cord injury; and 2) defining the operational parameters of electrical stimulation that that are most effective using a machine-learning protocol, and 3) produce a multi-channel commercial prototype. This commercial product will undergo testing similar to the proof-of- principle device. This device will then be tested in subjects with cervicothoracic spinal cord injury and evaluated with a machine-learning protocol. This Phase I proposal will deliver a device that can painlessly and non-invasively aid in the assessment and recovery of SCI by delivering a specific electrical stimulation paradigm to the lumbosacral cord that improves use of the lower limbs. PUBLIC HEALTH RELEVANCE: A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI NeuroEnabling Technologies, Inc. PROJECT NARRATIVE It now seems possible to apply three interventions: transcutaneous stimulation, administration of pharmacological agents, and motor training, to assess and enable the excitability of spared neural circuits in humans with a thoracic spinal cord injury (SCI), thus enabling these individuals to regain use of their legs. This enabling effect is similar to that observed with improved postura and locomotor function after a mid-thoracic SCI in which epidural stimulation was used. We will build and demonstrate a multi-channel transcutaneous electrical spinal cord stimulation theranostic tool that we propose will allow assessment and enabling of lower limb function following a cervicothoracic spinal cord injury.                ",A Theranostic Tool to Assess and Enable Spared Spinal Motor Function After SCI,8648234,R43EB018232,"['Address', 'Age-Years', 'Algorithms', 'American', 'Ankle', 'Bypass', 'Caring', 'Cervical', 'Cervical spinal cord injury', 'Chest', 'Chronic', 'Clinic', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Diagnosis', 'Diagnostic', 'Electric Stimulation', 'Electrodes', 'Enrollment', 'Evaluation', 'Felis catus', 'Financial cost', 'Goals', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Joints', 'Knee', 'Leg', 'Life', 'Limb structure', 'Lower Extremity', 'Lumbar spinal cord structure', 'Machine Learning', 'Measurement', 'Medical', 'Modality', 'Motor', 'Movement', 'Nervous System Physiology', 'Neurologic', 'Neurostimulation procedures of spinal cord tissue', 'Outpatients', 'Painless', 'Paralysed', 'Paraplegia', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physiological', 'Productivity', 'Protocols documentation', 'Rattus', 'Recovery', 'Residual state', 'Site', 'Skin', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord Part', 'Spinal Injuries', 'Spinal cord injury', 'Spinal cord injury patients', 'Stroke', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Transcutaneous Electric Nerve Stimulation', 'Translating', 'Upper Extremity', 'Weight-Bearing state', 'design', 'human subject', 'human subject protection', 'implantation', 'improved', 'improved functioning', 'injured', 'life time cost', 'meetings', 'motor control', 'motor function improvement', 'neural circuit', 'neuroregulation', 'prototype', 'public health relevance', 'response', 'theranostics', 'tool', 'transcutaneous stimulation']",NIBIB,"NEUROENABLING TECHNOLOGIES, INC.",R43,2013,346207,0.04402790375714625
"Electrocorticography signals for human hand prosthetics    DESCRIPTION (provided by applicant):  Neurological injury (such as from stroke, traumatic brain injury, and spinal cord injury) is a major cause of permanent disability.  Recent advances in the field of neuroprosthetics hold enormous potential for the development of brain-computer interfaces to restore neurological function.  This project will lead to a system that can control a robotic hand using recordings from the surface of the brain.  Interfaces based directly from brain signals may allow for direct decoding of control signals for maximally efficient prosthetics.  This project, a collaboration between neurosurgery, computer science, and physics departments, will explore the brain signals underlying hand movement using electrocorticography, or ECoG.  We have previously shown that high frequency (>75Hz) components of the ECoG carry information about local brain activity.  In the first aim, we will expand our understanding of the high-frequency signal components that correlate with individual finger movements.  We will extract broadband changes in ECoG from non-specific alpha and beta rhythms using PCA and enhance finger classification with machine learning algorithms.  In the second aim, we will look for control signals reflecting different hand functions, rather than movement of different fingers.  For instance, we will examine if pinch and grasp behaviors give more separable high- frequency ECoG signals.  We will also examine the behavior of these movements at higher spatial resolution.  In the third aim, we will measure ECoG changes associated with imagined movement and how these changes are altered with visual feedback when applied to a robotic hand.  In the final aim, we will add tactile feedback to the control to optimize ECoG-based control of a hand prosthesis.  By increasingly advancing the complexity of the control signal, and the complexity of the robotic hand output, we will establish if ECoG is a viable source of control signal for a hand neuroprosthetic device.       PUBLIC HEALTH RELEVANCE:  The development of a hand neuroprosthetic, or artificial device that interacts with the nervous system could restore function to those afflicted by stroke, brain injury, spinal cord injury, or neurodegenerative diseases that have damaged the use of a hand or arm.  This project examines whether signals recorded directly from the human brain (during surgery for epilepsy) could be used to control a robotic hand.            ",Electrocorticography signals for human hand prosthetics,8448702,R01NS065186,"['Algorithms', 'Alpha Rhythm', 'Animals', 'Area', 'Behavior', 'Behavioral', 'Beta Rhythm', 'Brain', 'Brain Injuries', 'Classification', 'Collaborations', 'Coupling', 'Degenerative Disorder', 'Development', 'Devices', 'Digit structure', 'Dimensions', 'Disease', 'Distant', 'Electrocorticogram', 'Electrodes', 'Epilepsy', 'Feedback', 'Fingers', 'Frequencies', 'Future', 'Hand', 'Hand functions', 'Human', 'Image', 'Imagery', 'Individual', 'Lead', 'Left', 'Life', 'Limb structure', 'Machine Learning', 'Measures', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Physiology', 'Nervous System Trauma', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurologic', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Penetration', 'Phase', 'Physics', 'Population Dynamics', 'Positioning Attribute', 'Prosthesis', 'Resolution', 'Robotics', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Stroke', 'Surface', 'Survivors', 'System', 'Tactile', 'Technology', 'Thumb structure', 'Training', 'Traumatic Brain Injury', 'Upper Extremity', 'Visual', 'Work', 'arm', 'base', 'brain computer interface', 'brain machine interface', 'computer science', 'disability', 'functional restoration', 'grasp', 'improved', 'indexing', 'limb movement', 'neurosurgery', 'public health relevance', 'tool', 'visual control', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2013,311136,0.022265898908949453
"Enabling forelimb function with agonist drug and epidural stimulation in SCI     DESCRIPTION (provided by applicant):  We have demonstrated that the physiological state of the lumbosacral spinal circuitry of spinal rats and cats can be modulated with spinal cord epidural stimulation (EDS) and/or administration of pharmacological agents to generate weight-bearing standing and stepping over a range of speeds, loads, and directions.  We have translated some of these results to humans by implanting 3 motor complete spinal cord injured (SCI) subjects about three years post-injury with an epidural electrode array over the lumbosacral spinal cord.  In less than one month post-electrode implant, the subjects could stand independently, and after up to 7 months of daily EDS and motor training, voluntary control of both legs was evident in the presence of EDS, whereas complete paralysis remained in absence of EDS.  We propose to employ a similar stimulation strategy for the recovery of upper limb function.  We will include extensive testing of spinal rats to guide our strategy to test for upper extremity improvement in human SCI subjects.  We will use off-the-shelf FDA approved pharmacological and stimulation modalities to:  1) Determine the optimal stimulation parameters, i.e., electrode placement and stimulation intensity, frequency and duration, for facilitating forelimb fine motor function in rats with a cervical SCI.  Using existing FDA-approved epidural electrodes, we will demonstrate in patients with a cervical SCI that cervical EDS can facilitate arm-hand function.  2) Identify an effective mode of administration, define the dose- response pharmacokinetics, and determine the effectiveness of a monoaminergic agonist to facilitate upper limb function after a cervical SCI.  We will assess the effectiveness of existing FDA-approved pharmacological agents (i.e., buspirone and as an alternative, bromocriptine), and determine their effectiveness in improving forelimb control in subjects with a cervical SCI.  3) Define the dose-response properties of monoaminergic agonists when combined with EDS in facilitating forelimb function in rats after a cervical SCI.  We will demonstrate the efficacy of ES in combination with a pharmacological intervention in facilitating arm and hand function in humans after a cervical SCI.  4) Determine whether motor training of spinal rats will further enhance the recovery of motor function when combined with pharmacological and/or EDS interventions.  5) Develop a protocol for machine learning to enable rapid selection of the optimal pharmacological and EDS parameters for motor recovery in rats and in human subjects.  If successful, this could represent the beginning of a paradigm shift in the use of minimally invasive strategies combined with rehabilitative approaches to realize significant improvement in upper limb function after paralysis.         PUBLIC HEALTH RELEVANCE:  It now seems possible to apply three interventions (epidural stimulation, administration of pharmacological agents, and motor training) to control the excitability of localized neural circuits in humans with a cervical spinal cord injury (SCI), thus enabling these individuals to regain use of their arms and hands.  This enabling effect is similar to that observed with improved postural and locomotor function after a mid-thoracic SCI.  We will reach critical milestones that will provide the basis for a series of clinical trials for furter defining the efficacy of these interventions.                ",Enabling forelimb function with agonist drug and epidural stimulation in SCI,8507061,U01EB015521,"['Agonist', 'Algorithms', 'Ankle', 'Bromocriptine', 'Buspirone', 'Cervical', 'Cervical spinal cord injury', 'Cervical spinal cord structure', 'Chronic', 'Clinical Trials', 'Complement', 'Devices', 'Dose', 'Drug Kinetics', 'Effectiveness', 'Electrodes', 'FDA approved', 'Felis catus', 'Food', 'Forelimb', 'Frequencies', 'Goals', 'Hand', 'Hand functions', 'Hip region structure', 'Human', 'Implant', 'Implanted Electrodes', 'Individual', 'Injury', 'Intervention', 'Knee', 'Leg', 'Lesion', 'Lower Extremity', 'Machine Learning', 'Methodology', 'Modality', 'Motor', 'Motor Skills', 'Oral', 'Paralysed', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Preparation', 'Property', 'Protocols documentation', 'Rattus', 'Recovery', 'Rehabilitation therapy', 'Retrieval', 'Series', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Testing', 'Thoracic spinal cord structure', 'Time', 'Toes', 'Training', 'Translating', 'Treatment Efficacy', 'Upper Extremity', 'Weight-Bearing state', 'arm', 'base', 'design', 'human subject', 'improved', 'minimally invasive', 'motor function recovery', 'neural circuit', 'neuroregulation', 'public health relevance', 'response']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,U01,2013,863301,0.020734129653831194
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    The technology developed as part of this NIH SBIR project will transform the cell phone camera of visually impaired individuals into a powerful tool capable of identifying the objects they encounter, track the items they own, or navigate complex new environments. Broad access to low-cost visual intelligence technologies developed in this project will improve the independence and capabilities of the visually impaired. There has been tremendous technological progress in computer vision and in the computational power and network bandwidth of and Smartphone platforms. The synergy of these advances stands to revolutionize the way people find information and interact with the physical world. However, these technologies are not yet fully in the hands of the visually impaired, arguably the population that could benefit the most from these developments. Part of the barrier to progress in this area has been that computer vision can accurately handle only a small fraction of the typical images coming from a cell phone camera. To cope with these limitations and make any-image recognition possible, IQ Engines will develop a hybrid system that uses both computer vision and crowdsourcing: if the computer algorithms are not able to understand an image, then the image is sent to a unique crowdsourcing network of people for image analysis. The proposed research includes specific aims to both develop advanced computer vision algorithms for object recognition and advanced crowdsourced networks optimized to the needs of the visually impaired community. This approach combines the speed and accuracy of computer vision with the robustness and understanding of human vision, ultimately providing the user fast and accurate information about the content of any image.           The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.            ",Mobile Search for the Visually Impaired,8389864,R44EY019790,"['Address', 'Algorithms', 'Area', 'Car Phone', 'Cellular Phone', 'Classification', 'Client', 'Clip', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Crowding', 'Data', 'Databases', 'Detection', 'Development', 'Devices', 'Ensure', 'Environment', 'Family', 'Feedback', 'Friends', 'Glosso-Sterandryl', 'Human', 'Hybrid Computers', 'Hybrids', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Location', 'Modeling', 'Monitor', 'Phase', 'Population', 'Preparation', 'Process', 'Quality of life', 'Research', 'Running', 'Scanning', 'Services', 'Small Business Innovation Research Grant', 'Social Network', 'Source', 'Speed', 'System', 'Technology', 'Telephone', 'Time', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual impairment', 'base', 'blind', 'cell transformation', 'coping', 'cost', 'improved', 'innovation', 'novel', 'object recognition', 'open source', 'sensor', 'tool', 'visual information', 'visual search', 'volunteer']",NEI,"IQ ENGINES, INC.",R44,2013,499358,-0.01612173265538507
"Sensor Activity Monitoring, Feedback, and Outcome Measures, Stroke Rehabilitation     DESCRIPTION (provided by applicant): ""Technologies for Healthy Independent Living"" coincides with our goal to test and further develop inexpensive wireless sensors with communication and analysis platforms to monitor everyday activities, such as walking and exercise, in disabled persons. Our Medical Daily Activity Wireless Network (MDAWN) aims to enable researchers, trialists, and clinicians to acquire reliable data about daily physical activites in the home and community, rather than only during clinic and laboratory visits or by questionnaires. Novel machine-learning algorithms developed for each person from ankle accelerometers will identify the type, quantity and quality of exercise and walking on a continuous basis. In addition, we will test an inexpensive, instrumented, ergometric pedaler designed for disabled persons, called the UCFit, to promote home-based fitness exercise. The MDAWN and UFCFit sensors send data to an Android smartphone, then over the Internet to a UCLA server for analysis. We will nest further evaluation of the utility of these remote sensing devices within the real-world setting of a clinical trial of patients with recent disabling stroke,for whom formal rehabilitation often falls short of enabling functional walking and cardiovascular fitness. In a phase 2, randomized controlled trial, we will compare two levels of weekly telephonic feedback about daily performance, made possible for the first time by remote data acquisition. The high feedback group will receive everyday performance data that includes the number of bouts and minutes of pedaling plus rate/RPMs and forces used, as well as the number of bouts of walking, duration, and average speed and distance used in home and community. The minimal feedback group only hears about total daily UCFit exercise and walking time. After 4 months of encouraging up to four 30-min sessions per week of UCFit exercise, we will test for a 50% between-group difference in amount of daily exercise and walking time. Secondary outcomes examine change in level of fitness, walking speed, and physical functioning. The two groups then cross over to high or low feedback for 4 more months, before outcomes are reassessed. Then, no feedback is given and participants are tested for amount of exercise and fitness at 12 months. We will determine which form of feedback motivates better self-management to optimize fitness and walking. We will gather unique data about mobility in the transition from rehabilitation hospital to home; quantify gait training durin usual care; assess walking skills under more complex conditions than in a laboratory; and test the responsiveness of sensor data as a ratio scale outcome measurement during a time of expected gains. This study will be the first comprehensive demonstration of mHealth remote monitoring and outcome measures of daily physical activity!          Several important public health needs will be met by testing, within a clinical trial in the home and community, a system of wearable activity and exercise monitoring technologies that measure the type, quantity and quality of walking and exercise. Our trial aims to increase fitness and enable more functional levels of daily activities in disable persons after stroke, while providing a proof-of-principle for the utility of wireless health toolsto reliably monitor real-world physical functioning and to provide clinically meaningful outcome measures. These generic tools for daily care and research can be deployed across diseases and disabilities.            ","Sensor Activity Monitoring, Feedback, and Outcome Measures, Stroke Rehabilitation",8514028,R01HD071809,"['Address', 'Adherence', 'Aerobic', 'Aerobic Exercise', 'Algorithms', 'Ankle', 'Beds', 'California', 'Cardiovascular system', 'Caregivers', 'Caring', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Trials', 'Communication', 'Communities', 'Complex', 'Continuity of Patient Care', 'Data', 'Devices', 'Disabled Persons', 'Disease', 'Effectiveness', 'Evaluation', 'Event', 'Exercise', 'Feedback', 'Gait', 'Generic Drugs', 'Genetic Crossing Over', 'Glosso-Sterandryl', 'Goals', 'Health', 'Hearing', 'Home environment', 'Hospitals', 'Independent Living', 'Inpatients', 'Internet', 'Intervention', 'Laboratories', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Monitor', 'Movement', 'Outcome', 'Outcome Measure', 'Outpatients', 'Participant', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Physical Function', 'Physical activity', 'Pilot Projects', 'Procedures', 'Public Health', 'Questionnaires', 'Randomized', 'Randomized Clinical Trials', 'Randomized Controlled Trials', 'Regimen', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Resistance', 'Self Management', 'Speed', 'Staging', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Torque', 'Training', 'Universities', 'Visit', 'Walking', 'Wireless Technology', 'arm', 'base', 'conditioning', 'cost', 'data acquisition', 'design', 'disability', 'falls', 'fitness', 'improved', 'insight', 'instrument', 'meetings', 'novel', 'post stroke', 'programs', 'randomized trial', 'remote sensing', 'remote sensor', 'secondary outcome', 'sensor', 'skills', 'spatiotemporal', 'stroke rehabilitation', 'tool', 'treatment as usual', 'wireless network']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2013,383437,-0.02537478100419937
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired     DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering.         PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.            ",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8650411,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Healthcare', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'high school', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'public health relevance', 'rehabilitation engineering', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2013,81362,0.013829362954416528
"Providing Access to Appliance Displays for Visually Impaired Users  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays. This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image. For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast. These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view. Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users. Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures. The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.                ",Providing Access to Appliance Displays for Visually Impaired Users,8579051,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype', 'public health relevance']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2013,376082,0.018883558992268814
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.        PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.               ",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,8432789,R01NS066340,"['Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2013,480486,0.015645407738127715
"A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians    DESCRIPTION (provided by applicant): A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians Abstract Project Summary Urban intersections are among the most dangerous parts of a blind person's travel. They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult. To alleviate this problem, we propose to develop and evaluate a cell phone-based system to analyze images of street intersections, taken by a blind or visually impaired person using a standard cell phone, to provide real-time feedback. Building on our past work on a prototype ""Crosswatch"" system that uses computer vision algorithms to find crosswalks and Walk lights, we will greatly enhance the functionality of the system with information about the intersection layout and the identity of its connecting streets, the presence of stop signs, one-way signs and other controls indicating right-of-way, and timing information integrated from Walk/Don't Walk lights, countdown timers and other traffic lights. The system will convey intersection information, and will actively guide the user to align himself/herself with crosswalks, using a combination of synthesized speech and audio tones. We will conduct human factors studies to optimize the system functionality and the configuration of the user interface, as well as develop interactive training applications to equip users with the skills to better use the system. These training applications, implemented as additional cell phone software to complement the intersection system, will train users to hold the camera horizontal and forward and to minimize veer when traversing a crosswalk. The intersection analysis and training software will be made freely available for download onto popular cell phones (such as iPhone, Android or Symbian models). The cell phone will not need any hardware modifications or add-ons to run this software. Ultimately a user will be able to download an entire suite of such algorithms for free onto the cell phone he or she is already likely to be carrying, without having to carry a separate piece of equipment for each function.       PUBLIC HEALTH RELEVANCE: The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.            ",A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians,8435501,R01EY018345,"['Address', 'Adoption', 'Algorithms', 'American', 'Cellular Phone', 'Complement', 'Complement component C4', 'Complex', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Crowding', 'Custom', 'Data', 'Development', 'Devices', 'Equipment', 'Face', 'Feedback', 'Glosso-Sterandryl', 'Grant', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Length', 'Light', 'Location', 'Mainstreaming', 'Modeling', 'Modification', 'Names', 'Process', 'Reading', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Running', 'Safety', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Speed', 'System', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Time', 'Training', 'Travel', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'abstracting', 'base', 'blind', 'consumer product', 'cost', 'design', 'improved', 'interest', 'legally blind', 'meter', 'prototype', 'public health relevance', 'sensor', 'skills', 'trafficking', 'volunteer', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2013,383018,0.024075500258168667
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,8413778,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Award', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2013,655370,0.009981621680355362
"Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance     DESCRIPTION (provided by applicant): The neuromuscular disorders include a wide group of conditions ranging from relatively mild focal problems, such as carpal tunnel syndrome, to severe, generalized diseases, such as amyotrophic lateral sclerosis (ALS). Current methods for evaluating these disorders remain limited to a variety of tests and procedures that are either invasive or remarkably qualitative in nature. One newer technique, electrical impedance myography (EIM), offers the prospect of obtaining quantitative data on muscle condition painlessly and non-invasively. However, no commercial devices specifically tailored for EIM use exist, with nearly all previous EIM work relying upon off-the-shelf bioimpedance devices designed for ""whole-body"" rather than single-muscle assessment. In Phase 1 of this SBIR, Convergence Medical Devices, Inc (CMD) developed an initial prototype system to test proof-of-principle innovative concepts in circuit design and data acquisition to provide highly sensitive and accurate data at an extended frequency range (out to 10 MHz) and over multiple angles relative to the major muscle fiber direction. This work was followed by supplemental work that produced the first hand-held device with robust electronics capable of similar measurements with a detachable, interchangeable electrode array. In this 3-year Phase 2 SBIR, CMD proposes to further refine that technology so as to assist in disease diagnosis and for following disease progression, with a specific focus on amyotrophic lateral sclerosis. In Aim 1 of the proposed grant, testing of multiple electrode array designs will be performed on a group of normal subjects and those with ALS to determine which electrode array designs offer the greatest reproducibility and ability to discriminate healthy from diseased individuals. In Aim 2, the device and the 3 ""best"" array designs identified in Aim 1 will be tested in 30 ALS patients, 30 patients with syndromes mimicking ALS (e.g., polyradiculopathy and motor-predominant neuropathy), and 30 subjects with suspected/possible ALS to determine the single best array design for diagnosis and to determine its sensitivity and specificity. This study will take place at CMD and four external sites and will be managed by the Northeast ALS trials Consortium (NEALS), the premier organization for overseeing clinical trials in ALS. In Aim 3, the 30 suspected/possible ALS patients recruited in SA2 and 30 additional suspected/possible ALS patients will be assessed monthly using EIM and the 3 arrays identified in SA1. All subjects will also undergo standard measurements of disease progression including handheld dynamometry, ALS Functional Rating Scale, and spirometry. The best array design for assessing disease progression will be identified and compared to conventional markers of disease progression to determine EIM's sensitivity to disease status. Thus, at the conclusion of this research program, we anticipate having developed and vigorously tested an EIM device and associated electrode designs that together will serve as a powerful new diagnostic and monitoring tool for neuromuscular disease.          The neuromuscular disorders are a group of conditions that impact the lives of millions of people in the United States alone. In this study, Convergence Medical Devices, in collaboration with neurologists at several medical centers, will develop and test a new device based on the concept of electrical impedance myography, a technique that offers the promise of rapid and accurate disease assessment. With the completion of this study, a new, painless tool will be developed and studied that will assist in individual patient care and will speed drug testing in clinical trials in diseases ranging from amyotrophic lateral sclerosis and muscular dystrophy to radiculopathy and polyneuropathy.            ",Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance,8456053,R44NS070385,"['Amyotrophic Lateral Sclerosis', 'Area', 'Biological Markers', 'Biopsy', 'Businesses', 'Carpal Tunnel Syndrome', 'Clinical', 'Clinical Trials', 'Collaborations', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Electrodes', 'Electromyography', 'Electronics', 'Entrapment Neuropathies', 'Frequencies', 'Future', 'Genetic', 'Goals', 'Grant', 'Individual', 'Limb structure', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Measures', 'Medical Device', 'Medical center', 'Methods', 'Monitor', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Fibers', 'Muscular Dystrophies', 'Myography', 'Nature', 'Needles', 'Neurologist', 'Neuromuscular Diseases', 'Neuropathy', 'Outcome', 'Painless', 'Patient Care', 'Patients', 'Phase', 'Physicians', 'Polyneuropathy', 'Polyradiculopathy', 'Procedures', 'Radiculopathy', 'Recruitment Activity', 'Relative (related person)', 'Reproducibility', 'Research', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Spirometry', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Clinical Trial', 'Time', 'United States', 'Widespread Disease', 'Work', 'base', 'clinical care', 'commercial application', 'data acquisition', 'design', 'diagnosis design', 'disease diagnosis', 'drug testing', 'electric impedance', 'improved', 'indexing', 'innovation', 'muscle strength', 'muscular structure', 'neuromuscular', 'novel diagnostics', 'programs', 'prototype', 'pulmonary function', 'tool', 'validation studies']",NINDS,"MYOLEX, INC.",R44,2013,531082,0.019421392910925497
"Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics    DESCRIPTION (provided by applicant): Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Often the disability is so severe that it is not possible to feed oneself or readily communicate. A new class of medical system termed brain-machine interfaces (BMIs) has emerged from research labs in the past decade and is now poised to dramatically improve these patients' quality of life. BMIs ""read out"" neural electrical activity directly from motor structures in the brain and decode these electrical impulses in order to determine the intended movement. Initial versions of BMI systems that control a computer cursor are now in FDA Phase-I clinical trials, and numerous agencies are actively engaged in clinical translation (e.g., NIH, DARPA, VA). Creating control signals to enable an amputee to feed himself with a prosthetic (robotic) arm and hand will require decoding signals from thousands of electrodes, rather than the hundred or so signals current systems read, as well as encoding thousands of sensor signals from the arm and hand into thousands of artificial neural signals to be ""written into"" the brain, which has not yet been attempted. The lack of low-power (so that it can be implanted) electronic circuitry needed to run BMIs' encoding and decoding algorithms (termed codecs) is a fundamental barrier to successful clinical translation. The technologies available until now are too power-hungry (digital) or too algorithmically inflexible (analog) to meet the challenge. Recent advances in neuromorphic engineering make it now possible to build a fully implantable and programmable codec chip. This innovative approach combines digital's and analog's best features-programmability and efficiency-while offering far greater robustness than either. Meanwhile recent advances in neuroscience techniques make it now possible to obtain the knowledge needed to design the right algorithms to run on our codec chip. Optogenetic stimulaton can now be used to drive neurons in macaque cortex and computer vision can now be used to track freely moving monkeys while recording wirelessly. We propose to leverage these recent advances to dramatically increase prosthetic performance through the principled design of: (1) An entirely new class of encoders that can spatio-temporally pattern neural activity via optogenetic techniques. (2) An entirely new class of decoders that can operate in the real world with animals moving freely around in far less constrained settings. (3) An entirely new class of implantable programmable electronics that achieves the level of energy- efficiency required to run these complex algorithms. We will demonstrate our success by having a freely moving primate, with a 96-microelectrode recording array and a 9-channel optogenetic stimulator implanted in its premotor and somatosensory cortex, respectively, control a human-like robotic arm. Our ultimate goal is to realize the neuromorphic engineer's dream: Helping untold millions with neurological injury by replacing damaged neural tissue with chips that work like the brain.           Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Brain-machine interfaces (BMIs) ""read out"" neural electrical activity directly from motor structures in the brain and decodes these signals in order to execute the intended movement with a robotic arm. This project seeks to increase BMI performance dramatically by leveraging recent advances in systems neuroscience and neuromorphic engineering.                                ",Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics,8470734,R01NS076460,"['Address', 'Adopted', 'Algorithms', 'Amplifiers', 'Amputees', 'Animals', 'Axon', 'Behavioral', 'Brain', 'Budgets', 'Clinical', 'Clinical Paths', 'Cochlea', 'Complex', 'Computer Vision Systems', 'Computers', 'Disabled Persons', 'Dreams', 'Electrodes', 'Electronics', 'Engineering', 'Goals', 'Hand', 'Human', 'Impairment', 'Implant', 'Knowledge', 'Macaca', 'Medical', 'Microelectrodes', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Neurons', 'Neurosciences', 'Patients', 'Performance', 'Phase I Clinical Trials', 'Primates', 'Prosthesis', 'Quality of life', 'Reading', 'Research', 'Robotics', 'Running', 'Sensory', 'Signal Transduction', 'Silicon', 'Solutions', 'Somatosensory Cortex', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Translating', 'Translations', 'United States National Institutes of Health', 'Walking', 'Work', 'Writing', 'analog', 'arm', 'base', 'brain machine interface', 'cranium', 'design', 'digital', 'disability', 'feeding', 'grasp', 'improved', 'innovation', 'interest', 'meetings', 'millisecond', 'nervous system disorder', 'neural patterning', 'neural prosthesis', 'optogenetics', 'relating to nervous system', 'research study', 'sensor', 'sensory cortex', 'spatiotemporal', 'success']",NINDS,STANFORD UNIVERSITY,R01,2013,878017,0.029013752914225463
"Context Understanding Technology to improve internet accessibility for users with     DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization.         PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.                ",Context Understanding Technology to improve internet accessibility for users with,8459121,R44EY020082,"['Advertisements', 'Area', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Government', 'Grouping', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Persons', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'public health relevance', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2013,371933,0.013896510479965237
"CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation Interacting with the physical environment and manipulating objects is an essential part of daily life. This ability is lost in upper-limb amputees as well as patients with spinal cord injury, stroke, ALS and other movement disorders. These people know what they want to do as well as how they would do it if their arms were functional. If such knowledge is decoded and sent to a prosthetic arm (or to the patient's own arm fitted with functional electric stimulators) the lost motor function could be restored. The decoding is unlikely to be perfect however the brain can adapt to an imperfect decoder using real-time feedback. Several groups including ours have recently demonstrated that at least in principle this can be achieved. However, as is often the case in science, the initial work has been done in idealized conditions and its applicability to real-world usage scenarios remains an open question. The goal of this project is to bring movement control brain-machine interfaces (BMIs) closer to helping the people who need them, and at the same time exploit the rich datasets we collect in order to advance our understanding of sensorimotor control and learning. This will be accomplished by creating hybrid BMIs which exploit information from multiple sources, combined with modern algorithms from machine learning and automatic control. RELEVANCE (See instructions): Being able to interact with the physical environment and manipulate objects is an essential part of daily life. Brain-machine interfaces are one way to restore this ability to patients who have lost it. The proposed project will bring brain-machine interfaces closer to helping patients in real-worid object manipulation tasks.  n/a",CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8288148,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2012,250764,0.0002943081743665986
"Electrocorticography signals for human hand prosthetics    DESCRIPTION (provided by applicant):  Neurological injury (such as from stroke, traumatic brain injury, and spinal cord injury) is a major cause of permanent disability.  Recent advances in the field of neuroprosthetics hold enormous potential for the development of brain-computer interfaces to restore neurological function.  This project will lead to a system that can control a robotic hand using recordings from the surface of the brain.  Interfaces based directly from brain signals may allow for direct decoding of control signals for maximally efficient prosthetics.  This project, a collaboration between neurosurgery, computer science, and physics departments, will explore the brain signals underlying hand movement using electrocorticography, or ECoG.  We have previously shown that high frequency (>75Hz) components of the ECoG carry information about local brain activity.  In the first aim, we will expand our understanding of the high-frequency signal components that correlate with individual finger movements.  We will extract broadband changes in ECoG from non-specific alpha and beta rhythms using PCA and enhance finger classification with machine learning algorithms.  In the second aim, we will look for control signals reflecting different hand functions, rather than movement of different fingers.  For instance, we will examine if pinch and grasp behaviors give more separable high- frequency ECoG signals.  We will also examine the behavior of these movements at higher spatial resolution.  In the third aim, we will measure ECoG changes associated with imagined movement and how these changes are altered with visual feedback when applied to a robotic hand.  In the final aim, we will add tactile feedback to the control to optimize ECoG-based control of a hand prosthesis.  By increasingly advancing the complexity of the control signal, and the complexity of the robotic hand output, we will establish if ECoG is a viable source of control signal for a hand neuroprosthetic device.      PUBLIC HEALTH RELEVANCE:  The development of a hand neuroprosthetic, or artificial device that interacts with the nervous system could restore function to those afflicted by stroke, brain injury, spinal cord injury, or neurodegenerative diseases that have damaged the use of a hand or arm.  This project examines whether signals recorded directly from the human brain (during surgery for epilepsy) could be used to control a robotic hand.              The development of a hand neuroprosthetic, or artificial device that interacts with the nervous system, could restore function to those afflicted by stroke, brain injury, spinal cord injury, or neurodegenerative diseases that have damaged the use of a hand or arm. This project examines whether signals recorded directly from the human brain (during surgery for epilepsy) could be used to control a robotic hand.",Electrocorticography signals for human hand prosthetics,8247688,R01NS065186,"['Algorithms', 'Alpha Rhythm', 'Animals', 'Area', 'Behavior', 'Behavioral', 'Beta Rhythm', 'Brain', 'Brain Injuries', 'Classification', 'Collaborations', 'Coupling', 'Degenerative Disorder', 'Development', 'Devices', 'Digit structure', 'Dimensions', 'Disease', 'Distant', 'Electrocorticogram', 'Electrodes', 'Epilepsy', 'Feedback', 'Fingers', 'Frequencies', 'Future', 'Hand', 'Hand functions', 'Human', 'Image', 'Imagery', 'Individual', 'Lead', 'Left', 'Life', 'Limb structure', 'Machine Learning', 'Measures', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Physiology', 'Nervous System Trauma', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurologic', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Penetration', 'Phase', 'Physics', 'Population Dynamics', 'Positioning Attribute', 'Prosthesis', 'Resolution', 'Robotics', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Stroke', 'Surface', 'Survivors', 'System', 'Tactile', 'Technology', 'Thumb structure', 'Training', 'Traumatic Brain Injury', 'Upper Extremity', 'Visual', 'Work', 'arm', 'base', 'brain computer interface', 'brain machine interface', 'computer science', 'disability', 'functional restoration', 'grasp', 'improved', 'indexing', 'limb movement', 'neurosurgery', 'public health relevance', 'tool', 'visual control', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2012,322420,0.016350463783969125
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    The technology developed as part of this NIH SBIR project will transform the cell phone camera of visually impaired individuals into a powerful tool capable of identifying the objects they encounter, track the items they own, or navigate complex new environments. Broad access to low-cost visual intelligence technologies developed in this project will improve the independence and capabilities of the visually impaired. There has been tremendous technological progress in computer vision and in the computational power and network bandwidth of and Smartphone platforms. The synergy of these advances stands to revolutionize the way people find information and interact with the physical world. However, these technologies are not yet fully in the hands of the visually impaired, arguably the population that could benefit the most from these developments. Part of the barrier to progress in this area has been that computer vision can accurately handle only a small fraction of the typical images coming from a cell phone camera. To cope with these limitations and make any-image recognition possible, IQ Engines will develop a hybrid system that uses both computer vision and crowdsourcing: if the computer algorithms are not able to understand an image, then the image is sent to a unique crowdsourcing network of people for image analysis. The proposed research includes specific aims to both develop advanced computer vision algorithms for object recognition and advanced crowdsourced networks optimized to the needs of the visually impaired community. This approach combines the speed and accuracy of computer vision with the robustness and understanding of human vision, ultimately providing the user fast and accurate information about the content of any image.      PUBLIC HEALTH RELEVANCE:    The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.                 The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.            ",Mobile Search for the Visually Impaired,8198847,R44EY019790,"['Address', 'Algorithms', 'Area', 'Car Phone', 'Cellular Phone', 'Classification', 'Client', 'Clip', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Crowding', 'Data', 'Databases', 'Detection', 'Development', 'Devices', 'Ensure', 'Environment', 'Family', 'Feedback', 'Friends', 'Glosso-Sterandryl', 'Human', 'Hybrid Computers', 'Hybrids', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Location', 'Modeling', 'Monitor', 'Phase', 'Population', 'Preparation', 'Process', 'Quality of life', 'Research', 'Running', 'Scanning', 'Services', 'Small Business Innovation Research Grant', 'Social Network', 'Source', 'Speed', 'System', 'Technology', 'Telephone', 'Time', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual impairment', 'base', 'blind', 'cell transformation', 'coping', 'cost', 'improved', 'innovation', 'novel', 'object recognition', 'open source', 'sensor', 'tool', 'visual information', 'visual search', 'volunteer']",NEI,"IQ ENGINES, INC.",R44,2012,499358,-0.018042179658729663
"Sensor Activity Monitoring, Feedback, and Outcome Measures, Stroke Rehabilitation     DESCRIPTION (provided by applicant): ""Technologies for Healthy Independent Living"" coincides with our goal to test and further develop inexpensive wireless sensors with communication and analysis platforms to monitor everyday activities, such as walking and exercise, in disabled persons. Our Medical Daily Activity Wireless Network (MDAWN) aims to enable researchers, trialists, and clinicians to acquire reliable data about daily physical activites in the home and community, rather than only during clinic and laboratory visits or by questionnaires. Novel machine-learning algorithms developed for each person from ankle accelerometers will identify the type, quantity and quality of exercise and walking on a continuous basis. In addition, we will test an inexpensive, instrumented, ergometric pedaler designed for disabled persons, called the UCFit, to promote home-based fitness exercise. The MDAWN and UFCFit sensors send data to an Android smartphone, then over the Internet to a UCLA server for analysis. We will nest further evaluation of the utility of these remote sensing devices within the real-world setting of a clinical trial of patients with recent disabling stroke,for whom formal rehabilitation often falls short of enabling functional walking and cardiovascular fitness. In a phase 2, randomized controlled trial, we will compare two levels of weekly telephonic feedback about daily performance, made possible for the first time by remote data acquisition. The high feedback group will receive everyday performance data that includes the number of bouts and minutes of pedaling plus rate/RPMs and forces used, as well as the number of bouts of walking, duration, and average speed and distance used in home and community. The minimal feedback group only hears about total daily UCFit exercise and walking time. After 4 months of encouraging up to four 30-min sessions per week of UCFit exercise, we will test for a 50% between-group difference in amount of daily exercise and walking time. Secondary outcomes examine change in level of fitness, walking speed, and physical functioning. The two groups then cross over to high or low feedback for 4 more months, before outcomes are reassessed. Then, no feedback is given and participants are tested for amount of exercise and fitness at 12 months. We will determine which form of feedback motivates better self-management to optimize fitness and walking. We will gather unique data about mobility in the transition from rehabilitation hospital to home; quantify gait training durin usual care; assess walking skills under more complex conditions than in a laboratory; and test the responsiveness of sensor data as a ratio scale outcome measurement during a time of expected gains. This study will be the first comprehensive demonstration of mHealth remote monitoring and outcome measures of daily physical activity!        PUBLIC HEALTH RELEVANCE: Several important public health needs will be met by testing, within a clinical trial in the home and community, a system of wearable activity and exercise monitoring technologies that measure the type, quantity and quality of walking and exercise. Our trial aims to increase fitness and enable more functional levels of daily activities in disable persons after stroke, while providing a proof-of-principle for the utility of wireless health toolsto reliably monitor real-world physical functioning and to provide clinically meaningful outcome measures. These generic tools for daily care and research can be deployed across diseases and disabilities.              Several important public health needs will be met by testing, within a clinical trial in the home and community, a system of wearable activity and exercise monitoring technologies that measure the type, quantity and quality of walking and exercise. Our trial aims to increase fitness and enable more functional levels of daily activities in disable persons after stroke, while providing a proof-of-principle for the utility of wireless health toolsto reliably monitor real-world physical functioning and to provide clinically meaningful outcome measures. These generic tools for daily care and research can be deployed across diseases and disabilities.            ","Sensor Activity Monitoring, Feedback, and Outcome Measures, Stroke Rehabilitation",8331820,R01HD071809,"['Address', 'Adherence', 'Aerobic', 'Aerobic Exercise', 'Algorithms', 'Ankle', 'Beds', 'California', 'Cardiovascular system', 'Caregivers', 'Caring', 'Chronic Disease', 'Clinic', 'Clinical', 'Clinical Trials', 'Communication', 'Communities', 'Complex', 'Continuity of Patient Care', 'Data', 'Devices', 'Disabled Persons', 'Disease', 'Effectiveness', 'Evaluation', 'Event', 'Exercise', 'Feedback', 'Gait', 'Generic Drugs', 'Genetic Crossing Over', 'Glosso-Sterandryl', 'Goals', 'Health', 'Hearing', 'Home environment', 'Hospitals', 'Independent Living', 'Inpatients', 'Internet', 'Intervention', 'Laboratories', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Monitor', 'Movement', 'Outcome', 'Outcome Measure', 'Outpatients', 'Participant', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Physical Function', 'Physical activity', 'Pilot Projects', 'Procedures', 'Public Health', 'Questionnaires', 'Randomized', 'Randomized Clinical Trials', 'Randomized Controlled Trials', 'Regimen', 'Rehabilitation therapy', 'Relative (related person)', 'Research', 'Research Personnel', 'Resistance', 'Self Management', 'Speed', 'Staging', 'Stroke', 'System', 'Technology', 'Testing', 'Time', 'Torque', 'Training', 'Universities', 'Visit', 'Walking', 'Wireless Technology', 'arm', 'base', 'conditioning', 'cost', 'data acquisition', 'design', 'disability', 'falls', 'fitness', 'improved', 'insight', 'instrument', 'meetings', 'novel', 'post stroke', 'programs', 'randomized trial', 'remote sensing', 'remote sensor', 'secondary outcome', 'sensor', 'skills', 'spatiotemporal', 'stroke rehabilitation', 'tool', 'treatment as usual', 'wireless network']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2012,414265,-0.02762693494361154
"Passive Activity Monitoring with Patient Identification and Gesture Detection     DESCRIPTION (provided by applicant): Elderly patients with Alzheimer's disease and dementia present a massive care challenge for family members and care professionals. In the last year of a patient's life, half of family caregivers report spending 46 or more hours a week assisting him/her with activities of daily living (ADL). Ingenium Care proposes to create a passive, self-learning, system for activity monitoring and support of elderly persons using the novel technology of Microsoft's Kinect device. This advanced activity monitoring combined with Ingenium Care's interactive communications and support system will extend independent living and the successful conduct of everyday tasks for the elderly with Alzheimer's disease, dementia, people with disabilities, and soldiers with PTSD and TBI. Existing monitoring technology has limited activity recognition capability or uses many sensors and wearable devices. The need for wearable devices requires cooperation from the elderly that may not reminder or resent to wear it. We propose to replace our existing wearable badge technology with a passive device based on the Kinect device from Microsoft. A network of these sensors provides precise location information within a home or facility and detects falls and gestures such as eating, drinking or taking medications. This device will eliminate the need to wear any device. Aim #1 - Goal: Develop Algorithms for Proof of Concept Gesture Recognition. Aim #2 - Goal: Do laboratory training and testing of detection algorithms utilizing a single work station. Aim #3 - Goal: Perform randomized activities and gestures in a simulated living environment and iteratively improve algorithms.        PUBLIC HEALTH RELEVANCE: Narrative Today, 60 million Americans - one in five - require assistance in their living arrangements and daily activities. These are primarily elderly individuals with Alzheimer's disease, dementia, and also persons with disabilities. By applying the latest monitoring and artificial intelligence technologies, the outcomes of this research would enable the Ingenium Care system to improve the quality of home and institutional health care, and at the same time, reduce the cost of providing that care. The marketplace for technology to assist the elderly will grow sharply from $2 billion today to more than $20 billion by 2020, according to new reports from Frost and Sullivan and Forester Research (Liz Boehm, Principal Analyst for Healthcare and Life Sciences) entitled ""Healthcare Unbound's Early Self-Pay Market"".                  Narrative Today, 60 million Americans - one in five - require assistance in their living arrangements and daily activities. These are primarily elderly individuals with Alzheimer's disease, dementia, and also persons with disabilities. By applying the latest monitoring and artificial intelligence technologies, the outcomes of this research would enable the Ingenium Care system to improve the quality of home and institutional health care, and at the same time, reduce the cost of providing that care. The marketplace for technology to assist the elderly will grow sharply from $2 billion today to more than $20 billion by 2020, according to new reports from Frost and Sullivan and Forester Research (Liz Boehm, Principal Analyst for Healthcare and Life Sciences) entitled ""Healthcare Unbound's Early Self-Pay Market"".                ",Passive Activity Monitoring with Patient Identification and Gesture Detection,8463373,R43AG044167,"['Activities of Daily Living', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Area', 'Artificial Intelligence', 'Biological Sciences', 'Caring', 'Collection', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Trees', 'Dementia', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Eating', 'Elderly', 'Ensure', 'Environment', 'Event', 'Facial Expression', 'Family Caregiver', 'Family member', 'Furniture', 'Gestures', 'Goals', 'Half-Life', 'Healthcare', 'Home environment', 'Hour', 'Human Resources', 'Independent Living', 'Individual', 'Interactive Communication', 'Laboratories', 'Learning', 'Life', 'Living Arrangement', 'Location', 'Marketing', 'Measures', 'Methods', 'Monitor', 'Motion', 'Nose', 'Outcome', 'Outcomes Research', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Post-Traumatic Stress Disorders', 'Process', 'Qualifying', 'Randomized', 'Reporting', 'Research', 'Running', 'Simulate', 'Soldier', 'Support System', 'System', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Training', 'Work', 'base', 'care systems', 'cost', 'drinking', 'falls', 'forest', 'improved', 'instrument', 'monitoring device', 'new technology', 'older patient', 'phase 2 study', 'pill', 'point of care', 'sensor', 'software development', 'tool', 'volunteer']",NIA,"INGENIUM CARE, LLC",R43,2012,145,-0.017756993786380463
"Toward an Animal Model of Freely Moving Humans PROJECT SUMMARY / ABSTRACT  Our overarching goal is to establish an animal model of freely moving humans. We choose to do so in order to directly measure the context-dependency of motor cortical activity and, ultimately, other activity reliant upon free movement such as social interaction among animals. Achieving this major technological challenge requires  a complete system that includes (Specific Aim 1) wireless transmission of neural data from electrode arrays chronically implanted in monkeys, (Specific Aim 2) computer-vision algorithms to automatically extract body and limb orientation during free movement, and (Specific Aim 3) new mathematical and computational models  to represent and extract information from high-dimensional neural and behavioral activity. This technology will enable an animal model of freely moving humans that will advance the development of cortical neural prostheses by providing models of the context-dependant nature of motor cortical control.   Unlike traditional laboratory environments used to study animal movement, human amputees and tetraplegics operate in a variety of contexts that involve their movement in the world. Understanding the motor control of complex movement in these natural settings is absolutely critical for future advances in cortically-controlled prostheses. Given our overarching goal, our hypothesis is that motor cortical activity (e.g.,  directional tuning curves, absolute firing rates, correlations among units, etc.) will be different in important ways when rhesus monkeys perform the same reaching arm movements in an un-constrained context (e.g., not sitting quietly, not head restrained, not in dark and quiet room, etc.) as in a traditional, highly constrained context. Our three Specific Aims will put in place the electronic, computational and mathematical technology  necessary to address this hypothesis, and also to make such studies of free behavior in rhesus monkeys possible.  The innovative integration of neural engineering, neuroscience, computer vision, mathematics and neural modeling will provide new tools to enable the unprecedented study of motor control during natural, unconstrained behavior. PROJECT NARRATIVE  The proposed research project is directly relevant to both basic neuroscience studies of higher brain function and to neural prosthesis research aimed at, ultimately, helping patients with motor disorders. We will conduct neurophysiological and behavioral experiments with rhesus monkeys in two different contexts - ""in home cage""  and ""in rig"" - to investigate the context dependence of motor cortical activity. With this knowledge, we will then design ""context independent"" models of the neural-behavioral relationship which we, and other researchers, could then use in neural prosthetic experiments while monkeys freely move around their less-constrained home cages.",Toward an Animal Model of Freely Moving Humans,8290387,R01NS066311,"['Address', 'Advanced Development', 'Algorithms', 'Amputees', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Behavioral', 'Brain', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Dependence', 'Dependency', 'Development', 'Devices', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Eye', 'Future', 'Goals', 'Hand', 'Head', 'Home environment', 'Human', 'Implant', 'Injury', 'Joints', 'Knowledge', 'Laboratories', 'Lead', 'Limb structure', 'Macaca mulatta', 'Mathematics', 'Measures', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nature', 'Neurologic', 'Neurons', 'Neurosciences', 'Patients', 'Posture', 'Process', 'Prosthesis', 'Quadriplegia', 'Records', 'Research', 'Research Personnel', 'Research Project Grants', 'Robotics', 'Signal Transduction', 'Social Interaction', 'Synaptic Transmission', 'System', 'Technology', 'Vision', 'Visual', 'Wireless Technology', 'arm', 'computer science', 'design', 'free behavior', 'implantation', 'innovation', 'mathematical model', 'motor control', 'motor disorder', 'neural model', 'neural prosthesis', 'neurophysiology', 'neuroregulation', 'relating to nervous system', 'research study', 'sample fixation', 'skills', 'tool', 'visual process', 'visual processing']",NINDS,STANFORD UNIVERSITY,R01,2012,227048,0.017565610143147167
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.       PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.                 Narrative This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Di(R)usion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from di(R)usion MRI scans.",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,8239526,R01NS066340,"['Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2012,497067,0.006545124460145709
"Vision Without Sight: Exploring the Environment with a Portable Camera  Vision without Sight: Exploring the Environment with a Portable Camera Project Summary As computer vision object recognition algorithms improve in accuracy and speed, and computers become more powerful and compact, it is becoming increasingly practical to implement such algorithms on portable devices such as camera-enabled cell phones. This ""mobile vision"" approach allows normally sighted users to identify objects, signs, places and other features in the environment simply by snapping a photo and waiting a few seconds for the results of the object recognition analysis. The approach holds great promise for blind or visually impaired (VI) users, who may have no other means of identifying important features that are undetectable by non-visual cues. However, in order for the approach to be practical for VI users, the interaction between the user and the environment using the camera must be properly facilitated. For instance, since the user may not know in advance which direction to point the camera towards a desired target, he or she must be able to pan the camera left and right to search for it, and receive rapid feedback whenever it is detected. Drawing on past experience of the PI and his colaborators on object recognition systems for VI users, we propose to study the use of mobile vision technologies for exploring features in the environment, specificaly examining the process of discovering these features and obtaining guidance towards them. Our main objectives are to investigate the strategies adopted by users of these technologies to expedite the exploration process, devise and test maximally effective user interfaces consistent with these strategies, and to assess and benchmark the efficiency of the technologies. The result will be a set of minimum design standards that will specify the system performance parameters, the user interface functionality and the operational strategies necessary for any mobile vision object recognition system for VI users.  Vision without Sight: Exploring the Environment with a Portable Camera Project Narrative The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cel phones but are typicaly designed for normaly sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population",Vision Without Sight: Exploring the Environment with a Portable Camera,8334623,R21EY021643,"['Address', 'Adopted', 'Algorithms', 'American', 'Benchmarking', 'Cellular Phone', 'Computer Hardware', 'Computer Vision Systems', 'Computers', 'Cues', 'Development', 'Devices', 'Environment', 'Feedback', 'Glosso-Sterandryl', 'Goals', 'Goggles', 'Grant', 'Image Analysis', 'Impairment', 'Lead', 'Learning', 'Left', 'Location', 'Performance', 'Population', 'Printing', 'Process', 'Research', 'Self-Help Devices', 'Specific qualifier value', 'Speed', 'System', 'Task Performances', 'Technology', 'Telephone', 'Testing', 'Time', 'Touch sensation', 'Training', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'blind', 'design', 'experience', 'improved', 'insight', 'interest', 'legally blind', 'meetings', 'new technology', 'object recognition', 'operation', 'usability', 'visual feedback']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2012,229834,-0.016366300667375933
"Longitudinal Assessment of Fall Risk    DESCRIPTION (provided by applicant): Falling is not a normal part of the aging process and yet 1/3 to 1/2 of adults 65 years and older sustain at least one fall annually. Older adults are hospitalized for fall related injuries five times more often than from injuries from other causes contributing to a cost of $19 billion for nonfatal falls in the United States. Projected for the increasing aging population in the year 2020, it is expected that the costs related to falls will reach a staggering 54.9 billion dollars. Current research and clinical practice guidelines focus on multifactorial fall risk assessments as the critical deterrent to falls in the elderly. A primary factor within these assessments is activity of daily living performance of the individual elder. While current standardized clinical balance assessment tools have been proven effective for predicting fall risk, the tests are most commonly performed in the clinical environment and at isolated times during an individual's day. The goal of this application is to develop and validate a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. Such a device: - will allow early detection of risk of falling, when therapeutic interventions are most efficient - will provide real-time feedback about activity pattern - will provide feedback about compliance with interventions and effectiveness of interventions - will be incorporated into conventional footwear and require no extra effort to operate - can be used in research, clinical and potentially in consumer applications The development of the ALARM system will be addressed in three specific aims:  Specific Aims 1: Develop a pattern recognition method that will improve recognition accuracy for activities of interest (such as walking and stepping up) by reducing the range of variation from current 76%- 100% to 9911%. Specific Aim 2: Collect data using the ALARM device on a group of elderly adults during clinical tests. Specific Aim 3: Develop algorithms for automatic assessment of risk of falling. In this Aim we will develop signal processing algorithms that automatically evaluate metrics indicative of the risk of falling in each activity of interest (e.g. duration of swing and stance phase during walking). Specific Aim 4: Validate the ALARM device in a double-blind unrestricted free living study. This set of Specific Aims will validate lead to creation of a unique wearable device capable of objective characterization of risk of falling.        This application aims at development of a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. In our previous research we have shown that major activities and posture allocations such as standing, sitting, walking, etc. can be recognized with high degree of accuracy (76%-100%) by a wearable device incorporated into conventional footwear. We also have shown that sensor signals captured by the wearable shoe device during activities such as walking are well- correlated with the risk of falling (with numerical estimates of risk obtained through signal processing being directly proportional to the normalized scores from the clinical tests). The goal of this application is to develop and validate a novel wearable device (ALARM) for longitudinal assessment of risk of falling.         ",Longitudinal Assessment of Fall Risk,8339885,R21EB013183,"['Acceleration', 'Activities of Daily Living', 'Address', 'Adult', 'Aging-Related Process', 'Algorithms', 'Classification', 'Clinical', 'Clinical Practice Guideline', 'Communities', 'Comparative Study', 'Computational algorithm', 'Computers', 'Data', 'Data Set', 'Development', 'Devices', 'Double-Blind Method', 'Early Diagnosis', 'Effectiveness of Interventions', 'Elderly', 'Engineering', 'Environment', 'Equilibrium', 'Evaluation', 'Feasibility Studies', 'Feedback', 'Goals', 'Heel', 'Individual', 'Injury', 'Intervention', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Metric', 'Monitor', 'Neural Network Simulation', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Posture', 'Process', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Series', 'Shoes', 'Signal Transduction', 'System', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'United States', 'Validation', 'Variant', 'Walking', 'aging population', 'base', 'computerized data processing', 'cost', 'fall risk', 'falls', 'human old age (65+)', 'improved', 'interest', 'novel', 'pressure', 'sensor', 'tool', 'volunteer']",NIBIB,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R21,2012,185300,-0.012365558535116623
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,8465025,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Award', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2012,40000,0.009981621680355362
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,8213637,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Award', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2012,699362,0.009981621680355362
"A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians    DESCRIPTION (provided by applicant): A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians Abstract Project Summary Urban intersections are among the most dangerous parts of a blind person's travel. They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult. To alleviate this problem, we propose to develop and evaluate a cell phone-based system to analyze images of street intersections, taken by a blind or visually impaired person using a standard cell phone, to provide real-time feedback. Building on our past work on a prototype ""Crosswatch"" system that uses computer vision algorithms to find crosswalks and Walk lights, we will greatly enhance the functionality of the system with information about the intersection layout and the identity of its connecting streets, the presence of stop signs, one-way signs and other controls indicating right-of-way, and timing information integrated from Walk/Don't Walk lights, countdown timers and other traffic lights. The system will convey intersection information, and will actively guide the user to align himself/herself with crosswalks, using a combination of synthesized speech and audio tones. We will conduct human factors studies to optimize the system functionality and the configuration of the user interface, as well as develop interactive training applications to equip users with the skills to better use the system. These training applications, implemented as additional cell phone software to complement the intersection system, will train users to hold the camera horizontal and forward and to minimize veer when traversing a crosswalk. The intersection analysis and training software will be made freely available for download onto popular cell phones (such as iPhone, Android or Symbian models). The cell phone will not need any hardware modifications or add-ons to run this software. Ultimately a user will be able to download an entire suite of such algorithms for free onto the cell phone he or she is already likely to be carrying, without having to carry a separate piece of equipment for each function.      PUBLIC HEALTH RELEVANCE: The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.              Public Health Relevance The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.",A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians,8227997,R01EY018345,"['Address', 'Adoption', 'Algorithms', 'American', 'Cellular Phone', 'Complement', 'Complement component C4', 'Complex', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Crowding', 'Custom', 'Data', 'Development', 'Devices', 'Equipment', 'Face', 'Feedback', 'Glosso-Sterandryl', 'Grant', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Length', 'Light', 'Location', 'Mainstreaming', 'Modeling', 'Modification', 'Names', 'Process', 'Reading', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Running', 'Safety', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Speed', 'System', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Time', 'Training', 'Travel', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'abstracting', 'base', 'blind', 'consumer product', 'cost', 'design', 'improved', 'interest', 'legally blind', 'meter', 'prototype', 'public health relevance', 'sensor', 'skills', 'trafficking', 'volunteer', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2012,403177,0.029937134284250263
"Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance     DESCRIPTION (provided by applicant): The neuromuscular disorders include a wide group of conditions ranging from relatively mild focal problems, such as carpal tunnel syndrome, to severe, generalized diseases, such as amyotrophic lateral sclerosis (ALS). Current methods for evaluating these disorders remain limited to a variety of tests and procedures that are either invasive or remarkably qualitative in nature. One newer technique, electrical impedance myography (EIM), offers the prospect of obtaining quantitative data on muscle condition painlessly and non-invasively. However, no commercial devices specifically tailored for EIM use exist, with nearly all previous EIM work relying upon off-the-shelf bioimpedance devices designed for ""whole-body"" rather than single-muscle assessment. In Phase 1 of this SBIR, Convergence Medical Devices, Inc (CMD) developed an initial prototype system to test proof-of-principle innovative concepts in circuit design and data acquisition to provide highly sensitive and accurate data at an extended frequency range (out to 10 MHz) and over multiple angles relative to the major muscle fiber direction. This work was followed by supplemental work that produced the first hand-held device with robust electronics capable of similar measurements with a detachable, interchangeable electrode array. In this 3-year Phase 2 SBIR, CMD proposes to further refine that technology so as to assist in disease diagnosis and for following disease progression, with a specific focus on amyotrophic lateral sclerosis. In Aim 1 of the proposed grant, testing of multiple electrode array designs will be performed on a group of normal subjects and those with ALS to determine which electrode array designs offer the greatest reproducibility and ability to discriminate healthy from diseased individuals. In Aim 2, the device and the 3 ""best"" array designs identified in Aim 1 will be tested in 30 ALS patients, 30 patients with syndromes mimicking ALS (e.g., polyradiculopathy and motor-predominant neuropathy), and 30 subjects with suspected/possible ALS to determine the single best array design for diagnosis and to determine its sensitivity and specificity. This study will take place at CMD and four external sites and will be managed by the Northeast ALS trials Consortium (NEALS), the premier organization for overseeing clinical trials in ALS. In Aim 3, the 30 suspected/possible ALS patients recruited in SA2 and 30 additional suspected/possible ALS patients will be assessed monthly using EIM and the 3 arrays identified in SA1. All subjects will also undergo standard measurements of disease progression including handheld dynamometry, ALS Functional Rating Scale, and spirometry. The best array design for assessing disease progression will be identified and compared to conventional markers of disease progression to determine EIM's sensitivity to disease status. Thus, at the conclusion of this research program, we anticipate having developed and vigorously tested an EIM device and associated electrode designs that together will serve as a powerful new diagnostic and monitoring tool for neuromuscular disease.        PUBLIC HEALTH RELEVANCE: The neuromuscular disorders are a group of conditions that impact the lives of millions of people in the United States alone. In this study, Convergence Medical Devices, in collaboration with neurologists at several medical centers, will develop and test a new device based on the concept of electrical impedance myography, a technique that offers the promise of rapid and accurate disease assessment. With the completion of this study, a new, painless tool will be developed and studied that will assist in individual patient care and will speed drug testing in clinical trials in diseases ranging from amyotrophic lateral sclerosis and muscular dystrophy to radiculopathy and polyneuropathy.              The neuromuscular disorders are a group of conditions that impact the lives of millions of people in the United States alone. In this study, Convergence Medical Devices, in collaboration with neurologists at several medical centers, will develop and test a new device based on the concept of electrical impedance myography, a technique that offers the promise of rapid and accurate disease assessment. With the completion of this study, a new, painless tool will be developed and studied that will assist in individual patient care and will speed drug testing in clinical trials in diseases ranging from amyotrophic lateral sclerosis and muscular dystrophy to radiculopathy and polyneuropathy.            ",Noninvasive Assessment of Neuromuscular Disease using Electrical Impedance,8315044,R44NS070385,"['Amyotrophic Lateral Sclerosis', 'Area', 'Biological Markers', 'Biopsy', 'Businesses', 'Carpal Tunnel Syndrome', 'Clinical', 'Clinical Trials', 'Collaborations', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Device Designs', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Electrodes', 'Electromyography', 'Electronics', 'Entrapment Neuropathies', 'Frequencies', 'Future', 'Genetic', 'Goals', 'Grant', 'Individual', 'Limb structure', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Measures', 'Medical Device', 'Medical center', 'Methods', 'Monitor', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Fibers', 'Muscular Dystrophies', 'Myography', 'Nature', 'Needles', 'Neurologist', 'Neuromuscular Diseases', 'Neuropathy', 'Outcome', 'Painless', 'Patient Care', 'Patients', 'Phase', 'Physicians', 'Polyneuropathy', 'Polyradiculopathy', 'Procedures', 'Radiculopathy', 'Recruitment Activity', 'Relative (related person)', 'Reproducibility', 'Research', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Spirometry', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Clinical Trial', 'Time', 'United States', 'Widespread Disease', 'Work', 'base', 'clinical care', 'commercial application', 'data acquisition', 'design', 'diagnosis design', 'disease diagnosis', 'drug testing', 'electric impedance', 'improved', 'indexing', 'innovation', 'muscle strength', 'muscular structure', 'neuromuscular', 'novel diagnostics', 'programs', 'prototype', 'pulmonary function', 'tool', 'validation studies']",NINDS,"MYOLEX, INC.",R44,2012,620921,0.02281750249417268
"Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics    DESCRIPTION (provided by applicant): Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Often the disability is so severe that it is not possible to feed oneself or readily communicate. A new class of medical system termed brain-machine interfaces (BMIs) has emerged from research labs in the past decade and is now poised to dramatically improve these patients' quality of life. BMIs ""read out"" neural electrical activity directly from motor structures in the brain and decode these electrical impulses in order to determine the intended movement. Initial versions of BMI systems that control a computer cursor are now in FDA Phase-I clinical trials, and numerous agencies are actively engaged in clinical translation (e.g., NIH, DARPA, VA). Creating control signals to enable an amputee to feed himself with a prosthetic (robotic) arm and hand will require decoding signals from thousands of electrodes, rather than the hundred or so signals current systems read, as well as encoding thousands of sensor signals from the arm and hand into thousands of artificial neural signals to be ""written into"" the brain, which has not yet been attempted. The lack of low-power (so that it can be implanted) electronic circuitry needed to run BMIs' encoding and decoding algorithms (termed codecs) is a fundamental barrier to successful clinical translation. The technologies available until now are too power-hungry (digital) or too algorithmically inflexible (analog) to meet the challenge. Recent advances in neuromorphic engineering make it now possible to build a fully implantable and programmable codec chip. This innovative approach combines digital's and analog's best features-programmability and efficiency-while offering far greater robustness than either. Meanwhile recent advances in neuroscience techniques make it now possible to obtain the knowledge needed to design the right algorithms to run on our codec chip. Optogenetic stimulaton can now be used to drive neurons in macaque cortex and computer vision can now be used to track freely moving monkeys while recording wirelessly. We propose to leverage these recent advances to dramatically increase prosthetic performance through the principled design of: (1) An entirely new class of encoders that can spatio-temporally pattern neural activity via optogenetic techniques. (2) An entirely new class of decoders that can operate in the real world with animals moving freely around in far less constrained settings. (3) An entirely new class of implantable programmable electronics that achieves the level of energy- efficiency required to run these complex algorithms. We will demonstrate our success by having a freely moving primate, with a 96-microelectrode recording array and a 9-channel optogenetic stimulator implanted in its premotor and somatosensory cortex, respectively, control a human-like robotic arm. Our ultimate goal is to realize the neuromorphic engineer's dream: Helping untold millions with neurological injury by replacing damaged neural tissue with chips that work like the brain.           Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Brain-machine interfaces (BMIs) ""read out"" neural electrical activity directly from motor structures in the brain and decodes these signals in order to execute the intended movement with a robotic arm. This project seeks to increase BMI performance dramatically by leveraging recent advances in systems neuroscience and neuromorphic engineering.                                ",Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics,8327105,R01NS076460,"['Address', 'Adopted', 'Algorithms', 'Amplifiers', 'Amputees', 'Animals', 'Axon', 'Behavioral', 'Brain', 'Budgets', 'Clinical', 'Clinical Paths', 'Cochlea', 'Complex', 'Computer Vision Systems', 'Computers', 'Disabled Persons', 'Dreams', 'Electrodes', 'Electronics', 'Engineering', 'Goals', 'Hand', 'Human', 'Impairment', 'Implant', 'Knowledge', 'Macaca', 'Medical', 'Microelectrodes', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Neurons', 'Neurosciences', 'Patients', 'Performance', 'Phase I Clinical Trials', 'Primates', 'Prosthesis', 'Quality of life', 'Reading', 'Research', 'Robotics', 'Running', 'Sensory', 'Signal Transduction', 'Silicon', 'Solutions', 'Somatosensory Cortex', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Translating', 'Translations', 'United States National Institutes of Health', 'Walking', 'Work', 'Writing', 'analog', 'arm', 'base', 'brain machine interface', 'cranium', 'design', 'digital', 'disability', 'feeding', 'grasp', 'improved', 'innovation', 'interest', 'meetings', 'millisecond', 'nervous system disorder', 'neural patterning', 'neural prosthesis', 'optogenetics', 'relating to nervous system', 'research study', 'sensor', 'sensory cortex', 'spatiotemporal', 'success']",NINDS,STANFORD UNIVERSITY,R01,2012,871992,0.029013752914225463
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,8473426,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Methodology', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'digital', 'experience', 'falls', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition', 'web services']",NEI,BLINDSIGHT CORPORATION,R44,2012,407051,0.02345151649192811
"Spinal Epidural Electrode Array to Facilitate Standing and Stepping After SCI     DESCRIPTION (provided by applicant):  We have demonstrated that an adult rat with a complete, mid-thoracic spinal cord transection can regain full weight-bearing stepping over a range of speeds, loads, and even directions when the spinal cord is stimulated tonically to increase the excitability of the lumbosacral locomotor circuitry.  Furthermore, we learned that load- bearing sensory information can serve as the controller of these complex motor tasks and that the performance of these tasks can be improved even further with pharmacological and motor training interventions.  Within the first 2.5 years of the present BRP Grant, not within the five years as initially proposed, we have gathered sufficient data to demonstrate that the human lumbosacral spinal cord has similar capabilities.  We have shown that an individual with a motor complete spinal cord injury can regain independent standing, assisted stepping, and even a significant level of voluntary control of the lower limbs in the presence of epidural stimulation after months of testing different spinal cord stimulation patterns and motor training.  Just as important and as impressive is the recovery of significant levels of bladder control, blood pressure, and temperature regulation, and even sexual function in this patient (13a).  These intriguing results compel us to begin additional efforts to overcome what are now recognized as the most critical factors limiting our progress toward making this intervention available in the clinic.  Based on our results, it is clear that we can develop the capability to selectively activae combinations of neural networks that can enable standing and probably stepping with improved technology in humans with a functionally motor complete spinal cord injury.  These functional improvements are even more likely to benefit those individuals that are functionally motor incomplete, but have severely impaired mobility.  Our present accomplishments have been realized using technology that is three decades old and initially designed for a different purpose, i.e., pain management.  Thus we are requesting funds to overcome the present technical, not physiological, limitations as expediently and as carefully as possible.  More specifically, the rat limiting factors are the lack of technology for chronic implants for a high number of electrodes and the need for a more clear understanding of how these epidural stimulation arrays can modulate the spinal circuitries.  To overcome these factors we need to 1) develop a device that will allow us to chronically implant an integrated electrode array and multiplexed stimulation device in rats with the necessary signal control capabilities, 2) evaluate hypotheses that will guide us to more clearly understand how to modulate the stimulation parameters to activate the desired spinal circuits, 3) develop a learning strategy to automatically optimize the stimulation parameters for a given patient to stand, step, or exert voluntary control, and 4) begin to explore the pathways through which voluntary control can be regained after a severe spinal cord injury.        PUBLIC HEALTH RELEVANCE:  It now seems possible to develop a technology that will enable the recovery of postural and locomotor function in humans after a motor complete spinal cord injury.  This technology includes the capability to stimulate the lower spinal cord in a manner that can enable a patient with complete paraplegia to stand and to step.  This project outlines the newly recognized technical capabilities that must be developed to accomplish this goal.                   It now seems possible to develop a technology that will enable the recovery of postural and locomotor function in humans after a motor complete spinal cord injury.  This technology includes the capability to stimulate the lower spinal cord in a manner that can enable a patient with complete paraplegia to stand and to step.  This project outlines the newly recognized technical capabilities that must be developed to accomplish this goal.                ",Spinal Epidural Electrode Array to Facilitate Standing and Stepping After SCI,8297976,R01EB007615,"['Action Potentials', 'Acute', 'Adult', 'Affect', 'Algorithms', 'Amplifiers', 'Animals', 'Behavior', 'Biological Neural Networks', 'Bladder Control', 'Blood Pressure', 'Central cord canal structure', 'Chronic', 'Clinic', 'Clinical', 'Complex', 'Computer Simulation', 'Computers', 'Coupled', 'Data', 'Devices', 'Documentation', 'Dorsal', 'Educational Intervention', 'Electrodes', 'Environment', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Human', 'Implant', 'Individual', 'Interneurons', 'Intervention', 'Isometric Exercise', 'Lateral', 'Lead', 'Learning', 'Locomotion', 'Lower Extremity', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical', 'Methods', 'Modeling', 'Motor', 'Motor Neurons', 'Motor Skills', 'Muscle', 'Neurons', 'Neurostimulation procedures of spinal cord tissue', 'Pain management', 'Paraplegia', 'Pathway interactions', 'Patients', 'Pattern', 'Phase', 'Physiological', 'Positioning Attribute', 'Posture', 'Procedures', 'Property', 'Rattus', 'Recovery', 'Regulation', 'Resources', 'Role', 'Saint Jude Children&apos', 's Research Hospital', 'Sensory', 'Sex Functioning', 'Signal Transduction', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal Cord transection injury', 'Spinal cord injury', 'Task Performances', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Thoracic spinal cord structure', 'Time', 'Training', 'Weight-Bearing state', 'Wireless Technology', 'Work', 'base', 'computer studies', 'density', 'design', 'functional improvement', 'human subject', 'improved', 'insight', 'miniaturize', 'motor control', 'novel', 'operation', 'prototype', 'research study', 'simulation', 'spinal nerve posterior root', 'success']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2012,246827,0.040932502343391734
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator.  The ultimate goal of this SBIR project is to provide the DOD, DOE, and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. In Phase I, Seacoast successfully demonstrated the feasibility of using a microsensor array with a proprietary trap-and- purge preconcentrator to detect chlorinated solvents, specifically TCE, and TCA, at levels low enough to meet EPA mandated levels for drinking water. In Phase II Seacoast proposes to improve the selectivity and sensitivity of the system to better meet the needs identified by the Phase I consultant. The systems have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator traps the contaminants and releases them to a microsensor array. These sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical.  In Phase II Seacoast will specifically develop new materials to improve the sensor array selectivity, 1) by using impedance spectroscopy to study the mechanisms by which the polymer-based sensors sorb the target chemicals, 2) by implementing pattern recognition algorithms to identify chemicals for the sensor responses, and 3) by designing new preconcentrator materials that can bind these chemicals more strongly.  The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. Potential markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology.      PUBLIC HEALTH RELEVANCE: This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.           PROJECT NARRATIVE This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.",Low-Cost Electronic Nose for Groundwater Contaminants,8260510,R44ES016941,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benchmarking', 'Benzene', 'Carcinogens', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Computer software', 'Cost Analysis', 'Cost Savings', 'Data', 'Data Collection', 'Detection', 'Development', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Equation', 'Equipment', 'Evaluation', 'Fingerprint', 'Fluorescence', 'Gases', 'Goals', 'Guidelines', 'Hazardous Waste', 'Industrial Health', 'Intervention', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Maps', 'Marketing', 'Measures', 'Metals', 'Methods', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Pesticides', 'Phase', 'Plants', 'Poison', 'Pollution', 'Polymers', 'Process', 'Public Health', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Route', 'Safety', 'Sampling', 'Science', 'Scientific Advances and Accomplishments', 'Site', 'Small Business Innovation Research Grant', 'Soil', 'Solvents', 'Source', 'Spectrum Analysis', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Time', 'Trichloroethylene', 'Water', 'Wireless Technology', 'Work', 'analytical method', 'base', 'chemical binding', 'cost', 'design', 'detector', 'drinking water', 'electric impedance', 'ground water', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'method development', 'new technology', 'novel', 'operation', 'pollutant', 'programs', 'prototype', 'public health relevance', 'purge', 'remediation', 'response', 'sensor', 'success', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R44,2012,459419,0.019876158889988192
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.          PROJECT NARRATIVE:  There is a considerable need for improved educational software for mathematics in general, but the problem of  quality educational software materials for the blind and visually impaired is particularly acute. A weak  mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or  even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of  science, technology, engineering and mathematics. Through previous federally-supported research, Quantum  Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI)  tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power  and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,8055353,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Health', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2011,394165,0.025053224833370507
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,8142000,R01EY016093,"['Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Peripheral', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2011,1141143,-0.006657641486763447
"The Development of a Noninvasive Monitoring System for Cigarette Smoking    DESCRIPTION (provided by applicant): Cigarette smoking is the leading cause of preventable death in the United States. Smoking produces over 440,000 deaths each year in this country and generates an estimated $167 billion in annual health-related economic losses. Available methods of smoking assessment (e.g., self-report, portable puff-topography instruments) do not permit the collection of accurate, non-reactive measures of smoking behavior that capture real-time smoking frequency and comprehensive within-cigarette puff topography. The objective of this project is to develop a non-invasive wearable system (Personal Automatic Cigarette Tracker - PACT) that is completely transparent to the end user and does not require any conscience effort to achieve reliable monitoring of smoking behavior in free living individuals. Methodologically, PACT will consist of two major components: 1. Wearable sensors. Miniature sensors integrated into the clothing will monitors the breathing and activity patterns of individuals. The signals from the sensors will be processed and recognized to identify and objectively characterize each individual puff. 2. Software for signal processing and pattern recognition. Automatic computer software will analyze sensor signals and detect patterns uniquely identifying smoking events. Objective metrics such as number of puffs and inter-puff interval will be extracted. The software will be based on the state-of-art machine learning methods. The development of the PACT system will be addressed in four specific aims: Specific Aim 1: Develop a wearable sensor system comprised of a breathing sensor integrated into conventional underwear and a hand gesture sensor integrated into a hand bracelet. Specific Aim 2: Collect sensor data from individuals wearing the instrumented system and performing everyday activities (including smoking) in laboratory conditions. Specific Aim 3: Develop pattern recognition methods to recognize individual puffs and smoke inhalation. Specific Aim 4: Evaluate the utility and sensitivity of the wearable sensor PACT system and pattern recognition method in people smoking in the natural environment. This set of Specific Aims will validate lead to creation of a unique wearable device capable of objective characterization of smoking behavior.      PUBLIC HEALTH RELEVANCE: Cigarette smoking is the leading cause of preventable death in the United States. Smoking produces over 440,000 deaths each year in this country and generates an estimated $167 billion in annual health-related economic losses. The goal of this research is to develop a non-invasive wearable system (Personal Automatic Cigarette Tracker - PACT) that is completely transparent to the end user and does not require any conscious effort to achieve reliable monitoring of smoking behavior in free living individuals. The PACT device will provide an accurate and precise measure of real-world smoking. The device can provide the user and health professional feedback on the frequency of smoking and inhalation patterns (such as depth of inhalation and smoke holding) throughout the day in their home and community. This information can be used to inform behavioral strategies in smoking cessation programs. The data collected by PACT can also provide an objective method of assessing the effectiveness of behavioral and pharmacological smoking interventions.           7. Project Narrative Cigarette smoking is the leading cause of preventable death in the United States. Smoking produces over 440,000 deaths each year in this country and generates an estimated $167 billion in annual health-related economic losses. The goal of this research is to develop a non-invasive wearable system (Personal Automatic Cigarette Tracker - PACT) that is completely transparent to the end user and does not require any conscious effort to achieve reliable monitoring of smoking behavior in free living individuals. The PACT device will provide an accurate and precise measure of real-world smoking. The device can provide the user and health professional feedback on the frequency of smoking and inhalation patterns (such as depth of inhalation and smoke holding) throughout the day in their home and community. This information can be used to inform behavioral strategies in smoking cessation programs. The data collected by PACT can also provide an objective method of assessing the effectiveness of behavioral and pharmacological smoking interventions.",The Development of a Noninvasive Monitoring System for Cigarette Smoking,8044829,R21DA029222,"['Address', 'Algorithms', 'Applications Grants', 'Arts', 'Behavioral', 'Breathing', 'Burn injury', 'Cellular Phone', 'Cessation of life', 'Characteristics', 'Cigarette', 'Clothing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Conscience', 'Conscious', 'Consumption', 'Country', 'Data', 'Data Set', 'Development', 'Devices', 'Eating', 'Economics', 'Effectiveness', 'Electronics', 'Environment', 'Event', 'Exhalation', 'Exposure to', 'Feedback', 'Frequencies', 'Future', 'Gestures', 'Goals', 'Hand', 'Health', 'Health Professional', 'Home environment', 'Hour', 'Individual', 'Instruction', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Metric', 'Monitor', 'Oral cavity', 'Patient Self-Report', 'Pattern', 'Pattern Recognition', 'Pattern Recognition Systems', 'Phase', 'Process', 'Reporting', 'Research', 'Signal Transduction', 'Smoke', 'Smoker', 'Smoking', 'Smoking Behavior', 'System', 'Testing', 'Time', 'Training', 'United States', 'United States Dept. of Health and Human Services', 'Validation', 'Variant', 'Walking', 'Work', 'base', 'cigarette smoking', 'cigarette smoking', 'computerized data processing', 'diaries', 'expiration', 'instrument', 'programs', 'public health relevance', 'respiratory', 'sensor', 'smoke inhalation', 'smoking cessation', 'smoking intervention']",NIDA,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R21,2011,215353,-0.008483475808627388
"Electrocorticography signals for human hand prosthetics    DESCRIPTION (provided by applicant):  Neurological injury (such as from stroke, traumatic brain injury, and spinal cord injury) is a major cause of permanent disability.  Recent advances in the field of neuroprosthetics hold enormous potential for the development of brain-computer interfaces to restore neurological function.  This project will lead to a system that can control a robotic hand using recordings from the surface of the brain.  Interfaces based directly from brain signals may allow for direct decoding of control signals for maximally efficient prosthetics.  This project, a collaboration between neurosurgery, computer science, and physics departments, will explore the brain signals underlying hand movement using electrocorticography, or ECoG.  We have previously shown that high frequency (>75Hz) components of the ECoG carry information about local brain activity.  In the first aim, we will expand our understanding of the high-frequency signal components that correlate with individual finger movements.  We will extract broadband changes in ECoG from non-specific alpha and beta rhythms using PCA and enhance finger classification with machine learning algorithms.  In the second aim, we will look for control signals reflecting different hand functions, rather than movement of different fingers.  For instance, we will examine if pinch and grasp behaviors give more separable high- frequency ECoG signals.  We will also examine the behavior of these movements at higher spatial resolution.  In the third aim, we will measure ECoG changes associated with imagined movement and how these changes are altered with visual feedback when applied to a robotic hand.  In the final aim, we will add tactile feedback to the control to optimize ECoG-based control of a hand prosthesis.  By increasingly advancing the complexity of the control signal, and the complexity of the robotic hand output, we will establish if ECoG is a viable source of control signal for a hand neuroprosthetic device.      PUBLIC HEALTH RELEVANCE:  The development of a hand neuroprosthetic, or artificial device that interacts with the nervous system could restore function to those afflicted by stroke, brain injury, spinal cord injury, or neurodegenerative diseases that have damaged the use of a hand or arm.  This project examines whether signals recorded directly from the human brain (during surgery for epilepsy) could be used to control a robotic hand.              The development of a hand neuroprosthetic, or artificial device that interacts with the nervous system, could restore function to those afflicted by stroke, brain injury, spinal cord injury, or neurodegenerative diseases that have damaged the use of a hand or arm. This project examines whether signals recorded directly from the human brain (during surgery for epilepsy) could be used to control a robotic hand.",Electrocorticography signals for human hand prosthetics,8065923,R01NS065186,"['Algorithms', 'Alpha Rhythm', 'Animals', 'Area', 'Behavior', 'Behavioral', 'Beta Rhythm', 'Brain', 'Brain Injuries', 'Classification', 'Collaborations', 'Coupling', 'Degenerative Disorder', 'Development', 'Devices', 'Digit structure', 'Dimensions', 'Disease', 'Distant', 'Electrocorticogram', 'Electrodes', 'Epilepsy', 'Feedback', 'Fingers', 'Frequencies', 'Future', 'Hand', 'Hand functions', 'Human', 'Image', 'Imagery', 'Individual', 'Lead', 'Left', 'Life', 'Limb structure', 'Machine Learning', 'Measures', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Physiology', 'Nervous System Trauma', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurologic', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Penetration', 'Phase', 'Physics', 'Population Dynamics', 'Positioning Attribute', 'Prosthesis', 'Resolution', 'Robotics', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Stroke', 'Surface', 'Survivors', 'System', 'Tactile', 'Technology', 'Thumb structure', 'Training', 'Traumatic Brain Injury', 'Upper Extremity', 'Visual', 'Work', 'arm', 'base', 'brain computer interface', 'brain machine interface', 'computer science', 'disability', 'functional restoration', 'grasp', 'improved', 'indexing', 'limb movement', 'neurosurgery', 'public health relevance', 'tool', 'visual control', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2011,322420,0.016350463783969125
"NLP for Augmentative and Alternative Communication in Adults    DESCRIPTION (provided by applicant):  This proposal relates to the technology of Augmentative and Alternative Communication (AAC).  The research, to be developed over the three-year course of this project, relates to increasing communication speed for adult users of typing-based AAC devices. The proposed method has commonalities both with chatter bots and more sophisticated automated question answering systems. In particular, we propose to develop a program that will mine a very large database of stored interactions for sentences that are similar to the sentence currently being uttered by the interlocutor, and propose a set of plausible responses for the AAC user. The outcome of this research will be a system that improves over the current state of the art in whole utterance approaches in AAC, making use of sophisticated natural language processing techniques.    Through this research and its practical application to helping real people with real communications needs, as well as coursework, seminars, participation in the AAC and disabilities community in Portland, OR, and intensive one-on-one meetings with his mentor Dr. Melanie Fried-Oken, the PI will accrue substantial clinical experience in AAC, and will gain a deep understanding of how technology can be used to help people.      PUBLIC HEALTH RELEVANCE: The proposed project will develop a research program in the field of Augmentative and Alternative Communication. The program proposes to improve the throughput of AAC devices for conversation by modeling dialogue context for literate adult users. Specifically, we will use corpus-based techniques from question answering and chatter bots to select appropriate utterances in response to utterances from interlocutors.              The proposed project will develop a research program in the field of Augmentative and Alternative Communication. The program proposes to improve the throughput of AAC devices for conversation by modeling dialogue context for literate adult users. Specifically, we will use corpus-based techniques from question answering and chatter bots to select appropriate utterances in response to utterances from interlocutors.            ",NLP for Augmentative and Alternative Communication in Adults,8189460,K25DC011308,"['Address', 'Adult', 'Area', 'Clinical', 'Communication', 'Communication Aids for Disabled', 'Communication Disability', 'Communities', 'Computers', 'Data', 'Databases', 'Devices', 'Environment', 'Food', 'Generations', 'Hobbies', 'Interview', 'Length', 'Measures', 'Mentors', 'Methods', 'Mining', 'Modeling', 'Modification', 'Names', 'Natural Language Processing', 'Oregon', 'Outcomes Research', 'Participant', 'Play', 'Questionnaires', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Restaurants', 'Role', 'Savings', 'Self Assessment', 'Simulate', 'Source', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Travel', 'Universities', 'alternative communication', 'base', 'efficacy testing', 'experience', 'improved', 'literate', 'meetings', 'movie', 'novel', 'practical application', 'programs', 'response', 'satisfaction', 'speech recognition', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,K25,2011,162459,0.00776192508666459
"Harnessing Motoneuron Activity: From Lab to Clinic    DESCRIPTION (provided by applicant):  We propose to continue the development of an automatic system that will accurately and quickly decompose electromyographic (EMG) signals into their constituent action potentials and provide the timing of every firing of a set of concurrently active motor units. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system. We will improve the performance of the decomposition algorithms by incorporating new Artificial Intelligence concepts, and a new multi-strategy Hidden Markov Model (HMM) processing stage, to address signal decomposition challenges that cannot be met by the present technology. We will improve the present accuracy from typically 85% for 8 concurrently active motor units to greater than 96% for up to 15 concurrently active motor units. We will also design and build the hardware and software for a stand-alone portable system that may be used in the laboratory or clinic. Then we will transfer the system to a manufacturer for commercialization. In so doing we will produce, for the first time, an advanced system for conveniently and accurately obtaining the firings of a large group of concurrently active motor units from an EMG signal. The new technology will be tested in two applied studies that will be carried out concurrently with the technical developments. One will investigate neural modifications in the firing characteristics of motor units as a function of aging and physical activity. The other will investigate the mitigating effects of resistive exercise on age-related neural adaptations, culminating in the development of a clinical marker to estimate the likelihood that an elderly individual will benefit from an exercise program. The proposed BRP will be lead by Drs. De Luca, Roy, and Adam, key personnel from Boston University (BU) with expertise in biomedical engineering and EMG system development. Signal processing/software development will be provided by the leadership from Dr. Nawab through BU's Department of Electrical and Computer Engineering. Clinical expertise on aging/motor control will be provided by Dr. Novak, from The Department of Neurology at BU School of Medicine, and through Dr. Wolf, from the Department of Rehabilitation Medicine at the Emory University School of Medicine in Atlanta           n/a",Harnessing Motoneuron Activity: From Lab to Clinic,8079038,R01HD050111,"['Action Potentials', 'Address', 'Aging', 'Algorithms', 'Artificial Intelligence', 'Biomedical Engineering', 'Boston', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Markers', 'Computer software', 'Computers', 'Development', 'Elderly', 'Electrodes', 'Engineering', 'Exercise', 'Human Resources', 'Individual', 'Laboratories', 'Lead', 'Leadership', 'Manufacturer Name', 'Medicine', 'Modeling', 'Modification', 'Motor', 'Motor Neurons', 'Neurology', 'Performance', 'Physical activity', 'Process', 'Rehabilitation therapy', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Surface', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Universities', 'Wolves', 'Work', 'advanced system', 'age related', 'commercialization', 'computerized data processing', 'design', 'improved', 'markov model', 'mathematical model', 'medical schools', 'meetings', 'motor control', 'neuroadaptation', 'neuromuscular system', 'new technology', 'programs', 'relating to nervous system', 'software development']",NICHD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2011,555311,0.00490623124947912
"Interactive, Self-programming, AI System for Activity Monitoring of the Elderly    DESCRIPTION (provided by applicant): Elderly patients with dementia present a massive care challenge for family members and care professionals. In the last year of a patient's life, half of family caregivers report spending 46 or more hours a week assisting him/her with activities of daily living (ADL). More than half felt they were ""on duty"" 24 hours a day, and half had to end/reduce employment due to the demands of care-giving. Ingenium proposes to create a practical, self-learning, system for activity monitoring and support of elderly persons. This advanced activity monitoring combined with Ingenium's interactive communications and support system will extend independent living and the successful conduct of everyday tasks for the elderly, disabled, and soldiers with PTSD and TBI. The goal in this proposal is to produce a system that can reliably recognize activities using only one Ingenium wireless room-master per room and an Ingenium wearable wireless badge linked to an AI system with self-learning capability. This is accomplished through the interactive badge and room masters. In contrast, existing technology uses many sensors and requires off-line processing to train the activity recognizer and is not useable beyond laboratory environments. Additionally, no current commercial system has interactive planning and scheduling support. Ingenium will utilize the assistance of the AI lab staff at Washington State University which is an acknowledged leader in recognizing activities of daily living. Aim #1 will re-create the WSU technology, transfer activity knowledge to the Ingenium platform and enhance the platform with interactive self learning Aim #2 will outfit the WSU smart apartment with the Ingenium system. The smart apartment has a complex set of 37 sensors. The Ingenium system will both simplify and enhance the WSU configuration by utilizing only 7 Ingenium room-masters. Twenty students will participate in a study to verify that the Ingenium system provides superior activity location and recognition than the current wired multiple motion sensor system. Aim #3 will test the ability of the enhanced interactive prompting and learning capability of the Ingenium system to learn the same activities without the knowledge transfer hence validating a real time learning activity recognizer is possible in a commercializable system. One of goals of Ingenium's business plan is to commercialize this system. .      PUBLIC HEALTH RELEVANCE: Today, 60 million Americans - one in five - require assistance in their living arrangements and daily activities. These are primarily elderly individuals and persons with disabilities. By applying the latest monitoring and artificial intelligence technologies, the outcomes of this research would enable the Ingenium system to improve the quality of home and institutional health care, and at the same time, reduce the cost of providing that care. The marketplace for technology to assist the elderly will grow sharply from $2 billion today to more than $20 billion by 2020, according to new reports from Frost & Sullivan and Forester Research (Liz Boehm, Principal Analyst for Healthcare and Life Sciences) entitled ""Healthcare Unbound's Early Self-Pay Market"".           Today, 60 million Americans - one in five - require assistance in their living arrangements and daily activities. These are primarily elderly individuals and persons with disabilities. By applying the latest monitoring and artificial intelligence technologies, the outcomes of this research would enable the Ingenium system to improve the quality of home and institutional health care, and at the same time, reduce the cost of providing that care. The marketplace for technology to assist the elderly will grow sharply from $2 billion today to more than $20 billion by 2020, according to new reports from Frost & Sullivan and Forester Research (Liz Boehm, Principal Analyst for Healthcare and Life Sciences) entitled ""Healthcare Unbound's Early Self-Pay Market"".         ","Interactive, Self-programming, AI System for Activity Monitoring of the Elderly",8062826,R43AG039229,"['Activities of Daily Living', 'American', 'Artificial Intelligence', 'Behavior', 'Biological Sciences', 'Businesses', 'Caring', 'Client', 'Cognitive', 'Communication', 'Complex', 'Computer software', 'Data', 'Dementia', 'Disabled Persons', 'Effectiveness', 'Elderly', 'Employment', 'Environment', 'Family Caregiver', 'Family member', 'Goals', 'Half-Life', 'Healthcare', 'Home environment', 'Hour', 'Independent Living', 'Individual', 'Interactive Communication', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Living Arrangement', 'Location', 'Marketing', 'Monitor', 'Motion', 'Outcome', 'Outcomes Research', 'Patients', 'Persons', 'Phase', 'Post-Traumatic Stress Disorders', 'Process', 'Qualifying', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Schedule', 'Self-Help Devices', 'Site', 'Soldier', 'Staging', 'Students', 'Support System', 'System', 'Systems Analysis', 'Technology', 'Technology Transfer', 'Testing', 'Time', 'Training Activity', 'Transference', 'Universities', 'Voice', 'Washington', 'Wireless Technology', 'Work', 'base', 'caregiving', 'cooking', 'cost', 'disability', 'experience', 'human subject', 'improved', 'innovation', 'older patient', 'programs', 'sensor', 'tool', 'volunteer']",NIA,"INGENIUM CARE, LLC",R43,2011,231016,-0.001878534035940583
"Toward an Animal Model of Freely Moving Humans Our overarching goal is to establish an animal model of freely moving humans. We choose to do so in order to directly measure the context-dependency of motor cortical activity and, ultimately, other activity reliant upon free movement such as social interaction among animals. Achieving this major technological challenge requires a complete system that includes (Specific Aim 1) wireless transmission of neural data from electrode arrays chronically implanted in monkeys, (Specific Aim 2) computer-vision algorithms to automatically extract body and limb orientation during free movement, and (Specific Aim 3) new mathematical and computational models to represent and extract information from high-dimensional neural and behavioral activity. This technology will enable an animal model of freely moving humans that will advance the development of cortical neural prostheses by providing models of the context-dependant nature of motor cortical control.  Unlike traditional laboratory environments used to study animal movement, human amputees and tetraplegics operate in a variety of contexts that involve their movement in the world. Understanding the motor control of complex movement in these natural settings is absolutely critical for future advances in cortically- controlled prostheses. Given our overarching goal, our hypothesis is that motor cortical activity (e.g., directional tuning curves, absolute firing rates, correlations among units, etc.) will be different in important ways when rhesus monkeys perform the same reaching arm movements in an un-constrained context (e.g., not sitting quietly, not head restrained, not in dark and quiet room, etc.) as in a traditional, highly constrained context. Our three Specific Aims will put in place the electronic, computational and mathematical technology necessary to address this hypothesis, and also to make such studies of free behavior in rhesus monkeys possible. The innovative integration of neural engineering, neuroscience, computer vision, mathematics and neural modeling will provide new tools to enable the unprecedented study of motor control during natural, unconstrained behavior.  PROJECT NARRATIVE The proposed research project is directly relevant to both basic neuroscience studies of higher brain function and to neural prosthesis research aimed at, ultimately, helping patients with motor disorders. We will conduct neurophysiological and behavioral experiments with rhesus monkeys in two different contexts - ""in home cage"" and ""in rig"" - to investigate the context dependence of motor cortical activity. With this knowledge, we will then design ""context independent"" models of the neural-behavioral relationship which we, and other researchers, could then use in neural prosthetic experiments while monkeys freely move around their less- constrained home cages.",Toward an Animal Model of Freely Moving Humans,8094411,R01NS066311,"['Address', 'Advanced Development', 'Algorithms', 'Amputees', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Dependence', 'Dependency', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Future', 'Goals', 'Head', 'Home environment', 'Human', 'Implant', 'Knowledge', 'Laboratories', 'Limb structure', 'Macaca mulatta', 'Mathematics', 'Measures', 'Modeling', 'Monkeys', 'Motor', 'Movement', 'Nature', 'Neurosciences', 'Patients', 'Prosthesis', 'Quadriplegia', 'Research', 'Research Personnel', 'Research Project Grants', 'Social Interaction', 'Synaptic Transmission', 'System', 'Technology', 'Wireless Technology', 'arm', 'design', 'free behavior', 'innovation', 'mathematical model', 'motor control', 'motor disorder', 'neural model', 'neural prosthesis', 'neurophysiology', 'relating to nervous system', 'research study', 'tool']",NINDS,STANFORD UNIVERSITY,R01,2011,1141716,0.017916109070750336
"Vision Without Sight: Exploring the Environment with a Portable Camera    DESCRIPTION (provided by applicant): As computer vision object recognition algorithms improve in accuracy and speed, and computers become more powerful and compact, it is becoming increasingly practical to implement such algorithms on portable devices such as camera-enabled cell phones. This ""mobile vision"" approach allows normally sighted users to identify objects, signs, places and other features in the environment simply by snapping a photo and waiting a few seconds for the results of the object recognition analysis. The approach holds great promise for blind or visually impaired (VI) users, who may have no other means of identifying important features that are undetectable by non-visual cues. However, in order for the approach to be practical for VI users, the interaction between the user and the environment using the camera must be properly facilitated. For instance, since the user may not know in advance which direction to point the camera towards a desired target, he or she must be able to pan the camera left and right to search for it, and receive rapid feedback whenever it is detected. Drawing on past experience of the PI and his collaborators on object recognition systems for VI users, we propose to study the use of mobile vision technologies for exploring features in the environment, specific examining the process of discovering these features and obtaining guidance towards them. Our main objectives are to investigate the strategies adopted by users of these technologies to expedite the exploration process, devise and test maximally effective user interfaces consistent with these strategies, and to assess and benchmark the efficiency of the technologies. The result will be a set of minimum design standards that will specify the system performance parameters, the user interface functionality and the operational strategies necessary for any mobile vision object recognition system for VI users.      PUBLIC HEALTH RELEVANCE: The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cell phones but are typically designed for normally sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population              The ability to locate and identify objects, places and other features in the environment is taken for granted every day by the sighted, but this fundamental capability is missing or severely degraded in the approximately 10 million Americans with significant vision impairments and a million who are legally blind. The proposed research would investigate how computer vision object recognition technologies, which are now being implemented on mobile vision devices such as cell phones but are typically designed for normally sighted users, could be modified and harnessed to meet the special needs of blind and visually impaired persons. Such research could lead to new technologies to dramatically improve independence for this population            ",Vision Without Sight: Exploring the Environment with a Portable Camera,8097202,R21EY021643,"['Address', 'Adopted', 'Algorithms', 'American', 'Benchmarking', 'Cellular Phone', 'Computer Hardware', 'Computer Vision Systems', 'Computers', 'Cues', 'Development', 'Devices', 'Environment', 'Feedback', 'Glosso-Sterandryl', 'Goals', 'Goggles', 'Grant', 'Image Analysis', 'Impairment', 'Lead', 'Learning', 'Left', 'Location', 'Performance', 'Population', 'Printing', 'Process', 'Research', 'Self-Help Devices', 'Specific qualifier value', 'Speed', 'System', 'Task Performances', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Training', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'blind', 'design', 'experience', 'improved', 'insight', 'interest', 'legally blind', 'meetings', 'new technology', 'object recognition', 'operation', 'usability', 'visual feedback']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2011,205070,-0.014732438479687887
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.       PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.                 Narrative This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Di(R)usion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from di(R)usion MRI scans.",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,8042555,R01NS066340,"['Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2011,503274,0.006545124460145709
"Longitudinal Assessment of Fall Risk    DESCRIPTION (provided by applicant): Falling is not a normal part of the aging process and yet 1/3 to 1/2 of adults 65 years and older sustain at least one fall annually. Older adults are hospitalized for fall related injuries five times more often than from injuries from other causes contributing to a cost of $19 billion for nonfatal falls in the United States. Projected for the increasing aging population in the year 2020, it is expected that the costs related to falls will reach a staggering 54.9 billion dollars. Current research and clinical practice guidelines focus on multifactorial fall risk assessments as the critical deterrent to falls in the elderly. A primary factor within these assessments is activity of daily living performance of the individual elder. While current standardized clinical balance assessment tools have been proven effective for predicting fall risk, the tests are most commonly performed in the clinical environment and at isolated times during an individual's day. The goal of this application is to develop and validate a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. Such a device: - will allow early detection of risk of falling, when therapeutic interventions are most efficient - will provide real-time feedback about activity pattern - will provide feedback about compliance with interventions and effectiveness of interventions - will be incorporated into conventional footwear and require no extra effort to operate - can be used in research, clinical and potentially in consumer applications The development of the ALARM system will be addressed in three specific aims:  Specific Aims 1: Develop a pattern recognition method that will improve recognition accuracy for activities of interest (such as walking and stepping up) by reducing the range of variation from current 76%- 100% to 9911%. Specific Aim 2: Collect data using the ALARM device on a group of elderly adults during clinical tests. Specific Aim 3: Develop algorithms for automatic assessment of risk of falling. In this Aim we will develop signal processing algorithms that automatically evaluate metrics indicative of the risk of falling in each activity of interest (e.g. duration of swing and stance phase during walking). Specific Aim 4: Validate the ALARM device in a double-blind unrestricted free living study. This set of Specific Aims will validate lead to creation of a unique wearable device capable of objective characterization of risk of falling.      PUBLIC HEALTH RELEVANCE: This application aims at development of a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. In our previous research we have shown that major activities and posture allocations such as standing, sitting, walking, etc. can be recognized with high degree of accuracy (76%-100%) by a wearable device incorporated into conventional footwear. We also have shown that sensor signals captured by the wearable shoe device during activities such as walking are well- correlated with the risk of falling (with numerical estimates of risk obtained through signal processing being directly proportional to the normalized scores from the clinical tests). The goal of this application is to develop and validate a novel wearable device (ALARM) for longitudinal assessment of risk of falling.           This application aims at development of a novel wearable device (Automatic Longitudinal Assessment Risk Monitor - ALARM) for longitudinal assessment of risk of falling. In our previous research we have shown that major activities and posture allocations such as standing, sitting, walking, etc. can be recognized with high degree of accuracy (76%-100%) by a wearable device incorporated into conventional footwear. We also have shown that sensor signals captured by the wearable shoe device during activities such as walking are well- correlated with the risk of falling (with numerical estimates of risk obtained through signal processing being directly proportional to the normalized scores from the clinical tests). The goal of this application is to develop and validate a novel wearable device (ALARM) for longitudinal assessment of risk of falling.         ",Longitudinal Assessment of Fall Risk,8240357,R21EB013183,"['Acceleration', 'Activities of Daily Living', 'Address', 'Adult', 'Aging-Related Process', 'Algorithms', 'Classification', 'Clinical', 'Clinical Practice Guideline', 'Communities', 'Comparative Study', 'Computational algorithm', 'Computers', 'Data', 'Data Set', 'Development', 'Devices', 'Double-Blind Method', 'Early Diagnosis', 'Effectiveness of Interventions', 'Elderly', 'Engineering', 'Environment', 'Equilibrium', 'Evaluation', 'Feasibility Studies', 'Feedback', 'Goals', 'Heel', 'Individual', 'Injury', 'Intervention', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Metric', 'Monitor', 'Neural Network Simulation', 'Outcome', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Posture', 'Process', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Series', 'Shoes', 'Signal Transduction', 'System', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'United States', 'Validation', 'Variant', 'Walking', 'aging population', 'base', 'computerized data processing', 'cost', 'fall risk', 'falls', 'human old age (65+)', 'improved', 'interest', 'novel', 'pressure', 'sensor', 'tool', 'volunteer']",NIBIB,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R21,2011,228569,0.004985126642725097
"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",A Wireless Multiscale Distributed Interface to the Cortex,8110556,R01NS062031,"['Address', 'Advanced Development', 'Algorithms', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cavia', 'Cell physiology', 'Characteristics', 'Communication', 'Computer software', 'Custom', 'Data', 'Devices', 'Discipline', 'Disease', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Health', 'Human', 'Imaging technology', 'Implant', 'In Vitro', 'Investigation', 'Learning', 'Machine Learning', 'Mediating', 'Microelectrodes', 'Monitor', 'Motor', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Outcome', 'Paralysed', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Rattus', 'Research', 'Retinal', 'Rodent', 'Rodent Model', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Slice', 'Stimulus', 'Stream', 'System', 'Telemetry', 'Testing', 'Time', 'Wireless Technology', 'awake', 'base', 'brain cell', 'brain machine interface', 'clinical application', 'computerized data processing', 'data acquisition', 'data exchange', 'density', 'design', 'disability', 'implantation', 'improved', 'in vivo', 'information processing', 'microsystems', 'nervous system disorder', 'neural circuit', 'operation', 'prototype', 'quantum', 'relating to nervous system', 'response', 'subcutaneous', 'tool']",NINDS,MICHIGAN STATE UNIVERSITY,R01,2011,508860,0.0029488115388662303
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,8020057,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Award', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2011,698439,0.009981621680355362
"A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians    DESCRIPTION (provided by applicant): A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians Abstract Project Summary Urban intersections are among the most dangerous parts of a blind person's travel. They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult. To alleviate this problem, we propose to develop and evaluate a cell phone-based system to analyze images of street intersections, taken by a blind or visually impaired person using a standard cell phone, to provide real-time feedback. Building on our past work on a prototype ""Crosswatch"" system that uses computer vision algorithms to find crosswalks and Walk lights, we will greatly enhance the functionality of the system with information about the intersection layout and the identity of its connecting streets, the presence of stop signs, one-way signs and other controls indicating right-of-way, and timing information integrated from Walk/Don't Walk lights, countdown timers and other traffic lights. The system will convey intersection information, and will actively guide the user to align himself/herself with crosswalks, using a combination of synthesized speech and audio tones. We will conduct human factors studies to optimize the system functionality and the configuration of the user interface, as well as develop interactive training applications to equip users with the skills to better use the system. These training applications, implemented as additional cell phone software to complement the intersection system, will train users to hold the camera horizontal and forward and to minimize veer when traversing a crosswalk. The intersection analysis and training software will be made freely available for download onto popular cell phones (such as iPhone, Android or Symbian models). The cell phone will not need any hardware modifications or add-ons to run this software. Ultimately a user will be able to download an entire suite of such algorithms for free onto the cell phone he or she is already likely to be carrying, without having to carry a separate piece of equipment for each function.      PUBLIC HEALTH RELEVANCE: The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.              The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.            ",A Cell Phone-Based Street Intersection Analyzer for Visually Impaired Pedestrians,8042468,R01EY018345,"['Address', 'Adoption', 'Algorithms', 'American', 'Cellular Phone', 'Complement', 'Complement component C4', 'Complex', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Crowding', 'Custom', 'Data', 'Development', 'Devices', 'Equipment', 'Face', 'Feedback', 'Glosso-Sterandryl', 'Grant', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Length', 'Light', 'Location', 'Mainstreaming', 'Modeling', 'Modification', 'Names', 'Process', 'Reading', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Running', 'Safety', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Speed', 'System', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Time', 'Training', 'Travel', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'abstracting', 'base', 'blind', 'consumer product', 'cost', 'design', 'improved', 'interest', 'legally blind', 'meter', 'prototype', 'sensor', 'skills', 'trafficking', 'volunteer', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2011,403177,0.029937134284250263
"Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface    DESCRIPTION (provided by applicant):      Over 600,000 Americans have severely impaired motor function from disorders including spinal cord injury, amyotrophic lateral sclerosis, pontine stroke, and cerebral palsy. A brain-machine interface (BMI) could enable locked-in or tetraplegic patients to communicate and interact with their environment. Two crucial decisions in designing a BMI are (1) what type of brain signals to use as inputs to a controller and (2) what methods to use to decode those signals. Most BMIs have used either noninvasive scalp EEG recordings or invasive intracortical recordings of single- or multi-neuron spikes as control inputs. A few have used subdural or intracortical local field potentials (LFPs). However, no group has yet systematically compared these signals in motor cortex for use in BMI applications. This proposal's first goal is to assess the relative performance of spikes and field potentials (both intracortical and epidural) as control inputs for a variety of movement-related outputs. Epidural field potentials (EFPs) are intermediate in invasiveness, signal quality, stability and spatial resolution compared with existing scalp, subdural, and intracortical recordings, and thus represent an unexplored middle ground. This proposal's second goal is to evaluate linear and nonlinear techniques-including several novel to BMI applications-for both decoding data and reducing the inherently large dimensionality of data from multiple neural signals. The primary hypotheses of the proposed project are (1) that spikes will perform better in decoding more complex movement-related outputs, but that field potentials may perform similarly on decoding simpler outputs, and (2) that nonlinear decoders and dimensionality-reduction techniques may provide improved accuracy over linear methods. The specific aims to address these hypotheses are 1) to evaluate single neuron spikes as inputs to decoders of movement- related outputs, 2) to develop a novel epidural multi-electrode recording technique in the macaque monkey, and 3) to evaluate field potential signals as inputs to decoders of movement-related outputs. Aims 1 and 3 will involve application of dimensionality-reduction algorithms (e.g., independent components analysis, Isomap) and decoding algorithms (system identification, neural networks, support vector machines) to both spikes and field potentials. Aim 2 will entail using a computer model and spatial spectral analysis to optimize the epidural electrode array design. This project will provide the first comparison of spikes, LFPs and EFPs as inputs for identical BMI output applications. The supervision of Drs. Lee Miller and W. Zev Rymer, with additional guidance from Drs. Simon Levine, Jonathan Wolpaw and Nicholas Hatsopoulos, will provide the principal investigator with expertise in recording and processing both spikes and field potentials for BMI applications using a variety of state-of-the- art techniques. A comprehensive career development plan including clinical and research mentoring, seminars, and courses, will foster the candidate's transition into an independent physician-scientist.           n/a",Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface,8091226,K08NS060223,"['Action Potentials', 'Address', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Benchmarking', 'Biological Neural Networks', 'Brain', 'Cerebral Palsy', 'Cervical spinal cord injury', 'Clinical Research', 'Complex', 'Computer Simulation', 'Craniotomy', 'Data', 'Development Plans', 'Discriminant Analysis', 'Disease', 'Dura Mater', 'Electrodes', 'Electroencephalography', 'Environment', 'Evaluation', 'Figs - dietary', 'Fostering', 'Frequencies', 'Genetic Programming', 'Goals', 'Hand', 'Implant', 'Implanted Electrodes', 'Knowledge', 'Learning', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Physicians', 'Pontine structure', 'Principal Investigator', 'Procedures', 'Process', 'Quadriplegia', 'Rattus', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Scalp structure', 'Scientist', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Statistical Methods', 'Stroke', 'Sum', 'Supervision', 'System', 'Techniques', 'Time', 'Tissues', 'Training', 'Visual', 'arm', 'brain machine interface', 'career development', 'computerized data processing', 'cranium', 'design', 'disability', 'feeding', 'flexibility', 'improved', 'in vivo', 'independent component analysis', 'motor control', 'novel', 'programs', 'prototype', 'relating to nervous system', 'research study', 'surgical technique development']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,K08,2011,167832,0.009360221344355102
"Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics    DESCRIPTION (provided by applicant): Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Often the disability is so severe that it is not possible to feed oneself or readily communicate. A new class of medical system termed brain-machine interfaces (BMIs) has emerged from research labs in the past decade and is now poised to dramatically improve these patients' quality of life. BMIs ""read out"" neural electrical activity directly from motor structures in the brain and decode these electrical impulses in order to determine the intended movement. Initial versions of BMI systems that control a computer cursor are now in FDA Phase-I clinical trials, and numerous agencies are actively engaged in clinical translation (e.g., NIH, DARPA, VA). Creating control signals to enable an amputee to feed himself with a prosthetic (robotic) arm and hand will require decoding signals from thousands of electrodes, rather than the hundred or so signals current systems read, as well as encoding thousands of sensor signals from the arm and hand into thousands of artificial neural signals to be ""written into"" the brain, which has not yet been attempted. The lack of low-power (so that it can be implanted) electronic circuitry needed to run BMIs' encoding and decoding algorithms (termed codecs) is a fundamental barrier to successful clinical translation. The technologies available until now are too power-hungry (digital) or too algorithmically inflexible (analog) to meet the challenge. Recent advances in neuromorphic engineering make it now possible to build a fully implantable and programmable codec chip. This innovative approach combines digital's and analog's best features-programmability and efficiency-while offering far greater robustness than either. Meanwhile recent advances in neuroscience techniques make it now possible to obtain the knowledge needed to design the right algorithms to run on our codec chip. Optogenetic stimulaton can now be used to drive neurons in macaque cortex and computer vision can now be used to track freely moving monkeys while recording wirelessly. We propose to leverage these recent advances to dramatically increase prosthetic performance through the principled design of: (1) An entirely new class of encoders that can spatio-temporally pattern neural activity via optogenetic techniques. (2) An entirely new class of decoders that can operate in the real world with animals moving freely around in far less constrained settings. (3) An entirely new class of implantable programmable electronics that achieves the level of energy- efficiency required to run these complex algorithms. We will demonstrate our success by having a freely moving primate, with a 96-microelectrode recording array and a 9-channel optogenetic stimulator implanted in its premotor and somatosensory cortex, respectively, control a human-like robotic arm. Our ultimate goal is to realize the neuromorphic engineer's dream: Helping untold millions with neurological injury by replacing damaged neural tissue with chips that work like the brain.        PUBLIC HEALTH RELEVANCE:  Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Brain-machine interfaces (BMIs) ""read out"" neural electrical activity directly from motor structures in the brain and decodes these signals in order to execute the intended movement with a robotic arm. This project seeks to increase BMI performance dramatically by leveraging recent advances in systems neuroscience and neuromorphic engineering.                                   Millions of people worldwide suffer from neurological injury and disease resulting in profound movement impairment. Brain-machine interfaces (BMIs) ""read out"" neural electrical activity directly from motor structures in the brain and decodes these signals in order to execute the intended movement with a robotic arm. This project seeks to increase BMI performance dramatically by leveraging recent advances in systems neuroscience and neuromorphic engineering.                                ",Fully Implantable and Programmable Spike-based Codecs for Neuroprosthetics,8181331,R01NS076460,"['Address', 'Adopted', 'Algorithms', 'Amplifiers', 'Amputees', 'Animals', 'Axon', 'Behavioral', 'Brain', 'Budgets', 'Clinical', 'Clinical Paths', 'Cochlea', 'Complex', 'Computer Vision Systems', 'Computers', 'Disabled Persons', 'Dreams', 'Electrodes', 'Electronics', 'Engineering', 'Goals', 'Hand', 'Human', 'Impairment', 'Implant', 'Knowledge', 'Macaca', 'Medical', 'Microelectrodes', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Neurons', 'Neurosciences', 'Patients', 'Performance', 'Phase I Clinical Trials', 'Primates', 'Prosthesis', 'Quality of life', 'Reading', 'Research', 'Robotics', 'Running', 'Sensory', 'Signal Transduction', 'Silicon', 'Solutions', 'Somatosensory Cortex', 'Structure', 'Synapses', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Translating', 'Translations', 'United States National Institutes of Health', 'Walking', 'Work', 'Writing', 'analog', 'arm', 'base', 'brain machine interface', 'cranium', 'design', 'digital', 'disability', 'feeding', 'grasp', 'improved', 'innovation', 'interest', 'meetings', 'millisecond', 'nervous system disorder', 'neural patterning', 'neural prosthesis', 'relating to nervous system', 'research study', 'sensor', 'sensory cortex', 'spatiotemporal', 'success']",NINDS,STANFORD UNIVERSITY,R01,2011,895817,0.031040985339243928
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,8133823,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Methodology', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'digital', 'experience', 'falls', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition', 'web services']",NEI,BLINDSIGHT CORPORATION,R44,2011,776548,0.02345151649192811
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator.  The ultimate goal of this SBIR project is to provide the DOD, DOE, and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. In Phase I, Seacoast successfully demonstrated the feasibility of using a microsensor array with a proprietary trap-and- purge preconcentrator to detect chlorinated solvents, specifically TCE, and TCA, at levels low enough to meet EPA mandated levels for drinking water. In Phase II Seacoast proposes to improve the selectivity and sensitivity of the system to better meet the needs identified by the Phase I consultant. The systems have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator traps the contaminants and releases them to a microsensor array. These sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical.  In Phase II Seacoast will specifically develop new materials to improve the sensor array selectivity, 1) by using impedance spectroscopy to study the mechanisms by which the polymer-based sensors sorb the target chemicals, 2) by implementing pattern recognition algorithms to identify chemicals for the sensor responses, and 3) by designing new preconcentrator materials that can bind these chemicals more strongly.  The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. Potential markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology.      PUBLIC HEALTH RELEVANCE: This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.           This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.         ",Low-Cost Electronic Nose for Groundwater Contaminants,8059710,R44ES016941,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benchmarking', 'Benzene', 'Carcinogens', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Computer software', 'Cost Analysis', 'Cost Savings', 'Data', 'Data Collection', 'Detection', 'Development', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Equation', 'Equipment', 'Evaluation', 'Fingerprint', 'Fluorescence', 'Gases', 'Goals', 'Guidelines', 'Hazardous Waste', 'Industrial Health', 'Intervention', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Maps', 'Marketing', 'Measures', 'Metals', 'Methods', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Pesticides', 'Phase', 'Plants', 'Poison', 'Pollution', 'Polymers', 'Process', 'Public Health', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Route', 'Safety', 'Sampling', 'Science', 'Scientific Advances and Accomplishments', 'Site', 'Small Business Innovation Research Grant', 'Soil', 'Solvents', 'Source', 'Spectrum Analysis', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Time', 'Trichloroethylene', 'Water', 'Wireless Technology', 'Work', 'analytical method', 'base', 'chemical binding', 'cost', 'design', 'detector', 'drinking water', 'electric impedance', 'ground water', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'method development', 'new technology', 'novel', 'operation', 'pollutant', 'programs', 'prototype', 'purge', 'remediation', 'response', 'sensor', 'success', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R44,2011,532144,0.019876158889988192
"Computational Methods for Analysis of Mouth Shapes in Sign Languages    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hand) and by the nonmanual components (the face). These facial articulations perform significant semantic, prosodic, pragmatic, and syntactic functions. This proposal will systematically study mouth positions in ASL. Our hypothesis is that ASL mouth positions are more extensive than those used in speech. To study this hypothesis, this project is divided into three aims. In our first aim, we hypothesize that mouth positions are fundamental for the understanding of signs produced in context because they are very distinct from signs seen in isolation. To study this we have recently collected a database of ASL sentences and nonmanuals in over 3600 video clips from 20 Deaf native signers. Our experiments will use this database to identify potential mappings from visual to linguistic features. To successfully do this, our second aim is to design a set of shape analysis and discriminant analysis algorithms that can efficiently analyze the large number of frames in these video clips. The goal is to define a linguistically useful model, i.e., the smallest model that contains the main visual features from which further predictions can be made. Then, in our third aim, we will explore the hypothesis that the linguistically distinct mouth positions are also visually distinct. In particular, we will use the algorithms defined in the second aim to determine if distinct visual features are used to define different linguistic categories. This result will show whether linguistically meaningful mouth positions are not only necessary in ASL (as hypothesized in aim 1), but whether they are defined using non-overlapping visual features (as hypothesized in aim 3). These aims address a critical need. At present, the study of nonmanuals must be carried out manually, that is, the shape and position of each facial feature in each frame must be recorded by hand. Furthermore, to be able to draw conclusive results for the design of a linguistic model, it is necessary to study many video sequences of related sentences as produced by different signers. It has thus proven nearly impossible to continue this research manually. The algorithms designed in the course of this grant will facilitate this analysis of ASL nonmanuals and lead to better teaching materials.      PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.           Project Narrative Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for Analysis of Mouth Shapes in Sign Languages,8109271,R21DC011081,"['Academic achievement', 'Access to Information', 'Address', 'Adult', 'Algorithms', 'Applications Grants', 'Categories', 'Child', 'Clip', 'Communication', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Databases', 'Devices', 'Discriminant Analysis', 'Educational process of instructing', 'Emotions', 'Excision', 'Eye', 'Face', 'Funding', 'Goals', 'Grant', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Joints', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Manuals', 'Modeling', 'Oral cavity', 'Parents', 'Pattern Recognition', 'Positioning Attribute', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Shapes', 'Sign Language', 'Social Interaction', 'Specific qualifier value', 'Speech', 'Teaching Materials', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visual', 'Work', 'computerized tools', 'deafness', 'design', 'experience', 'innovation', 'instructor', 'interest', 'novel', 'prevent', 'public health relevance', 'research study', 'shape analysis', 'success', 'syntax', 'teacher', 'tool', 'visual map']",NIDCD,OHIO STATE UNIVERSITY,R21,2011,205267,-0.03100671436781591
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.           PROJECT NARRATIVE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,8043275,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'public health relevance', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'stem', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2010,394165,0.025053224833370507
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7904837,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2010,1196495,-0.006657641486763447
"Electrocorticography signals for human hand prosthetics    DESCRIPTION (provided by applicant):  Neurological injury (such as from stroke, traumatic brain injury, and spinal cord injury) is a major cause of permanent disability.  Recent advances in the field of neuroprosthetics hold enormous potential for the development of brain-computer interfaces to restore neurological function.  This project will lead to a system that can control a robotic hand using recordings from the surface of the brain.  Interfaces based directly from brain signals may allow for direct decoding of control signals for maximally efficient prosthetics.  This project, a collaboration between neurosurgery, computer science, and physics departments, will explore the brain signals underlying hand movement using electrocorticography, or ECoG.  We have previously shown that high frequency (>75Hz) components of the ECoG carry information about local brain activity.  In the first aim, we will expand our understanding of the high-frequency signal components that correlate with individual finger movements.  We will extract broadband changes in ECoG from non-specific alpha and beta rhythms using PCA and enhance finger classification with machine learning algorithms.  In the second aim, we will look for control signals reflecting different hand functions, rather than movement of different fingers.  For instance, we will examine if pinch and grasp behaviors give more separable high- frequency ECoG signals.  We will also examine the behavior of these movements at higher spatial resolution.  In the third aim, we will measure ECoG changes associated with imagined movement and how these changes are altered with visual feedback when applied to a robotic hand.  In the final aim, we will add tactile feedback to the control to optimize ECoG-based control of a hand prosthesis.  By increasingly advancing the complexity of the control signal, and the complexity of the robotic hand output, we will establish if ECoG is a viable source of control signal for a hand neuroprosthetic device.      PUBLIC HEALTH RELEVANCE:  The development of a hand neuroprosthetic, or artificial device that interacts with the nervous system could restore function to those afflicted by stroke, brain injury, spinal cord injury, or neurodegenerative diseases that have damaged the use of a hand or arm.  This project examines whether signals recorded directly from the human brain (during surgery for epilepsy) could be used to control a robotic hand.              The development of a hand neuroprosthetic, or artificial device that interacts with the nervous system, could restore function to those afflicted by stroke, brain injury, spinal cord injury, or neurodegenerative diseases that have damaged the use of a hand or arm. This project examines whether signals recorded directly from the human brain (during surgery for epilepsy) could be used to control a robotic hand.",Electrocorticography signals for human hand prosthetics,7888004,R01NS065186,"['Algorithms', 'Animals', 'Area', 'Behavior', 'Behavioral', 'Beta Rhythm', 'Brain', 'Brain Injuries', 'Classification', 'Collaborations', 'Coupling', 'Degenerative Disorder', 'Development', 'Devices', 'Digit structure', 'Dimensions', 'Disease', 'Distant', 'Electrocorticogram', 'Electrodes', 'Epilepsy', 'Feedback', 'Fingers', 'Frequencies', 'Future', 'Hand', 'Hand functions', 'Human', 'Image', 'Imagery', 'Individual', 'Lead', 'Left', 'Life', 'Limb structure', 'Machine Learning', 'Measures', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Physiology', 'Nervous System Trauma', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurologic', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Penetration', 'Phase', 'Physics', 'Population Dynamics', 'Positioning Attribute', 'Prosthesis', 'Resolution', 'Robotics', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Stroke', 'Surface', 'Survivors', 'System', 'Tactile', 'Technology', 'Thumb structure', 'Training', 'Traumatic Brain Injury', 'Upper Extremity', 'Visual', 'Work', 'arm', 'base', 'brain computer interface', 'brain machine interface', 'computer science', 'disability', 'functional restoration', 'grasp', 'improved', 'indexing', 'limb movement', 'neurosurgery', 'public health relevance', 'tool', 'visual control', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2010,332430,0.016350463783969125
"The Development of a Noninvasive Monitoring System for Cigarette Smoking    DESCRIPTION (provided by applicant): Cigarette smoking is the leading cause of preventable death in the United States. Smoking produces over 440,000 deaths each year in this country and generates an estimated $167 billion in annual health-related economic losses. Available methods of smoking assessment (e.g., self-report, portable puff-topography instruments) do not permit the collection of accurate, non-reactive measures of smoking behavior that capture real-time smoking frequency and comprehensive within-cigarette puff topography. The objective of this project is to develop a non-invasive wearable system (Personal Automatic Cigarette Tracker - PACT) that is completely transparent to the end user and does not require any conscience effort to achieve reliable monitoring of smoking behavior in free living individuals. Methodologically, PACT will consist of two major components: 1. Wearable sensors. Miniature sensors integrated into the clothing will monitors the breathing and activity patterns of individuals. The signals from the sensors will be processed and recognized to identify and objectively characterize each individual puff. 2. Software for signal processing and pattern recognition. Automatic computer software will analyze sensor signals and detect patterns uniquely identifying smoking events. Objective metrics such as number of puffs and inter-puff interval will be extracted. The software will be based on the state-of-art machine learning methods. The development of the PACT system will be addressed in four specific aims: Specific Aim 1: Develop a wearable sensor system comprised of a breathing sensor integrated into conventional underwear and a hand gesture sensor integrated into a hand bracelet. Specific Aim 2: Collect sensor data from individuals wearing the instrumented system and performing everyday activities (including smoking) in laboratory conditions. Specific Aim 3: Develop pattern recognition methods to recognize individual puffs and smoke inhalation. Specific Aim 4: Evaluate the utility and sensitivity of the wearable sensor PACT system and pattern recognition method in people smoking in the natural environment. This set of Specific Aims will validate lead to creation of a unique wearable device capable of objective characterization of smoking behavior.      PUBLIC HEALTH RELEVANCE: Cigarette smoking is the leading cause of preventable death in the United States. Smoking produces over 440,000 deaths each year in this country and generates an estimated $167 billion in annual health-related economic losses. The goal of this research is to develop a non-invasive wearable system (Personal Automatic Cigarette Tracker - PACT) that is completely transparent to the end user and does not require any conscious effort to achieve reliable monitoring of smoking behavior in free living individuals. The PACT device will provide an accurate and precise measure of real-world smoking. The device can provide the user and health professional feedback on the frequency of smoking and inhalation patterns (such as depth of inhalation and smoke holding) throughout the day in their home and community. This information can be used to inform behavioral strategies in smoking cessation programs. The data collected by PACT can also provide an objective method of assessing the effectiveness of behavioral and pharmacological smoking interventions.          PUBLIC HEALTH RELEVANCE: Cigarette smoking is the leading cause of preventable death in the United States. Smoking produces over 440,000 deaths each year in this country and generates an estimated $167 billion in annual health-related economic losses. The goal of this research is to develop a non-invasive wearable system (Personal Automatic Cigarette Tracker - PACT) that is completely transparent to the end user and does not require any conscious effort to achieve reliable monitoring of smoking behavior in free living individuals. The PACT device will provide an accurate and precise measure of real-world smoking. The device can provide the user and health professional feedback on the frequency of smoking and inhalation patterns (such as depth of inhalation and smoke holding) throughout the day in their home and community. This information can be used to inform behavioral strategies in smoking cessation programs. The data collected by PACT can also provide an objective method of assessing the effectiveness of behavioral and pharmacological smoking interventions.",The Development of a Noninvasive Monitoring System for Cigarette Smoking,8089048,R21DA029222,"['Address', 'Algorithms', 'Applications Grants', 'Arts', 'Behavioral', 'Breathing', 'Burn injury', 'Calculi', 'Cellular Phone', 'Cessation of life', 'Characteristics', 'Cigarette', 'Clothing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Conscience', 'Conscious', 'Consumption', 'Country', 'Data', 'Data Set', 'Development', 'Devices', 'Eating', 'Economics', 'Effectiveness', 'Electronics', 'Environment', 'Event', 'Exhalation', 'Exposure to', 'Feedback', 'Frequencies', 'Future', 'Gestures', 'Goals', 'Hand', 'Health', 'Health Professional', 'Home environment', 'Hour', 'Individual', 'Instruction', 'Laboratories', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Metric', 'Monitor', 'Oral cavity', 'Patient Self-Report', 'Pattern', 'Pattern Recognition', 'Pattern Recognition Systems', 'Phase', 'Process', 'Reporting', 'Research', 'Signal Transduction', 'Smoke', 'Smoker', 'Smoking', 'Smoking Behavior', 'System', 'Testing', 'Time', 'Training', 'United States', 'United States Dept. of Health and Human Services', 'Validation', 'Variant', 'Walking', 'Work', 'Workplace', 'base', 'cigarette smoking', 'cigarette smoking', 'computerized data processing', 'diaries', 'expiration', 'instrument', 'programs', 'public health relevance', 'respiratory', 'sensor', 'smoke inhalation', 'smoking cessation', 'smoking intervention']",NIDA,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R21,2010,187368,-0.008483475808627388
"Harnessing Motoneuron Activity: From Lab to Clinic    DESCRIPTION (provided by applicant):  We propose to continue the development of an automatic system that will accurately and quickly decompose electromyographic (EMG) signals into their constituent action potentials and provide the timing of every firing of a set of concurrently active motor units. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system. We will improve the performance of the decomposition algorithms by incorporating new Artificial Intelligence concepts, and a new multi-strategy Hidden Markov Model (HMM) processing stage, to address signal decomposition challenges that cannot be met by the present technology. We will improve the present accuracy from typically 85% for 8 concurrently active motor units to greater than 96% for up to 15 concurrently active motor units. We will also design and build the hardware and software for a stand-alone portable system that may be used in the laboratory or clinic. Then we will transfer the system to a manufacturer for commercialization. In so doing we will produce, for the first time, an advanced system for conveniently and accurately obtaining the firings of a large group of concurrently active motor units from an EMG signal. The new technology will be tested in two applied studies that will be carried out concurrently with the technical developments. One will investigate neural modifications in the firing characteristics of motor units as a function of aging and physical activity. The other will investigate the mitigating effects of resistive exercise on age-related neural adaptations, culminating in the development of a clinical marker to estimate the likelihood that an elderly individual will benefit from an exercise program. The proposed BRP will be lead by Drs. De Luca, Roy, and Adam, key personnel from Boston University (BU) with expertise in biomedical engineering and EMG system development. Signal processing/software development will be provided by the leadership from Dr. Nawab through BU's Department of Electrical and Computer Engineering. Clinical expertise on aging/motor control will be provided by Dr. Novak, from The Department of Neurology at BU School of Medicine, and through Dr. Wolf, from the Department of Rehabilitation Medicine at the Emory University School of Medicine in Atlanta           n/a",Harnessing Motoneuron Activity: From Lab to Clinic,7860691,R01HD050111,"['Action Potentials', 'Address', 'Age', 'Aging', 'Algorithms', 'Artificial Intelligence', 'Biomedical Engineering', 'Boston', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Markers', 'Computer Systems Development', 'Computer software', 'Computers', 'Development', 'Elderly', 'Electrodes', 'Engineering', 'Exercise', 'Human Resources', 'Individual', 'Laboratories', 'Lead', 'Leadership', 'Manufacturer Name', 'Medicine', 'Modeling', 'Modification', 'Motor', 'Motor Neurons', 'Neurology', 'Performance', 'Physical activity', 'Process', 'Rehabilitation therapy', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Universities', 'Wolves', 'Work', 'advanced system', 'age related', 'commercialization', 'computerized data processing', 'design', 'improved', 'markov model', 'mathematical model', 'medical schools', 'meetings', 'motor control', 'neuroadaptation', 'neuromuscular system', 'new technology', 'programs', 'relating to nervous system', 'software development']",NICHD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2010,563762,0.00490623124947912
"A mobile Enabling Technology to promote adherence to behavioral therapy    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (06) Enabling Technologies, 06-DA-105: Improving health through ICT/mobile technologies. The ultimate goal of this research is to fundamentally change the ways in which behavioral interventions are delivered. We propose an innovative mobile Enabling Technology-iHeal-that recognizes stressors that threaten a patient's recovery and then delivers evidence-based interventions exactly at the moment of greatest need. Our objective is to determine, within subjects, the extent to which physiologic and affective changes detected by iHeal are predictive, within subjects, of posttraumatic stress or drug cues. The study team has considerable expertise in technology development and in assessment of behavioral interventions in co-occurring disorders. We will study 25 subjects drawn from an existing SAMHSA-funded investigation that utilizes intense case management to monitor progression of PTSD and substance abuse in returning combat veterans. Our proposed investigation will share interventions with the SMAHSA study that are based upon a blending of Motivational Interviewing and Cognitive Behavioral Therapy approaches for PTSD and substance abuse. Specific aims: 1) To evaluate the accuracy with which iHeal characterizes physiological and affective phenomena as acute stress reactions related to PTSD and environmental drug cues; and 2) To evaluate the effect of Motivational Interviewing-based interventions on acute stress reactions related to PTSD and environmental drug cues. This initial proposal is extremely innovative. The proposed iHeal device will employ cutting-edge wireless technology to link wearable sensors to personal mobile computing platforms (e.g., iPhone). This linkage will allow iHeal to detect co-occurring biological and behavioral processes, while embedded computing in the mobile platform permits iHeal to deliver evidence-based empathetic interventions at the opportune moment. iHeal can learn to intervene in ways that are most effective for the user, including scripted text-based dialogues modeled after brief interventions; use of motivating images or messages from loved ones; playing a meaningful song; or contacting a counselor at the moment of greatest need. Ultimately, a wearable wireless device that anticipates stressors and intervenes at a likely transition to risky activities has enormous potential in a variety of social, behavioral, and biomedical research enterprises. Importantly, iHeal has immediate commercial applications that will encourage job growth in behavioral science, biomedical, computer science, telecommunication, and electrical engineering enterprises. iHeal is an innovative device that uses wearable sensors to detect pulse, skin conductance, and acceleration; the sensor array links wirelessly to an iPhone which has an app that identifies changes in the user's physiology. Changes consistent with acute stress from PTSD exacerbations or drug use cues generate an empathetic conversation between the iPhone and the user, who enters real-time data on social/behavioral/environmental contexts. The iPhone (which tracks time and GPS data) uses predictive software to anticipate upcoming stressors and helps the user avoid them. The public health significance of this proposal is 1) iHeal will detect co-occurring biological and behavioral processes in real time; 2) it will discern undiscovered behavioral states; 3) it will predict a behavior of interest; and 4) it will deliver empathetic interventions to the user at the opportune moment for intervention. Because it is based on the union of existing technology and has immediate commercial applications, iHeal will encourage job growth in behavioral science, biomedical, computer science, telecommunication, and electrical engineering enterprises.               Project Narrative iHeal is an innovative device that uses wearable sensors to detect pulse, skin conductance, and acceleration; the sensor array links wirelessly to an iPhone which has an app that identifies changes in the user's physiology. Changes consistent with acute stress from PTSD exacerbations or drug use cues generate an empathetic conversation between the iPhone and the user, who enters real-time data on social/behavioral/environmental contexts. The iPhone (which tracks time and GPS data) uses predictive software to anticipate upcoming stressors and helps the user avoid them. The public health significance of this proposal is 1) iHeal will detect co-occurring biological and behavioral processes in real time; 2) it will discern undiscovered behavioral states; 3) it will predict a behavior of interest; and 4) it will deliver empathetic interventions to the user at the opportune moment for intervention. Because it is based on the union of existing technology and has immediate commercial applications, iHeal will encourage job growth in behavioral science, biomedical, computer science, telecommunication, and electrical engineering enterprises.",A mobile Enabling Technology to promote adherence to behavioral therapy,7941740,RC1DA028428,"['Acceleration', 'Acute', 'Address', 'Adherence', 'Adopted', 'Adoption', 'Affect', 'Affective', 'Afghanistan', 'Area', 'Artificial Intelligence', 'Arts', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Behavioral Sciences', 'Biological', 'Biomedical Research', 'Case Management', 'Chronic', 'Clinical', 'Cognitive Therapy', 'Communication', 'Computer software', 'Cues', 'Data', 'Devices', 'Disease', 'Drug usage', 'Effectiveness of Interventions', 'Electrical Engineering', 'Enrollment', 'Environment', 'Evidence based intervention', 'Feasibility Studies', 'Feedback', 'Funding', 'Galvanic Skin Response', 'Goals', 'Growth', 'Health', 'Hour', 'Image', 'Intervention', 'Investigation', 'Iraq', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Mental Health', 'Methods', 'Modeling', 'Monitor', 'Occupations', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Physiologic Monitoring', 'Physiologic pulse', 'Physiological', 'Physiology', 'Play', 'Population', 'Population Study', 'Post-Traumatic Stress Disorders', 'Process', 'Professional counselor', 'Public Health', 'Recovery', 'Recruitment Activity', 'Research', 'Risk Behaviors', 'Services', 'Stress', 'Substance abuse problem', 'Technology', 'Telecommunications', 'Text', 'Time', 'United States Substance Abuse and Mental Health Services Administration', 'Veterans', 'Wireless Technology', 'acute stress', 'acute traumatic stress disorder', 'base', 'biomedical Computer science', 'brief intervention', 'combat', 'commercial application', 'cost effectiveness', 'disorder later incidence prevention', 'evidence base', 'experience', 'follow-up', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'loved ones', 'motivational enhancement therapy', 'new technology', 'novel', 'response', 'sensor', 'social', 'stressor', 'study characteristics', 'substance abuse treatment', 'technology development']",NIDA,UNIV OF MASSACHUSETTS MED SCH WORCESTER,RC1,2010,496273,0.016547893950526363
"Camera-based Text Recognition from Complex Backgrounds for the Blind or Visually There are more than 10 million blind and visually impaired people living in America today. Recent technology developments in computer vision, digital cameras, and portable computers make it possible to assist these individuals by developing camera-based products that combine computer vision technology with other existing products.  Although a number of reading assistants have been designed specifically for people who are blind or visually impaired, reading text from complex backgrounds or non-flat surfaces is very challenging and has not yet been successfully addressed. Many everyday tasks involve these challenging conditions, such as reading instructions on vending machines, titles of books aligned on a shelf, instructions on medicine bottles or labels on soup cans.  This proposal focuses on the development of new computer vision algorithms to recognize text from complex backgrounds: 1) from backgrounds with multiple different colors (e.g .. the titles of books lined up on a shelf) and 2) from non-flat surfaces (e.g .. labels on medicine bottles or soup cans). The newly developed computer vision techniques will be integrated with off-the-shelf optical character recognition (OCR) and speech-synthesis software products. Visual information will be captured via a head-mounted camera (on sunglasses or hat) and analyzed by a portable computer (PDA or cell phone), while the speech display will be outputted via mini speakers, earphones, or Bluetooth device. A practical reading system prototype will be produced to read text from complex backgrounds and non-flat surfaces. The system will be cost-effective since it requires only a head mounted camera (<US$100 for 1M resolution), a wearable computer (<US$300), and two mini-speakers or earphones. The price of ""ReadIRlS"" [74] OCR software is under $150 and the ""TextAloud"" speech synthesis software is about $30 [75].  This project will be executed over two years at the City College of New York (CCNY) and Lighthouse International, New York. CCNY, located in the Harlem neighborhood of New York City, is designated as both a Minority Institution and a Hispanic-serving Institution (37% Hispanic and 27% African American). Lighthouse International is a leading non-profit organization dedicated to preserving vision and to providing critically needed vision and rehabilitation services to help people of all ages overcome the challenges of vision loss. During the two years, we will 1) develop new algorithms to recognize text from backgrounds with multiple different colors; 2) develop new algorithms to recognize text from non-flat surfaces; and 3) develop a cost-effective prototype reading system for blind users by integrating with off-the-shelf optical character recognition (OCR) and speech-synthesis software products. The effectiveness of the prototype and algorithms will be evaluated by people with normal vision and people with vision impairment. A database of text on complex backgrounds (multiple colors and non-flat surfaces) will be created for algorithm and system evaluation. The database will be made available to research communities in the areas of computer vision and vision rehabilitation science. In summary, this effort will provide a research-based foundation to inform the design of next generation reading assistants for blind persons, as well as produce a practical prototype to help the blind user read text from complex backgrounds in real-world environments. PROJECT NARRATIVE  The goal of the proposed research is to develop new computer vision algorithms for camera-based text recognition from complex backgrounds and non-flat surfaces, as well as produce a practical reading system prototype in combination with off-the-shelf  optical character recognition (OCR) and speech-synthesis software products, to help blind or visually impaired people read instructions on vending machines, titles of books aligned on a shelf, labels on medicine bottles or soup cans, etc. Visual information will be captured via a head-mounted camera (on sunglasses or hat) and analyzed in realtime through a portable computer, such as a mini laptop or a personal digital assistant (PDA). The speech display will be outputted via mini speakers, earphones, or Bluetooth device.",Camera-based Text Recognition from Complex Backgrounds for the Blind or Visually,7977496,R21EY020990,"['Address', 'African American', 'Age', 'Algorithms', 'Americas', 'Area', 'Blindness', 'Books', 'Cellular Phone', 'Cities', 'Color', 'Communities', 'Complex', 'Computer Systems Development', 'Computer Vision Systems', 'Computer software', 'Computers', 'Databases', 'Development', 'Devices', 'Effectiveness', 'Environment', 'Evaluation', 'Event', 'Facial Expression Recognition', 'Foundations', 'Goals', 'Grant', 'Head', 'Hispanics', 'Image', 'Impairment', 'Individual', 'Institution', 'Instruction', 'International', 'Label', 'Letters', 'Life', 'Mails', 'Marketing', 'Medicine', 'Methods', 'Minority', 'Neighborhoods', 'New York', 'New York City', 'Nonprofit Organizations', 'Output', 'Personal Digital Assistant', 'Price', 'Printing', 'Reading', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Resolution', 'Running', 'Scientist', 'Shapes', 'Solutions', 'Speech', 'Surface', 'System', 'Techniques', 'Technology', 'Text', 'Thick', 'Time', 'United States National Institutes of Health', 'Vertebral column', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Writing', 'base', 'blind', 'college', 'computer generated', 'computer human interaction', 'cost', 'design', 'digital', 'experience', 'laptop', 'next generation', 'optical character recognition', 'prototype', 'rehabilitation science', 'rehabilitation service', 'research and development', 'sunglasses', 'technology development', 'visual information']",NEI,CITY COLLEGE OF NEW YORK,R21,2010,190000,0.012245830505577126
"Toward an Animal Model of Freely Moving Humans Our overarching goal is to establish an animal model of freely moving humans. We choose to do so in order to directly measure the context-dependency of motor cortical activity and, ultimately, other activity reliant upon free movement such as social interaction among animals. Achieving this major technological challenge requires a complete system that includes (Specific Aim 1) wireless transmission of neural data from electrode arrays chronically implanted in monkeys, (Specific Aim 2) computer-vision algorithms to automatically extract body and limb orientation during free movement, and (Specific Aim 3) new mathematical and computational models to represent and extract information from high-dimensional neural and behavioral activity. This technology will enable an animal model of freely moving humans that will advance the development of cortical neural prostheses by providing models of the context-dependant nature of motor cortical control.  Unlike traditional laboratory environments used to study animal movement, human amputees and tetraplegics operate in a variety of contexts that involve their movement in the world. Understanding the motor control of complex movement in these natural settings is absolutely critical for future advances in cortically- controlled prostheses. Given our overarching goal, our hypothesis is that motor cortical activity (e.g., directional tuning curves, absolute firing rates, correlations among units, etc.) will be different in important ways when rhesus monkeys perform the same reaching arm movements in an un-constrained context (e.g., not sitting quietly, not head restrained, not in dark and quiet room, etc.) as in a traditional, highly constrained context. Our three Specific Aims will put in place the electronic, computational and mathematical technology necessary to address this hypothesis, and also to make such studies of free behavior in rhesus monkeys possible. The innovative integration of neural engineering, neuroscience, computer vision, mathematics and neural modeling will provide new tools to enable the unprecedented study of motor control during natural, unconstrained behavior.  PROJECT NARRATIVE The proposed research project is directly relevant to both basic neuroscience studies of higher brain function and to neural prosthesis research aimed at, ultimately, helping patients with motor disorders. We will conduct neurophysiological and behavioral experiments with rhesus monkeys in two different contexts - ""in home cage"" and ""in rig"" - to investigate the context dependence of motor cortical activity. With this knowledge, we will then design ""context independent"" models of the neural-behavioral relationship which we, and other researchers, could then use in neural prosthetic experiments while monkeys freely move around their less- constrained home cages.",Toward an Animal Model of Freely Moving Humans,7883275,R01NS066311,"['Address', 'Advanced Development', 'Algorithms', 'Amputees', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Dependence', 'Dependency', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Future', 'Goals', 'Head', 'Home environment', 'Human', 'Implant', 'Knowledge', 'Laboratories', 'Limb structure', 'Macaca mulatta', 'Mathematics', 'Measures', 'Modeling', 'Monkeys', 'Motor', 'Movement', 'Nature', 'Neurosciences', 'Patients', 'Prosthesis', 'Quadriplegia', 'Research', 'Research Personnel', 'Research Project Grants', 'Social Interaction', 'Synaptic Transmission', 'System', 'Technology', 'Wireless Technology', 'arm', 'design', 'free behavior', 'innovation', 'motor control', 'motor disorder', 'neural model', 'neural prosthesis', 'neurophysiology', 'relating to nervous system', 'research study', 'tool']",NINDS,STANFORD UNIVERSITY,R01,2010,303756,0.017916109070750336
"Wearable-Sensor System for Monitoring Motor Function    DESCRIPTION (provided by applicant): We propose to develop a wearable Personal Status Monitor for improving the medication management of Parkinson's Disease patients by monitoring the effects of the medication continuously during the day. New outcome measures are needed to supplement the self-reports currently in use that are ineffective in managing the complex and unpredictable nature of movement disorders in this population. The device we propose to develop can be worn unobtrusively by patients in their home to automatically provide the following clinically significant information: 1) the presence and severity of specific primary and secondary movement disorders associated with the disease, 2) the status of  On-Off motor fluctuation in response to anti-Parkinson's medication, and 3) the mobility status of the patient. The patient will be monitored by specially designed electromyographic (EMG) and accelerometric (ACC) body-worn sensors. Their signals will be analyzed by a novel Artificial Intelligence knowledge-based signal processing method developed by our group specifically for this purpose. Success of the system will be based on classification accuracy compared to observation by experts. The proposal is composed of two projects. The first and dominant project will develop the underlying technological requirements for the PSM system's application to Parkinson's disease. The aims will include acquisition hardware development in the form of hybrid EMG/ACC sensors. However, the emphasis will be on the development of the knowledge-based algorithms and their software implementation. The second project is designed to acquire the knowledge base needed in Project 1 through data collection experiments from control subjects and patients with Parkinson's disease. The experiments are designed to advance the algorithm development in a hierarchical manner starting from highly standardized activities to free-form activities which approximate real-world conditions. The development of the system will be constructed so that future versions can be adapted to other movement disorders. The successful development of this technology will be transferred for commercial development with the financial assistance of the Massachusetts Community Technology Foundation.         n/a",Wearable-Sensor System for Monitoring Motor Function,7922046,R01EB007163,"['Activities of Daily Living', 'Age', 'Algorithms', 'Artificial Intelligence', 'Body Surface', 'Bradykinesia', 'Cardiac', 'Classification', 'Clinical', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Data', 'Data Collection', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Effectiveness', 'Essential Tremor', 'Exertion', 'Exhibits', 'Fingers', 'Foundations', 'Freezing', 'Future', 'Gilles de la Tourette syndrome', 'Holter Electrocardiography', 'Home environment', 'Huntington Disease', 'Hybrids', 'Inherited Spinocerebellar Degenerations', 'Interview', 'Investigation', 'Kinetics', 'Levodopa', 'Limb structure', 'Lower Extremity', 'Massachusetts', 'Measurement', 'Medical', 'Medication Management', 'Methods', 'Monitor', 'Motion', 'Motor', 'Motor Activity', 'Movement Disorders', 'Muscle', 'Nature', 'Neurologist', 'Neuromuscular Diseases', 'Nose', 'Operative Surgical Procedures', 'Outcome Measure', 'Parkinson Disease', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phase II Clinical Trials', 'Population', 'Posture', 'Principal Investigator', 'Questionnaires', 'Recording of previous events', 'Research Personnel', 'Sampling', 'Severities', 'Signal Transduction', 'Simulate', 'Small Business Innovation Research Grant', 'Specialist', 'Staging', 'System', 'Tardive Dyskinesia', 'Technology', 'Testing', 'Text', 'Time', 'Tremor', 'Upper Extremity', 'Walking', 'Wireless Technology', 'Work', 'base', 'clinically significant', 'computerized data processing', 'design', 'diaries', 'improved', 'kinematics', 'knowledge base', 'miniaturize', 'monitoring device', 'motor disorder', 'nervous system disorder', 'novel', 'programs', 'prototype', 'research study', 'response', 'sensor', 'statistics', 'success', 'technology development', 'tool']",NIBIB,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2010,654993,0.042841374281923326
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7799708,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'image processing', 'meetings', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'public health relevance', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2010,427932,0.00853701712935333
"Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju    DESCRIPTION (provided by applicant): Establishing structure-function correlations is fundamental to understanding how information is processed in the central nervous system (CNS). Axonal connectivity is a key relationship that facilitates information transmission and reception within the CNS. Recently, diffusion weighted magnetic resonance imaging (DW-MRI) methods have been shown to provide fundamental information required for viewing structural connectivity and have allowed visualization of fiber bundles in the CNS in vivo. In this project, we propose to develop methods for extraction and analysis of these patterns from high angular resolution diffusion weighted images (HARDI) that is known to have better resolving power over diffusion tensor imaging (DTI). To this end, a biologically relevant and clinically important model has been chosen to study changes in the organization of fibers in the intact and injured spinal cord. Our hypothesis is that, changes in geometrical properties of the anatomical substrate, identifying the region of injury and neuroplastic changes in distant spinal segments, correlate with different magnitudes of injury and levels of locomotor recovery following spinal cord injury (SCI). Prior to hypothesis testing, we will denoise the HARDI data and then construct a normal atlas cord. Deformable registration and tensor morphometry between a normal atlas and an injured cord would be performed to provide a distinct signature for each type of behavior recovery associated with the SCI substrate. Validation of the hypothesis will be performed through systematic histological analysis of cord samples following acquisition of the HARDI data. Spinal cords will be cut and stained with fiber and cell stains to verify changes in anatomical organization that result from contusive injury (common in humans as well) to the spinal cord. A comparison between anatomical characteristics obtained from histological versus HARDI analysis will provide validation for the image analysis and the hypothesis. Three severities of spinal cord injuries will be produced (light, mild and moderate contusions) based upon normed injury device parameters. The structural signatures of these labeled data subsets will then be identified. Automatic classification of novel & injured cord HARDI data sets will then be achieved using a large margin classifier. Finally, HARDI data acquired over time will be analyzed in order to learn and predict the level of locomotor recovery by studying the structural changes over time and developing a dynamic model of structural transformations corresponding to each chosen class. We will use an auto-regressive model in the feature space to track and predict structural changes in SCI and correlate it to functional recovery.       PUBLIC HEALTH RELEVANCE: This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Diffusion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from diffusion MRI scans.                 Narrative This project involves the development of automated methods to extract morphological signatures that characterize changes in spinal cord injury (SCI) substrate estimated from Di(R)usion MRI scans of rats, and predict the functional recovery by correlating to behavioral studies. Although the various algorithms developed here are for analysis of SCI, they can be used in other applications such as traumatic brain injury, in tracking and predicting developmental changes etc. from di(R)usion MRI scans.",Automated Assessment of Structural Changes & Functional Recovery Post Spinal Inju,7903516,R01NS066340,"['Algorithms', 'Atlases', 'Behavior', 'Behavioral', 'Categories', 'Cations', 'Characteristics', 'Classification', 'Communities', 'Contusions', 'Data', 'Data Collection', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Distant', 'Fiber', 'Goals', 'Human', 'Image Analysis', 'Imagery', 'In Vitro', 'Injury', 'Label', 'Learning', 'Left', 'Light', 'Literature', 'Locomotion', 'Locomotor Recovery', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Metric', 'Modeling', 'Motor', 'Neuraxis', 'Pattern', 'Population', 'Population Control', 'Population Registers', 'Probability', 'Process', 'Property', 'Rattus', 'Recovery', 'Recovery of Function', 'Research', 'Resolution', 'Sampling', 'Sensory', 'Severities', 'Solutions', 'Sorting - Cell Movement', 'Spinal', 'Spinal Cord', 'Spinal cord injury', 'Staging', 'Staining method', 'Stains', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Time', 'Traumatic Brain Injury', 'Validation', 'Water', 'Weight', 'base', 'clinically relevant', 'density', 'expectation', 'fiber cell', 'imaging modality', 'in vivo', 'injured', 'interest', 'member', 'morphometry', 'novel', 'public health relevance', 'sensor', 'statistics', 'transmission process']",NINDS,UNIVERSITY OF FLORIDA,R01,2010,506525,0.006545124460145709
"A Cell Phone-based Sign Reader for Blind & Visually Impaired Persons    DESCRIPTION (provided by applicant): We propose to develop and evaluate a cell-phone-based system to enable blind and visually impaired individuals to find and read street signs and other signs relevant to wayfinding. Using the built-in camera and computing power of a standard cell phone, the system will process images captured by the user to find and analyze signs, and speak their contents. This will provide valuable assistance for blind or visually impaired pedestrians in finding and reading street signs, as well as locating and identifying addresses and store names, without requiring them to carry any special-purpose hardware. The sign finding and reading software will be made freely available for download into any camera-equipped cell phone that uses the widespread Symbian operating system (such as the popular Nokia cell phone series). We will build on our prior and ongoing work in applying computer vision techniques to practical problem-solving for blind persons, including cell-phone implementation of algorithms for indoor wayfinding and for reading digital appliance displays. We will develop, refine and transfer to the cell phone platform a new belief propagation-based algorithm that has shown preliminary success in finding and analyzing signs under difficult real-world conditions including partial shadow coverage. Human factors studies will help determine how to configure the system and its user controls for maximum effectiveness and ease of use, and provide an evaluation of the overall system. Access to environmental labels, signs or landmarks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.          n/a",A Cell Phone-based Sign Reader for Blind & Visually Impaired Persons,7911722,R01EY018210,"['Accidents', 'Address', 'Algorithms', 'American', 'Belief', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Databases', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Evaluation', 'Face', 'Figs - dietary', 'Generations', 'Grant', 'Human', 'Image', 'Impairment', 'Individual', 'Label', 'Left', 'Mainstreaming', 'Marketing', 'Modification', 'Names', 'Operating System', 'Performance', 'Problem Solving', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Sampling', 'Self-Help Devices', 'Series', 'Shadowing (Histology)', 'Signal Transduction', 'Speech', 'System', 'Target Populations', 'Techniques', 'Testing', 'Text', 'Training', 'Travel', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'base', 'blind', 'consumer product', 'cost', 'design', 'digital', 'experience', 'image processing', 'improved', 'legally blind', 'novel', 'open source', 'operation', 'prevent', 'programs', 'prototype', 'skills', 'success', 'tool', 'way finding', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2010,423145,0.03659839492990564
"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",A Wireless Multiscale Distributed Interface to the Cortex,7903986,R01NS062031,"['Address', 'Advanced Development', 'Algorithms', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cavia', 'Cell physiology', 'Characteristics', 'Communication', 'Computer software', 'Custom', 'Data', 'Devices', 'Discipline', 'Disease', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Imaging technology', 'Implant', 'In Vitro', 'Investigation', 'Learning', 'Machine Learning', 'Mediating', 'Microelectrodes', 'Monitor', 'Motor', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Outcome', 'Paralysed', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Rattus', 'Research', 'Retinal', 'Rodent', 'Rodent Model', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Slice', 'Stimulus', 'Stream', 'System', 'Telemetry', 'Testing', 'Time', 'Wireless Technology', 'awake', 'base', 'brain cell', 'brain machine interface', 'clinical application', 'computerized data processing', 'data acquisition', 'data exchange', 'density', 'design', 'disability', 'implantation', 'improved', 'in vivo', 'information processing', 'microsystems', 'nervous system disorder', 'neural circuit', 'operation', 'prototype', 'public health relevance', 'quantum', 'relating to nervous system', 'response', 'subcutaneous', 'tool']",NINDS,MICHIGAN STATE UNIVERSITY,R01,2010,511198,0.0029488115388662303
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,7743573,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical and Translational Science Awards', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2010,724428,0.009981621680355362
"Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface    DESCRIPTION (provided by applicant):      Over 600,000 Americans have severely impaired motor function from disorders including spinal cord injury, amyotrophic lateral sclerosis, pontine stroke, and cerebral palsy. A brain-machine interface (BMI) could enable locked-in or tetraplegic patients to communicate and interact with their environment. Two crucial decisions in designing a BMI are (1) what type of brain signals to use as inputs to a controller and (2) what methods to use to decode those signals. Most BMIs have used either noninvasive scalp EEG recordings or invasive intracortical recordings of single- or multi-neuron spikes as control inputs. A few have used subdural or intracortical local field potentials (LFPs). However, no group has yet systematically compared these signals in motor cortex for use in BMI applications. This proposal's first goal is to assess the relative performance of spikes and field potentials (both intracortical and epidural) as control inputs for a variety of movement-related outputs. Epidural field potentials (EFPs) are intermediate in invasiveness, signal quality, stability and spatial resolution compared with existing scalp, subdural, and intracortical recordings, and thus represent an unexplored middle ground. This proposal's second goal is to evaluate linear and nonlinear techniques-including several novel to BMI applications-for both decoding data and reducing the inherently large dimensionality of data from multiple neural signals. The primary hypotheses of the proposed project are (1) that spikes will perform better in decoding more complex movement-related outputs, but that field potentials may perform similarly on decoding simpler outputs, and (2) that nonlinear decoders and dimensionality-reduction techniques may provide improved accuracy over linear methods. The specific aims to address these hypotheses are 1) to evaluate single neuron spikes as inputs to decoders of movement- related outputs, 2) to develop a novel epidural multi-electrode recording technique in the macaque monkey, and 3) to evaluate field potential signals as inputs to decoders of movement-related outputs. Aims 1 and 3 will involve application of dimensionality-reduction algorithms (e.g., independent components analysis, Isomap) and decoding algorithms (system identification, neural networks, support vector machines) to both spikes and field potentials. Aim 2 will entail using a computer model and spatial spectral analysis to optimize the epidural electrode array design. This project will provide the first comparison of spikes, LFPs and EFPs as inputs for identical BMI output applications. The supervision of Drs. Lee Miller and W. Zev Rymer, with additional guidance from Drs. Simon Levine, Jonathan Wolpaw and Nicholas Hatsopoulos, will provide the principal investigator with expertise in recording and processing both spikes and field potentials for BMI applications using a variety of state-of-the- art techniques. A comprehensive career development plan including clinical and research mentoring, seminars, and courses, will foster the candidate's transition into an independent physician-scientist.           n/a",Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface,7876844,K08NS060223,"['Action Potentials', 'Address', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Arts', 'Benchmarking', 'Biological Neural Networks', 'Brain', 'Cerebral Palsy', 'Cervical spinal cord injury', 'Clinical Research', 'Complex', 'Computer Simulation', 'Craniotomy', 'Data', 'Development Plans', 'Discriminant Analysis', 'Disease', 'Dura Mater', 'Electrodes', 'Electroencephalography', 'Environment', 'Evaluation', 'Figs - dietary', 'Fostering', 'Frequencies', 'Genetic Programming', 'Goals', 'Hand', 'Implant', 'Implanted Electrodes', 'Knowledge', 'Learning', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Physicians', 'Pontine structure', 'Principal Investigator', 'Procedures', 'Process', 'Quadriplegia', 'Rattus', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Scalp structure', 'Scientist', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Statistical Methods', 'Stroke', 'Sum', 'Supervision', 'System', 'Techniques', 'Time', 'Tissues', 'Training', 'Visual', 'arm', 'brain machine interface', 'career development', 'computerized data processing', 'cranium', 'design', 'disability', 'feeding', 'flexibility', 'improved', 'in vivo', 'independent component analysis', 'motor control', 'novel', 'programs', 'prototype', 'relating to nervous system', 'research study', 'surgical technique development']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,K08,2010,167832,0.009360221344355102
"Handsight: Mobile Services for Low Vision    DESCRIPTION (provided by applicant): Handsight is a mobile phone service that offers an affordable, extensible set of automated sight-assistant functions to millions of blind and low-vision persons at $30/month atop standard voice and data fees. To the user, Handsight is simply a mobile phone application, requiring no special equipment or updating. By aiming a mobile telephone<s camera in roughly the right direction and pressing just one button, a Handsight user can snap a picture, send it to the Handsight computer center along with location data, and have a response within seconds. Moving the key computation and data from the handset to web servers cut cost, eases technology upgrades, and enables numerous data and technology partnerships needed to rapidly solve a broad spectrum of tasks. To allow widespread adoption Handsight uses voice, keypad, and vibration for user interaction; and for extensibility it is built on open-source software both on the handset and on the web application infrastructure. The range of tasks encountered by the blind and low-vision requires an array of components to solve: some are more heavily text-oriented and involve no location/navigational feedback (distinguishing and identifying different medicines; finding the phone bill in a stack of letters); some are more specifically navigational (locating the exact store entrance, finding the bus stop); yet others are informational (finding out when the next bus is due). Since we aim to provide a broadly useful tool, Handsight has to accommodate the whole range of task types. We are therefore proposing to build an architecture that integrates a set of components addressing the various task types, from text-detection and recognition software to navigational databases. Handsight<s application programming interface (API) will enable third parties to add capabilities to solve new tasks. As a web service, Handsight can evolve as computer vision and navigation technologies advance without requiring users to upgrade handsets or buy new versions of software. Phase I of this project was funded by the Dept. of Education / NIDRR and completed successfully between 10/01/2007 and 04/01/2008 under grant # H133S070044. It demonstrated not just the viability of the proposed project but also likely demand for such a service. (The NIDRR<s immutable deadlines precluded us from pursuing a Phase II with that agency.) Phase II consists in building the cell phone application and remote processing infrastructure with APIs to enable plug-in of the basic and future features. Subcontractor Smith-Kettlewell Institute for Eye Research will assure usability by blind and low-vision users; data partner NAVTEQ will provide a range of leading-edge digital map data. Blindsight already owns fast, accurate text detection and recognition software, and has experience in building scalable web services. A minimum set of features that make for a system with widespread appeal will be developed and/or licensed, and integrated into the service.      PUBLIC HEALTH RELEVANCE: The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today<s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, and shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.        Re: Project Title: Handsight: Mobile Services for Low Vision  FOA: PHS 2009-02 Omnibus Solicitation of the NIH, CDC, FDA and ACF for Small Business  Innovation Research Grant Applications (Parent SBIR [R43/R44])  Proposed project period: April 1, 2010 - March 31, 2012  Principal Investigator: Hallinan, Peter W. SF424 Research and Related Other Project Information: Project Narrative The proposed Handsight service falls squarely in the NEI mission to support research and programs with respect to visual disorders and the special health problems and requirements of the blind. It aims to provide a maximum of mobility and independence to the blind and low-vision using today�s mobile phone infrastructure via automated web services, using a minimum of specialized hardware and training. The 3 million-plus blind and low-vision persons in the U.S. encounter barriers to such activities of daily living as travel, navigation, shopping, reading and social interactions. The difficulty of recognizing when a friend is nearby, of finding a product in a grocery store, of making change or locating a destination building often require sighted friends or assistants to make these tasks possible. This is expensive, difficult to arrange, and increases dependence. The Handsight system will simplify or make possible to many a new set of tasks previously requiring human assistance or special-purpose devices.",Handsight: Mobile Services for Low Vision,7913126,R44EY020707,"['Activities of Daily Living', 'Address', 'Adoption', 'Architecture', 'Area', 'Businesses', 'Car Phone', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Dependence', 'Destinations', 'Detection', 'Devices', 'Education', 'Eye', 'Feedback', 'Fees', 'Focus Groups', 'Friends', 'Funding', 'Future', 'Grant', 'Health', 'Human', 'Individual', 'Institutes', 'Internet', 'Letters', 'Licensing', 'Location', 'Maps', 'Medicine', 'Methods', 'Mission', 'Parents', 'Persons', 'Phase', 'Plug-in', 'Principal Investigator', 'Process', 'Provider', 'Reading', 'Research', 'Research Design', 'Research Infrastructure', 'Research Institute', 'Research Project Grants', 'Research Support', 'Services', 'Simulate', 'Small Business Innovation Research Grant', 'Social Interaction', 'Special Equipment', 'System', 'Target Populations', 'Technology', 'Telephone', 'Text', 'Touch sensation', 'Training', 'Travel', 'United States National Institutes of Health', 'Update', 'Vision', 'Vision Disorders', 'Visual impairment', 'Voice', 'Work', 'blind', 'computer center', 'cost', 'design', 'digital', 'experience', 'falls', 'innovation', 'open source', 'programs', 'public health relevance', 'response', 'success', 'tool', 'usability', 'vibration', 'voice recognition']",NEI,BLINDSIGHT CORPORATION,R44,2010,656703,0.02345151649192811
"Computational Methods for Analysis of Mouth Shapes in Sign Languages    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hand) and by the nonmanual components (the face). These facial articulations perform significant semantic, prosodic, pragmatic, and syntactic functions. This proposal will systematically study mouth positions in ASL. Our hypothesis is that ASL mouth positions are more extensive than those used in speech. To study this hypothesis, this project is divided into three aims. In our first aim, we hypothesize that mouth positions are fundamental for the understanding of signs produced in context because they are very distinct from signs seen in isolation. To study this we have recently collected a database of ASL sentences and nonmanuals in over 3600 video clips from 20 Deaf native signers. Our experiments will use this database to identify potential mappings from visual to linguistic features. To successfully do this, our second aim is to design a set of shape analysis and discriminant analysis algorithms that can efficiently analyze the large number of frames in these video clips. The goal is to define a linguistically useful model, i.e., the smallest model that contains the main visual features from which further predictions can be made. Then, in our third aim, we will explore the hypothesis that the linguistically distinct mouth positions are also visually distinct. In particular, we will use the algorithms defined in the second aim to determine if distinct visual features are used to define different linguistic categories. This result will show whether linguistically meaningful mouth positions are not only necessary in ASL (as hypothesized in aim 1), but whether they are defined using non-overlapping visual features (as hypothesized in aim 3). These aims address a critical need. At present, the study of nonmanuals must be carried out manually, that is, the shape and position of each facial feature in each frame must be recorded by hand. Furthermore, to be able to draw conclusive results for the design of a linguistic model, it is necessary to study many video sequences of related sentences as produced by different signers. It has thus proven nearly impossible to continue this research manually. The algorithms designed in the course of this grant will facilitate this analysis of ASL nonmanuals and lead to better teaching materials.      PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.           Project Narrative Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for Analysis of Mouth Shapes in Sign Languages,8101448,R21DC011081,"['Academic achievement', 'Access to Information', 'Address', 'Adult', 'Algorithms', 'Applications Grants', 'Arts', 'Categories', 'Child', 'Clip', 'Communication', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Databases', 'Devices', 'Discriminant Analysis', 'Educational process of instructing', 'Emotions', 'Excision', 'Eye', 'Face', 'Funding', 'Goals', 'Grant', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Joints', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Manuals', 'Modeling', 'Oral cavity', 'Parents', 'Pattern Recognition', 'Positioning Attribute', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Shapes', 'Sign Language', 'Social Interaction', 'Specific qualifier value', 'Speech', 'Teaching Materials', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visual', 'Work', 'computerized tools', 'deafness', 'design', 'experience', 'innovation', 'instructor', 'interest', 'novel', 'prevent', 'public health relevance', 'research study', 'shape analysis', 'success', 'syntax', 'teacher', 'tool', 'visual map']",NIDCD,OHIO STATE UNIVERSITY,R21,2010,187999,-0.03100671436781591
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.           PROJECT NARRATIVE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,7608855,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'public health relevance', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'stem', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2009,164486,0.025053224833370507
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7668573,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,1187062,-0.006657641486763447
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7922310,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,152260,-0.006657641486763447
"Harnessing Motoneuron Activity: From Lab to Clinic    DESCRIPTION (provided by applicant):  We propose to continue the development of an automatic system that will accurately and quickly decompose electromyographic (EMG) signals into their constituent action potentials and provide the timing of every firing of a set of concurrently active motor units. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system. We will improve the performance of the decomposition algorithms by incorporating new Artificial Intelligence concepts, and a new multi-strategy Hidden Markov Model (HMM) processing stage, to address signal decomposition challenges that cannot be met by the present technology. We will improve the present accuracy from typically 85% for 8 concurrently active motor units to greater than 96% for up to 15 concurrently active motor units. We will also design and build the hardware and software for a stand-alone portable system that may be used in the laboratory or clinic. Then we will transfer the system to a manufacturer for commercialization. In so doing we will produce, for the first time, an advanced system for conveniently and accurately obtaining the firings of a large group of concurrently active motor units from an EMG signal. The new technology will be tested in two applied studies that will be carried out concurrently with the technical developments. One will investigate neural modifications in the firing characteristics of motor units as a function of aging and physical activity. The other will investigate the mitigating effects of resistive exercise on age-related neural adaptations, culminating in the development of a clinical marker to estimate the likelihood that an elderly individual will benefit from an exercise program. The proposed BRP will be lead by Drs. De Luca, Roy, and Adam, key personnel from Boston University (BU) with expertise in biomedical engineering and EMG system development. Signal processing/software development will be provided by the leadership from Dr. Nawab through BU's Department of Electrical and Computer Engineering. Clinical expertise on aging/motor control will be provided by Dr. Novak, from The Department of Neurology at BU School of Medicine, and through Dr. Wolf, from the Department of Rehabilitation Medicine at the Emory University School of Medicine in Atlanta           n/a",Harnessing Motoneuron Activity: From Lab to Clinic,7637376,R01HD050111,"['Action Potentials', 'Address', 'Age', 'Aging', 'Algorithms', 'Artificial Intelligence', 'Biomedical Engineering', 'Boston', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Markers', 'Computer Systems Development', 'Computer software', 'Computers', 'Development', 'Elderly', 'Electrodes', 'Engineering', 'Exercise', 'Human Resources', 'Individual', 'Laboratories', 'Lead', 'Leadership', 'Manufacturer Name', 'Medicine', 'Modeling', 'Modification', 'Motor', 'Motor Neurons', 'Neurology', 'Performance', 'Physical activity', 'Process', 'Rehabilitation therapy', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Universities', 'Wolves', 'Work', 'advanced system', 'age related', 'commercialization', 'computerized data processing', 'design', 'improved', 'markov model', 'mathematical model', 'medical schools', 'meetings', 'motor control', 'neuroadaptation', 'neuromuscular system', 'new technology', 'programs', 'relating to nervous system', 'software development']",NICHD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2009,562835,0.00490623124947912
"A mobile Enabling Technology to promote adherence to behavioral therapy    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (06) Enabling Technologies, 06-DA-105: Improving health through ICT/mobile technologies. The ultimate goal of this research is to fundamentally change the ways in which behavioral interventions are delivered. We propose an innovative mobile Enabling Technology-iHeal-that recognizes stressors that threaten a patient's recovery and then delivers evidence-based interventions exactly at the moment of greatest need. Our objective is to determine, within subjects, the extent to which physiologic and affective changes detected by iHeal are predictive, within subjects, of posttraumatic stress or drug cues. The study team has considerable expertise in technology development and in assessment of behavioral interventions in co-occurring disorders. We will study 25 subjects drawn from an existing SAMHSA-funded investigation that utilizes intense case management to monitor progression of PTSD and substance abuse in returning combat veterans. Our proposed investigation will share interventions with the SMAHSA study that are based upon a blending of Motivational Interviewing and Cognitive Behavioral Therapy approaches for PTSD and substance abuse. Specific aims: 1) To evaluate the accuracy with which iHeal characterizes physiological and affective phenomena as acute stress reactions related to PTSD and environmental drug cues; and 2) To evaluate the effect of Motivational Interviewing-based interventions on acute stress reactions related to PTSD and environmental drug cues. This initial proposal is extremely innovative. The proposed iHeal device will employ cutting-edge wireless technology to link wearable sensors to personal mobile computing platforms (e.g., iPhone). This linkage will allow iHeal to detect co-occurring biological and behavioral processes, while embedded computing in the mobile platform permits iHeal to deliver evidence-based empathetic interventions at the opportune moment. iHeal can learn to intervene in ways that are most effective for the user, including scripted text-based dialogues modeled after brief interventions; use of motivating images or messages from loved ones; playing a meaningful song; or contacting a counselor at the moment of greatest need. Ultimately, a wearable wireless device that anticipates stressors and intervenes at a likely transition to risky activities has enormous potential in a variety of social, behavioral, and biomedical research enterprises. Importantly, iHeal has immediate commercial applications that will encourage job growth in behavioral science, biomedical, computer science, telecommunication, and electrical engineering enterprises. iHeal is an innovative device that uses wearable sensors to detect pulse, skin conductance, and acceleration; the sensor array links wirelessly to an iPhone which has an app that identifies changes in the user's physiology. Changes consistent with acute stress from PTSD exacerbations or drug use cues generate an empathetic conversation between the iPhone and the user, who enters real-time data on social/behavioral/environmental contexts. The iPhone (which tracks time and GPS data) uses predictive software to anticipate upcoming stressors and helps the user avoid them. The public health significance of this proposal is 1) iHeal will detect co-occurring biological and behavioral processes in real time; 2) it will discern undiscovered behavioral states; 3) it will predict a behavior of interest; and 4) it will deliver empathetic interventions to the user at the opportune moment for intervention. Because it is based on the union of existing technology and has immediate commercial applications, iHeal will encourage job growth in behavioral science, biomedical, computer science, telecommunication, and electrical engineering enterprises.               Project Narrative iHeal is an innovative device that uses wearable sensors to detect pulse, skin conductance, and acceleration; the sensor array links wirelessly to an iPhone which has an app that identifies changes in the user's physiology. Changes consistent with acute stress from PTSD exacerbations or drug use cues generate an empathetic conversation between the iPhone and the user, who enters real-time data on social/behavioral/environmental contexts. The iPhone (which tracks time and GPS data) uses predictive software to anticipate upcoming stressors and helps the user avoid them. The public health significance of this proposal is 1) iHeal will detect co-occurring biological and behavioral processes in real time; 2) it will discern undiscovered behavioral states; 3) it will predict a behavior of interest; and 4) it will deliver empathetic interventions to the user at the opportune moment for intervention. Because it is based on the union of existing technology and has immediate commercial applications, iHeal will encourage job growth in behavioral science, biomedical, computer science, telecommunication, and electrical engineering enterprises.",A mobile Enabling Technology to promote adherence to behavioral therapy,7820117,RC1DA028428,"['Acceleration', 'Acute', 'Address', 'Adherence', 'Adopted', 'Adoption', 'Affect', 'Affective', 'Afghanistan', 'Area', 'Artificial Intelligence', 'Arts', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Behavioral Sciences', 'Biological', 'Biomedical Research', 'Case Management', 'Chronic', 'Clinical', 'Communication', 'Computer software', 'Cues', 'Data', 'Devices', 'Disease', 'Drug usage', 'Effectiveness of Interventions', 'Electrical Engineering', 'Enrollment', 'Environment', 'Evidence based intervention', 'Feasibility Studies', 'Feedback', 'Funding', 'Galvanic Skin Response', 'Goals', 'Growth', 'Health', 'Hour', 'Image', 'Intervention', 'Investigation', 'Iraq', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Mental Health', 'Methods', 'Modeling', 'Monitor', 'Occupations', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Physiologic Monitoring', 'Physiologic pulse', 'Physiological', 'Physiology', 'Play', 'Population', 'Population Study', 'Post-Traumatic Stress Disorders', 'Process', 'Professional counselor', 'Public Health', 'Recovery', 'Recruitment Activity', 'Research', 'Risk Behaviors', 'Services', 'Stress', 'Substance abuse problem', 'Technology', 'Telecommunications', 'Text', 'Time', 'United States Substance Abuse and Mental Health Services Administration', 'Veterans', 'Wireless Technology', 'acute stress', 'acute traumatic stress disorder', 'base', 'biomedical Computer science', 'brief intervention', 'cognitive behavior therapy', 'combat', 'commercial application', 'cost effectiveness', 'disorder later incidence prevention', 'evidence base', 'experience', 'follow-up', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'loved ones', 'motivational enhancement therapy', 'new technology', 'novel', 'response', 'sensor', 'social', 'stressor', 'study characteristics', 'technology development']",NIDA,UNIV OF MASSACHUSETTS MED SCH WORCESTER,RC1,2009,499381,0.016547893950526363
"Toward an Animal Model of Freely Moving Humans Our overarching goal is to establish an animal model of freely moving humans. We choose to do so in order to directly measure the context-dependency of motor cortical activity and, ultimately, other activity reliant upon free movement such as social interaction among animals. Achieving this major technological challenge requires a complete system that includes (Specific Aim 1) wireless transmission of neural data from electrode arrays chronically implanted in monkeys, (Specific Aim 2) computer-vision algorithms to automatically extract body and limb orientation during free movement, and (Specific Aim 3) new mathematical and computational models to represent and extract information from high-dimensional neural and behavioral activity. This technology will enable an animal model of freely moving humans that will advance the development of cortical neural prostheses by providing models of the context-dependant nature of motor cortical control.  Unlike traditional laboratory environments used to study animal movement, human amputees and tetraplegics operate in a variety of contexts that involve their movement in the world. Understanding the motor control of complex movement in these natural settings is absolutely critical for future advances in cortically- controlled prostheses. Given our overarching goal, our hypothesis is that motor cortical activity (e.g., directional tuning curves, absolute firing rates, correlations among units, etc.) will be different in important ways when rhesus monkeys perform the same reaching arm movements in an un-constrained context (e.g., not sitting quietly, not head restrained, not in dark and quiet room, etc.) as in a traditional, highly constrained context. Our three Specific Aims will put in place the electronic, computational and mathematical technology necessary to address this hypothesis, and also to make such studies of free behavior in rhesus monkeys possible. The innovative integration of neural engineering, neuroscience, computer vision, mathematics and neural modeling will provide new tools to enable the unprecedented study of motor control during natural, unconstrained behavior.  PROJECT NARRATIVE The proposed research project is directly relevant to both basic neuroscience studies of higher brain function and to neural prosthesis research aimed at, ultimately, helping patients with motor disorders. We will conduct neurophysiological and behavioral experiments with rhesus monkeys in two different contexts - ""in home cage"" and ""in rig"" - to investigate the context dependence of motor cortical activity. With this knowledge, we will then design ""context independent"" models of the neural-behavioral relationship which we, and other researchers, could then use in neural prosthetic experiments while monkeys freely move around their less- constrained home cages.",Toward an Animal Model of Freely Moving Humans,7725788,R01NS066311,"['Address', 'Advanced Development', 'Algorithms', 'Amputees', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Dependence', 'Dependency', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Future', 'Goals', 'Head', 'Home environment', 'Human', 'Implant', 'Knowledge', 'Laboratories', 'Limb structure', 'Macaca mulatta', 'Mathematics', 'Measures', 'Modeling', 'Monkeys', 'Motor', 'Movement', 'Nature', 'Neurosciences', 'Patients', 'Prosthesis', 'Quadriplegia', 'Research', 'Research Personnel', 'Research Project Grants', 'Social Interaction', 'Synaptic Transmission', 'System', 'Technology', 'Upper arm', 'Wireless Technology', 'design', 'free behavior', 'innovation', 'motor control', 'motor disorder', 'neural model', 'neural prosthesis', 'neurophysiology', 'relating to nervous system', 'research study', 'tool']",NINDS,STANFORD UNIVERSITY,R01,2009,366873,0.017916109070750336
"Wearable-Sensor System for Monitoring Motor Function    DESCRIPTION (provided by applicant): We propose to develop a wearable Personal Status Monitor for improving the medication management of Parkinson's Disease patients by monitoring the effects of the medication continuously during the day. New outcome measures are needed to supplement the self-reports currently in use that are ineffective in managing the complex and unpredictable nature of movement disorders in this population. The device we propose to develop can be worn unobtrusively by patients in their home to automatically provide the following clinically significant information: 1) the presence and severity of specific primary and secondary movement disorders associated with the disease, 2) the status of  On-Off motor fluctuation in response to anti-Parkinson's medication, and 3) the mobility status of the patient. The patient will be monitored by specially designed electromyographic (EMG) and accelerometric (ACC) body-worn sensors. Their signals will be analyzed by a novel Artificial Intelligence knowledge-based signal processing method developed by our group specifically for this purpose. Success of the system will be based on classification accuracy compared to observation by experts. The proposal is composed of two projects. The first and dominant project will develop the underlying technological requirements for the PSM system's application to Parkinson's disease. The aims will include acquisition hardware development in the form of hybrid EMG/ACC sensors. However, the emphasis will be on the development of the knowledge-based algorithms and their software implementation. The second project is designed to acquire the knowledge base needed in Project 1 through data collection experiments from control subjects and patients with Parkinson's disease. The experiments are designed to advance the algorithm development in a hierarchical manner starting from highly standardized activities to free-form activities which approximate real-world conditions. The development of the system will be constructed so that future versions can be adapted to other movement disorders. The successful development of this technology will be transferred for commercial development with the financial assistance of the Massachusetts Community Technology Foundation.         n/a",Wearable-Sensor System for Monitoring Motor Function,7682267,R01EB007163,"['Activities of Daily Living', 'Age', 'Algorithms', 'Artificial Intelligence', 'Body Surface', 'Bradykinesia', 'Cardiac', 'Classification', 'Clinical', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Data', 'Data Collection', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Effectiveness', 'Essential Tremor', 'Exertion', 'Exhibits', 'Fingers', 'Foundations', 'Freezing', 'Future', 'Gilles de la Tourette syndrome', 'Holter Electrocardiography', 'Home environment', 'Huntington Disease', 'Hybrids', 'Inherited Spinocerebellar Degenerations', 'Interview', 'Investigation', 'Kinetics', 'Levodopa', 'Limb structure', 'Lower Extremity', 'Massachusetts', 'Measurement', 'Medical', 'Medication Management', 'Methods', 'Monitor', 'Motion', 'Motor', 'Motor Activity', 'Movement Disorders', 'Muscle', 'Nature', 'Neurologist', 'Neuromuscular Diseases', 'Nose', 'Operative Surgical Procedures', 'Outcome Measure', 'Parkinson Disease', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phase II Clinical Trials', 'Population', 'Posture', 'Principal Investigator', 'Questionnaires', 'Recording of previous events', 'Research Personnel', 'Sampling', 'Severities', 'Signal Transduction', 'Simulate', 'Small Business Innovation Research Grant', 'Specialist', 'Staging', 'System', 'Tardive Dyskinesia', 'Technology', 'Testing', 'Text', 'Time', 'Tremor', 'Upper Extremity', 'Walking', 'Wireless Technology', 'Work', 'base', 'clinically significant', 'computerized data processing', 'design', 'diaries', 'improved', 'kinematics', 'knowledge base', 'miniaturize', 'monitoring device', 'motor disorder', 'nervous system disorder', 'novel', 'programs', 'prototype', 'research study', 'response', 'sensor', 'statistics', 'success', 'technology development', 'tool']",NIBIB,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2009,652788,0.042841374281923326
"Non-Invasive System for Identifying Neural Behavior    DESCRIPTION (provided by applicant): This application for ""Neurotechnology Research, Development, and Enhancement"" (PA-04-006) proposes the development of innovative technologies, methodologies, and instrumentation to advance our understanding of neural control mechanisms of muscle force production through a non-invasive means of recording neuronal firing patterns. The project will develop an automatic system to accurately and quickly decompose the surface Electromyographic (sEMG) signal into its constituent action potentials and provide the timing of the firings of concurrently active motor units. The goal is to achieve an accuracy of >85% in the automatic mode and >96% with the assistance of an interactive editor. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system by simply placing a sensor above a muscle with no assault to the CNS. The sEMG Decomposition System will replace existing technology that relies on invasive procedures to detect the EMG signal through needle or fine-wire electrodes. The proposed work includes: 1) mathematical modeling and empirical studies to develop a sEMG electrode array that maximizes shape differences of motor unit firings and thereby facilitates sEMG signal decomposition; 2) algorithm development using artificial intelligence technology of our own design combined with Principal Component Analysis techniques; and 3) data acquisition/processing software and hardware to build a portable prototype surface decomposition system. Performance testing of the system will be conducted using data collection experiments to ensure that the system is comparable in motor unit yield, processing speed, and accuracy to the current state-of-the art indwelling decomposition system. We will also prove that the signal decomposition is performed correctly by decomposing two separately collected signals and matching the results. A dissemination plan is included to make this technology available to the Motor Control community. Commercialization will be realized through Altec Inc. This technology will enable researchers in the fields of Motor Control, Aging, Exercise Physiology, Space Medicine, and Ergonomics, where it is of interest to understand how the CNS controls muscles, and how that control is altered as a consequence of aging, exercise, exposure to microgravity, fatigue, and excessive and prolonged force production. It will be useful to clinicians for assessing the degree of dysfunction in upper motoneuron diseases such as Cerebral Palsy, Parkinson's Disease, ALS, Stroke, and other disorders.              n/a",Non-Invasive System for Identifying Neural Behavior,7675312,R01NS058250,"['Action Potentials', 'Age', 'Aging', 'Algorithms', 'Artificial Intelligence', 'Arts', 'Basic Science', 'Behavior', 'Behavioral', 'Businesses', 'Cerebral Palsy', 'Characteristics', 'Clinical', 'Code', 'Communities', 'Computer software', 'Contracts', 'Data Collection', 'Detection', 'Development', 'Disease', 'Electrodes', 'Ensure', 'Exercise', 'Exercise Physiology', 'Exposure to', 'Fatigue', 'Feedback', 'Functional disorder', 'Goals', 'Grant', 'Individual', 'International', 'Left', 'Marketing', 'Measurement', 'Measures', 'Methodology', 'Microgravity', 'Modeling', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Contraction', 'Muscle Fibers', 'NIH Program Announcements', 'Needles', 'Neurons', 'Parkinson Disease', 'Pattern', 'Performance', 'Principal Component Analysis', 'Principal Investigator', 'Procedures', 'Process', 'Production', 'Publishing', 'Reliance', 'Research', 'Research Personnel', 'Right-On', 'Risk', 'Safety', 'Sensitivity and Specificity', 'Series', 'Shapes', 'Side', 'Signal Transduction', 'Skin', 'Source', 'Space Medicine', 'Specificity', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Tongue', 'Training', 'Validation', 'Work', 'assault', 'base', 'commercialization', 'data acquisition', 'design', 'ergonomics', 'experience', 'human subject', 'improved', 'innovative technologies', 'instrumentation', 'interest', 'mathematical model', 'motor control', 'neuromuscular system', 'neuroregulation', 'neurotechnology', 'new technology', 'non-invasive system', 'performance tests', 'processing speed', 'programs', 'prototype', 'relating to nervous system', 'research and development', 'research study', 'response', 'sensor', 'technology development', 'technology/technique']",NINDS,"ALTEC, INC.",R01,2009,446520,0.012086142338816606
"Wearable-Sensor System for Monitoring Motor Function    DESCRIPTION (provided by applicant): We propose to develop a wearable Personal Status Monitor for improving the medication management of Parkinson's Disease patients by monitoring the effects of the medication continuously during the day. New outcome measures are needed to supplement the self-reports currently in use that are ineffective in managing the complex and unpredictable nature of movement disorders in this population. The device we propose to develop can be worn unobtrusively by patients in their home to automatically provide the following clinically significant information: 1) the presence and severity of specific primary and secondary movement disorders associated with the disease, 2) the status of  On-Off motor fluctuation in response to anti-Parkinson's medication, and 3) the mobility status of the patient. The patient will be monitored by specially designed electromyographic (EMG) and accelerometric (ACC) body-worn sensors. Their signals will be analyzed by a novel Artificial Intelligence knowledge-based signal processing method developed by our group specifically for this purpose. Success of the system will be based on classification accuracy compared to observation by experts. The proposal is composed of two projects. The first and dominant project will develop the underlying technological requirements for the PSM system's application to Parkinson's disease. The aims will include acquisition hardware development in the form of hybrid EMG/ACC sensors. However, the emphasis will be on the development of the knowledge-based algorithms and their software implementation. The second project is designed to acquire the knowledge base needed in Project 1 through data collection experiments from control subjects and patients with Parkinson's disease. The experiments are designed to advance the algorithm development in a hierarchical manner starting from highly standardized activities to free-form activities which approximate real-world conditions. The development of the system will be constructed so that future versions can be adapted to other movement disorders. The successful development of this technology will be transferred for commercial development with the financial assistance of the Massachusetts Community Technology Foundation.         n/a",Wearable-Sensor System for Monitoring Motor Function,7880363,R01EB007163,"['Activities of Daily Living', 'Address', 'Age', 'Algorithms', 'Ambulatory Monitoring', 'American', 'Artificial Intelligence', 'Bradykinesia', 'Cardiac', 'Cardiovascular system', 'Caregivers', 'Classification', 'Clinic', 'Clinical', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Data', 'Data Collection', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Effectiveness', 'Employee Strikes', 'Essential Tremor', 'Exertion', 'Exhibits', 'Face', 'Fingers', 'Foundations', 'Freezing', 'Future', 'Gilles de la Tourette syndrome', 'Holter Electrocardiography', 'Home environment', 'Huntington Disease', 'Hybrids', 'Inherited Spinocerebellar Degenerations', 'Interview', 'Investigation', 'Kinetics', 'Laboratories', 'Levodopa', 'Limb structure', 'Literature', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medication Management', 'Memory', 'Methods', 'Monitor', 'Motion', 'Motor', 'Motor Activity', 'Movement Disorders', 'Muscle', 'Musculoskeletal System', 'Nature', 'Neurologic', 'Neurologist', 'Nose', 'Operative Surgical Procedures', 'Outcome Measure', 'Parkinson Disease', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Pattern', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phase II Clinical Trials', 'Physical Function', 'Physiological', 'Population', 'Posture', 'Questionnaires', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Personnel', 'Sampling', 'Severities', 'Signal Transduction', 'Simulate', 'Specialist', 'Surveys', 'System', 'Systems Analysis', 'Tardive Dyskinesia', 'Technology', 'Testing', 'Time', 'Tremor', 'Walking', 'Wireless Technology', 'base', 'clinically significant', 'computerized data processing', 'cost', 'design', 'diaries', 'improved', 'in vivo', 'kinematics', 'knowledge base', 'miniaturize', 'monitoring device', 'motor disorder', 'nervous system disorder', 'neuromuscular', 'new technology', 'novel', 'prototype', 'research study', 'response', 'sensor', 'statistics', 'success', 'technology development', 'tool']",NIBIB,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2009,213073,0.042841374281923326
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator. Seacoast's Phase I research will focus on developing the sensor array, demonstrating sensitivity to chlorinated hydrocarbons at relevant concentrations, and field tests in actual contaminated sites. The ultimate goal is to provide the DOD, DOE, NIEHS and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. The systems will have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator collects the contaminants and releases them to a microsensor array. The sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical. An array of differently responding sensors and pattern recognition can thereby compensate for changes in humidity, temperature, and composition. These low-power systems can be left unattended and transmit data wirelessly or through USB to a central location. The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. The potential commercial markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology. PUBLIC HEALTH RELEVANCE: This proposal will describe a potential method to specifically address the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.          n/a",Low-Cost Electronic Nose for Groundwater Contaminants,7847964,R43ES016941,"['Address', 'Algorithms', 'Characteristics', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Data', 'Data Collection', 'Detection', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Feedback', 'Fingerprint', 'Fluorescence', 'Goals', 'Humidity', 'Industrial Health', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Location', 'Machine Learning', 'Maps', 'Marketing', 'Measures', 'Methods', 'Modification', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Phase', 'Poison', 'Polymers', 'Process', 'Public Health', 'Pump', 'ROC Curve', 'Recommendation', 'Research', 'Risk', 'Safety', 'Sampling', 'Science', 'Simulate', 'Site', 'Soil', 'Solutions', 'Source', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Trichloroethylene', 'Water', 'Work', 'aqueous', 'base', 'cold temperature', 'computerized data processing', 'cost', 'cost effectiveness', 'design', 'detector', 'drinking water', 'ground water', 'innovation', 'membrane assembly', 'pollutant', 'prototype', 'public health relevance', 'remediation', 'response', 'sensor', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R43,2009,11376,0.01678060147277223
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7589644,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'image processing', 'meetings', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'public health relevance', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2009,426946,0.00853701712935333
"A Cell Phone-based Sign Reader for Blind & Visually Impaired Persons    DESCRIPTION (provided by applicant): We propose to develop and evaluate a cell-phone-based system to enable blind and visually impaired individuals to find and read street signs and other signs relevant to wayfinding. Using the built-in camera and computing power of a standard cell phone, the system will process images captured by the user to find and analyze signs, and speak their contents. This will provide valuable assistance for blind or visually impaired pedestrians in finding and reading street signs, as well as locating and identifying addresses and store names, without requiring them to carry any special-purpose hardware. The sign finding and reading software will be made freely available for download into any camera-equipped cell phone that uses the widespread Symbian operating system (such as the popular Nokia cell phone series). We will build on our prior and ongoing work in applying computer vision techniques to practical problem-solving for blind persons, including cell-phone implementation of algorithms for indoor wayfinding and for reading digital appliance displays. We will develop, refine and transfer to the cell phone platform a new belief propagation-based algorithm that has shown preliminary success in finding and analyzing signs under difficult real-world conditions including partial shadow coverage. Human factors studies will help determine how to configure the system and its user controls for maximum effectiveness and ease of use, and provide an evaluation of the overall system. Access to environmental labels, signs or landmarks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.          n/a",A Cell Phone-based Sign Reader for Blind & Visually Impaired Persons,7373002,R01EY018210,"['Accidents', 'Address', 'Algorithms', 'American', 'Belief', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Databases', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Evaluation', 'Face', 'Figs - dietary', 'Generations', 'Grant', 'Human', 'Image', 'Impairment', 'Individual', 'Label', 'Left', 'Mainstreaming', 'Marketing', 'Modification', 'Names', 'Operating System', 'Operative Surgical Procedures', 'Performance', 'Problem Solving', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Sampling', 'Self-Help Devices', 'Series', 'Shadowing (Histology)', 'Signal Transduction', 'Speech', 'System', 'Target Populations', 'Techniques', 'Testing', 'Text', 'Training', 'Travel', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'base', 'blind', 'consumer product', 'cost', 'design', 'digital', 'experience', 'image processing', 'improved', 'legally blind', 'novel', 'open source', 'prevent', 'programs', 'prototype', 'skills', 'success', 'tool', 'way finding', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2009,417177,0.03659839492990564
"A Cell Phone-Based Street Intersection Analyzer for Visually Impared Pedestrians    DESCRIPTION (provided by applicant): Urban intersections are the most dangerous parts of a blind person's travel. They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult. To alleviate this problem, we propose to develop and evaluate a cell phone-based system to analyze images of street intersections, taken by a blind or visually impaired person using a standard camera cell phone, to provide real-time feedback. Drawing on our recent work on computer vision algorithms that help a blind person find crosswalks and other important features in a street intersection, as well as our ongoing work on cell phone implementations of algorithms for indoor wayfinding and for reading digital appliance displays, we will refine these algorithms and implement them on a cell phone. The information extracted by the algorithms will be communicated to the user with a combination of synthesized speech, audio tones and/or tactile feedback (using the cell phone's built-in vibrator). Human factors studies will help determine how to configure the system and its user controls for maximum effectiveness and ease of use, and provide an evaluation of the overall system. The street intersection analysis software will be made freely available for download into any camera-equipped cell phone that uses the widespread Symbian operating system (such as the popular Nokia cell phone series). The cell phone will not need any hardware modifications or add-ons to run this software. Ultimately a user will be able to download an entire suite of such algorithms for free onto the cell phone he or she is already likely to be carrying, without having to carry a separate piece of equipment for each function. Relevance: The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.           n/a",A Cell Phone-Based Street Intersection Analyzer for Visually Impared Pedestrians,7681076,R01EY018345,"['Accidents', 'Address', 'Algorithms', 'American', 'Cellular Phone', 'Complex', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Detection', 'Devices', 'Effectiveness', 'Equipment', 'Evaluation', 'Face', 'Feedback', 'Figs - dietary', 'Grant', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Left', 'Light', 'Mainstreaming', 'Marketing', 'Modification', 'Operating System', 'Pattern', 'Performance', 'Reading', 'Research', 'Research Infrastructure', 'Resolution', 'Running', 'Self-Help Devices', 'Series', 'Signal Transduction', 'Speech', 'System', 'Tactile', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Training', 'Travel', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'Zebra', 'base', 'blind', 'consumer product', 'cost', 'digital', 'experience', 'image processing', 'improved', 'legally blind', 'novel', 'prevent', 'programs', 'skills', 'tool', 'trafficking', 'way finding', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2009,346662,0.023972715321965096
"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",A Wireless Multiscale Distributed Interface to the Cortex,7670296,R01NS062031,"['Address', 'Advanced Development', 'Algorithms', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cavia', 'Cell physiology', 'Characteristics', 'Communication', 'Computer software', 'Custom', 'Data', 'Devices', 'Discipline', 'Disease', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Imaging technology', 'Implant', 'In Vitro', 'Investigation', 'Learning', 'Machine Learning', 'Mediating', 'Microelectrodes', 'Monitor', 'Motor', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Outcome', 'Paralysed', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Rattus', 'Research', 'Retinal', 'Rodent', 'Rodent Model', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Slice', 'Stimulus', 'Stream', 'System', 'Telemetry', 'Testing', 'Time', 'Wireless Technology', 'awake', 'base', 'brain cell', 'brain machine interface', 'clinical application', 'computerized data processing', 'data acquisition', 'data exchange', 'density', 'design', 'disability', 'implantation', 'improved', 'in vivo', 'information processing', 'microsystems', 'nervous system disorder', 'neural circuit', 'prototype', 'public health relevance', 'quantum', 'relating to nervous system', 'response', 'subcutaneous', 'tool']",NINDS,MICHIGAN STATE UNIVERSITY,R01,2009,515852,0.0029488115388662303
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,7570367,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical and Translational Science Awards', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2009,708748,0.009981621680355362
"Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface    DESCRIPTION (provided by applicant):      Over 600,000 Americans have severely impaired motor function from disorders including spinal cord injury, amyotrophic lateral sclerosis, pontine stroke, and cerebral palsy. A brain-machine interface (BMI) could enable locked-in or tetraplegic patients to communicate and interact with their environment. Two crucial decisions in designing a BMI are (1) what type of brain signals to use as inputs to a controller and (2) what methods to use to decode those signals. Most BMIs have used either noninvasive scalp EEG recordings or invasive intracortical recordings of single- or multi-neuron spikes as control inputs. A few have used subdural or intracortical local field potentials (LFPs). However, no group has yet systematically compared these signals in motor cortex for use in BMI applications. This proposal's first goal is to assess the relative performance of spikes and field potentials (both intracortical and epidural) as control inputs for a variety of movement-related outputs. Epidural field potentials (EFPs) are intermediate in invasiveness, signal quality, stability and spatial resolution compared with existing scalp, subdural, and intracortical recordings, and thus represent an unexplored middle ground. This proposal's second goal is to evaluate linear and nonlinear techniques-including several novel to BMI applications-for both decoding data and reducing the inherently large dimensionality of data from multiple neural signals. The primary hypotheses of the proposed project are (1) that spikes will perform better in decoding more complex movement-related outputs, but that field potentials may perform similarly on decoding simpler outputs, and (2) that nonlinear decoders and dimensionality-reduction techniques may provide improved accuracy over linear methods. The specific aims to address these hypotheses are 1) to evaluate single neuron spikes as inputs to decoders of movement- related outputs, 2) to develop a novel epidural multi-electrode recording technique in the macaque monkey, and 3) to evaluate field potential signals as inputs to decoders of movement-related outputs. Aims 1 and 3 will involve application of dimensionality-reduction algorithms (e.g., independent components analysis, Isomap) and decoding algorithms (system identification, neural networks, support vector machines) to both spikes and field potentials. Aim 2 will entail using a computer model and spatial spectral analysis to optimize the epidural electrode array design. This project will provide the first comparison of spikes, LFPs and EFPs as inputs for identical BMI output applications. The supervision of Drs. Lee Miller and W. Zev Rymer, with additional guidance from Drs. Simon Levine, Jonathan Wolpaw and Nicholas Hatsopoulos, will provide the principal investigator with expertise in recording and processing both spikes and field potentials for BMI applications using a variety of state-of-the- art techniques. A comprehensive career development plan including clinical and research mentoring, seminars, and courses, will foster the candidate's transition into an independent physician-scientist.           n/a",Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface,7643089,K08NS060223,"['Action Potentials', 'Address', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Arts', 'Benchmarking', 'Biological Neural Networks', 'Brain', 'Cerebral Palsy', 'Cervical spinal cord injury', 'Clinical Research', 'Complex', 'Computer Simulation', 'Craniotomy', 'Data', 'Development Plans', 'Discriminant Analysis', 'Disease', 'Dura Mater', 'Electrodes', 'Electroencephalography', 'Environment', 'Evaluation', 'Figs - dietary', 'Fostering', 'Frequencies', 'Genetic Programming', 'Goals', 'Hand', 'Implant', 'Implanted Electrodes', 'Knowledge', 'Learning', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Physicians', 'Pontine structure', 'Principal Investigator', 'Procedures', 'Process', 'Quadriplegia', 'Rattus', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Scalp structure', 'Scientist', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Statistical Methods', 'Stroke', 'Sum', 'Supervision', 'System', 'Techniques', 'Time', 'Tissues', 'Training', 'Upper arm', 'Visual', 'brain machine interface', 'career development', 'computerized data processing', 'cranium', 'design', 'disability', 'feeding', 'flexibility', 'improved', 'in vivo', 'independent component analysis', 'motor control', 'novel', 'programs', 'prototype', 'relating to nervous system', 'research study', 'surgical technique development']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,K08,2009,167832,0.009360221344355102
"CRCNS: Where to look next? Modeling eye movements in normal and impaired vision    DESCRIPTION (provided by applicant): The goal of this proposal is to gain a better understanding of the information processing and decision strategies that underlie eye movement planning in both the normal and diseased state. In patients with age-related macular degeneration (AMD), central areas of the retina are damaged, creating a large blind spot that forces them to rely solely on residual vision in the periphery. Rehabilitation outcomes for these patients can be successful, but are often inconsistent. Despite similar retinopathies, some patients learn to use their residual vision more effectively than others. We have developed an information-theoretic model and experimental paradigm which will allow us to objectively measure human scanning efficiency. The development of the model has naturally motivated fundamental experimental questions about eye movements and neural decision making. The answers to these questions will be used to refine the model and enhance our understanding of the system in general. We will then apply the model framework to investigate differences in eye movement behavior between AMD patients and normally-sighted individuals. The interplay of model development and experimental investigation will significantly increase our knowledge of how humans use prior knowledge and task demands to direct their gaze, and how new visual information is incorporated into an eye movement plan. The results will have broad relevance to understanding neural decision making in general.   Relevance to Public Health. The application of the model to a clinical population will bring much-needed objective measures to understanding the extent of impairment in individuals with AMD. With this understanding comes great potential for improving rehabilitation training strategies that will enhance the quality of life for these patients and their families.          n/a",CRCNS: Where to look next? Modeling eye movements in normal and impaired vision,7904674,R01EY018004,"['Age related macular degeneration', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'California', 'Clinic', 'Clinical', 'Computer Simulation', 'Computer Vision Systems', 'Decision Making', 'Doctor of Philosophy', 'Ensure', 'Eye Movements', 'Family', 'Goals', 'Human', 'Impairment', 'Individual', 'Information Theory', 'Investigation', 'Knowledge', 'Learning', 'Measures', 'Medical center', 'Modeling', 'Movement', 'Ophthalmologist', 'Outcome', 'Patients', 'Pattern', 'Population', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Psychophysics', 'Psychophysiology', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Retina', 'Retinal', 'Retinal Diseases', 'Retinal blind spot', 'Saccades', 'Scanning', 'Signal Detection Analysis', 'Statistical Models', 'System', 'Techniques', 'Theoretical model', 'Training', 'Training Programs', 'Update', 'Vision', 'Visual', 'Visual impairment', 'Work', 'behavior prediction', 'design', 'disease characteristic', 'experience', 'gaze', 'image processing', 'improved', 'information processing', 'model development', 'predictive modeling', 'relating to nervous system', 'research study', 'sample fixation', 'success', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2009,92207,-0.004248364061798455
"Accessible Artificial Intelligence Tutoring Software (Phase II SBIR)    DESCRIPTION (provided by applicant): This Phase II proposal focuses on the development of accessible artificial intelligence (AI) software for individualized tutoring and formative assessment in chemistry education. If successful, an immediate outcome will be the very first AI tutoring systems for chemistry that are accessible to blind students, delivered through the Internet. An AI tutoring methodology formulated with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. Furthermore, classroom teachers can obtain individualized assessment reporting and diagnostic information for visually impaired students on demand, as if from a ""virtual teaching assistant"". Feasibility of Phase I was demonstrated by developing a prototype accessible AI tutoring program that received certification in the National Federation of the Blind's (NFB) Nonvisual Accessibility Web Application Certification Program. In previous SBIR projects, Quantum has successfully innovated new concepts in the field of AI and has developed, tested and brought to the classroom tutoring and assessment systems for science and mathematics education. Certain unique attributes of the Quantum AI Tutors make them potentially very well suited for full accessibility to the blind, as well as individuals with other print-related disabilities, using Internet- capable screen reader technology. The potential technological innovation is the development of the first advanced AI chemistry tutoring technology that has accessibility built into its framework design. Important Phase II objectives include:  Continued progress on chemistry-specific accessibility issues. Completion of full accessibility support in AI framework itself. Implementation of Braille support for chemical formulas and equations. Investigation of chemistry-specific pedagogical issues for blind students. Extension to accessible science assessment for blind/VI students, building on AI assessment technology currently under development by Quantum in other projects. Special education is a particular challenge for assessment within the No Child Left Behind legislation. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum has long-term partnerships with McGraw-Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as two additional commercial agreements with major science education supply companies, Science Kit & Boreal Laboratories and Sargent-Welch. Chemistry comprises the majority of the content standard for physical science in the National Science Education Standards, and yet is one of the most neglected areas in terms of quality educational software, in general, and is a particularly acute problem for the blind and visually impaired. Through recent federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom the very first artificial intelligence (AI) tutoring systems for chemistry. The goal of the present research is to bring the full power and benefit of this cutting-edge new educational technology to students who are blind and visually impaired using Internet-capable screen access technology.          n/a",Accessible Artificial Intelligence Tutoring Software (Phase II SBIR),7404392,R44EY016251,"['Achievement', 'Acute', 'Address', 'Agreement', 'American', 'Area', 'Artificial Intelligence', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Child', 'Computer software', 'Country', 'Development', 'Diagnostic', 'Drug Formulations', 'Education', 'Educational Technology', 'Educational process of instructing', 'Equation', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Investigation', 'Laboratories', 'Left', 'Mathematics', 'Methodology', 'Mission', 'Numbers', 'Outcome', 'Performance', 'Phase', 'Philosophy', 'Preparation', 'Printing', 'Purpose', 'Reader', 'Reporting', 'Research', 'Schools', 'Science', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Special Education', 'Standards of Weights and Measures', 'Statutes and Laws', 'Students', 'Support of Research', 'System', 'Technology', 'Technology Assessment', 'Testing', 'Visual impairment', 'Work', 'blind', 'braille', 'commercialization', 'concept', 'design', 'disability', 'falls', 'high school', 'improved', 'innovation', 'neglect', 'next generation', 'physical science', 'programs', 'prototype', 'quantum', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'virtual']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2008,383858,0.022789733739605012
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7500697,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2008,1146026,-0.006657641486763447
"Motor Learning for the Control of an Assistive Device The goal of these studies is to understand how movements of the body can be harnessed and trained to control electrically powered wheelchairs. Advanced wheelchair technology is often perceived to be a barrier by a large number of potential wheelchair users. An approach is proposed for the removal of this barrier based on adapting the assistive technology to the residual unconstrained mobility of the patients and on enhancing motor learning. This exploratory project aims at establishing the feasibility of such an approach and at developing training methods based on the identification of natural motions and on the use of virtual reality (VR). The proposed studies will be carried out on quadriplegic spinal cord injured patients with complete or incomplete cervical injuries. Healthy volunteers will also participate in these study to fine-tune the experimental apparatus and to provide a reference baseline to assess learning and coordination. Subjects will wear a novel upper-body sensing garment. A total of 52 electrical signals generated by the garment will be modulated by movements of the wrist, elbow, shoulder and torso. These signals will be mapped into the velocity commands for a simulated wheelchair. Subjects will wear VR-goggles and a head tracker, which will provide them with a immersive view of a computer-generated environment from the perspective of the simulated wheelchair. The combination of virtual reality environments and wearable signal technology will provide a framework for evaluating training protocols that would not be feasible with actual wheelchairs. The proposed studies are organized in two specific aims: (Aim 1.) To identify motor primitives for the control of a virtual wheelchair by unrestricted upper body motions Three well-established signal processing techniques - Principal Component Analysis, Independent Component Analysis and Isomap - will be used and compared for extracting low-dimensional signal patterns from the garment signals (Aim 2.) To identify maps and procedures that facilitate motor learning. The signal patterns extracted from Aim 1 will be used to design and test new transformations from subject motions to wheelchair commands. A well- known machine learning technique -least mean squares gradient descent - will be tested for matching the natural motor primitives of the subjects with an appropriate set of control signals to the wheelchair. Finally the safe VR environment will allow us to test whether it is most efficient to learn by gradually speeding up wheelchair motions or by gradually slowing them down. The results of these studies are expected to guide the development of new technology for assistive devices based on human motor learning and on engineering of adaptive control. Many disabled individuals are facing difficult challenges to take advantage of assistive technologies. In particular the safe and efficient use of powered wheelchair is limited by the need for patients to learn to operate their control apparatus. The proposed studies will investigate the possibility to reverse this situation and take advantage of advanced technologies for adapting the control apparatus to the residual skills of the patients. n/a",Motor Learning for the Control of an Assistive Device,7488480,R21HD053608,"['Cervical spinal cord injury', 'Development', 'Elbow', 'Engineering', 'Environment', 'Excision', 'Goals', 'Goggles', 'Head', 'Human', 'Learning', 'Machine Learning', 'Maps', 'Methods', 'Motion', 'Motor', 'Movement', 'Numbers', 'Patients', 'Pattern', 'Powered wheelchair', 'Principal Component Analysis', 'Principal Investigator', 'Procedures', 'Protocols documentation', 'Quadriplegia', 'Residual state', 'Self-Help Devices', 'Shoulder', 'Signal Transduction', 'Simulate', 'Speed', 'Spinal cord injury', 'Techniques', 'Technology', 'Testing', 'Training', 'Wheelchairs', 'Wrist', 'base', 'body sense', 'computer generated', 'computerized data processing', 'design', 'healthy volunteer', 'independent component analysis', 'motor learning', 'new technology', 'novel', 'programs', 'virtual', 'virtual reality']",NICHD,REHABILITATION INSTITUTE OF CHICAGO D/B/A SHIRLEY RYAN ABILITYLAB,R21,2008,98314,0.03586837546390738
"Development of a Bidirectional Brain Machine Interface    DESCRIPTION (provided by applicant): Recent technological advances have made it possible to move a robotic device in real time, using signals obtained directly from the brain. This field of Brain Machine Interface (BMI) has the means to provide movement for paralyzed patients, communication for locked-in patients, and a better understanding of the brain for all of society. In order to control movement effectively, the brain must be able to activate muscles appropriately, and monitor the evolving movement quickly and precisely. Existing BMIs for, while remarkable, do each of these tasks in poor imitation of the intact nervous system. Our proposed work addresses these limitations by developing a bidirectional interface that produces movement in a more natural way, and provides feedback about the movement by direct, electrical stimulation of the brain. Our partnership includes members at Northwestern Univ (NU), Univ of Chicago (UC), Univ of Mass, Amherst (UMass), and the autonomous Univ of Mexico (UNAM). Partners have advanced degrees in a range of biological science, computer science, physics, mathematics, and engineering disciplines. Miller (NU) will coordinate the partnership. He has extensive experience with a wide range of recording, stimulation and behavioral protocols in behaving monkeys. Hatsopoulos (UC) is at the forefront of the field of multi-electrode recordings. He was a leading member of the first group to demonstrate visually guided BMI control by a primate. Barto (U Mass) has done pioneering research in neural networks, machine learning and stochastic optimization. Fagg (UMass) is an authority in the control of reaching and grasping robots that learn to interact with the environment. Together they will develop the decoders of activity from the brain used to cause movement. Romo (UNAM), is a world leader in studies of the perceptual and decision making processes induced by electrical stimulation of the brain. Solla (NU) is an expert in neural networks and information theory. With Romo, she will develop optimal routines to encode information in stimulus trains to provide feedback to the brain. Mussa-Ivaldi (NU) will focus on the overall design and evaluation of the interfaces. He created the first ever bidirectional interface between neural tissue and a robotic device.          n/a",Development of a Bidirectional Brain Machine Interface,7414722,R01NS048845,"['Address', 'Affect', 'Area', 'Behavior', 'Behavioral', 'Behavioral Paradigm', 'Biological Neural Networks', 'Biological Sciences', 'Boxing', 'Brain', 'Brain Stem', 'Cerebellum', 'Chicago', 'Collaborations', 'Communication', 'Complex', 'Condition', 'Data', 'Decision Making', 'Development', 'Discipline', 'Effectiveness', 'Electric Stimulation', 'Electrical Stimulation of the Brain', 'Electrodes', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Evolution', 'Face', 'Feedback', 'Figs - dietary', 'Freedom', 'Hand', 'Hand functions', 'Implant', 'Information Networks', 'Information Theory', 'Joints', 'Kinetics', 'Lampreys', 'Learning', 'Limb structure', 'Link', 'Machine Learning', 'Mathematics', 'Measurement', 'Methods', 'Mexico', 'Microelectrodes', 'Modeling', 'Monitor', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Musculoskeletal', 'Nervous system structure', 'Neural Network Simulation', 'Numbers', 'Output', 'Paralysed', 'Pathway interactions', 'Patients', 'Perception', 'Performance', 'Physics', 'Physiological', 'Play', 'Positioning Attribute', 'Primates', 'Principal Investigator', 'Process', 'Property', 'Proprioception', 'Protocols documentation', 'Range', 'Rate', 'Reaction Time', 'Reflex action', 'Relative (related person)', 'Research', 'Research Personnel', 'Robot', 'Role', 'Rotation', 'Scientist', 'Secure', 'Sensory', 'Signal Transduction', 'Simulate', 'Societies', 'Somatosensory Cortex', 'Source', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Torque', 'Training', 'Upper arm', 'Vision', 'Work', 'authority', 'base', 'brain machine interface', 'computer science', 'design', 'experience', 'grasp', 'improved', 'kinematics', 'limb movement', 'member', 'novel', 'programs', 'relating to nervous system', 'research study', 'robotic device', 'sensory feedback', 'time use', 'virtual', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2008,788593,0.04231742503217313
"Harnessing Motoneuron Activity: From Lab to Clinic    DESCRIPTION (provided by applicant):  We propose to continue the development of an automatic system that will accurately and quickly decompose electromyographic (EMG) signals into their constituent action potentials and provide the timing of every firing of a set of concurrently active motor units. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system. We will improve the performance of the decomposition algorithms by incorporating new Artificial Intelligence concepts, and a new multi-strategy Hidden Markov Model (HMM) processing stage, to address signal decomposition challenges that cannot be met by the present technology. We will improve the present accuracy from typically 85% for 8 concurrently active motor units to greater than 96% for up to 15 concurrently active motor units. We will also design and build the hardware and software for a stand-alone portable system that may be used in the laboratory or clinic. Then we will transfer the system to a manufacturer for commercialization. In so doing we will produce, for the first time, an advanced system for conveniently and accurately obtaining the firings of a large group of concurrently active motor units from an EMG signal. The new technology will be tested in two applied studies that will be carried out concurrently with the technical developments. One will investigate neural modifications in the firing characteristics of motor units as a function of aging and physical activity. The other will investigate the mitigating effects of resistive exercise on age-related neural adaptations, culminating in the development of a clinical marker to estimate the likelihood that an elderly individual will benefit from an exercise program. The proposed BRP will be lead by Drs. De Luca, Roy, and Adam, key personnel from Boston University (BU) with expertise in biomedical engineering and EMG system development. Signal processing/software development will be provided by the leadership from Dr. Nawab through BU's Department of Electrical and Computer Engineering. Clinical expertise on aging/motor control will be provided by Dr. Novak, from The Department of Neurology at BU School of Medicine, and through Dr. Wolf, from the Department of Rehabilitation Medicine at the Emory University School of Medicine in Atlanta           n/a",Harnessing Motoneuron Activity: From Lab to Clinic,7433213,R01HD050111,"['Action Potentials', 'Address', 'Age', 'Aging', 'Algorithms', 'Artificial Intelligence', 'Biomedical Engineering', 'Boston', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Markers', 'Computer Systems Development', 'Computer software', 'Computers', 'Development', 'Elderly', 'Electrodes', 'Engineering', 'Exercise', 'Fire - disasters', 'Human Resources', 'Individual', 'Laboratories', 'Lead', 'Leadership', 'Manufacturer Name', 'Medicine', 'Modeling', 'Modification', 'Motor', 'Motor Neurons', 'Neurology', 'Performance', 'Physical activity', 'Process', 'Range', 'Rehabilitation therapy', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Universities', 'Wolves', 'Work', 'advanced system', 'age related', 'commercialization', 'computerized data processing', 'concept', 'design', 'improved', 'markov model', 'mathematical model', 'medical schools', 'motor control', 'neuroadaptation', 'neuromuscular system', 'new technology', 'programs', 'relating to nervous system', 'software development']",NICHD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2008,570370,0.00490623124947912
"Wearable-Sensor System for Monitoring Motor Function    DESCRIPTION (provided by applicant): We propose to develop a wearable Personal Status Monitor for improving the medication management of Parkinson's Disease patients by monitoring the effects of the medication continuously during the day. New outcome measures are needed to supplement the self-reports currently in use that are ineffective in managing the complex and unpredictable nature of movement disorders in this population. The device we propose to develop can be worn unobtrusively by patients in their home to automatically provide the following clinically significant information: 1) the presence and severity of specific primary and secondary movement disorders associated with the disease, 2) the status of  On-Off motor fluctuation in response to anti-Parkinson's medication, and 3) the mobility status of the patient. The patient will be monitored by specially designed electromyographic (EMG) and accelerometric (ACC) body-worn sensors. Their signals will be analyzed by a novel Artificial Intelligence knowledge-based signal processing method developed by our group specifically for this purpose. Success of the system will be based on classification accuracy compared to observation by experts. The proposal is composed of two projects. The first and dominant project will develop the underlying technological requirements for the PSM system's application to Parkinson's disease. The aims will include acquisition hardware development in the form of hybrid EMG/ACC sensors. However, the emphasis will be on the development of the knowledge-based algorithms and their software implementation. The second project is designed to acquire the knowledge base needed in Project 1 through data collection experiments from control subjects and patients with Parkinson's disease. The experiments are designed to advance the algorithm development in a hierarchical manner starting from highly standardized activities to free-form activities which approximate real-world conditions. The development of the system will be constructed so that future versions can be adapted to other movement disorders. The successful development of this technology will be transferred for commercial development with the financial assistance of the Massachusetts Community Technology Foundation.         n/a",Wearable-Sensor System for Monitoring Motor Function,7482475,R01EB007163,"['Activities of Daily Living', 'Age', 'Algorithms', 'Artificial Intelligence', 'Body Surface', 'Bradykinesia', 'Cardiac', 'Classification', 'Clinical', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Daily', 'Data', 'Data Collection', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Effectiveness', 'Essential Tremor', 'Exertion', 'Exhibits', 'Fingers', 'Foundations', 'Freezing', 'Future', 'Gilles de la Tourette syndrome', 'Holter Electrocardiography', 'Home environment', 'Huntington Disease', 'Hybrids', 'Inherited Spinocerebellar Degenerations', 'Interview', 'Investigation', 'Kinetics', 'Levodopa', 'Limb structure', 'Lower Extremity', 'Massachusetts', 'Measurement', 'Medical', 'Medication Management', 'Methods', 'Monitor', 'Motion', 'Motor', 'Motor Activity', 'Movement Disorders', 'Muscle', 'Nature', 'Neurologist', 'Neuromuscular Diseases', 'Nose', 'Numbers', 'Operative Surgical Procedures', 'Outcome Measure', 'Parkinson Disease', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phase II Clinical Trials', 'Population', 'Posture', 'Principal Investigator', 'Purpose', 'Questionnaires', 'Recording of previous events', 'Research Personnel', 'Sampling', 'Severities', 'Signal Transduction', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Specialist', 'Staging', 'Standards of Weights and Measures', 'System', 'Tardive Dyskinesia', 'Technology', 'Testing', 'Text', 'Time', 'Tremor', 'Upper Extremity', 'Walking', 'Week', 'Wireless Technology', 'Work', 'base', 'clinically significant', 'computerized data processing', 'day', 'design', 'diaries', 'improved', 'kinematics', 'knowledge base', 'miniaturize', 'monitoring device', 'motor disorder', 'nervous system disorder', 'novel', 'programs', 'prototype', 'research study', 'response', 'sensor', 'statistics', 'success', 'technology development', 'tool']",NIBIB,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2008,637832,0.042841374281923326
"Non-Invasive System for Identifying Neural Behavior    DESCRIPTION (provided by applicant): This application for ""Neurotechnology Research, Development, and Enhancement"" (PA-04-006) proposes the development of innovative technologies, methodologies, and instrumentation to advance our understanding of neural control mechanisms of muscle force production through a non-invasive means of recording neuronal firing patterns. The project will develop an automatic system to accurately and quickly decompose the surface Electromyographic (sEMG) signal into its constituent action potentials and provide the timing of the firings of concurrently active motor units. The goal is to achieve an accuracy of >85% in the automatic mode and >96% with the assistance of an interactive editor. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system by simply placing a sensor above a muscle with no assault to the CNS. The sEMG Decomposition System will replace existing technology that relies on invasive procedures to detect the EMG signal through needle or fine-wire electrodes. The proposed work includes: 1) mathematical modeling and empirical studies to develop a sEMG electrode array that maximizes shape differences of motor unit firings and thereby facilitates sEMG signal decomposition; 2) algorithm development using artificial intelligence technology of our own design combined with Principal Component Analysis techniques; and 3) data acquisition/processing software and hardware to build a portable prototype surface decomposition system. Performance testing of the system will be conducted using data collection experiments to ensure that the system is comparable in motor unit yield, processing speed, and accuracy to the current state-of-the art indwelling decomposition system. We will also prove that the signal decomposition is performed correctly by decomposing two separately collected signals and matching the results. A dissemination plan is included to make this technology available to the Motor Control community. Commercialization will be realized through Altec Inc. This technology will enable researchers in the fields of Motor Control, Aging, Exercise Physiology, Space Medicine, and Ergonomics, where it is of interest to understand how the CNS controls muscles, and how that control is altered as a consequence of aging, exercise, exposure to microgravity, fatigue, and excessive and prolonged force production. It will be useful to clinicians for assessing the degree of dysfunction in upper motoneuron diseases such as Cerebral Palsy, Parkinson's Disease, ALS, Stroke, and other disorders.              n/a",Non-Invasive System for Identifying Neural Behavior,7489322,R01NS058250,"['Action Potentials', 'Age', 'Aging', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Artificial Intelligence', 'Arts', 'Basic Science', 'Behavior', 'Behavioral', 'Businesses', 'Cerebral Palsy', 'Characteristics', 'Clinical', 'Code', 'Communities', 'Computer software', 'Contracts', 'Data Collection', 'Detection', 'Development', 'Disease', 'Electrodes', 'Electromyography', 'Ensure', 'Exercise', 'Exercise Physiology', 'Exposure to', 'Fatigue', 'Feedback', 'Fire - disasters', 'Functional disorder', 'Goals', 'Grant', 'Individual', 'International', 'Invasive', 'Left', 'Marketing', 'Measurement', 'Measures', 'Methodology', 'Microgravity', 'Modeling', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Contraction', 'Muscle Fibers', 'NIH Program Announcements', 'Needles', 'Neurons', 'Numbers', 'Parkinson Disease', 'Pattern', 'Performance', 'Principal Component Analysis', 'Principal Investigator', 'Procedures', 'Process', 'Production', 'Publishing', 'Purpose', 'Range', 'Rate', 'Reliance', 'Research', 'Research Personnel', 'Right-On', 'Risk', 'Safety', 'Sensitivity and Specificity', 'Series', 'Shapes', 'Side', 'Signal Transduction', 'Skin', 'Source', 'Space Medicine', 'Specificity', 'Standards of Weights and Measures', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Tongue', 'Training', 'Validation', 'Work', 'assault', 'base', 'commercialization', 'data acquisition', 'design', 'ergonomics', 'experience', 'human subject', 'improved', 'innovative technologies', 'instrumentation', 'interest', 'mathematical model', 'motor control', 'neuromuscular system', 'neuroregulation', 'neurotechnology', 'new technology', 'non-invasive system', 'performance tests', 'processing speed', 'programs', 'prototype', 'relating to nervous system', 'research and development', 'research study', 'response', 'sensor', 'technology development', 'technology/technique']",NINDS,"ALTEC, INC.",R01,2008,455129,0.012086142338816606
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator. Seacoast's Phase I research will focus on developing the sensor array, demonstrating sensitivity to chlorinated hydrocarbons at relevant concentrations, and field tests in actual contaminated sites. The ultimate goal is to provide the DOD, DOE, NIEHS and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. The systems will have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator collects the contaminants and releases them to a microsensor array. The sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical. An array of differently responding sensors and pattern recognition can thereby compensate for changes in humidity, temperature, and composition. These low-power systems can be left unattended and transmit data wirelessly or through USB to a central location. The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. The potential commercial markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology. PUBLIC HEALTH RELEVANCE: This proposal will describe a potential method to specifically address the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.          n/a",Low-Cost Electronic Nose for Groundwater Contaminants,7537117,R43ES016941,"['Address', 'Algorithms', 'Characteristics', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Compatible', 'Condition', 'Data', 'Data Collection', 'Detection', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Feedback', 'Fingerprint', 'Fluorescence', 'Goals', 'Humidity', 'Industrial Health', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Location', 'Machine Learning', 'Maps', 'Marketing', 'Measures', 'Methods', 'Modification', 'Monitor', 'Nose', 'Numbers', 'Pattern Recognition', 'Phase', 'Poison', 'Polymers', 'Process', 'Public Health', 'Pump', 'ROC Curve', 'Range', 'Rate', 'Recommendation', 'Research', 'Risk', 'Safety', 'Sampling', 'Science', 'Simulate', 'Site', 'Soil', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Trichloroethylene', 'Water', 'Work', 'aqueous', 'base', 'cold temperature', 'computerized data processing', 'cost', 'cost effectiveness', 'design', 'detector', 'drinking water', 'ground water', 'innovation', 'membrane assembly', 'pollutant', 'prototype', 'remediation', 'response', 'sensor', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R43,2008,97690,0.01678060147277223
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7446299,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Count', 'Custom', 'Daily', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Public Health', 'Range', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Standards of Weights and Measures', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'desire', 'image processing', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2008,421791,0.00853701712935333
"A Cell Phone-Based Street Intersection Analyzer for Visually Impared Pedestrians    DESCRIPTION (provided by applicant): Urban intersections are the most dangerous parts of a blind person's travel. They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult. To alleviate this problem, we propose to develop and evaluate a cell phone-based system to analyze images of street intersections, taken by a blind or visually impaired person using a standard camera cell phone, to provide real-time feedback. Drawing on our recent work on computer vision algorithms that help a blind person find crosswalks and other important features in a street intersection, as well as our ongoing work on cell phone implementations of algorithms for indoor wayfinding and for reading digital appliance displays, we will refine these algorithms and implement them on a cell phone. The information extracted by the algorithms will be communicated to the user with a combination of synthesized speech, audio tones and/or tactile feedback (using the cell phone's built-in vibrator). Human factors studies will help determine how to configure the system and its user controls for maximum effectiveness and ease of use, and provide an evaluation of the overall system. The street intersection analysis software will be made freely available for download into any camera-equipped cell phone that uses the widespread Symbian operating system (such as the popular Nokia cell phone series). The cell phone will not need any hardware modifications or add-ons to run this software. Ultimately a user will be able to download an entire suite of such algorithms for free onto the cell phone he or she is already likely to be carrying, without having to carry a separate piece of equipment for each function. Relevance: The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.           n/a",A Cell Phone-Based Street Intersection Analyzer for Visually Impared Pedestrians,7490458,R01EY018345,"['Accidents', 'Address', 'Algorithms', 'American', 'Cellular Phone', 'Complex', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Detection', 'Devices', 'Effectiveness', 'Equipment', 'Evaluation', 'Face', 'Feedback', 'Figs - dietary', 'Grant', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Left', 'Light', 'Mainstreaming', 'Marketing', 'Modification', 'Operating System', 'Pattern', 'Performance', 'Reading', 'Research', 'Research Infrastructure', 'Resolution', 'Running', 'Self-Help Devices', 'Series', 'Signal Transduction', 'Speech', 'Standards of Weights and Measures', 'System', 'Tactile', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Training', 'Travel', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'Zebra', 'base', 'blind', 'consumer product', 'cost', 'day', 'digital', 'experience', 'image processing', 'improved', 'legally blind', 'novel', 'prevent', 'programs', 'skills', 'tool', 'trafficking', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2008,335542,0.023972715321965096
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to build and test a ""Smart Telescope,"" a device for persons with low vision that uses computer vision algorithms to search for, detect and enhance targets such as text and faces to aid in everyday tasks such as travel, navigation and social interactions. The practical, cosmetically acceptable packaging will consist of a miniature camera and visual display discreetly mounted on spectacles or a hat, and a compact computing device and set of controls that fit into a pocket. The Smart Telescope advances today's state of the art in assistive devices for low vision by automatically searching for, detecting and enhancing target objects even when they fill only a small portion of the device's field of view, without the user having to point the device directly or accurately at the target as with optical telescopes. The Smart Telescope is small and lightweight, but large enough for the elderly to handle and control; simple to operate and easy to carry, store, recharge, don and remove. Advanced options are hidden during day-to-day use, but easy to access when necessary. In Phase I, we developed and evaluated a working prototype and received enthusiastic feedback from subjects in our target population. In Phase II we propose to prototype a commercially viable consumer version of the Smart Telescope. The Phase II work plan has four tracks: 1) User interaction and interface design, 2) physical design and configuration, 3) software design and development, and 4) hardware design and development. Smith-Kettlewell's Rehabilitation Engineering Research Center (RERC) will provide expertise for the human factors portions of the project. Blindsight will design and build the device hardware from off-the-shelf components with the help of Bolton Engineering. Low vision experts Drs. Don Fletcher, Melissa Chun and Ian Bailey will work with the RERC to guarantee a practical product for the target audience. The overall aim is to create a commercial version of the proposed device for persons with reduced visual acuity, reduced contrast sensitivity, or other loss of visual function caused by macular degeneration, diabetic retinopathy, glaucoma, cataracts, and other eye problems, increasing mobility and independence for those with acuity between approximately 20/200 and 20/600. At under $1,000, the total market for such a device is estimated at up to 300,000, i.e., 10% of low vision persons in the United States. The commercial version of the Smart Telescope will significantly increase mobility and independence for persons with visual acuity between approximately 20/200 and 20/600, aiding them in everyday tasks such as travel, navigation, and social interactions. It will advance today's state of the art in assistive devices for low vision by improving on and surpassing the capabilities of the traditional optical telescope, greatly benefiting persons with reduced visual acuity, reduced contrast sensitivity, or other loss of visual function caused by macular degeneration, diabetic retinopathy, glaucoma, cataracts, and other eye problems.          n/a",A Smart Telescope for Low Vision,7486800,R44EY014487,"['Algorithms', 'Arts', 'Cataract', 'Computer Vision Systems', 'Contrast Sensitivity', 'Development', 'Devices', 'Diabetic Retinopathy', 'Elderly', 'Engineering', 'Eye', 'Eyeglasses', 'Face', 'Feedback', 'Glaucoma', 'Human', 'Macular degeneration', 'Marketing', 'Melissa', 'Optics', 'Persons', 'Phase', 'Research', 'Self-Help Devices', 'Social Interaction', 'Software Design', 'Target Populations', 'Testing', 'Text', 'Today', 'Travel', 'United States', 'Vision', 'Visual', 'Visual Acuity', 'Visual impairment', 'Work', 'day', 'design', 'improved', 'low vision telescope', 'prototype', 'rehabilitation engineering']",NEI,BLINDSIGHT CORPORATION,R44,2008,434041,-0.009816066301024265
"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",A Wireless Multiscale Distributed Interface to the Cortex,7533930,R01NS062031,"['Address', 'Advanced Development', 'Algorithms', 'Animal Behavior', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cavia', 'Cell physiology', 'Characteristics', 'Communication', 'Computer information processing', 'Computer software', 'Custom', 'Data', 'Devices', 'Discipline', 'Disease', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Imaging technology', 'Implant', 'In Vitro', 'Investigation', 'Learning', 'Machine Learning', 'Mediating', 'Microelectrodes', 'Monitor', 'Motor', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Outcome', 'Paralysed', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Public Health', 'Rattus', 'Research', 'Retinal', 'Rodent', 'Rodent Model', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Slice', 'Stimulus', 'Stream', 'System', 'Telemetry', 'Testing', 'Time', 'Wireless Technology', 'awake', 'base', 'brain cell', 'brain machine interface', 'clinical application', 'computerized data processing', 'data acquisition', 'density', 'design', 'desire', 'disability', 'implantation', 'improved', 'in vivo', 'microsystems', 'nervous system disorder', 'neural circuit', 'prototype', 'quantum', 'relating to nervous system', 'response', 'size', 'subcutaneous', 'tool']",NINDS,MICHIGAN STATE UNIVERSITY,R01,2008,527963,0.0029488115388662303
"Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface    DESCRIPTION (provided by applicant):      Over 600,000 Americans have severely impaired motor function from disorders including spinal cord injury, amyotrophic lateral sclerosis, pontine stroke, and cerebral palsy. A brain-machine interface (BMI) could enable locked-in or tetraplegic patients to communicate and interact with their environment. Two crucial decisions in designing a BMI are (1) what type of brain signals to use as inputs to a controller and (2) what methods to use to decode those signals. Most BMIs have used either noninvasive scalp EEG recordings or invasive intracortical recordings of single- or multi-neuron spikes as control inputs. A few have used subdural or intracortical local field potentials (LFPs). However, no group has yet systematically compared these signals in motor cortex for use in BMI applications. This proposal's first goal is to assess the relative performance of spikes and field potentials (both intracortical and epidural) as control inputs for a variety of movement-related outputs. Epidural field potentials (EFPs) are intermediate in invasiveness, signal quality, stability and spatial resolution compared with existing scalp, subdural, and intracortical recordings, and thus represent an unexplored middle ground. This proposal's second goal is to evaluate linear and nonlinear techniques-including several novel to BMI applications-for both decoding data and reducing the inherently large dimensionality of data from multiple neural signals. The primary hypotheses of the proposed project are (1) that spikes will perform better in decoding more complex movement-related outputs, but that field potentials may perform similarly on decoding simpler outputs, and (2) that nonlinear decoders and dimensionality-reduction techniques may provide improved accuracy over linear methods. The specific aims to address these hypotheses are 1) to evaluate single neuron spikes as inputs to decoders of movement- related outputs, 2) to develop a novel epidural multi-electrode recording technique in the macaque monkey, and 3) to evaluate field potential signals as inputs to decoders of movement-related outputs. Aims 1 and 3 will involve application of dimensionality-reduction algorithms (e.g., independent components analysis, Isomap) and decoding algorithms (system identification, neural networks, support vector machines) to both spikes and field potentials. Aim 2 will entail using a computer model and spatial spectral analysis to optimize the epidural electrode array design. This project will provide the first comparison of spikes, LFPs and EFPs as inputs for identical BMI output applications. The supervision of Drs. Lee Miller and W. Zev Rymer, with additional guidance from Drs. Simon Levine, Jonathan Wolpaw and Nicholas Hatsopoulos, will provide the principal investigator with expertise in recording and processing both spikes and field potentials for BMI applications using a variety of state-of-the- art techniques. A comprehensive career development plan including clinical and research mentoring, seminars, and courses, will foster the candidate's transition into an independent physician-scientist.           n/a",Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface,7470575,K08NS060223,"['Action Potentials', 'Address', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Arts', 'Benchmarking', 'Biological Neural Networks', 'Brain', 'Cerebral Palsy', 'Cervical spinal cord injury', 'Clinical Research', 'Complex', 'Computer Simulation', 'Count', 'Craniotomy', 'Data', 'Development Plans', 'Discriminant Analysis', 'Disease', 'Disease regression', 'Dura Mater', 'Electrodes', 'Electroencephalography', 'Electromyography', 'Environment', 'Evaluation', 'Figs - dietary', 'Fostering', 'Frequencies', 'Genetic Programming', 'Goals', 'Hand', 'Implant', 'Implanted Electrodes', 'Invasive', 'Knowledge', 'Learning', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Physicians', 'Pontine structure', 'Principal Investigator', 'Procedures', 'Process', 'Quadriplegia', 'Rattus', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Scalp structure', 'Scientist', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Statistical Methods', 'Stroke', 'Sum', 'Supervision', 'System', 'Techniques', 'Time', 'Tissues', 'Training', 'Upper arm', 'Visual', 'brain machine interface', 'career', 'computerized data processing', 'cranium', 'design', 'disability', 'feeding', 'improved', 'in vivo', 'independent component analysis', 'motor control', 'novel', 'programs', 'prototype', 'relating to nervous system', 'research study', 'surgical technique development']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,K08,2008,167832,0.009360221344355102
"Webcam Interface for Audio/touch Graphics Access by Blind People    DESCRIPTION (provided by applicant):  The goal of this project is to develop a compact inexpensive alternative to the bulky expensive touchpads now required by blind people for audio/touch access to graphical information. Audio/touch is known to provide excellent access to computer-literate blind people as well as people with dyslexia or other severe print disabilities. Preparing Audio/touch materials was very expensive until ViewPlus introduced the IVEO Scalable Vector Graphic (SVG) Authoring/conversion software in 2005. IVEO permits virtually any graphical information to be created or converted/imported easily to a well- structured highly accessible SVG format. Tactile copy was also very expensive before 2000 when ViewPlus introduced the Tiger embossing Windows printers that ""print"" by embossing. The new ViewPlus Emprint printer/embossers emboss and also print color images, creating color tactile images particularly useful for people with dyslexia and a number of other print disabilities. An audio/touch user reads an IVEO SVG graphic using the free IVEO Viewer, a tactile copy of the image, and a touchpad. The user places the tactile graphic on the touchpad and presses a point of interest. The touchpad communicates the position of that point back to the computer, and the IVEO Viewer speaks the appropriate information. Tactile text made from mainstream graphics has a distinctive pattern. When a user presses, that text is spoken by the IVEO Viewer. When the user presses a graphic object having a SVG title within the file, that title will be spoken. Objects may also have arbitrarily long description fields that can be spoken and browsed. All spoken information can be displayed on an attached braille display if desired. Graphical information is ubiquitous today, but almost none is accessible to blind people. Government agencies, libraries, companies, and agencies serving people with disabilities could easily send highly accessible IVEO graphics files and tactile graphic copies to clients with disabilities, but there is a ""chicken and egg"" dilemma that must be overcome before they are likely to do so. Few blind people have a touchpad (which cost $500 or more), so few could use that information. The specific aim of this Phase I proposal is to develop an affordable webcam-based prototype as an alternative to touchpads. It is based on an inexpensive webcam that is focused on the graphic and follows a finger. A touchpad press is emulated in this prototype by pressing some computer key with the other hand. This project could be the key to bringing accessible graphics to all blind computer users and is clearly of interest to NEI whose mission statement includes mental health and quality of life of blind people. PUBLIC HEALTH RELEVANCE:  This proposal is relevant to the mission of the National Eye Institute, because it could be the key to making nearly all graphical information easily accessible to people who are blind or have other severe print disabilities. Graphical information is ubiquitous in the world today but is not presently accessible to blind people except through expensive and time-consuming conversion by trained transcribers. Making all graphical information accessible would have an obviously highly beneficial direct effect on education and professional opportunities, mental health, and quality of life of blind people. Mental health and quality of life issues for blind people are parts of the mission of the National Eye Institute.          n/a",Webcam Interface for Audio/touch Graphics Access by Blind People,7480812,R43EY018973,"['Back', 'Braille Display', 'Businesses', 'Chickens', 'Client', 'Color', 'Communities', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consultations', 'Development', 'Devices', 'Disabled Persons', 'Dyslexia', 'Event', 'Fingers', 'Goals', 'Government Agencies', 'Hand', 'Home environment', 'Image', 'Information Systems', 'Institution', 'Internet', 'Libraries', 'Link', 'Mainstreaming', 'Marketing', 'Mental Health', 'Methods', 'Mission', 'Modeling', 'Mus', 'National Eye Institute', 'Numbers', 'Oregon', 'Pattern', 'Phase', 'Positioning Attribute', 'Printing', 'Professional Education', 'Public Health', 'Publications', 'Quality of life', 'Range', 'Reading', 'Site', 'Structure', 'Structure of nail of finger', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Text', 'Tigers', 'Time', 'Title', 'Today', 'Touch sensation', 'Training', 'Universities', 'Visual', 'Visually Impaired Persons', 'base', 'blind', 'braille', 'cost', 'desire', 'digital', 'disability', 'egg', 'interest', 'literate', 'print disabilities', 'programs', 'prototype', 'research and development', 'tool', 'touchpad', 'vector']",NEI,"VIEWPLUS TECHNOLOGIES, INC.",R43,2008,100001,-0.012205054353283984
"Indoor Magnetic Wayfinding For The Visually Impaired    DESCRIPTION (provided by applicant): Advanced Medical Electronics (AME) proposes the development of an indoor way-finding device utilizing the unique magnetic anomaly patterns that exist in modern, man-made structures. The proposed system will record the magnitude of magnetic field strength from sensors in three orthogonal axes. The time history of these magnetic data points can be continuously compared with an electronic map of magnetic anomalies (or, ""signature"") to determine current position within a building. The phase I developed prototype system tracked in feasibility experiments with an accuracy of 1 foot (radius). Magnetic anomalies render a magnetic compass useless for finding a directional bearing. However, these same invisible anomalies represent valuable, unique indoor terrain features measurable by magnetic sensors located inside a small, portable device. Such a device would be able to provide low-vision users with a valuable indoor low-cost way-finding tool analogous to a Global Positioning System (GPS) device used outdoors. About 3.7 million Americans are visually disabled. Of these, 200,000 are blind, and the rest have low vision. The key advantage of the way-finding concept presented in this proposal, over other methods, is that the benefits are made available to the visually impaired community without requiring expensive building infrastructure investments. This is of particular advantage to large government buildings and educational campuses. The proposed approach allows a cost effective solution to way-finding within these buildings.          n/a",Indoor Magnetic Wayfinding For The Visually Impaired,7477498,R44EY015616,"['American', 'Appointment', 'Building Codes', 'Cognition', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Development', 'Devices', 'Disabled Persons', 'Doctor of Philosophy', 'Education', 'Electronics', 'Engineering', 'Fee-for-Service Plans', 'Funding', 'Government', 'Hand', 'Housing', 'Human', 'Indoor Magnetic Wayfinding', 'Investments', 'Joints', 'Label', 'Location', 'Magnetism', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Medical Electronics', 'Minnesota', 'Modeling', 'Modification', 'Neurosciences', 'Numbers', 'Oceans', 'Pattern', 'Pattern Recognition', 'Pennsylvania', 'Persons', 'Phase', 'Population', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychology', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Rest', 'Services', 'Silicon Dioxide', 'Solutions', 'Somatotype', 'Speech', 'Steel', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Today', 'Universities', 'Vision', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Wireless Technology', 'World Health Organization', 'base', 'blind', 'college', 'computer science', 'concept', 'cost', 'cost effective', 'court', 'design', 'digital', 'foot', 'human subject', 'innovation', 'interest', 'magnetic field', 'miniaturize', 'motor control', 'performance tests', 'professor', 'prototype', 'radius bone structure', 'research study', 'sensor', 'sensory integration', 'tool', 'way finding']",NEI,ADVANCED MEDICAL ELECTRONICS CORPORATION,R44,2008,365248,0.014096713117205197
"CRCNS: Where to look next? Modeling eye movements in normal and impaired vision    DESCRIPTION (provided by applicant): The goal of this proposal is to gain a better understanding of the information processing and decision strategies that underlie eye movement planning in both the normal and diseased state. In patients with age-related macular degeneration (AMD), central areas of the retina are damaged, creating a large blind spot that forces them to rely solely on residual vision in the periphery. Rehabilitation outcomes for these patients can be successful, but are often inconsistent. Despite similar retinopathies, some patients learn to use their residual vision more effectively than others. We have developed an information-theoretic model and experimental paradigm which will allow us to objectively measure human scanning efficiency. The development of the model has naturally motivated fundamental experimental questions about eye movements and neural decision making. The answers to these questions will be used to refine the model and enhance our understanding of the system in general. We will then apply the model framework to investigate differences in eye movement behavior between AMD patients and normally-sighted individuals. The interplay of model development and experimental investigation will significantly increase our knowledge of how humans use prior knowledge and task demands to direct their gaze, and how new visual information is incorporated into an eye movement plan. The results will have broad relevance to understanding neural decision making in general.   Relevance to Public Health. The application of the model to a clinical population will bring much-needed objective measures to understanding the extent of impairment in individuals with AMD. With this understanding comes great potential for improving rehabilitation training strategies that will enhance the quality of life for these patients and their families.          n/a",CRCNS: Where to look next? Modeling eye movements in normal and impaired vision,7477064,R01EY018004,"['Age related macular degeneration', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'California', 'Clinic', 'Clinical', 'Computer Simulation', 'Computer Vision Systems', 'Computer information processing', 'Condition', 'Decision Making', 'Doctor of Philosophy', 'Ensure', 'Experimental Models', 'Eye Movements', 'Family', 'Goals', 'Human', 'Impairment', 'Individual', 'Information Theory', 'Investigation', 'Knowledge', 'Learning', 'Measures', 'Medical center', 'Modeling', 'Movement', 'Ophthalmologist', 'Outcome', 'Patients', 'Pattern', 'Population', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Psychophysics', 'Psychophysiology', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Retina', 'Retinal', 'Retinal Diseases', 'Retinal blind spot', 'Saccades', 'Scanning', 'Signal Detection Analysis', 'Statistical Models', 'System', 'Techniques', 'Training', 'Training Programs', 'Update', 'Vision', 'Visual', 'Visual impairment', 'Work', 'behavior prediction', 'design', 'disease characteristic', 'experience', 'gaze', 'image processing', 'improved', 'model development', 'predictive modeling', 'relating to nervous system', 'research study', 'sample fixation', 'success', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2008,250129,-0.004248364061798455
"Accessible Artificial Intelligence Tutoring Software (Phase II SBIR)    DESCRIPTION (provided by applicant): This Phase II proposal focuses on the development of accessible artificial intelligence (AI) software for individualized tutoring and formative assessment in chemistry education. If successful, an immediate outcome will be the very first AI tutoring systems for chemistry that are accessible to blind students, delivered through the Internet. An AI tutoring methodology formulated with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. Furthermore, classroom teachers can obtain individualized assessment reporting and diagnostic information for visually impaired students on demand, as if from a ""virtual teaching assistant"". Feasibility of Phase I was demonstrated by developing a prototype accessible AI tutoring program that received certification in the National Federation of the Blind's (NFB) Nonvisual Accessibility Web Application Certification Program. In previous SBIR projects, Quantum has successfully innovated new concepts in the field of AI and has developed, tested and brought to the classroom tutoring and assessment systems for science and mathematics education. Certain unique attributes of the Quantum AI Tutors make them potentially very well suited for full accessibility to the blind, as well as individuals with other print-related disabilities, using Internet- capable screen reader technology. The potential technological innovation is the development of the first advanced AI chemistry tutoring technology that has accessibility built into its framework design. Important Phase II objectives include:  Continued progress on chemistry-specific accessibility issues. Completion of full accessibility support in AI framework itself. Implementation of Braille support for chemical formulas and equations. Investigation of chemistry-specific pedagogical issues for blind students. Extension to accessible science assessment for blind/VI students, building on AI assessment technology currently under development by Quantum in other projects. Special education is a particular challenge for assessment within the No Child Left Behind legislation. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum has long-term partnerships with McGraw-Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as two additional commercial agreements with major science education supply companies, Science Kit & Boreal Laboratories and Sargent-Welch. Chemistry comprises the majority of the content standard for physical science in the National Science Education Standards, and yet is one of the most neglected areas in terms of quality educational software, in general, and is a particularly acute problem for the blind and visually impaired. Through recent federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom the very first artificial intelligence (AI) tutoring systems for chemistry. The goal of the present research is to bring the full power and benefit of this cutting-edge new educational technology to students who are blind and visually impaired using Internet-capable screen access technology.          n/a",Accessible Artificial Intelligence Tutoring Software (Phase II SBIR),7220194,R44EY016251,"['Achievement', 'Acute', 'Address', 'Agreement', 'American', 'Area', 'Artificial Intelligence', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Child', 'Computer software', 'Country', 'Development', 'Diagnostic', 'Drug Formulations', 'Education', 'Educational Technology', 'Educational process of instructing', 'Equation', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Investigation', 'Laboratories', 'Left', 'Mathematics', 'Methodology', 'Mission', 'Numbers', 'Outcome', 'Performance', 'Phase', 'Philosophy', 'Preparation', 'Printing', 'Purpose', 'Reader', 'Reporting', 'Research', 'Schools', 'Science', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Special Education', 'Standards of Weights and Measures', 'Statutes and Laws', 'Students', 'Support of Research', 'System', 'Technology', 'Technology Assessment', 'Testing', 'Visual impairment', 'Work', 'blind', 'braille', 'commercialization', 'concept', 'design', 'disability', 'falls', 'high school', 'improved', 'innovation', 'neglect', 'next generation', 'physical science', 'programs', 'prototype', 'quantum', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'virtual']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2007,366168,0.022789733739605012
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7172503,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2007,1159531,-0.006657641486763447
"Home Sensor Date Fusion to Support Aging in Place    DESCRIPTION (provided by applicant): The aging of the U.S. population presents many challenges. The existing paradigm of care will not allocate resources efficiently as the size of the population requiring home care assistance grows. Our objective is to enhance elder independence by providing both better and more timely predictive health-status assessments and direct, real-time, recommendations and warnings. These together will lower the risk of elders remaining at home or in low intensity care settings. The objective of the Phase II research and development effort is to develop technology that can detect and track activities in the home environment and to demonstrate its usefulness in allowing elders to remain in their homes longer than is now possible. CleverSet will develop and deploy a prototype CleverSet Activity Tracker, CAT, that processes data from a robust set of simple sensors to (1) track the activities of daily living over time (2) modify these tracked activities to include uncertainty about the environment and risk to produce notifications of Events Requiring Intervention (ERIs); and (3) demonstrate the results of the models. The technological innovation of the proposed work is the application of dynamic relational Bayesian networks (DRBNs) to activities in the home environment. CleverSet's DRBN algorithms collectively referred to as CleverSet Modeler, exploit the data model and meta-data from the schema to guide and frame relational queries about behavior and events. In the proposed work, DRBNs will be used to represent complex, dynamic, multi-scale processes involving multiple actors, as probability distributions over the elements, queries, and relationships in the DRBN model. Activities of daily living (ADLs) will be identified using DRBN machine learning algorithms from sensor data and tracked through time. Short-term rhythms of daily life as well as longer-term transitions will be tracked. Risk modifiers relevant to elders will be integrated into the model and used to adapt the sensor data input. Sensor studies will also be performed to determine the relative contribution of sensors to the DRBN ADL models. A software prototype integrating the elements of the Phase II effort will be developed.         n/a",Home Sensor Date Fusion to Support Aging in Place,7287365,R44AG024687,"['Activities of Daily Living', 'Address', 'Aging', 'Algorithms', 'Behavior', 'Caregivers', 'Caring', 'Case Manager', 'Communities', 'Complex', 'Computer software', 'Computers', 'Contracts', 'Copyright', 'Daily', 'Data', 'Detection', 'Drops', 'Elderly', 'Elements', 'Environment', 'Equilibrium', 'Event', 'Family', 'Family member', 'Goals', 'Health Status', 'Home Care Services', 'Home environment', 'Household', 'Intervention', 'Licensing', 'Life', 'Machine Learning', 'Maintenance', 'Marketing', 'Methodology', 'Modeling', 'Monitor', 'Notification', 'Outsourcing', 'Phase', 'Placement', 'Population', 'Population Sizes', 'Privacy', 'Probability', 'Process', 'Recommendation', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Assessment', 'Security', 'Services', 'Site', 'Staging', 'Stream', 'System', 'Technology', 'Time', 'Uncertainty', 'Work', 'base', 'commercial application', 'computer based statistical methods', 'computerized data processing', 'cost', 'data modeling', 'network models', 'patient home care', 'programs', 'prototype', 'research and development', 'sensor', 'technological innovation', 'tool']",NIA,"CLEVERSET, INC.",R44,2007,378793,-0.000798256670686637
"Nanopore study of single antibody-antigen interactions DESCRIPTION:    Nanopore-based single-molecule detection has recently become established as a new tool in single molecule biophysics. Evidence is presented that single antibodies can be observed with a nanopore detector, which presents a wide range of possibilities for immunological research. The hypothesis to be tested is that nanopore-based detection can be used to study single molecule dynamics of antibody-antigen interaction and analyze conformational changes that occur in antibody upon binding to antigen. This application aims to develop the utility of the nanopore-based approach through improvements in both the detection device and the software used to extract information from the channel current signal. At the same time, these studies will allow the Candidate to gain expertise in immunology and the biophysical study of protein structure and function. To study the single molecule dynamics of antibody-antigen interaction, the following three specific aims are proposed:   1. Extend nanopore based detection to nanopore/antibody based detection.   2. Implement machine learning software for automated nanopore/antibody signal analysis and experimental feedback.   3. Use well-characterized, genetically engineered, antibodies to test the utility of the nanopore device to analyze motion in the antibody molecule.   These studies will expand the utility of nanopore devices to study single molecule protein interactions.   Information gained will lead to a better understanding of the molecular dynamics associated with antigen binding by antibody and the subsequent initiation of effector functions. Since most biological nanopore variants derive from pore-forming toxins, nanopore device enhancements eventually may lead to new methods for antibody and antimicrobial-peptide immunological screening. Antibody-based nanopore devices may also serve as highly sensitive immunosensors. n/a",Nanopore study of single antibody-antigen interactions,7286095,K22LM008794,"['Algorithms', 'Altretamine', 'Antibodies', 'Antigenic Specificity', 'Antigens', 'Architecture', 'Base Pairing', 'Binding', 'Biological', 'Biophysics', 'Biosensing Techniques', 'Buffers', 'Class', 'Classification', 'Computer software', 'Condition', 'DNA', 'Data', 'Detection', 'Development', 'Devices', 'Dissociation', 'Failure', 'Feedback', 'Fingerprint', 'Haptens', 'Hemolysin', 'Immunology', 'Informatics', 'Kinetics', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Motion', 'Noise', 'Pattern Recognition', 'Physiological', 'Play', 'Pliability', 'Preparation', 'Principal Investigator', 'Probability', 'Process', 'Proteins', 'Protocols documentation', 'Range', 'Rate', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Role', 'Sampling', 'Screening procedure', 'Semiconductors', 'Signal Transduction', 'Staging', 'Statistical Methods', 'Testing', 'Time', 'Time Study', 'Toxin', 'Variant', 'antibody engineering', 'antigen antibody binding', 'antigen binding', 'antimicrobial peptide', 'base', 'cheminformatics', 'computerized data processing', 'design', 'detector', 'expectation', 'experimental analysis', 'markov model', 'molecular dynamics', 'nanopore', 'programs', 'protein structure function', 'prototype', 'single molecule', 'stem', 'tool', 'vector', 'web interface']",NLM,CHILDREN'S HOSPITAL (NEW ORLEANS),K22,2007,162000,-0.01712065926620871
"Motor Learning for the Control of an Assistive Device    DESCRIPTION (provided by applicant):  The goal of these studies is to understand how movements of the body can be harnessed and trained to control electrically powered wheelchairs. Advanced wheelchair technology is often perceived to be a barrier by a large number of potential wheelchair users. An approach is proposed for the removal of this barrier based on adapting the assistive technology to the residual unconstrained mobility of the patients and on enhancing motor learning. This exploratory project aims at establishing the feasibility of such an approach and at developing training methods based on the identification of natural motions and on the use of virtual reality (VR). The proposed studies will be carried out on quadriplegic spinal cord injured patients with complete or incomplete cervical injuries. Healthy volunteers will also participate in these study to fine-tune the experimental apparatus and to provide a reference baseline to assess learning and coordination. Subjects will wear a novel upper-body sensing garment. A total of 52 electrical signals generated by the garment will be modulated by movements of the wrist, elbow, shoulder and torso. These signals will be mapped into the velocity commands for a simulated wheelchair. Subjects will wear VR-goggles and a head tracker, which will provide them with a immersive view of a computer-generated environment from the perspective of the simulated wheelchair. The combination of virtual reality environments and wearable signal technology will provide a framework for evaluating training protocols that would not be feasible with actual wheelchairs. The proposed studies are organized in two specific aims: (Aim 1.) To identify motor primitives for the control of a virtual wheelchair by unrestricted upper body motions Three well-established signal processing techniques - Principal Component Analysis, Independent Component Analysis and Isomap - will be used and compared for extracting low-dimensional signal patterns from the garment signals (Aim 2.) To identify maps and procedures that facilitate motor learning. The signal patterns extracted from Aim 1 will be used to design and test new transformations from subject motions to wheelchair commands. A well- known machine learning technique -least mean squares gradient descent - will be tested for matching the natural motor primitives of the subjects with an appropriate set of control signals to the wheelchair. Finally the safe VR environment will allow us to test whether it is most efficient to learn by gradually speeding up wheelchair motions or by gradually slowing them down. The results of these studies are expected to guide the development of new technology for assistive devices based on human motor learning and on engineering of adaptive control. Many disabled individuals are facing difficult challenges to take advantage of assistive technologies. In particular the safe and efficient use of powered wheelchair is limited by the need for patients to learn to operate their control apparatus. The proposed studies will investigate the possibility to reverse this situation and take advantage of advanced technologies for adapting the control apparatus to the residual skills of the patients.       n/a",Motor Learning for the Control of an Assistive Device,7258179,R21HD053608,"['Accidents', 'Accounting', 'Address', 'Asia', 'Behavior', 'Biomechanics', 'Cervical', 'Cervical spinal cord injury', 'Computers', 'Custom', 'Development', 'Disabled Persons', 'Elbow', 'Engineering', 'Environment', 'Evolution', 'Excision', 'Face', 'Family', 'Feedback', 'Freedom', 'Goals', 'Goggles', 'Head', 'Human', 'Individual', 'Injury', 'Investigation', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Methods', 'Motion', 'Motor', 'Motor Skills', 'Movement', 'Musculoskeletal', 'Numbers', 'Outcome', 'Patients', 'Pattern', 'Performance', 'Play', 'Powered wheelchair', 'Principal Component Analysis', 'Procedures', 'Process', 'Protocols documentation', 'Quadriplegia', 'Residual state', 'Risk', 'Role', 'Self-Help Devices', 'Shoulder', 'Signal Transduction', 'Simulate', 'Speed', 'Spinal cord injury', 'Staging', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Wheelchairs', 'Wrist', 'base', 'body sense', 'computer generated', 'computerized data processing', 'design', 'disability', 'healthy volunteer', 'independent component analysis', 'innovation', 'instrument', 'motor learning', 'new technology', 'novel', 'research study', 'skills', 'tool', 'virtual', 'virtual reality']",NICHD,REHABILITATION INSTITUTE OF CHICAGO,R21,2007,225323,0.03586837546390738
"Development of a Bidirectional Brain Machine Interface    DESCRIPTION (provided by applicant): Recent technological advances have made it possible to move a robotic device in real time, using signals obtained directly from the brain. This field of Brain Machine Interface (BMI) has the means to provide movement for paralyzed patients, communication for locked-in patients, and a better understanding of the brain for all of society. In order to control movement effectively, the brain must be able to activate muscles appropriately, and monitor the evolving movement quickly and precisely. Existing BMIs for, while remarkable, do each of these tasks in poor imitation of the intact nervous system. Our proposed work addresses these limitations by developing a bidirectional interface that produces movement in a more natural way, and provides feedback about the movement by direct, electrical stimulation of the brain. Our partnership includes members at Northwestern Univ (NU), Univ of Chicago (UC), Univ of Mass, Amherst (UMass), and the autonomous Univ of Mexico (UNAM). Partners have advanced degrees in a range of biological science, computer science, physics, mathematics, and engineering disciplines. Miller (NU) will coordinate the partnership. He has extensive experience with a wide range of recording, stimulation and behavioral protocols in behaving monkeys. Hatsopoulos (UC) is at the forefront of the field of multi-electrode recordings. He was a leading member of the first group to demonstrate visually guided BMI control by a primate. Barto (U Mass) has done pioneering research in neural networks, machine learning and stochastic optimization. Fagg (UMass) is an authority in the control of reaching and grasping robots that learn to interact with the environment. Together they will develop the decoders of activity from the brain used to cause movement. Romo (UNAM), is a world leader in studies of the perceptual and decision making processes induced by electrical stimulation of the brain. Solla (NU) is an expert in neural networks and information theory. With Romo, she will develop optimal routines to encode information in stimulus trains to provide feedback to the brain. Mussa-Ivaldi (NU) will focus on the overall design and evaluation of the interfaces. He created the first ever bidirectional interface between neural tissue and a robotic device.          n/a",Development of a Bidirectional Brain Machine Interface,7225186,R01NS048845,"['Address', 'Affect', 'Area', 'Behavior', 'Behavioral', 'Behavioral Paradigm', 'Biological Neural Networks', 'Biological Sciences', 'Boxing', 'Brain', 'Brain Stem', 'Cerebellum', 'Chicago', 'Collaborations', 'Communication', 'Complex', 'Condition', 'Data', 'Decision Making', 'Development', 'Discipline', 'Effectiveness', 'Electric Stimulation', 'Electrical Stimulation of the Brain', 'Electrodes', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Evolution', 'Face', 'Feedback', 'Figs - dietary', 'Freedom', 'Hand', 'Hand functions', 'Implant', 'Information Networks', 'Information Theory', 'Joints', 'Kinetics', 'Lampreys', 'Learning', 'Limb structure', 'Link', 'Machine Learning', 'Mathematics', 'Measurement', 'Methods', 'Mexico', 'Microelectrodes', 'Modeling', 'Monitor', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Musculoskeletal', 'Nervous system structure', 'Neural Network Simulation', 'Numbers', 'Output', 'Paralysed', 'Pathway interactions', 'Patients', 'Perception', 'Performance', 'Physics', 'Physiological', 'Play', 'Positioning Attribute', 'Primates', 'Principal Investigator', 'Process', 'Property', 'Proprioception', 'Protocols documentation', 'Range', 'Rate', 'Reaction Time', 'Reflex action', 'Relative (related person)', 'Research', 'Research Personnel', 'Robot', 'Role', 'Rotation', 'Scientist', 'Secure', 'Sensory', 'Signal Transduction', 'Simulate', 'Societies', 'Somatosensory Cortex', 'Source', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Torque', 'Training', 'Upper arm', 'Vision', 'Work', 'authority', 'base', 'brain machine interface', 'computer science', 'design', 'experience', 'grasp', 'improved', 'kinematics', 'limb movement', 'member', 'novel', 'programs', 'relating to nervous system', 'research study', 'robotic device', 'sensory feedback', 'time use', 'virtual', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2007,819258,0.04231742503217313
"Harnessing Motoneuron Activity: From Lab to Clinic    DESCRIPTION (provided by applicant):  We propose to continue the development of an automatic system that will accurately and quickly decompose electromyographic (EMG) signals into their constituent action potentials and provide the timing of every firing of a set of concurrently active motor units. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system. We will improve the performance of the decomposition algorithms by incorporating new Artificial Intelligence concepts, and a new multi-strategy Hidden Markov Model (HMM) processing stage, to address signal decomposition challenges that cannot be met by the present technology. We will improve the present accuracy from typically 85% for 8 concurrently active motor units to greater than 96% for up to 15 concurrently active motor units. We will also design and build the hardware and software for a stand-alone portable system that may be used in the laboratory or clinic. Then we will transfer the system to a manufacturer for commercialization. In so doing we will produce, for the first time, an advanced system for conveniently and accurately obtaining the firings of a large group of concurrently active motor units from an EMG signal. The new technology will be tested in two applied studies that will be carried out concurrently with the technical developments. One will investigate neural modifications in the firing characteristics of motor units as a function of aging and physical activity. The other will investigate the mitigating effects of resistive exercise on age-related neural adaptations, culminating in the development of a clinical marker to estimate the likelihood that an elderly individual will benefit from an exercise program. The proposed BRP will be lead by Drs. De Luca, Roy, and Adam, key personnel from Boston University (BU) with expertise in biomedical engineering and EMG system development. Signal processing/software development will be provided by the leadership from Dr. Nawab through BU's Department of Electrical and Computer Engineering. Clinical expertise on aging/motor control will be provided by Dr. Novak, from The Department of Neurology at BU School of Medicine, and through Dr. Wolf, from the Department of Rehabilitation Medicine at the Emory University School of Medicine in Atlanta           n/a",Harnessing Motoneuron Activity: From Lab to Clinic,7236418,R01HD050111,"['Action Potentials', 'Address', 'Age', 'Aging', 'Algorithms', 'Artificial Intelligence', 'Biomedical Engineering', 'Boston', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Markers', 'Computer Systems Development', 'Computer software', 'Computers', 'Development', 'Elderly', 'Electrodes', 'Engineering', 'Exercise', 'Fire - disasters', 'Human Resources', 'Individual', 'Laboratories', 'Lead', 'Leadership', 'Manufacturer Name', 'Medicine', 'Modeling', 'Modification', 'Motor', 'Motor Neurons', 'Neurology', 'Performance', 'Physical activity', 'Process', 'Range', 'Rehabilitation therapy', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Universities', 'Wolves', 'Work', 'advanced system', 'age related', 'commercialization', 'computerized data processing', 'concept', 'design', 'improved', 'markov model', 'mathematical model', 'medical schools', 'motor control', 'neuroadaptation', 'neuromuscular system', 'new technology', 'programs', 'relating to nervous system', 'software development']",NICHD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2007,557233,0.00490623124947912
"Wearable-Sensor System for Monitoring Motor Function    DESCRIPTION (provided by applicant): We propose to develop a wearable Personal Status Monitor for improving the medication management of Parkinson's Disease patients by monitoring the effects of the medication continuously during the day. New outcome measures are needed to supplement the self-reports currently in use that are ineffective in managing the complex and unpredictable nature of movement disorders in this population. The device we propose to develop can be worn unobtrusively by patients in their home to automatically provide the following clinically significant information: 1) the presence and severity of specific primary and secondary movement disorders associated with the disease, 2) the status of  On-Off motor fluctuation in response to anti-Parkinson's medication, and 3) the mobility status of the patient. The patient will be monitored by specially designed electromyographic (EMG) and accelerometric (ACC) body-worn sensors. Their signals will be analyzed by a novel Artificial Intelligence knowledge-based signal processing method developed by our group specifically for this purpose. Success of the system will be based on classification accuracy compared to observation by experts. The proposal is composed of two projects. The first and dominant project will develop the underlying technological requirements for the PSM system's application to Parkinson's disease. The aims will include acquisition hardware development in the form of hybrid EMG/ACC sensors. However, the emphasis will be on the development of the knowledge-based algorithms and their software implementation. The second project is designed to acquire the knowledge base needed in Project 1 through data collection experiments from control subjects and patients with Parkinson's disease. The experiments are designed to advance the algorithm development in a hierarchical manner starting from highly standardized activities to free-form activities which approximate real-world conditions. The development of the system will be constructed so that future versions can be adapted to other movement disorders. The successful development of this technology will be transferred for commercial development with the financial assistance of the Massachusetts Community Technology Foundation.         n/a",Wearable-Sensor System for Monitoring Motor Function,7285272,R01EB007163,"['Activities of Daily Living', 'Age', 'Algorithms', 'Artificial Intelligence', 'Body Surface', 'Bradykinesia', 'Cardiac', 'Classification', 'Clinical', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Daily', 'Data', 'Data Collection', 'Development', 'Devices', 'Disease', 'Dyskinetic syndrome', 'Effectiveness', 'Essential Tremor', 'Exertion', 'Exhibits', 'Fingers', 'Foundations', 'Freezing', 'Future', 'Gilles de la Tourette syndrome', 'Holter Electrocardiography', 'Home environment', 'Huntington Disease', 'Hybrids', 'Inherited Spinocerebellar Degenerations', 'Interview', 'Investigation', 'Kinetics', 'Levodopa', 'Limb structure', 'Lower Extremity', 'Massachusetts', 'Measurement', 'Medical', 'Medication Management', 'Methods', 'Monitor', 'Motion', 'Motor', 'Motor Activity', 'Movement Disorders', 'Muscle', 'Nature', 'Neurologist', 'Neuromuscular Diseases', 'Nose', 'Numbers', 'Operative Surgical Procedures', 'Outcome Measure', 'Parkinson Disease', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phase II Clinical Trials', 'Population', 'Posture', 'Principal Investigator', 'Purpose', 'Questionnaires', 'Recording of previous events', 'Research Personnel', 'Sampling', 'Severities', 'Signal Transduction', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Specialist', 'Staging', 'Standards of Weights and Measures', 'System', 'Tardive Dyskinesia', 'Technology', 'Testing', 'Text', 'Time', 'Tremor', 'Upper Extremity', 'Walking', 'Week', 'Wireless Technology', 'Work', 'base', 'clinically significant', 'computerized data processing', 'day', 'design', 'diaries', 'improved', 'kinematics', 'knowledge base', 'miniaturize', 'monitoring device', 'motor disorder', 'nervous system disorder', 'novel', 'programs', 'prototype', 'research study', 'response', 'sensor', 'statistics', 'success', 'technology development', 'tool']",NIBIB,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2007,617760,0.042841374281923326
"Non-Invasive System for Identifying Neural Behavior    DESCRIPTION (provided by applicant): This application for ""Neurotechnology Research, Development, and Enhancement"" (PA-04-006) proposes the development of innovative technologies, methodologies, and instrumentation to advance our understanding of neural control mechanisms of muscle force production through a non-invasive means of recording neuronal firing patterns. The project will develop an automatic system to accurately and quickly decompose the surface Electromyographic (sEMG) signal into its constituent action potentials and provide the timing of the firings of concurrently active motor units. The goal is to achieve an accuracy of >85% in the automatic mode and >96% with the assistance of an interactive editor. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system by simply placing a sensor above a muscle with no assault to the CNS. The sEMG Decomposition System will replace existing technology that relies on invasive procedures to detect the EMG signal through needle or fine-wire electrodes. The proposed work includes: 1) mathematical modeling and empirical studies to develop a sEMG electrode array that maximizes shape differences of motor unit firings and thereby facilitates sEMG signal decomposition; 2) algorithm development using artificial intelligence technology of our own design combined with Principal Component Analysis techniques; and 3) data acquisition/processing software and hardware to build a portable prototype surface decomposition system. Performance testing of the system will be conducted using data collection experiments to ensure that the system is comparable in motor unit yield, processing speed, and accuracy to the current state-of-the art indwelling decomposition system. We will also prove that the signal decomposition is performed correctly by decomposing two separately collected signals and matching the results. A dissemination plan is included to make this technology available to the Motor Control community. Commercialization will be realized through Altec Inc. This technology will enable researchers in the fields of Motor Control, Aging, Exercise Physiology, Space Medicine, and Ergonomics, where it is of interest to understand how the CNS controls muscles, and how that control is altered as a consequence of aging, exercise, exposure to microgravity, fatigue, and excessive and prolonged force production. It will be useful to clinicians for assessing the degree of dysfunction in upper motoneuron diseases such as Cerebral Palsy, Parkinson's Disease, ALS, Stroke, and other disorders.              n/a",Non-Invasive System for Identifying Neural Behavior,7280742,R01NS058250,"['Action Potentials', 'Age', 'Aging', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Artificial Intelligence', 'Arts', 'Basic Science', 'Behavior', 'Behavioral', 'Businesses', 'Cerebral Palsy', 'Characteristics', 'Clinical', 'Code', 'Communities', 'Computer software', 'Contracts', 'Data Collection', 'Detection', 'Development', 'Disease', 'Electrodes', 'Electromyography', 'Ensure', 'Exercise', 'Exercise Physiology', 'Exposure to', 'Fatigue', 'Feedback', 'Fire - disasters', 'Functional disorder', 'Goals', 'Grant', 'Individual', 'International', 'Invasive', 'Left', 'Marketing', 'Measurement', 'Measures', 'Methodology', 'Microgravity', 'Modeling', 'Motor', 'Motor Neurons', 'Muscle', 'Muscle Contraction', 'Muscle Fibers', 'NIH Program Announcements', 'Needles', 'Neurons', 'Numbers', 'Parkinson Disease', 'Pattern', 'Performance', 'Principal Component Analysis', 'Principal Investigator', 'Procedures', 'Process', 'Production', 'Publishing', 'Purpose', 'Range', 'Rate', 'Reliance', 'Research', 'Research Personnel', 'Right-On', 'Risk', 'Safety', 'Sensitivity and Specificity', 'Series', 'Shapes', 'Side', 'Signal Transduction', 'Skin', 'Source', 'Space Medicine', 'Specificity', 'Standards of Weights and Measures', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Tongue', 'Training', 'Validation', 'Work', 'assault', 'base', 'commercialization', 'data acquisition', 'design', 'ergonomics', 'experience', 'human subject', 'improved', 'innovative technologies', 'instrumentation', 'interest', 'mathematical model', 'motor control', 'neuromuscular system', 'neuroregulation', 'neurotechnology', 'new technology', 'non-invasive system', 'performance tests', 'processing speed', 'programs', 'prototype', 'relating to nervous system', 'research and development', 'research study', 'response', 'sensor', 'technology development', 'technology/technique']",NINDS,"ALTEC, INC.",R01,2007,441010,0.012086142338816606
"FLUORESCENT SPECKLE MICROSCOPY    DESCRIPTION (provided by applicant): Fluorescent speckle microscopy (FSM) is a technique we initially developed for measuring the movements and sites of polymerization/depolymerization of individual microtubules (MTs) and arrays of actin filaments in motile tissue culture cells and the poleward flux of MTs within spindle fibers during mitosis. Assembly of these polymers from a pool containing a low percentage of fluorescently labeled subunits (about 1% or less) produces a random distribution of fluorophores along the polymer lattice that produces ""fluorescent speckle"" fiduciary marks varying from zero to several fluorophores (5-8) within the diffraction limited resolution of the microscope. The major focus of this application is on the further development of the FSM method for the analysis of MT function in spindle mechanics. In particular, how MT and kinetochore proteins function in spindle assembly, chromosome alignment and accurate chromosome segregation. This requires the development of new FSM microscope technology for the rapid recording of multi-wavelength and 3-D time-lapse images of MT fluorescent speckles relative to fluorescent marks or speckles at kinetochores, poles, MT associated proteins (MAPs), motor proteins and MT ends. A major next step for FSM to become a powerful analytical tool for these systems is the development of new Computer Vision methods for obtaining quantitative information about polymer movement and turnover in 2-D and 3-D at high resolution relative to the other molecular fluorescent markers in the spindle. To study protein function, we are particularly interested in optimizing FSM for genetic model organisms including budding yeast, for the biochemically accessible Xenopus egg extracts and for siRNA with mammalian tissue cells. Experience gained in the course of these studies will be used to direct and refine hardware and software development.           n/a",FLUORESCENT SPECKLE MICROSCOPY,7163551,R01GM060678,"['3-Dimensional', 'Ablation', 'Address', 'Algorithms', 'Animal Model', 'Biochemical', 'Biological', 'Biological Assay', 'Cells', 'Centromere', 'Chromatin', 'Chromosome Segregation', 'Chromosomes', 'Computer Vision Systems', 'Computer software', 'Coupling', 'Data', 'Dependence', 'Detection', 'Development', 'Fiber', 'Fluorescence', 'Genetic', 'Genetic Screening', 'Goals', 'Image', 'Imagery', 'In Situ', 'In Vitro', 'Individual', 'Kinetics', 'Kinetochores', 'Label', 'Lasers', 'Maps', 'Measurement', 'Measures', 'Mechanics', 'Methods', 'Microfilaments', 'Microscope', 'Microscopy', 'Microtubule Proteins', 'Microtubule-Associated Proteins', 'Microtubules', 'Mitosis', 'Modeling', 'Molecular', 'Motor', 'Movement', 'Organism', 'Pattern', 'Plus End of the Microtubule', 'Polymers', 'Process', 'Proteins', 'Relative (related person)', 'Resistance', 'Resolution', 'Role', 'Running', 'Saccharomycetales', 'Site', 'Small Interfering RNA', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Tubulin', 'Writing', 'Xenopus', 'analytical tool', 'cell type', 'charge coupled device camera', 'depolymerization', 'egg', 'experience', 'fluorophore', 'in vitro Assay', 'interest', 'numb protein', 'polymerization', 'programs', 'protein function', 'quantum', 'software development', 'tissue/cell culture']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2007,475153,0.02199694401723183
"A Cell Phone-Based Street Intersection Analyzer for Visually Impared Pedestrians    DESCRIPTION (provided by applicant): Urban intersections are the most dangerous parts of a blind person's travel. They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult. To alleviate this problem, we propose to develop and evaluate a cell phone-based system to analyze images of street intersections, taken by a blind or visually impaired person using a standard camera cell phone, to provide real-time feedback. Drawing on our recent work on computer vision algorithms that help a blind person find crosswalks and other important features in a street intersection, as well as our ongoing work on cell phone implementations of algorithms for indoor wayfinding and for reading digital appliance displays, we will refine these algorithms and implement them on a cell phone. The information extracted by the algorithms will be communicated to the user with a combination of synthesized speech, audio tones and/or tactile feedback (using the cell phone's built-in vibrator). Human factors studies will help determine how to configure the system and its user controls for maximum effectiveness and ease of use, and provide an evaluation of the overall system. The street intersection analysis software will be made freely available for download into any camera-equipped cell phone that uses the widespread Symbian operating system (such as the popular Nokia cell phone series). The cell phone will not need any hardware modifications or add-ons to run this software. Ultimately a user will be able to download an entire suite of such algorithms for free onto the cell phone he or she is already likely to be carrying, without having to carry a separate piece of equipment for each function. Relevance: The ability to walk safely and confidently along sidewalks and traverse crosswalks is taken for granted every day by the sighted, but approximately 10 million Americans with significant vision impairments and a million who are legally blind face severe difficulties in this task. The proposed research would result in a highly accessible system (with zero or minimal cost to users) to augment existing wayfinding techniques, which could dramatically improve independent travel for blind and visually impaired persons.           n/a",A Cell Phone-Based Street Intersection Analyzer for Visually Impared Pedestrians,7298706,R01EY018345,"['Accidents', 'Address', 'Algorithms', 'American', 'Cellular Phone', 'Complex', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Detection', 'Devices', 'Effectiveness', 'Equipment', 'Evaluation', 'Face', 'Feedback', 'Figs - dietary', 'Grant', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Left', 'Light', 'Mainstreaming', 'Marketing', 'Modification', 'Operating System', 'Pattern', 'Performance', 'Reading', 'Research', 'Research Infrastructure', 'Resolution', 'Running', 'Self-Help Devices', 'Series', 'Signal Transduction', 'Speech', 'Standards of Weights and Measures', 'System', 'Tactile', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Training', 'Travel', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'Zebra', 'base', 'blind', 'consumer product', 'cost', 'day', 'digital', 'experience', 'image processing', 'improved', 'legally blind', 'novel', 'prevent', 'programs', 'skills', 'tool', 'trafficking', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2007,338243,0.023972715321965096
"Wayfinding for the blind & visually impaired using passive environmental labels    DESCRIPTION (provided by applicant): The objective of this proposal is to tackle the problem of way finding (finding one's way in an environment), faced by blind and severely visually impaired persons who are unable to find or read signs, landmarks and locations. We propose a novel and very inexpensive environmental labeling system to provide this population with access to information needed for indoor way finding (where GPS is not available). The system uses simple passive landmark symbols printed on paper or other material, placed next to text, Braille signs or barcode at locations of interest (offices, bathrooms, etc.) in an environment such as an office building. These printed patterns contain spatial and semantic information that is detected using computer vision algorithms running on a standard camera cell phone. By scanning the environment with the device, which detects all landmark symbols in its line of sight up to distances of 10 meters, the user can determine his or her approximate location in the environment as well as the information encoded near each landmark symbol. The system extracts this information in real-time and communicates it to the user by sound, synthesized speech and/or tactile feedback. This information includes spatial (e.g. audio tones to indicate the presence and direction of a label in the camera's field of view) and semantic information (""Mr. Johnson's office, room 429, at 11 o'clock""). The research proposed here will produce a prototype system that will be tested by blind and low vision subjects. Our team includes a blind expert on psychoacoustics (and other in-house blind staff) and an expert consultant on low-vision way finding and navigation to help optimize the user interface and guide development into a practical, easy-to-use system.              n/a",Wayfinding for the blind & visually impaired using passive environmental labels,7295688,R21EY017003,"['Access to Information', 'Address', 'Algorithms', 'Auditory', 'Bar Codes', 'Canes', 'Canis familiaris', 'Cellular Phone', 'Clutterings', 'Cognitive', 'Color', 'Complement component C1s', 'Computer Vision Systems', 'Computer software', 'Condition', 'Consultations', 'Databases', 'Detection', 'Development', 'Devices', 'Education', 'Elderly', 'Employment', 'Environment', 'Exhibits', 'Feedback', 'Future', 'Goals', 'Home environment', 'Housing', 'Image', 'Individual', 'Instruction', 'Label', 'Localized', 'Location', 'Modality', 'Museums', 'Paper', 'Pattern', 'Persons', 'Population', 'Printing', 'Psychoacoustics', 'Quality of life', 'Range', 'Rate', 'Reading', 'Research', 'Running', 'Scanning', 'Semantics', 'Shapes', 'Source', 'Speech', 'Standards of Weights and Measures', 'Stress', 'System', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'age group', 'base', 'blind', 'braille', 'concept', 'cost', 'design', 'interest', 'legally blind', 'meter', 'novel', 'optical character recognition', 'programs', 'prototype', 'research study', 'size', 'skills', 'sound', 'success', 'symposium', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2007,193398,0.02015551852924598
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to build and test a ""Smart Telescope,"" a device for persons with low vision that uses computer vision algorithms to search for, detect and enhance targets such as text and faces to aid in everyday tasks such as travel, navigation and social interactions. The practical, cosmetically acceptable packaging will consist of a miniature camera and visual display discreetly mounted on spectacles or a hat, and a compact computing device and set of controls that fit into a pocket. The Smart Telescope advances today's state of the art in assistive devices for low vision by automatically searching for, detecting and enhancing target objects even when they fill only a small portion of the device's field of view, without the user having to point the device directly or accurately at the target as with optical telescopes. The Smart Telescope is small and lightweight, but large enough for the elderly to handle and control; simple to operate and easy to carry, store, recharge, don and remove. Advanced options are hidden during day-to-day use, but easy to access when necessary. In Phase I, we developed and evaluated a working prototype and received enthusiastic feedback from subjects in our target population. In Phase II we propose to prototype a commercially viable consumer version of the Smart Telescope. The Phase II work plan has four tracks: 1) User interaction and interface design, 2) physical design and configuration, 3) software design and development, and 4) hardware design and development. Smith-Kettlewell's Rehabilitation Engineering Research Center (RERC) will provide expertise for the human factors portions of the project. Blindsight will design and build the device hardware from off-the-shelf components with the help of Bolton Engineering. Low vision experts Drs. Don Fletcher, Melissa Chun and Ian Bailey will work with the RERC to guarantee a practical product for the target audience. The overall aim is to create a commercial version of the proposed device for persons with reduced visual acuity, reduced contrast sensitivity, or other loss of visual function caused by macular degeneration, diabetic retinopathy, glaucoma, cataracts, and other eye problems, increasing mobility and independence for those with acuity between approximately 20/200 and 20/600. At under $1,000, the total market for such a device is estimated at up to 300,000, i.e., 10% of low vision persons in the United States. The commercial version of the Smart Telescope will significantly increase mobility and independence for persons with visual acuity between approximately 20/200 and 20/600, aiding them in everyday tasks such as travel, navigation, and social interactions. It will advance today's state of the art in assistive devices for low vision by improving on and surpassing the capabilities of the traditional optical telescope, greatly benefiting persons with reduced visual acuity, reduced contrast sensitivity, or other loss of visual function caused by macular degeneration, diabetic retinopathy, glaucoma, cataracts, and other eye problems.          n/a",A Smart Telescope for Low Vision,7327116,R44EY014487,"['Algorithms', 'Arts', 'Back', 'Cataract', 'Clutterings', 'Computer Vision Systems', 'Contrast Sensitivity', 'Development', 'Devices', 'Diabetic Retinopathy', 'Elderly', 'Engineering', 'Eye', 'Eyeglasses', 'Face', 'Feedback', 'Glaucoma', 'Human', 'Lighting', 'Location', 'Macular degeneration', 'Marketing', 'Melissa', 'Motion', 'Optics', 'Peripheral', 'Persons', 'Phase', 'Reading', 'Research', 'Self-Help Devices', 'Social Interaction', 'Software Design', 'Target Populations', 'Testing', 'Text', 'Today', 'Travel', 'United States', 'Vision', 'Visual', 'Visual Acuity', 'Visual impairment', 'Work', 'day', 'design', 'improved', 'low vision telescope', 'monocular', 'prototype', 'rehabilitation engineering']",NEI,BLINDSIGHT CORPORATION,R44,2007,448477,-0.009816066301024265
"Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface    DESCRIPTION (provided by applicant):      Over 600,000 Americans have severely impaired motor function from disorders including spinal cord injury, amyotrophic lateral sclerosis, pontine stroke, and cerebral palsy. A brain-machine interface (BMI) could enable locked-in or tetraplegic patients to communicate and interact with their environment. Two crucial decisions in designing a BMI are (1) what type of brain signals to use as inputs to a controller and (2) what methods to use to decode those signals. Most BMIs have used either noninvasive scalp EEG recordings or invasive intracortical recordings of single- or multi-neuron spikes as control inputs. A few have used subdural or intracortical local field potentials (LFPs). However, no group has yet systematically compared these signals in motor cortex for use in BMI applications. This proposal's first goal is to assess the relative performance of spikes and field potentials (both intracortical and epidural) as control inputs for a variety of movement-related outputs. Epidural field potentials (EFPs) are intermediate in invasiveness, signal quality, stability and spatial resolution compared with existing scalp, subdural, and intracortical recordings, and thus represent an unexplored middle ground. This proposal's second goal is to evaluate linear and nonlinear techniques-including several novel to BMI applications-for both decoding data and reducing the inherently large dimensionality of data from multiple neural signals. The primary hypotheses of the proposed project are (1) that spikes will perform better in decoding more complex movement-related outputs, but that field potentials may perform similarly on decoding simpler outputs, and (2) that nonlinear decoders and dimensionality-reduction techniques may provide improved accuracy over linear methods. The specific aims to address these hypotheses are 1) to evaluate single neuron spikes as inputs to decoders of movement- related outputs, 2) to develop a novel epidural multi-electrode recording technique in the macaque monkey, and 3) to evaluate field potential signals as inputs to decoders of movement-related outputs. Aims 1 and 3 will involve application of dimensionality-reduction algorithms (e.g., independent components analysis, Isomap) and decoding algorithms (system identification, neural networks, support vector machines) to both spikes and field potentials. Aim 2 will entail using a computer model and spatial spectral analysis to optimize the epidural electrode array design. This project will provide the first comparison of spikes, LFPs and EFPs as inputs for identical BMI output applications. The supervision of Drs. Lee Miller and W. Zev Rymer, with additional guidance from Drs. Simon Levine, Jonathan Wolpaw and Nicholas Hatsopoulos, will provide the principal investigator with expertise in recording and processing both spikes and field potentials for BMI applications using a variety of state-of-the- art techniques. A comprehensive career development plan including clinical and research mentoring, seminars, and courses, will foster the candidate's transition into an independent physician-scientist.           n/a",Action Potentials vs. Field Potentials as Inputs to a Brain-Machine Interface,7318680,K08NS060223,"['Action Potentials', 'Address', 'Algorithms', 'American', 'Amyotrophic Lateral Sclerosis', 'Arts', 'Benchmarking', 'Biological Neural Networks', 'Brain', 'Cerebral Palsy', 'Cervical spinal cord injury', 'Clinical Research', 'Complex', 'Computer Simulation', 'Count', 'Craniotomy', 'Data', 'Development Plans', 'Discriminant Analysis', 'Disease', 'Disease regression', 'Dura Mater', 'Electrodes', 'Electroencephalography', 'Electromyography', 'Environment', 'Evaluation', 'Figs - dietary', 'Fostering', 'Frequencies', 'Genetic Programming', 'Goals', 'Hand', 'Implant', 'Implanted Electrodes', 'Invasive', 'Knowledge', 'Learning', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Performance', 'Physicians', 'Pontine structure', 'Principal Investigator', 'Procedures', 'Process', 'Quadriplegia', 'Rattus', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Scalp structure', 'Scientist', 'Signal Transduction', 'Source', 'Spinal cord injury', 'Statistical Methods', 'Stroke', 'Sum', 'Supervision', 'System', 'Techniques', 'Time', 'Tissues', 'Training', 'Upper arm', 'Visual', 'brain machine interface', 'career', 'computerized data processing', 'cranium', 'design', 'disability', 'feeding', 'improved', 'in vivo', 'independent component analysis', 'motor control', 'novel', 'programs', 'prototype', 'relating to nervous system', 'research study', 'surgical technique development']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,K08,2007,167832,0.009360221344355102
"A Laser-Based Device for Work Site Stability Assessment    DESCRIPTION (provided by applicant): Summary: A laser-based acoustic emission (AE) detection device is proposed for work site structural stability assessment. This new device will take advantage of innovations in laser ultrasonics, artificial intelligence (Al) and advanced acoustic emission technology to provide mine workers with a unique instant, real time stability assessment of immediate rock structures in the working environment, which was not attainable in the past. Nonlinear optical interferometry based on two-wave mixing / photo-induced electromotive force techniques will be used for AE signal detection from rock structures in mine sites. Al criteria will be established by wave pattern recognition to identify unstable areas in mine sites. This research will also result in a unique non-contact monitoring device for acoustic emission/microseismic studies, which will be very useful in many areas of application. The primary objective of the Phase II research is to develop the prototype of the AE detector and test it in real-world mining facilities. The primary objective consists of six specific aims: 1. instrumentation development, 2. pre-field experiment preparation, 3. in-situ data collection, 4. Al criteria development, 5. system integration and in-situ trial, and 6. documentation and reporting. Relevance to Public Health: The innovation will contribute to a reduction the occupational injuries and fatalities caused by roof falls, sidewall crumples, stope collapses, and slope slides, etc., in the mining industry. The research and development addresses the miner's safety and contributes to ensuring the mineworker's right to ""safe and healthful working conditions"" (Occupational Safety and Health Act of 1970).          n/a",A Laser-Based Device for Work Site Stability Assessment,7278614,R44OH007662,[' '],NIOSH,AAC INTERNATIONAL,R44,2007,363328,0.002852034759626898
"Smart Wheelchair Component System    DESCRIPTION (provided by applicant):  Independent mobility is critical to individuals of any age. While the needs of many individuals with disabilities can be satisfied with power wheelchairs, some members of the disabled community find it difficult or impossible to operate a standard power wheelchair. This population includes, but is not limited to, individuals with low vision, visual field neglect, spasticity, tremors, or cognitive deficits. The goal of this project is to develop a set of components that can be added to standard power wheelchairs to convert them into ""smart"" wheelchairs which can assist the user in navigation and obstacle avoidance. During Phase I, a prototype of the Smart Wheelchair Component System (SWCS) was developed from a laptop computer and a collection of sonar, infrared and bump sensors. The evaluation activities performed during Phase I demonstrated that the system is compatible with multiple brands of wheelchairs, can accept both continuous and switch-based input, and can support front-, mid-, and rear-wheel drive wheelchairs. During Phase II, we propose to refine the system hardware and software; replace the laptop computer with an embedded microprocessor; fabricate enclosures for the system components; and develop tools to support clinicians in installing and configuring the system. The system will be evaluated in tests involving potential users, clinicians, and wheelchair design standards. The final product will be a market-ready modular system which can be attached to a variety of standard power wheelchairs. This product has the potential to increase the independence and quality of life of many wheelchair users and potential wheelchair users whose disabilities limit their capacity for independent wheelchair navigation.       n/a",Smart Wheelchair Component System,7237214,R44HD040023,"['Adult', 'Age', 'Child', 'Client', 'Cognitive deficits', 'Collection', 'Communities', 'Compatible', 'Computer Vision Systems', 'Computer software', 'Computers', 'Condition', 'Destinations', 'Development', 'Disabled Persons', 'Disadvantaged', 'Documentation', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Individual', 'Joystick', 'Laboratories', 'Learning', 'Location', 'Locomotion', 'Manufacturer Name', 'Marketing', 'Methods', 'Microprocessor', 'Numbers', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Powered wheelchair', 'Production', 'Quality of life', 'Range', 'Relative (related person)', 'Research Personnel', 'Robot', 'Self Perception', 'Standards of Weights and Measures', 'System', 'Technology', 'Testing', 'Touch sensation', 'Travel', 'Tremor', 'Visual Fields', 'Visual impairment', 'Wheelchairs', 'Work', 'base', 'data acquisition', 'design', 'disability', 'laptop', 'member', 'neglect', 'peer', 'prototype', 'sensor', 'sonar', 'tool']",NICHD,AT SCIENCES,R44,2007,387828,0.0033561747151491157
"Indoor Magnetic Wayfinding For The Visually Impaired    DESCRIPTION (provided by applicant): Advanced Medical Electronics (AME) proposes the development of an indoor way-finding device utilizing the unique magnetic anomaly patterns that exist in modern, man-made structures. The proposed system will record the magnitude of magnetic field strength from sensors in three orthogonal axes. The time history of these magnetic data points can be continuously compared with an electronic map of magnetic anomalies (or, ""signature"") to determine current position within a building. The phase I developed prototype system tracked in feasibility experiments with an accuracy of 1 foot (radius). Magnetic anomalies render a magnetic compass useless for finding a directional bearing. However, these same invisible anomalies represent valuable, unique indoor terrain features measurable by magnetic sensors located inside a small, portable device. Such a device would be able to provide low-vision users with a valuable indoor low-cost way-finding tool analogous to a Global Positioning System (GPS) device used outdoors. About 3.7 million Americans are visually disabled. Of these, 200,000 are blind, and the rest have low vision. The key advantage of the way-finding concept presented in this proposal, over other methods, is that the benefits are made available to the visually impaired community without requiring expensive building infrastructure investments. This is of particular advantage to large government buildings and educational campuses. The proposed approach allows a cost effective solution to way-finding within these buildings.          n/a",Indoor Magnetic Wayfinding For The Visually Impaired,7326673,R44EY015616,"['American', 'Appointment', 'Building Codes', 'Cognition', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Development', 'Devices', 'Disabled Persons', 'Doctor of Philosophy', 'Education', 'Electronics', 'Engineering', 'Fee-for-Service Plans', 'Funding', 'Government', 'Hand', 'Housing', 'Human', 'Indoor Magnetic Wayfinding', 'Investments', 'Joints', 'Label', 'Location', 'Magnetism', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Medical Electronics', 'Minnesota', 'Modeling', 'Modification', 'Neurosciences', 'Numbers', 'Oceans', 'Pattern', 'Pattern Recognition', 'Pennsylvania', 'Persons', 'Phase', 'Population', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychology', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Rest', 'Services', 'Silicon Dioxide', 'Solutions', 'Somatotype', 'Speech', 'Steel', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Today', 'Universities', 'Vision', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Wireless Technology', 'World Health Organization', 'base', 'blind', 'college', 'computer science', 'concept', 'cost', 'cost effective', 'court', 'design', 'digital', 'foot', 'human subject', 'innovation', 'interest', 'magnetic field', 'miniaturize', 'motor control', 'performance tests', 'professor', 'prototype', 'radius bone structure', 'research study', 'sensor', 'sensory integration', 'tool', 'way finding']",NEI,ADVANCED MEDICAL ELECTRONICS CORPORATION,R44,2007,386674,0.014096713117205197
"CRCNS: Where to look next? Modeling eye movements in normal and impaired vision    DESCRIPTION (provided by applicant): The goal of this proposal is to gain a better understanding of the information processing and decision strategies that underlie eye movement planning in both the normal and diseased state. In patients with age-related macular degeneration (AMD), central areas of the retina are damaged, creating a large blind spot that forces them to rely solely on residual vision in the periphery. Rehabilitation outcomes for these patients can be successful, but are often inconsistent. Despite similar retinopathies, some patients learn to use their residual vision more effectively than others. We have developed an information-theoretic model and experimental paradigm which will allow us to objectively measure human scanning efficiency. The development of the model has naturally motivated fundamental experimental questions about eye movements and neural decision making. The answers to these questions will be used to refine the model and enhance our understanding of the system in general. We will then apply the model framework to investigate differences in eye movement behavior between AMD patients and normally-sighted individuals. The interplay of model development and experimental investigation will significantly increase our knowledge of how humans use prior knowledge and task demands to direct their gaze, and how new visual information is incorporated into an eye movement plan. The results will have broad relevance to understanding neural decision making in general.   Relevance to Public Health. The application of the model to a clinical population will bring much-needed objective measures to understanding the extent of impairment in individuals with AMD. With this understanding comes great potential for improving rehabilitation training strategies that will enhance the quality of life for these patients and their families.          n/a",CRCNS: Where to look next? Modeling eye movements in normal and impaired vision,7271209,R01EY018004,"['Age related macular degeneration', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'California', 'Clinic', 'Clinical', 'Computer Simulation', 'Computer Vision Systems', 'Computer information processing', 'Condition', 'Decision Making', 'Doctor of Philosophy', 'Ensure', 'Experimental Models', 'Eye Movements', 'Family', 'Goals', 'Human', 'Impairment', 'Individual', 'Information Theory', 'Investigation', 'Knowledge', 'Learning', 'Measures', 'Medical center', 'Modeling', 'Movement', 'Ophthalmologist', 'Outcome', 'Patients', 'Pattern', 'Population', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Psychophysics', 'Psychophysiology', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Retina', 'Retinal', 'Retinal Diseases', 'Retinal blind spot', 'Saccades', 'Scanning', 'Signal Detection Analysis', 'Statistical Models', 'System', 'Techniques', 'Training', 'Training Programs', 'Update', 'Vision', 'Visual', 'Visual impairment', 'Work', 'behavior prediction', 'design', 'disease characteristic', 'experience', 'gaze', 'image processing', 'improved', 'model development', 'predictive modeling', 'relating to nervous system', 'research study', 'sample fixation', 'success', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2007,240641,-0.004248364061798455
"A Laser-Based Device for Work Site Stability Assessment    DESCRIPTION (provided by applicant): Summary: A laser-based acoustic emission (AE) detection device is proposed for work site structural stability assessment. This new device will take advantage of innovations in laser ultrasonics, artificial intelligence (Al) and advanced acoustic emission technology to provide mine workers with a unique instant, real time stability assessment of immediate rock structures in the working environment, which was not attainable in the past. Nonlinear optical interferometry based on two-wave mixing / photo-induced electromotive force techniques will be used for AE signal detection from rock structures in mine sites. Al criteria will be established by wave pattern recognition to identify unstable areas in mine sites. This research will also result in a unique non-contact monitoring device for acoustic emission/microseismic studies, which will be very useful in many areas of application. The primary objective of the Phase II research is to develop the prototype of the AE detector and test it in real-world mining facilities. The primary objective consists of six specific aims: 1. instrumentation development, 2. pre-field experiment preparation, 3. in-situ data collection, 4. Al criteria development, 5. system integration and in-situ trial, and 6. documentation and reporting. Relevance to Public Health: The innovation will contribute to a reduction the occupational injuries and fatalities caused by roof falls, sidewall crumples, stope collapses, and slope slides, etc., in the mining industry. The research and development addresses the miner's safety and contributes to ensuring the mineworker's right to ""safe and healthful working conditions"" (Occupational Safety and Health Act of 1970).          n/a",A Laser-Based Device for Work Site Stability Assessment,7109905,R44OH007662,"['artificial intelligence', 'bioengineering /biomedical engineering', 'data collection methodology /evaluation', 'human mortality', 'injury prevention', 'interferometry', 'lasers', 'mechanical stress', 'minings', 'monitoring device', 'occupational hazard', 'occupational health /safety', 'sound perception', 'technology /technique development', 'ultrasonography', 'work site']",NIOSH,AAC INTERNATIONAL,R44,2006,386471,0.002852034759626898
"INTELLIGENT CONTROL OF UPPER EXTREMITY NEURAL PROSTHESES INTELLIGENT CONTROL OF UPPER EXTREMITY NEURAL PROSTHESES   A common feature of spinal cord injury (SCI) and neurological movement disorders is that the peripheral neuromuscular system remains intact. Functional Electrical Stimulation (FES) offers the potential to restore movement in these individuals. Impressive improvements in electrode and sensor hardware have recently been made, but development of control algorithms for complex dynamic movements remains difficult.      Reinforcement learning (RL) is a technique from artificial intelligence that has the potential to overcome this problem. A RL-based control system learns from experience how to control movement, in very much the same way as an infant. The system receives information from multiple sensors, as well as a reward signal, and generates actions, i.e. muscle stiimulation levels, that are initially random. The system will learn to predict the consequences of its actions and will ultimately converge to a control strategy that maximizes the sum of rewards over time. An essential feature of RL is that the control strategy is not created by the designer, but is learned from experience. This learning process could ultimately result in motor behavior of much higher quality than can be achieved with traditionally designed feedback control systems, which tend to ""fight"" rather than exploit the natural dynamics of the body such as inertia, pendulum and mass-spring mechanisms. Furthermore, a self learning system has the advantage that it can adapt itself to the user's body mass, muscle strength, as well as variations in electrode location.      The long-term goal is a system that integrates high-level commands from the user with signals from implanted sensors to produce intelligent and adaptive motor function. Feasibility of this concept will be tested here for FES control of six muscles in the upper extremity, to perform the task of reaching in the horizontal plane. The following specific aims are proposed: (1) Implementation of RL control on a virtual arm with computer-generated commands and rewards, (2) RL control on a virtual arm, with commands and rewards given by a human operator, and (3) RL control of muscles in a paralyzed arm in two subjects with high cervical spinal cord injury, with commands and rewards given by the user via a head tracker based input device. n/a",INTELLIGENT CONTROL OF UPPER EXTREMITY NEURAL PROSTHESES,7085349,R21HD049662,"['artificial intelligence', 'clinical research', 'computer simulation', 'electrodes', 'electrostimulus', 'human subject', 'limb movement', 'nervous system prosthesis', 'neuromuscular disorder', 'neuromuscular stimulator', 'neuroregulation', 'spinal cord injury']",NICHD,CLEVELAND CLINIC LERNER COL/MED-CWRU,R21,2006,192359,0.03691821497177994
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,7004518,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2006,457462,0.0420541966012442
"Home Sensor Date Fusion to Support Aging in Place    DESCRIPTION (provided by applicant): The aging of the U.S. population presents many challenges. The existing paradigm of care will not allocate resources efficiently as the size of the population requiring home care assistance grows. Our objective is to enhance elder independence by providing both better and more timely predictive health-status assessments and direct, real-time, recommendations and warnings. These together will lower the risk of elders remaining at home or in low intensity care settings. The objective of the Phase II research and development effort is to develop technology that can detect and track activities in the home environment and to demonstrate its usefulness in allowing elders to remain in their homes longer than is now possible. CleverSet will develop and deploy a prototype CleverSet Activity Tracker, CAT, that processes data from a robust set of simple sensors to (1) track the activities of daily living over time (2) modify these tracked activities to include uncertainty about the environment and risk to produce notifications of Events Requiring Intervention (ERIs); and (3) demonstrate the results of the models. The technological innovation of the proposed work is the application of dynamic relational Bayesian networks (DRBNs) to activities in the home environment. CleverSet's DRBN algorithms collectively referred to as CleverSet Modeler, exploit the data model and meta-data from the schema to guide and frame relational queries about behavior and events. In the proposed work, DRBNs will be used to represent complex, dynamic, multi-scale processes involving multiple actors, as probability distributions over the elements, queries, and relationships in the DRBN model. Activities of daily living (ADLs) will be identified using DRBN machine learning algorithms from sensor data and tracked through time. Short-term rhythms of daily life as well as longer-term transitions will be tracked. Risk modifiers relevant to elders will be integrated into the model and used to adapt the sensor data input. Sensor studies will also be performed to determine the relative contribution of sensors to the DRBN ADL models. A software prototype integrating the elements of the Phase II effort will be developed.         n/a",Home Sensor Date Fusion to Support Aging in Place,7051911,R44AG024687,"['aging', 'artificial intelligence', 'assistive device /technology', 'behavioral /social science research tag', 'caregivers', 'clinical research', 'computer program /software', 'confidentiality', 'frail elderly', 'functional ability', 'home health care', 'human subject', 'injury prevention', 'mathematical model', 'medical rehabilitation related tag', 'microprocessor /microchip', 'monitoring device', 'outpatient care', 'quality of life', 'safety equipment', 'self care', 'technology /technique development']",NIA,"CLEVERSET, INC.",R44,2006,361154,-0.000798256670686637
"Wayfinding for the blind & visually impaired using passive environmental labels    DESCRIPTION (provided by applicant): The objective of this proposal is to tackle the problem of way finding (finding one's way in an environment), faced by blind and severely visually impaired persons who are unable to find or read signs, landmarks and locations. We propose a novel and very inexpensive environmental labeling system to provide this population with access to information needed for indoor way finding (where GPS is not available). The system uses simple passive landmark symbols printed on paper or other material, placed next to text, Braille signs or barcode at locations of interest (offices, bathrooms, etc.) in an environment such as an office building. These printed patterns contain spatial and semantic information that is detected using computer vision algorithms running on a standard camera cell phone. By scanning the environment with the device, which detects all landmark symbols in its line of sight up to distances of 10 meters, the user can determine his or her approximate location in the environment as well as the information encoded near each landmark symbol. The system extracts this information in real-time and communicates it to the user by sound, synthesized speech and/or tactile feedback. This information includes spatial (e.g. audio tones to indicate the presence and direction of a label in the camera's field of view) and semantic information (""Mr. Johnson's office, room 429, at 11 o'clock""). The research proposed here will produce a prototype system that will be tested by blind and low vision subjects. Our team includes a blind expert on psychoacoustics (and other in-house blind staff) and an expert consultant on low-vision way finding and navigation to help optimize the user interface and guide development into a practical, easy-to-use system.              n/a",Wayfinding for the blind & visually impaired using passive environmental labels,7143942,R21EY017003,"['clinical research', 'computers', 'reading', 'semantics', 'touch', 'vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2006,224601,0.02015551852924598
"Traffic Intersection Analysis Algorithms for the Blind DESCRIPTION (provided by applicant): This project aims to explore, develop and test computer vision algorithms to analyze images of street intersections from a camera worn by a blind person.  Urban intersections are the most dangerous parts of a blind person's travel.  They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult.  We will explore computer vision algorithms to help a blind person find the crosswalk, find the pedestrian signal button, determine when the ""walk"" light is on, and alert him/her to any veering out of the crosswalk.  We will emphasize the development of completely novel methods of analyzing non-ideal images including shadows, occlusions and other irregularities using spatial grouping techniques based on Bayesian inference.  The resulting algorithms are intended for eventual integration as modules for a computer vision system we are already developing to help blind persons with travel tasks such as finding and reading aloud printed signs and negotiating street crossings.  The combined system would have potential for a radical advance in independent travel for blind persons.  In this exploratory project, we aim to: (1) Explore and test alternative approaches to algorithm design to process intersection images and extract the information about the crosswalk, crossing signal, etc., using a database of real-world images taken by blind persons at a variety of different kinds of intersections.  (2) Test the algorithms using a portable camera connected to a notebook computer with speech output. n/a",Traffic Intersection Analysis Algorithms for the Blind,7096566,R21EY015187,"['blind aid', 'blindness', 'clinical research', 'computer simulation', 'computer system design /evaluation', 'gait', 'human subject', 'injury prevention', 'mathematical model', 'statistics /biometry', 'transportation /recreation safety', 'urban area']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2006,214738,0.023414445024787855
"Wearable-Sensor System for Monitoring Motor Function    DESCRIPTION (provided by applicant): We propose to develop a wearable Personal Status Monitor for improving the medication management of Parkinson's Disease patients by monitoring the effects of the medication continuously during the day. New outcome measures are needed to supplement the self-reports currently in use that are ineffective in managing the complex and unpredictable nature of movement disorders in this population. The device we propose to develop can be worn unobtrusively by patients in their home to automatically provide the following clinically significant information: 1) the presence and severity of specific primary and secondary movement disorders associated with the disease, 2) the status of  On-Off motor fluctuation in response to anti-Parkinson's medication, and 3) the mobility status of the patient. The patient will be monitored by specially designed electromyographic (EMG) and accelerometric (ACC) body-worn sensors. Their signals will be analyzed by a novel Artificial Intelligence knowledge-based signal processing method developed by our group specifically for this purpose. Success of the system will be based on classification accuracy compared to observation by experts. The proposal is composed of two projects. The first and dominant project will develop the underlying technological requirements for the PSM system's application to Parkinson's disease. The aims will include acquisition hardware development in the form of hybrid EMG/ACC sensors. However, the emphasis will be on the development of the knowledge-based algorithms and their software implementation. The second project is designed to acquire the knowledge base needed in Project 1 through data collection experiments from control subjects and patients with Parkinson's disease. The experiments are designed to advance the algorithm development in a hierarchical manner starting from highly standardized activities to free-form activities which approximate real-world conditions. The development of the system will be constructed so that future versions can be adapted to other movement disorders. The successful development of this technology will be transferred for commercial development with the financial assistance of the Massachusetts Community Technology Foundation.         n/a",Wearable-Sensor System for Monitoring Motor Function,7010950,R01EB007163,"['Parkinson&apos', 's disease', 'clinical research', 'fingers', 'gait', 'limbs']",NIBIB,BOSTON UNIVERSITY,R01,2006,619987,0.042841374281923326
"Non-Invasive System for Identifying Neural Behavior    DESCRIPTION (provided by applicant): This application for ""Neurotechnology Research, Development, and Enhancement"" (PA-04-006) proposes the development of innovative technologies, methodologies, and instrumentation to advance our understanding of neural control mechanisms of muscle force production through a non-invasive means of recording neuronal firing patterns. The project will develop an automatic system to accurately and quickly decompose the surface Electromyographic (sEMG) signal into its constituent action potentials and provide the timing of the firings of concurrently active motor units. The goal is to achieve an accuracy of >85% in the automatic mode and >96% with the assistance of an interactive editor. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system by simply placing a sensor above a muscle with no assault to the CNS. The sEMG Decomposition System will replace existing technology that relies on invasive procedures to detect the EMG signal through needle or fine-wire electrodes. The proposed work includes: 1) mathematical modeling and empirical studies to develop a sEMG electrode array that maximizes shape differences of motor unit firings and thereby facilitates sEMG signal decomposition; 2) algorithm development using artificial intelligence technology of our own design combined with Principal Component Analysis techniques; and 3) data acquisition/processing software and hardware to build a portable prototype surface decomposition system. Performance testing of the system will be conducted using data collection experiments to ensure that the system is comparable in motor unit yield, processing speed, and accuracy to the current state-of-the art indwelling decomposition system. We will also prove that the signal decomposition is performed correctly by decomposing two separately collected signals and matching the results. A dissemination plan is included to make this technology available to the Motor Control community. Commercialization will be realized through Altec Inc. This technology will enable researchers in the fields of Motor Control, Aging, Exercise Physiology, Space Medicine, and Ergonomics, where it is of interest to understand how the CNS controls muscles, and how that control is altered as a consequence of aging, exercise, exposure to microgravity, fatigue, and excessive and prolonged force production. It will be useful to clinicians for assessing the degree of dysfunction in upper motoneuron diseases such as Cerebral Palsy, Parkinson's Disease, ALS, Stroke, and other disorders.              n/a",Non-Invasive System for Identifying Neural Behavior,7132833,R01NS058250,"['action potentials', 'behavior', 'clinical research', 'community', 'electrodes', 'muscle', 'training']",NINDS,"ALTEC, INC.",R01,2006,427941,0.012086142338816606
"Instrument development & fabrication for vision research    DESCRIPTION (provided by applicant):  The objective of this proposal is to enhance the research capabilities and collaborative efforts of the vision researchers at the Columbia University Medical Center.  State-of-the-art vision research often requires the custom fabrication of mechanical instruments to support the research. Support is requested for a single module to renovate and support the machine shop in the Harkness Eye Institute at Columbia University, to be shared primarily between the Department of Ophthalmology and the Mahoney Center for Brain and Behavior.  The module will have 10 users, 7 of whom have NEI-funded RO1 grants, and 3 of whom perform research in the area of visual systems neuroscience on grants funded by the NIMH. All of the investigators are also mentors on an NEI-funded training grant. The current systems projects include studies of the neurophysiology   and psychophysics of spatial vision, visual attention, early cortical processing, visual emotional association, and visual motion; the cellular and molecular projects include studies of fluid transport across corneal epithelium, retinal axon guidance, ocular wound healing, and the impact of the lipofuscin fluorophores on retinal pigmented epithelial cell function and viability. All of these projects require the development and fabrication of devices primarily designed for a given project. A great number of these can, when perfected, be shared among a number of projects. Examples of such devices include custom-made nanoliter injection devices, recording chambers, multiple-microdrive platforms, dual recording-iontophoretic devices, illumination devices, and recording gdds. The PI has extensive experience collaborating with machinists, and several of the devices in whose development he participated have been marketed commercially.  Currently the Department of Ophthalmology has a fully-equipped machine shop the machines of which are all fine old Bridgeport and Hardinge manual machines. This proposal is to upgrade the machine shop, with a computer-controlled lathe and a computer-controlled milling machine, and to support the salary of the machinist who was hired in June, 2003, using university startup funds. The availability of an in-house professionally certified machinist will significantly speed the process of design and fabrication of custom instruments.  The use of computer controlled machine tools will facilitate duplication of instruments usable in multiple laboratories.            n/a",Instrument development & fabrication for vision research,7057358,R24EY015634,"['biomedical equipment', 'biomedical resource', 'clinical research', 'computers', 'neurosciences', 'vision']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R24,2006,180672,-0.03038722229308812
"Nanopore study of single antibody-antigen interactions DESCRIPTION:    Nanopore-based single-molecule detection has recently become established as a new tool in single molecule biophysics. Evidence is presented that single antibodies can be observed with a nanopore detector, which presents a wide range of possibilities for immunological research. The hypothesis to be tested is that nanopore-based detection can be used to study single molecule dynamics of antibody-antigen interaction and analyze conformational changes that occur in antibody upon binding to antigen. This application aims to develop the utility of the nanopore-based approach through improvements in both the detection device and the software used to extract information from the channel current signal. At the same time, these studies will allow the Candidate to gain expertise in immunology and the biophysical study of protein structure and function. To study the single molecule dynamics of antibody-antigen interaction, the following three specific aims are proposed:   1. Extend nanopore based detection to nanopore/antibody based detection.   2. Implement machine learning software for automated nanopore/antibody signal analysis and experimental feedback.   3. Use well-characterized, genetically engineered, antibodies to test the utility of the nanopore device to analyze motion in the antibody molecule.   These studies will expand the utility of nanopore devices to study single molecule protein interactions.   Information gained will lead to a better understanding of the molecular dynamics associated with antigen binding by antibody and the subsequent initiation of effector functions. Since most biological nanopore variants derive from pore-forming toxins, nanopore device enhancements eventually may lead to new methods for antibody and antimicrobial-peptide immunological screening. Antibody-based nanopore devices may also serve as highly sensitive immunosensors. n/a",Nanopore study of single antibody-antigen interactions,7119996,K22LM008794,"['antigen antibody reaction', 'bioinformatics', 'biomedical automation', 'computer program /software', 'computer system design /evaluation', 'intermolecular interaction', 'molecular dynamics', 'nanotechnology', 'pore forming protein', 'protein quantitation /detection']",NLM,CHILDREN'S HOSPITAL (NEW ORLEANS),K22,2006,162000,-0.01712065926620871
"FLUORESCENT SPECKLE MICROSCOPY    DESCRIPTION (provided by applicant): Fluorescent speckle microscopy (FSM) is a technique we initially developed for measuring the movements and sites of polymerization/depolymerization of individual microtubules (MTs) and arrays of actin filaments in motile tissue culture cells and the poleward flux of MTs within spindle fibers during mitosis. Assembly of these polymers from a pool containing a low percentage of fluorescently labeled subunits (about 1% or less) produces a random distribution of fluorophores along the polymer lattice that produces ""fluorescent speckle"" fiduciary marks varying from zero to several fluorophores (5-8) within the diffraction limited resolution of the microscope. The major focus of this application is on the further development of the FSM method for the analysis of MT function in spindle mechanics. In particular, how MT and kinetochore proteins function in spindle assembly, chromosome alignment and accurate chromosome segregation. This requires the development of new FSM microscope technology for the rapid recording of multi-wavelength and 3-D time-lapse images of MT fluorescent speckles relative to fluorescent marks or speckles at kinetochores, poles, MT associated proteins (MAPs), motor proteins and MT ends. A major next step for FSM to become a powerful analytical tool for these systems is the development of new Computer Vision methods for obtaining quantitative information about polymer movement and turnover in 2-D and 3-D at high resolution relative to the other molecular fluorescent markers in the spindle. To study protein function, we are particularly interested in optimizing FSM for genetic model organisms including budding yeast, for the biochemically accessible Xenopus egg extracts and for siRNA with mammalian tissue cells. Experience gained in the course of these studies will be used to direct and refine hardware and software development.           n/a",FLUORESCENT SPECKLE MICROSCOPY,7002662,R01GM060678,"['Urodela', 'Xenopus', 'animal tissue', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'centromere', 'computer program /software', 'computer system design /evaluation', 'fluorescence microscopy', 'fluorescent dye /probe', 'image enhancement', 'microtubules', 'mitotic spindle apparatus', 'small interfering RNA', 'technology /technique development', 'three dimensional imaging /topography', 'yeasts']",NIGMS,UNIVERSITY OF NORTH CAROLINA CHAPEL HILL,R01,2006,462742,0.02199694401723183
"Development of a Bidirectional Brain Machine Interface    DESCRIPTION (provided by applicant): Recent technological advances have made it possible to move a robotic device in real time, using signals obtained directly from the brain. This field of Brain Machine Interface (BMI) has the means to provide movement for paralyzed patients, communication for locked-in patients, and a better understanding of the brain for all of society. In order to control movement effectively, the brain must be able to activate muscles appropriately, and monitor the evolving movement quickly and precisely. Existing BMIs for, while remarkable, do each of these tasks in poor imitation of the intact nervous system. Our proposed work addresses these limitations by developing a bidirectional interface that produces movement in a more natural way, and provides feedback about the movement by direct, electrical stimulation of the brain. Our partnership includes members at Northwestern Univ (NU), Univ of Chicago (UC), Univ of Mass, Amherst (UMass), and the autonomous Univ of Mexico (UNAM). Partners have advanced degrees in a range of biological science, computer science, physics, mathematics, and engineering disciplines. Miller (NU) will coordinate the partnership. He has extensive experience with a wide range of recording, stimulation and behavioral protocols in behaving monkeys. Hatsopoulos (UC) is at the forefront of the field of multi-electrode recordings. He was a leading member of the first group to demonstrate visually guided BMI control by a primate. Barto (U Mass) has done pioneering research in neural networks, machine learning and stochastic optimization. Fagg (UMass) is an authority in the control of reaching and grasping robots that learn to interact with the environment. Together they will develop the decoders of activity from the brain used to cause movement. Romo (UNAM), is a world leader in studies of the perceptual and decision making processes induced by electrical stimulation of the brain. Solla (NU) is an expert in neural networks and information theory. With Romo, she will develop optimal routines to encode information in stimulus trains to provide feedback to the brain. Mussa-Ivaldi (NU) will focus on the overall design and evaluation of the interfaces. He created the first ever bidirectional interface between neural tissue and a robotic device.          n/a",Development of a Bidirectional Brain Machine Interface,7056128,R01NS048845,[' '],NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2006,693279,0.04231742503217313
"MobileEye OCR for the Visually Impaired    DESCRIPTION (provided by applicant): In this SBIR we propose to demonstrate the technical feasibility of Mobile OCR, a portable software system which makes use of existing personal devices to provide access to textual materials for the elderly or the visually impaired. The system will help these low vision individuals with basic daily activities, such as shopping, preparing meals, taking medication, and reading traffic signs. It will step beyond our proposed MobileEyes vision enhancement system to apply cutting edge recognition technology for mobile devices. The system will use common camera phone hardware to capture and enhance textual information, perform Optical Character Recognition (OCR) and provide audio or visual feedback. Our research will focus on implementing and integrating new vision enhancement and analysis techniques on limited resource mobile devices. Specifically, we will develop algorithms for detection and rectification of text on planes and generalized cylinders subject to perspective distortions, implement more robust and efficient algorithms and systems for stabilization and enhancement of text blocks, provide mobile OCR on complex textured backgrounds, and implement these techniques on small devices across a variety of platforms. The recognized text will be presented through Text-to-Speech (TTS), or displayed on the device with enhanced quality which can be easily read by low vision users. Phase I will focus on demonstrating the technical feasibility of our approach, and will incorporate a performance measurement methodology to quantitatively evaluate progress and evaluate our system against other approaches. In comparison to existing vision enhancement devices, such as magnifying glasses, telescopes, and text reading devices such as scanner-based OCR, our solution has several advantages: 1) it makes use of a single, portable device (camera cell phone) that is commonly available and typically already carried for its telecommunications capabilities; 2) it can be used selectively by users so they will not be overwhelmed by irrelevant information; and 3) it can be integrated directly with other applications for specialized tasks. Our research results will impact the millions of low-vision individuals and the blind, as well as vision and computer vision researchers. Our team is uniquely qualified to explore the feasibility of extending visual applications to these devices, and provide a platform for integrating future vision algorithms.         n/a",MobileEye OCR for the Visually Impaired,7053650,R43EY017216,"['reading', 'solutions', 'vision']",NEI,"APPLIED MEDIA ANALYSIS, LLC",R43,2006,104935,0.02695040278940472
"Accessible Artificial Intelligence Tutoring Software DESCRIPTION (provided by applicant): Quantum has successfully developed, tested and brought to the classroom the first artificial intelligence (Al) tutoring systems in chemistry education. This work successfully addressed several longstanding, clearly articulated needs for improved interactive educational software. A leading distributor for the U.S. and Canada, Science Kit & Boreal Laboratories, as well as prominent textbook publisher, Holt, Rinehart and Winston, have entered into long-term contracts with Quantum, resulting in rapid dissemination to an established end user base. The aim of this Phase I SBIR proposal is to bring the full power and benefits of this cutting-edge new educational technology to students who are blind and visually impaired. There is a considerable need for improved educational software for science education in general, but the problem of quality educational software materials for the blind is known to be particularly acute. Certain unique attributes of the Quantum Al Tutors make them potentially very well suited for full accessibility to the blind using Internet-capable screen reader technology. The potential technological innovation here is the development of advanced Al tutoring technology that has accessibility built into its framework design. If successful, an immediate outcome will be the first Al tutoring systems that are accessible to blind students, delivered through the Internet. A formulation of an Al tutoring methodology with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. This project can only be accomplished by working intimately with experts in education for the blind, and Quantum has arranged a number of important partnerships in this respect, for research as well as commercialization of the resulting technology, including: the National Federation of the Blind, the American Printing House for the Blind, Pearson Learning Group, Bartimaeus Group and Henter Mathematics. n/a",Accessible Artificial Intelligence Tutoring Software,6880607,R43EY016251,"['Internet', 'artificial intelligence', 'blind aid', 'chemistry', 'computer assisted instruction', 'computer human interaction', 'computer program /software', 'educational resource design /development', 'science education', 'technology /technique development']",NEI,"QUANTUM SIMULATIONS, INC.",R43,2005,100721,0.020828756721638978
"INTELLIGENT CONTROL OF UPPER EXTREMITY NEURAL PROSTHESES INTELLIGENT CONTROL OF UPPER EXTREMITY NEURAL PROSTHESES   A common feature of spinal cord injury (SCI) and neurological movement disorders is that the peripheral neuromuscular system remains intact. Functional Electrical Stimulation (FES) offers the potential to restore movement in these individuals. Impressive improvements in electrode and sensor hardware have recently been made, but development of control algorithms for complex dynamic movements remains difficult.      Reinforcement learning (RL) is a technique from artificial intelligence that has the potential to overcome this problem. A RL-based control system learns from experience how to control movement, in very much the same way as an infant. The system receives information from multiple sensors, as well as a reward signal, and generates actions, i.e. muscle stiimulation levels, that are initially random. The system will learn to predict the consequences of its actions and will ultimately converge to a control strategy that maximizes the sum of rewards over time. An essential feature of RL is that the control strategy is not created by the designer, but is learned from experience. This learning process could ultimately result in motor behavior of much higher quality than can be achieved with traditionally designed feedback control systems, which tend to ""fight"" rather than exploit the natural dynamics of the body such as inertia, pendulum and mass-spring mechanisms. Furthermore, a self learning system has the advantage that it can adapt itself to the user's body mass, muscle strength, as well as variations in electrode location.      The long-term goal is a system that integrates high-level commands from the user with signals from implanted sensors to produce intelligent and adaptive motor function. Feasibility of this concept will be tested here for FES control of six muscles in the upper extremity, to perform the task of reaching in the horizontal plane. The following specific aims are proposed: (1) Implementation of RL control on a virtual arm with computer-generated commands and rewards, (2) RL control on a virtual arm, with commands and rewards given by a human operator, and (3) RL control of muscles in a paralyzed arm in two subjects with high cervical spinal cord injury, with commands and rewards given by the user via a head tracker based input device. n/a",INTELLIGENT CONTROL OF UPPER EXTREMITY NEURAL PROSTHESES,6908435,R21HD049662,"['artificial intelligence', 'clinical research', 'computer simulation', 'electrodes', 'electrostimulus', 'human subject', 'limb movement', 'nervous system prosthesis', 'neuromuscular disorder', 'neuromuscular stimulator', 'neuroregulation', 'spinal cord injury']",NICHD,CLEVELAND CLINIC LERNER COL/MED-CWRU,R21,2005,164156,0.03691821497177994
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6995047,R43EY014487,"['artificial intelligence', 'biomedical equipment development', 'clinical research', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'data collection', 'digital imaging', 'functional ability', 'human subject', 'image processing', 'medical rehabilitation related tag', 'patient oriented research', 'portable biomedical equipment', 'questionnaires', 'vision aid', 'vision disorders', 'visual fields', 'visual perception', 'visual threshold', 'visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2005,144106,-0.0008143055682709141
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,6832762,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2005,461157,0.0420541966012442
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6940629,R01AG018751,"['aging', 'artificial intelligence', 'body movement', 'clinical research', 'computer system design /evaluation', 'hand', 'human old age (65+)', 'human subject', 'psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2005,231673,0.004940155763136587
"Intelligent Adaptive Wireless Reconfigurable EEG    DESCRIPTION (provided by the applicant)  The overall goal of the proposal is to improve ambulatory and long-term EEG monitoring using an innovative wireless EEG system. The specific aim of this proposal is to develop an ambulatory wireless EEG monitoring system with real-time adaptive and re-configuration capabilities, which will allow more clinical data to be transmitted in the same bandwidth and in a small portable package. The proposed device will adapt its data acquisition hardware to the underlying clinical event permitting it to focus its high transmission rates to periods of clinically relevant events. The events will be detected by our powerful seizure monitor algorithm which will have direct control over a flexible and innovative hardware. The result is enhanced wireless EEG in a small package, low power and with data quality comparable to bulkier clinical tethered system. The ability to optimize bandwidth is timely due to new FDA telemetry guidelines, which restricts the availability of frequencies and bandwidths in medical devices. Another advantage to optimizing output is that more meaningful data can be created without excessively large data files, which will speed analysis and review. Finally, the proposed device will be able to dynamically reconfigure itself in real time to compensate for serious data-corrupting events such as when one or several electrodes become loose or detached. In summary, the two major innovations are: 1- Real-time adaptive capability for adjusting the quantity and quality of the acquired and transmitted EEG data to better reflect the underlying clinical event (such as a seizure), 2- more practical and accurate ambulatory monitoring by the real-time automatic reconfiguration of the EEG acquisition system.       In Phase I, we designed, fabricated and tested a prototype system. Bench top and clinical testing showed that the system can indeed modify its output in response to artifacts or changes in EEG morphology. In Phase II, we will complete development including a radio design that meets the new FDA guidelines, and test on long-term patients with epilepsy.               n/a",Intelligent Adaptive Wireless Reconfigurable EEG,6952455,R44NS042999,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'electrodes', 'electroencephalography', 'epilepsy', 'human subject', 'patient monitoring device', 'patient oriented research', 'portable biomedical equipment', 'telemedicine', 'telemetry']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R44,2005,671838,-0.09357209641560944
"Traffic Intersection Analysis Algorithms for the Blind DESCRIPTION (provided by applicant): This project aims to explore, develop and test computer vision algorithms to analyze images of street intersections from a camera worn by a blind person.  Urban intersections are the most dangerous parts of a blind person's travel.  They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult.  We will explore computer vision algorithms to help a blind person find the crosswalk, find the pedestrian signal button, determine when the ""walk"" light is on, and alert him/her to any veering out of the crosswalk.  We will emphasize the development of completely novel methods of analyzing non-ideal images including shadows, occlusions and other irregularities using spatial grouping techniques based on Bayesian inference.  The resulting algorithms are intended for eventual integration as modules for a computer vision system we are already developing to help blind persons with travel tasks such as finding and reading aloud printed signs and negotiating street crossings.  The combined system would have potential for a radical advance in independent travel for blind persons.  In this exploratory project, we aim to: (1) Explore and test alternative approaches to algorithm design to process intersection images and extract the information about the crosswalk, crossing signal, etc., using a database of real-world images taken by blind persons at a variety of different kinds of intersections.  (2) Test the algorithms using a portable camera connected to a notebook computer with speech output. n/a",Traffic Intersection Analysis Algorithms for the Blind,6920594,R21EY015187,"['blind aid', 'blindness', 'clinical research', 'computer simulation', 'computer system design /evaluation', 'gait', 'human subject', 'injury prevention', 'mathematical model', 'statistics /biometry', 'transportation /recreation safety', 'urban area']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2005,255198,0.023414445024787855
"Instrument development & fabrication for vision research    DESCRIPTION (provided by applicant):  The objective of this proposal is to enhance the research capabilities and collaborative efforts of the vision researchers at the Columbia University Medical Center.  State-of-the-art vision research often requires the custom fabrication of mechanical instruments to support the research. Support is requested for a single module to renovate and support the machine shop in the Harkness Eye Institute at Columbia University, to be shared primarily between the Department of Ophthalmology and the Mahoney Center for Brain and Behavior.  The module will have 10 users, 7 of whom have NEI-funded RO1 grants, and 3 of whom perform research in the area of visual systems neuroscience on grants funded by the NIMH. All of the investigators are also mentors on an NEI-funded training grant. The current systems projects include studies of the neurophysiology   and psychophysics of spatial vision, visual attention, early cortical processing, visual emotional association, and visual motion; the cellular and molecular projects include studies of fluid transport across corneal epithelium, retinal axon guidance, ocular wound healing, and the impact of the lipofuscin fluorophores on retinal pigmented epithelial cell function and viability. All of these projects require the development and fabrication of devices primarily designed for a given project. A great number of these can, when perfected, be shared among a number of projects. Examples of such devices include custom-made nanoliter injection devices, recording chambers, multiple-microdrive platforms, dual recording-iontophoretic devices, illumination devices, and recording gdds. The PI has extensive experience collaborating with machinists, and several of the devices in whose development he participated have been marketed commercially.  Currently the Department of Ophthalmology has a fully-equipped machine shop the machines of which are all fine old Bridgeport and Hardinge manual machines. This proposal is to upgrade the machine shop, with a computer-controlled lathe and a computer-controlled milling machine, and to support the salary of the machinist who was hired in June, 2003, using university startup funds. The availability of an in-house professionally certified machinist will significantly speed the process of design and fabrication of custom instruments.  The use of computer controlled machine tools will facilitate duplication of instruments usable in multiple laboratories.            n/a",Instrument development & fabrication for vision research,6891373,R24EY015634,"['biomedical equipment', 'biomedical resource', 'clinical research', 'computers', 'neurosciences', 'vision']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R24,2005,175413,-0.03038722229308812
"Nanopore study of single antibody-antigen interactions DESCRIPTION:    Nanopore-based single-molecule detection has recently become established as a new tool in single molecule biophysics. Evidence is presented that single antibodies can be observed with a nanopore detector, which presents a wide range of possibilities for immunological research. The hypothesis to be tested is that nanopore-based detection can be used to study single molecule dynamics of antibody-antigen interaction and analyze conformational changes that occur in antibody upon binding to antigen. This application aims to develop the utility of the nanopore-based approach through improvements in both the detection device and the software used to extract information from the channel current signal. At the same time, these studies will allow the Candidate to gain expertise in immunology and the biophysical study of protein structure and function. To study the single molecule dynamics of antibody-antigen interaction, the following three specific aims are proposed:   1. Extend nanopore based detection to nanopore/antibody based detection.   2. Implement machine learning software for automated nanopore/antibody signal analysis and experimental feedback.   3. Use well-characterized, genetically engineered, antibodies to test the utility of the nanopore device to analyze motion in the antibody molecule.   These studies will expand the utility of nanopore devices to study single molecule protein interactions.   Information gained will lead to a better understanding of the molecular dynamics associated with antigen binding by antibody and the subsequent initiation of effector functions. Since most biological nanopore variants derive from pore-forming toxins, nanopore device enhancements eventually may lead to new methods for antibody and antimicrobial-peptide immunological screening. Antibody-based nanopore devices may also serve as highly sensitive immunosensors. n/a",Nanopore study of single antibody-antigen interactions,6959048,K22LM008794,"['antigen antibody reaction', 'bioinformatics', 'biomedical automation', 'computer program /software', 'computer system design /evaluation', 'intermolecular interaction', 'molecular dynamics', 'nanotechnology', 'pore forming protein', 'protein quantitation /detection']",NLM,CHILDREN'S HOSPITAL (NEW ORLEANS),K22,2005,162000,-0.01712065926620871
"FLUORESCENT SPECKLE MICROSCOPY    DESCRIPTION (provided by applicant): Fluorescent speckle microscopy (FSM) is a technique we initially developed for measuring the movements and sites of polymerization/depolymerization of individual microtubules (MTs) and arrays of actin filaments in motile tissue culture cells and the poleward flux of MTs within spindle fibers during mitosis. Assembly of these polymers from a pool containing a low percentage of fluorescently labeled subunits (about 1% or less) produces a random distribution of fluorophores along the polymer lattice that produces ""fluorescent speckle"" fiduciary marks varying from zero to several fluorophores (5-8) within the diffraction limited resolution of the microscope. The major focus of this application is on the further development of the FSM method for the analysis of MT function in spindle mechanics. In particular, how MT and kinetochore proteins function in spindle assembly, chromosome alignment and accurate chromosome segregation. This requires the development of new FSM microscope technology for the rapid recording of multi-wavelength and 3-D time-lapse images of MT fluorescent speckles relative to fluorescent marks or speckles at kinetochores, poles, MT associated proteins (MAPs), motor proteins and MT ends. A major next step for FSM to become a powerful analytical tool for these systems is the development of new Computer Vision methods for obtaining quantitative information about polymer movement and turnover in 2-D and 3-D at high resolution relative to the other molecular fluorescent markers in the spindle. To study protein function, we are particularly interested in optimizing FSM for genetic model organisms including budding yeast, for the biochemically accessible Xenopus egg extracts and for siRNA with mammalian tissue cells. Experience gained in the course of these studies will be used to direct and refine hardware and software development.           n/a",FLUORESCENT SPECKLE MICROSCOPY,6846631,R01GM060678,"['Urodela', 'Xenopus', 'animal tissue', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'centromere', 'computer program /software', 'computer system design /evaluation', 'fluorescence microscopy', 'fluorescent dye /probe', 'image enhancement', 'microtubules', 'mitotic spindle apparatus', 'small interfering RNA', 'technology /technique development', 'three dimensional imaging /topography', 'yeasts']",NIGMS,UNIVERSITY OF NORTH CAROLINA CHAPEL HILL,R01,2005,451020,0.02199694401723183
"Development of a Bidirectional Brain Machine Interface    DESCRIPTION (provided by applicant): Recent technological advances have made it possible to move a robotic device in real time, using signals obtained directly from the brain. This field of Brain Machine Interface (BMI) has the means to provide movement for paralyzed patients, communication for locked-in patients, and a better understanding of the brain for all of society. In order to control movement effectively, the brain must be able to activate muscles appropriately, and monitor the evolving movement quickly and precisely. Existing BMIs for, while remarkable, do each of these tasks in poor imitation of the intact nervous system. Our proposed work addresses these limitations by developing a bidirectional interface that produces movement in a more natural way, and provides feedback about the movement by direct, electrical stimulation of the brain. Our partnership includes members at Northwestern Univ (NU), Univ of Chicago (UC), Univ of Mass, Amherst (UMass), and the autonomous Univ of Mexico (UNAM). Partners have advanced degrees in a range of biological science, computer science, physics, mathematics, and engineering disciplines. Miller (NU) will coordinate the partnership. He has extensive experience with a wide range of recording, stimulation and behavioral protocols in behaving monkeys. Hatsopoulos (UC) is at the forefront of the field of multi-electrode recordings. He was a leading member of the first group to demonstrate visually guided BMI control by a primate. Barto (U Mass) has done pioneering research in neural networks, machine learning and stochastic optimization. Fagg (UMass) is an authority in the control of reaching and grasping robots that learn to interact with the environment. Together they will develop the decoders of activity from the brain used to cause movement. Romo (UNAM), is a world leader in studies of the perceptual and decision making processes induced by electrical stimulation of the brain. Solla (NU) is an expert in neural networks and information theory. With Romo, she will develop optimal routines to encode information in stimulus trains to provide feedback to the brain. Mussa-Ivaldi (NU) will focus on the overall design and evaluation of the interfaces. He created the first ever bidirectional interface between neural tissue and a robotic device.          n/a",Development of a Bidirectional Brain Machine Interface,6943266,R01NS048845,[' '],NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2005,768711,0.04231742503217313
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6740904,R24HD038585,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biological signal transduction', 'biomedical automation', 'biomedical equipment development', 'clinical research', 'electromyography', 'evaluation /testing', 'human subject', 'motor neurons', 'neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2004,626002,-0.007211964514205674
"A Laser-Based Device for Work Site Stability Assessment DESCRIPTION (provided by applicant): A laser-based acoustic emission (AE) detection device is proposed (Phase I & II) for work site structural stability assessment in order to reduce the occupational injuries and fatalities caused by roof falls, sidewall crumples, stop collapses, slope slides, etc., in the mining industry. This applied research and development addresses the miner's safety and contributes to ensuring the mineworker's right to ""safe and healthful working conditions"" (Occupational Safety and Health Act of 1970). This new device will take advantage of innovations in laser ultrasonic, artificial intelligence (AI) and conventional acoustic emission technology to provide mine workers with a unique instant, real time stability assessment of immediate rock structures in the working environment, which was not attainable in the past. This research will also result in a unique non-contact monitoring device for acoustic emission/microseismic studies, which will be very useful in many areas of application. The primary objective of the Phase I research is to demonstrate under laboratory conditions the concept of the laser device for stability assessment, and to construct a prototype setup for further development and optimization in the subsequent Phase II research. This primary objective consists of five specific aims: 1. Specimen preparation, 2. Development of laser-based AE monitor, 3. AE data collection and failure criteria development, 4. laboratory demonstration, and 5. final report and Phase II proposal. n/a",A Laser-Based Device for Work Site Stability Assessment,6730974,R43OH007662,"['artificial intelligence', 'bioengineering /biomedical engineering', 'data collection methodology /evaluation', 'human mortality', 'injury prevention', 'interferometry', 'lasers', 'mechanical stress', 'minings', 'monitoring device', 'occupational hazard', 'occupational health /safety', 'sound perception', 'technology /technique development', 'ultrasonography', 'work site']",NIOSH,AAC INTERNATIONAL,R43,2004,99998,0.011088154631014169
"Sign Finder: Computer Vision to Find and Read Signs DESCRIPTION (provided by applicant): We propose to build a device that enhances the mobility of visually impaired persons by finding and reading signs aloud without the need for infrastructure beyond ordinary signs. Using new computer vision techniques, it will detect and read text in images captured by a camera worn like a pendant around the user's neck.      We will build two commercially viable, self-contained consumer versions, a $1,500 device using consumer computers and cameras, and a $750 proprietary device.      In typical use, a wearer will select a mode (city street, supermarket) by pressing buttons and optionally speaking commands, and then either point the device at a scene, or scan the scene using auto-repeat image capture. The device will find and read signs, but only output audio for signs relevant to the mode.      The Phase II work plan has three tracks: 1) Computer vision software development and testing, 2) Human interface design and development, and 3) development and testing of the two forms of the device.       Continuing our collaboration from Phase I, we use Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for human factors. Bolton Engineering will design and build the proprietary device hardware. n/a",Sign Finder: Computer Vision to Find and Read Signs,6739928,R44EY011821,"['assistive device /technology', 'blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer system design /evaluation', 'functional ability', 'human subject', 'medical rehabilitation related tag', 'questionnaires']",NEI,BLINDSIGHT CORPORATION,R44,2004,462571,0.0420541966012442
"Intelligent Electric Stimulator with Sensor Capabilities    DESCRIPTION (provided by applicant):    The ultimate objective of this project is to develop intelligent electrical stimulation devices, which will automatically adjust the stimulator signal based on the conditions prevailing in the tissue, or in the media. This would allow for optimization of a long term treatment, as well as for an on demand treatment, if the conditions in the body suddenly change. Today such a treatment is used in, e.g., on-demand pacemakers. We are looking to extend it to physiological/biochemical processes in the body in addition to stimulation of functions.         n/a",Intelligent Electric Stimulator with Sensor Capabilities,6834042,R43RR021814,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'biosensor device', 'biotechnology', 'electrodes', 'electronic stimulator', 'miniature biomedical equipment']",NCRR,"HERBST RESEARCH, INC.",R43,2004,449282,0.01206237589138521
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6785858,R01AG018751,"['aging', 'artificial intelligence', 'body movement', 'clinical research', 'computer system design /evaluation', 'hand', 'human old age (65+)', 'human subject', 'psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2004,231788,0.004940155763136587
"Physiological Controller for Rotary Blood Pumps DESCRIPTION (provided by applicant):    As the prospects of chronic mechanical assistance for the failing human heart are fast becoming a reality, and patients are indeed returning home to regain a normal lifestyle, the limitations of this technology upon quality of life are becoming more apparent. To address many of these limitations, investigators are developing next-generation ventricular assist devices. Based on turbopump technology, these new devices offer smaller size, greater efficiency (hence smaller batteries), high reliability, and are more cost effective as compared to their pulsatile predecessors. For all the virtues of these new turbopumps, they bring additional challenges. Arguably the most urgent is the need for added ""intelligence."" These relatively ignorant devices are highly dependent on feedback-control to provide normal physiological response. The goal of the Phase- II effort proposed herein is to design a robust controller that may be incorporated into these turbodynamic pump systems for clinical use. The primary end product of this program would be a validated algorithm, in the form of firmware that will be embedded into existing rotary pump controller -- capable of maintaining optimal perfusion of the patient under a variety of hemodynamic demands and disturbances, while avoiding deleterious conditions such as ventricular suction. n/a",Physiological Controller for Rotary Blood Pumps,6803953,R44HL066656,"['artificial intelligence', 'auxiliary heart prosthesis', 'biomedical device power system', 'biomedical equipment development', 'cardiac output', 'circulatory assist', 'computer system design /evaluation', 'cow', 'electrophysiology', 'hemolysis', 'mathematical model', 'microprocessor /microchip', 'sheep']",NHLBI,"LAUNCHPOINT TECHNOLOGIES, INC.",R44,2004,374766,0.013203465895183435
"Intelligent Adaptive Wireless Reconfigurable EEG    DESCRIPTION (provided by the applicant)  The overall goal of the proposal is to improve ambulatory and long-term EEG monitoring using an innovative wireless EEG system. The specific aim of this proposal is to develop an ambulatory wireless EEG monitoring system with real-time adaptive and re-configuration capabilities, which will allow more clinical data to be transmitted in the same bandwidth and in a small portable package. The proposed device will adapt its data acquisition hardware to the underlying clinical event permitting it to focus its high transmission rates to periods of clinically relevant events. The events will be detected by our powerful seizure monitor algorithm which will have direct control over a flexible and innovative hardware. The result is enhanced wireless EEG in a small package, low power and with data quality comparable to bulkier clinical tethered system. The ability to optimize bandwidth is timely due to new FDA telemetry guidelines, which restricts the availability of frequencies and bandwidths in medical devices. Another advantage to optimizing output is that more meaningful data can be created without excessively large data files, which will speed analysis and review. Finally, the proposed device will be able to dynamically reconfigure itself in real time to compensate for serious data-corrupting events such as when one or several electrodes become loose or detached. In summary, the two major innovations are: 1- Real-time adaptive capability for adjusting the quantity and quality of the acquired and transmitted EEG data to better reflect the underlying clinical event (such as a seizure), 2- more practical and accurate ambulatory monitoring by the real-time automatic reconfiguration of the EEG acquisition system.       In Phase I, we designed, fabricated and tested a prototype system. Bench top and clinical testing showed that the system can indeed modify its output in response to artifacts or changes in EEG morphology. In Phase II, we will complete development including a radio design that meets the new FDA guidelines, and test on long-term patients with epilepsy.               n/a",Intelligent Adaptive Wireless Reconfigurable EEG,6888368,R44NS042999,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'electrodes', 'electroencephalography', 'epilepsy', 'human subject', 'patient monitoring device', 'patient oriented research', 'portable biomedical equipment', 'telemedicine', 'telemetry']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R44,2004,416347,-0.09357209641560944
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6801171,R01EY013875,"['blind aid', 'blindness', 'clinical research', 'computer human interaction', 'computer program /software', 'cues', 'human subject', 'reading', 'vision aid', 'vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,329706,0.019452254635642006
"Instrument development & fabrication for vision research    DESCRIPTION (provided by applicant):  The objective of this proposal is to enhance the research capabilities and collaborative efforts of the vision researchers at the Columbia University Medical Center.  State-of-the-art vision research often requires the custom fabrication of mechanical instruments to support the research. Support is requested for a single module to renovate and support the machine shop in the Harkness Eye Institute at Columbia University, to be shared primarily between the Department of Ophthalmology and the Mahoney Center for Brain and Behavior.  The module will have 10 users, 7 of whom have NEI-funded RO1 grants, and 3 of whom perform research in the area of visual systems neuroscience on grants funded by the NIMH. All of the investigators are also mentors on an NEI-funded training grant. The current systems projects include studies of the neurophysiology   and psychophysics of spatial vision, visual attention, early cortical processing, visual emotional association, and visual motion; the cellular and molecular projects include studies of fluid transport across corneal epithelium, retinal axon guidance, ocular wound healing, and the impact of the lipofuscin fluorophores on retinal pigmented epithelial cell function and viability. All of these projects require the development and fabrication of devices primarily designed for a given project. A great number of these can, when perfected, be shared among a number of projects. Examples of such devices include custom-made nanoliter injection devices, recording chambers, multiple-microdrive platforms, dual recording-iontophoretic devices, illumination devices, and recording gdds. The PI has extensive experience collaborating with machinists, and several of the devices in whose development he participated have been marketed commercially.  Currently the Department of Ophthalmology has a fully-equipped machine shop the machines of which are all fine old Bridgeport and Hardinge manual machines. This proposal is to upgrade the machine shop, with a computer-controlled lathe and a computer-controlled milling machine, and to support the salary of the machinist who was hired in June, 2003, using university startup funds. The availability of an in-house professionally certified machinist will significantly speed the process of design and fabrication of custom instruments.  The use of computer controlled machine tools will facilitate duplication of instruments usable in multiple laboratories.            n/a",Instrument development & fabrication for vision research,6795629,R24EY015634,"['biomedical equipment', 'biomedical resource', 'clinical research', 'computers', 'neurosciences', 'vision']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R24,2004,367302,-0.03038722229308812
"FLUORESCENT SPECKLE MICROSCOPY    DESCRIPTION (provided by applicant): Fluorescent speckle microscopy (FSM) is a technique we initially developed for measuring the movements and sites of polymerization/depolymerization of individual microtubules (MTs) and arrays of actin filaments in motile tissue culture cells and the poleward flux of MTs within spindle fibers during mitosis. Assembly of these polymers from a pool containing a low percentage of fluorescently labeled subunits (about 1% or less) produces a random distribution of fluorophores along the polymer lattice that produces ""fluorescent speckle"" fiduciary marks varying from zero to several fluorophores (5-8) within the diffraction limited resolution of the microscope. The major focus of this application is on the further development of the FSM method for the analysis of MT function in spindle mechanics. In particular, how MT and kinetochore proteins function in spindle assembly, chromosome alignment and accurate chromosome segregation. This requires the development of new FSM microscope technology for the rapid recording of multi-wavelength and 3-D time-lapse images of MT fluorescent speckles relative to fluorescent marks or speckles at kinetochores, poles, MT associated proteins (MAPs), motor proteins and MT ends. A major next step for FSM to become a powerful analytical tool for these systems is the development of new Computer Vision methods for obtaining quantitative information about polymer movement and turnover in 2-D and 3-D at high resolution relative to the other molecular fluorescent markers in the spindle. To study protein function, we are particularly interested in optimizing FSM for genetic model organisms including budding yeast, for the biochemically accessible Xenopus egg extracts and for siRNA with mammalian tissue cells. Experience gained in the course of these studies will be used to direct and refine hardware and software development.           n/a",FLUORESCENT SPECKLE MICROSCOPY,6720801,R01GM060678,"['Urodela', 'Xenopus', 'animal tissue', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'centromere', 'computer program /software', 'computer system design /evaluation', 'fluorescence microscopy', 'fluorescent dye /probe', 'image enhancement', 'microtubules', 'mitotic spindle apparatus', 'small interfering RNA', 'technology /technique development', 'three dimensional imaging /topography', 'yeasts']",NIGMS,UNIVERSITY OF NORTH CAROLINA CHAPEL HILL,R01,2004,622682,0.02199694401723183
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6642050,R24HD038585,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biological signal transduction', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' electromyography', ' evaluation /testing', ' human subject', ' motor neurons', ' neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2003,562596,-0.007211964514205674
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6710523,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,139234,-0.0008143055682709141
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6665322,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,245656,-0.0008143055682709141
"Spinal Cord Injury: Automatic Scoring of Motor Function    DESCRIPTION (provided by applicant): Disorders of motor function due to accidental injury, stroke and neurodegenerative disorders, together with disorders of mental health, are the most crippling human ailments. One common result of mechanical insult is spinal cord injury (SCI), in which damage of the spinal cord by contusion, compression or laceration causes loss of sensation, motor and reflex function below the point of injury. Other symptoms of SCI may include bowel and bladder dysfunction, hyperalgesia and sexual dysfunction. Although many SCI patients survive injury, major chronic dysfunction is the most common outcome. There are approximately 10,000 new cases of spinal cord injury (SCI) in the U.S each year. In contrast to the relatively small acute patient population, chronic SCI, involving approximately 200,000-250,000 people in this country, is extremely expensive to society, both in terms of human and economic costs. Because most SCI victims are under age 30 at the time of their injury, and most now live a near-normal life span, direct medical costs average $2 million per patient over a lifetime, and approximately $5 billion total per year in the US only. Therefore, any   drug or intervention that can positively improve the quality of life of patients suffering from SCI is likely to have a greater financial impact than would be expected simply from the cost of acute injury each year.  Animal models for SCI and other conditions that affect gait and motor coordination are successfully used today to develop new treatments. Assessing the level of motor dysfunction in an animal model is a difficult challenge as most researchers rely on the subjective scoring of symptoms. We propose here to build a system that will allow a more objective, faster and consistent assessment of the level of injury and course of recovery in rat and mouse models of SCI that can be applied in the future to other gait and motor coordination disorders. An artificial intelligent system based on computer vision will be developed to capture and score gait and motor coordination in rodents and will be validated against the standard scores of motor function obtained using the methods of Basso, Beattie, and Bresnahan (1995) for the rat model of SCI.         n/a",Spinal Cord Injury: Automatic Scoring of Motor Function,6695163,R43NS046980,"['artificial intelligence', ' computer system design /evaluation', ' gait', ' laboratory rat', ' limb movement', ' psychomotor function', ' spinal cord injury']",NINDS,"PSYCHOGENICS, INC.",R43,2003,234554,0.018784581870898584
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6637831,R01AG018751,"['aging', ' artificial intelligence', ' body movement', ' clinical research', ' computer system design /evaluation', ' hand', ' human old age (65+)', ' human subject', ' psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2003,231899,0.004940155763136587
"Physiological Controller for Rotary Blood Pumps DESCRIPTION (provided by applicant):    As the prospects of chronic mechanical assistance for the failing human heart are fast becoming a reality, and patients are indeed returning home to regain a normal lifestyle, the limitations of this technology upon quality of life are becoming more apparent. To address many of these limitations, investigators are developing next-generation ventricular assist devices. Based on turbopump technology, these new devices offer smaller size, greater efficiency (hence smaller batteries), high reliability, and are more cost effective as compared to their pulsatile predecessors. For all the virtues of these new turbopumps, they bring additional challenges. Arguably the most urgent is the need for added ""intelligence."" These relatively ignorant devices are highly dependent on feedback-control to provide normal physiological response. The goal of the Phase- II effort proposed herein is to design a robust controller that may be incorporated into these turbodynamic pump systems for clinical use. The primary end product of this program would be a validated algorithm, in the form of firmware that will be embedded into existing rotary pump controller -- capable of maintaining optimal perfusion of the patient under a variety of hemodynamic demands and disturbances, while avoiding deleterious conditions such as ventricular suction. n/a",Physiological Controller for Rotary Blood Pumps,6690298,R44HL066656,"['artificial intelligence', ' auxiliary heart prosthesis', ' biomedical device power system', ' biomedical equipment development', ' cardiac output', ' circulatory assist', ' computer system design /evaluation', ' cow', ' electrophysiology', ' hemolysis', ' mathematical model', ' microprocessor /microchip', ' sheep']",NHLBI,"LAUNCHPOINT TECHNOLOGIES, INC.",R44,2003,370076,0.013203465895183435
"Neurological Control During Brain Recording  DESCRIPTION (provided by applicant): This research proposal aims to investigate the optimal design features of intracortical motor neuroprosthetics by analyzing: 1) The ability of specific algorithms to predict movements from neural activity, 2) the ability of non-human primate subjects to control neurally-derived signals in a behaviorally useful way, and 3) explore the abilities of humans to control computer cursors with neural activity. First, discrete and continuous movement models will be evaluated to determine the minimum amount of data necessary to build robust decoders. This relates to clinical calibration: How much time will be required for patients to build decoding models that they can then use? Next, I will evaluate if and how animals can control a computer cursor whose position is driven by decoded neural activity alone: Whether they can generate stationary holds, ballistic reaches, and complex trajectories. Finally, I will test the decoding system in humans by participating in ongoing human multi-electrode recording. I hope to implement a real-time neural activity decoding system to test whether human subjects can rapidly acquire useful, accurate control over a movement signal. These investigations will shed light on which parameters are useful for achieving such control and yield insight on the optimal balance between computer and human learning in the closed-loop control system to restore maximum functional independence.   n/a",Neurological Control During Brain Recording,6583494,F31NS045460,"['Macaca', ' artificial intelligence', ' assistive device /technology', ' behavior test', ' behavioral /social science research tag', ' biomechanics', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' electrodes', ' functional ability', ' goal oriented behavior', ' human subject', ' mathematical model', ' medical rehabilitation related tag', ' nervous system prosthesis', ' neurophysiology', ' neuroregulation', ' predoctoral investigator']",NINDS,BROWN UNIVERSITY,F31,2003,37017,0.007268376973361113
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6666671,R01EY013875,"['blind aid', ' blindness', ' clinical research', ' computer human interaction', ' computer program /software', ' cues', ' human subject', ' reading', ' vision aid', ' vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,327524,0.019452254635642006
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6536089,R24HD038585,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biological signal transduction', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' electromyography', ' evaluation /testing', ' human subject', ' motor neurons', ' neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2002,622485,-0.007211964514205674
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6580977,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2002,246164,-0.0008143055682709141
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6533901,R01AG018751,"['aging', ' artificial intelligence', ' body movement', ' clinical research', ' computer system design /evaluation', ' hand', ' human old age (65+)', ' human subject', ' psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2002,232006,0.004940155763136587
"COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION There are approximately 2.5 million people in the US who are speech impaired to the extent that it is considered a functional limitation.  Today, many people with severe communication disabilities lack access to electronic and even printed material, have a lack of opportunity for interaction and opportunity for self-advocacy, and experience isolation.  Providing accessibility to wireless voice, data and Internet communications directly from the device is of tremendous importance to people with severe communication disabilities. The primary objective under the Phase I grant was to investigate the potential of word-level disambiguation technology for text generation on a communication aid to meet the needs of many individuals requiring augmentative and alternative communication (AAC).  Phase I findings validated T9 technology as a viable method for text generation and also AAC device users want to access wireless voice, data and Internet communications directly from the device.  The specific aims of Phase II are to: investigate hardware platforms for AAC device host candidates, develop Windows software modules for T9 and AAC, develop portable AAC resources, integrate wireless voice and data communications, and conduct usability testing of the product as it develops. PROPOSED COMMERCIAL APPLICATION The outcome of Phase II will be a communication aid device for production in Phase III that is based on commercially available hardware with minimal custom AAC hardware support.  The goal is that the software platform developed in Phase II will be ported to existing low-cost hardware as much as possible to: make use of newly developed platforms, provide more choice to AAC device users, provide more flexibility in user interface, and reduce overall device costs to the end user when commercially manufactured.  n/a",COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION,6569890,R44RR013191,"['Internet', ' artificial intelligence', ' biomedical equipment development', ' clinical biomedical equipment', ' clinical research', ' communication disorder aid', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' human subject', ' online computer', ' vocabulary', ' voice']",NCRR,"MADENTEC (USA), INC.",R44,2002,139082,0.010691810697525528
"A Personal Status Monitor for the Home The purpose of this Phase II SBIR is to develop a portable and completely wireless system that detects, processes, and analyzes muscle activity for remotely monitoring the functional status of an individual. The Personal Status Monitor (PSM) will remotely monitor the use of muscles during the exertion of motor tasks in a continuous and unobstructed fashion. Through pattern recognition of surface electromyographic (EMG) signals, the PSM will provide the caregiver with an objective parametric measure of how physically active their patient has been, such as walling, sitting, personal care, and feeding. The PSM will consist of three components: 1) four wireless EMG sensors, 2) a body worn transceiver (Repeater), and 3) the Base Station, which processes the signals for pattern recognition and feature extraction. The information can be sent to a remote location via telephone lines or the Internet. The specific aims of this program for Phase II are: Aim 1: To continue with Phase I development of the pattern recognition algorithms in patients with stroke; Aim 2: Design and build a working prototype of the hardware and software for the PSM; and Aim 3: Field test the prototype wireless system among stroke patients in the home environment. PROPOSED COMMERCIAL APPLICATIONS: The MA will primarily augment clinical service by making the line an effective place for rehabilitation. In addition, the PSM will have direct applicability to the field of ergonomics for work-site assessment, or in sports or recreational activities as a feedback device to facilitate training of skilled movements. Numerous other applications in the field of rehabilitation could include monitoring of drug therapies for tremor or other neuromuscular conditions, or home-exercise compliance. The knowledge base and prototypes developed in this project are directly transferable to other acquisition systems for biological signals recorded from the skin, such as EEGs and EKGs.  n/a",A Personal Status Monitor for the Home,6534517,R44AR047272,"['artificial intelligence', ' biomedical equipment development', ' caregivers', ' computer program /software', ' computer system design /evaluation', ' electromyography', ' functional ability', ' home health care', ' human subject', ' muscle function', ' patient monitoring device', ' portable biomedical equipment', ' stroke', ' telemedicine', ' telemetry']",NIAMS,"ALTEC, INC.",R44,2002,404087,-0.028514166513074316
"Locating and Reading Informational Signs  DESCRIPTION (provided by applicant): Our goal is to construct computer vision systems to enable the blind and severely visually impaired to detect and read informational text in city scenes. The informational text can be street signs, bus numbers hospital signs, supermarket signs, and names of products (eg. Kellogg's cornflakes). We will construct portable prototype computer vision systems implemented by digital cameras attached to personal, or hand held, computers. The camera need only be pointed in the general direction of the text (so the text is only one percent of the image). A speech synthesizer will read the text to the user. Blind and visually impaired users will test the device in the field (under supervision) and give feedback to improve the algorithms. We argue that this work will make a significant contribution to improving human health (rehabilitation). Computer vision is a rapidly maturing technology with immense potential to help the blind and visually impaired. Reports suggest that detecting and reading informational text is one of the main unsatisfied desires of these groups. Written signs and information in the environment are used for navigation, shopping, operating equipment, identifying buses, and many other purposes (to which a blind person does not otherwise have independent access). The blind and severely visually impaired make up a large fraction of the US population (3 million). Moreover, this proportion is expected to increase by a factor of two in the next ten years due to increased life expectancy. Our proposal is design-driven. It uses a new class of computer vision algorithms known as Data Driven Monte Carlo (DDMCMC). The algorithms are used to: (i) search for text, and (ii) to read it. Recent developments in digital cameras and portable/handheld computers make it practical to implement these algorithms in portable prototype systems. The three scientists in this proposal have the necessary expertise to accomplish it. Dr.'s Yuille and Zhu have backgrounds in computer vision and Dr. Brabyn has experience in developing and testing engineering systems to help the blind and visually impaired. Our proposal falls within the scope of the Bioengineering initiative because we are applying techniques from the mathematical/engineering sciences to develop informatic approaches for patient rehabilitation. More specifically, our work will facilitate the development of portable devices to help the blind and visually impaired.   n/a",Locating and Reading Informational Signs,6547549,R01EY013875,"['blind aid', ' blindness', ' clinical research', ' computer human interaction', ' computer program /software', ' cues', ' human subject', ' reading', ' vision aid', ' vision disorders']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2002,338540,0.019452254635642006
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6388212,R24HD038585,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biological signal transduction', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' electromyography', ' evaluation /testing', ' human subject', ' motor neurons', ' neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2001,604881,-0.007211964514205674
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6369619,R01AG018751,"['aging', ' artificial intelligence', ' body movement', ' clinical research', ' computer system design /evaluation', ' hand', ' human old age (65+)', ' human subject', ' psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2001,308867,0.004940155763136587
"PHYSIOLOGICAL CONTROLLER FOR ROTARY BLOOD PUMPS   DESCRIPTION (Verbatim From Applicant's Abstract): As the prospects of a              mechanical replacement for a failing human heart are fast becoming a reality,        and patients are indeed returning home to regain a ""normal"" lifestyle, the           limitations of this technology upon quality of life are becoming more apparent.      To address many of these limitations, investigators are developing                   next-generation ventricular assist devices. Based on turbopump technology,           these new devices offer smaller size, greater efficiency (hence smaller              batteries), high reliability, and are more cost effective as compared to their       pulsatile predecessessors. For all the virtues of these new turbopumps, they         bring with additional challenges. Arguably the most urgent is the need for           added intelligence."" These, relatively stupid, devices are highly dependent on       feedback-control to provide physiological response. Unfortunately, developers        have yet to wage a systematic assault on this problem. Preoccupied with              apparently more urgent issues, such as biocompatibility etc., there has been         relatively little attention or resources directed at developing a physiological      controller.                                                                                                                                                               For the past eight years, the P.I. has had an interest in this problem, and has      conducted basic and applied research towards developing control algorithms. He       now proposes to devise a general-purpose controller product, which can be            incorporated into a variety of rotary pump systems for clinical use.                                                                                                      The goal of the Phase-I effort proposed herein are to design a robust control        algorithm which may then be implemented, in Phase-Il, into an applications           specific integrated circuit. The P.I. envisions that this chip would be              made available to device developers much like control circuits produced by           Intel, Motorola, Texas Instruments, etc., are adopted by a wide variety of           users for their specific products.                                                   PROPOSED COMMERCIAL APPLICATION:  Direct application to virtually all rotary-type blood pumps for critical care and chronic use.  The P.I. envisions that the Antakamatics control chip would be made available to device  developers much like integrated circuits producted by Intel, Motorola, Texas Instruments,   etc. are adopted by a wide variety of users for their specific products.  The market for  this product is estimated to exceed 200,000 units per annum, and there currently exists  no competing product.                                                                                     n/a",PHYSIOLOGICAL CONTROLLER FOR ROTARY BLOOD PUMPS,6292387,R43HL066656,"['artificial intelligence', ' auxiliary heart prosthesis', ' biomedical device power system', ' biomedical equipment development', ' cardiac output', ' circulatory assist', ' computer system design /evaluation', ' electrophysiology', ' microprocessor /microchip']",NHLBI,"ANTAKAMATICS, INC.",R43,2001,98465,-0.010710432744433
"Shearography for Non-Invasive Dental Health Evaluation   DESCRIPTION: Optical holography has been applied to non-invasive clinical            diagnosis and monitoring of Dental and oral/facial pathology, but has been           sharply limited in its usefulness by its requirements of high laser coherence.       absolute stability of setup. and wet processing of holograms. Physical Optics        Corporation (POC) proposes to develop a shearographic micro-optic camera as a        novel means of non-invasive Dental evaluation and characterization based on          shearing speckle interferometry, miniature camera imaging, and proprietary           neural network image processing. The innovation in this concept is the use of        shearography to avoid the need for high stability, high temporal coherence, and      wet processing. Nearfield shearography will have high spatial resolution, and        the neural network will perform real-time data processing and display.                                                                                                    The unique high resolution. real-time operation. low cost. and miniaturization       will make this device attractive to a large commercial market in Dental and          clinical applications.                                                                                                                                                    In Phase 1. POC will develop a miniature shearographic micro-optic camera            (SMOC) with fiber light delivery. a micro-CCD imaging component. and neural          network. It will be capable of distinguishing among tooth enamel, cementum,           dentine, pulp, and soft tissue.                                                      PROPOSED COMMERCIAL APPLICATION:  This compact, low-cost, high resolution non-invasive shearography device will represent a  technological breakthrough not only for oral diagnostics but also for biomedical imaging in  general.  Because of its high resolution, real-time operation, and immunity to vibration, it will  also have wide applications beyond the medical field, particularly for industrial diagnostics.  High-strength aerospace composite material evaluation and testing as well as weld and pipe  defect inspection are areas where it will be particularly welcome.                                                                                     n/a",Shearography for Non-Invasive Dental Health Evaluation,6404393,R43DE014307,"['artificial intelligence', ' bioimaging /biomedical imaging', ' dental disorder diagnosis', ' diagnosis design /evaluation', ' fiber optics', ' image processing', ' interferometry', ' lasers', ' noninvasive diagnosis', ' oral health', ' video recording system']",NIDCR,PHYSICAL OPTICS CORPORATION,R43,2001,100000,0.0018555516619081865
"MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING   A low-cost, high-resolution, high-contrast color digital camera optimized        for ophthalmology will be demonstrated. The maximum entropy camera         will be tested for its effectiveness in meeting the image quality requirements       for telemedicine and for remote screening of pre-proliferative and                   proliferative diabetic retinopathy. The proposed device exploits recent              technological advances in high sensitivity CCD cameras and digital signal            processing electronics. Today's low cost 8-bit CCD cameras do not have the           dynamic range to image the human retina, which is characterized by regions of        high reflectivity (20-40 percent), such as the optic disc, and very low              reflectivity (<2 percent), such as the macula and fovea. Existing digital            cameras used in ophthalmology are not designed to deal with the high dynamic         range and do not consider the special re-saturated characteristics of the            retina. The proposed device will be shown to offer significant improvement over      existing digital color cameras by addressing each of the deficiencies                mentioned.                                                                           PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING,6292349,R43EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R43,2001,107706,-0.01082574294799456
"COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION There are approximately 2.5 million people in the US who are speech impaired to the extent that it is considered a functional limitation.  Today, many people with severe communication disabilities lack access to electronic and even printed material, have a lack of opportunity for interaction and opportunity for self-advocacy, and experience isolation.  Providing accessibility to wireless voice, data and Internet communications directly from the device is of tremendous importance to people with severe communication disabilities. The primary objective under the Phase I grant was to investigate the potential of word-level disambiguation technology for text generation on a communication aid to meet the needs of many individuals requiring augmentative and alternative communication (AAC).  Phase I findings validated T9 technology as a viable method for text generation and also AAC device users want to access wireless voice, data and Internet communications directly from the device.  The specific aims of Phase II are to: investigate hardware platforms for AAC device host candidates, develop Windows software modules for T9 and AAC, develop portable AAC resources, integrate wireless voice and data communications, and conduct usability testing of the product as it develops. PROPOSED COMMERCIAL APPLICATION The outcome of Phase II will be a communication aid device for production in Phase III that is based on commercially available hardware with minimal custom AAC hardware support.  The goal is that the software platform developed in Phase II will be ported to existing low-cost hardware as much as possible to: make use of newly developed platforms, provide more choice to AAC device users, provide more flexibility in user interface, and reduce overall device costs to the end user when commercially manufactured.  n/a",COMMUNICATION AID UTILIZING WORD LEVEL DISAMBIGUATION,6188611,R44RR013191,"['Internet', ' artificial intelligence', ' biomedical equipment development', ' clinical biomedical equipment', ' clinical research', ' communication disorder aid', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' human subject', ' online computer', ' vocabulary', ' voice']",NCRR,"MADENTEC (USA), INC.",R44,2001,316991,0.010691810697525528
"A Personal Status Monitor for the Home The purpose of this Phase II SBIR is to develop a portable and completely wireless system that detects, processes, and analyzes muscle activity for remotely monitoring the functional status of an individual. The Personal Status Monitor (PSM) will remotely monitor the use of muscles during the exertion of motor tasks in a continuous and unobstructed fashion. Through pattern recognition of surface electromyographic (EMG) signals, the PSM will provide the caregiver with an objective parametric measure of how physically active their patient has been, such as walling, sitting, personal care, and feeding. The PSM will consist of three components: 1) four wireless EMG sensors, 2) a body worn transceiver (Repeater), and 3) the Base Station, which processes the signals for pattern recognition and feature extraction. The information can be sent to a remote location via telephone lines or the Internet. The specific aims of this program for Phase II are: Aim 1: To continue with Phase I development of the pattern recognition algorithms in patients with stroke; Aim 2: Design and build a working prototype of the hardware and software for the PSM; and Aim 3: Field test the prototype wireless system among stroke patients in the home environment. PROPOSED COMMERCIAL APPLICATIONS: The MA will primarily augment clinical service by making the line an effective place for rehabilitation. In addition, the PSM will have direct applicability to the field of ergonomics for work-site assessment, or in sports or recreational activities as a feedback device to facilitate training of skilled movements. Numerous other applications in the field of rehabilitation could include monitoring of drug therapies for tremor or other neuromuscular conditions, or home-exercise compliance. The knowledge base and prototypes developed in this project are directly transferable to other acquisition systems for biological signals recorded from the skin, such as EEGs and EKGs.  n/a",A Personal Status Monitor for the Home,6403447,R44AR047272,"['artificial intelligence', ' biomedical equipment development', ' caregivers', ' computer program /software', ' computer system design /evaluation', ' electromyography', ' functional ability', ' home health care', ' human subject', ' muscle function', ' patient monitoring device', ' portable biomedical equipment', ' stroke', ' telemedicine', ' telemetry']",NIAMS,"ALTEC, INC.",R44,2001,403938,-0.028514166513074316
"SIGN FINDER: COMPUTER VISION TO FIND AND READ SIGNS In this Phase l proposal we plan to develop and test a new vision technology to locat and read general informational signs (street names, building directories, office door plates) and location and directional signs (EXIT, Information, aisle signs in supermarkets). To strengthen feasibility, we will target a restricted class of signs: those consisting primarily of one- color text on a different one-color background, and whose shape falls within a prescribed set. The intended market is for people who are blind or whose sight is impaired and hence cannot read these signs unaided. Our approach makes extensive use of recently developed computer vision recognition algorithms. We also make use of the Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for determining what the potential users will require from such a system. The ultimate goal, for Phase II, is to build and test a highly portable PC- based device implementing this vision technology using a CCD camera as input and a voice-generator as output. The user would scan/point the device at a scene and it would locate and read one or more signs. Given the pace of increase in power and decrease in size of computing devices, a hand-held Sign-Finder system may be plausible to build entirely with commercial, off-the-shelf hardware in two to three years. PROPOSED COMMERCIAL APPLICATION: The potential utility to blind and visually impaired individuals is great; a commercial product could have a market potential of 500,000.  n/a",SIGN FINDER: COMPUTER VISION TO FIND AND READ SIGNS,2720318,R43EY011821,"['artificial intelligence', ' blind aid', ' charge coupled device camera', ' computer graphics /printing', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' information display', ' portable biomedical equipment', ' symbolism', ' technology /technique development', ' vision aid']",NEI,BLINDSIGHT CORPORATION,R43,2000,100000,0.028262043158082045
"HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC   DESCRIPTION (Adapted from the applicant's abstract): This study will develop an                                                                             automatic system for decomposing the electromyographic signal into the               constituent action potentials corresponding to the firing of individual motor        units activated by motorneurons. The system will be an enhancement of a current      system used over the past 20 years in many studies carried out by the                Neuromuscular Research Lab at Boston University. Although the current system         has been a valuable research tool, it has never been useful as a clinical tool       due to limitations in processing time, accuracy and portability. Proposed            enhancements will be introduced by redesigning the hardware and rewriting the        decomposition software using a knowledge-based artificial intelligence language      (IPUS), which has recently been developed by the team. As part of this               application the enhanced system will be used in two laboratory studies and two       clinical studies. The laboratory studies will investigate the modifications          that occur in the firing of motor units as a function of ageing and will             quantify the benefits that can be restored by exercise. The system will also be      used to investigate the phenomena of motor unit substitution. The clinical           studies will address the use of the device in quantifying the degree of              denervation in paralyzed laryngeal muscles and in studying the effect of acute       ataxia on the firing characteristics of the motorneurons in cerebellar stroke.       As well as testing specific hypotheses, these studies will be used to test and       improve the evolving design of the new decomposition system.                                                                                                              n/a",HARNESSING MOTONEURON ACTIVITY: FROM LAB TO CLINIC,6054979,R24HD038585,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biological signal transduction', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' electromyography', ' evaluation /testing', ' human subject', ' motor neurons', ' neuromuscular function']",NICHD,BOSTON UNIVERSITY,R24,2000,593340,-0.007211964514205674
"A PERSONAL STATUS MONITOR FOR THE HOME We propose to develop and evaluate a wireless Personal Status Monitor (PSM) that can monitor the use of musculature in a continuous and unobstructive fashion while a subject performs normal and usual daily activities in the home. This innovation will provide the caregiver specific information describing their patient's physical and functional performance in the home, without relying on self-reports or having the patient leave the home environment. The PSM will consist of three components: I) wireless sensors to detect the electromyographic (BMG) signal, 2) a small body-worn transceiver, and 3) a base station, which processes the signals for feature extraction and transmission to the caregiver. The proposed Phase l program will focus on the development of methods to recognize specific functional tasks based solely on surface EMG signals. We propose to develop and evaluate pattern recognition algorithms using neural networks for processing EMG signals obtained from healthy subjects during the performance of specific functional tasks selected from the Functional Independence Measure (FIM). Proof of concept will be achieved by demonstrating that it is possible to accurately distinguish between these tasks using no more than 4 EMG sensors, even when extraneous motor activity is present. The commercial development of a PSM for the home will be continued during Phase II by: 1) designing and building the hardware, 2) developing the application software, and 3) expanding the development of intelligent algorithms to additional functional activities. PROPOSED COMMERCIAL APPLICATIONS: Successful completion of the proposed project will lead to the development of a new method for monitoring functional activity in the home. The innovation will rely on technological achievements involving wireless sensors and telemedicine to surpass the capability of current methods to measure functional activity in the home. It will replace, or augment, the current reliance on self-report questionnaires, non-specific physical activity monitors, and frequent home care or clinic visits to establish a patient record of physical activity in the home. The system will have commercial appeal to many of the rehabilitation specialties working with the elderly, neurologically impaired general orthopedic, cardiac, sports medicine and work-injured populations.  n/a",A PERSONAL STATUS MONITOR FOR THE HOME,6211028,R43AR047272,"['artificial intelligence', ' biomedical equipment development', ' caregivers', ' computer program /software', ' computer system design /evaluation', ' electromyography', ' home health care', ' human subject', ' patient monitoring device', ' telemetry']",NIAMS,"ALTEC, INC.",R43,2000,92686,-0.029509280937608715
"CLINICAL RESEARCH TOWARD CLOSED LOOP INSULIN DELIVERY DESCRIPTION (Adapted from applicant's abstract): The ""closed-loop                artificial pancreas,"" a device that would measure glucose level and              deliver insulin automatically as needed, has been an elusive goal in the         treatment of diabetes. There are three essential components: the blood           glucose sensor, linking algorithms and the delivery system. For the first        time, a viable sensor and a proven delivery system are now available for         research. The broad goal of this clinical research proposal is to complete       the studies needed to link the sensor to the delivery system, paving the         way for a functional closed-loop artificial pancreas. First, we will make        a detailed analysis of sensor signal as it reflects glucose level in             normal and diabetic humans. Second, we will study the precise                    pharmacokinetics of insulin delivery by external and implantable insulin         pumps. Third, analysis of these two data sets will provide the basis for         algorithms that link the sensor signal to insulin delivery. A formal             safety analysis will evaluate the safety features needed in a closed loop        device. In the last year of the project, the entire system will be tested        and fine-tuned. This project takes advantage of our relatively extensive         investigational experience with mechanical insulin delivery pumps in             people with diabetes, and the recent availability, for research, of a            subcutaneously placed, glucose oxidase-based continuous glucose sensor.          The investigators have established experienced with clinical research in         diabetes, and the resources of an excellent General Clinical Research            Center. The co-investigators have extensive experience with mathematical         modeling of biologic systems. There is a close working relationship              between the research team and the manufacturer of the sensor and pumps, as       reflected by the Interactive Research Project Grant collaboration, and by        a long-standing history of collaboration. It is essential to emphasize           that we do not anticipate completion of a manufacturable, clinically             usable, commercially viable artificial pancreas within the time-frame of         this work. Rather, we aim to complete the basic studies and modeling             analyses that would form the basis of such a system, and demonstrate the         feasibility of linking the sensor to the delivery device. If these studies       and these trials were successful, they would be a major step towards             development of a clinically useful close-loop artificial pancreas.                n/a",CLINICAL RESEARCH TOWARD CLOSED LOOP INSULIN DELIVERY,6177804,R01DK055132,"['artificial endocrine pancreas', ' artificial intelligence', ' biosensor device', ' clinical research', ' drug delivery systems', ' glucose metabolism', ' human subject', ' insulin', ' insulin dependent diabetes mellitus', ' medical implant science', ' pharmacokinetics']",NIDDK,JOHNS HOPKINS UNIVERSITY,R01,2000,252566,0.0143682767939636
"MICRO-OPTICS-BASED DIGITAL ALLERGEN COUNTER The current pollen identification and counting method based on microscopic visual examination is very time consuming and labor intensive. More importantly, it is very ""subjective"" and not truly scientific. Intelligent Optical Systems, Inc. proposes to develop a portable digital allergen counter (DAC) to accurately and reliably count and identify airborne pollen grains and fungal spores. The proposed DAC combines a micro-image scanner, a high-speed video chip, an allergen morphology data bank, and a built-in image processor into an integrated and automated pollen counter. The DAC will rapidly identify and quantify pollen, grains and spores. By making it much easier to collect allergen information in multiple locations, the proposed device will reduce morbidity by providing improved warnings on days with high pollen counts. The specific aims of the Phase I project are to design and construct optical image scanner suitable for allergen detection, identify the morphology of several types of pollen, grains, and spores, integrate the DAC system and test and evaluate the system feasibility. In Phase II, an engineering prototype of a portable instrument will be built and field-validated with real-world samples. We will also expand its capability to increase the pollen types of interest. PROPOSED COMMERCIAL APPLICATIONS: A compact, simple, and easy-to-use digital allergen counting system that can monitor indoor or outdoor air quality that will minimize people's overexposure to allergens.  This device is for aerobiological research that could be beneficial for public health, medical pharmaceutical and engineering applications. Universities, physicians, public health organizations, National Allergy Bureau (NAB) stations, and private air sampling consultants will  purchase the device.  n/a",MICRO-OPTICS-BASED DIGITAL ALLERGEN COUNTER,6211164,R43HL064459,"['air sampling /monitoring', ' allergens', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' computer program /software', ' computer system design /evaluation', ' image processing', ' monitoring device', ' optics', ' particle counter', ' pollen']",NHLBI,"INTELLIGENT OPTICAL SYSTEMS, INC.",R43,2000,99995,0.013726054333913279
"Ghost in the Machine: Melding Brain, Computer and Behavior Implantable devices are playing a greater role in neurologic care, but their effectiveness is limited, because they are blind to human thoughts, feelings, and behavior – factors that most dramatically affect our health. Coupling peripheral sensors to implants might help, but wouldn’t it be easier if the devices just asked us? Armed with this knowledge, next generation machines will more effectively drive neural activity in the brain to healthy states. They will also quickly learn behaviors that worsen health and guide us to better choices. Though DARPA, the NIH, and Neuralink are spending millions of dollars on new hardware for brain-computer interfaces, none focus on reciprocal, natural communication between host and machine. There is a desperate need for novel, practical methods that enable devices to learn from and guide human behavior.  In this application I propose to develop a new generation of autonomous brain-machine interfaces – devices that can question, record, act - and combine learning algorithms applied to neurosignals with teaching by their human hosts. Life with these implants will entail a subtle human- machine dialogue in which devices and humans teach and learn from each other. Humans will inform intelligent algorithms about what we are doing and feeling, while machines will incorporate this information into therapy and guide us to optimize quality of life in personalized ways. This is a paradigm shift from today’s simple devices, which are programmed by physicians during occasional office visits. I propose to demonstrate this paradigm in a practical, scalable way using current epilepsy implants that is rapidly translatable to many neurological disorders.  To achieve this goal, I will meld several cutting-edge technologies in novel ways, including: (1) State-of-the-art, high bandwidth implantables that sample neural activity, link to vast cloud- based computational power to process it, and intervene to modulate brain, spinal cord or peripheral neural activity. This work utilizes my experience from the past 20 years; (2) I will deploy powerful new computer science tools in novel ways. I will use convolutional neural nets (a.k.a. Deep Learning) to learn patterns from vast streams of continuous high-bandwidth neural data, build a two way human-machine interface using Natural Language Processing (NLP)., and probe networks with changes in human behavior and electrical stimulation and guide interventions toward therapeutic goals using Reinforcement Learning. Combining these computer science, machine learning techniques and measurements of human behavior is a new area of investigation for me that will leverage my unique background in clinical neurology and engineering to build a new class of interactive, human therapeutic devices. The goal of this project is to develop a revolutionary, new generation of implantable neurodevices that will communicate with, learn from, and teach their human hosts to better treat disease. Current implantable devices are blind to human actions, thoughts and behavior, which limits their effectiveness. State of the art computer techniques that can measure behavior and link them to brain activity will empower patients to teach, control and learn from their devices to improve health and quality of life.","Ghost in the Machine: Melding Brain, Computer and Behavior",10012013,DP1NS122038,"['Affect', 'Area', 'Behavior', 'Brain', 'Caring', 'Clinical', 'Communication', 'Computers', 'Coupling', 'Data', 'Devices', 'Disease', 'Educational process of instructing', 'Effectiveness', 'Electric Stimulation', 'Engineering', 'Epilepsy', 'Feeling', 'Generations', 'Goals', 'Health', 'Human', 'Implant', 'Intervention', 'Investigation', 'Knowledge', 'Learning', 'Life', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Natural Language Processing', 'Neurologic', 'Neurology', 'Office Visits', 'Patients', 'Pattern', 'Peripheral', 'Physicians', 'Play', 'Process', 'Psychological reinforcement', 'Quality of life', 'Role', 'Sampling', 'Spinal Cord', 'Stream', 'Techniques', 'Technology', 'Therapeutic', 'Thinking', 'United States National Institutes of Health', 'User-Computer Interface', 'Work', 'blind', 'brain computer interface', 'brain machine interface', 'cloud based', 'computer science', 'convolutional neural network', 'deep learning', 'experience', 'implantable device', 'improved', 'intelligent algorithm', 'learned behavior', 'learning algorithm', 'nervous system disorder', 'next generation', 'novel', 'relating to nervous system', 'sensor', 'tool']",NINDS,UNIVERSITY OF PENNSYLVANIA,DP1,2020,1134000,0.029618158311475105
"MRI and machine learning to improve early prognosis and clinical management after spinal cord injury PROJECT SUMMARY/ABSTRACT Purpose/Hypothesis: Spinal cord injury (SCI) causes substantial social, economic, and health burden.1 For individuals with motor incomplete SCI, some basic ability to stand or walk is expected during the recovery process,2 and this is a top priority in rehabilitative programs.3 However, establishing a prognosis for recovering community walking ability is extremely difficult.4 Within 72 hours after SCI,5 edema develops within the damaged spinal cord. This edema is a hallmark of spinal cord injury, expressed as signal hyperintensity using T2 magnetic resonance imaging (MRI).6 Correlations between the sagittal length of this spinal cord edema and walking ability are generally poor.7,8 However, advanced but available high resolution axial T2-weighted MRI to quantify spinal cord edema in people in the acute stage of SCI may improve prediction of walking ability.9,10 The early clinical management and targeted rehabilitation of these individuals could be drastically enhanced, optimizing recovery and rehabilitation outcomes. The main objective of this research project is to use early axial spinal cord MRI sequences as neuroprognostic biomarkers to improve the prediction of residual motor function. This objective will be realized by the implementing the following specific aims: Aim 1: To establish to what extent the axial damage ratio biomarker, measured by high-resolution axial T2-weighted structural imaging, can predict residual function in persons with SCI. Previously-collected axial T2-weighted spinal cord structural MRI data of 200 people with SCI from the US Model SCI System at Craig Hospital will be used to quantify cord damage. This metric will be related to the primary 1-year status-post injury outcome measures, which are clinical records of walking ability and function. Multivariate statistical analyses will be applied to create exploratory models to determine the prognostic value of the MRI measures. We hypothesize that the axial damage ratio can be used in the acute stage as an accurate and objective neuroprognostic biomarker of residual motor function. Aim 2: To identify the relationship between damage to specific spinal cord regions and specific motor and sensory deficits. MRI data from Aim 1 will be used. Spinal cord regional damage analysis will be related to right and left upper and lower extremity motor and sensory scores. Correlational statistical analyses will be applied to analyze relationships between specific tract damage and motor/sensory deficits. We hypothesize that damage to descending lateral corticospinal motor regions is related to ipsilesional motor deficits, and that similar findings exist for ascending sensory regions and sensory deficits. For both Aims, we will compare our manual damage quantification to our machine learning approach to automatically detect spinal cord damage. Aim 3: Develop, test, and distribute a machine-learning based analysis pipeline for spinal cord damage measures. We will use functions included in the Spinal Cord Toolbox and the open-source NiftyNet deep-learning platform to develop the machine-learning based analysis pipeline. The processing steps will include spinal cord detection, spinal cord damage segmentation, registration to the spinal cord template, and the calculation and output of the axial damage ratio and regional damage biomarkers. Significance: Successful completion of these Aims will advance the NIH/NICHD NCMRR aim: “to enhance the health, productivity, independence, and quality of life of people with physical disabilities.” The significance of this outcome relates directly to improving the clinical management of SCI. This research may inform clinicians, patients, and families, regarding the percentage chance of regaining walking ability. The healthcare team will be able to determine, early-on, which people will optimally respond to locomotor training. This work will significantly improve the prognosis for recovery of walking and specific motor/sensory function based on early imaging of the damaged spinal cord. PROJECT NARRATIVE The purpose of this research project is to use early axial MRI measures of spinal cord damage as objective biomarkers to improve the prediction of walking recovery and specific motor return of individuals following SCI. This research will provide patients with a quantified sense of expectations regarding their chances of walking recovery, and will help guide the healthcare team on the best options for clinical management and rehabilitation (i.e. focusing on neuroplasticity and restoration of walking versus compensatory strategies). Ultimately, this research aims to improve the lives and wellbeing of those suffering from spinal cord injury. Successful completion of this research will advance the NIH/NICHD NCMRR aim: “to enhance the health, productivity, independence, and quality of life of people with physical disabilities.” ! 1!",MRI and machine learning to improve early prognosis and clinical management after spinal cord injury,10236755,R03HD094577,"['Acute', 'Biological Markers', 'Biological Models', 'Chronic', 'Classification', 'Clinical', 'Clinical Management', 'Communities', 'Correlation Studies', 'Corticospinal Tracts', 'Data', 'Data Set', 'Detection', 'Development', 'Economics', 'Edema', 'Event', 'Family', 'Foundations', 'Future', 'Health', 'Health Care Costs', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Individual', 'Injury', 'International', 'Investigation', 'Lateral', 'Left', 'Length', 'Life Expectancy', 'Linear Regressions', 'Link', 'Location', 'Locomotor training', 'Lower Extremity', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Medical Care Team', 'Modeling', 'Motor', 'Motor output', 'National Institute of Child Health and Human Development', 'Neurologic', 'Neuronal Plasticity', 'Outcome', 'Outcome Measure', 'Output', 'Participant', 'Patients', 'Personal Satisfaction', 'Persons', 'Physical Function', 'Probability', 'Process', 'Productivity', 'Prognostic Marker', 'Quality of life', 'Records', 'Recovery', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Residual state', 'Resolution', 'Retrospective Studies', 'Rogaine', 'Sensory', 'Signal Transduction', 'Spinal Cord', 'Spinal cord damage', 'Spinal cord injury', 'Statistical Data Interpretation', 'Structure', 'System', 'T2 weighted imaging', 'Testing', 'United States', 'United States National Institutes of Health', 'Upper Extremity', 'Walking', 'Work', 'analysis pipeline', 'base', 'deep learning', 'design', 'dorsal column', 'early detection biomarkers', 'expectation', 'functional independence', 'imaging Segmentation', 'improved', 'machine learning method', 'magnetic resonance imaging biomarker', 'motor deficit', 'motor function recovery', 'motor recovery', 'novel', 'open source', 'outcome forecast', 'physically handicapped', 'primary outcome', 'prognostic value', 'programs', 'prospective', 'rehabilitation strategy', 'restoration', 'secondary outcome', 'social', 'spinal cord imaging']",NICHD,UNIVERSITY OF COLORADO DENVER,R03,2020,46297,0.021961144529046277
"MRI and machine learning to improve early prognosis and clinical management after spinal cord injury PROJECT SUMMARY/ABSTRACT Purpose/Hypothesis: Spinal cord injury (SCI) causes substantial social, economic, and health burden.1 For individuals with motor incomplete SCI, some basic ability to stand or walk is expected during the recovery process,2 and this is a top priority in rehabilitative programs.3 However, establishing a prognosis for recovering community walking ability is extremely difficult.4 Within 72 hours after SCI,5 edema develops within the damaged spinal cord. This edema is a hallmark of spinal cord injury, expressed as signal hyperintensity using T2 magnetic resonance imaging (MRI).6 Correlations between the sagittal length of this spinal cord edema and walking ability are generally poor.7,8 However, advanced but available high resolution axial T2-weighted MRI to quantify spinal cord edema in people in the acute stage of SCI may improve prediction of walking ability.9,10 The early clinical management and targeted rehabilitation of these individuals could be drastically enhanced, optimizing recovery and rehabilitation outcomes. The main objective of this research project is to use early axial spinal cord MRI sequences as neuroprognostic biomarkers to improve the prediction of residual motor function. This objective will be realized by the implementing the following specific aims: Aim 1: To establish to what extent the axial damage ratio biomarker, measured by high-resolution axial T2-weighted structural imaging, can predict residual function in persons with SCI. Previously-collected axial T2-weighted spinal cord structural MRI data of 200 people with SCI from the US Model SCI System at Craig Hospital will be used to quantify cord damage. This metric will be related to the primary 1-year status-post injury outcome measures, which are clinical records of walking ability and function. Multivariate statistical analyses will be applied to create exploratory models to determine the prognostic value of the MRI measures. We hypothesize that the axial damage ratio can be used in the acute stage as an accurate and objective neuroprognostic biomarker of residual motor function. Aim 2: To identify the relationship between damage to specific spinal cord regions and specific motor and sensory deficits. MRI data from Aim 1 will be used. Spinal cord regional damage analysis will be related to right and left upper and lower extremity motor and sensory scores. Correlational statistical analyses will be applied to analyze relationships between specific tract damage and motor/sensory deficits. We hypothesize that damage to descending lateral corticospinal motor regions is related to ipsilesional motor deficits, and that similar findings exist for ascending sensory regions and sensory deficits. For both Aims, we will compare our manual damage quantification to our machine learning approach to automatically detect spinal cord damage. Aim 3: Develop, test, and distribute a machine-learning based analysis pipeline for spinal cord damage measures. We will use functions included in the Spinal Cord Toolbox and the open-source NiftyNet deep-learning platform to develop the machine-learning based analysis pipeline. The processing steps will include spinal cord detection, spinal cord damage segmentation, registration to the spinal cord template, and the calculation and output of the axial damage ratio and regional damage biomarkers. Significance: Successful completion of these Aims will advance the NIH/NICHD NCMRR aim: “to enhance the health, productivity, independence, and quality of life of people with physical disabilities.” The significance of this outcome relates directly to improving the clinical management of SCI. This research may inform clinicians, patients, and families, regarding the percentage chance of regaining walking ability. The healthcare team will be able to determine, early-on, which people will optimally respond to locomotor training. This work will significantly improve the prognosis for recovery of walking and specific motor/sensory function based on early imaging of the damaged spinal cord. PROJECT NARRATIVE The purpose of this research project is to use early axial MRI measures of spinal cord damage as objective biomarkers to improve the prediction of walking recovery and specific motor return of individuals following SCI. This research will provide patients with a quantified sense of expectations regarding their chances of walking recovery, and will help guide the healthcare team on the best options for clinical management and rehabilitation (i.e. focusing on neuroplasticity and restoration of walking versus compensatory strategies). Ultimately, this research aims to improve the lives and wellbeing of those suffering from spinal cord injury. Successful completion of this research will advance the NIH/NICHD NCMRR aim: “to enhance the health, productivity, independence, and quality of life of people with physical disabilities.” ! 1!",MRI and machine learning to improve early prognosis and clinical management after spinal cord injury,9858377,R03HD094577,"['Acute', 'Biological Markers', 'Biological Models', 'Chronic', 'Classification', 'Clinical', 'Clinical Management', 'Communities', 'Correlation Studies', 'Corticospinal Tracts', 'Data', 'Data Set', 'Detection', 'Development', 'Economics', 'Edema', 'Event', 'Family', 'Foundations', 'Future', 'Health', 'Health Care Costs', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Individual', 'Injury', 'International', 'Investigation', 'Lateral', 'Left', 'Length', 'Life Expectancy', 'Linear Regressions', 'Link', 'Location', 'Locomotor training', 'Lower Extremity', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Medical Care Team', 'Modeling', 'Motor', 'Motor output', 'National Institute of Child Health and Human Development', 'Neurologic', 'Neuronal Plasticity', 'Outcome', 'Outcome Measure', 'Output', 'Participant', 'Patients', 'Personal Satisfaction', 'Persons', 'Physical Function', 'Probability', 'Process', 'Productivity', 'Prognostic Marker', 'Quality of life', 'Records', 'Recovery', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Residual state', 'Resolution', 'Retrospective Studies', 'Rogaine', 'Sensory', 'Signal Transduction', 'Spinal Cord', 'Spinal cord damage', 'Spinal cord injury', 'Statistical Data Interpretation', 'Structure', 'System', 'T2 weighted imaging', 'Testing', 'United States', 'United States National Institutes of Health', 'Upper Extremity', 'Walking', 'Work', 'analysis pipeline', 'base', 'deep learning', 'design', 'dorsal column', 'early detection biomarkers', 'expectation', 'functional independence', 'imaging Segmentation', 'improved', 'machine learning method', 'magnetic resonance imaging biomarker', 'motor deficit', 'motor function recovery', 'motor recovery', 'novel', 'open source', 'outcome forecast', 'physically handicapped', 'primary outcome', 'prognostic value', 'programs', 'prospective', 'rehabilitation strategy', 'restoration', 'secondary outcome', 'social', 'spinal cord imaging']",NICHD,REGIS UNIVERSITY,R03,2020,52775,0.021961144529046277
"An Interoperable HL7 FHIR-based Medical Device Data System (MDDS) For Accessing And Integrating Live Point-Of-Care Data From High-Acuity Bedside Patient Monitoring Equipment Abstract The overall goal of this proposal is to combine expertise and approaches from biomedical engineering and critical care medicine to design a universal system to acquire, record and transmit physiological signals from bedside monitored patients. Patient monitors generate over a million datapoints of information per hour, however, only a tiny fraction of those data are transmitted or recorded. In order to improve data exchange in healthcare, the Fast Healthcare Interoperability Resources (FHIR) standard was published in 2014. However, it has yet to make a significant impact on Medical Device Integration (MDI), which is the process of automating the flow of clinical data from bedside medical devices, such as patient monitors, to external systems such as Electronic Medical Records (EMR). Also, MDI is a complex task because data from these devices are high-frequency and high- volume and because most devices use proprietary protocols and outdated interfaces such as serial cables. Hospitals and researchers have therefore been left with few options except to use expensive and vendor-specific MDI solutions to access these data or to use manual data entry into the patient EMR, which leads to data entry errors, late entry of data, and lost time for clinical care. Manual data entry only captures a tiny fraction of the available data, and with increased research interest in Artificial Intelligence (AI) and Machine Learning, there is a growing need for a standardized way to access the vast amounts of data from bedside devices. This project will develop a vendor-neutral software-based Medical Device Data System (MDDS) that acquires and records data from bedside devices across a hospital network and makes live data available to 3rd party systems using a FHIR application programming interface (API). The proposed proof-of-concept will consist of three elements: [i] a transmitter which encrypts and transmits patient signals across the network, [ii] an aggregator which receives, translates and records the signals to a central location, and [iii] a FHIR Server with API for allowing external systems to access live data as FHIR resources. This proposal seeks to create a novel design that will overcome a critical barrier in healthcare, medicine and research. The proposed MDDS will be valuable to hospitals, clinicians, researchers and app developers because it makes data accessible which were previously only available to clinicians at the bedside in real-time. Narrative MediCollector’s proposed vendor-neutral medical device data system (MDDS) will be a valuable research tool to access, acquire and record high-frequency bedside patient monitor data for facilitating clinical research in hospitals. In addition, it will make live patient monitor data accessible to external systems through an HL7 FHIR application programming interface (API), thereby improving interoperability in hospitals and opening the doors to the integration of live data into external systems, such as smartphone apps and artificial intelligence algorithms, which can improve clinical workflow and healthcare in general.",An Interoperable HL7 FHIR-based Medical Device Data System (MDDS) For Accessing And Integrating Live Point-Of-Care Data From High-Acuity Bedside Patient Monitoring Equipment,10140938,R43EB030890,"['Artificial Intelligence', 'Beds', 'Biomedical Engineering', 'Boston', 'Client', 'Clinical', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'Computerized Medical Record', 'Critical Care', 'Data', 'Data Display', 'Devices', 'Documentation', 'Elements', 'Engineering', 'Environment', 'Equipment', 'Fast Healthcare Interoperability Resources', 'Frequencies', 'Goals', 'Healthcare', 'Hospitals', 'Hour', 'Information Systems', 'Instruction', 'Knowledge', 'Left', 'Location', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Medical', 'Medical Device', 'Medicine', 'Monitor', 'Patient Monitoring', 'Patients', 'Patients&apos', ' Rooms', 'Pediatric Hospitals', 'Physiological', 'Positioning Attribute', 'Problem Solving', 'Process', 'Protocols documentation', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Resources', 'Safety', 'Secure', 'Services', 'Signal Transduction', 'Standardization', 'Sum', 'System', 'Test Result', 'Testing', 'Time', 'Translating', 'Vendor', 'Ventilator', 'application programming interface', 'base', 'clinical care', 'clinically relevant', 'data access', 'data exchange', 'design', 'encryption', 'experience', 'graphical user interface', 'improved', 'intelligent algorithm', 'interest', 'interoperability', 'novel', 'point of care', 'sensor', 'smartphone Application', 'software systems', 'tool']",NIBIB,"MEDICOLLECTOR, LLC",R43,2020,210642,0.021370264293650625
"Closing the loop on markerless object tracking Abstract/Summary Tracking the movements of objects and parts of objects - referred to as pose estimation - is critical for understanding the mechanisms underlying complex behavior. Characterizing dynamic behaviors of animals (and other systems) is central to many disciplines, including computer science, physics, ethology, kinesiology, and sports medicine. Here we focus on neuroscience, where linking brain activity to associated dynamic behaviors is critical for both understanding normal function as well as effects of injury, disease, or degeneration. Invasive methods for measuring behavior are highly accurate, but require placement of sensors that may themselves interact with behavior and which may be susceptible to deterioration or infection. Video provides a non-invasive approach to characterizing behavior over time. Extracting behavior from video streams has, historically, been a slow and laborious process. Recent work in machine learning and artificial neural networks (ANNs), though, has revolutionized this process, making the analysis of complex video far easier and more accurate. While these systems are highly flexible, they were not designed for real time use, meaning that large video files must first be stored to disk for subsequent analysis. This poses two problems that this proposal will attempt to address. First, there is significant cost and management challenges associated with storage of large video stores, forming a practical barrier for adoption of this important technology for characterizing behavior. Second, estimates related to behavioral state are not available in real time so they cannot be used to control the experiment. We will develop a research methodology for “closing the loop”, by taking the networks trained by an existing and highly successful markerless object tracking system (DeepLabCut) and optimizing them for real time inference. After the system is functional, verified, and benchmarked, it will be shared with the community through open source repositories. Project Narrative Understanding the neural basis underlying complex behavior requires careful analysis of the dynamics of moving objects. Recent advances in computer vision has greatly facilitated our ability to track objects from video, but these tools are currently limited to offline analysis. Here we propose to build a system that addresses this problem by “closing the loop” using real time inference to be freely shared with the public to enhance ongoing research across the neuroscience spectrum.",Closing the loop on markerless object tracking,10047656,R03MH123990,"['Address', 'Adoption', 'Animal Behavior', 'Architecture', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Deterioration', 'Development', 'Discipline', 'Disease', 'Ensure', 'Ethology', 'Eye', 'Eye Movements', 'Freezing', 'Goals', 'Guidelines', 'Hand', 'Individual', 'Infection', 'Injury', 'Joints', 'Kinesiology', 'Label', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Modification', 'Monkeys', 'Movement', 'Neurosciences', 'Output', 'Performance', 'Physics', 'Process', 'Pupil', 'Research', 'Research Methodology', 'Research Personnel', 'Running', 'Sports Medicine', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Work', 'artificial neural network', 'base', 'computer science', 'cost', 'deep learning', 'design', 'experimental study', 'flexibility', 'gaze', 'haptics', 'open source', 'relating to nervous system', 'repository', 'sensor', 'time use', 'tool', 'virtual']",NIMH,BROWN UNIVERSITY,R03,2020,162500,-0.025621155758235863
"Touching on locomotion: an anatomical and functional analysis of spinal cord circuits that shape the way we move Project Summary/Abstract A central challenge in neuroscience biomedical research is to define the neural circuits that underlie behavior. Investigations of spinal cord circuits are ideally suited to answer these questions: the direct link between sensory input and motor output affords an exquisite experimental tractability that has been leveraged since Sherrington’s pioneering work on the proprioceptive reflex pathway1. Indeed, great progress has been made since then in understanding how proprioceptors (i.e., muscle sensory neurons) shape motor activity. Touch receptors in skin (i.e., cutaneous sensory neurons) encoding sensory modalities like vibration, indentation, and slip, are also critical for adapting the way we walk in response to changes in our environment. However, spinal cord integration of touch pathways that sculpt motor activity remains profoundly poorly understood. To address key conceptual and technical challenges in this field, we have built an extensive mouse genetic toolbox to visualize, quantify and manipulate touch-specific spinal cord circuits. In addition, we merge these powerful genetic tools with motor assays involving high-speed cameras, computer vision, and machine learning to quantify somatosensory behavior with unprecedented sensitivity. Combining these technologies, we identified a novel touch-specific premotor network important for sensorimotor function. Our overall hypothesis is that this network represents a critical node for integrating touch information to influence specific patterns of muscle groups that facilitate both corrective movements during locomotion and motor ‘switching’ during naturalistic behaviors. We interrogate this novel network to address fundamental questions whose answers will enable a deeper understanding of how touch pathways converge in the spinal cord to shape movement. In Aims 1 and 2 we combine genetic approaches, high-resolution synaptic analysis, slice electrophysiology and in-vivo muscle recordings to test the hypothesis that this network integrates multimodal sensory information to coordinate specific muscles in response to cutaneous input. Aim 3 combines joint and muscle activity recordings to test the hypothesis that this network shapes cutaneous responses to facilitate corrective movements during locomotion. We extend these behavioral studies by implementing computer vision and machine learning to parse out naturalistic behaviors into sub- second movements to test the hypothesis that touch-specific premotor networks sculpt how micro-movements are pieced together into complex motor behaviors . By understanding the final path for movement organization (i.e., the spinal cord) our research will lead to new therapies aimed at improving the quality of life of people suffering from a variety of neurological disorders. Thus, this research lays the critical foundation for novel ways to modulate spinal circuits for improving motor function. Project Narrative Our movements are shaped by sensory information, and though much progress has been made in understanding how proprioceptors (muscle sensory neurons) shape motor function, much less is known about how touch receptors (skin sensory neurons) influence motor pathways. To generate a complete picture of how sensory information affects motor actions, this project incorporates a multidisciplinary approach to provide a functional roadmap of how skin touch receptors interact with spinal cord motor centers to shape movement. By understanding the final path for movement organization (i.e., the spinal cord) our research lays the critical foundation for novel ways to modulate spinal circuits for improving motor function affected by disease or injury.",Touching on locomotion: an anatomical and functional analysis of spinal cord circuits that shape the way we move,10094597,R01NS119268,"['Address', 'Affect', 'Afferent Neurons', 'Anatomy', 'Behavior', 'Behavioral Assay', 'Biological Assay', 'Biomedical Research', 'Complex', 'Computer Vision Systems', 'Coupled', 'Cutaneous', 'Data', 'Disease', 'Electrophysiology (science)', 'Environment', 'Extensor', 'Flexor', 'Foundations', 'Genetic', 'Hindlimb', 'Individual', 'Injury', 'Interneurons', 'Investigation', 'Joints', 'Lateral', 'Length', 'Limb structure', 'Link', 'Locomotion', 'Machine Learning', 'Mechanics', 'Modality', 'Motor', 'Motor Activity', 'Motor Neurons', 'Motor Pathways', 'Motor output', 'Movement', 'Muscle', 'Muscle Contraction', 'Neurons', 'Neurosciences', 'Organ', 'Output', 'Parvalbumins', 'Pathway interactions', 'Pattern', 'Positioning Attribute', 'Property', 'Proprioception', 'Proprioceptor', 'Quality of life', 'Reflex action', 'Research', 'Resolution', 'Sensorimotor functions', 'Sensory', 'Shapes', 'Skin', 'Slice', 'Speed', 'Spinal', 'Spinal Cord', 'Spinal cord posterior horn', 'Structure', 'Synapses', 'Technology', 'Testing', 'Touch sensation', 'Walking', 'Work', 'behavioral study', 'cutaneous sensory neurons', 'electrical property', 'genetic approach', 'improved', 'in vivo', 'insight', 'interdisciplinary approach', 'motor behavior', 'motor function improvement', 'mouse genetics', 'multimodality', 'nervous system disorder', 'neural circuit', 'novel', 'novel strategies', 'novel therapeutics', 'programs', 'receptor', 'response', 'sensory input', 'sensory stimulus', 'somatosensory', 'tool', 'vibration']",NINDS,"RUTGERS, THE STATE UNIV OF N.J.",R01,2020,433281,-0.020679618316555484
"Abiotic-Biotic Interfaces for Ophthalmology Symposium ABSTRACT This proposal seeks funding to support a symposium, Abiotic-Biotic Interfaces for Ophthalmology (ABI), which will bring together recognized world experts in clinical, research, vision science, engineering, industrial and pharmaceutical communities as well as junior investigators (i.e., young faculty and those in training) to discuss the current state of ABI, ranging from bioelectronic implantable and wearable devices, to nanoscale scaffolds for stem cell and gene therapies. Given the multidisciplinary nature of this field, it is essential to bring together researchers and clinicians with varying levels of expertise across many domains related to ABI to advance the progress of this novel field, identify challenges of advancement, and develop a strategic action plan to overcome these challenges. The timing to have such a symposium to further the application of implantable and/or wearable bioengineered systems in ophthalmology is now as we focus on precision and personalized medicine and leverage the revolution in deep learning artificial intelligence algorithms. Through symposium talks, sessions, and discussions we will cover the fundamentals and also identify innovative and cutting-edge strategies and methodologies to accelerate the rate of major discoveries and development of novel therapeutics. The specific aims of this symposium are: Specific Aim 1. To bring together both established and junior investigators representing a broad range of disciplines to discuss cutting edge research in this novel field, catalyze the development of cross-disciplinary and translational approaches to advance abiotic-biotic interfaces for ophthalmology, and identify gaps in knowledge and barriers to advancement. We will identify research questions and develop an agenda to guide future research that is consistent with the objectives and interests of NEI. Specific Aim 2. Develop a junior investigator program to motivate a diverse group of students and junior investigators to pursue research careers in vision science and ophthalmologic therapeutic development, who will ultimately submit grant proposals to NEI solicitations and contribute to the scientific literature. Specific Aim 3. Develop a strategic action plan to set priorities for future studies that will encourage inter-agency collaborations (e.g., NEI, NSF, DARPA, etc.). This is critical because often certain engineering tasks are best suited to be supported by NSF or DARPA whereas the biological testing of the engineered systems lends itself to funding from NEI. Hence such inter-agency or cross-agency efforts can help leverage the funding to develop sophisticated abiotic-biotic systems NARRATIVE This meeting is the first on this topic dedicated to the broad use of implantable and/or wearable bioelectronics for ophthalmological applications. It is anticipated that the strategic action plan will significantly impact the field by greatly accelerating the translation of basic science and engineering research findings to stimulate the development of novel treatments and improve clinical practice. Key topics include visual restoration, drug and gene delivery, and sensing intraocular pressure. This meeting will foster training and development of future leaders in this emerging field and promote collaboration and exchange of knowledge and ideas among junior and established investigators.",Abiotic-Biotic Interfaces for Ophthalmology Symposium,10070800,R13EY031988,"['Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biological Testing', 'Biomedical Engineering', 'Cellular Phone', 'Clinical Research', 'Collaborations', 'Communities', 'Computer software', 'Contact Lenses', 'Custom', 'Data', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Drug Delivery Systems', 'Electronics', 'Engineering', 'Eye', 'Faculty', 'Fostering', 'Funding', 'Future', 'Gene Delivery', 'Glass', 'Industrialization', 'Intraocular lens implant device', 'Knowledge', 'Literature', 'Medicine', 'Methodology', 'Nature', 'Neural Retina', 'Ophthalmology', 'Optics', 'Pharmacologic Substance', 'Physiologic Intraocular Pressure', 'Physiological', 'Research', 'Research Personnel', 'Route', 'Scientific Inquiry', 'Scientist', 'Senior Scientist', 'Students', 'System', 'Time', 'Training', 'Translations', 'Virtual and Augmented reality', 'Visual', 'base', 'career', 'clinical practice', 'deep learning', 'gene therapy', 'implantable device', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'meetings', 'multidisciplinary', 'nanoscale', 'neural network', 'novel', 'novel therapeutics', 'personalized medicine', 'portability', 'precision medicine', 'programs', 'restoration', 'scaffold', 'stem cell therapy', 'symposium', 'therapeutic development', 'translational approach', 'vision science', 'wearable device']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R13,2020,42465,0.004032927087728196
"Topic 412: CHAMP-WARE: Continuous Health Monitoring and Predictions using a Wearables-Agnostics Platform for Cancer Patients, Phase I Commercially available off-the-shelves (COTS) wearables that objectively track physiological variables offer a rich source of information about a patient’s health to clinicians and oncology researchers, to facilitate early adverse-event detection and subsequent management, which can decrease healthcare costs and improve patient quality of life. The passive, continuously measured data streams generated by current or future COTS sensors will allow direct/indirect measures of cancer progression and its symptoms. Increased out-of-clinic patient and clinician engagement via these tools will allow more precise delivery of cancer care after as well as during cancer remission. Ultimately, these passive sensing platforms’ data for digital biomarkers will afford clinicians: 1) more objective metrics of response to therapeutics; 2) control and autoreporting of symptoms and their fluctuations; 3) monitoring of side-effects of experimental or standard of care therapies; and 4) more ecologically valid clinical endpoints, all decreasing assessment burden via increased continuity of physiological measurement sampling and patient context in the ambulatory setting. Furthermore, such data present an opportunity to measure population-based statistics from large cohorts of cancer patients by way of the myriad of devices currently available or being developed. Unfortunately, despite the availability of a myriad of COTS wearables capable of measuring physiological variables, their use for remote cancer patient monitoring or for out-of-clinic cancer research is yet to become mainstream. There is a considerable need for scalable informatics tools that allow automated data aggregation, integration and machine learning/artificial intelligence (AI)/predictive analytics that can pull from disparate data sets across COTS device vendors and have the flexibility to add new measures as they are developed. Furthermore, a central software platform is needed that could obtain wearable or external device data and uniformly compare/contrast/couple data streams to understand physiology versus patient context with respect to time: such a capability will substantially advance this unique approach to aid cancer patients, clinician assessment and clinical trial design. This work seeks to overcome these bottlenecks and provide a workflow and an infrastructure for out-of-clinic remote patient monitoring and online research collaboration for advancing population-based research. By developing a software system, comprised of a smartphone app, database, and a Web portal, which can a) collect and standardize raw sensor data from multitude of wearables, b) perform intelligent multi-sensor data analytics to provide clinically relevant outcomes in real time, c) store these data in a common repository, and d) provide online interfaces to view and analyze data, the proposed effort will significantly advance out-of-clinic cancer research and patient monitoring. n/a","Topic 412: CHAMP-WARE: Continuous Health Monitoring and Predictions using a Wearables-Agnostics Platform for Cancer Patients, Phase I",10265744,5N91020C00057,"['Adverse event', 'Algorithmic Analysis', 'Artificial Intelligence', 'Biological Markers', 'Cancer Patient', 'Cancer Remission', 'Clinic', 'Clinical', 'Clinical Trials Design', 'Collaborations', 'Computer software', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Detection', 'Devices', 'Documentation', 'Future', 'Health', 'Health Care Costs', 'Infrastructure', 'Intelligence', 'Internet', 'Machine Learning', 'Mainstreaming', 'Measurement', 'Measures', 'Monitor', 'Oncology', 'Outcome', 'Patient Monitoring', 'Patients', 'Phase', 'Physiological', 'Physiology', 'Population Research', 'Predictive Analytics', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Secure', 'Signal Transduction', 'Source', 'Standardization', 'Stream', 'Symptoms', 'System', 'Therapeutic', 'Time', 'Vendor', 'Work', 'anticancer research', 'cancer care', 'clinically relevant', 'cohort', 'data standards', 'data streams', 'data visualization', 'digital', 'flexibility', 'functional outcomes', 'improved', 'informatics tool', 'population based', 'prototype', 'repository', 'response', 'sensor', 'side effect', 'smartphone Application', 'software systems', 'standard of care', 'statistics', 'tool', 'tumor progression', 'web portal']",NCI,"INTELLIGENT AUTOMATION, INC.",N43,2020,399980,0.01800026540175576
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9899994,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2020,416374,0.0057228543458006645
"Machine-learning based control of functional electrical stimulation PROJECT SUMMARY/ABSTRACT Functional electrical stimulation involves artificial activation of paralyzed muscles with implanted electrodes and has been used successfully to improve the ability of tetraplegics to perform movements important for daily activities. The range of motor behaviors that can be generated by functional electrical stimulation, however, is limited to a relatively small set of preprogrammed movements such as hand grasp and release. A broader range of movements has not been implemented because of the substantial challenge associated with identifying the patterns of muscle stimulation needed to elicit specified movements. To address this limitation, we have developed machine-learning based algorithms that can predict patterns of muscle activity associated with a wide range of complex limb movements. In addition, we have devised a method whereby predicted patterns of muscle activity can then be transformed into stimulus pulse patterns needed to evoke movements in paralyzed limbs. Our goal for this project is to determine whether these approaches, when applied to temporarily paralyzed non-human primates, can be used to produce: 1) a wide range of movements of the hand throughout peri-personal reach space, and 2) configuration of the hand and fingers into a variety of shapes needed to interact with diverse objects in the environment. If successful, this approach would greatly expand the repertoire of motor behaviors available to individuals paralyzed because of spinal cord injury or stroke. Furthermore, this system ultimately might serve as the requisite interface between brain-derived trajectory information and functional electrical stimulation systems needed to realize a self-contained and self- controlled upper limb neuroprosthetic. PROJECT NARRATIVE The goal of this project is to develop methods to artificially activate and control paralyzed muscles with electrodes implanted in muscles. This effort will contribute to the restoration of voluntary limb movements in individuals paralyzed because of spinal cord injury or stroke.",Machine-learning based control of functional electrical stimulation,9878937,R01NS102259,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Animals', 'Back', 'Brain', 'Chronic', 'Complement', 'Complex', 'Data', 'Digit structure', 'Elbow', 'Electrodes', 'Elements', 'Environment', 'Error Sources', 'Experimental Models', 'Feedback', 'Fingers', 'Forearm', 'Goals', 'Hand', 'Health Benefit', 'Human', 'Implanted Electrodes', 'Individual', 'Intramuscular', 'Joints', 'Lifting', 'Limb structure', 'Macaca mulatta', 'Machine Learning', 'Measures', 'Methods', 'Monkeys', 'Motor', 'Movement', 'Muscle', 'Muscle Contraction', 'Muscle Fatigue', 'Output', 'Paralysed', 'Patients', 'Pattern', 'Personal Space', 'Physiologic pulse', 'Quadriplegia', 'Shapes', 'Shoulder', 'Signal Transduction', 'Skeletal Muscle', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Training', 'Upper Extremity', 'Wrist', 'arm', 'artificial neural network', 'awake', 'base', 'brain machine interface', 'design', 'experience', 'finger movement', 'functional electrical stimulation', 'grasp', 'hand grasp', 'human subject', 'improved', 'insight', 'kinematics', 'limb movement', 'machine learning algorithm', 'motor behavior', 'neuroprosthesis', 'nonhuman primate', 'response', 'restoration', 'robotic device', 'scapula']",NINDS,UNIVERSITY OF ARIZONA,R01,2020,301922,0.02230006072403384
"Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit SUMMARY  Many of the estimated four million adults in the U.S. with severe speech and physical impairments (SSPI) resulting from neurodevelopmental or neurodegenerative diseases cannot rely on current assistive technologies (AT) for communication. During a single day, or as their disease progresses, they may transition from one access technology to another due to fatigue, medications, changing physical status, or progressive motor dysfunction. There are currently no clinical or AT solutions that adapt to the multiple, dynamic access needs of these individuals, leaving many people poorly served. This competitive renewal, called BCI-FIT (Brain Computer Interface-Functional Implementation Toolkit) adds to our innovative multidisciplinary translational research conducted over the past 11 years for the advancement of science related to non-invasive BCIs for communication for these clinical populations. BCI-FIT relies on active inference and transfer learning to customize a completely adaptive intent estimation classifier to each user's multiple modality signals in real-time. The BCI-FIT acronym has many implications: our BCI fits to each user's brain signals; to the environment, offering relevant personal language; to the user's internal states, adjusting signals based on drowsiness, medications, physical and cognitive abilities; and to users' learning patterns from BCI introduction to expert use.  Three specific aims are proposed: (1) Develop and evaluate methods for optimizing system and user performance with on-line, robust adaptation of multi-modal signal models. (2) Develop and evaluate methods for efficient user intent inference through active querying. (3) Integrate language interaction and letter/word supplementation as input modalities in real-time BCI use. Four single case experimental research designs will evaluate both user performance and technology performance for functional communication with 35 participants with SSPI in the community, and 30 healthy controls for preliminary testing. The same dependent variables will be tested in all experiments: typing accuracy (correct character selections divided by total character selections), information transfer rate (ITR), typing speed (correct characters/minute), and user experience (UX) questionnaire responses about comfort, workload, and satisfaction. Our goal is to establish individualized recommendations for each user based on a combination of clinical and machine expertise. The clinical expertise plus user feedback added to active sensor fusion and reinforcement learning for intent inference will produce optimized multi-modal BCIs for each end-user that can adjust to short- and long-term fluctuating function. Our research is conducted by four sub-teams who have collaborated successfully to implement translational science: Electrical/computer engineering; Neurophysiology and systems science; Natural language processing; and Clinical rehabilitation. The project is grounded in solid machine learning approaches with models of participatory action research and AAC participation. This project will improve technologies and BCI technical capabilities, demonstrate BCI implementation paradigms and clinical guidelines for people with severe disabilities. PROJECT NARRATIVE The populations of US citizens with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies, as proposed in BCI-FIT. This project implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit,10044301,R01DC009834,"['Adult', 'Attention', 'Behavioral', 'Brain', 'Calibration', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communication', 'Communities', 'Computers', 'Custom', 'Data', 'Decision Making', 'Disease', 'Drowsiness', 'Electroencephalography', 'Engineering', 'Environment', 'Eye Movements', 'Fatigue', 'Feedback', 'Goals', 'Guidelines', 'Head Movements', 'Impairment', 'Individual', 'Informed Consent', 'Knowledge', 'Language', 'Learning', 'Letters', 'Life', 'Locked-In Syndrome', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Motor Skills', 'Movement', 'Muscle', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Participant', 'Partner Communications', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Population', 'Protocols documentation', 'Psychological Transfer', 'Psychological reinforcement', 'Public Health', 'Questionnaires', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Design', 'Role', 'Science', 'Secondary to', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Solid', 'Source', 'Speech', 'Speed', 'Supplementation', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vocabulary', 'Workload', 'acronyms', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinical implementation', 'cognitive ability', 'community based participatory research', 'computer science', 'disability', 'experience', 'experimental study', 'improved', 'innovation', 'learning strategy', 'motor disorder', 'multidisciplinary', 'multimodality', 'neurophysiology', 'phrases', 'residence', 'response', 'satisfaction', 'sensor', 'signal processing', 'simulation', 'spelling', 'theories', 'visual tracking']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,929399,-0.02459890804743672
"Population Invariant Neural Decoding Neural interfaces hold great potential to restore movement and communication function in millions of patients with paralysis, neuromuscular disorders, traumatic brain injury, stroke, or communication disorders. These systems rely on neural decoding algorithms to translate recorded neural activity into, for example, movements of a prosthetic limb or intended speech sounds. However, many technical challenges limit the predictive accuracy of these decoding models, preventing widespread deployment of restorative neuroprosthetic devices. A key challenge is the limited data available to train decoding models. In existing approaches, models must be trained separately for each individual subject, usually during simple behavioral tasks, and consequently fail to generalize well to new subjects or complex naturalistic behavioral settings. This proposal leverages recent advances in machine learning that directly address these limitations by developing a new decoding model framework that is capable of combining neural data across many subjects and tasks, as well as incorporating large-scale simulated data to improve prediction accuracy. In this framework, a single global model learns an internal representation of the neural system that is invariant to variations in behavioral task and stimulus set, anatomical variations, and functional variations in neural tuning of the underlying neuronal population (i.e., population-invariant neural decoding). This global model can therefore be applied and calibrated to new subjects and behavioral tasks where little or no additional training data is available. Using an existing intracranial neural data set collected from a large number of different subjects and stimulus sets, the project will establish this new modeling approach based on deep learning architectures that are explicitly designed to incorporate data pooled across subjects and tasks. We propose to show, through validation on measured intracranial neural data, that a global neuronal population-invariant decoding model substantially improves model prediction accuracy and generalization relative to existing state-of-the-art neural decoding models across many subjects. Development and validation of this approach will open new avenues for researchers to combine disparate data sets, for example, enabling community development, improvement, and sharing of “open source” models that can be shared among research groups and effectively applied across research studies. Thus, the proposal seeks to address key limitations in present neural decoding model approaches which must ultimately convert measured neural activity into useful behavioral or communication parameters across a wide range of subjects and complex behaviors in order for translational effects to be realized in important clinical applications of neural interfaces. Neural interfaces rely on predictive models to restore lost motor or communication function in millions of patients with paralysis, neuromuscular disorders, traumatic brain injury, stroke, or communication disorders. This project leverages novel machine learning models that allow neural data to be pooled across large-scale multi-subject data sets, permitting an order of magnitude increase in model complexity and prediction accuracy that is immediately generalizable across large patient populations with disordered speech or motor function. The outcome of this project is a new modeling framework where a single, highly performant global model can be easily calibrated to individual patient cases with limited data while maintaining high prediction accuracy.",Population Invariant Neural Decoding,9874435,R21DC018374,"['Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Auditory', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Cognitive', 'Communication', 'Communication impairment', 'Community Developments', 'Complex', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electrodes', 'Engineering', 'Experimental Designs', 'Human', 'Individual', 'Industry', 'Institution', 'Learning', 'Limb Prosthesis', 'Location', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Movement', 'Neuromuscular Diseases', 'Neurons', 'Neurosciences', 'Outcome', 'Paralysed', 'Patients', 'Performance', 'Population', 'Research', 'Research Personnel', 'Self-Help Devices', 'Sensory', 'Speech', 'Speech Disorders', 'Speech Sound', 'Statistical Data Interpretation', 'Stimulus', 'Stroke', 'System', 'Techniques', 'TensorFlow', 'Training', 'Translating', 'Traumatic Brain Injury', 'Validation', 'Variant', 'Work', 'base', 'clinical application', 'clinically relevant', 'data sharing', 'deep learning', 'design', 'experimental study', 'improved', 'individual patient', 'large datasets', 'neuroprosthesis', 'novel', 'open source', 'patient population', 'predictive modeling', 'premonitory sensory phenomena', 'prevent', 'relating to nervous system', 'research study', 'success', 'tool']",NIDCD,UNIVERSITY OF CALIFORNIA BERKELEY,R21,2020,235500,-0.038095761033252615
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Abstract COVID-19 has made traveling as a blind or visually impaired person much riskier and more difficult than before the pandemic. As a result, people with visual impairments may limit their essential travel such as trips to the doctor’s office, the pharmacy and grocery shopping and walks for exercise or leisure. Accordingly, the goal of this COVID Supplement, which builds on and expands the work being conducted by the parent grant, is to develop a COVID map tool that provides fully accessible, non-visual access to maps. This tool will allow visually impaired persons to explore maps and preview routes from the comfort of their home, allowing them to plan their travel along safer, less congested routes using crowdedness data. In addition, the tool will present county-by-county COVID incidence data in a fully accessible form, which will inform their travel plans over greater distances. Thus, this project will give visually impaired persons the tools and confidence to undertake safer, more independent travel. Health Relevance The COVID-19 pandemic has an especially severe impact on people with significant vision impairments or blindness. The need for social distancing and reduced touching of one’s surroundings has made traveling as a blind or visually impaired person much riskier and more difficult than before the pandemic. As a result, people with visual impairments may limit their essential travel such as trips to the doctor’s office, the pharmacy and grocery shopping and walks for exercise or leisure. These travel limitations may have adverse impacts on their physical and mental health. The proposed research would result in a new software tool that could greatly increase the confidence of the approximately 10 million Americans with significant vision impairments or blindness to undertake safe, independent travel.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,10220178,R01EY029033,"['American', 'Blindness', 'COVID-19', 'COVID-19 pandemic', 'Cellular Phone', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'County', 'Crowding', 'Data', 'Destinations', 'Development', 'Ensure', 'Evaluation', 'Exercise', 'Goals', 'Health', 'Home environment', 'Incidence', 'Internet', 'Knowledge', 'Leisures', 'Maps', 'Mental Health', 'Pharmacy facility', 'Process', 'Publications', 'Research', 'Route', 'Running', 'Social Distance', 'Software Tools', 'System', 'Tablets', 'Tactile', 'Target Populations', 'Touch sensation', 'Travel', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'blind', 'braille', 'coronavirus disease', 'design', 'outreach', 'pandemic disease', 'parent grant', 'physical conditioning', 'software development', 'symposium', 'tool', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2020,406525,0.0065461494846439285
"Characterizing the structure of motor cortex activity across multiple behaviors for improved brain-machine interfaces Project Abstract. Candidate and career goals: I am an engineer by training, with a strong background in neural engineering and the development of motor brain-machine interfaces (BMIs). My career goal is to establish an independent nonhuman primate (NHP) laboratory with two primary aims. First, I will advance our fundamental understanding of the motor system via the combination of electrophysiology with novel statistical and computational methods. Second, I will leverage this knowledge to develop frameworks for superior BMI systems.  Throughout my academic and research career I have developed expertise in engineering, computation, and neuroscience with the goal of pursuing these aims. Advances in machine learning, large-scale neural recordings, and deep learning in neural networks are happening quickly (in part via the BRAIN Initiative), and are very promising for the field. Yet very few researchers have the correct combination of skills to make use of them in my areas of interest. In completing the proposed training, I will be uniquely positioned to perform the innovative work necessary to advance our understanding of the planning and execution of cortically controlled movements. I will train the next generation of scientists and engineers in the experimental and computational methods necessary to understand fundamental principles of cortical computations.  Research plan: In this project, I will employ multiple computational approaches to understand the structure of population activity in motor cortex (M1) across multiple kinds of behaviors. I will then use that knowledge to create high performance BMI decoders that will be applicable to a wide range of movements.  Recent empirical observations are changing our view of the structure of M1 activity. During one particular task (e.g., reaching), neural activity may seem to exist within a small space that it explores completely. Yet as more tasks are observed, it becomes clear that activity comprises a highly structured geometry within a much larger space. This means that activity patters for different movements do not come ‘near’ one another or overlap. While counterintuitive, this geometry yields new opportunities. By exploiting the separation of activity patterns, movements can be readily distinguished, even when unfolding simultaneously. I will further explore this geometry across multiple behaviors, both in primates and neural network models, to develop new BMI methods. The specific aims of the plan are to (1) create a high-performance decoder for a novel wheelchair-relevant navigation task, (2) build network models to understand M1 activity structure and identify decoding principles that will generalize across tasks (reaching, navigation), and (3) implement a multitask BMI using a unified decoder that allows animals to both navigate and interact with objects. Career development plan: I will be trained by Dr. Mark Churchland and Dr. Larry Abbott at Columbia University. Project Narrative Brain-machine interfaces (BMIs) interpret brain activity to control external devices (computers, prosthetic limbs), and can restore voluntary movement to individuals with limb loss or paralysis. BMIs for reaching and grasping have been demonstrated in human clinical trials, and must now be extended to perform a variety of movements. The proposed work will use advanced computational methods to create an intuitively controllable and high performance BMI system applicable to many natural movements, including locomotion. This work will both develop neurotechnology, and add to our scientific understanding of the computational principles that underlie activity in motor cortex.",Characterizing the structure of motor cortex activity across multiple behaviors for improved brain-machine interfaces,9952827,K99NS115919,"['Address', 'Adopted', 'Animals', 'Area', 'BRAIN initiative', 'Back', 'Base of the Brain', 'Behavior', 'Behavioral', 'Biomimetics', 'Brain', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Development Plans', 'Devices', 'Electrophysiology (science)', 'Engineering', 'Future', 'Geometry', 'Goals', 'Human', 'Individual', 'Intuition', 'Investigation', 'Knowledge', 'Laboratories', 'Limb Prosthesis', 'Limb structure', 'Locomotion', 'Machine Learning', 'Mentors', 'Methods', 'Monkeys', 'Motor', 'Motor Cortex', 'Motor output', 'Movement', 'Muscle', 'Neural Network Simulation', 'Neurons', 'Output', 'Paralysed', 'Pattern', 'Performance', 'Periodicity', 'Persons', 'Population', 'Positioning Attribute', 'Primates', 'Research', 'Research Personnel', 'Scientist', 'Signal Transduction', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Wheelchairs', 'Work', 'base', 'brain machine interface', 'career', 'career development', 'combat', 'computational neuroscience', 'deep learning', 'density', 'design', 'flexibility', 'grasp', 'improved', 'innovation', 'interest', 'meetings', 'mind control', 'multitask', 'network models', 'neural network', 'neuroregulation', 'neurotechnology', 'next generation', 'nonhuman primate', 'novel', 'patient population', 'relating to nervous system', 'response', 'simulation', 'skills', 'theories', 'virtual', 'virtual reality environment', 'virtual world']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K99,2020,136242,0.015340312177332406
"Next generation brain-machine interfaces controlled synergistically with artificial intelligence PROJECT SUMMARY Over 5 million people in the USA – nearly 1 person in 50 – live with a form of paralysis due to causes including stroke, spinal cord injury, multiple sclerosis, and ALS. People who have lost the ability to move also lose a profound sense of control, freedom, and independence in their lives. But paralysis does not take away one's intent or desire to move; the brain still encodes these thoughts through neural signals. Brain-machine interfaces (BMIs) aim to restore the ability to communicate with the world by translating these neural signals into actions. BMIs decode neural signals into the movements of a computer cursor on a screen or a robotic arm, allowing the user to interact with the world autonomously. While BMIs have existed for over two decades, they have remained in pilot clinical trials dating back to 2004 and have not achieved widespread use. The key reason for this is that BMI performance has not achieved levels of performance that overcome their costs and risks. This is true for both invasive BMIs requiring neurosurgery, as well as for non-invasive BMIs, which can be used without surgical procedures but achieve low performance. This proposal aims to dramatically increase the quality of life for millions with paralysis by making widely accessi- ble BMIs available within the next ﬁve years. To achieve this groundbreaking goal, there needs to be a paradigm shift in the way BMIs fundamentally operate. Revolutionary next generation BMIs making signiﬁcant impact must be designed to: (1) achieve categorically unprecedented performance not possible with current BMI systems (e.g., over an order of magnitude improvement) and (2) minimize cost to patients, ideally being non-invasive. En- tirely novel BMI architectures are needed to fundamentally transcend a performance vs cost trade-off, achieving excellent performance at lower risks and costs. To meet this need, I propose to develop a next-generation BMI where the user and an artiﬁcial intelligence (AI) agent synergistically cooperate. We term this an “AI-BMI.” The AI agent predicts the user's intended motor actions and synergistically helps to complete them. Critically, the AI agent aids the precise and detailed execution of the user's intended movements, augmenting performance. By doing so, this architecture fundamentally changes the design objectives of BMIs from neural decoding of precise movements (difﬁcult) to behavioral and neural inference of the user's intent (easier). Non-invasive AI-BMIs, if successful, would be transformative, enabling next generation BMI technology that allows people with paralysis to once again move, but mitigates medical risks associated with neurosurgery and lowers system costs. PROJECT NARRATIVE For people who have lost the ability to move due to movement disorders, including paralysis and ALS, brain- mahince interfaces (BMIs) aim to restore movement and communication by decoding neural activity from motor regions of the brain to control prosthetic devices. The proposed work aims to create and optimize a new class of transformative BMIs that incorporate an external artiﬁcial intelligence agent who infers the user's intent and helps to carry out prosthesis actions. If successful, these new BMIs would signiﬁcantly increase BMI performance while lowering risks and costs, enabling widespread use.",Next generation brain-machine interfaces controlled synergistically with artificial intelligence,10003004,DP2NS122037,"['Architecture', 'Artificial Intelligence', 'Back', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Clinical Trials', 'Communication', 'Computers', 'Freedom', 'Goals', 'Medical', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Multiple Sclerosis', 'Operative Surgical Procedures', 'Paralysed', 'Patients', 'Performance', 'Persons', 'Prosthesis', 'Quality of life', 'Risk', 'Robotics', 'Spinal cord injury', 'Stroke', 'System', 'Technology', 'Thinking', 'Transcend', 'Translating', 'Work', 'arm', 'brain machine interface', 'cost', 'design', 'intelligent agent', 'neurosurgery', 'neurotransmission', 'next generation', 'novel', 'prosthesis control', 'relating to nervous system']",NINDS,UNIVERSITY OF CALIFORNIA LOS ANGELES,DP2,2020,2340000,0.022302270956624168
"User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control ABSTRACT Approximately 41,000 individuals live with upper-limb loss (loss of at least one hand) in the US. Fortunately, prosthetic devices have advanced considerably in the past decades with the development of dexterous, anthropomorphic hands. However, potentially the most promising used control strategy, myoelectric control, lacks a correspondingly high-level of performance and hence the use of dexterous hands remains highly limited. The need for a complete overhaul in upper limb prosthesis control is well highlighted by the abandonment rates of myoelectric devices, which can reach up to 40% in the case of trans-humeral amputees. The area of research that has received the most focus over the past decade has been “pattern recognition,” which is a signal processing based control method that uses multi-channel surface electromyography as the control input. While pattern recognition provides intuitive operation of multiple prosthetic degrees of freedom, it lacks robustness and requires frequent, often daily calibration. Thus, it has not yet achieved the desired clinical acceptance. Our team proposes clinical translation of a novel highly adaptive upper limb prosthesis control system that incorporates two major advances: 1) machine learning (robust classification by implementing a non-boundary based algorithm), and 2) training by retrospectively incorporating user data from activities of daily living (ADL). The proposed system will enable machine intelligence with user input for prosthesis control. Our work is organized as follows: Phase I: (a) First, we will implement a fundamentally new machine intelligence technique, Extreme Learning Machine with Adaptive Sparse Representation Classification (EASRC), that is more resilient to untrained noisy conditions that users may encounter in the real-world and requires less data than traditional myoelectric signal processing. (b) In parallel, we will implement an adaptive learning algorithm, Nessa, which allows users to relabel misclassified data recorded during use and then update the EASRC classifier to adapt to any major extrinsic or intrinsic changes in the signals. Taken together, EASRC and Nessa comprise the Retrospectively Supervised Classification Updating (RESCU) system. Once, the RESCU implementation is complete, we will optimize the system through a joint effort with Johns Hopkins University, and complete an iterative benchtop RESCU evaluation with a focus group of 3 amputee subjects and their prosthetists. Phase II: Verification and validation of RESCU will be completed, culminating in third-party validation testing and certification. Finally, we will complete a clinical assessment including self-reporting subjective measures, and real-world usage metrics in a long-term clinical study. PROJECT NARRATIVE In this project, we aim to empower the user by bringing them into the control loop of their prosthesis and improve the stability of their control strategy over time. Specifically, we implement to a robust classifier, an adaptive learning algorithm, and a smartwatch interface, which allows the user to teach their device when it misunderstands the commands that the user is sending to control the prosthesis. This will result in improved control without cumbersome or time-consuming effort on the part of the user and, more importantly, we hope that it will give the user a greater sense of empowerment and ownership over their prosthesis.",User-driven Retrospectively Supervised Classification Updating (RESCU) system for robust upper limb prosthesis control,10078697,U44NS108894,"['Activities of Daily Living', 'Adoption', 'Algorithms', 'Amputees', 'Area', 'Artificial Intelligence', 'Award', 'Calibration', 'Certification', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Communication', 'Consumption', 'Data', 'Development', 'Devices', 'Electromyography', 'Evaluation', 'Focus Groups', 'Freedom', 'Goals', 'Hand', 'Individual', 'Intuition', 'Joints', 'Label', 'Limb Prosthesis', 'Machine Learning', 'Measures', 'Methods', 'Outcome', 'Ownership', 'Parents', 'Patient Self-Report', 'Pattern Recognition', 'Performance', 'Phase', 'Prosthesis', 'Research', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Supervision', 'Surface', 'Surveys', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'Upper Extremity', 'Validation', 'Work', 'adaptive learning', 'base', 'clinical translation', 'empowerment', 'functional improvement', 'improved', 'innovation', 'intelligent algorithm', 'learning algorithm', 'myoelectric control', 'novel', 'operation', 'programs', 'prospective', 'prosthesis control', 'satisfaction', 'signal processing', 'smart watch', 'verification and validation']",NINDS,"INFINITE BIOMEDICAL TECHNOLOGIES, LLC",U44,2020,64079,0.026917327541462074
"Dense life-log health analytics from wearable senors using functional analysis and Riemannian geometry The growth and acceptance of wearable devices (e.g., accelerometers) and personal technologies (e.g., smartphones), coupled with larger storage capacities, waterproofing, and more unobtrusive wear locations, has made long-term monitoring of behaviors throughout the 24-hour spectrum more feasible. Wearable devices relevant for human activity (e.g., GENEActiv accelerometer) contain several complementary sensors (accelerometers, gyro, heart- rate monitor etc.) and sample at high rates (e.g., 100Hz for accelerometer). These high-sampling rates and the long duration of capture result in life-log data that truly qualifies as multimodal and big time-series data. The challenges and opportunities involved in fully harvesting these types of data, for widely applicable interventions, suggest that an interdisciplinary approach spanning mathematical sciences, signal processing, and health is needed. Our innovation includes the use of functional-data analysis tools to represent and process the dense time-series data. Functional data analysis is then integrated into machine learning and pattern discovery algorithms for activity classification, prediction of attributes, and discovery of new activity classes. We anticipate that the proposed framework will lead to new insights about human activity and its impact on health outcomes. This interdisciplinary project builds on several research activities of the team. Our past work includes: a) new mathematical developments for computing statistics on time-series data viewed as elements of a function-spaces, b) algorithms for activity recognition that integrate the function-space techniques, and c) data from long-term observational studies of human activity from multimodal sensors. The new work we propose addresses the unique mathematical and computational challenges posed by densely multimodal, long-term, densely-sampled Iifelog big-data in a comprehensive framework. The fusion of ideas from human activity modeling, functional-analysis, geometric metrics, and algorithmic machine learning, present unique opportunities for fundamental advancement of the state-of-the-art in objective measurement and quantification of behavioral markers from wearable devices. The proposed approach also brings to fore: a) new mathematical developments of elastic metrics over multi-modal time-series data, b) comparing sequences evolving on different feature manifolds, c) estimation of quasi- periodicities, d) and a new generation of machine-learning and pattern discovery algorithms. The mathematical and algorithmic tools proposed have the potential to significantly advance how wearable data from contemporary devices with high-sampling rates and large storage capabilities are represented, processed, and transformed into accurate inferences about human activity. Wearable devices are becoming more widely adopted in recent years for general health and recreational uses by the broad populace. This research will result in improved algorithms to process the data available from such wearable devices. The long-term goal of the research is to enable personalized home-based physical activity regimens for conditions such as stroke and diabetes. n/a",Dense life-log health analytics from wearable senors using functional analysis and Riemannian geometry,10023190,R01GM135927,"['Accelerometer', 'Address', 'Adopted', 'Algorithmic Software', 'Algorithms', 'Behavior monitoring', 'Behavioral', 'Big Data', 'Cellular Phone', 'Classification', 'Coupled', 'Data', 'Data Analyses', 'Development', 'Devices', 'Diabetes Mellitus', 'Elements', 'Generations', 'Geometry', 'Goals', 'Growth', 'Harvest', 'Health', 'Home environment', 'Hour', 'Human Activities', 'Intervention', 'Life', 'Location', 'Machine Learning', 'Mathematics', 'Measurement', 'Modeling', 'Observational Study', 'Outcome', 'Pattern', 'Periodicity', 'Physical activity', 'Process', 'Regimen', 'Research', 'Research Activity', 'Sampling', 'Series', 'Stroke', 'Techniques', 'Technology', 'Time', 'Work', 'base', 'heart rate monitor', 'improved', 'innovation', 'insight', 'interdisciplinary approach', 'machine learning algorithm', 'mathematical algorithm', 'mathematical sciences', 'multimodality', 'sensor', 'signal processing', 'statistics', 'tool', 'wearable device']",NIGMS,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,311680,0.007558217446197705
"Improved AD/ADRD Assessment Sensitivities Using a Novel In-Situ Sensor System Project Summary/Abstract  Accurate assessment of daily functions for individuals at risk for and with AD/ADRD, is fundamental to detection, diagnosis, and characterization of its progression and prescribed treatments. Current assessment techniques typically rely on non- continuous, discreet observations provided from a third party and covering single or limited performance domains. With significantly larger portions of American’s choosing to age in place, any assessment technology must be able to be in-situ (low-cost, ubiquitous) and operate without user interface (autonomous) to provide objective, cross-domain, and continuous daily function measurements and reporting.  The primary objective of this fast track SBIR project is to demonstrate the feasibility and effectiveness of using the Birkeland Current Sovrin IoT system to continuously and accurately assess daily functions, ADLs, and IADLs, for persons experiencing cognitive decline in a home or assisted care settings. This includes direct comparison with an accepted assessment technique, ADCS-ADL/23. Machine learning and artificial intelligent techniques will be employed to identify novel subfactors for improved sensitivities from available sensor data combinations. Secondary objectives include establishing a significant data set of detailed daily actions (<10 sec resolution) for 100+ individuals with AD/ADRD. Long-term goals support future intervention studies through improved assessment tools with enhanced sensitivity to early and mid-stage decline.  The Birkeland Current Sovrin IoT system makes use of patented proximity-based energy monitoring and control sensors, data analytics and change detection algorithms to continuously monitor activities of individuals in a home or assisted care environment. Intelligent power-strips and battery-based sensors located throughout the home or facility, monitor real time absolute location of individuals, caregivers, and devices they interact with. Correlation of high-fidelity data allows accurate determination of activities, attribution to a specific individual, mobility measurement, and behavior assessment across traditional and novel ADL/IADL categories. Birkeland Current is teamed with Texas A&M Center for Population Health and Aging, Georgia, Tech Institute for People and Technology, Baylor Scott and White Division of Gerontology, and multiple home-care and assisted-care facilities, in the development of the study approach, implementation plan, analytics tools, and applications to aging populations and future intervention studies. Project Narrative  The proposed research would utilize novel, ubiquitous Internet-of-Things sensors and automated analytics to demonstrate enhanced sensitivity and future utility of continuous in-situ IADL/ADL data for dementia research and its effectiveness in characterizing interventions for Alzheimer’s and related dementias of aging populations in support of NIA stated priorities.",Improved AD/ADRD Assessment Sensitivities Using a Novel In-Situ Sensor System,10131376,R44AG065118,"['Address', 'Adoption', 'Aging', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'American', 'Artificial Intelligence', 'Assessment tool', 'Behavior assessment', 'Behavioral Symptoms', 'Caregivers', 'Caring', 'Categories', 'Centers for Population Health', 'Classification', 'Communities', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Dementia', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Early Diagnosis', 'Early identification', 'Effectiveness', 'Environment', 'Future', 'Gerontology', 'Goals', 'Grouping', 'Health care facility', 'Home environment', 'Impaired cognition', 'In Situ', 'Individual', 'Industry', 'Institutes', 'Intelligence', 'Internet of Things', 'Intervention', 'Intervention Studies', 'Legal patent', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Monitor', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phase', 'Population', 'Problem Solving', 'Protocols documentation', 'Publishing', 'Recommendation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Risk', 'Series', 'Small Business Innovation Research Grant', 'System', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Texas', 'Time', 'Training', 'United States National Institutes of Health', 'Use Effectiveness', 'aging in place', 'aging population', 'analytical tool', 'base', 'cost', 'daily functioning', 'data acquisition', 'data integration', 'database structure', 'design', 'experience', 'improved', 'insight', 'instrumental activity of daily living', 'learning algorithm', 'novel', 'patient home care', 'personalized care', 'real time monitoring', 'sensor', 'symposium', 'tool']",NIA,BIRKELAND CURRENT LLC,R44,2020,1992588,-0.010115058097635144
"Dense Life-log Health Analytics from Wearable Sensors using Functional Analysis and Riemannian Geometry Project Summary The growth and acceptance of wearable devices (e.g., accelerometers) and personal technologies (e.g., smartphones), coupled with larger storage capacities, waterproofing, and more unobtrusive wear locations, has made long-term monitoring of behaviors throughout the 24-hour spectrum more feasible. Wearable devices relevant for human activity (e.g., GENEActiv accelerometer) contain several complementary sensors (accelerometers, gyro, heart- rate monitor etc.) and sample at high rates (e.g., 100Hz for accelerometer). These high-sampling rates and the long duration of capture result in life-log data that truly qualifies as multimodal and big time-series data. The challenges and opportunities involved in fully harvesting these types of data, for widely applicable interventions, suggest that an interdisciplinary approach spanning mathematical sciences, signal processing, and health is needed. Our innovation includes the use of functional-data analysis tools to represent and process the dense time-series data. Functional data analysis is then integrated into machine learning and pattern discovery algorithms for activity classification, prediction of attributes, and discovery of new activity classes. We anticipate that the proposed framework will lead to new insights about human activity and its impact on health outcomes. This interdisciplinary project builds on several research activities of the team. Our past work includes: a) new mathematical developments for computing statistics on time-series data viewed as elements of a function-spaces, b) algorithms for activity recognition that integrate the function-space techniques, and c) data from long-term observational studies of human activity from multimodal sensors. The new work we propose addresses the unique mathematical and computational challenges posed by densely multimodal, long-term, densely-sampled lifelog big-data in a comprehensive framework. The fusion of ideas from human activity modeling, functional-analysis, geometric metrics, and algorithmic machine learning, present unique opportunities for fundamental advancement of the state-of-the-art in objective measurement and quantification of behavioral markers from wearable devices. The proposed approach also brings to fore: a) new mathematical developments of elastic metrics over multi-modal time-series data, b) comparing sequences evolving on different feature manifolds, c) estimation of quasi- periodicities, d) and a new generation of machine-learning and pattern discovery algorithms. The mathematical and algorithmic tools proposed have the potential to significantly advance how wearable data from contemporary devices with high-sampling rates and large storage capabilities are represented, processed, and transformed into accurate inferences about human activity. Wearable devices are becoming more widely adopted in recent years for general health and recreational uses by the broad populace. This research will result in improved algorithms to process the data available from such wearable devices. The long-term goal of the research is to enable personalized home-based physical activity regimens for conditions such as stroke and diabetes. Project Number: 1R01GM135927-01 Title: Dense Life-log Health Analytics from Wearable Sensors using Functional Analysis and Riemannian Geometry Project Narrative In this revision application, we seek to submit an equipment supplement to our existing R01 referenced above. As our project progressed, we found that it is important to consider the role of new emerging feature-learning approaches to extract downstream time-series features. To fully develop our approach and conduct additional experiments, we need significant GPU computational resources that will be dedicated to this project.",Dense Life-log Health Analytics from Wearable Sensors using Functional Analysis and Riemannian Geometry,10135658,R01GM135927,"['Accelerometer', 'Address', 'Adopted', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Awareness', 'Behavior', 'Behavior Therapy', 'Behavior monitoring', 'Behavioral', 'Big Data', 'Cellular Phone', 'Classification', 'Coupled', 'Data', 'Data Analyses', 'Development', 'Devices', 'Diabetes Mellitus', 'Dimensions', 'Elements', 'Equipment', 'Generations', 'Geometry', 'Goals', 'Growth', 'Harvest', 'Health', 'Home environment', 'Hour', 'Human Activities', 'Intervention', 'Learning', 'Life', 'Location', 'Machine Learning', 'Mathematics', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Observational Study', 'Outcome', 'Pattern', 'Periodicity', 'Physical activity', 'Process', 'Regimen', 'Research', 'Research Activity', 'Role', 'Running', 'Sampling', 'Series', 'Statistical Methods', 'Stroke', 'Supervision', 'Techniques', 'Technology', 'Time', 'Time Series Analysis', 'Validation', 'Walking', 'Work', 'analysis pipeline', 'base', 'computing resources', 'density', 'experimental study', 'heart rate monitor', 'improved', 'innovation', 'insight', 'interdisciplinary approach', 'machine learning algorithm', 'mathematical algorithm', 'mathematical sciences', 'multimodality', 'preservation', 'sedentary lifestyle', 'sensor', 'signal processing', 'statistics', 'tool', 'wearable device', 'wearable sensor technology']",NIGMS,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,69169,0.010607022285505438
"Healthcare Impact of Consumer-Driven Atrial Fibrillation Detection PROJECT SUMMARY/ABSTRACT  Companies are increasingly marketing mobile technologies as FDA-cleared medical devices, yet we do not know the consequences of these devices on healthcare utilization, cost, and outcomes. Recently, Apple released the Apple Watch Series 4 as an FDA-cleared medical device. The device includes an alert for the presence of atrial fibrillation (AF) and allows anyone to monitor their heart rhythm for the presence of AF. Apple has an enormous global audience, and the number of people who will use this (and other similar devices) to self-diagnose or monitor AF will be substantial. On one hand, the device may allow new diagnoses that result in treatment, improved quality of life, fewer AF related complications. On the other hand, the device may result in false positives in otherwise healthy people, resulting in more testing and treatments with associated harms. In fact, the U.S. Preventative Task Force recommends against routine surveillance for AF in the general population, citing lack of evidence and possible harm. We have an urgent need for a population-based infrastructure to ensure that technologies entering the market as medical devices are beneficial and safe.  The overall goal of this project is to measure the uptake and effect of the Apple Watch 4 release on healthcare utilization among first-time and known AF patients. Dr. Shah is an early stage investigator with a K08 Career Development Award from the NHLBI. As part of the K08, she has developed a detailed cohort of contemporary AF patients, including clinical notes. Along with a team, she will use real world data, as proposed by the FDA, to generate evidence about risks and benefits of consumer-driven AF detection. She will use natural language processing to leverage the notes and identify AF patients who seek care due to the medical device, and evaluate downstream healthcare utilization, such as additional clinic visits, cardioversions, additional remote monitoring, and cost. The goals of this project will be accomplished through the following Specific Aims: 1) Estimate the proportion of first-time AF patient visits attributable to a mobile device before and after FDA clearance of the Apple Watch 4, and characterize device accuracy and downstream healthcare utilization in this population; and 2) Evaluate healthcare utilization patterns among prevalent AF patients who use mobile devices with AF alerts.  In 2017, Apple sold 17.7 million smart watches, in a device market that continues to grow. Extrapolating from prior annual sales and conservatively assuming a 5% increase in users each year, almost 60 million people will have an Apple Watch by the end of 2020 (not accounting for non-Apple devices with similar functionality). Thus, even in this short period of time, uptake will be substantial and warrant immediate feedback. The results of this project will provide preliminary data for a long-term, multicenter study that evaluates the benefits (improved quality of life, fewer strokes) and harms (increased treatment complications, increased cost) of consumer-driven AF detection. PROJECT NARRATIVE The consequence of mobile technologies marketed as medical devices are unknown, including devices that provide alerts for the presence of atrial fibrillation. The goal of this project is to evaluate the benefits and harm associated with consumer-driven atrial fibrillation detection.",Healthcare Impact of Consumer-Driven Atrial Fibrillation Detection,9980996,R03HL148372,"['Adult', 'Advisory Committees', 'Affect', 'Apple', 'Apple watch', 'Arrhythmia', 'Atrial Fibrillation', 'Benefits and Risks', 'Cardiovascular system', 'Caring', 'Case-Control Studies', 'Clinic Visits', 'Clinical', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Electric Countershock', 'Ensure', 'Feedback', 'General Population', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Hemorrhage', 'Holter Electrocardiography', 'Infrastructure', 'Interruption', 'Intervention', 'K-Series Research Career Programs', 'Lead', 'Marketing', 'Measures', 'Medical Device', 'Monitor', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Outcome', 'Patients', 'Pattern', 'Population', 'Prevalence', 'Preventive', 'Quality of life', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sales', 'Series', 'Sinus', 'Stroke', 'Technology', 'Testing', 'Text', 'Time', 'United States Food and Drug Administration', 'Universities', 'Utah', 'Visit', 'base', 'care seeking', 'cohort', 'cost', 'cost outcomes', 'cryptogenic stroke', 'design', 'follow-up', 'handheld mobile device', 'health care service utilization', 'heart rhythm', 'improved', 'mobile computing', 'population based', 'routine screening', 'self diagnosis', 'smart watch', 'uptake']",NHLBI,UNIVERSITY OF UTAH,R03,2020,76250,-0.0004991690683765299
"An Intracortical Brain-Computer Interface Model for High Efficiency Development of Closed-Loop Neural Decoding Algorithms An intracortical brain-computer interface (iBCI) is used to record electrical signals directly from a person's brain, predict their intention from those signals, then control an assistive device (e.g., a computer cursor, prosthetic limb, or powered wheelchair) according to those intentions. This technology enables severely paralyzed people to interact with the world. However, designing robust algorithms to extract intent from recordings of single neurons is extremely challenging, in large part because of the very limited access to humans, or even monkeys, from whom these invasive recordings can be made. In this project, we will develop a model iBCI system that generates real-time biomimetic neural data by capturing the high-degree-of-freedom finger movements of able-bodied human subjects. To accomplish this, we will construct a modular recurrent neural network (RNN). The RNN will be trained to predict the motor cortex activity of a monkey from the monkey's own finger kinematics. Small modules of the RNN will be interchanged according the particular animal or recording session to model the high inter-session variability present in motor cortex. Once the modular RNN is trained, its weights will be fixed and human finger kinematics will be used as the RNN inputs, which will generate subject-controlled emulated neural activity. The emulated neural activity can be passed to iBCI decoding algorithms that control computer cursors or other physical devices, allowing human subjects to interact directly with decoders in real time, closed-loop conditions. We call this model system the jaBCI. The jaBCI is low cost and noninvasive, making it possible to rapidly test and design novel iBCI decoders using statistically rigorous sample sizes. The project will be executed in close collaboration with intracortical microelectrode array data expert Dr. Lee Miller at Northwestern University. Dr. Miller's lab, with the help of our consultant Dr. Mathis, will obtain simultaneous finger kinematics and neural activity of monkey subjects that will serve as the training data for the RNN component of the iBCI model. We will validate the emulated neural data generated by the jaBCI across many measures to ensure the model captures as many features of intracortical data as possible. These include comparing the model and actual iBCI in subject performance, learning rates, control strategies, neural variation across days, neural firing rate distributions, and low-dimensional neural dynamics. With the validated model, we will undertake a study to rigorously evaluate the highest performing, current state-of-the-art iBCI decoders. This will yield useful insight into the features of decoders that yield the greatest performance gains, overcoming the current impossibility to compare iBCI decoders in well-controlled studies using more than two or three naïve human subjects. We will also use the iBCI model to evaluate novel decoder designs, and to determine the features of neural dynamics that are consistent across common iBCI tasks to help focus decoder development on those features. Narrative Brain-computer interfaces are systems that translate the electrical neural signatures of thought into instructions for a personal computer or powered wheelchair, which is an incredibly useful technology to help paralyzed people regain some independence and ability to communicate. This work would develop a tool that scientists can use to design, test, and optimize the sophisticated computer programs that translate brain signals into device instructions without having to implant electrodes into a person's brain until the program is completed and rigorously tested. This tool could increase the pace of discovery and development of brain-computer interfaces.",An Intracortical Brain-Computer Interface Model for High Efficiency Development of Closed-Loop Neural Decoding Algorithms,9995591,R01NS109257,"['Address', 'Algorithms', 'Animals', 'Biological Models', 'Biomimetics', 'Brain', 'Collaborations', 'Communities', 'Computers', 'Controlled Study', 'Data', 'Data Set', 'Development', 'Devices', 'Dimensions', 'Electroencephalography', 'Ensure', 'Exhibits', 'Feedback', 'Finger joint structure', 'Fingers', 'Freedom', 'Hand', 'Human', 'Human body', 'Implant', 'Implanted Electrodes', 'Industry Standard', 'Injury', 'Instruction', 'Intention', 'Joints', 'Learning', 'Limb Prosthesis', 'Limb structure', 'Literature', 'Measures', 'Methods', 'Microelectrodes', 'Modeling', 'Monkeys', 'Motor Cortex', 'Muscle', 'Neurons', 'Operating System', 'Operative Surgical Procedures', 'Paralysed', 'Patients', 'Performance', 'Personal Computers', 'Personal Power', 'Persons', 'Posture', 'Powered wheelchair', 'Protocols documentation', 'Reporting', 'Reproducibility', 'Robotics', 'Rotation', 'Sample Size', 'Scientist', 'Self-Help Devices', 'Series', 'Signal Transduction', 'Structure', 'System', 'Task Performances', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Validation', 'Variant', 'Weight', 'Work', 'brain computer interface', 'cohort', 'comparative', 'computer program', 'cost', 'design', 'finger movement', 'head-to-head comparison', 'high dimensionality', 'human subject', 'human-in-the-loop', 'innovation', 'insight', 'invention', 'kinematics', 'nervous system disorder', 'neurotransmission', 'novel', 'programs', 'recurrent neural network', 'relating to nervous system', 'skill acquisition', 'success', 'tool']",NINDS,FLORIDA INTERNATIONAL UNIVERSITY,R01,2020,327626,0.025296449521446513
"Mobilize Center: Models for Mobile Sensing and Precision Rehabilitation Limited mobility due to conditions like osteoarthritis (OA), cerebral palsy, and Parkinson’s disease affects millions of individuals, at enormous personal and societal cost. Rehabilitation can dramatically improve mobility and function, but current rehabilitation practice requires in-person guidance by a skilled clinician, increasing expense and limiting access. Mobile sensing technologies are now ubiquitous and have the potential to measure patient function and guide treatment outside the clinic, but they currently fail to capture the characteristics of motion required to accurately monitor function and customize treatment. Millions of low-cost mobile sensors are generating terabytes of data that could be analyzed in combination with other data, such as images, clinical records, and video, to enable studies of unprecedented scale, but machine learning models for analyzing these large-scale, heterogeneous, time-varying data are lacking.  To address these challenges, we will establish a Biomedical Technology Resource Center —The Mobilize Center. Through the leadership of an experienced scientific team, we will create and disseminate innovative tools to quantify movement biomechanics with mobile sensors.  Specifically, we will:  1. Push the bounds of what we can measure via wearable sensors using models that compute muscle  and joint forces and metabolic cost of locomotion. These models, based on biomechanical and machine  learning models, will be disseminated via our newly created OpenSense software, which will be used  by thousands of researchers to gain new insights into patient biomechanics using mobile sensors.  2. Meet the need for tools that analyze data about movement dynamics and develop machine learning  models to analyze and generate insights from unstructured, high-dimensional data, including time-  series (e.g., from mobile sensors), images (e.g., MRI), and video (e.g., smartphone video of a patient’s gait).  3. Provide tools needed to intervene in the real-world. We will develop algorithms to accurately quantify  kinematics outside the lab for long durations using data from inertial measurement units (IMUs). We will  also build behavioral models to adapt and personalize goal setting, drawing on movement records from  6 million individuals, as well as health goals and exercise for 1.7 million people.  Through intensive interactions with our Collaborative Projects, we will focus on improving rehabilitation outcomes for individuals with limited mobility due to osteoarthritis, obesity, Parkinson’s disease, and cerebral palsy. The Center’s tools and services will enable researchers to revolutionize how we diagnose, monitor, and treat mobility disorders, providing tools needed to deliver precision rehabilitation at low cost and on a massive scale in the future. Limited mobility due to conditions like osteoarthritis, cerebral palsy, and Parkinson’s affects millions of individuals, at a great cost to public health and personal well-being. Rehabilitation can dramatically improve mobility and function, but current rehabilitation practice requires in- person guidance by a skilled clinician, increasing expense and limiting access. This project will revolutionize how we diagnose, monitor, and treat mobility limitations and enable personalized rehabilitation at low cost and on a massive scale using wearable sensing technology in the future.",Mobilize Center: Models for Mobile Sensing and Precision Rehabilitation,9855893,P41EB027060,"['Address', 'Affect', 'Algorithms', 'Behavioral Model', 'Biomechanics', 'Biomedical Engineering', 'Biomedical Technology', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Clinic', 'Clinical', 'Communities', 'Computer software', 'Custom', 'Data', 'Data Science', 'Degenerative polyarthritis', 'Diagnosis', 'Disease', 'Documentation', 'Educational workshop', 'Engineering', 'Exercise', 'Exposure to', 'Feedback', 'Foundations', 'Freezing', 'Future', 'Gait', 'Goals', 'Guidelines', 'Home environment', 'Human', 'Image', 'Individual', 'Joints', 'Leadership', 'Literature', 'Locomotion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Metabolic', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Muscle', 'Obesity', 'Parkinson Disease', 'Pathologic', 'Patients', 'Personal Satisfaction', 'Persons', 'Public Health', 'Records', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Resources', 'Series', 'Services', 'Software Tools', 'Time', 'Training', 'Vision', 'base', 'biomechanical model', 'biomedical informatics', 'cohesion', 'coral', 'cost', 'evidence base', 'experience', 'handheld mobile device', 'health goals', 'improved', 'improved functioning', 'improved mobility', 'individualized medicine', 'industry partner', 'innovation', 'insight', 'joint loading', 'kinematics', 'large scale data', 'mHealth', 'mobile computing', 'multidimensional data', 'open source', 'programs', 'sensor', 'sensor technology', 'smart watch', 'societal costs', 'symposium', 'terabyte', 'tool', 'tool development', 'wearable sensor technology']",NIBIB,STANFORD UNIVERSITY,P41,2020,752316,0.011853904643864427
"Individualized Vestibular Rehabilitation for Elderly with Self-Management and Gaming Elements Project Summary/Abstract: Vestibular rehabilitation has been proven to be effective in reducing dizziness and falls in older adults, but patient adherence is a major problem. Recent research shows that less than half of patients complete their rehabilitation. Some of the main reasons for this are the numerous visits that are required and accessibility. In particular for older individuals who experience dizziness and/or falls, it may be difficult to travel to attend rehabilitation sessions. Additionally, rehabilitation programs become expensive in terms of equipment and health professional’s time. Programs may also not be available to all who may benefit because of geographical limitations. Previous research has shown that remote monitoring and gaming elements have great potential to solve these issues, even in an older population. However, current solutions are generic and effectiveness can be inconsistent. The overall goal of this project is to develop a vestibular rehabilitation app to be used by older adults at home. The app will improve adherence through gaming, self-management, and remote monitoring. Patients will use low-cost sensors placed on their bodies (head and waist) to play the games on the app. This allows simultaneous monitoring of patient progress while performing the exercises. This data can be shared with a clinician via email or the cloud, allowing the patient to perform the rehabilitation at their home and the clinician to monitor how well the patients performed their exercises. The vestibular rehabilitation components are packaged in a phone and tablet app that is easy to navigate for older individuals and has a modular design that allows individualized rehabilitation. By improving patient engagement and enjoyment, rehabilitation adherence should be improved as well. Phase I demonstrated feasibility of this approach. In Phase II, games will be added to cover a full at-home rehabilitation session and improve usability of the app. In addition, machine learning algorithms will be developed to provide real-time feedback if exercises are performed incorrectly. This ensures patients will perform their exercises correctly when at home. As in Phase I, clinical collaborators will provide continued guidance and testing throughout development to ensure clinical relevance and promote adoption during commercialization. This project uses a novel approach in that it develops rehabilitation games specifically designed for vestibular rehabilitation through a mobile app tailored for an older population. Current gaming approaches for rehabilitation typically use existing or commercial games. The use of sensors for remote monitoring is also novel in this area and allows patients to perform rehabilitation at their home, while being monitored by a clinician. This project is therefore likely to have a high clinical impact. It will advance clinical practice, make vestibular rehabilitation more accessible to older individuals, and help adherence to programs. Successful implementation of this program will reduce falls and improve quality of life of for patients. Project Narrative: The overall goal of this project is to develop an app for older individuals that will improve accessibility of vestibular rehabilitation and that will improve compliance compared to current rehabilitation programs. The proposed effort uses a novel approach that combines low-cost inertial sensors and machine learning algorithms with mobile device technology to measure performance, provide real-time feedback, and present data in a comprehensible way to the clinician via email or the cloud, removing the patients’ need to travel for rehabilitation sessions. These features are packaged in an app that is appropriate for and appealing to older users to improve compliance, and uses novel gaming elements specifically developed for vestibular rehabilitation rather than repurposing existing commercial games designed for younger users and entertainment.",Individualized Vestibular Rehabilitation for Elderly with Self-Management and Gaming Elements,10011222,R44DC017408,"['Adherence', 'Adoption', 'Algorithms', 'Area', 'Clinic', 'Clinical', 'Collaborations', 'Data', 'Data Analyses', 'Databases', 'Development', 'Dizziness', 'Effectiveness', 'Elderly', 'Electronic Mail', 'Elements', 'Engineering', 'Ensure', 'Equilibrium', 'Equipment', 'Exercise', 'Eye', 'Fall prevention', 'Feedback', 'Florida', 'Focus Groups', 'Geography', 'Goals', 'Head', 'Health Personnel', 'Health Professional', 'Health care facility', 'Home Care Services', 'Home environment', 'Hospitals', 'Individual', 'Kansas', 'Literature', 'Machine Learning', 'Measures', 'Monitor', 'Motion', 'Older Population', 'Patient Monitoring', 'Patients', 'Performance', 'Phase', 'Physical Rehabilitation', 'Physical therapy', 'Play', 'Population', 'Provider', 'Quality of life', 'Questionnaires', 'Records', 'Rehabilitation therapy', 'Reporting', 'Research', 'Rewards', 'Safety', 'Scientist', 'Self Management', 'Software Design', 'Supervision', 'Tablets', 'Technology', 'Telephone', 'Testing', 'Time', 'Travel', 'Universities', 'Update', 'Visit', 'Work', 'base', 'clinical practice', 'clinically relevant', 'commercialization', 'compliance behavior', 'cost', 'design', 'exercise rehabilitation', 'experience', 'falls', 'gaze', 'handheld mobile device', 'human old age (65+)', 'improved', 'interest', 'machine learning algorithm', 'machine learning method', 'mobile application', 'motion sensor', 'multidisciplinary', 'novel', 'novel strategies', 'patient engagement', 'physical therapist', 'programs', 'prototype', 'rehabilitation science', 'remote sensor', 'sensor', 'usability', 'visual tracking', 'web portal']",NIDCD,CFD RESEARCH CORPORATION,R44,2020,680368,-0.02110221470846207
"A new mechanistic and technological framework for uncovering the spinal cord neural systems important for functional recovery after injury Project Summary and Abstract Interventions that increase plasticity and regeneration after spinal cord injury (SCI) are improving, but little is known about the neural systems that would be most effective to target such interventions. Sensory based rehabilitation suggests a strong link between cutaneous and proprioceptive sensory neuron activity and motor recovery. Previous experiments provide strong support for the intermediate zone (IZ) of the spinal cord (SC) as an important site mediating this recovery. However, few studies have assessed the role of specific IZ neurons in functional recovery. Key barriers to progress include lack of characterization of specific cell types within the IZ and a paucity of tools to visualize circuits and test their functions in motor performance and recovery following SCI. Our lab combines sophisticated mouse genetic approaches with sensitive motor movement tracking to understand how sensory information is encoded by the SC to influence behavior. Using this approach, we uncovered that intermediate zone (IZ) parvalbumin positive interneurons (PVs) are important for tactile motor responses and locomotion. We hypothesize that IZ-PVs process sensory information to activate specific muscle groups during locomotion and that they play a critical role in activity-based functional recovery following SCI. The ability to identify circuits important for functional recovery relies on how accurately we can quantify differences in behavioral outcomes. We are implementing an unsupervised approach using 3-D pose dynamics and artificial intelligence (AI) to characterize both sensitive behavioral biomarkers and uncover key spinal cord circuits important for the recovery process. Interventions that increase plasticity and regeneration are improving, and this project both identifies the neural systems and synaptic mechanisms that would be most effective to target such interventions and establishes an AI-based platform for fast, reliable and unbiased quantification of motor recovery in rodents. Thus, this project makes original and important contributions to the field of spinal cord research in ways that are specifically aligned with central missions of the NINDS. Moreover, our experimental scrutiny at both the neural and behavioral levels establishes a critical foundation for developing a leading research program and securing independent award funding studying the spinal cord circuits important for sensorimotor function and recovery following SCI. To this end, I have developed a thorough and pragmatic career development plan supported by a strong committee of mentors with extensive track records of laboratory and departmental level mentoring and distinguished portfolios of SCI-specific grant support from the NIH, DoD and private foundations. My career development activities will be focused on four aspects of my academic success. 1) Mentorship and guidance focused on laboratory management. 2) Development and growth of my independent research program and award funding, with a focus on SCI research gap-based training. 3) Navigating institutional responsibilities and fulfilling requirements for promotion and tenure. 4) Expanding my scientific network and profile. Project Narrative Interventions that increase plasticity and regeneration after spinal cord injury (SCI) are improving, but little is known about the spinal cord neural systems that would be most effective to target such interventions. This project both identifies the spinal cord neural cell types and synaptic mechanisms that would be most effective to target such interventions and establishes an artificial intelligence (AI)-based platform for fast, reliable and unbiased quantification of motor recovery in rodents. Our experimental scrutiny at both the neural and behavioral levels establishes a critical foundation for developing a prominent research program and securing independent award funding studying the spinal cord circuits important for sensorimotor function and recovery following SCI.",A new mechanistic and technological framework for uncovering the spinal cord neural systems important for functional recovery after injury,9953321,K01NS116224,"['3-Dimensional', 'Anatomy', 'Artificial Intelligence', 'Award', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Biological Markers', 'Complex', 'Cutaneous', 'Data', 'Development Plans', 'Elements', 'Ensure', 'Foundations', 'Funding', 'Gait', 'Genetic', 'Goals', 'Grant', 'Growth and Development function', 'Injury', 'Interneurons', 'Intervention', 'Label', 'Laboratories', 'Leg', 'Link', 'Liquid substance', 'Locomotion', 'Mediating', 'Mentors', 'Mentorship', 'Mission', 'Modeling', 'Motor', 'Movement', 'Muscle', 'National Institute of Neurological Disorders and Stroke', 'Natural regeneration', 'Neurons', 'Output', 'Parvalbumins', 'Pattern', 'Performance', 'Play', 'Population', 'Positioning Attribute', 'Privatization', 'Probability', 'Process', 'Proprioceptor', 'Publishing', 'Records', 'Recovery', 'Recovery of Function', 'Rehabilitation therapy', 'Research', 'Rodent', 'Rogaine', 'Role', 'Secure', 'Sensorimotor functions', 'Sensory', 'Sensory Process', 'Shapes', 'Site', 'Spinal Cord', 'Spinal Cord Contusions', 'Spinal cord injury', 'Structure', 'Synapses', 'System', 'Tactile', 'Technology', 'Testing', 'Therapeutic Intervention', 'Three-Dimensional Imaging', 'Touch sensation', 'Training', 'United States National Institutes of Health', 'Volition', 'base', 'behavior influence', 'behavioral outcome', 'career development', 'cell type', 'defined contribution', 'experimental study', 'genetic approach', 'improved', 'injury recovery', 'insight', 'kinematics', 'motor behavior', 'motor recovery', 'mouse genetics', 'programs', 'relating to nervous system', 'response', 'success', 'synergism', 'tool']",NINDS,"RUTGERS, THE STATE UNIV OF N.J.",K01,2020,245164,-0.004088381116418501
"SCH: Multimodal,Task-Aware Movement Assessment and Control: Clinic to Home We propose to develop a novel, distributed sensor platform that continuously assesses movement in the background of one's life with the goal of helping people age in place and avoid expensive and lengthy hospitalizations. On the one hand, the platform will combine measurements from a heterogeneous and  complementary set of inertial, physiological , and vision sensors with state-of-the-art techniques from robotics and machine learning, together with clinically informed dynamic models of human motion. On the other hand, the platform will use these data to target the prompt detection of the mobility deficits that often precipitate the onset of frailty, with the goal of facilitating personalized caregiver alerts if a decline in functional status is detected. Moreover, the platform will provide context-aware control inputs to facilitate unconstrained use of powered assistive technologies in the home. This project has three main thrusts: assessment, control, and home intervention. In the assessment component, our work will extend well-proven techniques of multi-modal sensor fusion for mapping and localization of robots to home-based movement monitoring and intervention. The novelty of this work lies in the tight integration of machine learning modules for real-time activity recognition and movement dysfunction diagnosis. In the control component, our work will push the boundaries of what is possible with current powered assistive devices by developing novel control mechanisms that take advantage of the new capabilities provided by the estimation component (e.g., adapting control to changes in activities and environmental contexts). In the home intervention component, we will collect data that will refine the sensing and control algorithms and involve caregivers in alerts. A patient-in-the-loop development approach will be utilized where domain-informed protocols will generate the data necessary to train and evaluate our system, both in the clinic and in the home. By enabling timely detection of movement dysfunction and facilitating unconstrained use of powered assistive technologies, this foundational technology has paradigm-disrupting potential to prevent the onset of frailty and alter the treatment options for frail individuals. In parallel, the estimation component of the system could be used in clinical settings to automate and standardize time-intensive and highly subjective functional movement assessments, allowing more accurate diagnoses while freeing clinicians for other important tasks. RELEVANCE (See instructions): Frail older adults constitute the sickest, most expensive, and fastest growing segment of the US population. Home-based technologies that facilitate aging in place and reduce high-cost, hospital- and institution-based interventions are desperately needed. Our proposed distributed sensor platform has the potential to address this need by enabling the timely detection of the mobility deficits that often precipitate the onset of frailty and proactive caregiver and technological interventions that can delay, or prevent, mobility loss. n/a","SCH: Multimodal,Task-Aware Movement Assessment and Control: Clinic to Home",10019455,R01AG067394,"['Address', 'Adult', 'Algorithms', 'Awareness', 'Caregivers', 'Clinic', 'Clinical', 'Communities', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Distant', 'Emerging Technologies', 'Environment', 'Evaluation', 'Event', 'Foundations', 'Frail Elderly', 'Functional disorder', 'Goals', 'Healthcare Systems', 'Home environment', 'Hospitalization', 'Hospitals', 'Impairment', 'Independent Living', 'Individual', 'Institution', 'Instruction', 'Intervention', 'Laboratories', 'Learning Module', 'Life', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Muscle', 'Patients', 'Physical activity', 'Physiological', 'Population', 'Protocols documentation', 'Robot', 'Robotics', 'Self-Help Devices', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Vision', 'Walking', 'Work', 'accurate diagnosis', 'aging in place', 'base', 'cost', 'frailty', 'functional decline', 'functional electrical stimulation', 'functional status', 'human model', 'loss of function', 'multimodality', 'neuroprosthesis', 'next generation', 'novel', 'prevent', 'recruit', 'response', 'sensor', 'technology development', 'tool', 'wearable sensor technology']",NIA,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2020,290216,0.015506700463595483
"Wearable Sensors for Biofeedback & Remote Monitoring Rotator cuff tears are a common condition affecting approximately 25% of the population older than 60 years, and rotator cuff repair is a standard surgical procedure with nearly 500,000 procedures performed annually. In the United States alone the direct costs are over $7 billion per year. There is a relatively high rate of retears: ranging from 10% to 78%. Healing of the repair cuff is a protracted process during which the repaired tendon has to be unloaded by carefully restricting active muscle contraction. There is an inherent conflict in immobilizing the shoulder to protect the repair and mobilizing the shoulder to prevent stiffness. Teaching the patient passive exercises that do not activate contraction of the supraspinatus muscle is challenging and very difficult to monitor. To address this unmet need, we have developed a wearable sensor that provides direct real-time continuous biofeedback of muscle activity, joint angle, skin temperature, and swelling to enable passive shoulder exercises while minimizing muscle contraction. To test and validate this device we propose to the following Specific Aims. Aim 1: Design, manufacture, and test a wearable device with surface EMG (sEMG), inertial measurement unit (IMU), temperature, and bioimpedance sensors. Aim 2: Measure accuracy of Active4D sEMG and IMUs relative to standard clinical measurements. Active4D is a surgeon-driven company devoted to enhancing patient recovery from surgery by leveraging new technology. Active4D’s unique wearable sensor provides continuous long-term sensor augmented biofeedback to patients and enables remote patient monitoring for surgeons. The device measures seven physiologic metrics in real time – muscle activation, joint range of motion, skin temperature, swelling, activity, gait, and fall risk. Real time physiologic data will increase safety, improve outcomes, and enhance patient experience while lowering the cost of rehabilitation and complications. Unique artificial intelligence driven algorithms can decrease complications through predictive analytics which enable early detection and intervention for high risk patients.  The specific innovation to the application of rotator cuff repair, is the instantaneous feedback of muscle activity and motion which can accelerate recovery while reducing the risk of retears. At the successful completion of Phase I, we plan to launch a clinical trial comparing the outcomes of rotator cuff repair in patients guided by the A4D device in comparison to the current standard of postoperative rehabilitation.  Active4D is a small business with the objective of developing smart wearables, which integrate multiple biological and environmental sensors, wireless communication, computer models, and data analysis for providing feedback and remote monitoring, to enhance surgical rehabilitation and improved patient outcomes in orthopaedics. Co-founders Drs. Hoenecke and D’Lima have extensive experience in shoulder surgery and rehabilitation, multi-center clinical trials, and biomechanics research; and have successfully executed challenging projects such as implantation of innovative electronic knee designs and development of new shoulder implants. Dr. Hoenecke has over 30 years of experience in the practice of sports medicine with an emphasis on shoulder repair and reconstruction. He provides care for elite athletes and is design surgeon for two shoulder implants. Active4D has partnered with expert physical therapists and orthopedists to develop and test our innovative technology. Rotator cuff tears are a common condition affecting approximately 25% of the population older than 60 years. Despite the popularity of surgical repair, the rate of retears is high: ranging from 10% to 78%. Healing of the repair cuff is a lengthy process during which the repaired tendon has to be unloading by carefully restricting active muscle contraction. This Phase I SBIR will develop an innovative wearable device with the potential to facilitate safe exercises, alert the patient during activities at risk for retears, and accelerate recovery while reducing the risk for retears. The device can also remotely monitor progress of the patient over the postoperative period and can modulate the feedback appropriate to the phase of recovery.",Wearable Sensors for Biofeedback & Remote Monitoring,10156598,R43AR078082,"['Address', 'Affect', 'Algorithms', 'Articular Range of Motion', 'Artificial Intelligence', 'Biofeedback', 'Biological', 'Biomechanics', 'Biophysics', 'Businesses', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complication', 'Computer Models', 'Computer software', 'Conflict (Psychology)', 'Data', 'Data Analyses', 'Data Analytics', 'Development', 'Devices', 'Direct Costs', 'Early Diagnosis', 'Early Intervention', 'Educational process of instructing', 'Exercise', 'Feedback', 'Funding', 'Gait', 'Health', 'Immobilization', 'Implant', 'Industry', 'Infection', 'Joints', 'Knee', 'Laboratories', 'Legal patent', 'Letters', 'Measurement', 'Measures', 'Mission', 'Monitor', 'Motion', 'Multi-Institutional Clinical Trial', 'Muscle', 'Muscle Contraction', 'Older Population', 'Operative Surgical Procedures', 'Orthopedics', 'Outcome', 'Patient Monitoring', 'Patient-Focused Outcomes', 'Patients', 'Phase', 'Physiological', 'Postoperative Period', 'Predictive Analytics', 'Procedures', 'Process', 'Recovery', 'Rehabilitation therapy', 'Reproducibility', 'Research', 'Resources', 'Risk', 'Rotator Cuff', 'Safety', 'Science', 'Seeds', 'Series', 'Shoulder', 'Skin Temperature', 'Small Business Innovation Research Grant', 'Sports Medicine', 'Surface', 'Surgeon', 'Swelling', 'System', 'Temperature', 'Tendon structure', 'Testing', 'Thick', 'Time', 'United States', 'cost', 'design', 'experience', 'fall risk', 'healing', 'high risk', 'implantation', 'improved', 'improved outcome', 'innovation', 'innovative technologies', 'interest', 'miniaturize', 'new technology', 'physical therapist', 'post-operative rehabilitation', 'prevent', 'prototype', 'reconstruction', 'repaired', 'rotator cuff tear', 'sensor', 'success', 'supraspinatus muscle', 'trial comparing', 'wearable device', 'wearable sensor technology', 'wireless communication']",NIAMS,"ACTIVE4D, INC.",R43,2020,250998,0.0005940900312028691
"BehaviorSight: Privacy enhancing wearable system to detect health risk behaviors in real-time. Project Summary/Abstract Health-risk behaviors, such as overeating, smoking, consuming alcohol, and not adhering to medication, are responsible for increases in morbidity and mortality. To track and intervene during these health-risk behaviors, clinicians traditionally rely on self-reports. However, self-reports are inaccurate and biased. Therefore, we cannot use self-reports to validate health-risk behaviors in free-living conditions. Thus, an automated technique for validating health-risk behaviors is extremely necessary. With the growth and popularity of wearable devices (e.g., smartwatches), automatic monitoring of physical activity is possible. However, the devices often do not provide any visual confirmation, making it challenging to verify activities performed in free-living conditions. Cameras can capture point-of-view videos and can thus be used as a wearable device to capture videos for visual confirmation of activities, including health-risk behaviors. Such recordings can help us better understand health-risk behaviors. Additionally, video information can be automatically processed to confirm and validate health-risk behaviors. Recording videos of sensitive content and bystanders is associated with privacy and ethical concerns. Currently there is no privacy-preserving camera that can automatically detect health-risk behaviors, and most people are unwilling to wear cameras without raising privacy concerns. In addition to privacy concerns, people prefer wearables that are unobtrusive and small and that do not require frequent charging. Thus, a privacy-preserving, unobtrusive wearable camera would increase wearability. Infrared (IR) sensor arrays have the potential to provide independent temperature readings, which allows determining whether an object is near or far. The IR sensor array can help record only the wearer and objects near the wearer, while filtering out distant objects. IR sensor arrays have a small power footprint, thus providing longer battery life. Our project aims to develop a privacy-conscious, unobtrusive, wearable, behavior-detection platform that will make it possible to detect and intervene upon health-risk behaviors in real time. In this project, we will (1) develop the wearable behavior-detection device that allows visual confirmation without burdening the wearer. The device will augment RGB camera data with IR sensor array data for privacy-conscious recording and automatic behavior detection. (2) We will test various designs to determine a user's acceptability to wear the device. Then, we will test various image processing techniques and machine learning algorithms to determine the best algorithm for detecting health-risk behaviors. (3) We will incorporate the best-performing behavior-detection algorithm so that it can run on the developed wearable device. With a behavior-detection algorithm running on an acceptable wearable device, the ability to detect health-risk behaviors in real time will become a reality. Ultimately, our wearable device will allow researchers to test and apply appropriate behavioral interventions in real time, rather than relying on self-reports, whenever health-risk behaviors occur. Project Narrative Several activities involving hand-to-mouth gestures (e.g., overeating, smoking, consuming alcohol, or non- adherence to medication) are associated with health-risk behaviors that are a leading cause of preventable deaths. Being able to automatically monitor health-risk behaviors using wearable video cameras will improve our understanding of these behaviors and will ultimately enable us to design effective methods to intervene when they occur. We will develop BehaviorSight, a privacy-conscious, unobtrusive, wearable, behavior-detection device that will allow future researchers and behavioral scientists to use the device for monitoring numerous everyday health-risk behaviors in free-living settings.",BehaviorSight: Privacy enhancing wearable system to detect health risk behaviors in real-time.,10043674,R21EB030305,"['Address', 'Alcohol consumption', 'Algorithms', 'Behavior', 'Behavior Therapy', 'Behavior monitoring', 'Behavioral', 'Bluetooth', 'Cellular Phone', 'Charge', 'Chest', 'Clinical', 'Communication', 'Conscious', 'Data', 'Detection', 'Devices', 'Dietitian', 'Disease', 'Distant', 'Eating', 'Ensure', 'Ethics', 'Future', 'Gestures', 'Goals', 'Grant', 'Growth', 'Hand', 'Health', 'Hyperphagia', 'Intervention', 'Laboratory Study', 'Learning', 'Life', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Notification', 'Obesity', 'Oral cavity', 'Participant', 'Patient Self-Report', 'Pharmaceutical Preparations', 'Physical activity', 'Privacy', 'Process', 'Reading', 'Records', 'Research', 'Research Personnel', 'Resources', 'Risk Behaviors', 'Running', 'Science', 'Scientist', 'Smoke', 'Smoking', 'Substance abuse problem', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Video Recording', 'Visual', 'cost', 'data privacy', 'design', 'drinking', 'image processing', 'improved', 'light weight', 'machine learning algorithm', 'medication nonadherence', 'miniaturize', 'monitoring device', 'mortality', 'multimodality', 'novel', 'prevent', 'preventable death', 'privacy preservation', 'response', 'sensor', 'smart watch', 'wearable device', 'wearable sensor technology', 'willingness']",NIBIB,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2020,606713,0.028256683614708046
"Can fidgeting lead to enhanced attention and emotional regulation in adult ADHD? Fidgeting is a highly common behavior, with excessive fidgeting associated with attention-deficit/hyperactivity disorder (ADHD). Studies from our laboratory (1) and colleagues (2) suggest physical movement can enhance cognitive performance in children with ADHD. Hyper-sensorimotor behavior may be related to impaired regulation of arousal in the noradrenergic and dopaminergic systems (3). This project will assess if frequency and characteristics of sensorimotor behavior relates to cognitive and emotional response in adults with ADHD, in a fine-grained manner, unlike other studies. We will test if intrinsic fidgeting (Aim 1) and access to a specially designed fidget device (Aim 2) modulates behavioral and physiological response in cognitively and emotionally-demanding contexts. The hype of the commercially available Fidget Cube, its competitors and fidget spinners suggest it might, but there is no systematic evidence to inform consumers, a gap, we aim to fill. ADHD is a significant problem in adulthood, with estimates of 4.4% in the population (4). It is associated with higher rates of substance use disorders, traffic accidents and employment challenges and a national annual economic impact ranging from $143 to $266 billion (5). While overt hyperactivity is mostly associated with childhood, subtler, finer-grained frequent movements (e.g., leg movements, doodling, clicking objects, tapping) are highly common in adult ADHD. Little is known about the characteristics of fidgeting in adulthood or whether it can be harnessed to enhance self-regulation with the use of an external device. Our aims are as follows: Aim 1: Assess in a randomized controlled study if a) intrinsic fidgeting and b) use of a smart fidget device improves attention, working memory, processing speed and emotional regulation in adult ADHD; Aim 2: Identify specific touch characteristics associated with cognitive and emotional regulation in adult ADHD using behavioral coding and a prototype fidget ball (developed by Co-I Isbister) with embedded pressure sensors on the fidget surface transmitting real time data to a computer for data analysis; Exploratory Aim 3: Conduct a machine learning analysis of fidgeting behavior in relation to cognitive performance and emotional regulation to: 1) automate recognition of touch features present in fidgeting in adult ADHD; 2) correlate touch sequences with cognitive performance measures and; 3) recommend fidgeting strategies that should prove effective in a given situation. This project will build upon prior work by PI Schweitzer, with her expertise in ADHD, clinical translational research and cognitive neuroscience and Co-I Isbister, with expertise in computer science and engineering, who developed sensor-enabled, smart fidget devices with the goal of improving self-regulation of mood and attention (6-9); Co-I Shapiro (10) with machine learning expertise in analyzing fidgeting behavior. This project is highly responsive to NIMH Strategic Plan Objective 3 as it will inform researchers working to develop new interventions based on behavioral and physiological markers, tailored to the individual. This project will study how fidgeting relates to cognitive and emotional functioning in adults with attention- deficit/hyperactivity disorder (ADHD). It will determine, in a laboratory setting, whether movement and access to a “fidget device” providing sensory and motor stimulation can improve cognitive and emotional regulation (including on physiological measures) in adult ADHD. We will also acquire pilot data for machine learning analyses to be used in future, large scale studies to identify gestures and touch characteristics associated with improved cognitive and emotional regulation to see if we can predict and subsequently develop recommendations to improve performance and emotional control in natural settings (e.g., home, office, college classroom) for adult ADHD.",Can fidgeting lead to enhanced attention and emotional regulation in adult ADHD?,10064501,R21MH121901,"['Accidents', 'Adult', 'Affective', 'Arousal', 'Attention', 'Attention deficit hyperactivity disorder', 'Behavior', 'Behavioral', 'Biological Markers', 'Boredom', 'Brain region', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Cues', 'Data', 'Devices', 'Disease', 'Effectiveness', 'Emotional', 'Emotional Stress', 'Employment', 'Engineering', 'Exploratory/Developmental Grant', 'Frequencies', 'Future', 'Gestures', 'Goals', 'Grain', 'Home environment', 'Human', 'Hyperactive behavior', 'Impairment', 'Individual', 'Informal Social Control', 'Intervention', 'Laboratories', 'Lead', 'Leg', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Microprocessor', 'Motor', 'Motor Activity', 'Movement', 'National Institute of Mental Health', 'Occupational', 'Outcome', 'Patient Self-Report', 'Pattern', 'Performance', 'Physiological', 'Physiology', 'Population', 'Prediction of Response to Therapy', 'Reaction Time', 'Readability', 'Recommendation', 'Recovery', 'Regulation', 'Reporting', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Schools', 'Sensory', 'Short-Term Memory', 'Strategic Planning', 'Stress', 'Substance Use Disorder', 'Surface', 'System', 'Tactile', 'Task Performances', 'Taxes', 'Testing', 'Therapeutic Intervention', 'Time', 'Touch sensation', 'Toy', 'Traffic accidents', 'Translational Research', 'Update', 'Video Recording', 'Work', 'alertness', 'base', 'citizen science', 'cognitive enhancement', 'cognitive function', 'cognitive neuroscience', 'cognitive performance', 'cognitive reappraisal', 'college', 'computer data analysis', 'computer science', 'cost', 'design', 'digital', 'economic impact', 'emotion regulation', 'emotional functioning', 'heart rate variability', 'improved', 'large datasets', 'learning strategy', 'mood regulation', 'noradrenergic', 'novel', 'pressure sensor', 'processing speed', 'prototype', 'randomized controlled study', 'response', 'sensor', 'sensorimotor system', 'social relationships', 'success', 'theories', 'young adult']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2020,417969,-0.009199790032216012
"Combining Physiological, Genetic, and Computational Approaches with Naturalistic Climbing Behavior to Elucidate the Functional Elements of Descending Motor Control PROJECT SUMMARY Many mammals are distinguished by the exceptional diversity and agility of their limb movement. These qualities are critical to the fitness certain movements confer, and so to the evolutionary success of many species. While brain regions important for limb control have been identified, the neural signal processing that ultimately governs motor commands sent to muscles has remained stubbornly opaque. Mechanistic models of motor system operation in real time during movement are thus lacking. This obscures the etiology of motor deficits caused by neurological disease and stroke, which in turn stymies the development of effective treatments.  A primary cause of this opacity of motor system processing is the ambiguity of the basic functional elements comprising relevant neural circuits. An emerging view posits that these elements may be neuronal subtypes defined by features like axonal target region, target cell identity, and gene expression. Yet the fundamental question of what are the appropriate cellular features for defining functional units remains unanswered. This ambiguity stems from a host of technical limitations. We expect that functionally salient neuronal subtypes will make characteristic contributions to specific phases of movement. Yet traditional methods for silencing neural activity to assess function lack the temporal resolution to discern such specific influence. We also expect that functionally salient subtypes will exhibit distinct activity patterns and interactions with other neuronal populations. But classical methods for measuring neural firing are typically blind to key cellular features. Moreover, the behavioral paradigms used for motor system studies have not captured essential aspects of natural mammalian movement, for which motor system organization may have been adapted over evolution.  Fortunately though, systems neuroscience is currently being revolutionized by advances in physiological, genetic, and computational techniques. I plan to leverage many of these advances and pursue an innovative approach to resolve the basic functional elements within a model motor system population – the subcerebral projection neurons (SPNs) found in motor areas of the neocortex. We will employ a naturalistic climbing paradigm for mice engineered in my lab to overcome limitations of previous motor behavior paradigms. New genetically- mediated targeting strategies will provide access to potential functional subtypes for activity measurement and perturbation. We will novelly couple optogenetic probes, electromyography, and automated behavior decomposition to distinguish precise phases of neuronal subtype influence. Large-scale, multi-area activity recording, optogenetic identification, and machine learning will parse subtypes by their activity and interactions with other neuronal populations. Our work will articulate an interdisciplinary approach applicable to the fundamental question of functional units in other neural systems as well. The mechanistic insight our work begins to build will help elucidate the etiology of movement deficits stemming from conditions like ALS and Huntington’s disease, and following stroke. PROJECT NARRATIVE Our project aims to identify basic functional elements within motor circuits to help build mechanistic models of motor system operation in real time during movement execution. The lack of such models has sharply limited our understanding of the etiology of motor deficits stemming from neurological disease and stroke, which in turn stymies the development of effective treatment. The mechanistic insight our work builds will thus help elucidate the etiology of motor deficits and facilitate improved treatment.","Combining Physiological, Genetic, and Computational Approaches with Naturalistic Climbing Behavior to Elucidate the Functional Elements of Descending Motor Control",10002981,DP2NS120847,"['Area', 'Axon', 'Behavior', 'Behavioral Paradigm', 'Brain region', 'Cells', 'Characteristics', 'Computational Technique', 'Development', 'Electromyography', 'Elements', 'Engineering', 'Etiology', 'Evolution', 'Exhibits', 'Gene Expression', 'Genetic', 'Genetic Techniques', 'Huntington Disease', 'Limb structure', 'Machine Learning', 'Mammals', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motor', 'Movement', 'Mus', 'Muscle', 'Neocortex', 'Neurons', 'Neurosciences', 'Pattern', 'Phase', 'Physiological', 'Population', 'Stroke', 'System', 'Time', 'Work', 'blind', 'effective therapy', 'fitness', 'improved', 'innovation', 'insight', 'interdisciplinary approach', 'limb movement', 'motor behavior', 'motor control', 'motor deficit', 'nervous system disorder', 'neural circuit', 'neurotransmission', 'novel', 'operation', 'optogenetics', 'relating to nervous system', 'signal processing', 'stem', 'success', 'temporal measurement']",NINDS,NORTHWESTERN UNIVERSITY,DP2,2020,2340462,-0.024756416653164942
"The Neuroscience of Everyday World- A novel wearable system for continuous measurement of brain function Innovations in human neuroimaging tools have driven profound advances in our understanding of brain function under well-controlled and constrained conditions. While we are gaining greater understanding of how the brain functions in single-snapshot experiments under restricted lab settings, we do not know how it works in dynamic, complex and multisensory real-world environments. The goal of this project is to build a portable, miniaturized, lightweight, high-density wearable combined – functional Near Infrared-Spectroscopy (fNIRS) – Electro-Encepholography (EEG) - Eye-tracking system for enabling “Neuroscience of the Everyday World (NEW)” by permitting long duration continuous monitoring of normal / altered brain activity during movement, perception, and social interaction in real time and in the real world. In Aim 1, We will (A) develop a wearable and fully hybrid high-density EEG-fNIRS system that supports autonomous long-term recordings (>6 hours), (B) develop combined and miniaturized active EEG-Electrodes / fNIRS-Optodes; and (C) integrate the wearable system with Tobii Pro 2 eye-tracking/scene-camera glasses and state- of-the-art computer vision for adaptive acquisition and automated data annotation. In Aim 2, we will measure brain activity during walking, perceiving, and interacting, with experiments gradually increasing in complexity through three phases from lab to real world settings in young healthy adults and conduct a proof of principle in two sample clinical populations. In Aim 3, we will create an analysis workflow for data collected in Aim 2 that will accomplish the following: (1) removing nuisance signals from fNIRS/EEG signals, (2) analysis of multimodal fNIRS/EEG and behavioral data, (3) automatic annotation of and adaptation for real world measurements. This project brings together engineers, scientists and clinicians with the goal of building the next generation of imaging tools to capture brain function in real time. With our technological sophistication, interdisciplinary focus, and ready access to well-characterized clinical populations, we are uniquely positioned to successfully develop, apply, and disseminate our NEW technology, and lay down a foundation upon which groundbreaking advances in our understanding of the links between brain activity and behavior will build. There is a need to link brain activity to human movement, perception and cognition, and social communication in real time, and in the Everyday World. This project aims to develop a multi- modal wearable functional neuroimaging device to study brain function in freely behaving healthy subjects and to track the breakdown of normal brain function potentially revealing brain patterns that are signatures of these conditions.",The Neuroscience of Everyday World- A novel wearable system for continuous measurement of brain function,10007021,U01EB029856,"['Address', 'Adult', 'Algorithms', 'Area', 'Behavior', 'Behavioral', 'Blood Vessels', 'Brain', 'Brain imaging', 'Clinical', 'Cognition', 'Communication', 'Complement', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Device or Instrument Development', 'Devices', 'Disease', 'Electrodes', 'Engineering', 'Environment', 'Failure', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Hour', 'Human', 'Hybrids', 'Imaging Device', 'Individual', 'Investigation', 'Laboratories', 'Link', 'Maps', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Movement', 'Near-Infrared Spectroscopy', 'Neurologic', 'Neurons', 'Neurosciences', 'Noise', 'Parkinson Disease', 'Pattern', 'Perception', 'Phase', 'Physiological', 'Population', 'Positioning Attribute', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Signal Transduction', 'Social Interaction', 'Speech', 'Stroke', 'Support System', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translations', 'Walking', 'Work', 'density', 'design', 'experimental study', 'frontier', 'hemodynamics', 'innovation', 'insight', 'light weight', 'millisecond', 'miniaturize', 'multimodality', 'multisensory', 'nervous system disorder', 'neurofeedback', 'neuroimaging', 'new technology', 'next generation', 'novel', 'novel strategies', 'portability', 'relating to nervous system', 'response', 'sensory stimulus', 'signal processing', 'social communication', 'tool', 'visual tracking', 'wearable sensor technology']",NIBIB,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),U01,2020,1000000,0.0005273795350932853
"Sensor-based Just-in Time Adaptive Interventions (JITAIs) Targeting Eating Behavior PROJECT SUMMARY/ABSTRACT Long-term weight control is difficult to achieve and requires permanent changes in eating behavior. Emerging wearable sensor technology enables accurate and objective measurement of ingestive behavior, and real-time analysis of the sensor data paves the way for development of individually tailored and immediately delivered intervention (just-in-time adaptive Intervention; JITAI) to change eating behavior. Grounded in empirically and theoretically supported behavior change strategies for weight control, the proposed project relies on the synergy of wearable sensor technology, machine learning, behavioral science, personalized medicine, and nutrition to deliver and test such JITAIs. We previously developed a wearable sensor, the Automatic Ingestion Monitor (AIM), that automatically and accurately detects eating and characterizes meal microstructure (e.g., eating duration, rate of ingestion). These data can also be used to accurately estimate energy intake. The goals of this project are to: 1) use the AIM to study two common behavioral patterns observed among individuals with overweight/obesity, namely, excessive total daily energy intake (EI) and fast eating rate; 2) define the optimal personalized triggering metrics for two JITAIs targeting these behaviors; and 3) evaluate JITAIs’ effects on daily energy intake and targeted behaviors. In fulfillment of these goals, we will first conduct a study to characterize the target eating behaviors, then simulate and define triggering metrics for personalized JITAIs to change targeted eating behaviors and decrease EI. The JITAIs are rooted in self-regulation theory (SRT): setting a behavioral goal and monitoring progress toward that goal, with feedback to reinforce success. To enable the SRT-informed JITAIs, we will first use the AIM to collect data about ingestive behaviors quantified by objective, sensor-measured metrics from 90 adults with overweight/obesity who will wear the device for one week in free living conditions. Second, using the collected dataset, we will: a) analyze individual curves of cumulative daily EI and rate of eating within eating episodes to define triggering parameters for personalized JITAI delivery, and b) numerically simulate JITAI delivery and effects. We will then conduct a second study to evaluate the immediate effect of JITAIs on EI and ingestive behavior in free living participants. We will conduct a within-subjects trial with 128 adults wearing the AIM for 7 weeks. To personalize JITAIs, the AIM will learn individual eating patterns over a 1-week run-in period. Each JITAI will be delivered for two weeks (weeks 2-3 and 5-6) in a randomized crossover design with the resulting daily EI and ingestive behavior compared to baseline and the acceptability of the JITAIs assessed via questionnaire. On washout weeks 4 and 7, participants will continue to wear the AIM (no JITAIs) to assess persistence of intervention effects. The proposed project is the first step in demonstrating that AIM-based JITAIs can alter a variety of eating behaviors associated with excess EI. PROJECT NARRATIVE Achievement of changes in eating behaviors that facilitate long-term weight loss and maintenance is elusive. Emerging wearable sensor technology allows for accurate and objective measurement of ingestive behavior. Real-time analysis of the sensor data paves the way for individually tailored just-in-time adaptive interventions (JITAIs) based on empirically and theoretically supported behavior change strategies for healthy eating and weight control. The proposed project relies on synergy of wearable sensor technology, machine learning, behavioral science, personalized medicine, and nutrition to test two such JITAIs driven by the Automatic Ingestion Monitor (AIM), a device that automatically detects and characterize eating behavior in real-time. The information provided by the AIM will be used to implement and test personalized, adaptable behavioral interventions aimed at the reduction of energy intake.",Sensor-based Just-in Time Adaptive Interventions (JITAIs) Targeting Eating Behavior,10005321,R01DK122473,"['Achievement', 'Adult', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Behavioral Sciences', 'Body Weight decreased', 'Cellular Phone', 'Child', 'Crossover Design', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetes Mellitus', 'Eating', 'Eating Behavior', 'Eating Disorders', 'Elderly', 'Energy Intake', 'Feedback', 'Feeding behaviors', 'Food', 'Future', 'Goals', 'Healthy Eating', 'Image', 'Individual', 'Informal Social Control', 'Ingestion', 'Intervention', 'Learning', 'Liquid substance', 'Machine Learning', 'Mastication', 'Measurement', 'Measures', 'Monitor', 'Obesity', 'Overweight', 'Participant', 'Patient Self-Report', 'Pattern', 'Plant Roots', 'Population', 'Questionnaires', 'Randomized', 'Running', 'Sampling', 'Testing', 'Time', 'Weight', 'Weight maintenance regimen', 'Work', 'adaptive intervention', 'base', 'behavior change', 'clinical practice', 'cost', 'healthy weight', 'increased appetite', 'innovation', 'intervention effect', 'nutrition', 'personalized intervention', 'personalized medicine', 'sensor', 'simulation', 'success', 'sucking', 'synergism', 'theories', 'wearable device', 'wearable sensor technology', 'weight maintenance']",NIDDK,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R01,2020,613085,0.006838340412141487
"Sensor-based Just-in Time Adaptive Interventions (JITAIs) Targeting Eating Behavior PROJECT SUMMARY/ABSTRACT Long-term weight control is difficult to achieve and requires permanent changes in eating behavior. Emerging wearable sensor technology enables accurate and objective measurement of ingestive behavior, and real-time analysis of the sensor data paves the way for development of individually tailored and immediately delivered intervention (just-in-time adaptive Intervention; JITAI) to change eating behavior. Grounded in empirically and theoretically supported behavior change strategies for weight control, the proposed project relies on the synergy of wearable sensor technology, machine learning, behavioral science, personalized medicine, and nutrition to deliver and test such JITAIs. We previously developed a wearable sensor, the Automatic Ingestion Monitor (AIM), that automatically and accurately detects eating and characterizes meal microstructure (e.g., eating duration, rate of ingestion). These data can also be used to accurately estimate energy intake. The goals of this project are to: 1) use the AIM to study two common behavioral patterns observed among individuals with overweight/obesity, namely, excessive total daily energy intake (EI) and fast eating rate; 2) define the optimal personalized triggering metrics for two JITAIs targeting these behaviors; and 3) evaluate JITAIs’ effects on daily energy intake and targeted behaviors. In fulfillment of these goals, we will first conduct a study to characterize the target eating behaviors, then simulate and define triggering metrics for personalized JITAIs to change targeted eating behaviors and decrease EI. The JITAIs are rooted in self-regulation theory (SRT): setting a behavioral goal and monitoring progress toward that goal, with feedback to reinforce success. To enable the SRT-informed JITAIs, we will first use the AIM to collect data about ingestive behaviors quantified by objective, sensor-measured metrics from 90 adults with overweight/obesity who will wear the device for one week in free living conditions. Second, using the collected dataset, we will: a) analyze individual curves of cumulative daily EI and rate of eating within eating episodes to define triggering parameters for personalized JITAI delivery, and b) numerically simulate JITAI delivery and effects. We will then conduct a second study to evaluate the immediate effect of JITAIs on EI and ingestive behavior in free living participants. We will conduct a within-subjects trial with 128 adults wearing the AIM for 7 weeks. To personalize JITAIs, the AIM will learn individual eating patterns over a 1-week run-in period. Each JITAI will be delivered for two weeks (weeks 2-3 and 5-6) in a randomized crossover design with the resulting daily EI and ingestive behavior compared to baseline and the acceptability of the JITAIs assessed via questionnaire. On washout weeks 4 and 7, participants will continue to wear the AIM (no JITAIs) to assess persistence of intervention effects. The proposed project is the first step in demonstrating that AIM-based JITAIs can alter a variety of eating behaviors associated with excess EI. PROJECT NARRATIVE Achievement of changes in eating behaviors that facilitate long-term weight loss and maintenance is elusive. Emerging wearable sensor technology allows for accurate and objective measurement of ingestive behavior. Real-time analysis of the sensor data paves the way for individually tailored just-in-time adaptive interventions (JITAIs) based on empirically and theoretically supported behavior change strategies for healthy eating and weight control. The proposed project relies on synergy of wearable sensor technology, machine learning, behavioral science, personalized medicine, and nutrition to test two such JITAIs driven by the Automatic Ingestion Monitor (AIM), a device that automatically detects and characterize eating behavior in real-time. The information provided by the AIM will be used to implement and test personalized, adaptable behavioral interventions aimed at the reduction of energy intake.",Sensor-based Just-in Time Adaptive Interventions (JITAIs) Targeting Eating Behavior,10142163,R01DK122473,"['Achievement', 'Adult', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Behavioral Sciences', 'Body Weight decreased', 'Cellular Phone', 'Child', 'Crossover Design', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetes Mellitus', 'Eating', 'Eating Behavior', 'Eating Disorders', 'Elderly', 'Energy Intake', 'Feedback', 'Feeding behaviors', 'Food', 'Future', 'Goals', 'Healthy Eating', 'Image', 'Individual', 'Informal Social Control', 'Ingestion', 'Intervention', 'Learning', 'Liquid substance', 'Machine Learning', 'Mastication', 'Measurement', 'Measures', 'Monitor', 'Obesity', 'Overweight', 'Participant', 'Patient Self-Report', 'Pattern', 'Plant Roots', 'Population', 'Questionnaires', 'Randomized', 'Running', 'Sampling', 'Testing', 'Time', 'Weight', 'Weight maintenance regimen', 'Work', 'adaptive intervention', 'base', 'behavior change', 'clinical practice', 'cost', 'healthy weight', 'increased appetite', 'innovation', 'intervention effect', 'nutrition', 'personalized intervention', 'personalized medicine', 'sensor', 'simulation', 'success', 'sucking', 'synergism', 'theories', 'wearable device', 'wearable sensor technology', 'weight maintenance']",NIDDK,UNIVERSITY OF ALABAMA IN TUSCALOOSA,R01,2020,58911,0.006838340412141487
"Chemogenetic afferent modulation to understand spinal cord circuit function and plasticity post injury PROJECT SUMMARY Spinal cord injury (SCI) causes life-long neurological impairment, and there is currently no effective treatment. The premise of this proposal is recent work demonstrating that afferent stimulation paired with treadmill training can enhance standing, stepping, and volitional control in humans and animal models. Therefore, it is critically important to understand the mechanisms by which afferent stimulation drives motor improvement. Tools that can identify which afferents are necessary and sufficient to enhance recovery, and that can facilitate characterization of the helpful neural plasticity, are urgently needed. Our long-term goal is to develop approaches for selective afferent modulation, and apply them to the dissection of the mechanisms underlying recovery from SCI. The objective of this grant is to identify which sets of afferents are important for recovery and how spinal circuits change to facilitate it. To achieve selective modulation of afferents and enable genetic tracing we will use Designer Receptors Exclusively Activated by Designer Drugs (DREADDs) that can modulate excitability in specific populations of neurons. To accurately quantify improvement, we will use Deep Learning to analyze large kinematic data sets. Our preliminary data shows strong expression of DREADDs in large diameter DRG neurons, that their activation by CNO can excite or inhibit the H-reflex, and that activation of excitatory DREADDs during treadmill training post-SCI improves stepping. Our main hypothesis is that activation of large afferents by the excitatory DREADD (hM3Dq) during treadmill training will enhance recovery, whereas inhibitory DREADDs (hM4Di) will suppress recovery. Four sub- hypotheses will test whether recovery is mediated by increased afferent projection onto 1) motor neurons, or 2) inhibitory interneurons; or by sprouting of 3) reticulospinal and 4) propriospinal circuits. Our Specific Aims are to determine whether selective expression of DREADDs in (Aim 1) all large diameter (proprioceptive and tactile) neurons and (Aim 2) large proprioceptive afferents only can enhance recovery. The rationale for these aims is that afferent stimulation is hypothesized to work through selective excitation of large diameter sensory afferents (LDSA) that both drive motor pools locally and facilitate proprio- and surpraspinal input. To date, it has not been possible to definitively determine which afferents were recruited after electrical stimulation, or to select between afferents of similar diameter. The significance of this work lies in determining whether recovery is mediated exclusively by proprioceptive axons or a combination of proprioceptive and tactile afferents, and uncovering the mechanisms of functional plasticity in the spinal cord. PROJECT NARRATIVE Approximately 300,000 individuals are living with spinal cord injury (SCI) in the USA without an effective treatment. Recently, spinal cord stimulation during rehabilitation has been found to enable better standing, stepping, and voluntary control in patients with SCI. This study will improve our understanding of these mechanisms by 1) using new genetic tools to identify which afferents are necessary and sufficient for improvement, and 2) using genetic tracing techniques to uncover how spinal circuits are changing to enhance function.",Chemogenetic afferent modulation to understand spinal cord circuit function and plasticity post injury,10051492,R01NS114007,"['Affect', 'Afferent Neurons', 'Animal Model', 'Animals', 'Axon', 'Behavioral', 'Caliber', 'Complex', 'Coupled', 'Cutaneous', 'Data', 'Data Set', 'Dissection', 'Electric Stimulation', 'Genetic', 'Goals', 'Grant', 'H-Reflex', 'Histologic', 'Human', 'Impairment', 'Individual', 'Injury', 'Interneurons', 'Lesion', 'Life', 'Locomotor Recovery', 'Mediating', 'Methods', 'Modeling', 'Motor', 'Motor Neurons', 'Motor output', 'Movement', 'Neurologic', 'Neuronal Plasticity', 'Neurons', 'Neurostimulation procedures of spinal cord tissue', 'Outcome', 'Parvalbumins', 'Patients', 'Play', 'Population', 'Rattus', 'Recovery', 'Rehabilitation therapy', 'Role', 'Sensory', 'Spinal', 'Spinal Cord', 'Spinal Cord Contusions', 'Spinal cord injury', 'Synapses', 'Tactile', 'Techniques', 'Testing', 'Toes', 'Tracer', 'Training', 'Volition', 'Walking', 'Work', 'base', 'deep learning', 'density', 'designer receptors exclusively activated by designer drugs', 'effective therapy', 'feeding', 'functional plasticity', 'human model', 'improved', 'injury recovery', 'kinematics', 'neural circuit', 'neural network', 'neuronal excitability', 'neurophysiology', 'neuroregulation', 'novel', 'novel strategies', 'recruit', 'relating to nervous system', 'selective expression', 'sensory input', 'tool', 'treadmill training', 'vector']",NINDS,TEMPLE UNIV OF THE COMMONWEALTH,R01,2020,416293,-0.01892307646432073
"Inferential methods for functional data from wearable devices Project Summary/Abstract This is a project to develop new statistical methods for comparing groups of subjects in terms of health outcomes that are assessed using data from wearable devices. Inexpensive wearable sensors for health monitoring are now capable of generating massive amounts of data collected longitudinally, up to months at a time. The project will develop inferential methods that can deal with the complexity of such data. A serious challenge is the presence of unmeasured time-dependent confounders (e.g., circadian and dietary patterns), making direct comparisons or borrowing strength across subjects untenable unless the studies are carried out in controlled experimental con- ditions. Generic data mining and machine learning tools have been widely used to provide predictions of health status from such data. However, such tools cannot be used for signiﬁcance testing of covariate effects, which is necessary for designing precision medicine interventions, for example, without taking the inherent model selection or the presence of the unmeasured confounders into account. To overcome these difﬁculties, a systematic de- velopment of inferential methods for functional outcome data obtained from wearable devices will be carried out. There are three speciﬁc aims: 1) Develop metrics for functional outcome data from wearable devices, 2) Develop nonparametric estimation and testing methods for activity proﬁles and a screening method for predictors of activity proﬁles, 3) Implement the methods in an R package and carry out two case studies using accelerometer data. For Aim 1, the approach is to reduce the sensor data to occupation time proﬁles (e.g., as a function of activity level), and formulate the statistical modeling in terms of these proﬁles using survival and functional data analytic meth- ods. This will have a number of advantages, the principal one being that time-dependent confounders become less problematic because the effect of differences in temporal alignment across subjects is mitigated. In addition, survival analysis methods can be applied by viewing the occupation time as a time-to-event outcome indexed by activity level. For Aim 2, nonparametric methods will be used to compare and order occupation time distributions between groups of subjects that are speciﬁed in terms of baseline covariate levels or treatment groups. Further, a new method of post-selection inference based on marginal screening for function-on-scalar regression will be developed to identify and formally test whether covariates are signiﬁcantly associated with activity proﬁles. Aim 3 will develop an R-package implementation, and as a test-bed for the proposed methods they will be applied to two Columbia-based clinical studies: to the study of physical activity in children enrolled in New York City Head Start, and to the study of experimental drugs for the treatment of mitochondrial depletion syndrome. Project Narrative The relevance of the project to public health is that it will develop statistical methods for the physiological eval- uation of patients on the basis of data collected by inexpensive wearable sensors (e.g., accelerometers). By introducing methods for the rigorous comparison of healthcare status among groups of patients observed longi- tudinally over time using such devices, treatment decisions that can beneﬁt targeted populations of patients in terms of continuously-assessed health outcomes will become possible.",Inferential methods for functional data from wearable devices,9924432,R01AG062401,"['Acceleration', 'Accelerometer', 'Beds', 'Bypass', 'Case Study', 'Characteristics', 'Child', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Dietary Practices', 'Drug Combinations', 'Enrollment', 'Evaluation', 'Event', 'Grant', 'Head Start Program', 'Health', 'Health Status', 'Healthcare', 'Intervention', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Monitor', 'Motivation', 'Nature', 'New York City', 'Obesity', 'Occupations', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmacotherapy', 'Physical activity', 'Physiological', 'Preschool Child', 'Process', 'Proxy', 'Public Health', 'Recording of previous events', 'Regimen', 'Signal Transduction', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Stochastic Processes', 'Survival Analysis', 'Syndrome', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Work', 'analytical method', 'base', 'circadian', 'data mining', 'design', 'experimental study', 'functional outcomes', 'indexing', 'interest', 'lower income families', 'novel', 'patient population', 'precision medicine', 'screening', 'sensor', 'theories', 'time use', 'tool', 'treatment group', 'wearable device', 'wearable sensor technology']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,298890,0.0016796700429976515
"Device to control circadian-effective light in Alzheimer's disease environments Project Summary This proposed project will develop and field-test a device that accurately monitors and controls the circadian stimulus (CS) for Alzheimer disease (AD) and Alzheimer-disease-related dementia (ADRD) patients in nursing homes. Human biology has evolved to have two distinct optical systems: the visual system, by which we see and process images, and the circadian system, which regulates our biological clock and associated biological systems. These two systems have significantly different spectral and temporal responses to optical input. Specifically, circadian stimulation peaks at 460 nm and responds after several minutes of optical activation, while the visual system peaks at 555 nm and responds nearly instantaneously to inputs. All lighting systems are designed and installed in buildings with consideration only given to the photopic (visual) system and all light meters used to characterize lighting buildings are calibrated to measure photopic light, not CS. While a broad and growing body of research has documented the impacts of the circadian system on human health, including regulating sleep and improving cognition in AD/ADRD patients, research on the CS experienced by AD/ADRD patients is extremely limited. Researchers at the Lighting Research Center at Rensselaer Polytechnic Institute developed the Daysimeter, a calibrated light meter that measures circadian light and circadian stimulus. In Phase I of this project, researchers modified an existing workstation-based lighting control system they previously developed for the visual system to include Daysimeter technology, allowing this control system to record CS measurements. The accuracy of these CS measurements was confirmed in the laboratory and field-testing of 20 of devices is currently ongoing in AD/ADRD nursing homes. In this Phase II application, researchers propose adding control features to this device so that lighting can be controlled to optimize CS dosages in AD/ADRD patient environments. Machine learning-based lighting control algorithms will be driven by continuous light level and spectrum measurements as well as periodic (e.g., daily) patient health data. Data from these devices would be wirelessly transmitted to researchers via an Internet gateway and associated cloud-based data management systems. These data would be of immediate value for gaining a better understanding of AD/ADRD patients' CS exposure and could ultimately result in new lighting systems and/or building codes that consider both our visual and circadian systems. Following the development phase, 30 CS-enabled lighting control systems will be field tested over a 22-week test period. Researchers aim to commercialize this CS-enabled lighting control system shortly after the completion of this field test and the Phase II project specifically targeting AD/ADRD nursing home applications. Project Narrative A growing body of research has demonstrated how light impacts human circadian systems and how these impacts can affect sleep, alertness, cognition and agitation in people with Alzheimer's disease (AD) and Alzheimer's-disease-related dementia (ADRD). Still, significant knowledge gaps exist in determining how much circadian stimulation is typically provided to AD/ADRD patients and there are no commercial products designed to control lighting in AD/ADRD environments in ways that promote circadian-related health. This project aims to fill in these gaps by developing and testing a device specifically designed to measure and control the circadian stimulation experienced by AD/ADRD patients in nursing homes.",Device to control circadian-effective light in Alzheimer's disease environments,10018621,R44AG060857,"['Affect', 'Agitation', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Back', 'Behavior', 'Biological Clocks', 'Building Codes', 'Characteristics', 'Clinical Trials', 'Cognition', 'Data', 'Database Management Systems', 'Development', 'Device or Instrument Development', 'Devices', 'Dose', 'Effectiveness', 'Elderly', 'Environment', 'Feeds', 'Health', 'Hour', 'Human', 'Human Biology', 'Image', 'Institutes', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Measures', 'Monitor', 'Moods', 'Nursing Homes', 'Optics', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Phototherapy', 'Planet Earth', 'Population', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Rotation', 'Running', 'Sleep', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Visual', 'Visual system structure', 'Wakefulness', 'Wireless Technology', 'Work', 'active control', 'alertness', 'appropriate dose', 'awake', 'base', 'biological systems', 'circadian', 'circadian pacemaker', 'cloud based', 'commercialization', 'design', 'dosage', 'effectiveness testing', 'experience', 'falls', 'field study', 'health data', 'improved', 'interest', 'meter', 'next generation', 'novel', 'prototype', 'residence', 'response', 'success', 'therapy design']",NIA,"ERIK PAGE AND ASSOCIATES, INC.",R44,2020,1232387,-0.03496869627843222
"Multiple timescales of motor planning and execution in mouse cortex Project Summary/Abstract: For animals to execute complicated behaviors, successful motor planning and execution is essential. Moreover, the sequence of events leading to successful goal-based behavior takes place over a wide range of timescales. For example, when walking from home to work, one must first make an abstract, long-timescale decision to go to work, which much then be translated into a sequence of shorter-timescale right-left turning decisions, which are translated into the finely fluctuating electrical patterns that control the muscles. How motor planning and execution occur simultaneously over many timescales in populations of motor cortex neurons is not well understood. Much work in humans and nonhuman primates have shown that visual and auditory stimuli integrate over multiple timescales. This work has shown that early sensory regions, like primary visual cortex, respond to fast fluctuations in the environment. This information is integrated to longer-timescale information in secondary cortical regions, with the longest- timescale information in frontal and association areas. We therefore hypothesize that secondary motor cortex (M2) neurons control behavior over longer timescales than primary motor cortex (M1) neurons. To study this phenomenon, I have built a setup in which head-fixed mice navigate in virtual reality to a rewarded location. In this setup, I can record video from all sides of the animal for high spatiotemporal resolution measurement of motor behaviors. I have developed machine learning algorithms to extract 3D pose data from these videos. In Aim 1, I will use calcium imaging to record large numbers of neurons in mouse M1 and M2 to correlate the activity of individual neurons and populations to the animal’s ongoing pose kinematics. We will supplement with targeted silicon probe recordings to capture fast neural responses. In Aim 2, I will compare the calcium dynamics in populations of M1 and M2 neurons in mice trained to perform a virtual motor planning task versus mice that have not been trained. We hypothesize that training to plan motor actions increases the timescale of M1/M2 neural activity. In Aim 3, we will use optogenetic silencing in specific regions of cortex to perturb the animal’s motor behavior. We hypothesize that the duration of the perturbed movements will be longer when M2 is perturbed than M1. In this way, we will study how different cortical regions relate to behavior over many timescales. This proposal will broaden our knowledge of cortical processing in general, and motor planning and execution in particular. Patients with mental illness, such as ADHD, autism, and Asperger’s disorder show impaired ability to plan upcoming movements. The first step to successfully treating these illnesses is to better understand how motor planning occurs in general. Project Narrative: This proposal will elucidate how motor planning and execution take place simultaneously, over many timescales, and across brain regions. Better understanding motor planning will help generate new treatments for diseases that affect motor planning, like attention deficit hyperactivity disorder and autism.",Multiple timescales of motor planning and execution in mouse cortex,10007591,F31NS108450,"['3-Dimensional', 'Affect', 'Animal Behavior', 'Animals', 'Area', 'Asperger Syndrome', 'Attention deficit hyperactivity disorder', 'Behavior', 'Behavior Control', 'Brain region', 'Calcium', 'Code', 'Communication', 'Cues', 'Data', 'Disease', 'Ensure', 'Environment', 'Event', 'Future', 'Goals', 'Head', 'Home environment', 'Human', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Laser Scanning Microscopy', 'Lasers', 'Left', 'Light', 'Location', 'Measurement', 'Measures', 'Memory', 'Mental disorders', 'Modeling', 'Motor', 'Motor Cortex', 'Movement', 'Mus', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Population', 'Research', 'Resolution', 'Rewards', 'Running', 'Sensory', 'Short-Term Memory', 'Side', 'Silicon', 'Stereotyping', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Vision', 'Walking', 'Work', 'area striata', 'auditory stimulus', 'autism spectrum disorder', 'base', 'frontal lobe', 'kinematics', 'machine learning algorithm', 'motor behavior', 'neuromechanism', 'nonhuman primate', 'novel', 'optogenetics', 'prevent', 'relating to nervous system', 'response', 'sensory cortex', 'sensory stimulus', 'spatiotemporal', 'theories', 'two-photon', 'virtual', 'virtual reality', 'visual stimulus']",NINDS,HARVARD MEDICAL SCHOOL,F31,2020,33236,-0.02625848593864341
"Graphene-based Nanosensor Device for Rapid, Onsite Detection of Total Lead in Tap Water PROJECT SUMMARY Detrimental health impacts of lead are largely attributed to long-term exposures to undetected lead, which are particularly troublesome and problematic because of the neurological damage to children, a situation that should not be tolerated by an advanced society like the U.S. The Flint Water Crisis and many other water catastrophes could have been avoided if early warning can be made possible through timely detection of lead in drinking water at the point of use. Our extensive customer interviews unambiguously suggest that current options for lead detection are unsatisfactory for on-site testing, as they represent two extremes: one being accurate but expensive, slow, and hard to use; and the other being low-cost, fast, and easy to use but inaccurate. NanoAffix Science LLC (NAFX) proposes to address the above unmet need and niche market product gap by empowering water users (particularly those in economically disadvantaged communities) and water service providers with a low-cost, easy-to-use, and accurate handheld tester for rapid detection of total lead in the tap water, right from the kitchen sink. The handheld lead tester combines a novel proprietary micro-sized sensor chip embedded in a proprietary test cell with a portable digital meter for direct readout of testing results. The Phase I project has successfully established the feasibility for detection of soluble lead in the tap water using an earlier version of the prototype handheld tester. The Phase II project will continue to develop the handheld tester toward total lead detection, better device uniformity, pilot scale-up manufacturing, and accurate calibration. At the end of the Phase II project, NAFX plans to produce 20 beta units of the handheld lead tester meeting all performance specifications for field validation by 10 initial customers (e.g., schools/daycares, end water users, and well water drillers). Major innovations of the proposed approach include accurate prediction of the particulate lead through partial digestion based on lead digestion kinetics, and strategic and synergistic improvement of the ultimate sensor prediction accuracy by (1) improving the physical sensor device uniformity (both intra-wafer and inter-wafer) through innovative device configuration and rigorous quality control; and (2) improving the calibration accuracy through innovative theoretical equilibrium chemistry modeling and machine learning data analytics. The NAFX handheld lead tester is the first of its kind to (1) offer all three features sought by customers: accurate, cheap, and fast; and (2) to simultaneously report all three types of lead: total lead (indicative of overall toxicity), soluble lead (indicative of slow leaching of lead), and particulate lead (indicative of sporadic flaking of lead), which thus can not only alert customers to the lead hazard in their drinking water but also enable customers to identify possible causes and most effective solutions to mitigate the lead contamination. Therefore, the project will result in not only considerable economic impact but also immense societal impact. The regular use of NAFX handheld tester - even if intermittently - will virtually eliminate the chance of chronic exposure to undetected lead, thereby accruing significant and predictable public health impact, especially in locations with the highest risk. PROJECT NARRATIVE The NanoAffix Phase II project aims to continue the development of a handheld lead tester for accurate and low- cost onsite detection of total lead in tap water by untrained users, based on the success of the Phase I project. The project will contribute to enhancing the public health by offering an accessible tool for quantitative monitoring of all three types of lead: total lead (indicative of overall toxicity), soluble lead (indicative of slow leaching of lead), and particulate lead (indicative of sporadic flaking of lead) in tap water. The regular use of NanoAffix handheld tester - even if intermittently - will virtually eliminate the chance of chronic exposure to undetected lead, thereby accruing significant and predictable public health impact, especially in locations with the highest risk.","Graphene-based Nanosensor Device for Rapid, Onsite Detection of Total Lead in Tap Water",10024064,R44ES028656,"['Address', 'Algorithms', 'Calibration', 'Cations', 'Cells', 'Chemistry', 'Child', 'Chronic', 'Communication', 'Communities', 'Complex', 'Contracts', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Digestion', 'Disinfection', 'Economically Deprived Population', 'Equilibrium', 'Equipment', 'Exposure to', 'Goals', 'Gold', 'Health', 'International', 'Interview', 'Kinetics', 'Laboratories', 'Lead', 'Lead Poisoning', 'Location', 'Machine Learning', 'Measurement', 'Michigan', 'Modeling', 'Monitor', 'Nervous System Trauma', 'Paper', 'Particulate', 'Performance', 'Phase', 'Procedures', 'Process', 'Public Health', 'Quality Control', 'Reporting', 'Research', 'Schools', 'Science', 'Site', 'Societies', 'Specialist', 'System', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Training', 'Uncertainty', 'Validation', 'Variant', 'Water', 'Water Supply', 'Wireless Technology', 'aqueous', 'base', 'cost', 'digital', 'drinking water', 'economic impact', 'empowered', 'graphene', 'hazard', 'high risk', 'improved', 'innovation', 'lead concentration', 'lead contamination', 'manufacturing scale-up', 'meetings', 'meter', 'nanosensors', 'novel', 'operation', 'portability', 'prototype', 'rapid detection', 'real time monitoring', 'response', 'sample collection', 'sensor', 'service providers', 'success', 'tool', 'virtual', 'water quality', 'well water']",NIEHS,"NANOAFFIX SCIENCE, LLC",R44,2020,719088,0.0099166918031187
"Characterizing Activity Patterns in Functional Mobility After Spinal Cord Injury Abstract  My career and research interests have centered on the science of movement and factors that maximize mobility. Whether this is through injury prevention, assistive technology, or biomechanical optimization, it is critical to clinical practice that these processes be well understood so that we can provide the most informed patient treatments. In order to carry out more effective clinically-based studies that inform patient care, it is my desire to continue my training through practical experiences with both formal coursework and a oversight by a strong mentoring team in the following domains: (1) activity-based data collection and analysis and (2) use of advanced statistical methods to investigate multiple factors. Through the K23, I will also gain experience specifically focused on my transition to independence; this will include grantsmanship and lab management, leading the design and implementation of clinical and translational studies, management of personnel and meetings, and pursuit of tenure and an R01. This continued training will be completed in the context of a research study that characterizes activity patterns in functional mobility after spinal cord injury (SCI).  Aim 1 of this study is to predict mobility at discharge and at 1-year post-discharge, based upon patient characteristics and activity during IPR. Mobility outcomes can be challenging to predict, particularly for individuals with moderate strength and sensory impairments. Selecting appropriate training is increasingly important with shrinking lengths of stay and there are potential opportunity costs and adverse consequences on quality of life and participation for individuals who do not receive appropriate interventions. Additional activity measures that we can collect early in the IPR stay, by utilizing low-cost sensors, have the potential to provide rich data sets that we can examine to garner insight into outcomes with little administrative burden. Using a machine learning approach, we will investigate patient characteristics and activity-monitoring data to improve predictive models of patient mobility based on data acquired early in the rehab stay. Achieving these aims will improve patient and clinician understanding of anticipated changes in mobility in the year following SCI to appropriately target expectations and interventions to maximize functional outcomes.  Aim 2 of this proposal is to quantitatively evaluate functional mobility changes (i.e., wheeling walking or changes in activity within mode) in the first year post injury and their impact on quality of life and participation. There are factors following discharge that challenge or enhance the sustainability of walking for functional mobility including energy costs, neurologic recovery and biopsychosocial factors such as resilience, self-efficacy, environment, and caregiver support. The association between these factors and post-discharge changes in mobility are not well understood. Using wearable sensors we will quantify time spent walking and wheeling to identify transitions between walking and wheeling, identify factors that contribute to these transitions and investigate their impact on participation. Project Narrative In the context of steadily decreasing lengths of stay for inpatient rehabilitation, and in conjunction with therapy caps in outpatient therapy settings that have led to an overall decrease in patient time spent within a clinical context, it is becoming ever more critical that rehabilitation interventions appropriately target functional mobility (walking or wheeling). Unfortunately, the needed data on how mobility changes following discharge and those factors that most accurately predict patient outcomes is lacking. This proposal seeks to improve patient and clinician understanding of anticipated changes in mobility in the year following SCI so that expectations and interventions can be appropriately targeted to maximize functional outcomes through the following aims: (1) predict mobility at 1 year post-discharge based on patient characteristics, biopyschosocial factors, and activity during inpatient rehabilitation and (2) quantitatively evaluate functional mobility changes in the first year post injury and their impact on quality of life and participation.",Characterizing Activity Patterns in Functional Mobility After Spinal Cord Injury,10003374,K23HD096134,"['Address', 'Biomechanics', 'Caregiver support', 'Caring', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Coin', 'Cost efficiency', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Dose', 'Environment', 'Esthesia', 'Exertion', 'Foundations', 'Future', 'Goals', 'Impairment', 'Individual', 'Injury', 'Inpatients', 'Intervention', 'Joints', 'Kinesiology', 'Length of Stay', 'Machine Learning', 'Measures', 'Mentors', 'Modeling', 'Monitor', 'Movement', 'Outcome', 'Outpatients', 'Pain', 'Pathology', 'Patient Care', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Personnel Management', 'Physical activity', 'Predictive Factor', 'Probability', 'Process', 'Quality of life', 'Rehabilitation therapy', 'Research', 'Resource Allocation', 'Resources', 'Secondary to', 'Self Efficacy', 'Self-Help Devices', 'Sensory', 'Spinal cord injury', 'Statistical Methods', 'Therapeutic Intervention', 'Time', 'Training', 'Upper Extremity', 'Walking', 'Wheelchairs', 'adverse outcome', 'base', 'biopsychosocial', 'career', 'clinical care', 'clinical implementation', 'clinical practice', 'community setting', 'cost', 'design', 'evidence base', 'expectation', 'experience', 'functional outcomes', 'gait rehabilitation', 'improved', 'improved mobility', 'injury prevention', 'innovation', 'inpatient service', 'insight', 'interest', 'meetings', 'muscle strength', 'neurological recovery', 'opportunity cost', 'patient mobility', 'person centered', 'predictive modeling', 'preservation', 'research study', 'resilience', 'sensor', 'translational study', 'wearable sensor technology']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K23,2020,132314,0.01695534429738523
"Clinical Evaluation of Burns using Spatial Frequency Domain Imaging Program Director/Principal Investigator (Last, First, Middle): Durkin, Anthony J. Abstract The central aim of this 3 year competing R01 renewal is to characterize and apply a new, compact, clinic- friendly Spatial Frequency Domain Imaging (SFDI) device to objectively and non-invasively classify burn severity (burn grade) over a large areas of skin. Delays in determining burn severity directly impacts patient treatment plans (including decisions whether to graft), rates of infection and scarring, duration of hospitalization and ultimately cost of care. Currently, the primary method of determining burn severity continues to be clinical assessment, which is highly subjective. While both superficial thickness and full-thickness burns are typically readily diagnosed based on visual clinical impression, partial thickness burns are difficult to classify and carry with them considerable potential for complications. Burn severity classification accuracy, even by experts, is only 60–80%. Our research in animal models demonstrates that SFDI data can successfully be used to classify different regions of burn severities. Typically, these differences are not apparent to the unaided eye and a great deal of training and experience is required in order for clinicians to accurately differentiate them Our work using a research grade, hybrid-SFDI device suggests that objective parameters provided by SFDI can be used within 24 hours after injury, to accurately classify burn severity. Specifically, we have demonstrated in a porcine burn model that the research grade SFDI outperforms laser speckle imaging and thermal imaging at 24 hours post-burn, in terms of predicting whether a burn will require a graft or not. However, translating these results to the clinic has been difficult due to several device limitations. The research grade SFDI device has slow acquisition times that can result in motion artifacts. It is also sensitive to ambient light which is often an issue in a clinical setting. Additionally, the SFDI device generates so much diverse data (oxygenated and deoxygenated hemoglobin, water fraction, reduced scattering coefficients at multiple wavelengths), there is no obvious way to present it to a clinical user to make a quick decision. To this end, we propose to methodically investigate an improved next generation SFDI device that addresses these issues by using brighter LEDs and fewer wavelengths to rapidly collect data in a way that reduces motion artifacts and is independent of clinical lighting conditions. In addition, we will develop a machine learning based classification framework that will provide the clinical with actionalble diagnostic information. The central aim of this 3 year competing R01 renewal is to characterize and then modify a new clinic-friendly SFDI device (Clarifi) to objectively classify in- vivo regions of different burn severity over large areas. The proposed research seeks to investigate this via the following Specific Aims: 1) Test & Validate Clinical SFDI Instrument, 2) Compare Clinical SFDI Instrument to other Modalities on a Long Term Swine Model of Graded Burns, 3) Develop Spatially Resolved Classification Maps of Burn Severity based on SFDI Data, 4) Conduct Clinical Measurements of Burn Severity using the new SFDI device and Spatially Resolved Burn Severity Classification Maps based on SFDI data. Program Director (Last, first, middle): Durkin, Anthony J. PROJECT NARRATIVE Burn injuries rank in the top 15 causes of global burden of disease. Burn severity assessment, which is a critical step in treatment planning, is subjective, depending on the experience of the treating physician. This leads to misdiagnosis and increased days of hospitalization and cost. In order to address this, we propose to test, validate and apply a novel optical imaging device in order to provide noninvasive objective assessment of burn wound severity. This has the potential to improve management of burn patients and reduce rates of complications.",Clinical Evaluation of Burns using Spatial Frequency Domain Imaging,10052657,R01GM108634,"['Address', 'Animal Model', 'Area', 'Biometry', 'Blood Vessels', 'Burn Centers', 'Burn injury', 'Cicatrix', 'Classification', 'Clinic', 'Clinical', 'Clinical assessments', 'Collaborations', 'Custom', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Enrollment', 'Eye', 'Family suidae', 'Female', 'Hemoglobin', 'Hospital Costs', 'Hospitalization', 'Hour', 'Hybrids', 'Image', 'Imaging Device', 'Injury', 'Laser Speckle Imaging', 'Lasers', 'Light', 'Lighting', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medical center', 'Methods', 'Modality', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Optics', 'Output', 'Patients', 'Physicians', 'Principal Investigator', 'Property', 'Reporting', 'Research', 'Severities', 'Side', 'Signal Transduction', 'Skin', 'Spatial Frequency Domain Imaging', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translating', 'Ulcer', 'Variant', 'Visual', 'Water', 'Work', 'base', 'burden of illness', 'burn model', 'burn wound', 'care costs', 'clinical imaging', 'cost', 'data acquisition', 'data integrity', 'data modeling', 'diverse data', 'experience', 'healing', 'human data', 'imaging system', 'impression', 'improved', 'in vivo', 'infection rate', 'male', 'next generation', 'novel', 'optical imaging', 'pre-clinical', 'programs', 'research clinical testing', 'stability testing', 'treatment planning']",NIGMS,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2020,430325,0.012388515000567478
"An Unobtrusive Continuous Cuff-less Blood Pressure Monitor for Nocturnal Hypertension PROJECT SUMMARY/ABSTRACT The objective of this project is to create an unobtrusive, wrist-worn, cuff-less blood pressure monitor for measurement and identification of nocturnal nondipping hypertension. The investigation includes extensive validation with state-of-the-art ambulatory blood pressure monitors at nighttime in presence of heterogeneous treatment paradigms. Cardiovascular disease (CVD) is one of the major causes of ailments worldwide. Hypertension alone affects one in three adults according to the World Health Organization. Therefore, monitoring blood pressure has become a critical part of healthcare as it is known to be linked to many CVDs. Traditionally, clinical practitioners have relied on the mercury-based (or digital equivalent) inflatable cuff-based sphygmomanometer. However, the nature of the device allows for only infrequent measurements and its somewhat invasive nature and associated discomfort prohibits additional nocturnal measurements. There is certainly a value to measuring blood pressure continuously in the natural context of the user’s environment, in particular during sleep, without being disturbed by the instrument. Our proposed technology can provide a wealth of information to physicians, help identify certain short-term dynamics/variations of blood pressure, and allow effective monitoring of response to medication, among other things. Nocturnal measurements provide additional prognostic value in identifying risk. Despite these benefits, no wearable, non-invasive device for continuous blood pressure monitoring exists on the market simply because none have been reliable enough to be considered clinical grade. This project aims to develop a robust and reliable blood pressure monitor in the form of a wrist-worn device that uses bio-impedance sensors, and for the first time, demonstrate clinical grade reliability. These sensors measure pulse wave velocity (PWV) along with several other derivatives for cardiovascular parameters including heart rate and blood volume changes in arteries, which correlate with the blood pressure. The system will incorporate clever hardware design to localize underlying vasculature and focus on arterial sites for enhanced accuracy. The device will include a motion sensor to take into account the user’s movements and motion artifacts, the contact quality, and reliability of the measurements. Advanced machine learning techniques, leveraging both general and personalized models, will be developed to convert bio-impedance measurements to blood pressure. This project aims to then validate the system and analytics in both a healthy patient cohort and a hypertensive cohort, learning the impact that nocturnal ‘nondipping’ hypertension and anti-hypertensive treatments have on PWV/other cardiovascular correlates and blood pressure estimates. After decades of relying on the inflatable cuff- based technique, this system could represent a significant change in how we measure blood pressure. PROJECT NARRATIVE Continuous monitoring of nocturnal blood pressure can help early diagnosis of developing cardiac conditions, reveal short term blood pressure variations, and also help the physician monitor differences in variations in response to medication for hypertensive patients. Moreover, the comfort and convenience of a wearable monitor would allow measurement in the natural context of daily life, including important nocturnal measurements, and reduce the burden of adherence on the user. The system will also provide feedback on quality of measurements to allow the users or care-givers to gauge reliability.",An Unobtrusive Continuous Cuff-less Blood Pressure Monitor for Nocturnal Hypertension,9998433,R01HL151240,"['Adherence', 'Adult', 'Affect', 'Age', 'Ambulatory Blood Pressure Monitoring', 'Antihypertensive Agents', 'Arteries', 'Awareness', 'Biometry', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood Volume', 'Blood flow', 'Calibration', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Characteristics', 'Clinical', 'Data', 'Data Collection', 'Development', 'Devices', 'Early Diagnosis', 'Environment', 'FDA approved', 'Feedback', 'Future', 'Gold', 'Healthcare', 'Heart Rate', 'Home environment', 'Hour', 'Human', 'Hypertension', 'Investigation', 'Learning', 'Legal patent', 'Life', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mercury', 'Methods', 'Microfabrication', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Movement', 'Nature', 'Organ', 'Outcome', 'Outcomes Research', 'Participant', 'Patient Monitoring', 'Patient risk', 'Patients', 'Pattern', 'Penetration', 'Pharmaceutical Preparations', 'Physicians', 'Physiologic pulse', 'Physiology', 'Positioning Attribute', 'Proxy', 'Reading', 'Recording of previous events', 'Regimen', 'Research', 'Risk', 'Risk Factors', 'Science', 'Signal Transduction', 'Site', 'Skin', 'Sleep', 'Sleep Deprivation', 'Sphygmomanometers', 'Structural Models', 'Supine Position', 'System', 'Techniques', 'Technology', 'Time', 'Uncertainty', 'Validation', 'Variant', 'Work', 'World Health Organization', 'Wrist', 'advanced analytics', 'analytical method', 'arterial stiffness', 'base', 'cohort', 'comorbidity', 'design', 'digital', 'effectiveness validation', 'electric impedance', 'insight', 'instrument', 'model development', 'monitoring device', 'motion sensor', 'multidisciplinary', 'novel', 'novel strategies', 'patient stratification', 'patient subsets', 'performance tests', 'prognostic value', 'response', 'sensor', 'sex', 'sleep position', 'supine sleep', 'wearable device', 'wearable sensor technology', 'willingness']",NHLBI,TEXAS ENGINEERING EXPERIMENT STATION,R01,2020,766675,-0.003940143123613762
"A Hybrid Neural-Machine Interface for Volitional Control of a Powered Lower Limb Prosthesis Project Summary  The goal of the proposed work is to develop a robust hybrid neural-machine interface (NMI), combining brain and muscle signals, to improve overall control of a lower limb prosthetic device during activities of daily living. Limb amputation affects over 600,000 individuals annually in the US, and is a major cause of physical disability that causes activities of daily living to become difficult or impossible for the amputee. The limitations of current lower-limb prostheses are associated with limited volitional control, reduced mobility, and chronic gait abnormalities, which have been linked to exhaustion from increased energy expenditure, increased risk of falling, and degenerative bone and joint disorders in both the intact and amputated limb. In this study, EMG signals from both residual and intact lower limbs and EEG signals from the cortex are leveraged to decode transitions to and from various modes of locomotion modes in able-bodied individuals and transfemoral amputees, and to provide a global understanding of movement at the cortical, muscular, and kinematic level in amputees. Specifically, time and frequency domain features are leveraged to create a prediction algorithm capable of identifying upcoming terrain transitions in advance. In lower limb amputees, this hybrid NMI paradigm translates to volitional control of a powered lower-limb prosthesis, which allows for seamless transitions between various movement conditions. The high-level of control is expected to result in significant increases in level of activity and overall improvements in gait. Previous studies have demonstrated the feasibility of EEG or EMG based NMIs for orthotic and prosthetic devices; however, no study to date has integrated EEG and EMG in a NMI for powered lower limb prostheses. This study is motivated by the need to explore advanced neural control sources for intuitive control of artificial limbs.  This project aligns directly with the Mission & Goals of the NIH, the Brain Initiative, and NIH’s Blueprint Program by expanding fundamental knowledge of neuroscience, human, health and wellness; by utilizing an innovative research strategy; and ultimately returning the knowledge to the public through the development of a highly advanced medical technology. Furthermore, the technology developed through this work has implications beyond the amputee population in the treatment of many neurological conditions and injuries, such as in neurorehabilitation after stroke. The innovation of this project lies in the novel approach of using multimodal neural signals and movement synergies as a framework for interpreting movement of the lower limb. The scientific impact is realized by a greater understanding of the neural correlates of movement after lower-limb amputation. The direct clinical significance for the patient can be measured directly through improved gait performance and walking confidence, leading to increased mobility and a reduced risk of falling, exhaustion, and bone and joint disorders. Project Narrative  The development of a hybrid neural-machine interface that incorporates muscle and brain signaling for communication with robotic systems is important to public health because it allows for robust volitional control of powered prostheses and exoskeletons during activities of daily living. This will directly benefit the amputee population by allowing better control of their prosthesis during locomotion, especially when navigating complex terrains, such as stairs and inclines. The implications of this technology can be used beyond the amputee population to further understand the effect of neurological injuries on the brain, and for improving rehabilitation paradigms associated with their treatment.",A Hybrid Neural-Machine Interface for Volitional Control of a Powered Lower Limb Prosthesis,10214202,K00NS105210,"['Activities of Daily Living', 'Affect', 'Amputees', 'Ankle', 'Artificial Intelligence', 'Award', 'BRAIN initiative', 'Bone Diseases', 'Brain', 'Brain imaging', 'Chronic', 'Communication', 'Complex', 'Detection', 'Development', 'Electroencephalography', 'Electromyography', 'Electronic Mail', 'Energy Metabolism', 'Engineering', 'Frequencies', 'Funding Agency', 'Future Teacher', 'Gait', 'Gait abnormality', 'Goals', 'Grant', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Individual', 'Injury', 'Intelligence', 'International', 'Intuition', 'Joints', 'Knee', 'Knowledge', 'Leadership', 'Limb Prosthesis', 'Link', 'Locomotion', 'Lower Extremity', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Mentors', 'Mentorship', 'Metabolic', 'Methods', 'Mission', 'Motion', 'Movement', 'Muscle', 'Nervous System Trauma', 'Neurologic', 'Neurologic Effect', 'Neurosciences', 'Oral', 'Orthotic Devices', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Prosthesis', 'Public Health', 'Ramp', 'Research', 'Research Project Grants', 'Residual state', 'Robotics', 'Scalp structure', 'Signal Transduction', 'Social Network', 'Source', 'Surface', 'System', 'Teacher Professional Development', 'Technical Expertise', 'Technology', 'Telephone', 'Time', 'Training Programs', 'Translating', 'United States', 'United States National Institutes of Health', 'Upper Extremity', 'Visual Cortex', 'Volition', 'Walking', 'Work', 'arthropathies', 'base', 'clinically significant', 'exhaustion', 'experience', 'fall risk', 'improved', 'innovation', 'instrument', 'kinematics', 'limb amputation', 'limb movement', 'multimodality', 'neural correlate', 'neurological rehabilitation', 'neuroregulation', 'neurotransmission', 'novel strategies', 'physically handicapped', 'post stroke', 'posters', 'powered exoskeleton', 'powered prosthesis', 'prediction algorithm', 'programs', 'rehabilitation paradigm', 'relating to nervous system', 'robot control', 'robot exoskeleton', 'robot rehabilitation', 'robotic system', 'sensor', 'signal processing', 'skills', 'stroke rehabilitation', 'symposium', 'synergism', 'undergraduate student', 'visual motor']",NINDS,UNIVERSITY OF PENNSYLVANIA,K00,2020,72598,0.011076039629232657
"An unobtrusive monitoring device used for tracking asthma symptoms and lungfunction variability Executive Summary of Predicate (One Page) Summary of Specific Aims of Phase I Specific Aim 1: Train and evaluate an algorithm to detect pediatric asthma symptoms (cough and wheeze) on a low power, small form factor wearable device. Specifications: 90% sensitivity; false alarm rate: 1 cough episode/day or 1 wheeze episode/day. Evaluate algorithm against medical expert (physician) scoring using the two best available asthma scoring tools (AS: asthma score; PRAM: Pediatric Respiratory Assessment Measure). Specific Aim 2: Design and evaluate algorithm to detect lung function variability on a low power, small form factor wearable device. Specifications: Using respiratory signals from sensor patch, detect variations ≥ 10% in forced expiratory volume in 1 second to forced vital capacity (FEV1/FVC). Evaluate algorithm against spirometry gold standard. Progress towards Specific Aims As of today, January 21, 2020, the work on the predicate NIH STTR award has not yet begun. The work related to this NIH STTR is anticipated to begin April 2020. Prior to submitting our NIH STTR application, significant work was completed to test the viability of collecting lung function using our wearable technology. We tested on over 20 patients in the hospital, and in this study we found a positive correlation between our measurements and those of spirometry. Our NIH STTR work will build upon this. Technical, administrative, or commercial challenges and how they’ve been addressed During our customer discovery so far, we have learned about the complexities of achieving reimbursement, even if we have identified applicable CPT codes. Realizing this challenge, we selected an initial customer that will not require reimbursement. Our initial customer will be respiratory clinical trials. From our interviews, we have learned that they have a strong unmet need, they are willing to pay a large amount, and we will be able to serve them earlier than other customer types. We hope to explore this further during this NIH I-Corps program. Brief intro to team members Principal Investigator: Justice Amoh, PhD, CTO of Clairways - Justice is a pioneer in embedded systems for stochastic modelling of physiological signals. His focus is on deep neural network models for detecting the onset of symptoms in respiratory diseases. C-Level Corporate Officer: Jeff Bemowski, MBA, CEO of Clairways - Jeff is experienced in product management, market research, and customer discovery for novel biomedical devices. He previously worked in product management for Endotronix, a Series C funded medical device company. Industry Expert: Bob Gatewood, VP Digital Health at Portal Instruments - Bob Gatewood is an experienced healthcare and digital health entrepreneur. Bob was one of the founding members of Athenahealth, which is now valued at over $5.5 billion. He has already worked through many of the challenges Clairways will have to overcome, so his perspective will be very valuable to our team. Additionally, Bob is well connected within the industry and will aid in connecting with 100 potential customers within the short timeline. n/a",An unobtrusive monitoring device used for tracking asthma symptoms and lungfunction variability,10087375,R41HL146027,"['Address', 'Algorithms', 'Asthma', 'Award', 'Childhood', 'Childhood Asthma', 'Clinical Trials', 'Coughing', 'Current Procedural Terminology Codes', 'Devices', 'Doctor of Philosophy', 'Funding', 'Gold', 'Health', 'Healthcare', 'Hospitals', 'Industry', 'Innovation Corps', 'Interview', 'Justice', 'Lung diseases', 'Market Research', 'Measurement', 'Measures', 'Medical', 'Medical Device', 'Neural Network Simulation', 'Patients', 'Phase', 'Physicians', 'Principal Investigator', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Respiratory physiology', 'Series', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Spirometry', 'Symptoms', 'System', 'Testing', 'TimeLine', 'Training', 'United States National Institutes of Health', 'Variant', 'Vital capacity', 'Wheezing', 'Work', 'deep neural network', 'design', 'digital', 'experience', 'instrument', 'member', 'monitoring device', 'novel', 'physiologic model', 'programs', 'respiratory', 'sensor', 'tool', 'wearable device']",NHLBI,"CLAIRWAYS, LLC",R41,2020,55000,-0.02723438959171265
SCH: INT: A Context-aware Cuff-less Wearable Ambulatory Blood Pressure Monitor using a Bio-Impedance Sensor Array No abstract provided n/a,SCH: INT: A Context-aware Cuff-less Wearable Ambulatory Blood Pressure Monitor using a Bio-Impedance Sensor Array,9982327,R01EB028106,"['Address', 'Aging', 'Algorithms', 'Ambulatory Blood Pressure Monitoring', 'American', 'American Heart Association', 'Arteries', 'Awareness', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood Vessels', 'Calibration', 'Cardiology', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Trials', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Frequencies', 'Funding', 'Guidelines', 'Hour', 'Human Resources', 'Hypertension', 'Institutes', 'Institution', 'International', 'Intervention Trial', 'Investigation', 'Laboratories', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Phenotype', 'Physiologic pulse', 'Play', 'Positioning Attribute', 'Posture', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Role', 'Skin', 'Source', 'System', 'Technology', 'Testing', 'Texas', 'Time', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Validation', 'Wearable Computer', 'Wrist', 'advanced analytics', 'base', 'clinical practice', 'cohesion', 'college', 'cost', 'design', 'electric impedance', 'health disparity', 'machine learning method', 'minority health', 'novel strategies', 'patient population', 'sensor', 'signal processing', 'therapy development', 'validation studies', 'wearable sensor technology']",NIBIB,TEXAS ENGINEERING EXPERIMENT STATION,R01,2020,289073,0.022878279132992466
"Gaze-contingent computer screen magnification control for people with low vision ! Project Summary This application describes proposed research with the goal of facilitating use of a computer screen magnifier by people with low vision. Screen magnification is a well-established, popular technology for access of onscreen content. Its main shortcoming is that it requires the user to continuously control, with the mouse or trackpad, the location of the focus of magnification, in order to ensure that the magnified content of interest is within the screen viewport. This tedious process may be time-consuming and ineffective. For example, the simple task of reading the news on a web site requires continuous horizontal scrolling, which affects the experience of using this otherwise very beneficial technology, and may discourage its use, especially by those with poor manual coordination.  We propose to develop a software system that enables hands-free control of a screen magnifier. This system will rely on the user’s eye gaze (measured by a regular IR-based tracker, or from analysis of the images in a camera embedded in the screen) to update the location of the focus of magnification as desired. This research is inspired by preliminary work, which showed promising results with two simple gaze-based control algorithms, tested on three individuals with low vision.  This project will be a collaboration between the Department of Computer Science and Engineering at UC Santa Cruz (PI: Manduchi, Co-I: Prado) and the School of Optometry at UC Berkeley (PI: Chung). Dr. Legge from the Department of Psychology at U. Minnesota will participate as a consultant. Two human subjects studies are planned. In Study 1 with 80 low vision subjects from four different categories of visual impairment, we will investigate the failure rate of a commercial gaze tracker (Aim 1), and will record mouse tracks, gaze tracks, and images from the subjects while performing a number of tasks using two modalities of screen magnification (Aim 2). In Study 2, with the same number of subjects, we will repeat the Study 1 experiment, but using a gaze-based controller trained from the data collected in Study 1, and individually tunable for best performance (Aim 3). In addition, we will experiment with an appearance-based gaze tracker that uses images from the screen camera, thereby removing the need for specialized gaze tracking hardware, as well as with a computer tablet form factor (Aim 4). We expect that reading speed and error rate using our gaze-based controller will be no worse than using mouse-based control. If successful, this study will show that the convenience of hands-free control offered by the proposed system comes at no additional cost in terms of individual performance at the considered tasks. ! ! Project Narrative People with low vision often use screen magnification software to read on a computer screen. Since a magnifier expands the screen content beyond the physical size of the screen (the “viewport”), it is necessary to move the content using the mouse so that the portion of interest falls within the viewport. This project will facilitate use of a screen magnifier by means of a new software system that relies on the user’s own gaze to control scrolling when reading with magnification. !",Gaze-contingent computer screen magnification control for people with low vision,10053172,R01EY030952,"['Affect', 'Age', 'Algorithms', 'Appearance', 'Apple', 'Behavior Control', 'Benchmarking', 'Blindness', 'Categories', 'Collaborations', 'Communication', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Correlation Studies', 'Data', 'Data Set', 'Desktop Video', 'Engineering', 'Ensure', 'Eye', 'Face', 'Failure', 'Funding', 'Glass', 'Goals', 'Hand', 'Image', 'Individual', 'Learning', 'Location', 'Magic', 'Manuals', 'Measures', 'Minnesota', 'Modality', 'Mus', 'Operating System', 'Optometry', 'Performance', 'Peripheral', 'Process', 'Psychological reinforcement', 'Psychology', 'Reader', 'Reading', 'Research', 'Resort', 'Role', 'Schools', 'Science', 'Speech', 'Speed', 'Structure', 'Study Subject', 'System', 'Tablet Computer', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Update', 'Vision', 'Visual', 'Visual impairment', 'Work', 'algorithm development', 'algorithm training', 'base', 'computer science', 'control trial', 'cost', 'data acquisition', 'design', 'experience', 'experimental study', 'falls', 'gaze', 'human subject', 'interest', 'motor control', 'news', 'recurrent neural network', 'sample fixation', 'software systems', 'tool', 'web page', 'web site']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R01,2020,350753,-0.0018095543154459251
"Novel Wearable and Wireless Scratch Sensor as a Drug Discovery Tool Itch leads to serious impairment of quality of life—often times on par with pain. Itch is the hallmark symptom and primary driver of morbidity for atopic dermatitis (AD)—one of the most common inflammatory skin diseases affecting 24 million adults and 10 million children in the U.S. Currently, there is a severe lack of objective measurement of itch. Psychometric surveys are point measurements that lack sensitivity and validity—particularly in children. Measuring itch-related scratching behavior offers a potential objective way to measure itch. Unfortunately, wrist strapped electronics fail to capture scratch accurately and are not adapted for children. This project seeks to accelerate the full qualification of a novel, wearable sensor leveraging a machine learning algorithm to objectively and accurately measure scratching. We propose to address key comments from the FDA in our accepted letter of intent (DDT COA #000120) by accomplishing the following specific aims. Aim 1: we will augment our current scratch sensor to achieve 7-day battery life on a single wireless charge (current battery life: 24 hours) to increase adherence and reduce user burden. Aim 2: we propose to extend healthy normal testing to strengthen our predictive algorithm and train against additional cofounders with an additional 8 subjects (n=16 total). In addition, we will improve the usability and cybersecurity of our software and cloud system. Aim 3: we will extend our existing clinical study at Northwestern University to include more pediatric and adult individuals with AD (n=30 target total). Psychometric surveys will assess user/caregiver experience afterwards, and determine which features of the sensor have greatest value to patients. Success will be defined by successful submission of a full qualification plan to the FDA within 12 months as a fully accepted drug discovery tool. The long- term goal is to make this scratch sensor widely available to support drug development by providing an objective endpoint for itch, and inform future clinical care of treatment response in a patient’s naturalistic environment. Further applications include deployment in other itchy conditions (e.g. prurigo nodularis, chronic pruritus of the elderly, pruritus associated with renal or hepatic failure). Itch is a profoundly disturbing symptom that greatly reduces quality of life. For Atopic dermatitis (eczema) sufferers, a disease that afflicts 10% of children and 4% of adults in the U.S., itch is the greatest source of morbidity. However, there remains a lack of objective, repeatable measurement tools for itch hindering drug development. Measuring scratch behavior offers one opportunity to quantify itch. This project will support efforts to fully qualify an accepted letter of intent for a novel wearable scratch sensor as a drug development tool (COA# 0001120).",Novel Wearable and Wireless Scratch Sensor as a Drug Discovery Tool,10146184,U01FD007001,[' '],FDA,"SONICA, LLC",U01,2020,249103,-0.022918243510416627
"Wireless withdrawal detection and monitoring system for neonatal abstinence syndrome. SPECIFIC AIMS Neonatal abstinence syndrome (NAS) is an opioid withdrawal syndrome that develops shortly after birth to in utero-exposed neonates. The cost of NAS is high: newborns with NAS are typically receive care in the Neonatal Intensive Care Unit (NICU), where the daily cost of care is high. Nearly 22,000 infants are born with NAS each year at a cost of $1.5 billion. Moreover, medication-based interventions for the treatment of NAS, used in up to 80% of opioid-exposed infants, carry their own risks of toxicity and drug interactions. Despite the medical cost, high societal impact of NAS, and the risks of treatment, the tools to assess the severity of NAS can be subjective and suffer from examiner bias. There is an urgent need for innovative new methods to diagnose NAS and assess the efficacy of responses to treatment. Flexible, low-cost wearable devices (worn on the skin) that can report measures of systemic biochemical and biomechanical processes offer a simple and economical solution. In NAS, surges of sympathetic nervous system activity produce increased heart rate, skin conductance, unstable temperature, and tremor. These manifest in increased infant sweating, seizures, tremors, unstable body temperature, and more—events that must continually monitored and assessed by nurses. The unsupervised, objective detection/quantification of the bodily response of neonates suffering from NAS could drive the development of new, objective scoring tools that can guide the initiation, intensity, and duration of therapies for NAS. Such tools could significantly reduce medical costs and improve patient outcomes by reducing patient time in NICU, reducing nurse load, improving outpatient monitoring, and helping to assist in the optimization of patient treatments. Critically, we believe such a tool may be able to objectively capture events that may go unnoticed by nurses or while the infant is sleeping (minor tremors, poor oxygenation, temperature fluctuations, dehydration). This proposal seeks to develop interlinked, infant-targeted wearable biosensor-systems capable of continuously monitoring the biochemical to biophysical parameters of opioid-dependent neonates under treatment for NAS. Our team has outstanding experience in all areas necessary to this investigation. Our business unit has extensive NIH funded experience in wearable biosensing, in the detection of sympathetic nervous system activity in opioid withdrawal, pediatrics, business development, and intellectual property. Our academic partners have broad experience in novel biosensor development. PROJECT NARRATIVE Rekovar is developing a low cost wearable device that integrates wirelessly with a mobile device to allow real- time monitoring of the baby’s physical and physiological state and its ability to sleep, eat, and be nurtured while undergoing neonatal abstinence syndrome (NAS). This device has significant impact in helping reduce both hospital stay and costs as neonates receiving pharmacological treatment are usually in the NICU away from family and non-pharmacological care. Our interest lies with respect to proper neonatal care, where separate procedures occur for essential neonatal needs and needs for neonates undergoing withdrawal, and by using this monitoring device to assess addicted neonates undergoing withdrawal, caregivers are provided the better ability of treating the right neonatal needs with the appropriate procedure in hospitals.",Wireless withdrawal detection and monitoring system for neonatal abstinence syndrome.,10013069,R41DA049615,"['Accelerometer', 'Acoustics', 'Adult', 'Algorithms', 'Ambulatory Monitoring', 'Area', 'Biochemical', 'Biomechanics', 'Biometry', 'Biosensing Techniques', 'Biosensor', 'Birth', 'Blood', 'Body Temperature', 'Breathing', 'Businesses', 'Caregivers', 'Caring', 'Chest', 'Computers', 'Custom', 'Data', 'Data Analyses', 'Data Engineering', 'Dehydration', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Drug Interactions', 'Eating', 'Electroencephalography', 'Event', 'Family', 'Funding', 'Galvanic Skin Response', 'Guidelines', 'Heart Rate', 'Hospital Costs', 'Hospitals', 'Hydration status', 'Infant', 'Intellectual Property', 'Intervention', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Mechanics', 'Medical Care Costs', 'Methodology', 'Methods', 'Minor', 'Monitor', 'Motion', 'Neonatal', 'Neonatal Abstinence Syndrome', 'Neonatal Intensive Care Units', 'Newborn Infant', 'Nurses', 'Opiate Addiction', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pediatrics', 'Pharmaceutical Preparations', 'Pharmacological Treatment', 'Physiological', 'Play', 'Procedures', 'Process', 'Pulse Oximetry', 'Reporting', 'Research', 'Risk', 'Seizures', 'Severities', 'Skin', 'Sleep', 'Sneezing', 'Substance Withdrawal Syndrome', 'Sweating', 'Sympathetic Nervous System', 'Symptoms', 'System', 'Temperature', 'Testing', 'Time', 'Toxic effect', 'Tremor', 'United States National Institutes of Health', 'Validation', 'Wireless Technology', 'Withdrawal', 'arm', 'base', 'biophysical properties', 'care costs', 'complex data ', 'cost', 'experience', 'flexibility', 'handheld mobile device', 'human subject', 'improved', 'innovation', 'interest', 'machine learning algorithm', 'microchip', 'monitoring device', 'nanofabrication', 'neonatal care', 'neonate', 'neuromuscular activity', 'novel', 'opioid exposure', 'opioid withdrawal', 'phase 1 study', 'phase 2 study', 'prenatal exposure', 'printed circuit board', 'real time monitoring', 'response', 'sensor', 'therapy duration', 'tool', 'treatment response', 'treatment risk', 'wearable device', 'wearable sensor technology']",NIDA,REKOVAR INC.,R41,2020,225000,-0.006163635275617966
"Novel Approaches to Advance Coordinated Registry Networks (CRNs). Project Summary The technological transformation of US health care with the explosion of new devices and iterative changes mandates the acquisition of real-world evidence (RWE) to study devices and technologies pragmatically. The US Food and Drug Administration (FDA) has spearheaded the RWE framework development in the pursuit of sufficient evidence that is required for regulatory decision-making such as device approvals and surveillance. With regulatory support since the launch of the National Medical Device Registry Task Force in 2015, the Medical Device Epidemiology Network (MDEpiNet) created 15 national and international coordinated registry networks (CRNs), which develop or link well-curated national RWE sources such as registries, administrative, and electronic health records (EHRs) data. The MDEpiNet is a key partner of the National Evaluation System of Technologies (NEST) coordinating center and is an international public-private partnership focusing on building global infrastructure and methodologies to advance the use of RWE for medical device evaluation. CRNs not only focus on prevention of harms but also the promotion of safer device innovation through the development of study designs that expedites patient recruitment at lower costs than traditional clinical research. MDEpiNet developed a maturity model for CRNs with various levels of achievements in seven key domains: 1) device identification, 2) quality improvement, 3) total product life-cycle, 4) data quality, 5) efficiency, 6) governance and sustainability, 7) patient engagement. This proposal focuses on the creation of innovative tools and methods necessary to achieve maturation of the networks through efficient curation of robust RWE. We will capitalize on established partnerships with registries, professional societies, integrated health systems, and many academic institutions to advance this critical national infrastructure as a foundational component of NEST. We will facilitate advancements of RWE through stakeholder roundtables, patient-facing mobile app development, and continued innovative methods development to link registries with Medicare, commercial, statewide, and EHR data to enable better research and surveillance for devices. Our specific aims facilitate stakeholder engagement for device-specific core minimum data development in women's health, prostate cancer, orthopedics, vascular disease, robot-assisted surgery, and temporomandibular joints. We will also advance and enrich linked data capacities in vascular disease, hernia repair, breast implant, prostate cancer, Women's Health, and gastrointestinal cancer CRNs. Finally, we conduct advanced analytics to determine gender disparities in device outcomes and use machine learning and active surveillance methods in hernia repair, orthopedics, stroke treatment, vascular disease, and Women's health CRNs. The CRN community of practice will enable centralized knowledge sharing to support cross-specialty and technology learning and applications. Through this, we advance the CRNs using innovative, scalable, and dynamic approaches and help them become foundational components of NEST. Narrative Medical Device Epidemiology Network will advance the research and surveillance capabilities of coordinated registry networks through stakeholder roundtables, patient-facing mobile app development, and linkages of real-world data sources. We will also conduct advanced analytics to determine gender disparities, use machine learning for risk predictions, and implement active surveillance for devices and technologies.",Novel Approaches to Advance Coordinated Registry Networks (CRNs).,10128755,U01FD006936,[' '],FDA,WEILL MEDICAL COLL OF CORNELL UNIV,U01,2020,1770000,-0.024350305296891528
"Tissue-specific protein interactome mapping in a vertebrate embryo Abstract Proteins rarely act in isolation, but rather function in multi-protein complexes. Accordingly, protein-protein interactomes are exceptionally valuable resources that provide deep mechanistic insights and generate myriad hypotheses. Current methods for interactome mapping, such as affinity purification mass-spectrometry (APMS), are extremely difficult to deploy in vivo, so little comprehensive interactome data yet exists for developing embryos and even less for specific tissues within embryos. This fact poses an especially acute problem for understanding highly dynamic processes in which post-transcriptional controls dominate, for example collective cell movements. Here, we will use tissue engaged in convergent extension, a crucial collective movement that elongates the axis of animal embryos, to test the efficacy of new label-free interactome mapping approaches. Successful completion of the project will therefore be significant both for developing broadly applicable new methods and also for providing systems-level insights into a disease- relevant, vertebrate collective cell movement. Project Narrative: This study centers on developing novel methods for systematically identifying protein-protein interactions in embryos. To explore the utility of the method, we focus our efforts on proteins involved in collective cell movements called convergent extension, which are governed by the planar cell polarity (or PCP) proteins. These experiments will be significant because defects in PCP proteins or convergent extension lead to “neural tube defects” such as spina bifida and anencephaly, as well as congenital skeletal dysplasias.",Tissue-specific protein interactome mapping in a vertebrate embryo,10104048,R21HD103882,"['Actomyosin', 'Acute', 'Adhesions', 'Affinity Chromatography', 'Amphibia', 'Anencephaly and spina bifida X linked', 'Animals', 'Biological', 'Cadherins', 'Cells', 'Cellular biology', 'Communities', 'Data', 'Data Set', 'Defect', 'Developmental Biology', 'Developmental Process', 'Disease', 'Dorsal', 'Embryo', 'Fractionation', 'Genetic', 'In Vitro', 'Label', 'Lead', 'Light', 'Machine Learning', 'Mammals', 'Mass Spectrum Analysis', 'Mesoderm', 'Methods', 'Modeling', 'Molecular', 'Movement', 'Multiprotein Complexes', 'Neural Tube Closure', 'Neural Tube Defects', 'Post-Transcriptional Regulation', 'Process', 'Protein Interaction Mapping', 'Protein-Protein Interaction Map', 'Proteins', 'Proteome', 'Proteomics', 'Rana', 'Resources', 'Sampling', 'Spectrometry', 'System', 'Testing', 'Tissues', 'Vertebrates', 'Work', 'Xenopus', 'base', 'cell motility', 'convergent extension', 'data integration', 'efficacy testing', 'embryo tissue', 'experimental study', 'improved', 'in vivo', 'insight', 'novel', 'planar cell polarity', 'protein complex', 'protein protein interaction', 'skeletal dysplasia', 'success', 'vertebrate embryos']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",R21,2020,237750,0.00783530931170678
"Development/Commercialization of a Sensing Device to Detect Vaping Development/Commercialization of a Sensing Device to Detect Vaping Summary The use of e-cigarettes or vaping has been steadily increasing since its introduction. While potentially a tool to wean cigarette smokers from combustible tobacco, one consequence of the introduction of these devices has been the adoption of vaping by adolescents. While companies that offer vaping instruments for sale note that their material is directed to adults and intended as an aid for smoking cessation, recent reports have demonstrated that middle school and high school students in many countries, some as young as thirteen, have taken to vaping. Data analysis from a 2015 study in the U.S. indicated that 16% of high school students and 5% of middle school students reported vaping in the past thirty days. Most researchers speculated that the number of users would increase from these baselines and evidence indicates that this prediction is correct. Anecdotal evidence indicates that vaping in middle school and high school bathrooms is a major problem. FreshAir Sensor currently sells tobacco and marijuana smoking sensors along with 24/7 monitoring of the devices. The company has leveraged the knowledge of sensor development to produce preliminary components of an early stage sensing system capable of detecting vaping. Preliminary data to demonstrate this accomplishment is provided. The fast track research described in this proposal will enable the optimization of the sensor as well as commercialization of the resulting instrument in minimal time. The need to reduce and eventually eliminate adolescent vaping is urgent. The deployment of the proposed device in schools and other educational institutions will eliminate vaping during school hours and will, therefore, contribute to improvements in the overall health of adolescents by curtailing nicotine intake. Narrative Vaping has become a problem in schools with students, in steadily increasing numbers, using bathrooms and other less monitored spaces to indulge in the use of the newest vaping hardware. FreshAir Sensor is developing a sensor to detect vaping in otherwise unmonitored spaces. The use of this sensing system has the potential to reduce and, eventually, eliminate vaping behavior in schools, thereby reducing the harmful effects of nicotine in adolescents.",Development/Commercialization of a Sensing Device to Detect Vaping,10092402,R44DA049595,"['Adolescent', 'Adoption', 'Adult', 'Air', 'Algorithms', 'Behavior', 'Chemicals', 'Cigarette Smoker', 'Country', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Dose', 'Effectiveness', 'Electronic cigarette', 'Electronics', 'Engineering', 'Environmental Risk Factor', 'Event', 'Exposure to', 'Fatigue', 'Film', 'Goals', 'High School Student', 'Hour', 'Humidity', 'Institution', 'Intake', 'JUUL', 'Knowledge', 'Laboratories', 'Longevity', 'Marijuana', 'Marijuana Smoking', 'Methods', 'Middle School Student', 'Minor', 'Modality', 'Monitor', 'Morphology', 'Neurotoxins', 'Nicotine', 'Phase', 'Polymers', 'Production', 'Property', 'Public Housing', 'Reporting', 'Research', 'Research Personnel', 'Sales', 'Schools', 'Science', 'Smoking', 'Specificity', 'Students', 'System', 'Temperature', 'Testing', 'Time', 'Tobacco', 'Tobacco smoking behavior', 'Weaning', 'adolescent health', 'base', 'commercialization', 'design', 'detector', 'electronic cigarette use', 'high school', 'instrument', 'junior high school', 'machine learning algorithm', 'monitoring device', 'prototype', 'research and development', 'response', 'sensor', 'sensor technology', 'smoking cessation', 'tool', 'vaping', 'vapor']",NIDA,FRESHAIR SENSOR CORPORATION,R44,2020,830874,0.016038133817669498
"Eliminating the human factor from stereotaxic surgeries Project Summary: The main goal of this research project is to develop a new line of new stereotaxic devices for small animal research that outperforms existing devices in terms of accuracy, reproducibility, and ease of use. Advancing a tool such as an electrode, injection pipette or optical fiber through a small hole in the cranium, sometimes over long distances, and placing it precisely in a particular brain area, often much less than one millimeter in diameter, is a significant experimental challenge. Any time an investigator misses the target brain area and the experiment fails as a result, a significant amount of work is lost, additional animals get sacrificed, materials are wasted, and the pace of scientific discovery has been slowed. Even in cases when experiments succeed, they can be difficult to reproduce because many research groups rely on their most experienced lab members and their “special touch” to perform these procedures – thereby adding an element of non- quantitativeness to the procedures, effectively making the experiment less reproducible. We propose to develop a novel stereotaxic apparatus which will overcome many of these shortcomings. Our device features a radically different mechanical design which is natively compatible with both traditional and novel in-vivo techniques. We propose to combine computer 3D vision and robotics for automatic and software guided adjustments of the animal's skull. Landmarks are measured with 3D vision, based on structured illumination at a level of accuracy that has not been accomplished by any of the existing devices. This information will guide a robotic platform to position the animal for the experiment. Finally, we propose to develop an open software platform for neuronavigation that will allow investigators to use the platform with any small animal species they desire to use. Brain atlas systems for neuronavigation can either be downloaded from a cloud based site, or produced de-novo by the investigator by preparing a single set of MRI and CT scans from one sample animal. Our device will help make stereotaxic procedures more accurate and less dependent on human input and thereby increase the repeatability of experiments within a laboratory as well as the reproducibility of experiments across laboratories. Narrative: The main goal of this research project is to develop a new line of new stereotaxic devices for small animal research that outperforms existing devices in terms of accuracy, reproducibility, and ease of use. These devices will help make stereotaxic procedures less dependent on human input and thereby increase the repeatability of experiments within a laboratory as well as the reproducibility of experiments across laboratories. Most importantly, they will help reduce or eliminate failed experiments due to mistargeted interventions, thereby accelerating the pace of scientific discovery.",Eliminating the human factor from stereotaxic surgeries,10080673,R41NS119079,"['3-Dimensional', 'Animal Experimentation', 'Animal Experiments', 'Animals', 'Area', 'Atlases', 'Base of the Brain', 'Brain', 'Caliber', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Devices', 'Dorsal', 'Electrodes', 'Elements', 'Ensure', 'Frustration', 'Goals', 'Human', 'Image', 'Injections', 'Intervention', 'Laboratories', 'Lighting', 'Location', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Mechanics', 'Monitor', 'Neuronavigation', 'Operative Surgical Procedures', 'Persons', 'Positioning Attribute', 'Procedures', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Robotics', 'Sampling', 'Savings', 'Scanning', 'Side', 'Site', 'Speed', 'Structure', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Time', 'Touch sensation', 'Translations', 'Vision', 'Work', 'X-Ray Computed Tomography', 'age group', 'base', 'bone', 'bone imaging', 'brain tissue', 'cloud based', 'cost effective', 'cranium', 'design', 'experimental study', 'genetic strain', 'hexapod', 'in vivo', 'laboratory experience', 'member', 'millimeter', 'novel', 'operation', 'optical fiber', 'programs', 'prototype', 'soft tissue', 'software development', 'tool', 'virtual', 'wasting']",NINDS,POPNEURON LTD.,R41,2020,251960,0.012889678913936886
"Incorporating Learning Effects into Medical Device Active Safety Surveillance Methods Implantable medical devices have revolutionized contemporary cardiovascular care, and are used in a wide spectrum of acute and chronic cardiovascular conditions. However, medical device design fault or incorrect use may lead to significant risk of patient injury and represents an important preventable public health risk in the United States. To help identify device-related safety issues, a strategy of active, prospective, post-market safety surveillance has been recommended by the FDA, and evaluated methodologically. This type of surveillance offers significant advantages over traditional adverse event reporting strategies. However, all such approaches are challenged by the need to incorporate learning effects into expectations regarding safety. These learning impacts been repeatedly shown to have dramatic impacts on outcomes during early device experience. Quantifying learning effects on the outcomes associated with high-risk cardiovascular devices will improve our understanding of intrinsic device performance, thereby identifying patient populations best treated with such devices while simultaneously providing necessary feedback to device manufacturers to support iterative improvement in device design. Separately, understanding the impacts of learning may identify opportunities for targeted training as well as help to tease apart institutional and operator characteristics that may accelerate the achievement of optimal outcomes in the use of the specific cardiovascular device.  This proposal seeks to extend the previously validated, open-source, active, prospective device safety surveillance tool, by developing and validating robust learning curve (LC) detection and quantification algorithms, designed to simultaneously account for the effects at the operator and institutional levels. We propose a “blinded” development strategy, in which one team will generate robust synthetic clinical data simulator with LC impacts, and the other team develops and applies LC detection and quantification algorithms, without knowledge of the underlying relationships, determine performance and accuracy through sequential refinement and validation steps. We propose to formally validate the optimized LC tools in real-world data through re-analysis of previously published LC effects on transcatheter valves and vascular closure devices using national cardiovascular registries. In addition, the LC tools will be incorporated into two active, prospective device safety surveillance studies of novel implantable cardiovascular devices using large clinical registries. This proposal seeks to understand the impact of institutional and physician learning on the safety of newly approved cardiovascular devices, and to use this knowledge to support and improve effective medical device safety surveillance. We propose a “blinded” strategy of separating simulated dataset generation from the learning effects detection and quantification algorithm development. Incorporating learning effects adjustment into a validated, prospective, near-real-time safety surveillance system, this research will improve public health by identifying poorer performing cardiovascular devices, and provide physicians, device manufacturers and public health officials with better information to optimize the use of medical devices, iteratively improve their design, and identify opportunities for enhanced training that will result in improved patient outcomes.",Incorporating Learning Effects into Medical Device Active Safety Surveillance Methods,9863048,R01HL149948,"['Achievement', 'Acute', 'Address', 'Adverse event', 'Algorithm Design', 'Algorithms', 'Blinded', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Set', 'Detection', 'Development', 'Device Designs', 'Device Safety', 'Devices', 'Early Diagnosis', 'Elements', 'Environment', 'Etiology', 'Evaluation', 'Event', 'Feedback', 'Generations', 'Implant', 'Injections', 'Injury', 'Institution', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Manufacturer Name', 'Medical Device', 'Medical Device Designs', 'Medical Device Safety', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Process', 'Provider', 'Public Health', 'Publishing', 'Registries', 'Reporting', 'Risk', 'Safety', 'Signal Transduction', 'Specific qualifier value', 'Statistical Models', 'Structure', 'Surveillance Methods', 'Time', 'Training', 'United States', 'Validation', 'Variant', 'adverse outcome', 'algorithm development', 'cardiovascular risk factor', 'clinical heterogeneity', 'design', 'expectation', 'experience', 'high risk', 'implantable device', 'improved', 'novel', 'open source', 'patient population', 'post-market', 'prospective', 'safety outcomes', 'simulation', 'surveillance strategy', 'surveillance study', 'systems research', 'tool']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,828534,-0.022806996236027374
"Development of a visual-to-tactile conversion system for automating tactile graphic generation process PROJECT SUMMARY/ABSTRACT There are an estimated 23.7 million people who are blind or visually-impaired (BVI) in the U.S. and 285 million globally. Of this population, 30% do not travel independently outside of their home, only ~11% have a bachelor’s degree, and more than 70% are unemployed. The goal of this SBIR effort is to develop a novel system, which performs principled down-sampling and translation of visual information from digital documents into tactile equivalents. Timely access to information is one of the biggest challenges for BVI people. While access to textual information has largely been solved via screen reading software (e.g., JAWS or VoiceOver), very little progress has been made in making graphical information accessible. Although few assistive technology (AT) devices aim provide non-visual graphical access, they suffer from several shortcomings including high cost, limited portability, lack of multi-purpose, and inability to present information in a real-time context. Importantly, a common underlying problem across all extant approaches is that they require intensive human effort for producing or authoring tactile (and/or multimodal) graphics, which leads to high production costs and significant delays in the time between when the accessible materials are needed, and when they are actually delivered, adversely impacting BVI individuals in K-12 schools, colleges, and workplace settings. To address this long-standing problem, UNAR Labs aims to develop a novel system, which will automatically down-sample and translate visual graphical information into an intuitive tactile equivalent that can be used in tactile embossers. Building upon eight years of empirical research, this Phase I SBIR effort will prove the technical feasibility and functional viability of a prototype system for automating visual-to-tactile graphic conversion process and using the output in embossers. Two specific aims will guide this Phase I project: (1) to develop a prototype of an automated system for performing visual-to-tactile conversion without human intervention, and (2) to assess the technical feasibility and functional utility of the system through a rigorous human study. Success in this effort will provide a robust automated system for tactile graphic generation and promote empowerment of millions of BVI individuals by supporting increased educational attainment, proliferation of vocational opportunities, and enhancing overall quality of life for BVI people. PROJECT NARRATIVE Lack of equitable and timely access to information among persons who are blind or visually impaired (BVI) is key to realizing an inclusive world for all as it alleviates a known impediment that is hugely detrimental to their success in activities affecting quality of life and socio-economic status. The proposed innovation presents a first- of-its kind on-demand visual-to-tactile translation system, which will fully automate the tactile graphic generation process using bio-inspired sensory substitution rules and will instantly deliver the translated information for use in tactile embossers. Successful completion of this project will significantly reduce tactile graphic production costs and preparation time, and will promote empowerment of millions of BVI individuals by supporting increased educational attainment, vocational opportunities, and overall better quality of life.",Development of a visual-to-tactile conversion system for automating tactile graphic generation process,10008494,R43EY031628,"['Access to Information', 'Address', 'Adoption', 'Affect', 'Bachelor&apos', 's Degree', 'Benchmarking', 'Braille Display', 'Characteristics', 'Cognitive', 'Computer software', 'Computers', 'Data', 'Development', 'Devices', 'Elements', 'Empirical Research', 'Evaluation', 'Floor', 'Generations', 'Goals', 'Graph', 'Home environment', 'Human', 'Individual', 'Information Retrieval', 'Intervention', 'Intuition', 'Maine', 'Maps', 'Nature', 'Output', 'Performance', 'Persons', 'Phase', 'Plant Roots', 'Population', 'Preparation', 'Process', 'Production', 'Productivity', 'Psychophysics', 'Quality of life', 'Readability', 'Reading', 'Research', 'Route', 'Sampling', 'Schools', 'Self-Help Devices', 'Sensory', 'Small Business Innovation Research Grant', 'Socioeconomic Status', 'Software Framework', 'Support System', 'System', 'Tactile', 'Text', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Unemployment', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'braille', 'college', 'cost', 'data modeling', 'deep learning', 'digital', 'empowerment', 'human study', 'innovation', 'multimodality', 'multisensory', 'novel', 'operation', 'portability', 'prototype', 'success', 'touchscreen', 'usability', 'visual information', 'visual learning']",NEI,"UNAR LABS, LLC",R43,2020,300000,0.002751304880886734
"Customized Health Alerts and Consumer-Centered Interfaces Using In-Home and Wearable Sensors In-home sensing technologies hold enormous potential for early detection of health changes that can dramatically affect the experiences of aging: enabling functional independence, improving self-management of chronic or acute conditions, and improving quality of life. Chronic diseases especially affect older adults. Problems in chronic disease management are often the cause of losing independence for aging Americans. In 2012, 1 in 2 American adults (117 million) had at least one chronic condition, and 26% of the population had multiple chronic conditions, accounting for 84% of US health care costs. Early illness recognition and early treatment is key to improving health status with rapid recovery after an exacerbation of a chronic illness or acute illness, and also key to reducing morbidity and mortality in older adults and controlling health care costs.  In previous work, the team developed a health alert system that captures and analyzes data from sensors embedded in the home. Sensor data are captured passively and continuously in the home. In a pilot NIH R21 study, significant differences in health outcomes were shown with health alerts from motion and bed sensor data, based on bed restlessness and low, normal, and high pulse and respiration rates. The system actually detected changes in chronic diseases or acute illnesses on average 10 days to 2 weeks before usual assessment methods or self-reports of illness. For this project, the team will expand from the clinician-focused system to a consumer-focused system by incorporating more finely grained sensing (gait and quantitative pulse and respiration), with new improved algorithms that integrate individual health status and medication use, and track trajectories of health changes, for more sensitive, and more personalized health alerts with fewer false alarms. A recently developed bed sensor will be incorporated to passively capture quantitative pulse, respiration, and restlessness while the subject is resting. Gait parameters (e.g., in-home walking speed, stride time and stride length) will also be captured using depth images that show shadowy silhouettes. In addition, the team will solicit the consumer perspective on customized health alerts and a user interface for displaying sensor and alert information. The views of seniors and their family members will be used to inform the development of the new customized alert algorithms and drive the development of a consumer-focused interface that will provide empowering tools for self-management of chronic illnesses. In addition, the use of commercially available wrist-worn sensors will be explored for the purpose of recognizing health changes. The study will include a retrospective analysis of sensor data collected in 13 senior housing sites in Missouri. New participants will be recruited in 5 senior housing sites in Columbia, MO to investigate the consumer perspective. The important process of engaging consumers in this work is the next step in translating these systems into clinical practice for self-managing chronic health conditions, supporting seniors living independently. PROJECT NARRATIVE We will build on our current work using intelligent, in-home sensor systems with automated health alerts to investigate new health alert algorithms that are more sensitive and more customized to the individual. These will be tested with data from 13 senior housing sites in Missouri using clinician feedback and actual health trajectories for evaluation. We will also recruit subjects in independent living housing to solicit the views of consumers on wearable sensors, health alerts, and user interfaces that allow seniors and their family members to view the health alert information in a way that empowers them to better self-manage their own health.",Customized Health Alerts and Consumer-Centered Interfaces Using In-Home and Wearable Sensors,9830682,R01NR016423,"['Accounting', 'Acute', 'Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Aging', 'Agitation', 'Algorithms', 'American', 'Beds', 'Caregivers', 'Chronic', 'Chronic Disease', 'Complex', 'Custom', 'Data', 'Data Analyses', 'Development', 'Disease Management', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Family', 'Family member', 'Feedback', 'Gait', 'Grain', 'Health', 'Health Care Costs', 'Health Status', 'Home environment', 'Hospital Costs', 'Hospitalization', 'Housing', 'Image', 'Independent Living', 'Individual', 'Intelligence', 'Length', 'Length of Stay', 'Machine Learning', 'Methods', 'Missouri', 'Monitor', 'Morbidity - disease rate', 'Motion', 'Nursing Homes', 'Outcome', 'Participant', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevention', 'Privacy', 'Process', 'Quality of life', 'Recovery', 'Respiration', 'Rest', 'Retrospective Studies', 'Self Management', 'Site', 'System', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Walking', 'Work', 'Wrist', 'active control', 'base', 'clinical practice', 'clinically relevant', 'cost', 'design', 'empowered', 'experience', 'fall risk', 'fitness', 'functional independence', 'health assessment', 'health difference', 'improved', 'information display', 'mortality', 'multiple chronic conditions', 'preference', 'recruit', 'sensor', 'sensor technology', 'tool', 'walking speed', 'wearable sensor technology']",NINR,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2020,100000,-0.009135386249535138
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9932509,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual environment', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,615717,0.0008201762125645231
"Controlling Locomotion over Continuously Varying Activities for Agile Powered Prosthetic Legs PROJECT ABSTRACT Above-knee amputees often struggle to perform the varying activities of daily life with conventional prostheses. Emerging powered knee-ankle prostheses have motors that can restore normative biomechanics, but these devices are limited to a small set of pre-defined activities that must be tuned to the user by technical experts over several hours. The overall goal of this project is to model and control human locomotion over continuously varying tasks for the design of agile, powered prostheses that require little to no tuning. The universal use of different task-specific controllers in current powered legs is a direct consequence of the prevailing paradigm for viewing human locomotion as a discrete set of activities. There is a fundamental gap in knowledge about how to analyze, model, and control continuously varying locomotion, which greatly limits the adaptability and agility of powered prostheses. The central hypothesis of this project is that continuously varying activities can be represented by a single mathematical model based on measureable physical quantities called task variables. The proposed project will be scientifically significant to understanding how humans continuously adapt to varying activities and environments, technologically significant to the design of agile, user-synchronized powered prosthetic legs, and clinically significant to the adoption of powered knee-ankle prostheses for improved community ambulation. The proposed model of human locomotion will enable new prosthetic strategies for controlling and adapting to the environment, which aligns with the missions of the NICHD/NCMRR Devices and Technology Development program area and the NIBIB Mathematical Modeling, Simulation, and Analysis program. The innovation of this work is encompassed in 1) a continuous paradigm for variable locomotor activities that challenges the existing discrete paradigm, 2) a unified task control methodology that drastically improves the agility of powered prosthetic legs, and 3) a partially automated tuning process that significantly reduces the time and technical expertise required to configure powered knee- ankle prostheses. This continuous task paradigm will provide new methods and models for studying human locomotion across tasks and task transitions. This innovation will address a key roadblock in control technology that currently restricts powered legs to a small set of activities that do not generalize well across users. The adaptability of the proposed control paradigm across users and activities will transform the prosthetics field with a new generation of “plug-and-play” powered legs for community ambulation. PROJECT NARRATIVE The proposed research is relevant to public health because the clinical application of variable-activity powered prosthetic legs can significantly improve community mobility and therefore quality of life for nearly a million American amputees. Recently developed powered knee-ankle prostheses are limited to a small set of pre- defined activities that require several hours of expert tuning for each user. This project will model and control human locomotion over continuously varying tasks for the design of agile, powered prostheses that require little to no tuning, which aligns with the missions of the Devices and Technology Development program area of the NICHD National Center for Medical Rehabilitation Research and the Mathematical Modeling, Simulation, and Analysis program of the NIBIB.",Controlling Locomotion over Continuously Varying Activities for Agile Powered Prosthetic Legs,9925236,R01HD094772,"['Address', 'Adoption', 'American', 'Amputees', 'Ankle', 'Area', 'Artificial Leg', 'Biomechanics', 'Clinical', 'Communities', 'Data', 'Degree program', 'Device or Instrument Development', 'Devices', 'Doctor of Philosophy', 'Electrical Engineering', 'Environment', 'Gait', 'Gait speed', 'Generations', 'Goals', 'Hand', 'Home environment', 'Hour', 'Human', 'Human body', 'Joints', 'Knee', 'Knowledge', 'Lead', 'Leg', 'Life', 'Locomotion', 'Lower Extremity', 'Machine Learning', 'Mathematical Model Simulation', 'Measurable', 'Measures', 'Mechanics', 'Medical center', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motor', 'Motor Activity', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'Orthotic Devices', 'Outcome', 'Phase', 'Play', 'Process', 'Program Development', 'Prosthesis', 'Public Health', 'Quality of life', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Speed', 'Spinal cord injury', 'Stroke', 'Study models', 'System', 'Technical Expertise', 'Technology', 'Time', 'United States National Institutes of Health', 'Walking', 'Work', 'base', 'clinical application', 'clinically significant', 'design', 'exoskeleton', 'experience', 'human data', 'human model', 'improved', 'innovation', 'kinematics', 'mathematical model', 'multidisciplinary', 'powered prosthesis', 'programs', 'prosthesis control', 'rehabilitation research', 'robot control', 'sensor', 'success', 'technology development', 'temporal measurement', 'trend']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,446707,0.012340721156814165
"A Novel, Low-Cost Device to Guide Peripherally Inserted Central Catheter (PICC) Line Placement Abstract In the United States alone, more than three million peripherally inserted central catheters (PICCs) are placed each year to provide IV therapies, where navigation through the venous system is typically performed blind, or without navigation guidance. Improper PICC placement is relatively common, is costly, and has serious complications for critically-ill patients. Unfortunately, under blind placement 30-55% of PICC tips are not optimally placed on the first attempt and require repositioning, which has an average direct cost of $223 per patient and often necessitates the removal and reinsertion of the catheter line that carries a 4-6% risk of pneumothorax. Moreover, approximately 17% of these improperly positioned PICCs are placed into the right atrium, which is associated with a multitude of life-threatening complications. Improper placement of PICCs also often requires referral to an interventional radiologist for fluoroscopic-guided central line placement, which is expensive ($1,000) and requires more radiation exposure for the patient. Not surprisingly, over half of all PICCs are administered to patients over the age of 60. Therefore, safe and accurate PICC placement is critical for providing high-quality care to older Americans. Despite serious adverse events associated with blind placement of PICC lines, current vascular access systems have not been widely adopted. The Teleflex ARROW® G4 VPS and the Bard Sherlock 3CG® TCS are PICC guidance systems that employ ECG for positioning the PICC tip into the correct location: the region that includes the lower superior vena cava (SVC) and cavoatrial junction (CAJ). While these procedures often limit the need for a confirmatory X-ray, they have poor and variable successful placement rates (44-84%), are 30-70% more expensive than standard PICCs, require skilled staff, and have significantly longer procedure times as compared to standard, blind PICC placement. Additionally, these guidance systems rely on the use of ECG, which is ineffective for patients with cardiac arrhythmias, a condition that affects approximately 16% of all patients requiring a PICC line. To address the need for accurate, safe, and cost- effective PICC placement, Piccolo Medical has developed the Smart PICC™ system, a point-of-care catheter system that uses unique hemodynamic signatures of different vascular regions for real-time vascular access guidance into the SVC/CAJ. The goals of this Phase II proposal are to validate the accuracy of the Piccolo Smart PICC™ for navigation and placement of a PICC tip into the SVC or CAJ for adult patients with and without cardiac arrhythmias. First, we will verify the sensitivity of the Smart PICC™ system algorithm to identify correct PICC placement in adult patients with both normal and altered cardiac rhythms (Aim 1). Second, we will compare the accuracy of the Smart PICC™ system to the most widely used catheter navigation system (BD’s Sherlock 3CG® TCS) in a head-to-head superiority study (Aim 2).The data obtained will support FDA 510(k) clearance and will allow us to commercialize the system within ~2.5 years of the funding of this proposal. Narrative Peripherally inserted central catheters (PICCs) are widely used to provide life-sustaining intravenous therapies, where navigation through the venous system is typically performed blind, or without navigation guidance. Commercially available PICC navigation systems can be effective, but have limitations that have impeded adoption into the clinic. We propose an inexpensive, easily operated catheter system for real-time vascular access guidance that addresses the limitations of current systems.","A Novel, Low-Cost Device to Guide Peripherally Inserted Central Catheter (PICC) Line Placement",10019319,R44AG060793,"['Address', 'Adopted', 'Adoption', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'American', 'Anatomy', 'Area Under Curve', 'Arrhythmia', 'Automobile Driving', 'Blinded', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Catheters', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Critical Illness', 'Data', 'Detection', 'Devices', 'Direct Costs', 'Distal', 'EKG P Wave', 'Electrocardiogram', 'Excision', 'Family suidae', 'Funding', 'Future', 'Goals', 'Head', 'Heart Atrium', 'Heart Valves', 'Infusion procedures', 'Intervention', 'Intravenous', 'Lead', 'Life', 'Location', 'Measures', 'Medical', 'Modeling', 'Multi-site clinical study', 'Myocardial', 'Navigation System', 'Nurses', 'Patients', 'Perforation', 'Performance', 'Peripheral', 'Phase', 'Pneumothorax', 'Positioning Attribute', 'Procedures', 'Quality of Care', 'ROC Curve', 'Radiation exposure', 'Randomized', 'Real-Time Systems', 'Research', 'Resolution', 'Right atrial structure', 'Risk', 'Roentgen Rays', 'Savings', 'Serious Adverse Event', 'Signal Transduction', 'Superior vena cava structure', 'System', 'Technology', 'Thermodilution', 'Thoracic Radiography', 'Thrombus', 'Time', 'Training', 'United States', 'Venous system', 'Work', 'base', 'blind', 'cohort', 'cost', 'cost effective', 'follow-up', 'heart rhythm', 'hemodynamics', 'improved', 'in vivo', 'innovation', 'machine learning algorithm', 'novel', 'point of care', 'pre-clinical', 'radiologist', 'sensor']",NIA,"PICCOLO MEDICAL, INC.",R44,2020,561565,-0.00035839262110112433
"Implantable Neurostimulators for Control of Oscillatory Brain Networks We propose to develop an implantable brain stimulation system to measure and control oscillatory local field potential (LFP) synchrony within brain networks. Implantable neurotechnologies like deep brain stimulation (DBS) have revolutionized the treatment of movement disorders and epilepsy. DBS has some clinical signal in psychiatry as well, but individual trial results are highly variable. We have argued that this is a target engagement problem – that the high-frequency constant stimulation used in Parkinson’s or other tremor disorders is not the right approach to the circuits of mental illness. Instead, we believe the correct approach is to identify signatures of healthy communication in these circuits/networks, then design stimulation protocols that specifically produce those signatures. LFP synchrony is likely one of those communication signatures. Across multiple domains of cognitive and emotional function, behavioral performance (a read-out of successful network communication) improves when brain regions show synchronous (coherent) LFP oscillations. Further, clinically effective DBS, in movement and psychiatric disorders, is associated with changes in LFP synchrony. Co-PI Widge has developed algorithms that specifically control inter-regional LFP synchrony, by locking electrical stimulation pulses in one region to the phase of an ongoing oscillation in another region. The translational challenge is that efficient, implantable real-time synchrony monitoring and phase-locked stimulation require signal processing capabilities not found in any existing or anticipated device. Co-PI Shoaran has developed power-efficient phase estimation circuits, specifically optimized for DBS- like implants. We propose to combine these approaches. Aims 1 and 2 will develop a new application- specific integrated circuit (ASIC) that integrates Dr. Shoaran’s measurement and neural decoding frameworks with Dr. Widge’s oscillation-control methods. We will validate this circuit’s recording and phase-locking capabilities in vivo in Dr. Widge’s rodent lab. In Aim 3, a world-leading contract implant manufacturer (Cirtec) will integrate that new ASIC into a packaged, implant-ready device ready for large animal safety testing. Cirtec has already developed a DBS prototyping platform optimized to get new therapies more quickly into first-in- human, allowing us to greatly accelerate the path to the clinic and reduce regulatory risk. At the end of 5 years, we will either be ready for that clinical pilot or have only modest safety testing remaining. Our team has expertise in electronics, medical device fabrication, clinical brain stimulation, and technology commercialization. The work will be headquartered in Minnesota’s “Medical Alley”, an epicenter of medical device innovation. We are well-qualified to execute these Aims and bring the resulting technology to market. Success would yield a new implant optimized for network monitoring and therapy, a powerful new tool for both psychiatric treatment and cutting-edge neuroscience research. Project Narrative We will develop a new implantable medical device for treating severe psychiatric illness, especially mood and anxiety disorders. Many, if not all, of these disorders arise from communication failure in distributed brain networks, networks that communicate through rhythmic, oscillatory firing of large groups of brain cells. Our device will implement new algorithms that measure and control that rhythmic firing, restoring patterns of healthy communication.",Implantable Neurostimulators for Control of Oscillatory Brain Networks,10034533,R01MH123634,"['Algorithms', 'Animal Testing', 'Anxiety Disorders', 'Area', 'Behavioral', 'Brain', 'Brain region', 'Budgets', 'Clinic', 'Clinical', 'Communication', 'Complex', 'Consensus', 'Contracts', 'Coupling', 'Data', 'Data Analyses', 'Deep Brain Stimulation', 'Detection', 'Devices', 'Disease', 'Ecosystem', 'Electric Stimulation', 'Electronics', 'Electrophysiology (science)', 'Epilepsy', 'Equipment', 'Failure', 'Frequencies', 'Future', 'Human', 'Implant', 'Individual', 'Laboratory Animals', 'Machine Learning', 'Manufactured form', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical', 'Medical Device', 'Medical Device Designs', 'Mental disorders', 'Methods', 'Minnesota', 'Modeling', 'Modernization', 'Monitor', 'Mood Disorders', 'Movement Disorders', 'Neurosciences', 'Neurosciences Research', 'Output', 'Parkinson Disease', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Physiologic pulse', 'Physiology', 'Play', 'Positioning Attribute', 'Protocols documentation', 'Psychiatric therapeutic procedure', 'Psychiatry', 'Rattus', 'Resolution', 'Risk', 'Rodent', 'Seizures', 'Signal Transduction', 'Speed', 'Structure', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Effect', 'Time', 'Translating', 'Tremor', 'Universities', 'Validation', 'Work', 'analog', 'animal safety', 'base', 'brain cell', 'brain dysfunction', 'cognitive function', 'cognitive neuroscience', 'commercialization', 'conditioning', 'design', 'digital', 'emotional functioning', 'first-in-human', 'improved', 'in vivo', 'industry partner', 'innovation', 'nanofabrication', 'neural circuit', 'neurotechnology', 'novel strategies', 'novel therapeutics', 'programs', 'prototype', 'psychiatric symptom', 'relating to nervous system', 'safety testing', 'signal processing', 'success', 'tool', 'translational neuroscience', 'trigonometry']",NIMH,UNIVERSITY OF MINNESOTA,R01,2020,885873,-0.014588001703322046
"Continuous Non-Invasive Blood Pressure Monitor for Neonates Summary/Abstract Each year, about 5-18% of babies are born preterm, accounting for over 0.5M births in the US and 15M globally. Many of these babies are admitted to Neonatal Intensive Care Units (NICUs) where the medical staff generally have the option of using either invasive arterial lines (IALs) or inflatable-cuff non-invasive blood pressure (NIBP) monitoring. The former introduces the risk of infection, tissue and nerve damage, and the latter is less accurate, especially for hypotensive infants, and may add the risk of ischemic and nerve damage upon repeated measurement. There is a clear need for a safer, continuous, and cost effective form of NIBP measurement to meet the challenge of managing unhealthy blood pressures for neonates. PyrAmes Inc. has developed a novel capacitive sensor technology that is paper thin and flexible and can accurately detect blood pressure (BP). This sensor technology is part of a unique continuous BP monitoring platform that provides accurate, lightweight and comfortable BP monitoring in a wireless, wrist-worn package that is easy to use. The system uses lightweight neural networks to analyze pulse waveform data to provide continuous determination of systolic, diastolic, and mean BP, heart rate, and their variabilities. The sensor is easy to apply non-invasively and records pulsatile data similar to an arterial line, while avoiding the difficulties of placing and maintaining an arterial line. This device can provide gold standard BP monitoring without perturbing the patients for more accurate and relevant measurements. The objective of this project is to extend the platform for use with term and pre-term neonates. This goal will be accomplished through redesign of the sensor hardware and optimization of the data analytics software. We will validate these modifications with clinical data from the NICU at Stanford University Medical Center. In Phase I, we will miniaturize the electronics and modify the sensor array of a wrist-worn pulse wave monitor to be sized more appropriately for neonates. We will validate the new device design by collecting NICU clinical data from patients who have IALs in place in an IRB-approved study. From IAL and sensor data taken simultaneously, we will determine ground truth values on a pulse-by-pulse basis and use these data in conjunction with additional IAL data from historical databases to improve our sensor quality and predictive BP models. Our success metric will be to equal or exceed the quality and accuracy of our data for adults. Phase II will be a follow-up IRB-approved pivotal study using the device from Phase 1 to position our device for FDA submission and clearance and scale up to pilot production of this device. Project Narrative The goal of this Phase 1 project is to confirm that machine learning can be used to extract blood pressure values for critically ill neonates from pulse waveform data collected with a wearable, non-invasive device that is comfortable, low-cost and easy to use. The proposed device will significantly reduce the need for frequent cuff-based measurements and/or invasive arterial lines, thereby decreasing morbidity, risk of complications, patient discomfort, and overall cost of care. This project is based on the pioneering efforts of Prof. Zhenan Bao’s lab at Stanford on thin film sensors for electronic skin and includes the design and use of a miniaturized device to collect clinical data from neonates that will be used to validate a model which derives blood pressure values from the pulse waveform without external calibration.",Continuous Non-Invasive Blood Pressure Monitor for Neonates,9910153,R43HD101175,"['Academic Medical Centers', 'Accounting', 'Adult', 'Antihypertensive Agents', 'Area', 'Arterial Lines', 'Birth', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood pressure determination', 'Bluetooth', 'Calibration', 'Cells', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Research', 'Coin', 'Computer Analysis', 'Computer software', 'Consumption', 'Critical Illness', 'Data', 'Data Analytics', 'Databases', 'Development', 'Device Designs', 'Devices', 'Disadvantaged', 'Electromagnetics', 'Electronics', 'Female', 'Film', 'Goals', 'Gold', 'Heart Rate', 'Hemorrhage', 'Infant', 'Institutional Review Boards', 'Lead', 'Limb structure', 'Machine Learning', 'Measurement', 'Measures', 'Medical Staff', 'Methods', 'Modeling', 'Modification', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Neonatal', 'Neonatal Intensive Care Units', 'Nerve', 'Neural Network Simulation', 'Noise', 'Pain', 'Paper', 'Patients', 'Phase', 'Photoplethysmography', 'Physiologic pulse', 'Polychlorinated Biphenyls', 'Positioning Attribute', 'Process', 'Production', 'Pulse Pressure', 'Reading', 'Records', 'Resolution', 'Risk', 'Signal Transduction', 'Skin', 'Surface', 'System', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Wireless Technology', 'Work', 'Wrist', 'artificial neural network', 'base', 'care costs', 'cost', 'cost effective', 'demographics', 'design', 'encryption', 'flexibility', 'follow-up', 'improved', 'infection risk', 'light weight', 'male', 'miniaturize', 'neonate', 'neural network', 'novel', 'pressure', 'preterm newborn', 'scale up', 'sensor', 'sensor technology', 'skills', 'success', 'tonometry']",NICHD,"PYRAMES, INC.",R43,2020,224556,0.03868059467799101
"Development of a web-based platform implementing novel Predictor of Skin Sensitization for Medical Devices (PreSS/MD) PROJECT SUMMARY Medical devices have been documented to contain toxic chemicals that can leach and cause acute contact dermatitis (ACD) after repeated exposure or prolonged contact of the skin to these toxins. ACD is credited for 10-15% of all occupational illnesses and is also the second highest reported occupational hazard. Given its prevalence, ACD is also a great public health burden with combined yearly costs of up to $1 billion, which spans including medical costs, worker’s compensation and lost working time due to workplace absence. To this end, the U.S. Food and Drug Administration has mandated that all medical devices must be evaluated for possible skin sensitization using in vivo animal assays, which includes the Guinea pig maximization test (GPMT). Although GPMT tests provide valuable data on the skin sensitization effects of potential toxins, these assays are time-consuming and expensive. Moreover, the Interagency Coordinating Committee on the Validation of Alternative Methods (ICCVAM) recently published a Strategic Roadmap, calling for the development of alternative approaches to reduce animal testing of chemical and medical agents. Thus, there is a stated need to modernize safety evaluation of medical devices to reduce animal testing and shorten the regulatory review time, which would ultimately bring safer devices to the market faster. To address this unmet need, the key objectives of our FDA Phase I SBIR project are to (i) produce rigorously validated computational models for the GPMT assay integrating data obtained in human, mouse, and in vitro assays; and (ii) integrate these models into a software product termed PreSS/MD (Predictor of Skin Sensitization for Medical Devices). Our specific aims for this study include: 1) collecting, curating, and integrating the largest publicly available dataset for GMPT; 2) creating and validating novel computational models for GMPT data; 3) developing the PreSS/MD web server to allow users to make predictions of skin sensitization potential in medical devices. We will also develop a model for mixtures, including compounds tested jointly in different concentrations, using an approach that we developed previously. Finally, we will implement novel approaches to help users of our PreSS/MD platform interpret the developed models in terms of key chemical features responsible for skin sensitization. In addition, we will employ biomedical knowledge graphs to elucidate Adverse Outcome Pathways (AOPs) for skin sensitizers. Successful execution of this Phase I project will yield in the development of PreSS/MD as a centralized resource to evaluate the skin sensitization potential for medical devices. We expect this software-as-a-service web server platform will be of great value for companies and sponsors seeking regulatory approval of medical devices. PROJECT NARRATIVE Given that medical devices have been documented to contain toxic chemicals that may lead to allergic contact dermatitis, the US Food and Drug Administration requires that all devices be evaluated for possible skin sensitization effects using in vivo assays such as the Guinea pig maximization test. In the effort to modernize skin sensitization safety evaluation methods to reduce in vivo animal testing, herein we propose to develop a software product, PreSS/-MD (Predictor of Skin Sensitization caused by Medical Devices), as an innovative and unique in silico alternative with the potential to better predict human response compared to the existing approaches for skin sensitization assessment. Successful execution of the objectives described in this project will result in a centralized web server platform to evaluate the skin sensitization potential for medical devices, which will be of significant value for companies and sponsors seeking regulatory approval of medical devices.",Development of a web-based platform implementing novel Predictor of Skin Sensitization for Medical Devices (PreSS/MD),10079701,R43ES032371,"['Acute', 'Address', 'Advanced Development', 'Allergic Contact Dermatitis', 'Animal Testing', 'Animals', 'Bayesian Method', 'Bayesian Modeling', 'Biological Assay', 'Cavia', 'Chemical Structure', 'Chemicals', 'Computer Models', 'Computer software', 'Consumption', 'Contact Dermatitis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Economics', 'Evaluation', 'Feedback', 'Generations', 'Human', 'Immune response', 'Instruction', 'Interagency Coordinating Committee on the Validation of Alternative Methods', 'International', 'Knowledge', 'Lead', 'Medical', 'Medical Care Costs', 'Medical Device', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Occupational', 'Online Systems', 'Pathway interactions', 'Phase', 'Poison', 'Prevalence', 'Prostheses and Implants', 'Public Health', 'Publishing', 'Pythons', 'Quantitative Structure-Activity Relationship', 'Reaction', 'Reporting', 'Resources', 'Safety', 'Skin', 'Small Business Innovation Research Grant', 'Structure', 'Test Result', 'Testing', 'Time', 'Toxic effect', 'Toxin', 'United States Food and Drug Administration', 'Validation', 'Workers&apos', ' Compensation', 'Workplace', 'adverse outcome', 'chemical release', 'cost', 'experience', 'in silico', 'in vitro Assay', 'in vivo', 'innovation', 'knowledge graph', 'lymph nodes', 'machine learning algorithm', 'model development', 'novel', 'novel strategies', 'occupational hazard', 'operation', 'phase 1 study', 'response', 'skin patch', 'software as a service', 'success', 'systemic toxicity', 'tool', 'web portal', 'web server']",NIEHS,"PREDICTIVE, LLC",R43,2020,167910,-0.015062907468094393
