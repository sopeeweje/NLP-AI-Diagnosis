text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,10160864,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Models', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'machine learning method', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,335661
"Effects of Lifetime Noise Exposure Viewed Through the Brainstem Reflex Bifocals: Middle Ear Muscle Reflex and Medial Olivocochlear Reflex Project Summary Noise-induced hearing loss (NIHL) affects nearly one in four adults in the United States. With recent discov- eries pertaining to cochlear synaptopathy and outer hair cell (OHC) loss in the extended high frequencies, it is clear that much of the early NIHL remains `hidden' under traditional audiological scrutiny. Without early de- tection and intervention, such damage can progress into more severe hearing loss. Thus a critical window for therapeutics/lifestyle changes may go unutilized. However, there are currently no feasible tools that can identify early hearing damage. Prior studies that test the integrity of the auditory afferent pathway have not produced conclusive results. However, short- and long-term noise exposure-related peripheral damage are correlated with changes in the auditory efferent system. Speciﬁcally, hyperactivity in the medial olivocochlear reﬂex (MOCR) and threshold elevation of the middle ear muscle reﬂex (MEMR) have been reported. Given the protective roles of the MOCR and the MEMR through inhibition of peripheral inputs, and their differential changes with damage, we argue that a combined assay of MOCR and MEMR may serve as a marker for early hearing damage in humans.  Using a novel otoacoustic emission (OAE)-based efferent assay, in the proposed studies we aim to (1) eval- uate long-term age-speciﬁc changes in efferent and afferent function due to noise exposure and (2) evaluate short-term changes in efferent and afferent function due to noise exposure. We will investigate the concurrent working of the two reﬂexes across a wide age range (18-50 years) and noise exposure by recruiting individuals from high noise exposure (musicians, veterans, construction workers, farmer) and low noise exposure occupa- tions (students, professors). To evaluate short-term changes due to noise exposure, we will test participants before and after their typical work day. For reliable exposure stratiﬁcation, noise exposure will be objectively quantiﬁed using 5-day sound dosimetry. We will also use the most sensitive afferent measures to allow compari- son with efferent measures. Machine learning approaches will be employed to ascertain relationships among the cochlear, afferent, and efferent function for short- and long-term noise exposures.  Findings from project 1 will reveal if the combined MOCR and MEMR metrics can delineate noise exposure effects from aging, and highlight the relationships among cochlear, afferent, and efferent measures. Findings from project 2 will reveal if long-term noise exposure predicts short-term changes following noise exposure and vice- versa. A better understanding of short- and long-term changes in the auditory system following noise exposure will aid in the development of (1) an objective rapid screening test of the auditory efferents capable of detecting noise exposure-related hearing damage and (2) a statistical model to enable predicting impending damage based on efferent function. Together, these tools will contribute to early detection and promote hearing conservation. Project Narrative This study will investigate the role of the auditory efferents, the medial olivocochlear reﬂex (MOCR) and the middle ear muscle reﬂex (MEMR), in short- and long-term noise exposure-related changes in the auditory system. Additionally, statistical models will be developed to understand the relationship between efferent and afferent candidate measures of hearing damage. The outcomes of this study will lay the foundation for a screening test of early hearing damage based on the integrity of the auditory efferent system.",Effects of Lifetime Noise Exposure Viewed Through the Brainstem Reflex Bifocals: Middle Ear Muscle Reflex and Medial Olivocochlear Reflex,10204332,R21DC018108,"['Accounting', 'Adult', 'Affect', 'Afferent Pathways', 'Age', 'Auditory', 'Auditory system', 'Behavioral', 'Bilateral', 'Biological Assay', 'Brain Stem', 'Clinical', 'Cochlea', 'Cohort Studies', 'Control Groups', 'Data', 'Development', 'Early Diagnosis', 'Exposure to', 'Foundations', 'Frequencies', 'Goals', 'Growth', 'Hearing', 'Hearing Protection', 'Hearing Tests', 'Human', 'Hyperactive behavior', 'Individual', 'Intervention', 'Kinetics', 'Legal patent', 'Life Style', 'Long-Term Effects', 'Machine Learning', 'Measures', 'Medial', 'Methodology', 'Methods', 'Noise', 'Noise-Induced Hearing Loss', 'Occupational', 'Occupational Noise', 'Occupations', 'Outcome Study', 'Outer Hair Cells', 'Participant', 'Peripheral', 'Protocols documentation', 'Rapid screening', 'Reflex action', 'Reporting', 'Role', 'Screening procedure', 'Statistical Models', 'Stratification', 'Students', 'System', 'Temporary Threshold Shift', 'Testing', 'Time', 'United States', 'Veterans', 'Work', 'age effect', 'age group', 'age related', 'base', 'clinically translatable', 'cochlear synaptopathy', 'conditioning', 'demographics', 'dosimetry', 'ear muscle', 'farmer', 'hearing impairment', 'middle ear', 'musician', 'normal hearing', 'novel', 'otoacoustic emission', 'professor', 'recruit', 'response', 'screening', 'sound', 'therapeutic lifestyle change', 'tool']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,R21,2021,155333
"AUDITORY NEURAL FUNCTION IN IMPLANTED PATIENTS WITH USHER SYNDROME PROJECT SUMMARY/ABSTRACT  Usher syndrome (USH) is an autosomal recessive disorder characterized by hearing loss, visual impairment, and in some cases, vestibular dysfunction. It is the leading cause of hereditary deaf-blindness in humans. USH causes extensive degeneration in the cochlear nerve (CN), especially in CN fibers innervating the base of the cochlea. Whereas there is no treatment for arresting this degenerative process or for restoring visual loss, the restoration of auditory input is possible with cochlear implantation. Due to the progressive deterioration in vision, using visual cues for communication will eventually become impossible. Therefore, the importance of optimizing auditory inputs through cochlear implants (CIs) for patients with USH is paramount. However, patients with USH have much higher rates of neurological, mental, or behavioral disorders than the general CI patient population, which limits their ability to provide reliable behavioral responses or sufficient verbal descriptions of their auditory perception, especially for pediatric patients. In addition, optimal programming parameters for CI users with CN damage differ from those used in typical CI users due to declined CN responsiveness to electrical stimulation. As a result, the clinical programming process in implanted patients with USH can be extremely challenging. To date, auditory neural encoding of electrical stimulation in patients with USH has not been systematically evaluated. Consequently, the field lacks evidence-based practice guidelines for managing implanted patients with USH. For patients who cannot provide reliable feedback, clinicians rely on a “trial-and-error” approach for adjusting CI programming settings, which ultimately may not result in appropriate programming maps for individual patients. Therefore, there is an urgent need to develop objective clinical tools for optimizing CI settings for these patients. As the first step toward developing evidence-based practice for managing patients with USH, this study evaluates local neural health, as well as the neural encoding of temporal and spectral cues at the CN in implanted patients with USH. Aim 1 will determine local CN health in patients with USH by assessing the sensitivity of the electrically evoked compound action potential to changes in interphase gap and pulse polarity. Aim 2 will determine group differences in neural encoding of temporal and spectral cues at the CN between patients with USH and patients with idiopathic hearing loss. Aim 3 will use supervised machine learning techniques to develop an objective tool for assessing the electrode-neuron interface at individual electrode locations. Results of this study have high scientific significance because they will establish how CN degeneration affects neural encoding and processing of electrical stimulation, and identify tests that distinguish the loss of spiral ganglion neurons from the loss of peripheral axons. Results of this study also have high clinical significance because they will 1) lay the groundwork for developing effective, evidence-based clinical practice guidelines for managing patients with USH, and 2) yield an objective tool for assessing the site-specific electrode-neuron interface in all CI users, which is foundational for creating optimal programming maps for individual patients. PROJECT NARRATIVE The proposed study is relevant to public health because it aims to better understand neural encoding and processing of electrical stimulation in patients with Usher syndrome (USH) – an autosomal recessive disorder that is the leading cause of hereditary deaf-blindness. Results from this study will have a broad impact on the field by 1) establishing how cochlear nerve degeneration affects neural encoding and processing of electrical stimulation, 2) identifying tests that distinctly evaluate the loss in the spiral ganglion cells vs the loss in the peripheral axon, and 3) yielding an objective tool for assessing the site-specific electrode-neural interface in all cochlear implant users. Results from this study will also have a targeted impact on implanted patients with USH by laying the groundwork for developing an effective, evidence-based clinical practice for managing these patients. This project is relevant to the mission of NIH because it seeks fundamental knowledge about the nature of electrical hearing in patients with USH and strives to apply this knowledge to reduce disability in all patients with cochlear implants.",AUDITORY NEURAL FUNCTION IN IMPLANTED PATIENTS WITH USHER SYNDROME,10192995,R21DC019458,"['Accounting', 'Action Potentials', 'Address', 'Adopted', 'Affect', 'Auditory', 'Auditory Perception', 'Auditory system', 'Axon', 'Behavior Disorders', 'Blindness', 'Child', 'Childhood', 'Clinical', 'Clinical Practice Guideline', 'Cochlea', 'Cochlear Implants', 'Cochlear Nerve', 'Cochlear implant procedure', 'Communication', 'Cues', 'Data Set', 'Degenerative Disorder', 'Deterioration', 'Disease', 'Electric Stimulation', 'Electrodes', 'Electrophysiology (science)', 'Evidence based practice', 'Feedback', 'Foundations', 'Frequencies', 'Functional disorder', 'Gap Junctions', 'Goals', 'Health', 'Hearing', 'Human', 'Implant', 'Individual', 'Inherited', 'Interphase', 'Knowledge', 'Location', 'Maps', 'Measures', 'Mental disorders', 'Mission', 'Modeling', 'Mutation', 'Nature', 'Nerve Degeneration', 'Nerve Fibers', 'Neurons', 'Neurophysiology - biologic function', 'Output', 'Patients', 'Pattern', 'Peripheral', 'Physiologic pulse', 'Play', 'Practice Management', 'Process', 'Public Health', 'Recovery of Function', 'Refractory', 'Research', 'Retinitis Pigmentosa', 'Sensorineural Hearing Loss', 'Site', 'Speech', 'Speech Perception', 'Techniques', 'Testing', 'United States', 'United States National Institutes of Health', 'Usher Syndrome', 'Vision', 'Visual', 'Visual impairment', 'axonal degeneration', 'base', 'behavioral response', 'clinical care', 'clinical practice', 'clinically significant', 'comorbidity', 'daily functioning', 'deaf', 'disability', 'evidence base', 'evidence based guidelines', 'ganglion cell', 'hearing impairment', 'histological studies', 'individual patient', 'model development', 'nervous system disorder', 'neuron loss', 'patient population', 'pediatric patients', 'point of care', 'programs', 'relating to nervous system', 'response', 'restoration', 'spiral ganglion', 'supervised learning', 'temporal measurement', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R21,2021,196406
"Revealing the organization and functional significance of neural timescales in auditory cortex Project Summary People are remarkably adept at making sense of the world through sound: understanding speech in a noisy restaurant, picking out the voice of a family member, or recognizing a familiar melody. Although we take these abilities for granted, they reflect impressive computational feats of biological engineering that are remarkably difficult to replicate in machine systems. The long-term goal of my research program is to develop computational and experimental methods to reverse-engineer how the brain codes natural sounds like speech and to exploit these advances to understand and aid in the treatment of hearing impairment. One of the central challenges of coding natural sounds is that they are structured at many different timescales from milliseconds to seconds and even minutes. How does the brain integrate across these diverse timescales to derive meaning from sound? Answering this question has been challenging because there are no general-purpose methods for measuring neural timescales in the brain. As a consequence, we know relatively little about how neural timescales are organized in auditory cortex and how this organization enables the coding of natural sounds. To overcome these limitations, we develop a simple experimental paradigm (the “temporal context invariance” or TCI paradigm) for estimating the temporal integration period of any sensory response: the time window during which stimuli alter the response. We apply the TCI method to human electrocorticography (ECoG) and animal physiology recordings to reveal the organization of neural timescales at both the region and single-cell level (Aim I). Pilot data from our analyses reveal that timescales are organized hierarchically, with higher-order regions showing substantially longer integration periods. To explore the functional significance of this timescale hierarchy, we couple TCI with computational techniques well-suited for characterizing natural sounds (Aim II). We test whether increased integration periods enable a more noise-robust representation of speech (Aim IIA), whether regions with longer integration periods code higher-order properties of natural sounds (Aim IIB&IIC), whether there are dedicated integration periods for important sounds categories like speech or music (Aim IID), and whether cortical integration periods can be explained by the duration of the features they respond to (Aim IIE). In the process of conducting this research, I will be trained in two critical areas: (1) ECoG, which is the only method with the spatial and temporal precision to understand how neural timescales are organized in the human brain (2) deep neural networks (DNN) which are the only models able to perform challenging perceptual tasks at human levels and predict neural responses in higher-order cortical regions. After completing this training, I will have a unique set of experimental (fMRI, ECoG, psychophysics) and computational skills (data-driven statistical modeling and hypothesis-driven DNN modeling), which will facilitate my transition to an independent investigator. Project Narrative Natural sounds like speech contain information at many different timescales (e.g. phonemes, syllables, words), but how the human brain extracts this information remains unclear. Understanding this process is critical to understanding how hearing impairment degrades speech perception. The proposed research will reveal the organization of neural timescales in the brain, and how this organization facilitates the coding of natural sounds like speech, which is a critical first step in understanding how this code is impaired by hearing loss.",Revealing the organization and functional significance of neural timescales in auditory cortex,10169404,K99DC018051,"['Address', 'Animals', 'Area', 'Auditory area', 'Biological', 'Brain', 'Categories', 'Cells', 'Code', 'Collaborations', 'Communication', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Data', 'Electrocorticogram', 'Engineering', 'Family member', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Hearing', 'Human', 'Learning', 'Measures', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurosciences', 'Noise', 'Physiology', 'Population', 'Process', 'Property', 'Psychophysics', 'Reaction Time', 'Research', 'Research Personnel', 'Research Training', 'Restaurants', 'Sensory', 'Speech', 'Speech Perception', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'Voice', 'Work', 'clinically significant', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'millisecond', 'neuromechanism', 'programs', 'relating to nervous system', 'response', 'skills', 'sound', 'theories']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,K99,2021,125442
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology Project Summary Listening in noise is a core problem in everyday hearing. Sound sources of interest routinely occur amid irrelevant distractors, as when you talk with someone in a bustling coffee shop. This background “noise” distorts the pattern of spikes in the auditory nerve, often to a profound degree. Thus, to recognize sources of interest, the auditory system must somehow separate or suppress the effects of the background. Typical human hearing is remarkably noise-robust, but listeners with age-related hearing loss or other forms of impaired hearing struggle in noisy environments – and are not much helped by contemporary hearing aids. Previous work on the neural basis of noise robustness has typically employed simple, synthetic noise sources, which lack the structure present in real-world sounds, and this work has focused on subcortical regions or on primary auditory cortex. Reasoning that real-world conditions might necessitate more complicated solutions, in the applicant's doctoral work, he considered everyday sources of noise, and leveraged the large-scale coverage afforded by fMRI to examine noise robustness throughout human auditory cortex. Real-world “background noise” was operationalized as a natural sound with statistical properties that are stable over time (i.e., are stationary), conveying little new information about the world (e.g., swamp insects, an air conditioner, rain on pavement). The applicant measured fMRI responses in human listeners to a broad set of natural sounds presented in quiet, as well as embedded in the real-world background noises. Primary auditory cortical responses were substantially altered by the background, but non-primary responses were substantially more robust. This effect was not seen for simple synthetic backgrounds as had been used in previous work, suggesting that becoming robust to real-world background noises require different mechanisms. The applicant's thesis work demonstrates where noise invariance arises, but understanding how will require data with finer spatial and temporal resolution, and thus the proposed postdoctoral research will consist of training in single-unit electrophysiology using marmosets. Aim 1A builds on previous work examining single- unit noise robustness in artificial conditions, extending such work to real-world noise. Aim 1B leverages texture models to probe what aspects of real-world backgrounds disrupt the encoding of foregrounds. Aim 2A deploys linear reconstruction techniques to probe population representations. Aim 2B involves optimizing deep neural networks for noise invariance tasks, and using them as an encoding model to predict single-unit responses. Furthermore, such networks will be deployed as nonlinear decoding algorithms, reconstructing stimuli from neuronal populations. Throughout all aims, the work will characterize neuronal responses in non-primary areas, and in particular in parabelt, which is understudied in primates. The proposed work may enable improvements in hearing aid algorithms or neural prosthetics. Lastly, this training will lay the groundwork for the applicant's long-term goal of developing a marmoset model for hearing loss. Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,10115690,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Quality of life', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'algorithm training', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2021,66390
"Decoding parametric attributes of auditory working memories from human brain activity Decoding parametric attributes of auditory working memories from human brain activity Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Auditory WM dysfunctions are evidenced in individuals with speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as central auditory processing disorders (CAPD). Better understanding of auditory WM would help develop more precise biomarkers and targeted interventions for these deficits. Evidence for neuronal activation related to auditory WM patterns have been found in laboratory animals as well as in non- invasive human neuroimaging studies, both in auditory cortices (AC) and elsewhere in the brain. Recent human fMRI data also provide some evidence on item-specific activation patterns in ACs and frontal cortices. However, exactly where in the brain auditory WM content is stored and, more importantly, how the memorized information is represented is still unclear.  This research program pursues a better understanding of human auditory WM by attempting to infer its contents from the brain: Using state-of-the-art non-invasive neuroimaging and advanced signal-analysis methods we will search for cortical activation patterns that would predict item-specific WM information. We will examine brain function non-invasively with magneto- and electroencephalography (MEG/EEG), transcranial magnetic stimulation (TMS), and functional MRI (fMRI), and validate the findings using intracranial EEG (iEEG) measurements in presurgical patients. Recent studies suggest that, instead of persistent activation patterns, WM is supported by short-term synaptic facilitation, i.e., ""activity-silent"" population-level mechanisms. We hypothesize that these activity-silent representations could be decoded by analyzing the aftereffects of generic auditory ""impulse stimuli"" or TMS, which are utilized to ""ping"" the underlying cortical network during memory maintenance. We also hypothesize that although auditory WM likely involves co-operation of multiple brain regions, which are involved in articulatory-motor functions, perceptual categorization, or semantic processing, the retention of auditory-sensory attributes such as spectrotemporal modulation patterns critically depends on ACs. To examine WM of such auditory attributes, we will use tasks with dynamic ripple sound stimuli, which are spectrotemporally similar to human vocalizations but resist non-auditory processing strategies.  The major significance of this project is that it will increase the understanding of auditory WM, a crucial cognitive function whose neuronal bases have remained elusive. The results may also help develop more precise tools for characterizing auditory WM dysfunctions in hearing and communication deficits as well as in disorders such as dyslexia, attention deficit/hyperactivity disorder (ADHD), and schizophrenia. Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Our research program pursues a better theoretical understanding of this crucial cognitive function using advanced multimodal neuroimaging methods, validated using intracranial recordings in pre-surgical patients. Our results may also help develop more precise tools for characterizing auditory WM dysfunctions in speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as attention deficit/hyperactivity disorder (ADHD) and schizophrenia.",Decoding parametric attributes of auditory working memories from human brain activity,10105316,R01DC016915,"['Attention deficit hyperactivity disorder', 'Auditory', 'Auditory area', 'Biological Markers', 'Brain', 'Brain region', 'Central Auditory Processing Disorder', 'Cognition', 'Communication', 'Data', 'Disease', 'Dyslexia', 'Electroencephalography', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Individual', 'Intervention', 'Laboratory Animals', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measurement', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Motor', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perceptual Disorders', 'Population', 'Principal Component Analysis', 'Problem Solving', 'Reading', 'Research', 'Schizophrenia', 'Sensory', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Speech Perception', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Transcranial magnetic stimulation', 'base', 'cognitive function', 'cortex mapping', 'electric field', 'experimental study', 'frontal lobe', 'multimodality', 'neuroimaging', 'operation', 'programs', 'semantic processing', 'sound', 'tool', 'vocalization']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,599963
"Behavioral and neural algorithms for decision confidence Project Summary/Abstract The long-term goal of our investigations is to understand how neural circuits in the frontal cortex support decision- making. Orbitofrontal cortex (OFC) plays a key role in decision-making under uncertainty and is thought to enable humans and other animals to make predictions about outcomes more accurately. The objective of this proposal is to determine the algorithms responsible for confidence-guided behaviors and their neural basis in the mammalian brain.  Previous work from our laboratory has shown that `decision confidence', a cognitive variable, is encoded in single OFC neurons and OFC inactivation specifically impairs a confidence-guided behavior, time investment. The proposed experiments are designed to determine the computational and neural algorithms responsible for two confidence-guided behaviors: time investment and choice strategy updating (learning). Our central hypothesis is that OFC generates an abstract representation of decision confidence, independent of sensory evidence, that supports multiple confidence-guided behaviors. To test this idea, we have designed a quantitative psychophysical task for rats, adapted from human and primate work, that enable behavioral readouts of confidence, as a post-decision temporal wager. Simply, after each perceptual decision (olfactory or auditory) rats invest time waiting for a delayed, uncertain reward. These graded- duration time investments serve as a behavioral report of confidence that the perceptual decision just made will result in the success of the perceptual decision. First, we will develop computational algorithms to explain confidence-guided time investment and learning, and second we will identify neural substrates of these algorithms in the OFC. Third, we will determine if OFC representations are sensory-modality and behavioral-output general and test the causal role of OFC using inactivations. Finally, we will map a sensory route for auditory information to inform OFC representations and test the hypothesis that auditory cortex lesions lead to deaf-hearing, the ability to discriminate sounds without perceptual confidence.  These contributions are significant, in our opinion, because they will provide critical missing information about the algorithmic and neural foundations of decision confidence, a key cognitive variable. Our approach is innovative, chiefly because we have developed a computational and behavioral framework to study confidence in rats. Beyond these mechanistic studies, the proposed work will advance knowledge about the frontal cortical logic of cognitive variable representations and inform an improved framework for understanding how impairments in a single brain area can lead to a wide range of psychiatric disorders, as seen in depression, obsessive- compulsive and psychotic disorders. Project narrative This proposal aims to identify the computational algorithms of two confidence-guided behaviors, time investment and choice strategy updating, and the neural processes underlying these. We will use a combination of electrophysiology, viral tracing, optogenetics in a quantitative confidence-reporting behavior in rats, interpreted with computational modeling and statistical analysis. We aim to test our central hypothesis that OFC generates an abstract representation of decision confidence that supports multiple confidence-guided behavioral processes.",Behavioral and neural algorithms for decision confidence,10178111,R01MH097061,"['Algorithms', 'Animals', 'Anxiety', 'Area', 'Auditory', 'Auditory area', 'Awareness', 'Behavior', 'Behavioral', 'Behavioral trial', 'Belief', 'Brain', 'Cognitive', 'Complex', 'Computational algorithm', 'Computer Models', 'Data', 'Decision Making', 'Electrophysiology (science)', 'Foundations', 'Goals', 'Hearing', 'Human', 'Impairment', 'Investigation', 'Investments', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Lesion', 'Logic', 'Maps', 'Mental Depression', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Monkeys', 'Neurons', 'Obsessive compulsive behavior', 'Outcome', 'Output', 'Pathologic', 'Play', 'Population', 'Primates', 'Process', 'Psychophysics', 'Psychotic Disorders', 'Rattus', 'Reporting', 'Rewards', 'Rodent', 'Role', 'Route', 'Sensory', 'Statistical Data Interpretation', 'Stream', 'Testing', 'Time', 'Uncertainty', 'Update', 'Viral', 'Vision', 'Visual', 'Visual Cortex', 'Wages', 'Work', 'base', 'blind', 'deaf', 'design', 'experimental study', 'falls', 'frontal lobe', 'improved', 'innovation', 'machine learning method', 'neural circuit', 'neuropsychiatry', 'novel', 'optogenetics', 'relating to nervous system', 'sensory cortex', 'sound', 'success']",NIMH,WASHINGTON UNIVERSITY,R01,2021,442510
"Auditory precursors of language delay in toddlers with autism spectrum disorders Abstract Language delay and impairments are common in autism spectrum disorders (ASDs), as are sensory (including auditory) anomalies. Since acquisition of spoken language relies on the integrity of the auditory system, language delay and impairments may be related to sound processing abnormalities that are frequently observed in children with ASDs (despite normal peripheral hearing). However, it is not understood if and how early auditory brain anomalies may developmentally contribute to impaired language development.  This project will examine the maturation of auditory and language systems in the brain across early childhood, during the critical period for language acquisition. We will employ a longitudinal design and multimodal neuroimaging, including high-resolution anatomical, diffusion, and functional magnetic resonance imaging (MRI), with added frequent and extensive behavioral and neuropsychological assessments. Our central hypothesis is that early disruptions to cortical sound processing precede and predict language impairments in ASDs and may thus be considered causal contributors – a hypothesis that has been frequently considered in the literature, but never tested at the neural level.  Our aims are to thoroughly characterize the structural integrity and functional differentiation of the cortical auditory and language systems (Aim 1) and their maturational trajectories (Aim 2) in toddlers with ASDs and age-matched typically developing peers. This will allow us to establish whether neural abnormalities in cortical processing of complex sounds in toddlers are predictive of language development and social behavior at the pre-school age (Aim 3). The rationale and translational significance of this project are that identification of alterations in brain development linked to language delay and impairment in the first years of life will allow for more targeted interventions in the auditory domain at a time when they are most effective. Project narrative The project aims to find causes of language impairment in children with autism spectrum disorders by studying the brain organization of the auditory system in toddlers at the very earliest age of provisional diagnosis. The overarching hypothesis is that atypical auditory processing contributes to language delay and impairment. Pinpointing auditory causes of language problems in children with ASDs may inform early interventions.",Auditory precursors of language delay in toddlers with autism spectrum disorders,10132296,R01DC017736,"['Age', 'Anatomy', 'Animal Model', 'Anisotropy', 'Auditory', 'Auditory area', 'Auditory system', 'Basic Science', 'Behavioral', 'Brain', 'Brain region', 'Child', 'Complex', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Early Intervention', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Imaging Techniques', 'Impairment', 'Intervention', 'Language', 'Language Delays', 'Language Development', 'Length', 'Life', 'Link', 'Literature', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Morphology', 'Neurites', 'Neuropsychology', 'Nursery Schools', 'Organizational Change', 'Pattern', 'Peripheral', 'Radial', 'Research', 'Research Priority', 'Resolution', 'Risk', 'Sensory', 'Sleep', 'Social Behavior', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'TEP1 gene', 'Techniques', 'Testing', 'Thalamic structure', 'Thick', 'Time', 'Toddler', 'auditory processing', 'autism spectrum disorder', 'autistic children', 'base', 'critical period', 'density', 'early childhood', 'gray matter', 'indexing', 'individuals with autism spectrum disorder', 'language impairment', 'longitudinal design', 'machine learning method', 'molecular modeling', 'multimodality', 'myelination', 'neuroimaging', 'novel', 'peer', 'phonology', 'recruit', 'relating to nervous system', 'response', 'sound', 'theories', 'translational impact']",NIDCD,SAN DIEGO STATE UNIVERSITY,R01,2021,588497
"The Nanoscale Connectome of the Cochlear Nucleus The cochlear nucleus is the gateway for central nervous system processing of auditory information in mammals. It has been proposed that parallel processing channels are set up in the CN, and these form the basis for further computation at higher stations of the auditory system. Despite decades of study, enumeration of CN cell types is incomplete and CN circuitry is described only superficially. In neuroscience generally, classification and naming of neurons has relied primarily upon qualitative approaches based upon human observational capabilities. We have implemented and in some cases developed novel high-throughput and unbiased techniques for labeling, segmenting and classifying neurons in 3D, generated from large-scale electron microscopy image volumes. We propose to deliver a nanoscale map, or connectome, of the mouse CN with enumerated and localized cell types and their synaptic connections. This effort is unbiased because all neurons will be sampled. To achieve this goal, we bring together four parallel modes of tissue analysis for neuron classification: morphology, connectivity, molecular identity and function. We propose that connectivity analysis will define long-proposed parallel processing circuits that will be tested functionally using realistic biophysical models of identified cell types. Notably, the cochlear nucleus contains both amorphous and layered organizations of cells, which serve as templates for all other brain regions. By investigating the fundamental structure of this sensory center, we will establish principles of neural computation and methods for structural and functional phenotyping that will apply to other brain regions regardless of their particular neural architecture. Relevance to Public Health The goal of this project is to deliver to the auditory research community the connectome of the mouse cochlear nucleus. In the process we will refine and develop comprehensive and high throughput methods to catalogue cell types and their connections in any brain region, and will provide molecular phenotypes for cochlear nucleus cell types that may be useful in their targeted manipulation for research and therapeutic purposes. This work forms a basis to study central alterations following noise- induced hearing loss or other cochlear pathology, and gain deeper understanding of all auditory structures from brainstem to cortex.",The Nanoscale Connectome of the Cochlear Nucleus,10131580,R01DC015901,"['3-Dimensional', 'Acoustic Nerve', 'Acoustics', 'Adult', 'Architecture', 'Auditory', 'Auditory system', 'Automobile Driving', 'Axon', 'Biophysics', 'Birds', 'Brain Stem', 'Brain region', 'CNS processing', 'Catalogs', 'Cell model', 'Cells', 'Cellular Structures', 'Censuses', 'Classification', 'Cochlea', 'Cochlear nucleus', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Electron Microscopy', 'Experimental Designs', 'Frequencies', 'Future', 'Gene Expression', 'Genetic', 'Goals', 'Graph', 'Hearing', 'Hearing problem', 'Human', 'Image', 'Knowledge', 'Label', 'Learning', 'Link', 'Location', 'Mammals', 'Maps', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Names', 'Nerve', 'Nerve Fibers', 'Neurons', 'Neurosciences', 'Noise-Induced Hearing Loss', 'Octopus', 'Pathology', 'Pattern', 'Peripheral', 'Phenotype', 'Process', 'Public Health', 'Research', 'Resolution', 'Sampling', 'Scanning Electron Microscopy', 'Sensory', 'Shapes', 'Skeleton', 'Specific qualifier value', 'Standardization', 'Structure', 'Supervision', 'Synapses', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Tissues', 'Work', 'afferent nerve', 'auditory processing', 'automated segmentation', 'base', 'biophysical model', 'cell type', 'cellular targeting', 'connectome', 'experimental study', 'fluorescence imaging', 'granule cell', 'health goals', 'human error', 'in silico', 'microscopic imaging', 'molecular phenotype', 'molecular scale', 'nanoscale', 'nerve supply', 'neural circuit', 'neural model', 'novel', 'parallel processing', 'prevent', 'programs', 'recombinase', 'relating to nervous system', 'sensory system', 'sound', 'tool', 'transcription factor', 'unsupervised learning', 'virtual reality']",NIDCD,UNIVERSITY OF SOUTH FLORIDA,R01,2021,620597
"SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN) PROJECT SUMMARY/ABSTRACT In recent years, human cognitive auditory neuroscience has made rapid strides due to advances in human neuroimaging, the advent of innovative machine learning/big data analytic approaches, and a greater mechanistic understanding of cognitive-sensory interactions in animal models. The dynamic landscape of this emergent field necessitates a highly interdisciplinary, human and translation-centric symposium that brings together expertise across academia and industry. This application requests partial funding for the Symposium on Cognitive Auditory Neuroscience (SCAN) to be hosted in Pittsburgh, PA in July 2020 and 2022, as a joint venture between Carnegie Mellon University (CMU) and University of Pittsburgh (Pitt). As a biennial meeting, SCAN aims to become the premiere intellectual and professional venue for current research in the emerging field of human cognitive auditory neuroscience. SCAN will incorporate elements typical to academic conferences (research talks, posters) as well as novel ideas that promote ‘blue sky’ thinking in this rapidly evolving field. SCAN will assiduously and innovatively work towards inclusivity and creating an atmosphere that encourages intellectual and professional engagement from women, underrepresented minorities, and individuals with disabilities. Another critical aim of the SCAN is to foster industry-academic partnerships with an eye towards translation of basic research and fostering career opportunities for trainees. Pittsburgh is uniquely situated to launch SCAN. With an enviable concentration of co-located auditory neuroscience expertise, Pittsburgh is also an intellectual hub for industries/start-ups engaged in in machine learning, natural language processing, and speech recognition. SCAN will leverage these advantages to foster growth and innovation tied to core missions of the National Institutes of Deafness and Communication Disorders. PROJECT NARRATIVE The Symposium on Cognitive Auditory Neuroscience (SCAN) has a strong connection to deafness and communication disorders through its focus on the basic science of human cognitive auditory neuroscience, and its translation. SCAN will establish an intellectual home for dissemination of cutting-edge research in human cognitive auditory neuroscience, support the development of the next generation of scientists, build a vibrant and inclusive community that engages with the grand challenges in the field, and forge new academia-industry partnerships.",SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN),10078266,R13DC018243,"['Academia', 'Acoustics', 'Address', 'Affect', 'Americas', 'Animal Model', 'Atmosphere', 'Attention', 'Auditory', 'Auditory Perception', 'BRAIN initiative', 'Base of the Brain', 'Basic Science', 'Behavioral', 'Big Data Methods', 'Brain', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communities', 'Complex', 'Development', 'Disabled Persons', 'Disease', 'Ear', 'Educational workshop', 'Elements', 'Environment', 'Eye', 'Fertilization', 'Fostering', 'Funding', 'Geographic Locations', 'Goals', 'Growth', 'Hearing', 'Home environment', 'Human', 'Industry', 'Influentials', 'Institutes', 'Joint Ventures', 'Learning', 'Life', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Mission', 'Natural Language Processing', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Otolaryngology', 'Participant', 'Perception', 'Peripheral', 'Problem Solving', 'Process', 'Request for Applications', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Seeds', 'Sensory', 'Societies', 'Speech', 'Thinking', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'analytical tool', 'base', 'career', 'cognitive neuroscience', 'deafness', 'industry partner', 'innovation', 'interest', 'meetings', 'millisecond', 'neuroimaging', 'new technology', 'next generation', 'novel', 'open data', 'posters', 'pressure', 'relating to nervous system', 'sensory input', 'sound', 'speech recognition', 'symposium', 'virtual reality']",NIDCD,CARNEGIE-MELLON UNIVERSITY,R13,2021,1766
"Sound encoding by neural populations in auditory cortex during behavior Project Summary Throughout life, humans and other animals adapt their hearing to perceive features of sound that are important for successful behavioral decisions. Normal-hearing humans are able to detect and discriminate important sounds in crowded noisy scenes and to understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings. Even when they can perceive sounds accurately, the additional listening effort required negatively impacts other cognitive functions. A better understanding of how the healthy auditory system operates in cognitively challenging contexts will support new treatments for these deficits. This project will study how the auditory system represents sound information as it operates in challenging acoustic environments. There are three specific aims. First, high-density microelectrode arrays will be used to record the simultaneous activity of neural populations in auditory cortex during behaviors that require detecting sounds masked by noise or learning new sound-reward associations. Recording from multiple neurons will enable characterizing how information is encoded by the simultaneous activity of neural populations. These experiments will test the hypothesis that population activity in auditory cortex generates representations that are invariant to irrelevant distracting sounds. Second, optogenetic tools will be used to identify distinct neuronal cell types (excitatory versus inhibitory) in cortex. This study will test the hypothesis that tonic activation of inhibitory neurons can explain changes in population activity during behavior. Third, machine learning tools will be used to model the simultaneously recorded neural activity. These experiments will test the hypothesis that neurons in the same local anatomical circuit in auditory cortex encode information about a relatively small domain in the space of all possible auditory stimuli. Models fit to experimental data will also describe how changes in behavioral state shift the way neurons encode sounds and describe sources of correlated population activity that impact neural discriminability during behavior. Together these experiments will establish new links between neural representation of sound and the cognitive processes that extract important information from sound for successful behavior. Project Narrative Patients with hearing impairment and central neurological disorders have difficulty keeping track of speech and other complex sounds, particularly in challenging noisy environments. We seek to understand how populations of neurons in auditory cortex change their activity as the brain adapts to noisy environments. These experiments will provide insight into basic function of the healthy brain that can inform treatment of hearing disorders.",Sound encoding by neural populations in auditory cortex during behavior,10302718,R01DC014950,"['Acoustics', 'Affect', 'Anatomy', 'Animals', 'Area', 'Arousal', 'Attention', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Code', 'Cognitive', 'Complex', 'Computer Models', 'Crowding', 'Data', 'Dimensions', 'Discrimination', 'Electrophysiology (science)', 'Enhancers', 'Environment', 'Ferrets', 'Frequencies', 'Hearing', 'Hearing problem', 'Human', 'Individual', 'Interneurons', 'Label', 'Lasers', 'Learning', 'Life', 'Link', 'Machine Learning', 'Masks', 'Measures', 'Mediating', 'Methods', 'Microelectrodes', 'Modeling', 'Monitor', 'Neurons', 'Noise', 'Operating System', 'Patients', 'Performance', 'Peripheral', 'Play', 'Population', 'Process', 'Property', 'Pupil', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Testing', 'Time', 'Training', 'Virus', 'auditory processing', 'auditory stimulus', 'cell type', 'cognitive function', 'cognitive process', 'deep neural network', 'density', 'excitatory neuron', 'experimental study', 'flexibility', 'frontal lobe', 'hearing impairment', 'improved', 'indexing', 'inhibitory neuron', 'insight', 'machine learning method', 'nervous system disorder', 'neural model', 'neuromechanism', 'neurophysiology', 'new technology', 'normal hearing', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,320591
"Motor Modulation of Auditory Processing Project Summary Vocal communication depends on distinguishing our own vocal sounds (vocal feedback) from other sounds. Vocal motor-related corollary discharge (vocal CD) signals that suppress auditory responses to predictable vocal feedback help make this distinction. Notably, vocal CD signals in the human auditory cortex are especially important to speech and their dysfunction is thought to cause auditory hallucinations. Despite the key roles postulated for vocal CD signals, the challenges of monitoring and manipulating their activity in vocalizing animals has prevented systematic analyses. The long-term objective of this application is to understand with synaptic, cellular, and circuit resolution how vocal CD signals modulate auditory cortical responses to vocal feedback, detailed knowledge of which is essential to understand adaptive and maladaptive aspects of audition. We will gain detailed knowledge of synaptic, cellular, and circuit mechanisms underlying this process by studying the mouse, the vertebrate most suited to advanced genetic, electrophysiological, and optical tools. In the prior funding period, we used these tools to advance our understanding the synaptic and circuit mechanisms by which movement-related CD signals modulate auditory cortical activity. These advances included mapping a motor to auditory cortical circuit, determining that various head and body movements activate this pathway to suppress auditory cortical responses to sounds, and showing that this pathway can “learn” to selectively suppress sounds that are predictably yoked to locomotor movements. We also observed auditory cortical suppression in vocalizing male mice, but vocalization occurred during female courtship and was always accompanied by other movements, as well as by social and sexual stimuli. Therefore, whether vocalization-specific CD signals modulate the auditory cortex and suppress predictable vocal feedback remain unknown. Fortunately, we also developed methods for optogenetically gating ultrasonic vocalizations (USVs) and for distorting vocal feedback in the isolated, head-fixed mouse. Here we propose to combine these methods with other state of the art techniques, including multi-electrode arrays, in vivo multiphoton imaging, controlled manipulation of vocalization-related auditory feedback, and novel computational methods for voco-acoustic analysis. In the first Aim, we will test the idea that vocalization suppresses auditory cortical activity and use machine learning methods to rigorously quantify and compare spontaneous and optogenetically-evoked USVs. In the second Aim, we will isolate cortical contributions to the vocal modulation of auditory cortical activity. In the third Aim, we will distort vocal feedback to determine if vocal suppression of the auditory cortex is predictive, and use computational methods to systematically quantify vocal distortion. Together, these Aims will provide novel insights into the synaptic, cellular, and circuit mechanisms by which vocal CD signals influence auditory cortical processing. Project Narrative Normal hearing depends on the brain’s ability to anticipate and suppress responses to self-generated vocal sounds, while impaired suppression generates auditory hallucinations. We aim to show how vocal motor signals suppress auditory activity in the brain, thus informing how hearing works in health and disease.",Motor Modulation of Auditory Processing,10121250,R01DC013826,"['Acoustics', 'Address', 'Animals', 'Arousal', 'Auditory', 'Auditory Hallucination', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Bone Conduction', 'Brain', 'Cells', 'Communication', 'Complex', 'Computing Methodologies', 'Courtship', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Feedback', 'Female', 'Functional disorder', 'Funding', 'Genetic', 'Goals', 'Grant', 'Head', 'Head Movements', 'Health', 'Hearing', 'Human', 'Image', 'Impairment', 'Interneurons', 'Knowledge', 'Learning', 'Locomotion', 'Maps', 'Measures', 'Methods', 'Monitor', 'Monkeys', 'Motor', 'Movement', 'Mus', 'Neurons', 'Optical Methods', 'Optics', 'Pathway interactions', 'Physiological', 'Process', 'Production', 'Property', 'Pyramidal Cells', 'Resolution', 'Signal Transduction', 'Social Environment', 'Speech', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Thalamic structure', 'Time', 'Ultrasonics', 'Variant', 'Work', 'auditory feedback', 'auditory processing', 'auditory stimulus', 'autoencoder', 'deaf', 'excitatory neuron', 'experience', 'experimental study', 'flexibility', 'in vivo', 'inhibitory neuron', 'insight', 'machine learning method', 'male', 'multi-electrode arrays', 'multiphoton imaging', 'neural circuit', 'normal hearing', 'novel', 'optogenetics', 'prevent', 'response', 'social', 'sound', 'tool', 'two-photon', 'unsupervised learning', 'vocalization']",NIDCD,DUKE UNIVERSITY,R01,2021,429899
