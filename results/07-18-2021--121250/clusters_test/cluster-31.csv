text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Transcriptional Regulatory Networks of Craniofacial Development Abstract Human craniofacial development is a complex process and frequently goes awry to cause a major class of birth defects, orofacial clefting, which affects approximately 1 in 700 live births. Proper facial development in mouse and human requires three sets of paired facial prominences coming together by growth, morphogenesis, and fusion. Embryonic facial development is strikingly similar in human and mouse, making the mouse the best available model system for human. Previous studies have shown that the expression of many thousands of genes changes across tissue layer, age, and/or prominence, as well as cell population during early mouse facial development. However, we still only have a rudimentary understanding of how these changes are regulated by the interaction of transcriptional modulators in the developing face. To understand how genes are transcriptionally regulated during facial development, this research seeks to construct transcriptional regulatory networks in a temporospatial manner by in silico analysis of publicly available multi- omic datasets. Aim 1 will focus on the identification and verification of transcriptional regulatory networks operating in facial mesenchyme with a focus on super-enhancers. Aim 2 will adopt a similar approach to study the ectoderm which acts as a vital signaling center for the mesenchyme. Finally, in Aim 3 I will apply knowledge from Aims 1 and 2 to build transcriptional regulatory networks at the single cell level. These aims will take advantage of available RNA-seq, ATAC-seq, histone marker ChIP-seq, transcription factor ChIP-seq, bulk and single cell RNA-seq data from wild-type or mutant mice, as well as facial enhancer expression databases. Accomplishment of these studies will predict how genes are transcriptionally regulated in a temporospatial manner during facial development and discover sets of core transcription factors and super- enhancers controlling facial development. These transcriptional regulatory networks will be relevant to the genetic and molecular underpinnings of human orofacial clefting, and will provide clear testable predictions about transcription factor function and the consequences of aberrant expression. Performance and accomplishment of these Aims will also act as a major component of my career development plan, in which my goal is to obtain and independent tenure-track faculty position and serve as a mentor to the next generation of scientists. A major aspect of my career development plan is to build on my growing strength in bioinformatics by learning more advanced techniques in this specialty alongside new computational based approaches, such as machine learning. In this respect, my Aims and career development plan are aligned with a Notice of Special Interest (NOSI) of NIDCR in Supporting Dental, Oral, and Craniofacial Research Using Bioinformatic, Computational, and Data Science Approaches (NOT-DE-20-006) for which this application is targeted. I have recruited a mentorship team with specialties in craniofacial biology, bioinformatics, machine learning, and career development to help me achieve these goals. Project Narrative Human craniofacial development is a complex process and requires suites of genes to be switched on and off at appropriate times and spaces during formation of the embryo. There is now a wealth of data available in public databases concerning which genes are expressed when and where during mammalian facial development, including for the transcription factors which are the proteins that regulate these critical expression programs, but we have not yet begun to connect this information together to derive logical predictions about the critical networks responsible for craniofacial development. This proposal will address that gap using both computational and laboratory-based methods to derive and verify transcriptional regulatory networks relevant to the genetic and molecular underpinnings of normal facial development as well as how these are disrupted to cause defects such as human orofacial clefting.",Transcriptional Regulatory Networks of Craniofacial Development,10284443,K01DE030923,"['ATAC-seq', 'Address', 'Adopted', 'Affect', 'Age', 'Automobile Driving', 'Bioinformatics', 'Biological Assay', 'Biological Models', 'Biology', 'Cartilage', 'Cells', 'ChIP-seq', 'Complex', 'Computational Science', 'Computer Models', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Databases', 'Defect', 'Dental', 'Dependence', 'Development', 'Development Plans', 'Ectoderm', 'Embryo', 'Enhancers', 'Face', 'FaceBase', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Growth', 'Histones', 'Human', 'Human Genetics', 'Instruction', 'Knowledge', 'Laboratories', 'Learning', 'Live Birth', 'Machine Learning', 'Mentors', 'Mentorship', 'Mesenchymal', 'Mesenchyme', 'Methods', 'Molecular', 'Morphogenesis', 'Mus', 'Muscle', 'Mutant Strains Mice', 'National Institute of Dental and Craniofacial Research', 'Oral', 'Pathology', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Process', 'Proteins', 'Regulatory Element', 'Research', 'Resources', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Solid', 'Study models', 'System', 'Techniques', 'Technology', 'Time', 'Tissues', 'Transcriptional Regulation', 'Transgenic Organisms', 'Validation', 'Wild Type Mouse', 'base', 'bone', 'career', 'career development', 'cell type', 'craniofacial', 'craniofacial development', 'critical period', 'design', 'differential expression', 'in silico', 'interest', 'medical specialties', 'mouse model', 'multiple omics', 'network models', 'next generation', 'orofacial cleft', 'programs', 'promoter', 'recruit', 'research and development', 'single-cell RNA sequencing', 'spatiotemporal', 'tenure track', 'transcription factor', 'transcriptome', 'transcriptome sequencing']",NIDCR,UNIVERSITY OF COLORADO DENVER,K01,2021,130135
"Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure Abstract As a constitutent component of CIFASD4, this project will focus on earlier detection of the neurofacial effects of prenatal alcohol exposure. Four topics of the Request for Application (RFA) will be targeted: a) improved FAS/FASD facial recognition through 3D photography and computer analyses in individuals of different age groups; b) the utility of prenatal ultrasound as a screening or diagnostic modality; c) 3D facial imaging during the neonatal period to detect more subtle facial features affected by prenatal alcohol exposure; d) innovative uses of technologies, including handheld devices with apps, to screen for dysmorphology. Previously, we have implemented methods and associated software for analyzing postnatal face shape for the detection of the effects of prenatal alcohol exposure. Although effective in their accuracy, they rely on the use of expensive and relatively clumsy 3D cameras for which not insignificant training is required. New methods of 2D image analysis are available, mobile device acquisition of 3D images is imminent and online recruitment to clinical research is becoming more common place. Finally, state-of-the-art machine learning methods are proving effective in large-scale analysis of ultrasound and MRI data. To accomplish our goals, we propose the following specific aims: 1. Automated screening of facial images for effects of prenatal alcohol exposure with potential for on-line and  mobile device use and integration of genetic, behavioral and cognitive data; 2. Fetal ultrasound analysis to detect facial, cranial and neural effects of prenatal alcohol exposure with  neonatal follow-up; 3. Algorithm and software development to improve current analysis of face-brain-alcohol interactions. Achieving aim 1 will dramatically impact access to validated facial screening for prenatal alcohol exposure. Successful demonstration of aim 2 will achieve the earliest possible diagnosis enabling further research on interventions but also anticipatory neonatal management. Progress in aim 3 will enhance face-brain morphometric analyses in collaboration with other CIFASD partners (U01:Parnell/Eberhart, U01:Wozniak). We will work collaboratively with consortium partners who will recruit subjects and provide facial and ultrasound images (U01: Chambers; U01: Coles; U01: Mattson; U01: Weinberg; U01: Wozniak). We will co- operate on the analysis of images arising from basic science partners focusing on the use of animal models. We will rely on research resources for validation of postnatal screening tools (R24 Dysmorphology - Jones) and online/app development and data management (R24 Informatics - Barnett). Project Narrative The goal of this project is to develop new methods for screening for the effects of prenatal alcohol exposure. It will exploit the wide availability and convenience of smartphone and tablet devices to detect the facial effects in children and adults and new ways of analyzing ultrasound images to detect facial and brain effects in the fetus. Our aim is to establish earlier detection so as to allow earlier intervention to improve outcome.",Image Analysis of Neurofacial Effects of Prenatal Alcohol  Exposure,10174601,U01AA014809,"['3-Dimensional', '3D Print', '3D ultrasound', 'Adult', 'Affect', 'Agreement', 'Alcohols', 'Animal Model', 'Animals', 'Area', 'Basic Science', 'Behavioral', 'Brain', 'Caucasians', 'Cellular Phone', 'Cephalic', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Cognitive', 'Collaborations', 'Color', 'Computer Analysis', 'Computer software', 'Corpus Callosum', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Discrimination', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Evaluation', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal alcohol effects', 'Fetus', 'Genetic', 'Goals', 'Hand', 'Image', 'Image Analysis', 'Impaired cognition', 'Individual', 'Informatics', 'Intervention', 'Link', 'Location', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Modality', 'Monoclonal Antibody R24', 'Neonatal', 'Nose', 'Photography', 'Pilot Projects', 'Pregnancy', 'Preparation', 'Request for Applications', 'Research', 'Research Project Grants', 'Resources', 'Screening procedure', 'Shapes', 'Software Tools', 'Syndrome', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Ultrasonography', 'Validation', 'Weight', 'Work', 'age group', 'alcohol exposure', 'algorithm development', 'automated image analysis', 'base', 'caudate nucleus', 'clinical Diagnosis', 'cohort', 'cost', 'data management', 'experience', 'fetal', 'follow-up', 'handheld equipment', 'handheld mobile device', 'improved', 'improved outcome', 'indexing', 'innovation', 'machine learning method', 'maternal cigarette smoking', 'mouse model', 'neonatal period', 'novel', 'operation', 'postnatal', 'potential biomarker', 'prenatal', 'prenatal testing', 'recruit', 'relating to nervous system', 'screening', 'software development', 'tobacco exposure']",NIAAA,UNIVERSITY OF OXFORD,U01,2021,225264
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ï»¿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9841303,R01DC014498,"['3-Dimensional', 'Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deaf', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'machine learning algorithm', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,317844
